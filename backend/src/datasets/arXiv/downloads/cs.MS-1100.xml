<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.MS%26id_list%3D%26start%3D0%26max_results%3D1100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.MS&amp;id_list=&amp;start=0&amp;max_results=1100</title>
  <id>http://arxiv.org/api/ZgQWOUlcAvLVOCCbybttKR7EPV8</id>
  <updated>2025-05-27T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">2391</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1202.1490v1</id>
    <updated>2012-02-07T18:37:07Z</updated>
    <published>2012-02-07T18:37:07Z</published>
    <title>Singular Values using Cholesky Decomposition</title>
    <summary>  In this paper two ways to compute singular values are presented which use
Cholesky decomposition as their basic operation.
</summary>
    <author>
      <name>Aravindh Krishnamoorthy</name>
    </author>
    <author>
      <name>Kenan Kocagoez</name>
    </author>
    <link href="http://arxiv.org/abs/1202.1490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.2630v1</id>
    <updated>2014-03-11T16:23:23Z</updated>
    <published>2014-03-11T16:23:23Z</published>
    <title>A SageTeX Hypermatrix Algebra Package</title>
    <summary>  We describe here a rudimentary sage implementation of the Bhattacharya-Mesner
hypermatrix algebra package.
</summary>
    <author>
      <name>Edinah K. Gnang</name>
    </author>
    <author>
      <name>Ori Parzanchevski</name>
    </author>
    <author>
      <name>Yuval Filmus</name>
    </author>
    <link href="http://arxiv.org/abs/1403.2630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.2630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.0039v1</id>
    <updated>2014-06-27T00:13:14Z</updated>
    <published>2014-06-27T00:13:14Z</published>
    <title>Integer formula encoding SageTeX package</title>
    <summary>  The paper describes a SageTeX implementation of an integer encoding
procedures.
</summary>
    <author>
      <name>Edinah K. Gnang</name>
    </author>
    <link href="http://arxiv.org/abs/1407.0039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.0039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07848v1</id>
    <updated>2016-12-23T01:16:54Z</updated>
    <published>2016-12-23T01:16:54Z</published>
    <title>BSEPACK User's Guide</title>
    <summary>  This is the user manual for the software package BSEPACK (Bethe--Salpeter
Eigenvalue Solver Package).
</summary>
    <author>
      <name>Meiyue Shao</name>
    </author>
    <author>
      <name>Chao Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The software is available at
  https://sites.google.com/a/lbl.gov/bsepack/</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.3141v1</id>
    <updated>2007-04-24T08:33:52Z</updated>
    <published>2007-04-24T08:33:52Z</published>
    <title>Algorithm for Evaluation of the Interval Power Function of Unconstrained
  Arguments</title>
    <summary>  We describe an algorithm for evaluation of the interval extension of the
power function of variables x and y given by the expression x^y. Our algorithm
reduces the general case to the case of non-negative bases.
</summary>
    <author>
      <name>Evgueni Petrov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.3141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.3141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3020v1</id>
    <updated>2011-03-15T20:27:16Z</updated>
    <published>2011-03-15T20:27:16Z</published>
    <title>A study of the existing linear algebra libraries that you can use from
  C++ (Une étude des bibliothèques d'algèbre linéaire utilisables en
  C++)</title>
    <summary>  A study of the existing linear algebra libraries that you can use from C++
</summary>
    <author>
      <name>Claire Mouton</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1103.3020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.6005v2</id>
    <updated>2012-03-30T18:49:36Z</updated>
    <published>2012-03-27T15:57:59Z</published>
    <title>The Kernel Quantum Probabilities (KQP) Library</title>
    <summary>  In this document, we show how the different quantities necessary to compute
kernel quantum probabilities can be computed. This document form the basis of
the implementation of the Kernel Quantum Probability (KQP) open source project
</summary>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Describes the library available at http://kqp.bpiwowar.net/</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.6005v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.6005v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3020v1</id>
    <updated>2012-04-12T16:36:59Z</updated>
    <published>2012-04-12T16:36:59Z</published>
    <title>TeXmacs-Reduce interface</title>
    <summary>  This tutorial (based on the talk at the TeXmacs workshop in Faro, Portugal,
February 26 - March 2, 2012) describes the new and improved Reduce plugin in
GNU TeXmacs.
</summary>
    <author>
      <name>Andrey Grozin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">html exported from TeXmacs (alas, arXiv does not accept TeXmacs
  files)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.3020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4212v1</id>
    <updated>2012-05-17T07:32:57Z</updated>
    <published>2012-05-17T07:32:57Z</published>
    <title>Sample programs in C++ for matrix computations in max plus algebra</title>
    <summary>  The main purpose of this paper is to propose five programs in C++ for matrix
computations and solving recurrent equations systems with entries in max plus
algebra.
</summary>
    <author>
      <name>Mihai Ivan</name>
    </author>
    <author>
      <name>Gheorghe Ivan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A80, 68-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5353v1</id>
    <updated>2014-01-21T15:43:52Z</updated>
    <published>2014-01-21T15:43:52Z</published>
    <title>STABLAB Documentation for KdV : Numerical proof of stability of roll
  waves in the small-amplitude limit for inclined thin film flow</title>
    <summary>  We document the MATLAB code used in the following study: Numerical proof of
stability of roll waves in the small-amplitude limit for inclined thin film
flow.
</summary>
    <author>
      <name>Blake Barker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Documentation, 255 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.5353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04979v3</id>
    <updated>2016-01-20T23:51:33Z</updated>
    <published>2015-01-16T01:22:55Z</published>
    <title>FASTA: A Generalized Implementation of Forward-Backward Splitting</title>
    <summary>  This is a user manual for the software package FASTA.
</summary>
    <author>
      <name>Tom Goldstein</name>
    </author>
    <author>
      <name>Christoph Studer</name>
    </author>
    <author>
      <name>Richard Baraniuk</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04979v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04979v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07231v1</id>
    <updated>2015-08-28T14:42:09Z</updated>
    <published>2015-08-28T14:42:09Z</published>
    <title>Clone and graft: Testing scientific applications as they are built</title>
    <summary>  This article describes our experience developing and maintaining automated
tests for scientific applications. The main idea evolves around building on
already existing tests by cloning and grafting. The idea is demonstrated on a
minimal model problem written in Python.
</summary>
    <author>
      <name>Bruno Turcksin</name>
    </author>
    <author>
      <name>Timo Heister</name>
    </author>
    <author>
      <name>Wolfgang Bangerth</name>
    </author>
    <link href="http://arxiv.org/abs/1508.07231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05057v1</id>
    <updated>2016-05-17T08:40:14Z</updated>
    <published>2016-05-17T08:40:14Z</published>
    <title>The polymake XML file format</title>
    <summary>  We describe an XML file format for storing data from computations in algebra
and geometry. We also present a formal specification based on a RELAX-NG
schema.
</summary>
    <author>
      <name>Ewgenij Gawrilow</name>
    </author>
    <author>
      <name>Simon Hampe</name>
    </author>
    <author>
      <name>Michael Joswig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Extended abstract for the 5th International Congress on
  Mathematical Software (ICMS), Berlin 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.09567v1</id>
    <updated>2016-11-29T11:12:06Z</updated>
    <published>2016-11-29T11:12:06Z</published>
    <title>Moore: Interval Arithmetic in Modern C++</title>
    <summary>  We present the library Moore, which implements Interval Arithmetic in modern
C++. This library is based on a new feature in the C++ language called
concepts, which reduces the problems caused by template meta programming, and
leads to a new approach for implementing interval arithmetic libraries in C++.
</summary>
    <author>
      <name>Walter F. Mascarenhas</name>
    </author>
    <link href="http://arxiv.org/abs/1611.09567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.09567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08558v1</id>
    <updated>2018-02-21T19:02:45Z</updated>
    <published>2018-02-21T19:02:45Z</published>
    <title>Moore: Interval Arithmetic in C++20</title>
    <summary>  This article presents the Moore library for interval arithmetic in C++20. It
gives examples of how the library can be used, and explains the basic
principles underlying its design.
</summary>
    <author>
      <name>Walter F. Mascarenhas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1611.09567"</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.08558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.08607v2</id>
    <updated>2018-08-23T09:56:59Z</updated>
    <published>2018-07-11T09:19:41Z</published>
    <title>Computational and applied topology, tutorial</title>
    <summary>  This is a tutorial in applied and computational topology and topological data
analysis. It is illustrated with numerous computational examples that utilize
Gudhi library. It is under constant development, so please do not consider this
version as final.
</summary>
    <author>
      <name>Paweł Dłotko</name>
    </author>
    <link href="http://arxiv.org/abs/1807.08607v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.08607v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.09891v1</id>
    <updated>2018-10-23T14:46:09Z</updated>
    <published>2018-10-23T14:46:09Z</published>
    <title>Nonequispaced Fast Fourier Transform (NFFT) Interface for Julia</title>
    <summary>  This report describes the newly added Julia interface to the NFFT3 library.
We explain the multidimensional NFFT algorithm and basics of the interface.
Furthermore, we go into detail about the different parameters and how to adjust
them properly.
</summary>
    <author>
      <name>Michael Schmischke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.09891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.09891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07645v1</id>
    <updated>2019-12-16T19:17:46Z</updated>
    <published>2019-12-16T19:17:46Z</published>
    <title>Alsvinn: A Fast multi-GPGPU finite volume solver with a strong emphasis
  on reproducibility</title>
    <summary>  We present the Alsvinn simulator, a fast multi general purpose graphical
processing unit (GPGPU) finite volume solver for hyperbolic conservation laws
in multiple space dimensions. Alsvinn has native support for uncertainty
quantifications, and exhibits excellent scaling on top tier compute clusters.
</summary>
    <author>
      <name>Kjetil Lye</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.03772v1</id>
    <updated>2023-02-07T22:05:26Z</updated>
    <published>2023-02-07T22:05:26Z</published>
    <title>A note on the standard diffusion curve of TAP analysis</title>
    <summary>  The standard diffusion curve used in models of TAP reactors, as it is usually
defined, is numerically unstable for small values. We use a functional equation
satisfied by the curve to define a numerically stable way of computing it for
all values.
</summary>
    <author>
      <name>Toby Isaac</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 figures, 2 code listings</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.03772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.03772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.16589v2</id>
    <updated>2023-07-04T18:37:18Z</updated>
    <published>2023-06-28T22:41:14Z</published>
    <title>Collective-Optimized FFTs</title>
    <summary>  This paper measures the impact of the various alltoallv methods. Results are
analyzed within Beatnik, a Z-model solver that is bottlenecked by HeFFTe and
representative of applications that rely on FFTs.
</summary>
    <author>
      <name>Evelyn Namugwanya</name>
    </author>
    <author>
      <name>Amanda Bienz</name>
    </author>
    <author>
      <name>Derek Schafer</name>
    </author>
    <author>
      <name>Anthony Skjellum</name>
    </author>
    <link href="http://arxiv.org/abs/2306.16589v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.16589v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.00465v1</id>
    <updated>2023-09-01T14:03:44Z</updated>
    <published>2023-09-01T14:03:44Z</published>
    <title>A FAIR File Format for Mathematical Software</title>
    <summary>  We describe a generic JSON based file format which is suitable for
computations in computer algebra. This is implemented in the computer algebra
system OSCAR, but we also indicate how it can be used in a different context.
</summary>
    <author>
      <name>Antony Della Vecchia</name>
    </author>
    <author>
      <name>Michael Joswig</name>
    </author>
    <author>
      <name>Benjamin Lorenz</name>
    </author>
    <link href="http://arxiv.org/abs/2309.00465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.00465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.06241v1</id>
    <updated>2024-04-09T12:08:24Z</updated>
    <published>2024-04-09T12:08:24Z</published>
    <title>Confirmable Workflows in OSCAR</title>
    <summary>  We discuss what is special about the reproducibility of workflows in computer
algebra. It is emphasized how the programming language Julia and the new
computer algebra system OSCAR support such a reproducibility, and how users can
benefit for their own work.
</summary>
    <author>
      <name>Michael Joswig</name>
    </author>
    <author>
      <name>Lars Kastner</name>
    </author>
    <author>
      <name>Benjamin Lorenz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.06241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.06241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.09622v1</id>
    <updated>2024-09-15T06:11:57Z</updated>
    <published>2024-09-15T06:11:57Z</published>
    <title>Computing Arrangements of Hypersurfaces</title>
    <summary>  We present a Julia package HypersurfaceRegions.jl for computing all connected
components in the complement of an arrangement of real algebraic hypersurfaces
in $\mathbb{R}^n$.
</summary>
    <author>
      <name>Paul Breiding</name>
    </author>
    <author>
      <name>Bernd Sturmfels</name>
    </author>
    <author>
      <name>Kexin Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.09622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.09622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809105v1</id>
    <updated>1998-09-24T20:56:11Z</updated>
    <published>1998-09-24T20:56:11Z</published>
    <title>Hyper-Systolic Matrix Multiplication</title>
    <summary>  A novel parallel algorithm for matrix multiplication is presented. The
hyper-systolic algorithm makes use of a one-dimensional processor abstraction.
The procedure can be implemented on all types of parallel systems. It can
handle matrix-vector multiplications as well as transposed matrix products.
</summary>
    <author>
      <name>Thomas Lippert</name>
    </author>
    <author>
      <name>Nikolay Petkov</name>
    </author>
    <author>
      <name>Paolo Palazzari</name>
    </author>
    <author>
      <name>Klaus Schilling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0004004v1</id>
    <updated>2000-04-13T13:43:48Z</updated>
    <published>2000-04-13T13:43:48Z</published>
    <title>Mathematical Software: Past, Present, and Future</title>
    <summary>  This paper provides some reflections on the field of mathematical software on
the occasion of John Rice's 65th birthday. I describe some of the common themes
of research in this field and recall some significant events in its evolution.
Finally, I raise a number of issues that are of concern to future developments.
</summary>
    <author>
      <name>Ronald F. Boisvert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the Proceedings of the International Symposium on
  Computational Sciences, Purdue University, May 21-22, 1999. 20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0004004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0004004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101001v1</id>
    <updated>2001-01-03T17:33:59Z</updated>
    <published>2001-01-03T17:33:59Z</published>
    <title>Automatic Differentiation Tools in Optimization Software</title>
    <summary>  We discuss the role of automatic differentiation tools in optimization
software. We emphasize issues that are important to large-scale optimization
and that have proved useful in the installation of nonlinear solvers in the
NEOS Server. Our discussion centers on the computation of the gradient and
Hessian matrix for partially separable functions and shows that the gradient
and Hessian matrix can be computed with guaranteed bounds in time and memory
requirements
</summary>
    <author>
      <name>Jorge J. Moré</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0101001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102001v2</id>
    <updated>2004-03-05T16:28:24Z</updated>
    <published>2001-02-01T20:37:46Z</published>
    <title>Benchmarking Optimization Software with Performance Profiles</title>
    <summary>  We propose performance profiles-distribution functions for a performance
metric-as a tool for benchmarking and comparing optimization software. We show
that performance profiles combine the best features of other tools for
performance evaluation.
</summary>
    <author>
      <name>Elizabeth D. Dolan</name>
    </author>
    <author>
      <name>Jorge J. Moré</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages plus title and toc pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Math. Program., Ser. A 91: 201-213 (2002)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0102001v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102001v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310057v1</id>
    <updated>2003-10-28T19:41:44Z</updated>
    <published>2003-10-28T19:41:44Z</published>
    <title>An Introduction to Using Software Tools for Automatic Differentiation</title>
    <summary>  We give a gentle introduction to using various software tools for automatic
differentiation (AD). Ready-to-use examples are discussed, and links to further
information are presented. Our target audience includes all those who are
looking for a straightforward way to get started using the available AD
technology. The document is dynamic in the sense that its content will be
updated as the AD software evolves.
</summary>
    <author>
      <name>Uwe Naumann</name>
    </author>
    <author>
      <name>Andrea Walther</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406049v1</id>
    <updated>2004-06-25T20:37:44Z</updated>
    <published>2004-06-25T20:37:44Z</published>
    <title>A Fast, Vectorizable Algorithm for Producing Single-Precision
  Sine-Cosine Pairs</title>
    <summary>  This paper presents an algorithm for computing Sine-Cosine pairs to modest
accuracy, but in a manner which contains no conditional tests or branching,
making it highly amenable to vectorization. An exemplary implementation for
PowerPC AltiVec processors is included, but the algorithm should be easily
portable to other achitectures, such as Intel SSE.
</summary>
    <author>
      <name>Marcus H. Mendenhall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 block sample code</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0406049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505031v1</id>
    <updated>2005-05-11T18:50:32Z</updated>
    <published>2005-05-11T18:50:32Z</published>
    <title>Estudo e Implementacao de Algoritmos de Roteamento sobre Grafos em um
  Sistema de Informacoes Geograficas</title>
    <summary>  This article presents an implementation of a graphical software with various
algorithms in Operations research, like minimum path, minimum tree, chinese
postman problem and travelling salesman.
</summary>
    <author>
      <name>Rudini M. Sampaio</name>
    </author>
    <author>
      <name>Horacio H. Yanasse</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science, 3(1), 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604038v1</id>
    <updated>2006-04-10T06:30:02Z</updated>
    <published>2006-04-10T06:30:02Z</published>
    <title>UniCalc.LIN: a linear constraint solver for the UniCalc system</title>
    <summary>  In this short paper we present a linear constraint solver for the UniCalc
system, an environment for reliable solution of mathematical modeling problems.
</summary>
    <author>
      <name>E. Petrov</name>
    </author>
    <author>
      <name>Yu. Kostov</name>
    </author>
    <author>
      <name>E. Botoeva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">rejected by the programm committee of the conforence on Perspective
  of System Informatics held in Novosibirsk, Russian Federation July 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0604038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609082v1</id>
    <updated>2006-09-14T18:32:46Z</updated>
    <published>2006-09-14T18:32:46Z</published>
    <title>Classifying extrema using intervals</title>
    <summary>  We present a straightforward and verified method of deciding whether the
n-dimensional point x (n&gt;=1), such that \nabla f(x)=0, is the local minimizer,
maximizer or just a saddle point of a real-valued function f.
  The method scales linearly with dimensionality of the problem and never
produces false results.
</summary>
    <author>
      <name>Marek W. Gutowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTeX, 7 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.1.0; G.1.2; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4053v1</id>
    <updated>2009-03-24T10:10:37Z</updated>
    <published>2009-03-24T10:10:37Z</published>
    <title>The generating of Fractal Images Using MathCAD Program</title>
    <summary>  This paper presents the graphic representation in the z-plane of the first
three iterations of the algorithm that generates the Sierpinski Gasket. It
analyzes the influence of the f(z) map when we represent fractal images.
</summary>
    <author>
      <name>Laura Stefan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, exposed on 2nd "European Conference on Computer Science and
  Applications" - XA2008, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series 6 (2008), 211 - 220</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.4053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4307v1</id>
    <updated>2009-03-25T11:42:46Z</updated>
    <published>2009-03-25T11:42:46Z</published>
    <title>FISLAB - the Fuzzy Inference Tool-box for SCILAB</title>
    <summary>  The present study represents "The Fislab package of programs meant to develop
the fuzzy regulators in the Scilab environment" in which we present some
general issues, usage requirements and the working mode of the Fislab
environment. In the second part of the article some features of the Scilab
functions from the Fislab package are described.
</summary>
    <author>
      <name>Simona Apostol</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 105-114</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.4307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.4598v1</id>
    <updated>2009-05-28T10:10:06Z</updated>
    <published>2009-05-28T10:10:06Z</published>
    <title>Iterative Methods for Systems' Solving - a C# approach</title>
    <summary>  This work wishes to support various mathematical issues concerning the
iterative methods with the help of new programming languages. We consider a way
to show how problems in math have an answer by using different academic
resources and different thoughts. Here we treat methods like Gauss-Seidel's,
Cramer's and Gauss-Jordan's.
</summary>
    <author>
      <name>Claudiu Chirilov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages,exposed on 5th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2009, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 71-78</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.4598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.4598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3180v1</id>
    <updated>2010-02-16T22:17:56Z</updated>
    <published>2010-02-16T22:17:56Z</published>
    <title>Factorization of Non-Commutative Polynomials</title>
    <summary>  We describe an algorithm for the factorization of non-commutative polynomials
over a field. The first sketch of this algorithm appeared in an unpublished
manuscript (literally hand written notes) by James H. Davenport more than 20
years ago. This version of the algorithm contains some improvements with
respect to the original sketch. An improved version of the algorithm has been
fully implemented in the Axiom computer algebra system.
</summary>
    <author>
      <name>Fabrizio Caruso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4725v1</id>
    <updated>2010-02-25T15:42:39Z</updated>
    <published>2010-02-25T15:42:39Z</published>
    <title>Transferring a symbolic polynomial expression from \emph{Mathematica} to
  \emph{Matlab}</title>
    <summary>  A \emph{Mathematica} Notebook is presented which allows for the transfer or
any kind of polynomial expression to \emph{Matlab}. The output is formatted in
such a way that \emph{Matlab} routines such as "Root" can be readily
implemented. Once the Notebook has been executed, only one copy-paste operation
in necessary.
</summary>
    <author>
      <name>A. Bret</name>
    </author>
    <link href="http://arxiv.org/abs/1002.4725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.1628v2</id>
    <updated>2018-01-07T15:18:25Z</updated>
    <published>2010-03-08T13:47:25Z</published>
    <title>Having Fun with Lambert W(x) Function</title>
    <summary>  This short note presents the Lambert W(x) function and its possible
application in the framework of physics related to the Pierre Auger
Observatory. The actual numerical implementation in C++ consists of Halley's
and Fritsch's iteration with branch-point expansion, asymptotic series and
rational fits as initial approximations.
</summary>
    <author>
      <name>Darko Veberic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 11 figures, 4 tables, updated link to sources</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.1628v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.1628v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0404v1</id>
    <updated>2010-06-02T14:30:55Z</updated>
    <published>2010-06-02T14:30:55Z</published>
    <title>Computational Complexity of Iterated Maps on the Interval (Extended
  Abstract)</title>
    <summary>  The exact computation of orbits of discrete dynamical systems on the interval
is considered. Therefore, a multiple-precision floating point approach based on
error analysis is chosen and a general algorithm is presented. The correctness
of the algorithm is shown and the computational complexity is analyzed. As a
main result, the computational complexity measure considered here is related to
the Ljapunow exponent of the dynamical system under consideration.
</summary>
    <author>
      <name>Christoph Spandl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.24.18</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.24.18" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 24, 2010, pp. 139-150</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.0404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0066v1</id>
    <updated>2011-03-01T02:05:42Z</updated>
    <published>2011-03-01T02:05:42Z</published>
    <title>Finite Element Integration on GPUs</title>
    <summary>  We present a novel finite element integration method for low order elements
on GPUs. We achieve more than 100GF for element integration on first order
discretizations of both the Laplacian and Elasticity operators.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Andy R. Terrel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2427023.2427027</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2427023.2427027" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, 39(2), 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2952v1</id>
    <updated>2011-03-14T15:20:46Z</updated>
    <published>2011-03-14T15:20:46Z</published>
    <title>Data sets of very large linear feasibility problems solved by projection
  methods</title>
    <summary>  We give a link to a page on the Web on which we deposited a set of eight huge
Linear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)
treatment planning. These huge LP problems were employed in our recent research
and we were asked to make them public.
</summary>
    <author>
      <name>Wei Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4144v2</id>
    <updated>2013-10-17T20:33:59Z</updated>
    <published>2011-11-17T16:44:40Z</published>
    <title>Matrix Inversion Using Cholesky Decomposition</title>
    <summary>  In this paper we present a method for matrix inversion based on Cholesky
decomposition with reduced number of operations by avoiding computation of
intermediate results; further, we use fixed point simulations to compare the
numerical accuracy of the method.
</summary>
    <author>
      <name>Aravindh Krishnamoorthy</name>
    </author>
    <author>
      <name>Deepak Menon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3pp with minor changes, pre-print; accepted for publication 2013 IEEE
  Signal Processing: Algorithms, Architectures, Arrangements, and Applications
  (SPA) conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4144v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4144v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0540v1</id>
    <updated>2012-01-02T21:48:33Z</updated>
    <published>2012-01-02T21:48:33Z</published>
    <title>ProofPeer - A Cloud-based Interactive Theorem Proving System</title>
    <summary>  ProofPeer strives to be a system for cloud-based interactive theorem proving.
After illustrating why such a system is needed, the paper presents some of the
design challenges that ProofPeer needs to meet to succeed. Contexts are
presented as a solution to the problem of sharing proof state among the users
of ProofPeer. Chronicles are introduced as a way to organize and version
contexts.
</summary>
    <author>
      <name>Steven Obua</name>
    </author>
    <link href="http://arxiv.org/abs/1201.0540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3179v1</id>
    <updated>2012-01-16T09:12:34Z</updated>
    <published>2012-01-16T09:12:34Z</published>
    <title>Matrix representation of a solution of a combinatorial problem of the
  group theory</title>
    <summary>  An equivalence relation in the symmetric group, where is a positive integer
has been considered. An algorithm for calculation of the number of the
equivalence classes by this relation for arbitrary integer has been described.
</summary>
    <author>
      <name>Krasimir Yordzhev</name>
    </author>
    <author>
      <name>Lilyana Totina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Fourth International Scientific Conference --
  FMNS2011, 8 -- 11 June 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics and natural science, v. 1, 2011, 144-152</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.3179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4837v1</id>
    <updated>2012-02-22T06:43:11Z</updated>
    <published>2012-02-22T06:43:11Z</published>
    <title>The GF Mathematics Library</title>
    <summary>  This paper is devoted to present the Mathematics Grammar Library, a system
for multilingual mathematical text processing. We explain the context in which
it originated, its current design and functionality and the current development
goals. We also present two prototype services and comment on possible future
applications in the area of artificial mathematics assistants.
</summary>
    <author>
      <name>Jordi Saludes</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UPC</arxiv:affiliation>
    </author>
    <author>
      <name>Sebastian Xambó</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UPC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.79.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.79.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings THedu'11, arXiv:1202.4535</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 79, 2012, pp. 102-110</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.4837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0053v2</id>
    <updated>2012-04-16T19:17:52Z</updated>
    <published>2012-03-31T00:56:44Z</published>
    <title>Theory Presentation Combinators</title>
    <summary>  We motivate and give semantics to theory presentation combinators as the
foundational building blocks for a scalable library of theories. The key
observation is that the category of contexts and fibered categories are the
ideal theoretical tools for this purpose.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <author>
      <name>Russell O'Connor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-31374-5_14</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-31374-5_14" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of paper to appear in proceedings of CICM 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AISC/MKM/Calculemus 2012: 202-215</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.0053v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0053v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4869v1</id>
    <updated>2012-08-23T21:52:32Z</updated>
    <published>2012-08-23T21:52:32Z</published>
    <title>User Manual for the Complex Conjugate Gradient Methods Library CCGPAK
  2.0</title>
    <summary>  This manual describes the library of conjugate gradients codes CCGPAK, which
solves system of complex linear system of equations. The library is written in
FORTRAN90 and is highly portable. The codes are general and provide mechanism
for matrix times vector multiplication which is separated from the conjugate
gradient iterations itself. It is simple to switch between single and double
precisions. All codes follow the same naming conventions.
</summary>
    <author>
      <name>Piotr J. Flatau</name>
    </author>
    <link href="http://arxiv.org/abs/1208.4869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0735v2</id>
    <updated>2018-01-07T14:33:32Z</updated>
    <published>2012-08-31T21:07:48Z</published>
    <title>Lambert W Function for Applications in Physics</title>
    <summary>  The Lambert W(x) function and its possible applications in physics are
presented. The actual numerical implementation in C++ consists of Halley's and
Fritsch's iterations with initial approximations based on branch-point
expansion, asymptotic series, rational fits, and continued-logarithm recursion.
</summary>
    <author>
      <name>Darko Veberic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2012.07.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2012.07.008" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 12 figures. Extended version of arXiv:1003.1628, updated
  link to sources</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 183 (2012) 2622-2628</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.0735v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0735v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1204v2</id>
    <updated>2013-09-06T19:35:43Z</updated>
    <published>2013-09-04T23:03:33Z</published>
    <title>Achieving High Performance with Unified Residual Evaluation</title>
    <summary>  We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Jed Brown</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1204v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1204v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1783v2</id>
    <updated>2013-09-15T19:56:50Z</updated>
    <published>2013-09-06T21:55:23Z</published>
    <title>DUNE as an Example of Sustainable Open Source Scientific Software
  Development</title>
    <summary>  In this paper we describe how DUNE, an open source scientific software
framework, is developed. Having a sustainable software framework for the
solution of partial differential equations is the main driver of DUNE's
development. We take a look how DUNE strives to stay sustainable software.
</summary>
    <author>
      <name>Makus Blatt</name>
    </author>
    <link href="http://arxiv.org/abs/1309.1783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.9; K.6.1; K.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.7962v1</id>
    <updated>2014-01-29T10:44:45Z</updated>
    <published>2014-01-29T10:44:45Z</published>
    <title>Numerical application and Turbo C program using the Gauss-Jordan Method</title>
    <summary>  The article presents the general notions and algorithm about the Gauss-Jordan
method. An eloquent example is given and the Turbo C program illustrated this
method. We conclude that we can obtain by this method the determinant, by
simple calculations and reducing the rounding errors
</summary>
    <author>
      <name>Anghel Drugarin</name>
    </author>
    <author>
      <name>Cornelia Victoria</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Romanian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Algebra liniara. Programare liniara, vol.1, Eftimie Murgu,Press
  Resita (2003). AGIR Press, vol.22, 2012, pp.171-176</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.7962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.7962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3809v2</id>
    <updated>2014-03-13T17:55:31Z</updated>
    <published>2014-02-16T15:43:05Z</published>
    <title>Toward Resilient Algorithms and Applications</title>
    <summary>  Over the past decade, the high performance computing community has become
increasingly concerned that preserving the reliable, digital machine model will
become too costly or infeasible. In this paper we discuss four approaches for
developing new algorithms that are resilient to hard and soft failures.
</summary>
    <author>
      <name>Michael A. Heroux</name>
    </author>
    <link href="http://arxiv.org/abs/1402.3809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; D.1.3; D.4.5; G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5835v2</id>
    <updated>2016-05-04T20:34:48Z</updated>
    <published>2014-02-24T14:26:08Z</published>
    <title>Polcovar: Software for Computing the Mean and Variance of Subgraph
  Counts in Random Graphs</title>
    <summary>  The mean and variance of the number of appearances of a given subgraph $H$ in
an Erd\H{o}s--R\'enyi random graph over $n$ nodes are rational polynomials in
$n$. We present a piece of software named Polcovar (from "polynomial" and
"covariance") that computes the exact rational coefficients of these
polynomials in function of $H$.
</summary>
    <author>
      <name>Jérôme Kunegis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages; fixed some wording; added link to Github</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.5835v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5835v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5668v1</id>
    <updated>2014-05-22T08:41:00Z</updated>
    <published>2014-05-22T08:41:00Z</published>
    <title>NLCertify: A Tool for Formal Nonlinear Optimization</title>
    <summary>  NLCertify is a software package for handling formal certification of
nonlinear inequalities involving transcendental multivariate functions. The
tool exploits sparse semialgebraic optimization techniques with approximation
methods for transcendental functions, as well as formal features. Given a box
and a transcendental multivariate function as input, NLCertify provides OCaml
libraries that produce nonnegativity certificates for the function over the
box, which can be ultimately proved correct inside the Coq proof assistant.
</summary>
    <author>
      <name>Victor Magron</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5316v1</id>
    <updated>2014-12-17T10:06:49Z</updated>
    <published>2014-12-17T10:06:49Z</published>
    <title>Twofolds in C and C++</title>
    <summary>  Here I propose C and C++ interfaces and experimental implementation for
twofolds arithmetic. I introduce twofolds in my previous article entitled
"Twofold fast arithmetic" for tracking floating-point inaccuracy. Testing
shows, plain C enables high-performance computing with twofolds. C++ interface
enables coding as easily as ordinary floating-point numbers. My goal is
convincing you to try twofolds; I think assuring accuracy of math computations
is worth its cost. Code and use examples available at my web site, references
inside.
</summary>
    <author>
      <name>Evgeny Latkin</name>
    </author>
    <link href="http://arxiv.org/abs/1412.5316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05216v1</id>
    <updated>2015-02-17T02:55:35Z</updated>
    <published>2015-02-17T02:55:35Z</published>
    <title>Twofold exp and log</title>
    <summary>  This article is about twofold arithmetic. Here I introduce algorithms and
experimental code for twofold variant of C/C++ standard functions exp() and
log(), and expm1() and log1p(). Twofold function $y_0+y_1 \approx f(x_0+x_1)$
is nearly 2x-precise so can assess accuracy of standard one. Performance allows
assessing on-fly: twofold texp() over double is ~10x times faster than expq()
by GNU quadmath.
</summary>
    <author>
      <name>Evgeny Latkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Experimental code and tests at "twofolds" project Web site:
  https://sites.google.com/site/yevgenylatkin/</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.05216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06734v1</id>
    <updated>2015-04-25T14:45:33Z</updated>
    <published>2015-04-25T14:45:33Z</published>
    <title>Symmetric matrix inversion using modified Gaussian elimination</title>
    <summary>  In this paper we present two different variants of method for symmetric
matrix inversion, based on modified Gaussian elimination. Both methods avoid
computation of square roots and have a reduced machine time's spending.
Further, both of them can be used efficiently not only for positive (semi-)
definite, but for any non-singular symmetric matrix inversion. We use
simulation to verify results, which represented in this paper.
</summary>
    <author>
      <name>Anton Kochnev</name>
    </author>
    <author>
      <name>Nicolai Savelov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.06734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.01598v2</id>
    <updated>2015-06-17T12:01:04Z</updated>
    <published>2015-06-04T14:09:47Z</published>
    <title>decimalInfinite: All Decimals In Bits, No Loss, Same Order, Simple</title>
    <summary>  This paper introduces a binary encoding that supports arbitrarily large,
small and precise decimals. It completely preserves information and order. It
does not rely on any arbitrary use-case-based choice of calibration and is
readily implementable and usable, as is. Finally, it is also simple to explain
and understand.
</summary>
    <author>
      <name>Ghislain Fourny</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report, 9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.01598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.01598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97R50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.02796v1</id>
    <updated>2015-09-09T14:53:02Z</updated>
    <published>2015-09-09T14:53:02Z</published>
    <title>Rust-Bio - a fast and safe bioinformatics library</title>
    <summary>  We present Rust-Bio, the first general purpose bioinformatics library for the
innovative Rust programming language. Rust-Bio leverages the unique combination
of speed, memory safety and high-level syntax offered by Rust to provide a fast
and safe set of bioinformatics algorithms and data structures with a focus on
sequence analysis.
</summary>
    <author>
      <name>Johannes Köster</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/bioinformatics/btv573</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/bioinformatics/btv573" rel="related"/>
    <link href="http://arxiv.org/abs/1509.02796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.02796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02683v1</id>
    <updated>2016-01-11T23:03:10Z</updated>
    <published>2016-01-11T23:03:10Z</published>
    <title>Software for enumerative and analytic combinatorics</title>
    <summary>  We survey some general-purpose symbolic software packages that implement
algorithms from enumerative and analytic combinatorics. Software for the
following areas is covered: basic combinatorial objects, symbolic
combinatorics, P\'olya theory, combinatorial species, and asymptotics. We
describe the capabilities that the packages offer as well as some of the
algorithms used, and provide links to original documentation. Most of the
packages are freely downloadable from the web.
</summary>
    <author>
      <name>Andrew MacFie</name>
    </author>
    <link href="http://arxiv.org/abs/1601.02683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00999v1</id>
    <updated>2016-09-04T23:44:20Z</updated>
    <published>2016-09-04T23:44:20Z</published>
    <title>Automatic Generation of Vectorized Montgomery Algorithm</title>
    <summary>  Modular arithmetic is widely used in crytography and symbolic computation.
This paper presents a vectorized Montgomery algorithm for modular
multiplication, the key to fast modular arithmetic, that fully utilizes the
SIMD instructions. We further show how the vectorized algorithm can be
automatically generated by the {\SPIRAL} system, as part of the effort for
automatic generation of a modular polynomial multiplication library.
</summary>
    <author>
      <name>Lingchuan Meng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, based on the thesis work by Lingchuan Meng</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.00999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01534v1</id>
    <updated>2016-11-03T10:09:13Z</updated>
    <published>2016-11-03T10:09:13Z</published>
    <title>GFA: Exploratory Analysis of Multiple Data Sources with Group Factor
  Analysis</title>
    <summary>  The R package GFA provides a full pipeline for factor analysis of multiple
data sources that are represented as matrices with co-occurring samples. It
allows learning dependencies between subsets of the data sources, decomposed
into latent factors. The package also implements sparse priors for the
factorization, providing interpretable biclusters of the multi-source data
</summary>
    <author>
      <name>Eemeli Leppäaho</name>
    </author>
    <author>
      <name>Muhammad Ammad-ud-din</name>
    </author>
    <author>
      <name>Samuel Kaski</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03266v1</id>
    <updated>2017-05-09T10:45:42Z</updated>
    <published>2017-05-09T10:45:42Z</published>
    <title>Computing the Lambert W function in arbitrary-precision complex interval
  arithmetic</title>
    <summary>  We describe an algorithm to evaluate all the complex branches of the Lambert
W function with rigorous error bounds in interval arithmetic, which has been
implemented in the Arb library. The classic 1996 paper on the Lambert W
function by Corless et al. provides a thorough but partly heuristic numerical
analysis which needs to be complemented with some explicit inequalities and
practical observations about managing precision and branch cuts.
</summary>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.03266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09616v3</id>
    <updated>2018-08-28T06:42:48Z</updated>
    <published>2017-07-30T13:18:06Z</published>
    <title>Owl: A General-Purpose Numerical Library in OCaml</title>
    <summary>  Owl is a new numerical library developed in the OCaml language. It focuses on
providing a comprehensive set of high-level numerical functions so that
developers can quickly build up data analytical applications. In this abstract,
we will present Owl's design, core components, and its key functionality.
</summary>
    <author>
      <name>Liang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1707.09616v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09616v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04021v1</id>
    <updated>2017-08-14T07:13:39Z</updated>
    <published>2017-08-14T07:13:39Z</published>
    <title>The basic principles and the structure and algorithmically software of
  computing by hypercomplex number</title>
    <summary>  In article the basic principles put in a basis of algorithmicallysoftware of
hypercomplex number calculations, structure of a software, structure of
functional subsystems are considered. The most important procedures included in
subsystems are considered, program listings and examples of their application
are given.
</summary>
    <author>
      <name>Ya. Kalinovsky</name>
    </author>
    <author>
      <name>Yu. Boyarinova</name>
    </author>
    <author>
      <name>A. Sukalo</name>
    </author>
    <author>
      <name>Ya. Hitsko</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.05554v1</id>
    <updated>2018-01-17T05:19:49Z</updated>
    <published>2018-01-17T05:19:49Z</published>
    <title>rlsm: R package for least squares Monte Carlo</title>
    <summary>  This short paper briefly describes the implementation of the least squares
Monte Carlo method in the rlsm package. This package provides users with an
easy manner to experiment with the large amount of R regression tools on any
regression basis and reward functions. This package also computes lower and
upper bounds for the true value function via duality methods.
</summary>
    <author>
      <name>Jeremy Yee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.05554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.05554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.06029v1</id>
    <updated>2018-01-18T14:19:36Z</updated>
    <published>2018-01-18T14:19:36Z</published>
    <title>rcss: Subgradient and duality approach for dynamic programming</title>
    <summary>  This short paper gives an introduction to the \emph{rcss} package. The R
package \emph{rcss} provides users with a tool to approximate the value
functions in the Bellman recursion using convex piecewise linear functions
formed using operations on tangents. A pathwise method is then used to gauge
the quality of the numerical results.
</summary>
    <author>
      <name>Juri Hinz</name>
    </author>
    <author>
      <name>Jeremy Yee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.06029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.06029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.07942v1</id>
    <updated>2018-02-22T08:46:14Z</updated>
    <published>2018-02-22T08:46:14Z</published>
    <title>Numerical integration in arbitrary-precision ball arithmetic</title>
    <summary>  We present an implementation of arbitrary-precision numerical integration
with rigorous error bounds in the Arb library. Rapid convergence is ensured for
piecewise complex analytic integrals by use of the Petras algorithm, which
combines adaptive bisection with adaptive Gaussian quadrature where error
bounds are determined via complex magnitudes without evaluating derivatives.
The code is general, easy to use, and efficient, often outperforming existing
non-rigorous software.
</summary>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.07942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.07942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65G20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.10469v2</id>
    <updated>2018-11-30T15:56:06Z</updated>
    <published>2018-06-26T10:07:22Z</published>
    <title>Elfun18 A collection of Matlab functions for the computation of
  Elliptical Integrals and Jacobian elliptic functions of real arguments</title>
    <summary>  In the article we outline the set of Matlab functions that enable the
computation of elliptic Integrals and Jacobian elliptic functions for real
arguments. Correctness, robustness, efficiency and accuracy of the functions
are discussed in some details. An example from the elasticity theory
illustrates use of the collection.
</summary>
    <author>
      <name>Milan Batista</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2019.100245</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2019.100245" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SoftwareX, Volume 10, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1806.10469v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.10469v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.01361v2</id>
    <updated>2018-10-03T09:40:53Z</updated>
    <published>2018-10-02T16:38:07Z</published>
    <title>Validation of a PETSc based software implementing a 4DVAR Data
  Assimilation algorithm: a case study related with an Oceanic Model based on
  Shallow Water equation</title>
    <summary>  In this work are presented and discussed some results related to the
validation process of a software module based on PETSc which implements a Data
Assimilation algorithm.
</summary>
    <author>
      <name>Luisa Carracciuolo</name>
    </author>
    <author>
      <name>Emil M. Constantinescu</name>
    </author>
    <author>
      <name>Luisa D'Amore</name>
    </author>
    <link href="http://arxiv.org/abs/1810.01361v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.01361v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03251v3</id>
    <updated>2021-08-24T12:36:01Z</updated>
    <published>2019-07-07T08:40:33Z</published>
    <title>Unveiling patterns in xorshift128+ pseudorandom number generators</title>
    <summary>  Xorshift128+ is a newly proposed pseudorandom number generator (PRNG), which
is now the standard PRNG on a number of platforms. We demonstrate that
three-dimensional plots of the random points generated by the generator have
visible structures: they concentrate on particular planes in the cube. We
provide a mathematical analysis of this phenomenon.
</summary>
    <author>
      <name>Hiroshi Haramoto</name>
    </author>
    <author>
      <name>Makoto Matsumoto</name>
    </author>
    <author>
      <name>Mutsuo Saito</name>
    </author>
    <link href="http://arxiv.org/abs/1907.03251v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03251v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01589v1</id>
    <updated>2019-12-03T18:39:11Z</updated>
    <published>2019-12-03T18:39:11Z</published>
    <title>CheasePy</title>
    <summary>  CheasePy is code written in Python to run the CHEASE (Cubic Hermite Element
Axisymmetric Static Equilibrium) code, which solves the Grad-Shafranov equation
for toroidal MHD equilibria using pressure and current profiles and fixed
plasma boundaries that is defined by a set of experimental data points (R,Z).
The CheasePy code allows an iterative running of the CHEASE code either to
check the preservation of MHD equilibria or converging to an experimentally
defined total toroidal plasma current by modifying any input quantity.
</summary>
    <author>
      <name>Ehab Hassan</name>
    </author>
    <link href="http://arxiv.org/abs/1912.01589v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01589v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.06181v1</id>
    <updated>2020-03-13T10:07:21Z</updated>
    <published>2020-03-13T10:07:21Z</published>
    <title>FunGrim: a symbolic library for special functions</title>
    <summary>  We present the Mathematical Functions Grimoire (FunGrim), a website and
database of formulas and theorems for special functions. We also discuss the
symbolic computation library used as the backend and main development tool for
FunGrim, and the Grim formula language used in these projects to represent
mathematical content semantically.
</summary>
    <author>
      <name>Fredrik Johansson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LFANT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/2003.06181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.10635v1</id>
    <updated>2020-05-21T13:37:25Z</updated>
    <published>2020-05-21T13:37:25Z</published>
    <title>SymJAX: symbolic CPU/GPU/TPU programming</title>
    <summary>  SymJAX is a symbolic programming version of JAX simplifying graph
input/output/updates and providing additional functionalities for general
machine learning and deep learning applications. From an user perspective
SymJAX provides a la Theano experience with fast graph optimization/compilation
and broad hardware support, along with Lasagne-like deep learning
functionalities.
</summary>
    <author>
      <name>Randall Balestriero</name>
    </author>
    <link href="http://arxiv.org/abs/2005.10635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.10635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.13055v1</id>
    <updated>2020-07-26T04:50:51Z</updated>
    <published>2020-07-26T04:50:51Z</published>
    <title>Optimizing Block-Sparse Matrix Multiplications on CUDA with TVM</title>
    <summary>  We implemented and optimized matrix multiplications between dense and
block-sparse matrices on CUDA. We leveraged TVM, a deep learning compiler, to
explore the schedule space of the operation and generate efficient CUDA code.
With the automatic parameter tuning in TVM, our cross-thread reduction based
implementation achieved competitive or better performance compared with other
state-of-the-art frameworks.
</summary>
    <author>
      <name>Zijing Gu</name>
    </author>
    <link href="http://arxiv.org/abs/2007.13055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.13055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.05158v1</id>
    <updated>2021-01-13T15:55:51Z</updated>
    <published>2021-01-13T15:55:51Z</published>
    <title>UFL Dual Spaces, a proposal</title>
    <summary>  This white paper highlights current limitations in the algebraic closure
Unified Form Language (UFL). UFL currently represents forms over finite element
spaces, however finite element problems naturally result in objects in the dual
to a finite element space, and operators mapping between primal and dual finite
element spaces. This document sketches the relevant mathematical areas and
proposes changes to the UFL language to support dual spaces as first class
types in UFL.
</summary>
    <author>
      <name>David A. Ham</name>
    </author>
    <link href="http://arxiv.org/abs/2101.05158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.05158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.12199v1</id>
    <updated>2019-06-27T11:56:05Z</updated>
    <published>2019-06-27T11:56:05Z</published>
    <title>Remark on Algorithm 680: evaluation of the complex error function: Cause
  and Remedy for the Loss of Accuracy Near the Real Axis</title>
    <summary>  In this remark we identify the cause of the loss of accuracy in the
computation of the Faddeyeva function, w(z), near the real axis when using
Algorithm 680. We provide a simple correction to this problem which allows us
to restore this code as one of the important reference routines for accuracy
comparisons.
</summary>
    <author>
      <name>Mofreh Zaghloul</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3309681</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3309681" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, Vol. 45, No. 2, Article
  24.(2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.12199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.12199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.01728v1</id>
    <updated>2020-11-03T14:22:18Z</updated>
    <published>2020-11-03T14:22:18Z</published>
    <title>Calcium: computing in exact real and complex fields</title>
    <summary>  Calcium is a C library for real and complex numbers in a form suitable for
exact algebraic and symbolic computation. Numbers are represented as elements
of fields $\mathbb{Q}(a_1,\ldots,a_n)$ where the extensions numbers $a_k$ may
be algebraic or transcendental. The system combines efficient field operations
with automatic discovery and certification of algebraic relations, resulting in
a practical computational model of $\mathbb{R}$ and $\mathbb{C}$ in which
equality is rigorously decidable for a large class of numbers.
</summary>
    <author>
      <name>Fredrik Johansson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LFANT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/2011.01728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.01728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.02847v1</id>
    <updated>2022-02-06T20:38:12Z</updated>
    <published>2022-02-06T20:38:12Z</published>
    <title>Solidfmm: A highly optimised library of operations on the solid
  harmonics for use in fast multipole methods</title>
    <summary>  We present solidfmm, a highly optimised C++ library for the solid harmonics
as they are needed in fast multipole methods. The library provides efficient,
vectorised implementations of the translation operations M2M, M2L, and L2L, and
is available as free software. While asymptotically of complexity $O(P^3)$, for
all practically relevant expansion orders, the translation operators display an
empirical complexity of $O(P^2)$, outperforming the na\"ive implementation by
orders of magnitude.
</summary>
    <author>
      <name>Matthias Kirchhart</name>
    </author>
    <link href="http://arxiv.org/abs/2202.02847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.02847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.03068v1</id>
    <updated>2023-04-06T13:36:20Z</updated>
    <published>2023-04-06T13:36:20Z</published>
    <title>Formal Derivation of LU Factorization with Pivoting</title>
    <summary>  The FLAME methodology for deriving linear algebra algorithms from
specification, first introduced around 2000, has been successfully applied to a
broad cross section of operations. An open question has been whether it can
yield algorithms for the best-known operation in linear algebra, LU
factorization with partial pivoting (Gaussian elimination with row swapping).
This paper shows that it can.
</summary>
    <author>
      <name>Robert van de Geijn</name>
    </author>
    <author>
      <name>Maggie Myers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.03068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.03068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.01375v1</id>
    <updated>2023-05-02T12:51:25Z</updated>
    <published>2023-05-02T12:51:25Z</published>
    <title>Diddy: a Python toolbox for infinite discrete dynamical systems</title>
    <summary>  We introduce Diddy, a collection of Python scripts for analyzing infinite
discrete dynamical systems. The main focus is on generalized multidimensional
shifts of finite type (SFTs). We show how Diddy can be used to easily define
SFTs and cellular automata, and analyze their basic properties. We also
showcase how to verify or rediscover some results from coding theory and
cellular automata theory.
</summary>
    <author>
      <name>Ville Salo</name>
    </author>
    <author>
      <name>Ilkka Törmä</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.01375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.01375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.11619v2</id>
    <updated>2023-08-25T15:02:20Z</updated>
    <published>2023-06-21T15:53:14Z</published>
    <title>An algorithm to approximate the real trilogarithm for a real argument</title>
    <summary>  We present an algorithm to approximate the real trilogarithm for a real
argument with IEEE 754-1985 double precision accuracy. The approximation is
structured such that it can make use of instruction-level parallelism when
executed on appropriate CPUs.
</summary>
    <author>
      <name>Alexander Voigt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 tables, attached source code</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.11619v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.11619v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="33-04, 33E20, 33F05, 65D20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.19304v1</id>
    <updated>2025-05-25T20:24:22Z</updated>
    <published>2025-05-25T20:24:22Z</published>
    <title>f4ncgb: High Performance Gröbner Basis Computations in Free Algebras</title>
    <summary>  We present f4ncgb, a new open-source C++ library for Gr\"obner basis
computations in free algebras, which transfers recent advancements in
commutative Gr\"obner basis software to the noncommutative setting. As our
experiments show, f4ncgb establishes a new state-of-the-art for noncommutative
Gr\"obner basis computations. We also discuss implementation details and design
choices.
</summary>
    <author>
      <name>Maximilian Heisinger</name>
    </author>
    <author>
      <name>Clemens Hofstadler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 2 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.19304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.19304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.6373v1</id>
    <updated>2014-08-27T10:13:45Z</updated>
    <published>2014-08-27T10:13:45Z</published>
    <title>Concurrent Cuba</title>
    <summary>  The parallel version of the multidimensional numerical integration package
Cuba is presented and achievable speed-ups discussed.
</summary>
    <author>
      <name>T. Hahn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTeX, 14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.6373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.6373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.06918v1</id>
    <updated>2022-06-14T15:25:51Z</updated>
    <published>2022-06-14T15:25:51Z</published>
    <title>varFEM: variational formulation based programming for finite element
  methods in Matlab</title>
    <summary>  This paper summarizes the development of varFEM, which provides a realization
of the programming style in FreeFEM by using the Matlab language.
</summary>
    <author>
      <name>Yue Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">FreeFEM</arxiv:comment>
    <link href="http://arxiv.org/abs/2206.06918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.06918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.12211v2</id>
    <updated>2023-09-21T04:49:10Z</updated>
    <published>2022-06-29T15:54:16Z</published>
    <title>hp3D User Manual</title>
    <summary>  User Manual for the hp3D Finite Element Software, available on GitHub at
https://github.com/Oden-EAG/hp3d
</summary>
    <author>
      <name>Stefan Henneking</name>
    </author>
    <author>
      <name>Leszek Demkowicz</name>
    </author>
    <link href="http://arxiv.org/abs/2207.12211v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.12211v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001018v1</id>
    <updated>2000-01-23T20:36:49Z</updated>
    <published>2000-01-23T20:36:49Z</published>
    <title>Adaptive simulated annealing (ASA): Lessons learned</title>
    <summary>  Adaptive simulated annealing (ASA) is a global optimization algorithm based
on an associated proof that the parameter space can be sampled much more
efficiently than by using other previous simulated annealing algorithms. The
author's ASA code has been publicly available for over two years. During this
time the author has volunteered to help people via e-mail, and the feedback
obtained has been used to further develop the code. Some lessons learned, in
particular some which are relevant to other simulated annealing algorithms, are
described.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 PostScript pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Control and Cybernetics 25 (1996) 33-54</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0001018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101018v1</id>
    <updated>2001-01-19T21:14:52Z</updated>
    <published>2001-01-19T21:14:52Z</published>
    <title>GPCG: A Case Study in the Performance and Scalability of Optimization
  Algorithms</title>
    <summary>  GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for
solving bound constrained, convex quadratic problems. Originally developed by
More' and Toraldo, this algorithm was designed for large-scale problems but had
been implemented only for a single processor. The TAO implementation is
available for a wide range of high-performance architecture, and has been
tested on up to 64 processors to solve problems with over 2.5 million
variables.
</summary>
    <author>
      <name>Steven J. Benson</name>
    </author>
    <author>
      <name>Lois Curfman McInnes</name>
    </author>
    <author>
      <name>Jorge J. Moré</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">title + 16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0101018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0201007v2</id>
    <updated>2009-10-14T19:00:06Z</updated>
    <published>2002-01-10T15:54:24Z</published>
    <title>Algorithm for generating orthogonal matrices with rational elements</title>
    <summary>  Special orthogonal matrices with rational elements form the group SO(n,Q),
where Q is the field of rational numbers. A theorem describing the structure of
an arbitrary matrix from this group is proved. This theorem yields an algorithm
for generating such matrices by means of random number routines.
</summary>
    <author>
      <name>Ruslan Sharipov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AmSTeX, 7 pages, amsppt style, English wording is improved,
  references are transformed to hyperlinks, the fugure is incorporated into the
  PS and PDF files</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0201007v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0201007v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302026v1</id>
    <updated>2003-02-19T15:59:28Z</updated>
    <published>2003-02-19T15:59:28Z</published>
    <title>Recursive function templates as a solution of linear algebra expressions
  in C++</title>
    <summary>  The article deals with a kind of recursive function templates in C++, where
the recursion is realized corresponding template parameters to achieve better
computational performance. Some specialization of these template functions ends
the recursion and can be implemented using optimized hardware dependent or
independent routines. The method is applied in addition to the known expression
templates technique to solve linear algebra expressions with the help of the
BLAS library. The whole implementation produces a new library, which keeps
object-oriented benefits and has a higher computational speed represented in
the tests.
</summary>
    <author>
      <name>Volodymyr Myrnyy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brandenburg University of Technology, Cottbus, Germany</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Latex2e, 8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0302026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; I.1.2; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408029v1</id>
    <updated>2004-08-13T21:25:42Z</updated>
    <published>2004-08-13T21:25:42Z</published>
    <title>Tsnnls: A solver for large sparse least squares problems with
  non-negative variables</title>
    <summary>  The solution of large, sparse constrained least-squares problems is a staple
in scientific and engineering applications. However, currently available codes
for such problems are proprietary or based on MATLAB. We announce a freely
available C implementation of the fast block pivoting algorithm of Portugal,
Judice, and Vicente. Our version is several times faster than Matstoms' MATLAB
implementation of the same algorithm. Further, our code matches the accuracy of
MATLAB's built-in lsqnonneg function.
</summary>
    <author>
      <name>Jason Cantarella</name>
    </author>
    <author>
      <name>Michael Piatek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0408029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G. 1 3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603001v1</id>
    <updated>2006-03-01T15:45:57Z</updated>
    <published>2006-03-01T15:45:57Z</published>
    <title>BioSig - An application of Octave</title>
    <summary>  BioSig is an open source software library for biomedical signal processing.
Most users in the field are using Matlab; however, significant effort was
undertaken to provide compatibility to Octave, too. This effort has been widely
successful, only some non-critical components relying on a graphical user
interface are missing. Now, installing BioSig on Octave is as easy as on
Matlab. Moreover, a benchmark test based on BioSig has been developed and the
benchmark results of several platforms are presented.
</summary>
    <author>
      <name>Alois Schlögl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, submission for the Octave 2006 meeting</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2; J.3; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603052v2</id>
    <updated>2006-03-14T12:48:25Z</updated>
    <published>2006-03-13T12:05:08Z</published>
    <title>Evaluation of interval extension of the power function by graph
  decomposition</title>
    <summary>  The subject of our talk is the correct evaluation of interval extension of
the function specified by the expression x^y without any constraints on the
values of x and y. The core of our approach is a decomposition of the graph of
x^y into a small number of parts which can be transformed into subsets of the
graph of x^y for non-negative bases x. Because of this fact, evaluation of
interval extension of x^y, without any constraints on x and y, is not much
harder than evaluation of interval extension of x^y for non-negative bases x.
</summary>
    <author>
      <name>Evgueni Petrov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to the INTERVAL 2006 workshop to be held in St. Petersburg
  June 2006, Russia; extended abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603052v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603052v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604039v1</id>
    <updated>2006-04-10T08:22:01Z</updated>
    <published>2006-04-10T08:22:01Z</published>
    <title>A Fixed-Point Type for Octave</title>
    <summary>  This paper announces the availability of a fixed point toolbox for the Matlab
compatible software package Octave. This toolbox is released under the GNU
Public License, and can be used to model the losses in algorithms implemented
in hardware. Furthermore, this paper presents as an example of the use of this
toolbox, the effects of a fixed point implementation on the precision of an
OFDM modulator.
</summary>
    <author>
      <name>David Bateman</name>
    </author>
    <author>
      <name>Laurent Mazet</name>
    </author>
    <author>
      <name>Veronique Buzenac-Settineri</name>
    </author>
    <author>
      <name>Markus Muck</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0604039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609129v2</id>
    <updated>2006-09-24T23:11:02Z</updated>
    <published>2006-09-22T18:53:17Z</published>
    <title>One approach to the digital visualization of hedgehogs in holomorphic
  dynamics</title>
    <summary>  In the field of holomorphic dynamics in one complex variable, hedgehog is the
local invariant set arising about a Cremer point and endowed with a very
complicate shape as well as relating to very weak numerical conditions. We give
a solution to the open problem of its digital visualization, featuring either a
time saving approach and a far-reaching insight.
</summary>
    <author>
      <name>Alessandro Rosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 51 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Journal of Differential Equations and Control
  Processes, n.1, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0609129v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609129v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611127v1</id>
    <updated>2006-11-24T16:43:06Z</updated>
    <published>2006-11-24T16:43:06Z</published>
    <title>Coupling Methodology within the Software Platform Alliances</title>
    <summary>  CEA, ANDRA and EDF are jointly developing the software platform ALLIANCES
which aim is to produce a tool for the simulation of nuclear waste storage and
disposal repository. This type of simulations deals with highly coupled
thermo-hydro-mechanical and chemical (T-H-M-C) processes. A key objective of
Alliances is to give the capability for coupling algorithms development between
existing codes. The aim of this paper is to present coupling methodology use in
the context of this software platform.
</summary>
    <author>
      <name>Philippe Montarnal</name>
    </author>
    <author>
      <name>Alain Dimier</name>
    </author>
    <author>
      <name>Estelle Deville</name>
    </author>
    <author>
      <name>Erwan Adam</name>
    </author>
    <author>
      <name>Jérôme Gaombalet</name>
    </author>
    <author>
      <name>Alain Bengaouer</name>
    </author>
    <author>
      <name>Laurent Loth</name>
    </author>
    <author>
      <name>Clément Chavant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Methods for Coupled Problems in Science and
  Engineering (04/2005) CD-ROM</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703040v1</id>
    <updated>2007-03-08T19:49:35Z</updated>
    <published>2007-03-08T19:49:35Z</published>
    <title>Why the Standard Data Processing should be changed</title>
    <summary>  The basic statistical methods of data representation did not change since
their emergence. Their simplicity was dictated by the intricacies of
computations in the before computers epoch. It turns out that such approach is
not uniquely possible in the presence of quick computers. The suggested here
method improves significantly the reliability of data processing and their
graphical representation. In this paper we show problems of the standard data
processing which can bring to incorrect results. A method solving these
problems is proposed. It is based on modification of data representation. The
method was implemented in a computer program Consensus5. The program
performances are illustrated through varied examples.
</summary>
    <author>
      <name>Yefim Bakman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tel-Aviv University</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0703040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.4651v1</id>
    <updated>2007-07-31T17:04:34Z</updated>
    <published>2007-07-31T17:04:34Z</published>
    <title>Comments on the Reliability of Lawson and Hanson's Linear Distance
  Programming Algorithm: Subroutine LDP</title>
    <summary>  This brief paper: (1) Discusses strategies to generate random test cases that
can be used to extensively test any Linear Distance Program (LDP) software. (2)
Gives three numerical examples of input cases generated by this strategy that
cause problems in the Lawson and Hanson LDP module. (3) Proposes, as a standard
matter of acceptable implementation procedures, that (unless it is done
internally in the software itself, but, in general, this seems to be much rarer
than one would expect) all users should test the returned output from any LDP
module for self-consistency since it incurs only a small amount of added
computational overhead and it is not hard to do.
</summary>
    <author>
      <name>Alan Rufty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.4651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.4651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4.x; D.2.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.1413v1</id>
    <updated>2009-01-11T04:43:51Z</updated>
    <published>2009-01-11T04:43:51Z</published>
    <title>Bitslicing and the Method of Four Russians Over Larger Finite Fields</title>
    <summary>  We present a method of computing with matrices over very small finite fields
of size larger than 2. Specifically, we show how the Method of Four Russians
can be efficiently adapted to these larger fields, and introduce a row-wise
matrix compression scheme that both reduces memory requirements and allows one
to vectorize element operations. We also present timings which confirm the
efficiency of these methods and exceed the speed of the fastest implementations
the authors are aware of.
</summary>
    <author>
      <name>Tomas J. Boothby</name>
    </author>
    <author>
      <name>Robert W. Bradshaw</name>
    </author>
    <link href="http://arxiv.org/abs/0901.1413v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.1413v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.1040v2</id>
    <updated>2009-05-29T09:02:51Z</updated>
    <published>2009-02-06T09:51:09Z</published>
    <title>Fast solving of Weighted Pairing Least-Squares systems</title>
    <summary>  This paper presents a generalization of the "weighted least-squares" (WLS),
named "weighted pairing least-squares" (WPLS), which uses a rectangular weight
matrix and is suitable for data alignment problems. Two fast solving methods,
suitable for solving full rank systems as well as rank deficient systems, are
studied. Computational experiments clearly show that the best method, in terms
of speed, accuracy, and numerical stability, is based on a special {1, 2,
3}-inverse, whose computation reduces to a very simple generalization of the
usual "Cholesky factorization-backward substitution" method for solving linear
systems.
</summary>
    <author>
      <name>Pierre Courrieu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cam.2009.01.016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cam.2009.01.016" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational and Applied Mathematics 231, 1 (2009)
  39-48</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.1040v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.1040v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4313v1</id>
    <updated>2009-03-25T12:10:32Z</updated>
    <published>2009-03-25T12:10:32Z</published>
    <title>The development of a fuzzy regulator with an entry and an output in
  Fislab</title>
    <summary>  The present article is a sequel of the article "Fislab the Fuzzy Inference
Tool-Box for Scilab" and it represents the practical application of:"The
development of the Fuzzy regulator with an input and an output in Fislab". The
article contains, besides this application, some functions to be used in the
program, namely Scilab functions for the fuzzification of the firm information,
functions for the operation of de-fuzzification and functions for the
implementation of.
</summary>
    <author>
      <name>Simona Apostol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, exposed on 4th International Conferences "Actualities and
  Perspectives on Hardware and Software" - APHS2007, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 115-120</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.4313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.4430v1</id>
    <updated>2009-05-27T14:11:37Z</updated>
    <published>2009-05-27T14:11:37Z</published>
    <title>Limits of Educational Soft "GeoGebra" in a Critical Constructive Review</title>
    <summary>  Mathematical educational soft explore, investigating in a dynamical way, some
algebraically, geometrically problems, the expected results being used to
involve a lot of mathematical results. One such software soft is GeoGebra. The
software is free and multi-platform dynamic mathematics software for learning
and teaching, awards in Europe and the USA. This paper describes some critical
but constructive investigation using the platform for graph functions and
dynamic geometry.
</summary>
    <author>
      <name>Valerian Antohe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, exposed on 5th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2009, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 47-54</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.4430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.4430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0792v1</id>
    <updated>2009-07-04T20:17:28Z</updated>
    <published>2009-07-04T20:17:28Z</published>
    <title>A generalized inner and outer product of arbitrary multi-dimensional
  arrays using A Mathematics of Arrays (MoA)</title>
    <summary>  An algorithm has been devised to compute the inner and outer product between
two arbitrary multi-dimensional arrays A and B in a single piece of code. It
was derived using A Mathematics of Arrays (MoA) and the $\psi$-calculus.
Extensive tests of the new algorithm are presented for running in sequential as
well as OpenMP multiple processor modes.
</summary>
    <author>
      <name>James E. Raynolds</name>
    </author>
    <author>
      <name>Lenore M. Mullin</name>
    </author>
    <link href="http://arxiv.org/abs/0907.0792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3173v2</id>
    <updated>2010-04-20T00:56:02Z</updated>
    <published>2010-04-19T12:26:15Z</published>
    <title>MP users guide</title>
    <summary>  MP is a package of ANSI Standard Fortran (ANS X3.9-1966) subroutines for
performing multiple-precision floating-point arithmetic and evaluating
elementary and special functions. The subroutines are machine independent and
the precision is arbitrary, subject to storage limitations. The User's Guide
describes the routines and their calling sequences, example and test programs,
use of the Augment precompiler, and gives installation instructions for the
package.
</summary>
    <author>
      <name>Richard P. Brent</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MP Users Guide (fourth edition), 73 pages. A technical report that
  was not published elsewhere, submitted for archival purposes. For further
  information see http://wwwmaths.anu.edu.au/~brent/pub/pub035.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3173v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3173v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80 (Primary), 11-04 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2314v1</id>
    <updated>2010-05-13T13:22:04Z</updated>
    <published>2010-05-13T13:22:04Z</published>
    <title>Some comments on C. S. Wallace's random number generators</title>
    <summary>  We outline some of Chris Wallace's contributions to pseudo-random number
generation. In particular, we consider his idea for generating normally
distributed variates without relying on a source of uniform random numbers, and
compare it with more conventional methods for generating normal random numbers.
Implementations of Wallace's idea can be very fast (approximately as fast as
good uniform generators). We discuss the statistical quality of the output, and
mention how certain pitfalls can be avoided.
</summary>
    <author>
      <name>Richard P. Brent</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/comjnl/bxm122</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/comjnl/bxm122" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages. For further information, see
  http://wwwmaths.anu.edu.au/~brent/pub/pub213.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Computer Journal 51, 5 (Sept. 2008), 579-584</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.2314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11K45 (Primary) 65-03, 65C10 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; G.4; K.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3992v2</id>
    <updated>2010-06-26T21:43:47Z</updated>
    <published>2010-05-19T11:26:36Z</published>
    <title>Groebner bases in Java with applications in computer graphics</title>
    <summary>  In this paper we present a Java implementation of the algorithm that computes
Buchbereger's and reduced Groebner's basis step by step. The Java application
enables graphical representation of the intersection of two surfaces in
3-dimensional space and determines conditions of existence and planarity of the
intersection.
</summary>
    <author>
      <name>Branko J. Malesevic</name>
    </author>
    <author>
      <name>Ivana V. Jovovic</name>
    </author>
    <author>
      <name>Milan Z. Campara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International convention on Descriptive Geometry and Engineering
  Graphics moNGeometrija 2010, http://www.mongeometrija.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.3992v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3992v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4395v1</id>
    <updated>2010-05-24T18:46:34Z</updated>
    <published>2010-05-24T18:46:34Z</published>
    <title>An OpenMath Content Dictionary for Tensor Concepts</title>
    <summary>  We introduce a new OpenMath content dictionary, named tensor1, containing
symbols for the expression of tensor formulas. These symbols support the
expression of non-Cartesian coordinates and invariant, multilinear expressions
in the context of coordinate transformations. While current OpenMath symbols
support the expression of linear algebra formulas using matrices and vectors,
we find that there is an underlying assumption of Cartesian, or standard,
coordinates that makes the expression of general tensor formulas difficult, if
not impossible. In introducing these new OpenMath symbols for the expression of
tensor formulas, we attempt to maintain, as much as possible, consistency with
prior OpenMath symbol definitions for linear algebra.
</summary>
    <author>
      <name>Joseph B. Collins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in The 9th International Conference on Mathematical
  Knowledge Management: MKM 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0401v1</id>
    <updated>2010-06-02T14:30:40Z</updated>
    <published>2010-06-02T14:30:40Z</published>
    <title>Making big steps in trajectories</title>
    <summary>  We consider the solution of initial value problems within the context of
hybrid systems and emphasise the use of high precision approximations (in
software for exact real arithmetic). We propose a novel algorithm for the
computation of trajectories up to the area where discontinuous jumps appear,
applicable for holomorphic flow functions. Examples with a prototypical
implementation illustrate that the algorithm might provide results with higher
precision than well-known ODE solvers at a similar computation time.
</summary>
    <author>
      <name>Norbert Th. Müller</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universität Trier, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Margarita Korovina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University Manchester, UK</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.24.15</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.24.15" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 24, 2010, pp. 106-119</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.0401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.1523v1</id>
    <updated>2011-02-08T07:25:56Z</updated>
    <published>2011-02-08T07:25:56Z</published>
    <title>The NumPy array: a structure for efficient numerical computation</title>
    <summary>  In the Python world, NumPy arrays are the standard representation for
numerical data. Here, we show how these arrays enable efficient implementation
of numerical computations in a high-level language. Overall, three techniques
are applied to improve performance: vectorizing calculations, avoiding copying
data in memory, and minimizing operation counts. We first present the NumPy
array structure, then show how to use it for efficient computation, and finally
how to share array data with other libraries.
</summary>
    <author>
      <name>Stefan Van Der Walt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Parietal</arxiv:affiliation>
    </author>
    <author>
      <name>S. Chris Colbert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Parietal</arxiv:affiliation>
    </author>
    <author>
      <name>Gaël Varoquaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Parietal</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MCSE.2011.37</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MCSE.2011.37" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computing in Science and Engineering 13, 2 (2011) 22-30</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.1523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.1523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3774v1</id>
    <updated>2011-02-18T08:00:01Z</updated>
    <published>2011-02-18T08:00:01Z</published>
    <title>Quantum Anticipation Explorer</title>
    <summary>  Quantum anticipation explorer is a computer program allowing the numerical
exploration of quantum anticipation which has been analyzed in arXiv:0810.183v1
and arXiv:1003.1090v1 for H-Atom, equidistant, random and custom spectra. This
tool determines the anticipation strength at those times orthogonal evolution
is possible. This paper is the user's guide explaining its capabilities,
installation and usage, and documenting the mathematics and algorithms
implemented in the software. A zip file containing the setup and documentation
can be downloaded from
http://www.thomannconsulting.ch/public/aboutus/aboutus-en.htm free of cost.
</summary>
    <author>
      <name>Hans-Rudolf Thomann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0628v1</id>
    <updated>2011-04-04T17:12:55Z</updated>
    <published>2011-04-04T17:12:55Z</published>
    <title>Automated code generation for discontinuous Galerkin methods</title>
    <summary>  A compiler approach for generating low-level computer code from high-level
input for discontinuous Galerkin finite element forms is presented. The input
language mirrors conventional mathematical notation, and the compiler generates
efficient code in a standard programming language. This facilitates the rapid
generation of efficient code for general equations in varying spatial
dimensions. Key concepts underlying the compiler approach and the automated
generation of computer code are elaborated. The approach is demonstrated for a
range of common problems, including the Poisson, biharmonic,
advection--diffusion and Stokes equations.
</summary>
    <author>
      <name>Kristian B. Ølgaard</name>
    </author>
    <author>
      <name>Anders Logg</name>
    </author>
    <author>
      <name>Garth N. Wells</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/070710032</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/070710032" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM J. Sci. Comput. 31(2), 2008, pp. 849-864</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N30, 68N20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1533v1</id>
    <updated>2011-04-08T09:40:04Z</updated>
    <published>2011-04-08T09:40:04Z</published>
    <title>Operand Folding Hardware Multipliers</title>
    <summary>  This paper describes a new accumulate-and-add multiplication algorithm. The
method partitions one of the operands and re-combines the results of
computations done with each of the partitions. The resulting design turns-out
to be both compact and fast.
  When the operands' bit-length $m$ is 1024, the new algorithm requires only
$0.194m+56$ additions (on average), this is about half the number of additions
required by the classical accumulate-and-add multiplication algorithm
($\frac{m}2$).
</summary>
    <author>
      <name>Byungchun Chung</name>
    </author>
    <author>
      <name>Sandra Marcello</name>
    </author>
    <author>
      <name>Amir-Pasha Mirbaha</name>
    </author>
    <author>
      <name>David Naccache</name>
    </author>
    <author>
      <name>Karim Sabeg</name>
    </author>
    <link href="http://arxiv.org/abs/1104.1533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1347v1</id>
    <updated>2011-06-03T09:17:11Z</updated>
    <published>2011-06-03T09:17:11Z</published>
    <title>Methods of Matrix Multiplication: An Overview of Several Methods and
  their Implementation</title>
    <summary>  In this overview article we present several methods for multiplying matrices
and the implementation of these methods in C. Also a little test program is
given to compare their running time and the numerical stability.
  The methods are: naive method, naive method working on arrays, naive method
with the \textsc{Kahan} trick, three methods with loop unrolling, winograd
method and the scaled variant, original \textsc{Strassen} method and the
\textsc{Strassen}-\textsc{Winograd} variant.
  Please note, that this is the FIRST version. The algorithms are not well
tested and the implementation is not optimized. If you like to join the
project, please contact me.
</summary>
    <author>
      <name>Ivo Hedtke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.1347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1862v1</id>
    <updated>2011-06-09T17:16:38Z</updated>
    <published>2011-06-09T17:16:38Z</published>
    <title>The MathScheme Library: Some Preliminary Experiments</title>
    <summary>  We present some of the experiments we have performed to best test our design
for a library for MathScheme, the mechanized mathematics software system we are
building. We wish for our library design to use and reflect, as much as
possible, the mathematical structure present in the objects which populate the
library.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <author>
      <name>William M. Farmer</name>
    </author>
    <author>
      <name>Filip Jeremic</name>
    </author>
    <author>
      <name>Vincent Maccio</name>
    </author>
    <author>
      <name>Russell O'Connor</name>
    </author>
    <author>
      <name>Quang M. Tran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as a work-in-progress paper at CICM 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.1862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.1; D.3.3; F.4.1; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4448v2</id>
    <updated>2011-09-22T12:47:56Z</updated>
    <published>2011-06-22T13:58:58Z</published>
    <title>Tactics for Reasoning modulo AC in Coq</title>
    <summary>  We present a set of tools for rewriting modulo associativity and
commutativity (AC) in Coq, solving a long-standing practical problem. We use
two building blocks: first, an extensible reflexive decision procedure for
equality modulo AC; second, an OCaml plug-in for pattern matching modulo AC. We
handle associative only operations, neutral elements, uninterpreted function
symbols, and user-defined equivalence relations. By relying on type-classes for
the reification phase, we can infer these properties automatically, so that
end-users do not need to specify which operation is A or AC, or which constant
is a neutral element.
</summary>
    <author>
      <name>Thomas Braibant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG</arxiv:affiliation>
    </author>
    <author>
      <name>Damien Pous</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-25379-9_14</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-25379-9_14" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16p</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Certified Proofs and Programs, Ta\"iwan, Province De Chine (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.4448v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4448v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3397v1</id>
    <updated>2011-10-15T09:41:24Z</updated>
    <published>2011-10-15T09:41:24Z</published>
    <title>Odeint - Solving ordinary differential equations in C++</title>
    <summary>  Many physical, biological or chemical systems are modeled by ordinary
differential equations (ODEs) and finding their solution is an every-day-task
for many scientists. Here, we introduce a new C++ library dedicated to find
numerical solutions of initial value problems of ODEs: odeint (www.odeint.com).
odeint is implemented in a highly generic way and provides extensive
interoperability at top performance. For example, due to it's modular design it
can be easily parallized with OpenMP and even runs on CUDA GPUs. Despite that,
it provides a convenient interface that allows for a simple and easy usage.
</summary>
    <author>
      <name>Karsten Ahnert</name>
    </author>
    <author>
      <name>Mario Mulansky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3637934</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3637934" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IP Conf. Proc. - September 14, 2011 - Volume 1389, pp. 1586-1589</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.3397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5441v2</id>
    <updated>2012-06-27T22:30:05Z</updated>
    <published>2011-10-25T08:44:51Z</published>
    <title>LINPRO: linear inverse problem library for data contaminated by
  statistical noise</title>
    <summary>  The library LINPRO which provides solution to the linear inverse problem for
data contaminated by a statistical noise is presented. The library makes use of
two methods: Maximum Entropy Method and Singular Value Decomposition. As an
example it has been applied to perform an analytic continuation of the
imaginary time propagator obtained within the Quantum Monte Carlo method.
</summary>
    <author>
      <name>Piotr Magierski</name>
    </author>
    <author>
      <name>Gabriel Wlazlowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2012.05.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2012.05.005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The associated computer program is available at:
  http://tja.if.pw.edu.pl/linpro/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Commun. 183 (2012) 2264-2271</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.5441v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5441v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3124v1</id>
    <updated>2011-11-14T07:50:31Z</updated>
    <published>2011-11-14T07:50:31Z</published>
    <title>A multiprecision matrix calculation library and its extension library
  for a matrix-product-state simulation of quantum computing</title>
    <summary>  A C++ library, named ZKCM, has been developed for the purpose of
multiprecision matrix calculations, which is based on the GNU MP and MPFR
libraries. It is especially convenient for writing programs involving
tensor-product operations, tracing-out operations, and singular-value
decompositions. Its extension library, ZKCM_QC, for simulating quantum
computing has been developed using the time-dependent matrix-product-state
simulation method. This report gives a brief introduction to the libraries with
sample programs.
</summary>
    <author>
      <name>Akira SaiToh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, technical report (a software overview)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80, 81-01" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6549v1</id>
    <updated>2011-11-28T18:55:12Z</updated>
    <published>2011-11-28T18:55:12Z</published>
    <title>Efficient Dense Gaussian Elimination over the Finite Field with Two
  Elements</title>
    <summary>  In this work we describe an efficient implementation of a hierarchy of
algorithms for Gaussian elimination upon dense matrices over the field with two
elements. We discuss both well-known and new algorithms as well as our
implementations in the M4RI library, which has been adopted into Sage. The
focus of our discussion is a block iterative algorithm for PLE decomposition
which is inspired by the M4RI algorithm. The implementation presented in this
work provides considerable performance gains in practice when compared to the
previously fastest implementation. We provide performance figures on x86_64
CPUs to demonstrate the alacrity of our approach.
</summary>
    <author>
      <name>Martin R. Albrecht</name>
    </author>
    <author>
      <name>Gregory V. Bard</name>
    </author>
    <author>
      <name>Clément Pernet</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0499v1</id>
    <updated>2012-01-02T17:10:49Z</updated>
    <published>2012-01-02T17:10:49Z</published>
    <title>Evaluating polynomials in several variables and their derivatives on a
  GPU computing processor</title>
    <summary>  In order to obtain more accurate solutions of polynomial systems with
numerical continuation methods we use multiprecision arithmetic. Our goal is to
offset the overhead of double double arithmetic accelerating the path trackers
and in particular Newton's method with a general purpose graphics processing
unit. In this paper we describe algorithms for the massively parallel
evaluation and differentiation of sparse polynomials in several variables. We
report on our implementation of the algorithmic differentiation of products of
variables on the NVIDIA Tesla C2050 Computing Processor using the NVIDIA CUDA
compiler tools.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <author>
      <name>Genady Yoffe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key words and phrases: algorithmic differentiation, compute unified
  device architecture (CUDA), graphics processing unit (GPU), massively
  parallel polynomial evaluation, Speelpenning product</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1473v1</id>
    <updated>2012-01-06T18:49:43Z</updated>
    <published>2012-01-06T18:49:43Z</published>
    <title>A Representation of Binary Matrices</title>
    <summary>  In this article we discuss the presentation of a random binary matrix using
sequence of whole nonnegative numbers. We examine some advantages and
disadvantages of this presentation as an alternative of the standard
presentation using two-dimensional array. It is shown that the presentation of
binary matrices using ordered n-tuples of natural numbers makes the algorithms
faster and saves a lot of memory. In this work we use object-oriented
programming using the syntax and the semantic of C++ programming language.
</summary>
    <author>
      <name>Hristina Kostadinova</name>
    </author>
    <author>
      <name>Krasimir Yordzhev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Thirty Ninth Spring Conference of the Union of
  Bulgarian Mathematicians, Albena, April 6-10, 2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics and education in mathematics, v. 39, 2010, 198-206</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.1473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N15, 68W40, 15B34" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5964v1</id>
    <updated>2012-02-27T15:02:13Z</updated>
    <published>2012-02-27T15:02:13Z</published>
    <title>Technique detection software for Sparse Matrices</title>
    <summary>  Sparse storage formats are techniques for storing and processing the sparse
matrix data efficiently. The performance of these storage formats depend upon
the distribution of non-zeros, within the matrix in different dimensions. In
order to have better results we need a technique that suits best the
organization of data in a particular matrix. So the decision of selecting a
better technique is the main step towards improving the system's results
otherwise the efficiency can be decreased. The purpose of this research is to
help identify the best storage format in case of reduced storage size and high
processing efficiency for a sparse matrix.
</summary>
    <author>
      <name>Muhammad Taimoor Khan</name>
    </author>
    <author>
      <name>Anila Usman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII/2 (2009), 57-66</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.5964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6548v2</id>
    <updated>2012-03-01T13:31:54Z</updated>
    <published>2012-02-29T13:49:10Z</published>
    <title>mlpy: Machine Learning Python</title>
    <summary>  mlpy is a Python Open Source Machine Learning library built on top of
NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of
state-of-the-art machine learning methods for supervised and unsupervised
problems and it is aimed at finding a reasonable compromise among modularity,
maintainability, reproducibility, usability and efficiency. mlpy is
multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at
the website http://mlpy.fbk.eu.
</summary>
    <author>
      <name>Davide Albanese</name>
    </author>
    <author>
      <name>Roberto Visintainer</name>
    </author>
    <author>
      <name>Stefano Merler</name>
    </author>
    <author>
      <name>Samantha Riccadonna</name>
    </author>
    <author>
      <name>Giuseppe Jurman</name>
    </author>
    <author>
      <name>Cesare Furlanello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected a few typos; rephrased two sentences in the Overview
  section</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.6548v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6548v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3506v1</id>
    <updated>2012-05-15T20:42:23Z</updated>
    <published>2012-05-15T20:42:23Z</published>
    <title>Efficient Expression Templates for Operator Overloading-based Automatic
  Differentiation</title>
    <summary>  Expression templates are a well-known set of techniques for improving the
efficiency of operator overloading-based forward mode automatic differentiation
schemes in the C++ programming language by translating the differentiation from
individual operators to whole expressions. However standard expression template
approaches result in a large amount of duplicate computation, particularly for
large expression trees, degrading their performance. In this paper we describe
several techniques for improving the efficiency of expression templates and
their implementation in the automatic differentiation package Sacado. We
demonstrate their improved efficiency through test functions as well as their
application to differentiation of a large-scale fluid dynamics simulation code.
</summary>
    <author>
      <name>Eric Phipps</name>
    </author>
    <author>
      <name>Roger Pawlowski</name>
    </author>
    <link href="http://arxiv.org/abs/1205.3506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0141v2</id>
    <updated>2014-05-22T09:34:45Z</updated>
    <published>2012-06-01T10:36:53Z</published>
    <title>Parallelizing Mizar</title>
    <summary>  This paper surveys and describes the implementation of parallelization of the
Mizar proof checking and of related Mizar utilities. The implementation makes
use of Mizar's compiler-like division into several relatively independent
passes, with typically quite different processing speeds. The information
produced in earlier (typically much faster) passes can be used to parallelize
the later (typically much slower) passes. The parallelization now works by
splitting the formalization into a suitable number of pieces that are processed
in parallel, assembling from them together the required results. The
implementation is evaluated on examples from the Mizar library, and future
extensions are discussed.
</summary>
    <author>
      <name>Josef Urban</name>
    </author>
    <link href="http://arxiv.org/abs/1206.0141v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0141v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2291v1</id>
    <updated>2012-07-10T10:21:34Z</updated>
    <published>2012-07-10T10:21:34Z</published>
    <title>On Formal Specification of Maple Programs</title>
    <summary>  This paper is an example-based demonstration of our initial results on the
formal specification of programs written in the computer algebra language
MiniMaple (a substantial subset of Maple with slight extensions). The main goal
of this work is to define a verification framework for MiniMaple. Formal
specification of MiniMaple programs is rather complex task as it supports
non-standard types of objects, e.g. symbols and unevaluated expressions, and
additional functions and predicates, e.g. runtime type tests etc. We have used
the specification language to specify various computer algebra concepts
respective objects of the Maple package DifferenceDifferential developed at our
institute.
</summary>
    <author>
      <name>Muhammad Taimoor Khan</name>
    </author>
    <author>
      <name>Wolfgang Schreiner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-31374-5_33</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-31374-5_33" rel="related"/>
    <link href="http://arxiv.org/abs/1207.2291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4721v1</id>
    <updated>2012-08-23T11:09:57Z</updated>
    <published>2012-08-23T11:09:57Z</published>
    <title>Hamilton Operators, Discrete Symmetries, Brute Force and SymbolicC++</title>
    <summary>  To find the discrete symmetries of a Hamilton operator $\hat H$ is of central
importance in quantum theory. Here we describe and implement a brute force
method to determine the discrete symmetries given by permutation matrices for
Hamilton operators acting in a finite-dimensional Hilbert space. Spin and Fermi
systems are considered as examples. A computer algebra implementation in
SymbolicC++ is provided.
</summary>
    <author>
      <name>Willi-Hans Steeb</name>
    </author>
    <author>
      <name>Yorick Hardy</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0129183112500957</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0129183112500957" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Mod. Phys. C 24, 1250095 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.4721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4233v1</id>
    <updated>2012-09-18T15:17:10Z</updated>
    <published>2012-09-18T15:17:10Z</published>
    <title>Writing Reusable Digital Geometry Algorithms in a Generic Image
  Processing Framework</title>
    <summary>  Digital Geometry software should reflect the generality of the underlying
mathe- matics: mapping the latter to the former requires genericity. By
designing generic solutions, one can effectively reuse digital geometry data
structures and algorithms. We propose an image processing framework focused on
the Generic Programming paradigm in which an algorithm on the paper can be
turned into a single code, written once and usable with various input types.
This approach enables users to design and implement new methods at a lower
cost, try cross-domain experiments and help generalize results
</summary>
    <author>
      <name>Roland Levillain</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM, LRDE</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Géraud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LRDE</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Najman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-32313-3_10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-32313-3_10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Applications of Discrete Geometry and Mathematical
  Morphology, Istanb : France (2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0128v1</id>
    <updated>2013-01-01T19:58:26Z</updated>
    <published>2013-01-01T19:58:26Z</published>
    <title>Binary Tree Arithmetic with Generalized Constructors</title>
    <summary>  We describe arithmetic computations in terms of operations on some well known
free algebras (S1S, S2S and ordered rooted binary trees) while emphasizing the
common structure present in all them when seen as isomorphic with the set of
natural numbers.
  Constructors and deconstructors seen through an initial algebra semantics are
generalized to recursively defined functions obeying similar laws.
  Implementation using Scala's apply and unapply are discussed together with an
application to a realistic arbitrary size arithmetic package written in Scala,
based on the free algebra of rooted ordered binary trees, which also supports
rational number operations through an extension to signed rationals of the
Calkin-Wilf bijection.
</summary>
    <author>
      <name>Paul Tarau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UNPUBLISHED DRAFt, 7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0129v1</id>
    <updated>2013-01-01T20:10:51Z</updated>
    <published>2013-01-01T20:10:51Z</published>
    <title>On Two Infinite Families of Pairing Bijections</title>
    <summary>  We describe two general mechanisms for producing pairing bijections
(bijective functions defined from N x N to N).
  The first mechanism, using n-adic valuations results in parameterized
algorithms generating a countable family of distinct pairing bijections.
  The second mechanism, using characteristic functions of subsets of N provides
2^N distinct pairing bijections.
  Mechanisms to combine such pairing functions and their application to
generate families of permutations of N are also described.
  The paper uses a small subset of the functional language Haskell to provide
type checked executable specifications of all the functions defined in a
literate programming style. The self-contained Haskell code extracted from the
paper is available at http://logic.cse.unt.edu/tarau/research/2012/infpair.hs .
</summary>
    <author>
      <name>Paul Tarau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UNPUBLISHED DRAFT</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1704v1</id>
    <updated>2013-01-08T21:57:20Z</updated>
    <published>2013-01-08T21:57:20Z</published>
    <title>Parallel Algorithms for Constructing Data Structures for Fast Multipole
  Methods</title>
    <summary>  We present efficient algorithms to build data structures and the lists needed
for fast multipole methods. The algorithms are capable of being efficiently
implemented on both serial, data parallel GPU and on distributed architectures.
With these algorithms it is possible to map the FMM efficiently on to the GPU
or distributed heterogeneous CPU-GPU systems. Further, in dynamic problems, as
the distribution of the particles change, the reduced cost of building the data
structures improves performance. Using these algorithms, we demonstrate example
high fidelity simulations with large problem sizes by using FMM on both single
and multiple heterogeneous computing facilities equipped with multi-core CPU
and many-core GPUs.
</summary>
    <author>
      <name>Qi Hu</name>
    </author>
    <author>
      <name>Nail A. Gumerov</name>
    </author>
    <author>
      <name>Ramani Duraiswami</name>
    </author>
    <link href="http://arxiv.org/abs/1301.1704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6034v2</id>
    <updated>2013-04-15T10:46:46Z</updated>
    <published>2013-03-25T06:18:35Z</published>
    <title>ZKCM: a C++ library for multiprecision matrix computation with
  applications in quantum information</title>
    <summary>  ZKCM is a C++ library developed for the purpose of multiprecision matrix
computation, on the basis of the GNU MP and MPFR libraries. It provides an
easy-to-use syntax and convenient functions for matrix manipulations including
those often used in numerical simulations in quantum physics. Its extension
library, ZKCM_QC, is developed for simulating quantum computing using the
time-dependent matrix-product-state simulation method. This paper gives an
introduction about the libraries with practical sample programs.
</summary>
    <author>
      <name>Akira SaiToh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2013.03.022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2013.03.022" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 5 figures, to appear in Comput. Phys. Comm.; this is an
  extended version of arXiv:1111.3124, v2: typographical corrections only</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Comm. 184, 2005-2020 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1303.6034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80, 81-01" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7855v1</id>
    <updated>2013-04-30T04:13:58Z</updated>
    <published>2013-04-30T04:13:58Z</published>
    <title>Enhancements to ACL2 in Versions 5.0, 6.0, and 6.1</title>
    <summary>  We report on highlights of the ACL2 enhancements introduced in ACL2 releases
since the 2011 ACL2 Workshop. Although many enhancements are critical for
soundness or robustness, we focus in this paper on those improvements that
could benefit users who are aware of them, but that might not be discovered in
everyday practice.
</summary>
    <author>
      <name>Matt Kaufmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Texas at Austin</arxiv:affiliation>
    </author>
    <author>
      <name>J Strother Moore</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Texas at Austin</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.114.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.114.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ACL2 2013, arXiv:1304.7123</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 114, 2013, pp. 5-12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; I.2.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1335v1</id>
    <updated>2013-07-04T14:06:46Z</updated>
    <published>2013-07-04T14:06:46Z</published>
    <title>Investigating independent subsets of graphs, with Mathematica</title>
    <summary>  With this work we aim to show how Mathematica can be a useful tool to
investigate properties of combinatorial structures. Specifically, we will face
enumeration problems on independent subsets of powers of paths and cycles,
trying to highlight the correspondence with other combinatorial objects with
the same cardinality. Then we will study the structures obtained by ordering
properly independent subsets of paths and cycles. We will approach some
enumeration problems on the resulting partially ordered sets, putting in
evidence the correspondences with structures known as Fibonacci and Lucas
Cubes.
</summary>
    <author>
      <name>Pietro Codara</name>
    </author>
    <author>
      <name>Ottavio M. D'Antona</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematica Italia User Group Meeting (UGM) 2013, ISBN
  9788896810033. (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1348v1</id>
    <updated>2013-07-04T14:29:01Z</updated>
    <published>2013-07-04T14:29:01Z</published>
    <title>Making simple proofs simpler</title>
    <summary>  An open partition \pi{} [Cod09a, Cod09b] of a tree T is a partition of the
vertices of T with the property that, for each block B of \pi, the upset of B
is a union of blocks of \pi. This paper deals with the number, NP(n), of open
partitions of the tree, V_n, made of two chains with n points each, that share
the root.
</summary>
    <author>
      <name>Pietro Codara</name>
    </author>
    <author>
      <name>Ottavio M. D'Antona</name>
    </author>
    <author>
      <name>Francesco Marigo</name>
    </author>
    <author>
      <name>Corrado Monti</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematica Italia User Group Meeting (UGM) 2013, ISBN
  9788896810033. (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.7042v1</id>
    <updated>2013-07-26T14:18:21Z</updated>
    <published>2013-07-26T14:18:21Z</published>
    <title>Python for education: permutations</title>
    <summary>  Python implementation of permutations is presented. Three classes are
introduced: Perm for permutations, Group for permutation groups, and PermError
to report any errors for both classes. The class Perm is based on Python
dictionaries and utilize cycle notation. The methods of calculation for the
perm order, parity, ranking and unranking are given. A random permutation
generation is also shown. The class Group is very simple and it is also based
on dictionaries. It is mainly the presentation of the permutation groups
interface with methods for the group order, subgroups (normalizer, centralizer,
center, stabilizer), orbits, and several tests. The corresponding Python code
is contained in the modules perms and groups.
</summary>
    <author>
      <name>Andrzej Kapanowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 1 figure, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Python Papers 9, 3 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.7042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.7042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0056v2</id>
    <updated>2014-04-29T15:00:39Z</updated>
    <published>2013-09-30T21:05:03Z</published>
    <title>Modernizing PHCpack through phcpy</title>
    <summary>  PHCpack is a large software package for solving systems of polynomial
equations. The executable phc is menu driven and file oriented. This paper
describes the development of phcpy, a Python interface to PHCpack. Instead of
navigating through menus, users of phcpy solve systems in the Python shell or
via scripts. Persistent objects replace intermediate files.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0056v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0056v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1191v1</id>
    <updated>2013-10-04T07:50:02Z</updated>
    <published>2013-10-04T07:50:02Z</published>
    <title>Numerical integration on GPUs for higher order finite elements</title>
    <summary>  The paper considers the problem of implementation on graphics processors of
numerical integration routines for higher order finite element approximations.
The design of suitable GPU kernels is investigated in the context of general
purpose integration procedures, as well as particular example applications. The
most important characteristic of the problem investigated is the large
variation of required processor and memory resources associated with different
degrees of approximating polynomials. The questions that we try to answer are
whether it is possible to design a single integration kernel for different GPUs
and different orders of approximation and what performance can be expected in
such a case.
</summary>
    <author>
      <name>Krzysztof Banaś</name>
    </author>
    <author>
      <name>Przemysław Płaszewski</name>
    </author>
    <author>
      <name>Paweł Macioł</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2014.01.021</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2014.01.021" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers and Mathematics with Applications, Volume 67, Issue 6,
  April 2014, Pages 1319-1344</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.1191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.0455v1</id>
    <updated>2013-12-02T13:47:14Z</updated>
    <published>2013-12-02T13:47:14Z</published>
    <title>Radix Conversion for IEEE754-2008 Mixed Radix Floating-Point Arithmetic</title>
    <summary>  Conversion between binary and decimal floating-point representations is
ubiquitous. Floating-point radix conversion means converting both the exponent
and the mantissa. We develop an atomic operation for FP radix conversion with
simple straight-line algorithm, suitable for hardware design. Exponent
conversion is performed with a small multiplication and a lookup table. It
yields the correct result without error. Mantissa conversion uses a few
multiplications and a small lookup table that is shared amongst all types of
conversions. The accuracy changes by adjusting the computing precision.
</summary>
    <author>
      <name>O. Kupriianova</name>
    </author>
    <author>
      <name>Ch. Lauter</name>
    </author>
    <author>
      <name>J. -M. Muller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACSSC.2013.6810471</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACSSC.2013.6810471" rel="related"/>
    <link href="http://arxiv.org/abs/1312.0455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.0455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1290v1</id>
    <updated>2014-01-07T07:07:49Z</updated>
    <published>2014-01-07T07:07:49Z</published>
    <title>Program Verification of Numerical Computation</title>
    <summary>  These notes outline a formal method for program verification of numerical
computation. It forms the basis of the software package VPC in its initial
phase of development. Much of the style of presentation is in the form of notes
that outline the definitions and rules upon which VPC is based. The initial
motivation of this project was to address some practical issues of computation,
especially of numerically intensive programs that are commonplace in computer
models. The project evolved into a wider area for program construction as
proofs leading to a model of inference in a more general sense. Some basic
results of machine arithmetic are derived as a demonstration of VPC.
</summary>
    <author>
      <name>Garry Pantelis</name>
    </author>
    <link href="http://arxiv.org/abs/1401.1290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Fxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; F.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.2248v4</id>
    <updated>2015-01-02T11:10:05Z</updated>
    <published>2014-01-10T08:12:46Z</published>
    <title>Boolean Functions, Quantum Gates, Hamilton Operators, Spin Systems and
  Computer Algebra</title>
    <summary>  We describe the construction of quantum gates (unitary operators) from
boolean functions and give a number of applications. Both non-reversible and
reversible boolean functions are considered. The construction of the Hamilton
operator for a quantum gate is also described with the Hamilton operator
expressed as spin system. Computer algebra implementations are provided.
</summary>
    <author>
      <name>Yorick Hardy</name>
    </author>
    <author>
      <name>Willi-Hans Steeb</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">title extended, construction of spin system added</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.2248v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.2248v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.4950v1</id>
    <updated>2014-01-20T15:52:03Z</updated>
    <published>2014-01-20T15:52:03Z</published>
    <title>MRRR-based Eigensolvers for Multi-core Processors and Supercomputers</title>
    <summary>  The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR or MR3 in short) - introduced in the
late 1990s - is among the fastest methods. To compute k eigenpairs of a real
n-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in
contrast, all the other practical methods require O(k^2 n) or O(n^3) operations
in the worst case. This thesis centers around the performance and accuracy of
MRRR.
</summary>
    <author>
      <name>Matthias Petschow</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.4950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.4950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.8230v2</id>
    <updated>2014-05-12T12:45:45Z</updated>
    <published>2014-01-29T20:20:18Z</published>
    <title>Increasing precision of uniform pseudorandom number generators</title>
    <summary>  A general method to produce uniformly distributed pseudorandom numbers with
extended precision by combining two pseudorandom numbers with lower precision
is proposed. In particular, this method can be used for pseudorandom number
generation with extended precision on graphics processing units (GPU), where
the performance of single and double precision operations can vary
significantly.
</summary>
    <author>
      <name>Vadim Demchik</name>
    </author>
    <author>
      <name>Alexey Gulov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure; additional description of algorithm is applied</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.8230v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.8230v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5897v1</id>
    <updated>2014-02-21T12:23:19Z</updated>
    <published>2014-02-21T12:23:19Z</published>
    <title>A Study on the Influence of Caching: Sequences of Dense Linear Algebra
  Kernels</title>
    <summary>  It is universally known that caching is critical to attain high- performance
implementations: In many situations, data locality (in space and time) plays a
bigger role than optimizing the (number of) arithmetic floating point
operations. In this paper, we show evidence that at least for linear algebra
algorithms, caching is also a crucial factor for accurate performance modeling
and performance prediction.
</summary>
    <author>
      <name>Elmar Peise</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the Ninth International Workshop on Automatic
  Performance Tuning (iWAPT2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.5897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.1140v1</id>
    <updated>2014-03-05T14:14:12Z</updated>
    <published>2014-03-05T14:14:12Z</published>
    <title>Matrix Methods for Solving Algebraic Systems</title>
    <summary>  We present our public-domain software for the following tasks in sparse (or
toric) elimination theory, given a well-constrained polynomial system. First, C
code for computing the mixed volume of the system. Second, Maple code for
defining an overconstrained system and constructing a Sylvester-type matrix of
its sparse resultant. Third, C code for a Sylvester-type matrix of the sparse
resultant and a superset of all common roots of the initial well-constrained
system by computing the eigen-decomposition of a square matrix obtained from
the resultant matrix. We conclude with experiments in computing molecular
conformations.
</summary>
    <author>
      <name>Ioannis Z. Emiris</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages. arXiv admin note: text overlap with arXiv:1201.5810</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.1140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.1140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7645v1</id>
    <updated>2014-03-29T16:30:21Z</updated>
    <published>2014-03-29T16:30:21Z</published>
    <title>Using RngStreams for Parallel Random Number Generation in C++ and R</title>
    <summary>  The RngStreams software package provides one viable solution to the problem
of creating independent random number streams for simulations in parallel
processing environments. Techniques are presented for effectively using
RngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to
access the backbone generator from RngStreams in R through the parallel and
rstream packages are also described. The ideas in the paper are illustrated
with both a simple running example and a Monte Carlo integration application.
</summary>
    <author>
      <name>Andrew T. Karl</name>
    </author>
    <author>
      <name>Randy Eubank</name>
    </author>
    <author>
      <name>Jelena Milovanovic</name>
    </author>
    <author>
      <name>Mark Reiser</name>
    </author>
    <author>
      <name>Dennis Young</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00180-014-0492-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00180-014-0492-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted by Computational Statistics and is
  currently in press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Statistics, 2014, 29:1301-1320</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.7645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3406v1</id>
    <updated>2014-04-13T18:13:32Z</updated>
    <published>2014-04-13T18:13:32Z</published>
    <title>Knowledge-Based Automatic Generation of Linear Algebra Algorithms and
  Code</title>
    <summary>  This dissertation focuses on the design and the implementation of
domain-specific compilers for linear algebra matrix equations. The development
of efficient libraries for such equations, which lie at the heart of most
software for scientific computing, is a complex process that requires expertise
in a variety of areas, including the application domain, algorithms, numerical
analysis and high-performance computing. Moreover, the process involves the
collaboration of several people for a considerable amount of time. With our
compilers, we aim to relieve the developers from both designing algorithms and
writing code, and to generate routines that match or even surpass the
performance of those written by human experts.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Dissertation</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4410v2</id>
    <updated>2016-01-04T19:09:17Z</updated>
    <published>2014-04-17T01:31:39Z</published>
    <title>A heuristic prover for real inequalities</title>
    <summary>  We describe a general method for verifying inequalities between real-valued
expressions, especially the kinds of straightforward inferences that arise in
interactive theorem proving. In contrast to approaches that aim to be complete
with respect to a particular language or class of formulas, our method
establishes claims that require heterogeneous forms of reasoning, relying on a
Nelson-Oppen-style architecture in which special-purpose modules collaborate
and share information. The framework is thus modular and extensible. A
prototype implementation shows that the method works well on a variety of
examples, and complements techniques that are used by contemporary interactive
provers.
</summary>
    <author>
      <name>Jeremy Avigad</name>
    </author>
    <author>
      <name>Robert Y. Lewis</name>
    </author>
    <author>
      <name>Cody Roux</name>
    </author>
    <link href="http://arxiv.org/abs/1404.4410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2; G.4; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0292v1</id>
    <updated>2014-06-02T08:44:33Z</updated>
    <published>2014-06-02T08:44:33Z</published>
    <title>Interactive Simplifier Tracing and Debugging in Isabelle</title>
    <summary>  The Isabelle proof assistant comes equipped with a very powerful tactic for
term simplification. While tremendously useful, the results of simplifying a
term do not always match the user's expectation: sometimes, the resulting term
is not in the form the user expected, or the simplifier fails to apply a rule.
We describe a new, interactive tracing facility which offers insight into the
hierarchical structure of the simplification with user-defined filtering,
memoization and search. The new simplifier trace is integrated into the
Isabelle/jEdit Prover IDE.
</summary>
    <author>
      <name>Lars Hupel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-08434-3_24</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-08434-3_24" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conferences on Intelligent Computer Mathematics, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1796v2</id>
    <updated>2019-09-14T21:15:15Z</updated>
    <published>2014-06-06T19:22:44Z</published>
    <title>A Generic Numbering System based on Catalan Families of Combinatorial
  Objects</title>
    <summary>  We describe arithmetic algorithms on a canonical number representation based
on the Catalan family of combinatorial objects specified as a Haskell type
class.
  Our algorithms work on a {\em generic} representation that we illustrate on
instances members of the Catalan family, like ordered binary and multiway
trees. We validate the correctness of our algorithms by defining an instance of
the same type class based the usual bitstring-based natural numbers.
  While their average and worst case complexity is within constant factors of
their traditional counterparts, our algorithms provide super-exponential gains
for numbers corresponding to Catalan objects of low representation size.
</summary>
    <author>
      <name>Paul Tarau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.1796v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1796v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5597v1</id>
    <updated>2014-06-21T11:19:59Z</updated>
    <published>2014-06-21T11:19:59Z</published>
    <title>Transpose-free Fast Fourier Transform for Turbulence Simulation</title>
    <summary>  Pseudo-spectral method is one of the most accurate techniques for simulating
turbulent flows. Fast Fourier transform (FFT) is an integral part of this
method. In this paper, we present a new procedure to compute FFT in which we
save operations during interprocess communications by avoiding transpose of the
array. As a result, our transpose-free FFT is 15\% to 20\% faster than FFTW.
</summary>
    <author>
      <name>A. G. Chatterjee</name>
    </author>
    <author>
      <name>M. K. Verma</name>
    </author>
    <author>
      <name>M. Chaudhuri</name>
    </author>
    <link href="http://arxiv.org/abs/1406.5597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3383v1</id>
    <updated>2014-07-12T13:21:01Z</updated>
    <published>2014-07-12T13:21:01Z</published>
    <title>Modular SIMD arithmetic in Mathemagix</title>
    <summary>  Modular integer arithmetic occurs in many algorithms for computer algebra,
cryptography, and error correcting codes. Although recent microprocessors
typically offer a wide range of highly optimized arithmetic functions, modular
integer operations still require dedicated implementations. In this article, we
survey existing algorithms for modular integer arithmetic, and present detailed
vectorized counterparts. We also present several applications, such as fast
modular Fourier transforms and multiplication of integer polynomials and
matrices. The vectorized algorithms have been implemented in C++ inside the
free computer algebra and analysis system Mathemagix. The performance of our
implementation is illustrated by various benchmarks.
</summary>
    <author>
      <name>Joris van der Hoeven</name>
    </author>
    <author>
      <name>Grégoire Lecerf</name>
    </author>
    <author>
      <name>Guillaume Quintin</name>
    </author>
    <link href="http://arxiv.org/abs/1407.3383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0854v1</id>
    <updated>2014-08-05T03:18:28Z</updated>
    <published>2014-08-05T03:18:28Z</published>
    <title>Semi-Analytical Computation of Acoustic Scattering by Spheroids and
  Disks</title>
    <summary>  Analytical solutions to acoustic scattering problems involving nonspherical
shapes, such as spheroids and disks, have long been known and have many
applications. However, these solutions require special functions that are not
easily computable. For this reason, their asymptotic forms are typically used
since they are more readily available. We explore these solutions and provide
computational software for calculating their nonasymptotic forms, which are
accurate over a wide range of frequencies and distances. This software, which
runs in MATLAB, computes the solutions to acoustic scattering problems
involving spheroids and disks by semi-analytical means, and is freely available
from our webpage.
</summary>
    <author>
      <name>Ross Adelman</name>
    </author>
    <author>
      <name>Nail A. Gumerov</name>
    </author>
    <author>
      <name>Ramani Duraiswami</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1121/1.4901318</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1121/1.4901318" rel="related"/>
    <link href="http://arxiv.org/abs/1408.0854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2008v2</id>
    <updated>2015-01-25T18:34:58Z</updated>
    <published>2014-09-06T12:19:37Z</published>
    <title>Computing the coefficients for the power series solution of the
  Lane-Emden equation with the Python library SymPy</title>
    <summary>  It is shown how the Python library Sympy can be used to compute symbolically
the coefficients of the power series solution of the Lane-Emden equation (LEE).
Sympy is an open source Python library for symbolic mathematics. The power
series solutions are compared to the numerically computed solutions using
matplotlib. The results of a run time measurement of the implemented algorithm
are discussed at the end.
</summary>
    <author>
      <name>Klaus Rohe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures, 2 source code listings</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2008v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2008v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4618v2</id>
    <updated>2015-05-11T13:19:00Z</updated>
    <published>2014-09-16T13:08:47Z</published>
    <title>Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements</title>
    <summary>  We propose an effective and flexible way to assemble finite element stiffness
and mass matrices in MATLAB. We apply this for problems discretized by edge
finite elements. Typical edge finite elements are Raviart-Thomas elements used
in discretizations of H(div) spaces and Nedelec elements in discretizations of
H(curl) spaces. We explain vectorization ideas and comment on a freely
available MATLAB code which is fast and scalable with respect to time.
</summary>
    <author>
      <name>Immanuel Anjam</name>
    </author>
    <author>
      <name>Jan Valdman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.amc.2015.03.105</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.amc.2015.03.105" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, ESCO 2014 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4618v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4618v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80, 65M60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7176v2</id>
    <updated>2015-06-09T07:14:40Z</updated>
    <published>2014-10-27T10:35:42Z</published>
    <title>Efficient implementation of elementary functions in the medium-precision
  range</title>
    <summary>  We describe a new implementation of the elementary transcendental functions
exp, sin, cos, log and atan for variable precision up to approximately 4096
bits. Compared to the MPFR library, we achieve a maximum speedup ranging from a
factor 3 for cos to 30 for atan. Our implementation uses table-based argument
reduction together with rectangular splitting to evaluate Taylor series. We
collect denominators to reduce the number of divisions in the Taylor series,
and avoid overhead by doing all multiprecision arithmetic using the mpn layer
of the GMP library. Our implementation provides rigorous error bounds.
</summary>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ARITH 22</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.7176v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7176v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01577v1</id>
    <updated>2015-05-07T04:09:24Z</updated>
    <published>2015-05-07T04:09:24Z</published>
    <title>Documentation Generator Focusing on Symbols for the HTML-ized Mizar
  Library</title>
    <summary>  The purpose of this project is to collect symbol information in the Mizar
Mathematical Library and manipulate it into practical and organized
documentation. Inspired by the MathWiki project and API reference systems for
computer programs, we developed a documentation generator focusing on symbols
for the HTML-ized Mizar library. The system has several helpful features,
including a symbol list, incremental search, and a referrer list. It targets
those who use proof assistance systems, the volume of whose libraries has been
rapidly increasing year by year.
</summary>
    <author>
      <name>Kazuhisa Nakasho</name>
    </author>
    <author>
      <name>Yasunari Shidama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figures, Conference on Intelligent Computer Mathematics
  2015 (CICM2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.08019v1</id>
    <updated>2015-05-29T12:33:52Z</updated>
    <published>2015-05-29T12:33:52Z</published>
    <title>Research on the fast Fourier transform of image based on GPU</title>
    <summary>  Study of general purpose computation by GPU (Graphics Processing Unit) can
improve the image processing capability of micro-computer system. This paper
studies the parallelism of the different stages of decimation in time radix 2
FFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT
on GPU. The experiment result demonstrates the validity and advantage over
general CPU, especially in the condition of large input size. The approach can
also be generalized to other transforms alike.
</summary>
    <author>
      <name>Feifei Shen</name>
    </author>
    <author>
      <name>Zhenjian Song</name>
    </author>
    <author>
      <name>Congrui Wu</name>
    </author>
    <author>
      <name>Jiaqi Geng</name>
    </author>
    <author>
      <name>Qingyun Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1505.08019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.08019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02618v1</id>
    <updated>2015-06-08T19:05:49Z</updated>
    <published>2015-06-08T19:05:49Z</published>
    <title>Solving Polynomial Systems in the Cloud with Polynomial Homotopy
  Continuation</title>
    <summary>  Polynomial systems occur in many fields of science and engineering.
Polynomial homotopy continuation methods apply symbolic-numeric algorithms to
solve polynomial systems. We describe the design and implementation of our web
interface and reflect on the application of polynomial homotopy continuation
methods to solve polynomial systems in the cloud. Via the graph isomorphism
problem we organize and classify the polynomial systems we solved. The
classification with the canonical form of a graph identifies newly submitted
systems with systems that have already been solved.
</summary>
    <author>
      <name>Nathan Bliss</name>
    </author>
    <author>
      <name>Jeff Sommars</name>
    </author>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <author>
      <name>Xiangcheng Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the Proceedings of CASC 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03726v2</id>
    <updated>2016-02-18T16:02:44Z</updated>
    <published>2015-06-11T16:08:54Z</published>
    <title>Lacunaryx: Computing bounded-degree factors of lacunary polynomials</title>
    <summary>  In this paper, we report on an implementation in the free software Mathemagix
of lacunary factorization algorithms, distributed as a library called
Lacunaryx. These algorithms take as input a polynomial in sparse
representation, that is as a list of nonzero monomials, and an integer $d$, and
compute its irreducible degree-$\le d$ factors. The complexity of these
algorithms is polynomial in the sparse size of the input polynomial and $d$.
</summary>
    <author>
      <name>Bruno Grenet</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2893803.2893807</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2893803.2893807" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Communications in Computer Algebra 49(4), 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.03726v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03726v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04776v1</id>
    <updated>2015-06-15T21:20:06Z</updated>
    <published>2015-06-15T21:20:06Z</published>
    <title>Encog: Library of Interchangeable Machine Learning Models for Java and
  C#</title>
    <summary>  This paper introduces the Encog library for Java and C#, a scalable,
adaptable, multiplatform machine learning framework that was 1st released in
2008. Encog allows a variety of machine learning models to be applied to
datasets using regression, classification, and clustering. Various supported
machine learning models can be used interchangeably with minimal recoding.
Encog uses efficient multithreaded code to reduce training time by exploiting
modern multicore processors. The current version of Encog can be downloaded
from http://www.encog.org.
</summary>
    <author>
      <name>Jeff Heaton</name>
    </author>
    <link href="http://arxiv.org/abs/1506.04776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T01" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06704v1</id>
    <updated>2015-04-25T07:16:35Z</updated>
    <published>2015-04-25T07:16:35Z</published>
    <title>Software realization of the complex spectra analysis algorithm in R</title>
    <summary>  Software realization of the complex spectra decomposition on unknown number
of similarcomponents is proposed.The algorithm is based on non-linear
minimizing the sum of squared residuals of the spectrum model. For the adequacy
checking the complex of criteria is used.It tests the model residuals
correspondence with the normal distribution, equality to zero of their mean
value and autocorrelation. Also the closeness of residuals and experimental
data variances is checked.
</summary>
    <author>
      <name>Vladimir Bakhrushin</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bakhrushin, V. (2015) "Software realization of the complex spectra
  analysis algorithm in R" ["Programmnaya realizatsiya algoritma analiza
  slozhnyih spektrov na yazyike R"], Sistemni tehnologiyi, No 2 (97), pp. 3 - 7</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.06704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00688v1</id>
    <updated>2015-08-04T07:25:56Z</updated>
    <published>2015-08-04T07:25:56Z</published>
    <title>Accelerating R with high performance linear algebra libraries</title>
    <summary>  Linear algebra routines are basic building blocks for the statistical
software. In this paper we analyzed how can we can improve R performance for
matrix computations. We benchmarked few matrix operations using the standard
linear algebra libraries included in the R distribution and high performance
libraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best
results are obtained with the MKL library, the other two libraries having
similar performances, but lower than MKL
</summary>
    <author>
      <name>Bogdan Oancea</name>
    </author>
    <author>
      <name>Tudorel Andrei</name>
    </author>
    <author>
      <name>Raluca Mariana Dragoescu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Romanian Statistical Review, No. 3, 2015, pp. 109-117</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1508.00688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05374v1</id>
    <updated>2015-05-11T19:11:56Z</updated>
    <published>2015-05-11T19:11:56Z</published>
    <title>POLYANA - A tool for the calculation of molecular radial distribution
  functions based on Molecular Dynamics trajectories</title>
    <summary>  We present an application for the calculation of radial distribution
functions for molecular centres of mass, based on trajectories generated by
molecular simulation methods (Molecular Dynamics, Monte Carlo). When designing
this application, the emphasis was placed on ease of use as well as ease of
further development. In its current version, the program can read trajectories
generated by the well-known DL_POLY package, but it can be easily extended to
treat other formats. It is also very easy to 'hack' the program so it can
compute intermolecular radial distribution functions for groups of interaction
sites rather than whole molecules.
</summary>
    <author>
      <name>Christos Dimitroulis</name>
    </author>
    <author>
      <name>Theophanes Raptis</name>
    </author>
    <author>
      <name>Vasilios Raptis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2015.08.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2015.08.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05374v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05374v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05470v4</id>
    <updated>2019-06-07T00:49:39Z</updated>
    <published>2015-08-22T04:43:36Z</published>
    <title>Non-Metric Space Library Manual</title>
    <summary>  This document covers a library for fast similarity (k-NN)search. It describes
only search methods and distances (spaces). Details about building, installing,
Python bindings can be found
online:https://github.com/searchivarius/nmslib/tree/v1.8/. Even though the
library contains a variety of exact metric-space access methods, our main focus
is on more generic and approximate search methods, in particular, on methods
for non-metric spaces. NMSLIB is possibly the first library with a principled
support for non-metric space searching.
</summary>
    <author>
      <name>Bilegsaikhan Naidan</name>
    </author>
    <author>
      <name>Leonid Boytsov</name>
    </author>
    <author>
      <name>Yury Malkov</name>
    </author>
    <author>
      <name>David Novak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Methodology paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05470v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05470v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02789v1</id>
    <updated>2015-10-08T09:47:51Z</updated>
    <published>2015-10-08T09:47:51Z</published>
    <title>A novel code generation methodology for block diagram modeler and
  simulators Scicos and VSS</title>
    <summary>  Block operations during simulation in Scicos and VSS environments can
naturally be described as Nsp functions. But the direct use of Nsp functions
for simulation leads to poor performance since the Nsp language is interpreted,
not compiled. The methodology presented in this paper is used to develop a tool
for generating efficient compilable code, such as C and ADA, for Scicos and VSS
models from these block Nsp functions. Operator overloading and partial
evaluation are the key elements of this novel approach. This methodology may be
used in other simulation environments such as Matlab/Simulink.
</summary>
    <author>
      <name>Jean-Philippe Chancelier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <author>
      <name>Ramine Nikoukhah</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">METALAU</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1510.02789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03167v1</id>
    <updated>2015-11-10T16:22:27Z</updated>
    <published>2015-11-10T16:22:27Z</published>
    <title>BOAT: a cross-platform software for data analysis and numerical
  computing with arbitrary-precision</title>
    <summary>  BOAT is a free cross-platform software for statistical data analysis and
numerical computing. Thanks to its multiple-precision floating point engine, it
allows arbitrary-precision calculations, whose digits of precision are only
limited by the amount of memory of the host machine. At the core of the
software is a simple and efficient expression language, whose use is
facilitated by the assisted typing, the auto-complete engine and the built-in
help for the syntax. In this paper a quick overview of the software is given.
Detailed information, together with its applications to some case studies, is
available at the BOAT web page.
</summary>
    <author>
      <name>Davide Pagano</name>
    </author>
    <link href="http://arxiv.org/abs/1511.03167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05986v2</id>
    <updated>2016-11-07T05:06:40Z</updated>
    <published>2015-11-15T19:33:39Z</published>
    <title>Computing with Harmonic Functions</title>
    <summary>  This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions.
</summary>
    <author>
      <name>Sheldon Axler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">77 pages. Software available at http://axler.net/HFT_Math.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05986v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05986v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="31B05, 31B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07789v3</id>
    <updated>2016-07-22T14:38:42Z</updated>
    <published>2016-01-26T13:24:40Z</published>
    <title>Vectorization of Multibyte Floating Point Data Formats</title>
    <summary>  We propose a scheme for reduced-precision representation of floating point
data on a continuum between IEEE-754 floating point types. Our scheme enables
the use of lower precision formats for a reduction in storage space
requirements and data transfer volume. We describe how our scheme can be
accelerated using existing hardware vector units on a general-purpose processor
(GPP). Exploiting native vector hardware allows us to support reduced precision
floating point with low overhead. We demonstrate that supporting reduced
precision in the compiler as opposed to using a library approach can yield a
low overhead solution for GPPs.
</summary>
    <author>
      <name>Andrew Anderson</name>
    </author>
    <author>
      <name>David Gregg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2967938.2967966</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2967938.2967966" rel="related"/>
    <link href="http://arxiv.org/abs/1601.07789v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07789v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.4; G.1.0; B.2.4; I.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06763v2</id>
    <updated>2022-04-06T06:32:17Z</updated>
    <published>2016-02-22T13:21:05Z</published>
    <title>Algorithm 979: Recursive Algorithms for Dense Linear Algebra -- The
  ReLAPACK Collection</title>
    <summary>  To exploit both memory locality and the full performance potential of highly
tuned kernels, dense linear algebra libraries such as LAPACK commonly implement
operations as blocked algorithms. However, to achieve next-to-optimal
performance with such algorithms, significant tuning is required. On the other
hand, recursive algorithms are virtually tuning free, and yet attain similar
performance. In this paper, we first analyze and compare blocked and recursive
algorithms in terms of performance, and then introduce ReLAPACK, an open-source
library of recursive algorithms to seamlessly replace most of LAPACK's blocked
algorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,
and even improves upon the performance of optimizes libraries.
</summary>
    <author>
      <name>Elmar Peise</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1602.06763v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06763v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.08991v1</id>
    <updated>2016-02-25T22:42:50Z</updated>
    <published>2016-02-25T22:42:50Z</published>
    <title>Extending DUNE: The dune-xt modules</title>
    <summary>  We present our effort to extend and complement the core modules of the
Distributed and Unified Numerics Environment DUNE (http://dune-project.org) by
a well tested and structured collection of utilities and concepts. We describe
key elements of our four modules dune-xt-common, dune-xt-grid, dune-xt-la and
dune-xt-functions, which aim at further enabling the programming of generic
algorithms within DUNE as well as adding an extra layer of usability and
convenience.
</summary>
    <author>
      <name>Tobias Leibner</name>
    </author>
    <author>
      <name>René Milk</name>
    </author>
    <author>
      <name>Felix Schindler</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.11588/ans.2017.1.27720</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.11588/ans.2017.1.27720" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archive of Numerical Software, 5 (2017), pp. 193-216</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.08991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.08991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.04483v1</id>
    <updated>2016-03-14T21:28:46Z</updated>
    <published>2016-03-14T21:28:46Z</published>
    <title>Fast calculation of inverse square root with the use of magic constant
  $-$ analytical approach</title>
    <summary>  We present a mathematical analysis of transformations used in fast
calculation of inverse square root for single-precision floating-point numbers.
Optimal values of the so called magic constants are derived in a systematic
way, minimizing either absolute or relative errors at subsequent stages of the
discussed algorithm.
</summary>
    <author>
      <name>Leonid V. Moroz</name>
    </author>
    <author>
      <name>Cezary J. Walczyk</name>
    </author>
    <author>
      <name>Andriy Hrynchyshyn</name>
    </author>
    <author>
      <name>Vijay Holimath</name>
    </author>
    <author>
      <name>Jan L. Cieśliński</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.04483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.04483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07008v1</id>
    <updated>2016-03-22T22:07:18Z</updated>
    <published>2016-03-22T22:07:18Z</published>
    <title>A mixed precision semi-Lagrangian algorithm and its performance on
  accelerators</title>
    <summary>  In this paper we propose a mixed precision algorithm in the context of the
semi-Lagrangian discontinuous Galerkin method. The performance of this approach
is evaluated on a traditional dual socket workstation as well as on a Xeon Phi
and an NVIDIA K80. We find that the mixed precision algorithm can be
implemented efficiently on these architectures. This implies that, in addition
to the considerable reduction in memory, a substantial increase in performance
can be observed as well. Moreover, we discuss the relative performance of our
implementations.
</summary>
    <author>
      <name>Lukas Einkemmer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HPCSim.2016.7568318</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HPCSim.2016.7568318" rel="related"/>
    <link href="http://arxiv.org/abs/1603.07008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05872v1</id>
    <updated>2016-04-20T09:39:29Z</updated>
    <published>2016-04-20T09:39:29Z</published>
    <title>An algorithm for the optimization of finite element integration loops</title>
    <summary>  We present an algorithm for the optimization of a class of finite element
integration loop nests. This algorithm, which exploits fundamental mathematical
properties of finite element operators, is proven to achieve a locally optimal
operation count. In specified circumstances the optimum achieved is global.
Extensive numerical experiments demonstrate significant performance
improvements over the state of the art in finite element code generation in
almost all cases. This validates the effectiveness of the algorithm presented
here, and illustrates its limitations.
</summary>
    <author>
      <name>Fabio Luporini</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <author>
      <name>Paul H. J. Kelly</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3054944</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3054944" rel="related"/>
    <link href="http://arxiv.org/abs/1604.05872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06112v1</id>
    <updated>2016-04-20T20:07:48Z</updated>
    <published>2016-04-20T20:07:48Z</published>
    <title>Convex Hull Calculations: a Matlab Implementation and Correctness Proofs
  for the lrs-Algorithm</title>
    <summary>  This paper provides full \Matlab-code and informal correctness proofs for the
lexicographic reverse search algorithm for convex hull calculations. The
implementation was tested on a 1993 486-PC for various small and some larger,
partially highly degenerate combinatorial polytopes, one of which (a certain
13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well
known problem posed by Professor Graciano de Oliveira: see end of section 1.
</summary>
    <author>
      <name>Alexander Kovačec</name>
    </author>
    <author>
      <name>Bernardete Ribeiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.06112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07242v1</id>
    <updated>2016-04-25T13:22:16Z</updated>
    <published>2016-04-25T13:22:16Z</published>
    <title>Implementation of $hp$-adaptive discontinuous finite element methods in
  Dune-Fem</title>
    <summary>  In this paper we describe generic algorithms and data structures for the
implementation of $hp$-adaptive discontinuous finite element methods in the
Dune-Fem library. Special attention is given to the often tedious and
error-prone task of transferring user data during adaptation. Simultaneously,
we generalize the approach to the restriction and prolongation of data
currently implemented in Dune-Fem to the case of $p$- and $hp$-adaptation. The
dune-fem-hpdg module described in this paper provides an extensible reference
implementation of $hp$-adaptive discontinuous discrete function spaces. We give
details on its implementation and the extended adaptive interface. As proof of
concept we present the practical realization of an $hp$-adaptive interior
penalty method for elliptic problems.
</summary>
    <author>
      <name>Christoph Gersbacher</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00998v1</id>
    <updated>2016-05-03T17:49:27Z</updated>
    <published>2016-05-03T17:49:27Z</published>
    <title>Blackbox: A procedure for parallel optimization of expensive black-box
  functions</title>
    <summary>  This note provides a description of a procedure that is designed to
efficiently optimize expensive black-box functions. It uses the response
surface methodology by incorporating radial basis functions as the response
model. A simple method based on a Latin hypercube is used for initial sampling.
A modified version of CORS algorithm with space rescaling is used for the
subsequent sampling. The procedure is able to scale on multicore processors by
performing multiple function evaluations in parallel. The source code of the
procedure is written in Python.
</summary>
    <author>
      <name>Paul Knysh</name>
    </author>
    <author>
      <name>Yannis Korkolis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.00998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02532v3</id>
    <updated>2017-08-10T20:20:02Z</updated>
    <published>2016-05-09T11:24:39Z</published>
    <title>HLinear: Exact Dense Linear Algebra in Haskell</title>
    <summary>  We present an implementation in the functional programming language Haskell
of the PLE decomposition of matrices over division rings. Our benchmarks
indicate that it is competitive with the C-based implementation provided in
Flint. Describing the guiding principles of our work, we introduce the reader
to basic ideas from high-performance functional programming.
</summary>
    <author>
      <name>Alexandru Ghitza</name>
    </author>
    <author>
      <name>Martin Raum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 tables; code available at
  https://github.com/martinra/hlinear/tree/paper-toms</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02532v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02532v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N18" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00541v1</id>
    <updated>2016-06-02T05:54:09Z</updated>
    <published>2016-06-02T05:54:09Z</published>
    <title>Parallel Triangular Solvers on GPU</title>
    <summary>  In this paper, we investigate GPU based parallel triangular solvers
systematically. The parallel triangular solvers are fundamental to incomplete
LU factorization family preconditioners and algebraic multigrid solvers. We
develop a new matrix format suitable for GPU devices. Parallel lower triangular
solvers and upper triangular solvers are developed for this new data structure.
With these solvers, ILU preconditioners and domain decomposition
preconditioners are developed. Numerical results show that we can speed
triangular solvers around seven times faster.
</summary>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00545v1</id>
    <updated>2016-06-02T06:01:05Z</updated>
    <published>2016-06-02T06:01:05Z</published>
    <title>Development of Krylov and AMG linear solvers for large-scale sparse
  matrices on GPUs</title>
    <summary>  This research introduce our work on developing Krylov subspace and AMG
solvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,
SpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix
format and a communication mechanism are established. And also, a set of
specific algorithms for solving preconditioned systems in parallel environments
are designed, including ILU(k), RAS and parallel triangular solvers. Based on
these work, several Krylov solvers and AMG solvers are developed. According to
numerical experiments, favorable acceleration performance is acquired from our
Krylov solver and AMG solver under various parameter conditions.
</summary>
    <author>
      <name>Bo Yang</name>
    </author>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00545v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00545v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06311v1</id>
    <updated>2016-06-20T20:14:12Z</updated>
    <published>2016-06-20T20:14:12Z</published>
    <title>Benchmarking Python Tools for Automatic Differentiation</title>
    <summary>  In this paper we compare several Python tools for automatic differentiation.
In order to assess the difference in performance and precision, the problem of
finding the optimal geometrical structure of the cluster with identical atoms
is used as follows. First, we compare performance of calculating gradients for
the objective function. We showed that the PyADOL-C and PyCppAD tools have much
better performance for big clusters than the other ones. Second, we assess
precision of these two tools by calculating the difference between the obtained
at the optimal configuration gradient norms. We conclude that PyCppAD has the
best performance among others, while having almost the same precision as the
second- best performing tool - PyADOL-C.
</summary>
    <author>
      <name>Andrei Turkin</name>
    </author>
    <author>
      <name>Aung Thu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.06311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01477v2</id>
    <updated>2016-07-30T16:52:39Z</updated>
    <published>2016-07-06T04:19:04Z</published>
    <title>Accelerating eigenvector and pseudospectra computation using blocked
  multi-shift triangular solves</title>
    <summary>  Multi-shift triangular solves are basic linear algebra calculations with
applications in eigenvector and pseudospectra computation. We propose blocked
algorithms that efficiently exploit Level 3 BLAS to perform multi-shift
triangular solves and safe multi-shift triangular solves. Numerical experiments
indicate that computing triangular eigenvectors with a safe multi-shift
triangular solve achieves speedups by a factor of 60 relative to LAPACK. This
algorithm accelerates the calculation of general eigenvectors threefold. When
using multi-shift triangular solves to compute pseudospectra, we report
ninefold speedups relative to EigTool.
</summary>
    <author>
      <name>Tim Moon</name>
    </author>
    <author>
      <name>Jack Poulson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01477v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01477v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04091v2</id>
    <updated>2016-11-23T09:58:28Z</updated>
    <published>2016-07-14T11:26:28Z</published>
    <title>Generalized Sampling in Julia</title>
    <summary>  Generalized sampling is a numerically stable framework for obtaining
reconstructions of signals in different bases and frames from their samples. In
this paper, we will introduce a carefully documented toolbox for performing
generalized sampling in Julia. Julia is a new language for technical computing
with focus on performance, which is ideally suited to handle the large size
problems often encountered in generalized sampling. The toolbox provides
specialized solutions for the setup of Fourier bases and wavelets. The
performance of the toolbox is compared to existing implementations of
generalized sampling in MATLAB.
</summary>
    <author>
      <name>Robert Dahl Jacobsen</name>
    </author>
    <author>
      <name>Morten Nielsen</name>
    </author>
    <author>
      <name>Morten Grud Rasmussen</name>
    </author>
    <link href="http://arxiv.org/abs/1607.04091v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04091v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04767v1</id>
    <updated>2016-07-16T16:54:39Z</updated>
    <published>2016-07-16T16:54:39Z</published>
    <title>Optimized Automatic Code Generation for Geometric Algebra Based
  Algorithms with Ray Tracing Application</title>
    <summary>  Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application.
</summary>
    <author>
      <name>Ahmad Hosney Awad Eid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Thesis, 2010, 249 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04041v1</id>
    <updated>2016-08-14T00:58:41Z</updated>
    <published>2016-08-14T00:58:41Z</published>
    <title>Julia Implementation of the Dynamic Distributed Dimensional Data Model</title>
    <summary>  Julia is a new language for writing data analysis programs that are easy to
implement and run at high performance. Similarly, the Dynamic Distributed
Dimensional Data Model (D4M) aims to clarify data analysis operations while
retaining strong performance. D4M accomplishes these goals through a
composable, unified data model on associative arrays. In this work, we present
an implementation of D4M in Julia and describe how it enables and facilitates
data analysis. Several experiments showcase scalable performance in our new
Julia version as compared to the original Matlab implementation.
</summary>
    <author>
      <name>Alexander Chen</name>
    </author>
    <author>
      <name>Alan Edelman</name>
    </author>
    <author>
      <name>Jeremy Kepner</name>
    </author>
    <author>
      <name>Vijay Gadepally</name>
    </author>
    <author>
      <name>Dylan Hutchison</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HPEC.2016.7761626</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HPEC.2016.7761626" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 16 figures, IEEE HPEC 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04152v1</id>
    <updated>2016-08-14T23:17:03Z</updated>
    <published>2016-08-14T23:17:03Z</published>
    <title>Computation of the incomplete gamma function for negative values of the
  argument</title>
    <summary>  An algorithm for computing the incomplete gamma function $\gamma^*(a,z)$ for
real values of the parameter $a$ and negative real values of the argument $z$
is presented. The algorithm combines the use of series expansions,
Poincar\'e-type expansions, uniform asymptotic expansions and recurrence
relations, depending on the parameter region. A relative accuracy $\sim
10^{-13}$ in the parameter region $(a,z) \in [-500,\,500] \times [-500,\,0)$
can be obtained when computing the function $\gamma^*(a,z)$ with the Fortran 90
module IncgamNEG implementing the algorithm.
</summary>
    <author>
      <name>A. Gil</name>
    </author>
    <author>
      <name>D. Ruiz-Antolín</name>
    </author>
    <author>
      <name>J. Segura</name>
    </author>
    <author>
      <name>N. M. Temme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ACM Trans. Math. Softw</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01088v1</id>
    <updated>2016-09-05T10:41:14Z</updated>
    <published>2016-09-05T10:41:14Z</published>
    <title>GTApprox: surrogate modeling for industrial design</title>
    <summary>  We describe GTApprox - a new tool for medium-scale surrogate modeling in
industrial design. Compared to existing software, GTApprox brings several
innovations: a few novel approximation algorithms, several advanced methods of
automated model selection, novel options in the form of hints. We demonstrate
the efficiency of GTApprox on a large collection of test problems. In addition,
we describe several applications of GTApprox to real engineering problems.
</summary>
    <author>
      <name>Mikhail Belyaev</name>
    </author>
    <author>
      <name>Evgeny Burnaev</name>
    </author>
    <author>
      <name>Ermek Kapushev</name>
    </author>
    <author>
      <name>Maxim Panov</name>
    </author>
    <author>
      <name>Pavel Prikhodko</name>
    </author>
    <author>
      <name>Dmitry Vetrov</name>
    </author>
    <author>
      <name>Dmitry Yarotsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.01088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00675v2</id>
    <updated>2018-05-28T11:47:47Z</updated>
    <published>2016-11-02T16:39:06Z</published>
    <title>emgr - The Empirical Gramian Framework</title>
    <summary>  System Gramian matrices are a well-known encoding for properties of
input-output systems such as controllability, observability or minimality.
These so-called system Gramians were developed in linear system theory for
applications such as model order reduction of control systems. Empirical
Gramian are an extension to the system Gramians for parametric and nonlinear
systems as well as a data-driven method of computation. The empirical Gramian
framework - emgr - implements the empirical Gramians in a uniform and
configurable manner, with applications such as Gramian-based (nonlinear) model
reduction, decentralized control, sensitivity analysis, parameter
identification and combined state and parameter reduction.
</summary>
    <author>
      <name>Christian Himpe</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3390/a11070091</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3390/a11070091" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Algorithms 11(7): 91, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1611.00675v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00675v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="93A15, 93B20, 93C10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.02831v1</id>
    <updated>2016-11-09T06:23:37Z</updated>
    <published>2016-11-09T06:23:37Z</published>
    <title>Arb: Efficient Arbitrary-Precision Midpoint-Radius Interval Arithmetic</title>
    <summary>  Arb is a C library for arbitrary-precision interval arithmetic using the
midpoint-radius representation, also known as ball arithmetic. It supports real
and complex numbers, polynomials, power series, matrices, and evaluation of
many special functions. The core number types are designed for versatility and
speed in a range of scenarios, allowing performance that is competitive with
non-interval arbitrary-precision types such as MPFR and MPC floating-point
numbers. We discuss the low-level number representation, strategies for
precision and error bounds, and the implementation of efficient polynomial
arithmetic with interval coefficients.
</summary>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.02831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.02831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01145v1</id>
    <updated>2017-04-04T18:28:01Z</updated>
    <published>2017-04-04T18:28:01Z</published>
    <title>Conical: an extended module for computing a numerically satisfactory
  pair of solutions of the differential equation for conical functions</title>
    <summary>  Conical functions appear in a large number of applications in physics and
engineering. In this paper we describe an extension of our module CONICAL for
the computation of conical functions. Specifically, the module includes now a
routine for computing the function ${{\rm R}}^{m}_{-\frac{1}{2}+i\tau}(x)$, a
real-valued numerically satisfactory companion of the function ${\rm
P}^m_{-\tfrac12+i\tau}(x)$ for $x&gt;1$. In this way, a natural basis for solving
Dirichlet problems bounded by conical domains is provided.
</summary>
    <author>
      <name>T. M. Dunster</name>
    </author>
    <author>
      <name>A. Gil</name>
    </author>
    <author>
      <name>J. Segura</name>
    </author>
    <author>
      <name>N. M. Temme</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2017.04.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2017.04.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Computer Physics Communications</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.01145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05594v2</id>
    <updated>2018-07-02T03:06:51Z</updated>
    <published>2017-04-19T02:58:23Z</published>
    <title>DATeS: A Highly-Extensible Data Assimilation Testing Suite v1.0</title>
    <summary>  A flexible and highly-extensible data assimilation testing suite, named
DATeS, is described in this paper. DATeS aims to offer a unified testing
environment that allows researchers to compare different data assimilation
methodologies and understand their performance in various settings. The core of
DATeS is implemented in Python and takes advantage of its object-oriented
capabilities. The main components of the package (the numerical models, the
data assimilation algorithms, the linear algebra solvers, and the time
discretization routines) are independent of each other, which offers great
flexibility to configure data assimilation applications. DATeS can interface
easily with large third-party numerical models written in Fortran or in C, and
with a plethora of external solvers.
</summary>
    <author>
      <name>Ahmed Attia</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <link href="http://arxiv.org/abs/1704.05594v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05594v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08907v2</id>
    <updated>2017-10-11T20:50:12Z</updated>
    <published>2017-04-28T12:49:43Z</published>
    <title>Particle-based and Meshless Methods with Aboria</title>
    <summary>  Aboria is a powerful and flexible C++ library for the implementation of
particle-based numerical methods. The particles in such methods can represent
actual particles (e.g. Molecular Dynamics) or abstract particles used to
discretise a continuous function over a domain (e.g. Radial Basis Functions).
Aboria provides a particle container, compatible with the Standard Template
Library, spatial search data structures, and a Domain Specific Language to
specify non-linear operators on the particle set. This paper gives an overview
of Aboria's design, an example of use, and a performance benchmark.
</summary>
    <author>
      <name>Martin Robinson</name>
    </author>
    <author>
      <name>Maria Bruna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2017.07.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2017.07.002" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SoftwareX 6 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.08907v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08907v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06134v1</id>
    <updated>2017-05-17T13:10:32Z</updated>
    <published>2017-05-17T13:10:32Z</published>
    <title>Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia
  Programming Language</title>
    <summary>  We introduce two new packages, Nemo and Hecke, written in the Julia
programming language for computer algebra and number theory. We demonstrate
that high performance generic algorithms can be implemented in Julia, without
the need to resort to a low-level C implementation. For specialised algorithms,
we use Julia's efficient native C interface to wrap existing C/C++ libraries
such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke
and Nemo and discuss some algorithms that we have implemented to provide high
performance basic arithmetic.
</summary>
    <author>
      <name>Claus Fieker</name>
    </author>
    <author>
      <name>William Hart</name>
    </author>
    <author>
      <name>Tommy Hofmann</name>
    </author>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3087604.3087611</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3087604.3087611" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISSAC '17, Kaiserslautern, Germany, July 25-28, 2017, 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.06134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08569v2</id>
    <updated>2018-12-13T20:21:25Z</updated>
    <published>2017-06-26T19:27:58Z</published>
    <title>Parareal Algorithm Implementation and Simulation in Julia</title>
    <summary>  We present a full implementation of the parareal algorithm---an integration
technique to solve differential equations in parallel---in the Julia
programming language for a fully general, first-order, initial-value problem.
We provide a brief overview of Julia---a concurrent programming language for
scientific computing. Our implementation of the parareal algorithm accepts both
coarse and fine integrators as functional arguments. We use Euler's method and
another Runge-Kutta integration technique as the integrators in our
experiments. We also present a simulation of the algorithm for purposes of
pedagogy and as a tool for investigating the performance of the algorithm.
</summary>
    <author>
      <name>Tyler M. Masthay</name>
    </author>
    <author>
      <name>Saverio Perugini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, 2 listings</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08569v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08569v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03776v1</id>
    <updated>2017-07-12T15:51:35Z</updated>
    <published>2017-07-12T15:51:35Z</published>
    <title>Optimised finite difference computation from symbolic equations</title>
    <summary>  Domain-specific high-productivity environments are playing an increasingly
important role in scientific computing due to the levels of abstraction and
automation they provide. In this paper we introduce Devito, an open-source
domain-specific framework for solving partial differential equations from
symbolic problem definitions by the finite difference method. We highlight the
generation and automated execution of highly optimized stencil code from only a
few lines of high-level symbolic Python for a set of scientific equations,
before exploring the use of Devito operators in seismic inversion problems.
</summary>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Navjot Kukreja</name>
    </author>
    <author>
      <name>Fabio Luporini</name>
    </author>
    <author>
      <name>Mathias Louboutin</name>
    </author>
    <author>
      <name>Charles Yount</name>
    </author>
    <author>
      <name>Jan Hückelheim</name>
    </author>
    <author>
      <name>Gerard J. Gorman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Proceedings of the 16th Python in Science
  Conference (SciPy 2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04254v1</id>
    <updated>2017-07-13T13:51:26Z</updated>
    <published>2017-07-13T13:51:26Z</published>
    <title>Language-based Abstractions for Dynamical Systems</title>
    <summary>  Ordinary differential equations (ODEs) are the primary means to modelling
dynamical systems in many natural and engineering sciences. The number of
equations required to describe a system with high heterogeneity limits our
capability of effectively performing analyses. This has motivated a large body
of research, across many disciplines, into abstraction techniques that provide
smaller ODE systems while preserving the original dynamics in some appropriate
sense. In this paper we give an overview of a recently proposed
computer-science perspective to this problem, where ODE reduction is recast to
finding an appropriate equivalence relation over ODE variables, akin to
classical models of computation based on labelled transition systems.
</summary>
    <author>
      <name>Andrea Vandin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMT School for Advanced Studies Lucca</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.250.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.250.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings QAPL 2017, arXiv:1707.03668</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 250, 2017, pp. 15-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.04254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08711v1</id>
    <updated>2017-07-27T05:42:54Z</updated>
    <published>2017-07-27T05:42:54Z</published>
    <title>Example Setups of Navier-Stokes Equations with Control and Observation:
  Spatial Discretization and Representation via Linear-quadratic Matrix
  Coefficients</title>
    <summary>  We provide spatial discretizations of nonlinear incompressible Navier-Stokes
equations with inputs and outputs in the form of matrices ready to use in any
numerical linear algebra package. We discuss the assembling of the system
operators and the realization of boundary conditions and inputs and outputs. We
describe the two benchmark problems - the driven cavity and the cylinder wake -
and provide the corresponding data. The use of the data is illustrated by
numerous example setups. The test cases are provided as plain PYTHON or
OCTAVE/MATLAB script files for immediate replication.
</summary>
    <author>
      <name>Maximilian Behr</name>
    </author>
    <author>
      <name>Peter Benner</name>
    </author>
    <author>
      <name>Jan Heiland</name>
    </author>
    <link href="http://arxiv.org/abs/1707.08711v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08711v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01133v1</id>
    <updated>2017-09-28T14:36:55Z</updated>
    <published>2017-09-28T14:36:55Z</published>
    <title>HPC optimal parallel communication algorithm for the simulation of
  fractional-order systems</title>
    <summary>  A parallel numerical simulation algorithm is presented for fractional-order
systems involving Caputo-type derivatives, based on the Adams-Bashforth-Moulton
(ABM) predictor-corrector scheme. The parallel algorithm is implemented using
several different approaches: a pure MPI version, a combination of MPI with
OpenMP optimization and a memory saving speedup approach. All tests run on a
BlueGene/P cluster, and comparative improvement results for the running time
are provided. As an applied experiment, the solutions of a fractional-order
version of a system describing a forced series LCR circuit are numerically
computed, depicting cascades of period-doubling bifurcations which lead to the
onset of chaotic behavior.
</summary>
    <author>
      <name>Cosmin Bonchis</name>
    </author>
    <author>
      <name>Eva Kaslik</name>
    </author>
    <author>
      <name>Florin Rosu</name>
    </author>
    <link href="http://arxiv.org/abs/1710.01133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01839v1</id>
    <updated>2017-10-05T00:50:37Z</updated>
    <published>2017-10-05T00:50:37Z</published>
    <title>Tuning Technique for Multiple Precision Dense Matrix Multiplication
  using Prediction of Computational Time</title>
    <summary>  Although reliable long precision floating-point arithmetic libraries such as
QD and MPFR/GMP are necessary to solve ill-conditioned problems in numerical
simulation, long precision BLAS-level computation such as matrix multiplication
has not been fully optimized because tuning costs are very high compared to
IEEE float and double precision arithmetic. In this study, we develop a
technique to shorten this tuning time by using prediction of computational
times in several block sizes for the blocking algorithm, and then selecting the
fastest matrix multiplication method for tuning multiple precision dense real
matrix multiplication in various precisions, matrix sizes, and degrees of
parallelization.
</summary>
    <author>
      <name>Tomonori Kouya</name>
    </author>
    <link href="http://arxiv.org/abs/1710.01839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.10951v2</id>
    <updated>2018-06-18T23:32:35Z</updated>
    <published>2017-10-27T07:42:06Z</published>
    <title>SGDLibrary: A MATLAB library for stochastic gradient descent algorithms</title>
    <summary>  We consider the problem of finding the minimizer of a function $f:
\mathbb{R}^d \rightarrow \mathbb{R}$ of the finite-sum form $\min f(w) =
1/n\sum_{i}^n f_i(w)$. This problem has been studied intensively in recent
years in the field of machine learning (ML). One promising approach for
large-scale data is to use a stochastic optimization algorithm to solve the
problem. SGDLibrary is a readable, flexible and extensible pure-MATLAB library
of a collection of stochastic optimization algorithms. The purpose of the
library is to provide researchers and implementers a comprehensive evaluation
environment for the use of these algorithms on various ML problems.
</summary>
    <author>
      <name>Hiroyuki Kasai</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research, vol.18, no.215, pp.1-5, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1710.10951v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.10951v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.07438v1</id>
    <updated>2017-12-20T12:13:44Z</updated>
    <published>2017-12-20T12:13:44Z</published>
    <title>CameraTransform: a Scientific Python Package for Perspective Camera
  Corrections</title>
    <summary>  Scientific applications often require an exact reconstruction of object
positions and distances from digital images. Therefore, the images need to be
corrected for perspective distortions. We present \textit{CameraTransform}, a
python package that performs a perspective image correction whereby the height,
tilt/roll angle and heading of the camera can be automatically obtained from
the images if additional information such as GPS coordinates or object sizes
are provided. We present examples of images of penguin colonies that are
recorded with stationary cameras and from a helicopter.
</summary>
    <author>
      <name>Richard Gerum</name>
    </author>
    <author>
      <name>Sebastian Richter</name>
    </author>
    <author>
      <name>Alexander Winterl</name>
    </author>
    <author>
      <name>Ben Fabry</name>
    </author>
    <author>
      <name>Daniel Zitterbart</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2019.100333</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2019.100333" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.07438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.07438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.01928v2</id>
    <updated>2020-03-02T21:51:20Z</updated>
    <published>2018-01-05T21:58:01Z</published>
    <title>Tensor Train decomposition on TensorFlow (T3F)</title>
    <summary>  Tensor Train decomposition is used across many branches of machine learning.
We present T3F -- a library for Tensor Train decomposition based on TensorFlow.
T3F supports GPU execution, batch processing, automatic differentiation, and
versatile functionality for the Riemannian optimization framework, which takes
into account the underlying manifold structure to construct efficient
optimization methods. The library makes it easier to implement machine learning
papers that rely on the Tensor Train decomposition. T3F includes documentation,
examples and 94% test coverage.
</summary>
    <author>
      <name>Alexander Novikov</name>
    </author>
    <author>
      <name>Pavel Izmailov</name>
    </author>
    <author>
      <name>Valentin Khrulkov</name>
    </author>
    <author>
      <name>Michael Figurnov</name>
    </author>
    <author>
      <name>Ivan Oseledets</name>
    </author>
    <link href="http://arxiv.org/abs/1801.01928v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.01928v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.02247v1</id>
    <updated>2018-02-06T22:13:26Z</updated>
    <published>2018-02-06T22:13:26Z</published>
    <title>Automatic differentiation of ODE integration</title>
    <summary>  We discuss the calculation of the derivatives of ODE systems with the
automatic differentiation tool ADiMat. Using the well-known Lotka-Volterra
equations and the ode23 ODE solver as examples we show the analytic derivatives
and detail how to differentiate a top-level function that calls ode23 somewhere
with ADiMat. This involves the manual construction of substitution function to
propagate the derivatives in forward and reverse mode. We also show how to use
the reverse mode code to evaluate the Hessian in forward-over-reverse mode.
</summary>
    <author>
      <name>Johannes Willkomm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figure, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.02247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.02247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.07832v1</id>
    <updated>2018-02-21T22:11:58Z</updated>
    <published>2018-02-21T22:11:58Z</published>
    <title>Comparative study of finite element methods using the Time-Accuracy-Size
  (TAS) spectrum analysis</title>
    <summary>  We present a performance analysis appropriate for comparing algorithms using
different numerical discretizations. By taking into account the total
time-to-solution, numerical accuracy with respect to an error norm, and the
computation rate, a cost-benefit analysis can be performed to determine which
algorithm and discretization are particularly suited for an application. This
work extends the performance spectrum model in Chang et. al. 2017 for
interpretation of hardware and algorithmic tradeoffs in numerical PDE
simulation. As a proof-of-concept, popular finite element software packages are
used to illustrate this analysis for Poisson's equation.
</summary>
    <author>
      <name>Justin Chang</name>
    </author>
    <author>
      <name>Maurice S. Fabien</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Richard T. Mills</name>
    </author>
    <link href="http://arxiv.org/abs/1802.07832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.07832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05, 65Y20, 68N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.03807v2</id>
    <updated>2018-06-17T19:57:36Z</updated>
    <published>2018-04-11T04:41:49Z</published>
    <title>A Blackbox Polynomial System Solver on Parallel Shared Memory Computers</title>
    <summary>  A numerical irreducible decomposition for a polynomial system provides
representations for the irreducible factors of all positive dimensional
solution sets of the system, separated from its isolated solutions. Homotopy
continuation methods are applied to compute a numerical irreducible
decomposition. Load balancing and pipelining are techniques in a parallel
implementation on a computer with multicore processors. The application of the
parallel algorithms is illustrated on solving the cyclic $n$-roots problems, in
particular for $n = 8, 9$, and~12.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the proceedings of CASC 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.03807v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.03807v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.02136v1</id>
    <updated>2018-06-06T11:54:34Z</updated>
    <published>2018-06-06T11:54:34Z</published>
    <title>Efficient Differentiable Programming in a Functional Array-Processing
  Language</title>
    <summary>  We present a system for the automatic differentiation of a higher-order
functional array-processing language. The core functional language underlying
this system simultaneously supports both source-to-source automatic
differentiation and global optimizations such as loop transformations. Thanks
to this feature, we demonstrate how for some real-world machine learning and
computer vision benchmarks, the system outperforms the state-of-the-art
automatic differentiation tools.
</summary>
    <author>
      <name>Amir Shaikhha</name>
    </author>
    <author>
      <name>Andrew Fitzgibbon</name>
    </author>
    <author>
      <name>Dimitrios Vytiniotis</name>
    </author>
    <author>
      <name>Simon Peyton Jones</name>
    </author>
    <author>
      <name>Christoph Koch</name>
    </author>
    <link href="http://arxiv.org/abs/1806.02136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.02136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.09545v1</id>
    <updated>2018-06-25T15:58:53Z</updated>
    <published>2018-06-25T15:58:53Z</published>
    <title>Function space bases in the dune-functions module</title>
    <summary>  The dune-functions Dune module provides interfaces for functions and function
space bases. It forms one abstraction level above grids, shape functions, and
linear algebra, and provides infrastructure for full discretization frameworks
like dune-pdelab and dune-fem. This document describes the function space bases
provided by dune-functions. These are based on an abstract description of bases
for product spaces as trees of simpler bases. From this description, many
different numberings of degrees of freedom by multi-indices can be derived in a
natural way. We describe the abstract concepts, document the programmer
interface, and give a complete example program that solves the stationary
Stokes equation using Taylor-Hood elements.
</summary>
    <author>
      <name>Christian Engwer</name>
    </author>
    <author>
      <name>Carsten Gräser</name>
    </author>
    <author>
      <name>Steffen Müthing</name>
    </author>
    <author>
      <name>Oliver Sander</name>
    </author>
    <link href="http://arxiv.org/abs/1806.09545v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.09545v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.10584v3</id>
    <updated>2018-08-01T18:50:36Z</updated>
    <published>2018-06-27T17:31:48Z</published>
    <title>Implementation of a Near-Optimal Complex Root Clustering Algorithm</title>
    <summary>  We describe Ccluster, a software for computing natural $\epsilon$-clusters of
complex roots in a given box of the complex plane. This algorithm from Becker
et al.~(2016) is near-optimal when applied to the benchmark problem of
isolating all complex roots of an integer polynomial. It is one of the first
implementations of a near-optimal algorithm for complex roots. We describe some
low level techniques for speeding up the algorithm. Its performance is compared
with the well-known MPSolve library and Maple.
</summary>
    <author>
      <name>Rémi Imbach</name>
    </author>
    <author>
      <name>Victor Y. Pan</name>
    </author>
    <author>
      <name>Chee Yap</name>
    </author>
    <link href="http://arxiv.org/abs/1806.10584v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.10584v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.00532v1</id>
    <updated>2018-07-30T18:09:13Z</updated>
    <published>2018-07-30T18:09:13Z</published>
    <title>GuiTeNet: A graphical user interface for tensor networks</title>
    <summary>  We introduce a graphical user interface for constructing arbitrary tensor
networks and specifying common operations like contractions or splitting,
denoted GuiTeNet. Tensors are represented as nodes with attached legs,
corresponding to the ordered dimensions of the tensor. GuiTeNet visualizes the
current network, and instantly generates Python/NumPy source code for the
hitherto sequence of user actions. Support for additional programming languages
is planned for the future. We discuss the elementary operations on tensor
networks used by GuiTeNet, together with high-level optimization strategies.
The software runs directly in web browsers and is available online at
http://guitenet.org.
</summary>
    <author>
      <name>Lisa Sahlmann</name>
    </author>
    <author>
      <name>Christian B. Mendl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.304</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.304" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Open Res. Softw. 8(1), 29 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1808.00532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.00532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.04033v1</id>
    <updated>2018-10-09T14:37:52Z</updated>
    <published>2018-10-09T14:37:52Z</published>
    <title>Coloured and task-based stencil codes</title>
    <summary>  Simple stencil codes are and remain an important building block in scientific
computing. On shared memory nodes, they are traditionally parallelised through
colouring or (recursive) tiling. New OpenMP versions alternatively allow users
to specify data dependencies explicitly and to outsource the decision how to
distribute the work to the runtime system. We evaluate traditional
multithreading strategies on both Broadwell and KNL, study the arising
assignment of tasks to threads and, from there, derive two efficient ways to
parallelise stencil codes on regular Cartesian grids that fuse colouring and
task-based approaches.
</summary>
    <author>
      <name>Benjamin Hazelwood</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.04033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.04033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.05704v1</id>
    <updated>2018-11-14T09:56:30Z</updated>
    <published>2018-11-14T09:56:30Z</published>
    <title>AMGCL: an Efficient, Flexible, and Extensible Algebraic Multigrid
  Implementation</title>
    <summary>  The paper presents AMGCL -- an opensource C++ library implementing the
algebraic multigrid method (AMG) for solution of large sparse linear systems of
equations, usually arising from discretization of partial differential
equations on an unstructured grid. The library supports both shared and
distributed memory computation, allows to utilize modern massively parallel
processors via OpenMP, OpenCL, or CUDA technologies, has minimal dependencies,
and is easily extensible. The design principles behind AMGCL are discussed and
it is shown that the code performance is on par with alternative
implementations.
</summary>
    <author>
      <name>Denis Demidov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S1995080219050056</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S1995080219050056" rel="related"/>
    <link href="http://arxiv.org/abs/1811.05704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.05704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.02423v1</id>
    <updated>2019-03-04T19:44:24Z</updated>
    <published>2019-03-04T19:44:24Z</published>
    <title>Performance Analysis of Effective Symbolic Methods for Solving Band
  Matrix SLAEs</title>
    <summary>  This paper presents an experimental performance study of implementations of
three symbolic algorithms for solving band matrix systems of linear algebraic
equations with heptadiagonal, pentadiagonal, and tridiagonal coefficient
matrices. The only assumption on the coefficient matrix in order for the
algorithms to be stable is nonsingularity. These algorithms are implemented
using the GiNaC library of C++ and the SymPy library of Python, considering
five different data storing classes. Performance analysis of the
implementations is done using the high-performance computing (HPC) platforms
"HybriLIT" and "Avitohol". The experimental setup and the results from the
conducted computations on the individual computer systems are presented and
discussed. An analysis of the three algorithms is performed.
</summary>
    <author>
      <name>Milena Veneva</name>
    </author>
    <author>
      <name>Alexander Ayriyan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/epjconf/201921405004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/epjconf/201921405004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 9 tables, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.02423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.02423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10441v2</id>
    <updated>2019-05-30T12:12:54Z</updated>
    <published>2019-03-22T17:38:23Z</published>
    <title>pyLLE: a Fast and User Friendly Lugiato-Lefever Equation Solver</title>
    <summary>  We present the development of pyLLE, a freely accessible and cross-platform
Lugiato-Lefever equation solver programmed in Python and Julia and optimized
for the simulation of microresonator frequency combs. Examples illustrating its
operation, the simplicity of use, and performance against other programming
language are presented. The documentation of the software can be found at
https://gregmoille.github.io/pyLLE/
</summary>
    <author>
      <name>Gregory Moille</name>
    </author>
    <author>
      <name>Qing Li</name>
    </author>
    <author>
      <name>Xiyuan Lu</name>
    </author>
    <author>
      <name>Kartik Srinivasan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6028/jres.124.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6028/jres.124.012" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Research of National Institute of Standards and
  Technology, Volume 124, Article No. 124012 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1903.10441v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10441v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12380v2</id>
    <updated>2019-05-27T08:33:00Z</updated>
    <published>2019-04-28T20:19:22Z</published>
    <title>Softmax Optimizations for Intel Xeon Processor-based Platforms</title>
    <summary>  Softmax is popular normalization method used in machine learning. Deep
learning solutions like Transformer or BERT use the softmax function
intensively, so it is worthwhile to optimize its performance. This article
presents our methodology of optimization and its results applied to softmax. By
presenting this methodology, we hope to increase an interest in deep learning
optimizations for CPUs. We believe that the optimization process presented here
could be transferred to other deep learning frameworks such as TensorFlow or
PyTorch.
</summary>
    <author>
      <name>Jacek Czaja</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intel Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Michal Gallus</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intel Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Tomasz Patejko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intel Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Jian Tang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Baidu</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1904.12380v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12380v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01063v2</id>
    <updated>2020-05-16T23:23:03Z</updated>
    <published>2019-07-01T20:36:16Z</published>
    <title>GPU-based Parallel Computation Support for Stan</title>
    <summary>  This paper details an extensible OpenCL framework that allows Stan to utilize
heterogeneous compute devices. It includes GPU-optimized routines for the
Cholesky decomposition, its derivative, other matrix algebra primitives and
some commonly used likelihoods, with more additions planned for the near
future. Stan users can now benefit from large speedups offered by GPUs with
little effort and without changes to their existing Stan code. We demonstrate
the practical utility of our work with two examples - logistic regression and
Gaussian Process regression.
</summary>
    <author>
      <name>Rok Češnovar</name>
    </author>
    <author>
      <name>Steve Bronder</name>
    </author>
    <author>
      <name>Davor Sluga</name>
    </author>
    <author>
      <name>Jure Demšar</name>
    </author>
    <author>
      <name>Tadej Ciglarič</name>
    </author>
    <author>
      <name>Sean Talts</name>
    </author>
    <author>
      <name>Erik Štrumbelj</name>
    </author>
    <link href="http://arxiv.org/abs/1907.01063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.02597v1</id>
    <updated>2019-07-03T08:16:49Z</updated>
    <published>2019-07-03T08:16:49Z</published>
    <title>Multi-dimensional interpolations in C++</title>
    <summary>  A C++ software design is presented that can be used to interpolate data in
any number of dimensions. The design is based on a combination of templates of
functional collections of elements and so-called type lists. The design allows
for different search methodologies and interpolation techniques in each
dimension. It is also possible to expand and reduce the number of dimensions,
to interpolate composite data types and to produce on-the-fly additional values
such as derivatives of the interpolating function.
</summary>
    <author>
      <name>Maarten de Jong</name>
    </author>
    <link href="http://arxiv.org/abs/1907.02597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.02597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.09301v1</id>
    <updated>2019-08-25T11:21:56Z</updated>
    <published>2019-08-25T11:21:56Z</published>
    <title>OpenMP parallelization of multiple precision Taylor series method</title>
    <summary>  OpenMP parallelization of multiple precision Taylor series method is
proposed. A very good parallel performance scalability and parallel efficiency
inside one computation node of a CPU-cluster is observed. We explain the
details of the parallelization on the classical example of the Lorentz
equations. The same approach can be applied straightforwardly to a large class
of chaotic dynamical systems.
</summary>
    <author>
      <name>S. Dimova</name>
    </author>
    <author>
      <name>I. Hristov</name>
    </author>
    <author>
      <name>R. Hristova</name>
    </author>
    <author>
      <name>I. Puzynin</name>
    </author>
    <author>
      <name>T. Puzynina</name>
    </author>
    <author>
      <name>Z. Sharipov</name>
    </author>
    <author>
      <name>N. Shegunov</name>
    </author>
    <author>
      <name>Z. Tukhliev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.13251v2</id>
    <updated>2020-01-27T14:00:11Z</updated>
    <published>2019-10-23T18:00:10Z</published>
    <title>RationalizeRoots: Software Package for the Rationalization of Square
  Roots</title>
    <summary>  The computation of Feynman integrals often involves square roots. One way to
obtain a solution in terms of multiple polylogarithms is to rationalize these
square roots by a suitable variable change. We present a program that can be
used to find such transformations. After an introduction to the theoretical
background, we explain in detail how to use the program in practice.
</summary>
    <author>
      <name>Marco Besier</name>
    </author>
    <author>
      <name>Pascal Wasser</name>
    </author>
    <author>
      <name>Stefan Weinzierl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2020.107197</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2020.107197" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 4 ancillary files, v2: version to be published</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.13251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00488v1</id>
    <updated>2019-12-01T19:39:16Z</updated>
    <published>2019-12-01T19:39:16Z</published>
    <title>Replicated Computational Results (RCR) Report for "Code Generation for
  Generally Mapped Finite Elements"</title>
    <summary>  "Code Generation for Generally Mapped Finite Elements" includes performance
results for the finite element methods discussed in that manuscript. The
authors provided a Zenodo archive with the Firedrake components and
dependencies used, as well as the scripts that generated the results. The
software was installed on two similar platforms; then, new results were
gathered and compared to the original results. After completing this process,
the results have been deemed replicable by the reviewer.
</summary>
    <author>
      <name>Neil Lindquist</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3360984</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3360984" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures. Submitted to ACM Transactions on Mathematical
  Software</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software (TOMS): Volume 45 Issue
  4, December 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.00488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="10002944.10011123.10011676, 10002950.10003705.10011686,&#10;  10002950.10003705.10003707" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.01640v2</id>
    <updated>2020-03-25T22:20:07Z</updated>
    <published>2019-12-03T19:25:20Z</published>
    <title>bertha: Project Skeleton for Scientific Software</title>
    <summary>  Science depends heavily on reliable and easy-to-use software packages, such
as mathematical libraries or data analysis tools. Developing such packages
requires a lot of effort, which is too often avoided due to the lack of funding
or recognition. In order to reduce the efforts required to create sustainable
software packages, we present a project skeleton that ensures the best software
engineering practices from the start of a project, or serves as reference for
existing projects.
</summary>
    <author>
      <name>Michael Riesch</name>
    </author>
    <author>
      <name>Tien Dat Nguyen</name>
    </author>
    <author>
      <name>Christian Jirauschek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0230557</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0230557" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Source code available at https://gitlab.com/cph-tum/bertha</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS One. 2020; 15(3): e0230557</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.01640v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.01640v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03099v1</id>
    <updated>2020-03-06T09:27:10Z</updated>
    <published>2020-03-06T09:27:10Z</published>
    <title>COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for
  Social Inquiry</title>
    <summary>  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into
complex data/systems, designed to increase non-expert access to the tools of
computational social science (i.e., cluster analysis, artificial intelligence,
data visualization, data forecasting, and scenario simulation). In particular,
COMPLEX-IT aids social inquiry though a heavy emphasis on learning about the
complex data/system under study, which it does by (a) identifying and
forecasting major and minor clusters/trends; (b) visualizing their complex
causality; and (c) simulating scenarios for potential interventions. COMPLEX-IT
is accessible through the web or can be run locally and is powered by R and the
Shiny web framework.
</summary>
    <author>
      <name>Corey Schimpf</name>
    </author>
    <author>
      <name>Brian Castellani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.298</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.298" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Open Research Software (2020) 8:25</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.03099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.05825v2</id>
    <updated>2020-07-02T15:20:02Z</updated>
    <published>2020-03-12T14:50:53Z</published>
    <title>Parametric model order reduction using pyMOR</title>
    <summary>  pyMOR is a free software library for model order reduction that includes both
reduced basis and system-theoretic methods. All methods are implemented in
terms of abstract vector and operator interfaces, which allows direct
integration of pyMOR's algorithms with a wide array of external PDE solvers. In
this contribution, we give a brief overview of the available methods and
experimentally compare them for the parametric instationary thermal-block
benchmark defined in arXiv:2003.00846.
</summary>
    <author>
      <name>Petar Mlinarić</name>
    </author>
    <author>
      <name>Stephan Rave</name>
    </author>
    <author>
      <name>Jens Saak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-72983-7_17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-72983-7_17" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.05825v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.05825v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.06316v2</id>
    <updated>2020-03-19T15:06:22Z</updated>
    <published>2020-03-13T14:23:22Z</published>
    <title>An R Package for generating covariance matrices for maximum-entropy
  sampling from precipitation chemistry data</title>
    <summary>  We present an open-source R package (MESgenCov v 0.1.0) for temporally
fitting multivariate precipitation chemistry data and extracting a covariance
matrix for use in the MESP (maximum-entropy sampling problem). We provide
multiple functionalities for modeling and model assessment. The package is
tightly coupled with NADP/NTN (National Atmospheric Deposition Program /
National Trends Network) data from their set of 379 monitoring sites,
1978--present. The user specifies the sites, chemicals, and time period
desired, fits an appropriate user-specified univariate model for each site and
chemical selected, and the package produces a covariance matrix for use by MESP
algorithms.
</summary>
    <author>
      <name>Hessa Al-Thani</name>
    </author>
    <author>
      <name>Jon Lee</name>
    </author>
    <link href="http://arxiv.org/abs/2003.06316v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06316v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C27, 62M30, 62M10, 94A17" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.12029v1</id>
    <updated>2020-03-26T16:50:43Z</updated>
    <published>2020-03-26T16:50:43Z</published>
    <title>FlexRiLoG -- A SageMath Package for Motions of Graphs</title>
    <summary>  In this paper we present the SageMath package FlexRiLoG (short for flexible
and rigid labelings of graphs). Based on recent results the software generates
motions of graphs using special edge colorings. The package computes and
illustrates the colorings and the motions. We present the structure and usage
of the package.
</summary>
    <author>
      <name>Georg Grasegger</name>
    </author>
    <author>
      <name>Jan Legerský</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-52200-1_44</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-52200-1_44" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Bigatti A., Carette J., Davenport J., Joswig M., de Wolff T.
  (eds) Mathematical Software - ICMS 2020. Lecture Notes in Computer Science,
  vol. 12097</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.12029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.12029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="52C25, 68R10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.05261v1</id>
    <updated>2020-05-11T17:05:30Z</updated>
    <published>2020-05-11T17:05:30Z</published>
    <title>A modular extension for a computer algebra system</title>
    <summary>  Computer algebra systems are complex software systems that cover a wide range
of scientific and practical problems. However, the absolute coverage cannot be
achieved. Often, it is required to create a user extension for an existing
computer algebra system. In this case, the extensibility of the system should
be taken into account. In this paper, we consider a technology for extending
the SymPy computer algebra system with a low-level module that implements a
random number generator.
</summary>
    <author>
      <name>Migran N. Gevorkyan</name>
    </author>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <author>
      <name>Leonid A. Sevastianov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S036176882002005X</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S036176882002005X" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English; in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.05261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.05261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.05041v2</id>
    <updated>2020-11-27T19:58:28Z</updated>
    <published>2020-07-09T19:27:10Z</published>
    <title>Blends in Maple</title>
    <summary>  A blend of two Taylor series for the same smooth real- or complex-valued
function of a single variable can be useful for approximation. We use an
explicit formula for a two-point Hermite interpolational polynomial to
construct such blends. We show a robust Maple implementation that can stably
and efficiently evaluate blends using linear-cost Horner form, evaluate their
derivatives to arbitrary order at the same time, or integrate a blend exactly.
The implementation is suited for use with evalhf. We provide a top-level user
interface and efficient module exports for programmatic use. This work was
presented at the Maple Conference 2020. See www.maplesoft.com/mapleconference
</summary>
    <author>
      <name>Robert M. Corless</name>
    </author>
    <author>
      <name>Erik Postma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.05041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.05041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D05, 65D32, 68W30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.1; G.1.2; G.1.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.05094v1</id>
    <updated>2020-07-09T22:11:48Z</updated>
    <published>2020-07-09T22:11:48Z</published>
    <title>ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians</title>
    <summary>  The computation of first and second-order derivatives is a staple in many
computing applications, ranging from machine learning to scientific computing.
We propose an algorithm to automatically differentiate algorithms written in a
subset of C99 code and its efficient implementation as a Python script. We
demonstrate that our algorithm enables automatic, reliable, and efficient
differentiation of common algorithms used in physical simulation and geometry
processing.
</summary>
    <author>
      <name>Deshana Desai</name>
    </author>
    <author>
      <name>Etai Shuchatowitz</name>
    </author>
    <author>
      <name>Zhongshi Jiang</name>
    </author>
    <author>
      <name>Teseo Schneider</name>
    </author>
    <author>
      <name>Daniele Panozzo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2021.100901</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2021.100901" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SoftwareX, Volume 17, 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.05094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.05094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.13152v2</id>
    <updated>2020-07-29T13:55:07Z</updated>
    <published>2020-07-26T15:43:10Z</published>
    <title>multivar_horner: a python package for computing Horner factorisations of
  multivariate polynomials</title>
    <summary>  Many applications in the sciences require numerically stable and
computationally efficient evaluation of multivariate polynomials. Finding
beneficial representations of polynomials, such as Horner factorisations, is
therefore crucial. multivar_horner, the python package presented here, is the
first open source software for computing multivariate Horner factorisations.
This work briefly outlines the functionality of the package and puts it into
reference to previous work in the field. Benchmarks additionally prove the
advantages of the implementation and Horner factorisations in general.
</summary>
    <author>
      <name>Jannik Michelfeit</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technische Universität Dresden</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, submitted to "The Journal of Open Source
  Software"</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.13152v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.13152v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.06607v1</id>
    <updated>2020-12-11T19:23:55Z</updated>
    <published>2020-12-11T19:23:55Z</published>
    <title>Parallel Software to Offset the Cost of Higher Precision</title>
    <summary>  Hardware double precision is often insufficient to solve large scientific
problems accurately. Computing in higher precision defined by software causes
significant computational overhead. The application of parallel algorithms
compensates for this overhead. Newton's method to develop power series
expansions of algebraic space curves is the use case for this application.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper corresponds to a talk given by the author at the HILT 2020
  Workshop on Safe Languages and Technologies for Structured and Efficient
  Parallel and Distributed/Cloud Computing, 16-17 November 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.06607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.06607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.11003v2</id>
    <updated>2024-08-12T08:43:35Z</updated>
    <published>2021-01-26T10:07:33Z</published>
    <title>FDApy: a Python package for functional data</title>
    <summary>  We introduce FDApy, an open-source Python package for the analysis of
functional data. The package provides tools for the representation of
(multivariate) functional data defined on different dimensional domains and for
functional data that is irregularly sampled. Additionally, dimension reduction
techniques are implemented for multivariate and/or multidimensional functional
data that are regularly or irregularly sampled. A toolbox for generating
functional datasets is also provided. The documentation includes installation
and usage instructions, examples on simulated and real datasets and a complete
description of the API. FDApy is released under the MIT license. The code and
documentation are available at https://github.com/StevenGolovkine/FDApy.
</summary>
    <author>
      <name>Steven Golovkine</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/joss.07526</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/joss.07526" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.11003v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.11003v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62R10 (Primary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.09480v2</id>
    <updated>2021-10-26T07:54:41Z</updated>
    <published>2021-03-17T07:25:24Z</published>
    <title>Hessian Chain Bracketing</title>
    <summary>  Second derivatives of mathematical models for real-world phenomena are
fundamental ingredients of a wide range of numerical simulation methods
including parameter sensitivity analysis, uncertainty quantification, nonlinear
optimization and model calibration. The evaluation of such Hessians often
dominates the overall computational effort. The combinatorial {\sc Hessian
Accumulation} problem aiming to minimize the number of floating-point
operations required for the computation of a Hessian turns out to be
NP-complete. We propose a dynamic programming formulation for the solution of
{\sc Hessian Accumulation} over a sub-search space. This approach yields
improvements by factors of ten and higher over the state of the art based on
second-order tangent and adjoint algorithmic differentiation.
</summary>
    <author>
      <name>Uwe Naumann</name>
    </author>
    <author>
      <name>Shubhaditya Burela</name>
    </author>
    <link href="http://arxiv.org/abs/2103.09480v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.09480v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.04771v1</id>
    <updated>2021-04-10T13:56:39Z</updated>
    <published>2021-04-10T13:56:39Z</published>
    <title>MIPROT: A Medical Image Processing Toolbox for MATLAB</title>
    <summary>  This paper presents a Matlab toolbox to perform basic image processing and
visualization tasks, particularly designed for medical image processing. The
functionalities available are similar to basic functions found in other
non-Matlab widely used libraries such as the Insight Toolkit (ITK). The toolbox
is entirely written in native Matlab code, but is fast and flexible.
  Main use cases for the toolbox are illustrated here, including image
input/output, pre-processing, filtering, image registration and visualisation.
Both the code and sample data are made publicly available and open source.
</summary>
    <author>
      <name>Alberto Gomez</name>
    </author>
    <link href="http://arxiv.org/abs/2104.04771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.04771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.08012v1</id>
    <updated>2021-04-16T10:14:54Z</updated>
    <published>2021-04-16T10:14:54Z</published>
    <title>Code generation for productive portable scalable finite element
  simulation in Firedrake</title>
    <summary>  Creating scalable, high performance PDE-based simulations requires a suitable
combination of discretizations, differential operators, preconditioners and
solvers. The required combination changes with the application and with the
available hardware, yet software development time is a severely limited
resource for most scientists and engineers. Here we demonstrate that generating
simulation code from a high-level Python interface provides an effective
mechanism for creating high performance simulations from very few lines of user
code. We demonstrate that moving from one supercomputer to another can require
significant algorithmic changes to achieve scalable performance, but that the
code generation approach enables these algorithmic changes to be achieved with
minimal development effort.
</summary>
    <author>
      <name>Jack D. Betteridge</name>
    </author>
    <author>
      <name>Patrick E. Farrell</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <link href="http://arxiv.org/abs/2104.08012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.08012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.13921v2</id>
    <updated>2021-07-07T18:50:43Z</updated>
    <published>2021-05-27T10:42:09Z</published>
    <title>TensorFlow RiemOpt: a library for optimization on Riemannian manifolds</title>
    <summary>  The adoption of neural networks and deep learning in non-Euclidean domains
has been hindered until recently by the lack of scalable and efficient learning
frameworks. Existing toolboxes in this space were mainly motivated by research
and education use cases, whereas practical aspects, such as deploying and
maintaining machine learning models, were often overlooked.
  We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python
library for optimization on Riemannian manifolds in TensorFlow. The library is
designed with the aim for a seamless integration with the TensorFlow ecosystem,
targeting not only research, but also streamlining production machine learning
pipelines.
</summary>
    <author>
      <name>Oleg Smirnov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The library code is available at
  https://github.com/master/tensorflow-riemopt</arxiv:comment>
    <link href="http://arxiv.org/abs/2105.13921v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.13921v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.15066v1</id>
    <updated>2021-06-29T02:57:34Z</updated>
    <published>2021-06-29T02:57:34Z</published>
    <title>Web-based Structural Identifiability Analyzer</title>
    <summary>  Parameter identifiability describes whether, for a given differential model,
one can determine parameter values from model equations. Knowing global or
local identifiability properties allows construction of better practical
experiments to identify parameters from experimental data. In this work, we
present a web-based software tool that allows to answer specific
identifiability queries. Concretely, our toolbox can determine identifiability
of individual parameters of the model and also provide all functions of
parameters that are identifiable (also called identifiable combinations) from
single or multiple experiments. The program is freely available at
https://maple.cloud/app/6509768948056064.
</summary>
    <author>
      <name>Ilia Ilmer</name>
    </author>
    <author>
      <name>Alexey Ovchinnikov</name>
    </author>
    <author>
      <name>Gleb Pogudin</name>
    </author>
    <link href="http://arxiv.org/abs/2106.15066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.15066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.02054v1</id>
    <updated>2021-08-04T13:32:17Z</updated>
    <published>2021-08-04T13:32:17Z</published>
    <title>Partial Reuse AMG Setup Cost Amortization Strategy for the Solution of
  Non-Steady State Problems</title>
    <summary>  The partial reuse algebraic multigrid (AMG) setup cost amortization strategy
is presented for the solution of non-steady state problems. The transfer
operators are reused from the previous time steps, and the system matrices and
the smoother operators are rebuilt on each of the AMG hierarchy levels. It is
shown on the example of modelling a two-fluid dam break scenario that the
strategy may decrease the AMG preconditioner setup cost by 40% to 200%. The
total compute time is decreased by up to 20%, but the specific outcome depends
on the fraction of time that the setup step initially takes.
</summary>
    <author>
      <name>D. E. Demidov</name>
    </author>
    <link href="http://arxiv.org/abs/2108.02054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.02054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.04791v1</id>
    <updated>2021-08-08T17:26:14Z</updated>
    <published>2021-08-08T17:26:14Z</published>
    <title>Improving MATLAB's isprime performance without arbitrary-precision
  arithmetic</title>
    <summary>  MATLAB is a numerical computing platform used by scientists, engineers,
mathematicians, and students which contains many mathematical functions,
including isprime. MATLAB's isprime function determines which elements of an
input array are prime. This research details modular arithmetic techniques, the
Miller-Rabin primality test, vectorized operations, and division-minimizing
strategies which harness the power of MATLAB's capabilities to improve
isprime's performance. The results are typically 5 to 10 times faster for small
integers and many hundreds of times faster for large integers and long arrays.
</summary>
    <author>
      <name>Travis Near</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 tables, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.04791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.04791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.08845v1</id>
    <updated>2021-08-19T05:25:47Z</updated>
    <published>2021-08-19T05:25:47Z</published>
    <title>PyParSVD: A streaming, distributed and randomized
  singular-value-decomposition library</title>
    <summary>  We introduce PyParSVD\footnote{https://github.com/Romit-Maulik/PyParSVD}, a
Python library that implements a streaming, distributed and randomized
algorithm for the singular value decomposition. To demonstrate its
effectiveness, we extract coherent structures from scientific data. Futhermore,
we show weak scaling assessments on up to 256 nodes of the Theta machine at
Argonne Leadership Computing Facility, demonstrating potential for large-scale
data analyses of practical data sets.
</summary>
    <author>
      <name>Romit Maulik</name>
    </author>
    <author>
      <name>Gianmarco Mengaldo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2103.09389</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.08845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.08845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.08392v1</id>
    <updated>2021-09-17T07:58:43Z</updated>
    <published>2021-09-17T07:58:43Z</published>
    <title>Arbitrary-precision computation of the gamma function</title>
    <summary>  We discuss the best methods available for computing the gamma function
$\Gamma(z)$ in arbitrary-precision arithmetic with rigorous error bounds. We
address different cases: rational, algebraic, real or complex arguments; large
or small arguments; low or high precision; with or without precomputation. The
methods also cover the log-gamma function $\log \Gamma(z)$, the digamma
function $\psi(z)$, and derivatives $\Gamma^{(n)}(z)$ and $\psi^{(n)}(z)$.
Besides attempting to summarize the existing state of the art, we present some
new formulas, estimates, bounds and algorithmic improvements and discuss
implementation results.
</summary>
    <author>
      <name>Fredrik Johansson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LFANT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/2109.08392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.08392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.00186v1</id>
    <updated>2021-10-01T03:07:26Z</updated>
    <published>2021-10-01T03:07:26Z</published>
    <title>An Attempt to Generate Code for Symmetric Tensor Computations</title>
    <summary>  This document describes an attempt to develop a compiler-based approach for
computations with symmetric tensors. Given a computation and the symmetries of
its input tensors, we derive formulas for random access under a storage scheme
that eliminates redundancies; construct intermediate representations to
describe the loop structure; and translate this information, using the taco
tensor algebra compiler, into code. While we achieve a framework for reasoning
about a fairly general class of symmetric computations, the resulting code is
not performant when the symmetries are misaligned.
</summary>
    <author>
      <name>Jessica Shi</name>
    </author>
    <author>
      <name>Stephen Chou</name>
    </author>
    <author>
      <name>Fredrik Kjolstad</name>
    </author>
    <author>
      <name>Saman Amarasinghe</name>
    </author>
    <link href="http://arxiv.org/abs/2110.00186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.00186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.10153v2</id>
    <updated>2021-10-25T09:40:02Z</updated>
    <published>2021-10-19T10:28:35Z</published>
    <title>The Creation of Puffin, the Automatic Uncertainty Compiler</title>
    <summary>  An uncertainty compiler is a tool that automatically translates original
computer source code lacking explicit uncertainty analysis into code containing
appropriate uncertainty representations and uncertainty propagation algorithms.
We have developed an prototype uncertainty compiler along with an associated
object-oriented uncertainty language in the form of a stand-alone Python
library. It handles the specifications of input uncertainties and inserts calls
to intrusive uncertainty quantification algorithms in the library. The
uncertainty compiler can apply intrusive uncertainty propagation methods to
codes or parts of codes and therefore more comprehensively and flexibly address
both epistemic and aleatory uncertainties.
</summary>
    <author>
      <name>Nicholas Gray</name>
    </author>
    <author>
      <name>Marco De Angelis</name>
    </author>
    <author>
      <name>Scott Ferson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijar.2023.108951</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijar.2023.108951" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 Pages, 10 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2110.10153v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.10153v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.12749v1</id>
    <updated>2021-11-24T19:21:14Z</updated>
    <published>2021-11-24T19:21:14Z</published>
    <title>FCMpy: A Python Module for Constructing and Analyzing Fuzzy Cognitive
  Maps</title>
    <summary>  FCMpy is an open source package in Python for building and analyzing Fuzzy
Cognitive Maps. More specifically, the package allows 1) deriving fuzzy causal
weights from qualitative data, 2) simulating the system behavior, 3) applying
machine learning algorithms (e.g., Nonlinear Hebbian Learning, Active Hebbian
Learning, Genetic Algorithms and Deterministic Learning) to adjust the FCM
causal weight matrix and to solve classification problems, and 4) implementing
scenario analysis by simulating hypothetical interventions (i.e., analyzing
what-if scenarios).
</summary>
    <author>
      <name>Samvel Mkhitaryan</name>
    </author>
    <author>
      <name>Philippe J. Giabbanelli</name>
    </author>
    <author>
      <name>Maciej K. Wozniak</name>
    </author>
    <author>
      <name>Gonzalo Napoles</name>
    </author>
    <author>
      <name>Nanne K. de Vries</name>
    </author>
    <author>
      <name>Rik Crutzen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7717/peerj-cs.1078</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7717/peerj-cs.1078" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 9 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PeerJ Computer Science 8:e1078, 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2111.12749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.12749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.00004v1</id>
    <updated>2021-11-30T06:15:26Z</updated>
    <published>2021-11-30T06:15:26Z</published>
    <title>cliquematch: Finding correspondence via cliques in large graphs</title>
    <summary>  The maximum clique problem finds applications in computer vision,
bioinformatics, and network analysis, many of which involve the construction of
correspondence graphs to find similarities between two given objects.
cliquematch is a Python package designed for this purpose: it provides a simple
framework to construct correspondence graphs, and implements an algorithm to
find and enumerate maximum cliques in C++, that can process graphs of a few
million edges on consumer hardware, with comparable performance to publicly
available methods.
</summary>
    <author>
      <name>Gautham Venkatasubramanian</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5281/zenodo.4277288</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5281/zenodo.4277288" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, 1 table; Code available at
  https://github.com/ahgamut/cliquematch</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.00004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.00004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.2.2; G.2.4; G.4; I.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.02078v1</id>
    <updated>2021-11-30T02:18:03Z</updated>
    <published>2021-11-30T02:18:03Z</published>
    <title>On the very accurate evaluation of the Voigt/complex error function with
  small imaginary argument</title>
    <summary>  A rapidly convergent series, based on Taylor expansion of the imaginary part
of the complex error function, is presented for highly accurate approximation
of the Voigt/complex error function with small imaginary argument (Y less than
0.1). Error analysis and run-time tests in double-precision computing platform
reveals that in the real and imaginary parts the proposed algorithm provides
average accuracy exceeding 10^-15 and 10^-16, respectively, and the calculation
speed is as fast as that of reported in recent publications. An optimized
MATLAB code providing rapid computation with high accuracy is presented.
</summary>
    <author>
      <name>Yihong Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.02078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.02078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.03036v1</id>
    <updated>2021-12-03T12:33:56Z</updated>
    <published>2021-12-03T12:33:56Z</published>
    <title>Differentiable Scripting</title>
    <summary>  In Computational Science, Engineering and Finance (CSEF) scripts typically
serve as the "glue" between potentially highly complex and computationally
expensive external subprograms. Differentiability of the resulting programs
turns out to be essential in the context of derivative-based methods for error
analysis, uncertainty quantification, optimization or training of surrogates.
We argue that it should be enforced by the scripting language itself through
exclusive support of differentiable (smoothed) external subprograms and
differentiable intrinsics combined with prohibition of nondifferentiable
branches in the data flow. Illustration is provided by a prototype adjoint code
compiler for a simple Python-like scripting language.
</summary>
    <author>
      <name>Uwe Naumann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.03036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.03036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0874v3</id>
    <updated>2008-03-14T07:35:16Z</updated>
    <published>2008-03-06T18:45:39Z</published>
    <title>A Method for Solving Cyclic Block Penta-diagonal Systems of Linear
  Equations</title>
    <summary>  A method for solving cyclic block three-diagonal systems of equations is
generalized for solving a block cyclic penta-diagonal system of equations.
Introducing a special form of two new variables the original system is split
into three block pentagonal systems, which can be solved by the known methods.
As such method belongs to class of direct methods without pivoting.
Implementation of the algorithm is discussed in some details and the numerical
examples are present.
</summary>
    <author>
      <name>Milan Batista</name>
    </author>
    <link href="http://arxiv.org/abs/0803.0874v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0874v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4539v2</id>
    <updated>2012-10-17T17:23:43Z</updated>
    <published>2012-10-16T19:52:16Z</published>
    <title>A Robust Complex Division in Scilab</title>
    <summary>  The most widely used algorithm for floating point complex division, known as
Smith's method, may fail more often than expected. This document presents two
improved complex division algorithms. We present a proof of the robustness of
the first improved algorithm. Numerical simulations show that this algorithm
performs well in practice and is significantly more robust than other known
implementations. By combining additionnal scaling methods with this first
algorithm, we were able to create a second algorithm, which rarely fails.
</summary>
    <author>
      <name>Michael Baudin</name>
    </author>
    <author>
      <name>Robert L. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1210.4539v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4539v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04955v1</id>
    <updated>2015-03-17T09:03:34Z</updated>
    <published>2015-03-17T09:03:34Z</published>
    <title>Fast Multiplication of Large Integers: Implementation and Analysis of
  the DKSS Algorithm</title>
    <summary>  The Sch\"onhage-Strassen algorithm (SSA) is the de-facto standard for
multiplication of large integers. For $N$-bit numbers it has a time bound of
$O(N \cdot \log N \cdot \log \log N)$. De, Kurur, Saha and Saptharishi (DKSS)
presented an asymptotically faster algorithm with a better time bound of $N
\cdot \log N \cdot 2^{O(\log^* N)}$. In this diploma thesis, results of an
implementation of DKSS multiplication are presented: run-time is about 30 times
larger than SSA, while memory requirements are about 3.75 times higher than
SSA. A possible crossover point is estimated to be out of reach even if we
utilized the whole universe for computer memory.
</summary>
    <author>
      <name>Christoph Lüders</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Diploma Thesis, Universit\"at Bonn</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.04955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0; G.4; I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.02513v3</id>
    <updated>2022-06-29T22:52:58Z</updated>
    <published>2017-11-03T23:29:00Z</published>
    <title>CGAlgebra: a Mathematica package for conformal geometric algebra. v.2.0</title>
    <summary>  A tutorial of the Mathematica package CGAlgebra, for conformal geometric
algebra calculations is presented. Using rule-based programming, the
5-dimensional conformal geometric algebra is implemented and defined functions
simplify the calculations of geometric, outer and inner products, as well as
many other calculations related with geometric transformations. CGAlgebra is
available from https://github.com/jlaragonvera/Geometric-Algebra
</summary>
    <author>
      <name>E. Alejandra Ortiz-Duran</name>
    </author>
    <author>
      <name>Jose L. Aragon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Improved version, one figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.02513v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.02513v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.09777v3</id>
    <updated>2017-11-29T22:58:07Z</updated>
    <published>2017-11-24T09:36:13Z</published>
    <title>PhasePack User Guide</title>
    <summary>  "Phase retrieval" refers to the recovery of signals from the magnitudes (and
not the phases) of linear measurements. While there has been a recent explosion
in development of phase retrieval methods, the lack of a common interface has
made it difficult to compare new methods against the current state-of-the-art.
PhasePack is a software library that creates a common interface for a wide
range of phase retrieval schemes. PhasePack also provides a test bed for phase
retrieval methods using both synthetic data and publicly available empirical
datasets.
</summary>
    <author>
      <name>Rohan Chandra</name>
    </author>
    <author>
      <name>Ziyuan Zhong</name>
    </author>
    <author>
      <name>Justin Hontz</name>
    </author>
    <author>
      <name>Val McCulloch</name>
    </author>
    <author>
      <name>Christoph Studer</name>
    </author>
    <author>
      <name>Tom Goldstein</name>
    </author>
    <link href="http://arxiv.org/abs/1711.09777v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.09777v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.10911v2</id>
    <updated>2018-05-30T09:14:53Z</updated>
    <published>2017-11-28T15:53:22Z</published>
    <title>HomotopyContinuation.jl: A package for homotopy continuation in Julia</title>
    <summary>  We present the Julia package HomotopyContinuation.jl, which provides an
algorithmic framework for solving polynomial systems by numerical homotopy
continuation. We introduce the basic capabilities of the package and
demonstrate the software on an illustrative example. We motivate our choice of
Julia and how its features allow us to improve upon existing software packages
with respect to usability, modularity and performance. Furthermore, we compare
the performance of HomotopyContinuation.jl to the existing packages Bertini and
PHCpack.
</summary>
    <author>
      <name>Paul Breiding</name>
    </author>
    <author>
      <name>Sascha Timme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.10911v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.10911v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.04424v1</id>
    <updated>2018-09-09T01:51:45Z</updated>
    <published>2018-09-09T01:51:45Z</published>
    <title>Tuning the Performance of a Computational Persistent Homology Package</title>
    <summary>  In recent years, persistent homology has become an attractive method for data
analysis. It captures topological features, such as connected components,
holes, and voids from point cloud data and summarizes the way in which these
features appear and disappear in a filtration sequence. In this project, we
focus on improving the performance of Eirene, a computational package for
persistent homology. Eirene is a 5000-line open-source software library
implemented in the dynamic programming language Julia. We use the Julia
profiling tools to identify performance bottlenecks and develop novel methods
to manage them, including the parallelization of some time-consuming functions
on multicore/manycore hardware. Empirical results show that performance can be
greatly improved.
</summary>
    <author>
      <name>Alan Hylton</name>
    </author>
    <author>
      <name>Gregory Henselman-Petrusek</name>
    </author>
    <author>
      <name>Janche Sang</name>
    </author>
    <author>
      <name>Robert Short</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.04424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.04424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.03770v1</id>
    <updated>2018-12-10T12:52:03Z</updated>
    <published>2018-12-10T12:52:03Z</published>
    <title>Functional Design of Computation Graph</title>
    <summary>  Representing the control flow of a computer program as a computation graph
can bring many benefits in a broad variety of domains where performance is
critical. This technique is a core component of most major numerical libraries
(TensorFlow, PyTorch, Theano, MXNet,...) and is successfully used to speed up
and optimise many computationally-intensive tasks. However, different design
choices in each of these libraries lead to noticeable differences in efficiency
and in the way an end user writes efficient code. In this report, we detail the
implementation and features of the computation graph support in OCaml's
numerical library Owl, a recent entry in the world of scientific computing.
</summary>
    <author>
      <name>Pierre Vandenhove</name>
    </author>
    <link href="http://arxiv.org/abs/1812.03770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.03770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00785v1</id>
    <updated>2019-06-03T13:22:27Z</updated>
    <published>2019-06-03T13:22:27Z</published>
    <title>Bembel: The Fast Isogeometric Boundary Element C++ Library for Laplace,
  Helmholtz, and Electric Wave Equation</title>
    <summary>  In this article, we present Bembel, the C++ library featuring higher order
isogeometric Galerkin boundary element methods for Laplace, Helmholtz, and
Maxwell problems. Bembel is compatible with geometries from the Octave NURBS
package and provides an interface to the Eigen template library for linear
algebra operations. For computational efficiency, it applies an embedded fast
multipole method tailored to the isogeometric analysis framework and a parallel
matrix assembly based on OpenMP.
</summary>
    <author>
      <name>J. Dölz</name>
    </author>
    <author>
      <name>H. Harbrecht</name>
    </author>
    <author>
      <name>S. Kurz</name>
    </author>
    <author>
      <name>M. Multerer</name>
    </author>
    <author>
      <name>S. Schöps</name>
    </author>
    <author>
      <name>F. Wolf</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06507v2</id>
    <updated>2020-11-09T16:41:43Z</updated>
    <published>2019-06-15T09:22:03Z</published>
    <title>Computing Theta Functions with Julia</title>
    <summary>  We present a new package Theta.jl for computing with the Riemann theta
function. It is implemented in Julia and offers accurate numerical evaluation
of theta functions with characteristics and their derivatives of arbitrary
order. Our package is optimized for multiple evaluations of theta functions for
the same Riemann matrix, in small dimensions. As an application, we report on
experimental approaches to the Schottky problem in genus five.
</summary>
    <author>
      <name>Daniele Agostini</name>
    </author>
    <author>
      <name>Lynn Chua</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2140/jsag.2021.11.41</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2140/jsag.2021.11.41" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v2: to appear in the Journal of Software for Algebra and Geometry.
  Content reorganized according to the published version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Softw. Alg. Geom. 11 (2021) 41-51</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.06507v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06507v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07574v1</id>
    <updated>2019-06-14T02:45:35Z</updated>
    <published>2019-06-14T02:45:35Z</published>
    <title>Bspline solids manipulation with Mathematica</title>
    <summary>  Bspline solids are used for solid objects modeling in R3. Mathematica
incorporates a several commands to manipulate symbolic and graphically Bspline
basis functions and to graphically manipulate Bsplines curves and surfaces;
however, it does not incorporate any command to the graphical manipulation of
Bspline solids. In this paper, we describe a new Mathematica program to compute
and plotting the Bspline solids. The output obtained is consistent with
Mathematica's notation. The performance of the commands are discussed by using
some illustrative examples.
</summary>
    <author>
      <name>R. Ipanaqué</name>
    </author>
    <author>
      <name>R. Velezmoro</name>
    </author>
    <author>
      <name>R. T. Urbina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08613v1</id>
    <updated>2019-06-20T13:44:41Z</updated>
    <published>2019-06-20T13:44:41Z</published>
    <title>Program Generation for Linear Algebra Using Multiple Layers of DSLs</title>
    <summary>  Numerical software in computational science and engineering often relies on
highly-optimized building blocks from libraries such as BLAS and LAPACK, and
while such libraries provide portable performance for a wide range of computing
architectures, they still present limitations in terms of flexibility. We
advocate a domain-specific program generator capable of producing library
routines tailored to the specific needs of the application in terms of sizes,
interface, and target architecture.
</summary>
    <author>
      <name>Daniele G. Spampinato</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Diego Fabregat-Traver</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Markus Püschel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1906.08613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10811v1</id>
    <updated>2019-06-26T02:11:08Z</updated>
    <published>2019-06-26T02:11:08Z</published>
    <title>Investigating the OPS intermediate representation to target GPUs in the
  Devito DSL</title>
    <summary>  The Devito DSL is a code generation tool for the solution of partial
differential equations using the finite difference method specifically aimed at
seismic inversion problems.
  In this work we investigate the integration of OPS, an API to generate highly
optimized code for applications running on structured meshes targeting various
platforms, within Devito as a mean of bringing it to the GPU realm by providing
an implementation of a OPS backend in Devito, obtaining considerable speed ups
compared to the core Devito backend.
</summary>
    <author>
      <name>Vincenzo Pandolfo</name>
    </author>
    <link href="http://arxiv.org/abs/1906.10811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02491v1</id>
    <updated>2020-01-08T13:09:11Z</updated>
    <published>2020-01-08T13:09:11Z</published>
    <title>Comparing Python, Go, and C++ on the N-Queens Problem</title>
    <summary>  Python currently is the dominant language in the field of Machine Learning
but is often criticized for being slow to perform certain tasks. In this
report, we use the well-known $N$-queens puzzle as a benchmark to show that
once compiled using the Numba compiler it becomes competitive with C++ and Go
in terms of execution speed while still allowing for very fast prototyping.
This is true of both sequential and parallel programs. In most cases that arise
in an academic environment, it therefore makes sense to develop in ordinary
Python, identify computational bottlenecks, and use Numba to remove them.
</summary>
    <author>
      <name>Pascal Fua</name>
    </author>
    <author>
      <name>Krzysztof Lis</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.08478v1</id>
    <updated>2020-08-19T14:38:07Z</updated>
    <published>2020-08-19T14:38:07Z</published>
    <title>Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear
  Algebra Computations</title>
    <summary>  GPU accelerators have become an important backbone for scientific high
performance computing, and the performance advances obtained from adopting new
GPU hardware are significant. In this paper we take a first look at NVIDIA's
newest server line GPU, the A100 architecture part of the Ampere generation.
Specifically, we assess its performance for sparse linear algebra operations
that form the backbone of many scientific applications and assess the
performance improvements over its predecessor.
</summary>
    <author>
      <name>Yuhsiang Mike Tsai</name>
    </author>
    <author>
      <name>Terry Cojean</name>
    </author>
    <author>
      <name>Hartwig Anzt</name>
    </author>
    <link href="http://arxiv.org/abs/2008.08478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.08478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.11799v1</id>
    <updated>2020-08-26T20:38:31Z</updated>
    <published>2020-08-26T20:38:31Z</published>
    <title>GPU-accelerating ImageJ Macro image processing workflows using CLIJ</title>
    <summary>  This chapter introduces GPU-accelerated image processing in ImageJ/FIJI. The
reader is expected to have some pre-existing knowledge of ImageJ Macro
programming. Core concepts such as variables, for-loops, and functions are
essential. The chapter provides basic guidelines for improved performance in
typical image processing workflows. We present in a step-by-step tutorial how
to translate a pre-existing ImageJ macro into a GPU-accelerated macro.
</summary>
    <author>
      <name>Daniela Vorkel</name>
    </author>
    <author>
      <name>Robert Haase</name>
    </author>
    <link href="http://arxiv.org/abs/2008.11799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.11799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.04938v3</id>
    <updated>2022-02-09T14:46:01Z</updated>
    <published>2020-09-10T15:32:42Z</published>
    <title>Dune-CurvedGrid -- A Dune module for surface parametrization</title>
    <summary>  In this paper we introduce and describe an implementation of curved (surface)
geometries within the Dune framework for grid-based discretizations. Therefore,
we employ the abstraction of geometries as local-functions bound to a grid
element, and the abstraction of a grid as connectivity of elements together
with a grid-function that can be localized to the elements to provide element
local parametrizations of the curved surface.
</summary>
    <author>
      <name>Simon Praetorius</name>
    </author>
    <author>
      <name>Florian Stenger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.11588/ans.2022.1.75917</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.11588/ans.2022.1.75917" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Arch. Num. Soft., 2022, 6(1)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2009.04938v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.04938v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="53-04 (Primary) 53A05, 58J90, 65M50, 65-04 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.08461v1</id>
    <updated>2020-11-17T06:28:05Z</updated>
    <published>2020-11-17T06:28:05Z</published>
    <title>Deep Learning Framework From Scratch Using Numpy</title>
    <summary>  This work is a rigorous development of a complete and general-purpose deep
learning framework from the ground up. The fundamental components of deep
learning - automatic differentiation and gradient methods of optimizing
multivariable scalar functions - are developed from elementary calculus and
implemented in a sensible object-oriented approach using only Python and the
Numpy library. Demonstrations of solved problems using the framework, named
ArrayFlow, include a computer vision classification task, solving for the shape
of a catenary, and a 2nd order differential equation.
</summary>
    <author>
      <name>Andrei Nicolae</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2011.08461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.08461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.03681v1</id>
    <updated>2021-02-06T23:17:10Z</updated>
    <published>2021-02-06T23:17:10Z</published>
    <title>FastAD: Expression Template-Based C++ Library for Fast and
  Memory-Efficient Automatic Differentiation</title>
    <summary>  Automatic differentiation is a set of techniques to efficiently and
accurately compute the derivative of a function represented by a computer
program. Existing C++ libraries for automatic differentiation (e.g. Adept, Stan
Math Library), however, exhibit large memory consumptions and runtime
performance issues. This paper introduces FastAD, a new C++ template library
for automatic differentiation, that overcomes all of these challenges in
existing libraries by using vectorization, simpler memory management using a
fully expression-template-based design, and other compile-time optimizations to
remove some run-time overhead. Benchmarks show that FastAD performs 2-10 times
faster than Adept and 2-19 times faster than Stan across various test cases
including a few real-world examples.
</summary>
    <author>
      <name>James Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2102.03681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.03681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.08518v1</id>
    <updated>2021-02-17T00:55:19Z</updated>
    <published>2021-02-17T00:55:19Z</published>
    <title>Automatic Generation of Interpolants for Lattice Samplings: Part II --
  Implementation and Code Generation</title>
    <summary>  In the prequel to this paper, we presented a systematic framework for
processing spline spaces. In this paper, we take the results of that framework
and provide a code generation pipeline that automatically generates efficient
implementations of spline spaces. We decompose the final algorithm from Part I
and translate the resulting components into LLVM-IR (a low level language that
can be compiled to various targets/architectures). Our design provides a
handful of parameters for a practitioner to tune - this is one of the avenues
that provides us with the flexibility to target many different computational
architectures and tune performance on those architectures. We also provide an
evaluation of the effect of the different parameters on performance.
</summary>
    <author>
      <name>Joshua Horacsek</name>
    </author>
    <author>
      <name>Usman Alim</name>
    </author>
    <link href="http://arxiv.org/abs/2102.08518v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.08518v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.10346v1</id>
    <updated>2021-07-21T20:28:38Z</updated>
    <published>2021-07-21T20:28:38Z</published>
    <title>Comparing OpenMP Implementations With Applications Across A64FX
  Platforms</title>
    <summary>  The development of the A64FX processor by Fujitsu has created a massive
innovation in High-Performance Computing and the birth of Fugaku: the current
world's fastest supercomputer. A variety of tools are used to analyze the
run-times and performances of several applications, and in particular, how
these applications scale on the A64FX processor. We examine the performance and
behavior of applications through OpenMP scaling and how their performance
differs across different compilers on the new Ookami cluster at Stony Brook
University as well as the Fugaku supercomputer at RIKEN in Japan.
</summary>
    <author>
      <name>Benjamin Michalowicz</name>
    </author>
    <author>
      <name>Eric Raut</name>
    </author>
    <author>
      <name>Yan Kang</name>
    </author>
    <author>
      <name>Tony Curtis</name>
    </author>
    <author>
      <name>Barbara Chapman</name>
    </author>
    <author>
      <name>Dossay Oryspayev</name>
    </author>
    <link href="http://arxiv.org/abs/2107.10346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.10346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.12550v1</id>
    <updated>2021-07-27T01:57:03Z</updated>
    <published>2021-07-27T01:57:03Z</published>
    <title>Accelerated Multiple Precision Direct Method and Mixed Precision
  Iterative Refinement on Python Programming Environment</title>
    <summary>  Current Python programming environment does not have any reliable and
efficient multiple precision floating-point (MPF) arithmetic except ``mpmath"
and ``gmpy2" packages based on GNU MP(GMP) and MPFR libraries. Although it is
well known that multi-component-type MPF library can be utilized for middle
length precision arithmetic under 200 bits, they are not widely used on Python
environment. In this paper, we describe our accelerated MPF direct method with
AVX2 techniques and its application to mixed precision iterative refinement
combined with mpmath, and demonstrate their efficiency on x86\_64 computational
environments.
</summary>
    <author>
      <name>Tomonori Kouya</name>
    </author>
    <link href="http://arxiv.org/abs/2107.12550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.12550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.02806v3</id>
    <updated>2022-07-27T16:36:32Z</updated>
    <published>2022-01-08T11:14:28Z</published>
    <title>Parallel Metric-Based Mesh Adaptation in PETSc using ParMmg</title>
    <summary>  This research note documents the integration of the MPI-parallel metric-based
mesh adaptation toolkit ParMmg into the solver library PETSc. This coupling
brings robust, scalable anisotropic mesh adaptation to a wide community of
PETSc users, as well as users of downstream packages. We demonstrate the new
functionality via the solution of Poisson problems in three dimensions, with
both uniform and spatially-varying right-hand sides.
</summary>
    <author>
      <name>Joseph G. Wallwork</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Nicolas Barral</name>
    </author>
    <author>
      <name>Matthew D. Piggott</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures. Appeared as a research note in the 30th
  International Meshing Roundtable</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.02806v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.02806v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.07637v1</id>
    <updated>2022-05-10T15:50:54Z</updated>
    <published>2022-05-10T15:50:54Z</published>
    <title>MATLAB implementation of hp finite elements on rectangles</title>
    <summary>  A simple MATLAB implementation of hierarchical shape functions on 2D
rectangles is explained and available for download. Global shape functions are
ordered for a given polynomial degree according to the indices of the nodes,
edges, or elements to which they belong. For a uniform p-refinement, the
hierarchical structure enables an effective assembly of mass and stiffness
matrices. A solution of a boundary value problem is approximated for various
levels of uniform h and p refinements.
</summary>
    <author>
      <name>Alexej Moskovka</name>
    </author>
    <author>
      <name>Jan Valdman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.07637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.07637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.06803v2</id>
    <updated>2022-07-26T13:48:10Z</updated>
    <published>2022-07-14T10:31:21Z</published>
    <title>FFTc: An MLIR Dialect for Developing HPC Fast Fourier Transform
  Libraries</title>
    <summary>  Discrete Fourier Transform (DFT) libraries are one of the most critical
software components for scientific computing. Inspired by FFTW, a widely used
library for DFT HPC calculations, we apply compiler technologies for the
development of HPC Fourier transform libraries. In this work, we introduce
FFTc, a domain-specific language, based on Multi-Level Intermediate
Representation (MLIR), for expressing Fourier Transform algorithms. We present
the initial design, implementation, and preliminary results of FFTc.
</summary>
    <author>
      <name>Yifei He</name>
    </author>
    <author>
      <name>Artur Podobas</name>
    </author>
    <author>
      <name>Måns I. Andersson</name>
    </author>
    <author>
      <name>Stefano Markidis</name>
    </author>
    <link href="http://arxiv.org/abs/2207.06803v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.06803v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.04818v1</id>
    <updated>2022-12-09T12:46:24Z</updated>
    <published>2022-12-09T12:46:24Z</published>
    <title>Parallelism detection using graph labelling</title>
    <summary>  Usage of multiprocessor and multicore computers implies parallel programming.
Tools for preparing parallel programs include parallel languages and libraries
as well as parallelizing compilers and convertors that can perform automatic
parallelization. The basic approach for parallelism detection is analysis of
data dependencies and properties of program components, including data use and
predicates. In this article a suite of used data and predicates sets for
program components is proposed and an algorithm for computing these sets is
suggested. The algorithm is based on wave propagation on graphs with cycles and
labelling. This method allows analyzing complex program components, improving
data localization and thus providing enhanced data parallelism detection.
</summary>
    <author>
      <name>Pavel Telegin</name>
    </author>
    <author>
      <name>Anton Baranov</name>
    </author>
    <author>
      <name>Boris Shabanov</name>
    </author>
    <author>
      <name>Artem Tikhomirov</name>
    </author>
    <link href="http://arxiv.org/abs/2212.04818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.04818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.06935v3</id>
    <updated>2024-02-12T16:25:18Z</updated>
    <published>2023-04-14T05:47:34Z</published>
    <title>Groebner.jl: A package for Gröbner bases computations in Julia</title>
    <summary>  We present Groebner.jl, a Julia package for computing Groebner bases with the
F4 algorithm. Groebner.jl is an efficient, portable, and open-source software.
Groebner.jl works over integers modulo a prime and over the rationals, supports
basic multi-threading, and specializes in computation in the degree reverse
lexicographical monomial ordering. The implementation incorporates various
symbolic computation techniques and leverages the Julia type system and
tooling, which allows Groebner.jl to compete with the existing state of the
art, in many instances outperform it, and exceed them in extensibility.
Groebner.jl is freely available at https://github.com/sumiya11/Groebner.jl.
</summary>
    <author>
      <name>Alexander Demin</name>
    </author>
    <author>
      <name>Shashi Gowda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.06935v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.06935v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.10032v1</id>
    <updated>2023-07-19T15:16:01Z</updated>
    <published>2023-07-19T15:16:01Z</published>
    <title>Automatic Conversion of MiniZinc Programs to QUBO</title>
    <summary>  Obtaining Quadratic Unconstrained Binary Optimisation models for various
optimisation problems, in order to solve those on physical quantum computers
(such as the the DWave annealers) is nowadays a lengthy and tedious process
that requires one to remodel all problem variables as binary variables and
squeeze the target function and the constraints into a single quadratic
polynomial into these new variables.
  We report here on the basis of our automatic converter from MiniZinc to QUBO,
which is able to process a large set of constraint optimisation and constraint
satisfaction problems and turn them into equivalent QUBOs, effectively
optimising the whole process.
</summary>
    <author>
      <name>Armin Wolf</name>
    </author>
    <author>
      <name>Cristian Grozea</name>
    </author>
    <link href="http://arxiv.org/abs/2307.10032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.10032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.00497v1</id>
    <updated>2023-08-01T12:32:26Z</updated>
    <published>2023-08-01T12:32:26Z</published>
    <title>Leveraging MLIR for Loop Vectorization and GPU Porting of FFT Libraries</title>
    <summary>  FFTc is a Domain-Specific Language (DSL) for designing and generating Fast
Fourier Transforms (FFT) libraries. The FFTc uniqueness is that it leverages
and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize
FFT code generation. In this work, we present FFTc extensions and improvements
such as the possibility of using different data layout for complex-value
arrays, and sparsification to enable efficient vectorization, and a seamless
porting of FFT libraries to GPU systems. We show that, on CPUs, thanks to
vectorization, the performance of the FFTc-generated FFT is comparable to
performance of FFTW, a state-of-the-art FFT libraries. We also present the
initial performance results for FFTc on Nvidia GPUs.
</summary>
    <author>
      <name>Yifei He</name>
    </author>
    <author>
      <name>Artur Podobas</name>
    </author>
    <author>
      <name>Stefano Markidis</name>
    </author>
    <link href="http://arxiv.org/abs/2308.00497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.00497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.10960v1</id>
    <updated>2023-08-21T18:15:05Z</updated>
    <published>2023-08-21T18:15:05Z</published>
    <title>Hierarchical Lowrank Arithmetic with Binary Compression</title>
    <summary>  With lowrank approximation the storage requirements for dense data are
reduced down to linear complexity and with the addition of hierarchy this also
works for data without global lowrank properties. However, the lowrank factors
itself are often still stored using double precision numbers. Newer approaches
exploit the different IEEE754 floating point formats available nowadays in a
mixed precision approach. However, these formats show a significant gap in
storage (and accuracy), e.g. between half, single and double precision. We
therefore look beyond these standard formats and use adaptive compression for
storing the lowrank and dense data and investigate how that affects the
arithmetic of such matrices.
</summary>
    <author>
      <name>Ronald Kriemann</name>
    </author>
    <link href="http://arxiv.org/abs/2308.10960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.10960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05, 65Y20, 68W10, 68W25, 68P30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.06306v2</id>
    <updated>2024-01-25T11:04:46Z</updated>
    <published>2023-09-12T15:17:16Z</published>
    <title>CDL: A fast and flexible library for the study of permutation sets with
  structural restrictions</title>
    <summary>  In this paper, we introduce CDL, a software library designed for the analysis
of permutations and linear orders subject to various structural restrictions.
Prominent examples of these restrictions include pattern avoidance, a topic of
interest in both computer science and combinatorics, and "never conditions"
utilized in social choice and voting theory.
  CDL offers a range of fundamental functionalities, including identifying the
permutations that meet specific restrictions and determining the isomorphism of
such sets. To facilitate exploration of large permutation sets or domains, CDL
incorporates multiple search strategies and heuristics.
</summary>
    <author>
      <name>Bei Zhou</name>
    </author>
    <author>
      <name>Klas Markstrōm</name>
    </author>
    <author>
      <name>Søren Riis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.06306v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.06306v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.10700v2</id>
    <updated>2025-04-10T15:07:00Z</updated>
    <published>2023-11-17T18:44:40Z</published>
    <title>Deriving Algorithms for Triangular Tridiagonalization a Skew-Symmetric
  Matrix</title>
    <summary>  This paper provides technical details regarding the application of the FLAME
methodology to derive algorithms hand in hand with their proofs of correctness
for the computation of the $ L T L^T $ decomposition (with and without
pivoting) of a skew-symmetric matrix. The approach yields known as well as new
algorithms, presented using the FLAME notation, enabling comparing and
contrasting. A number of BLAS-like primitives are exposed at the core of the
resulting unblocked and blocked algorithms.
</summary>
    <author>
      <name>Robert van de Geijn</name>
    </author>
    <author>
      <name>Maggie Myers</name>
    </author>
    <author>
      <name>RuQing G. Xu</name>
    </author>
    <author>
      <name>Devin Matthews</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages. arXiv admin note: text overlap with arXiv:2411.09859</arxiv:comment>
    <link href="http://arxiv.org/abs/2311.10700v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.10700v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.17283v1</id>
    <updated>2023-11-28T23:50:08Z</updated>
    <published>2023-11-28T23:50:08Z</published>
    <title>Lineax: unified linear solves and linear least-squares in JAX and
  Equinox</title>
    <summary>  We introduce Lineax, a library bringing linear solves and linear
least-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses
general linear operators, and unifies linear solves and least-squares into a
single, autodifferentiable API. Solvers and operators are user-extensible,
without requiring the user to implement any custom derivative rules to get
differentiability. Lineax is available at https://github.com/google/lineax.
</summary>
    <author>
      <name>Jason Rader</name>
    </author>
    <author>
      <name>Terry Lyons</name>
    </author>
    <author>
      <name>Patrick Kidger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure, NeurIPS 2023 AI for Science workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2311.17283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.17283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.02121v1</id>
    <updated>2023-12-04T18:50:41Z</updated>
    <published>2023-12-04T18:50:41Z</published>
    <title>Mathematical Supplement for the $\texttt{gsplat}$ Library</title>
    <summary>  This report provides the mathematical details of the gsplat library, a
modular toolbox for efficient differentiable Gaussian splatting, as proposed by
Kerbl et al. It provides a self-contained reference for the computations
involved in the forward and backward passes of differentiable Gaussian
splatting. To facilitate practical usage and development, we provide a user
friendly Python API that exposes each component of the forward and backward
passes in rasterization at github.com/nerfstudio-project/gsplat .
</summary>
    <author>
      <name>Vickie Ye</name>
    </author>
    <author>
      <name>Angjoo Kanazawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Find the library at: https://docs.gsplat.studio/</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.02121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.02121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.03917v1</id>
    <updated>2024-01-08T14:24:54Z</updated>
    <published>2024-01-08T14:24:54Z</published>
    <title>Toward a comprehensive simulation framework for hypergraphs: a
  Python-base approach</title>
    <summary>  Hypergraphs, or generalization of graphs such that edges can contain more
than two nodes, have become increasingly prominent in understanding complex
network analysis. Unlike graphs, hypergraphs have relatively few supporting
platforms, and such dearth presents a barrier to more widespread adaptation of
hypergraph computational toolboxes that could enable further research in
several areas. Here, we introduce HyperRD, a Python package for hypergraph
computation, simulation, and interoperability with other powerful Python
packages in graph and hypergraph research. Then, we will introduce two models
on hypergraph, the general Schelling's model and the SIR model, and simulate
them with HyperRD.
</summary>
    <author>
      <name>Quoc Chuong Nguyen</name>
    </author>
    <author>
      <name>Trung Kien Le</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.03917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.03917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.02523v1</id>
    <updated>2024-02-04T15:11:04Z</updated>
    <published>2024-02-04T15:11:04Z</published>
    <title>FEniCSx Preconditioning Tools (FEniCSx-pctools)</title>
    <summary>  FEniCSx Preconditioning Tools (FEniCSx-pctools) is a software package for
easing the specification of PETSc-based block preconditioning strategies in the
DOLFINx finite element solver of the FEniCS Project. It attaches all of the
necessary metadata to the block-structured linear systems in order that
block-structured preconditioners can be applied straightforwardly via PETSc's
options-based configuration system. Fast prototyping is facilitated thanks to
the implementation in Python, and all intensive operations are executed in
C/C++. FEniCSx-pctools is available under the LGPLv3 or later license.
</summary>
    <author>
      <name>Martin Řehoř</name>
    </author>
    <author>
      <name>Jack S. Hale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.02523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.02523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N22, 65F08, 65F10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.12797v1</id>
    <updated>2024-04-19T11:24:03Z</updated>
    <published>2024-04-19T11:24:03Z</published>
    <title>Conversion of Boolean and Integer FlatZinc Builtins to Quadratic or
  Linear Integer Problems</title>
    <summary>  Constraint satisfaction or optimisation models -- even if they are formulated
in high-level modelling languages -- need to be reduced into an equivalent
format before they can be solved by the use of Quantum Computing. In this paper
we show how Boolean and integer FlatZinc builtins over finite-domain integer
variables can be equivalently reformulated as linear equations, linear
inequalities or binary products of those variables, i.e. as finite-domain
quadratic integer programs. Those quadratic integer programs can be further
transformed into equivalent Quadratic Unconstrained Binary Optimisation problem
models, i.e. a general format for optimisation problems to be solved on Quantum
Computers especially on Quantum Annealers.
</summary>
    <author>
      <name>Armin Wolf</name>
    </author>
    <link href="http://arxiv.org/abs/2404.12797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.12797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.17039v2</id>
    <updated>2024-05-06T19:15:43Z</updated>
    <published>2024-04-25T21:05:01Z</published>
    <title>Differentiating Through Linear Solvers</title>
    <summary>  Computer programs containing calls to linear solvers are a known challenge
for automatic differentiation. Previous publications advise against
differentiating through the low-level solver implementation, and instead
advocate for high-level approaches that express the derivative in terms of a
modified linear system that can be solved with a separate solver call. Despite
this ubiquitous advice, we are not aware of prior work comparing the accuracy
of both approaches. With this article we thus empirically study a simple
question: What happens if we ignore common wisdom, and differentiate through
linear solvers?
</summary>
    <author>
      <name>Paul Hovland</name>
    </author>
    <author>
      <name>Jan Hückelheim</name>
    </author>
    <link href="http://arxiv.org/abs/2404.17039v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.17039v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.10130v1</id>
    <updated>2024-05-16T14:29:02Z</updated>
    <published>2024-05-16T14:29:02Z</published>
    <title>PyOptInterface: Design and implementation of an efficient modeling
  language for mathematical optimization</title>
    <summary>  This paper introduces the design and implementation of PyOptInterface, a
modeling language for mathematical optimization embedded in Python programming
language. PyOptInterface uses lightweight and compact data structure to bridge
high-level entities in optimization models like variables and constraints to
internal indices of optimizers efficiently. It supports a variety of
optimization solvers and a range of common problem classes. We provide
benchmarks to exhibit the competitive performance of PyOptInterface compared
with other state-of-the-art modeling languages.
</summary>
    <author>
      <name>Yue Yang</name>
    </author>
    <author>
      <name>Chenhui Lin</name>
    </author>
    <author>
      <name>Luo Xu</name>
    </author>
    <author>
      <name>Wenchuan Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.10130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.10130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.07751v1</id>
    <updated>2024-06-11T22:22:13Z</updated>
    <published>2024-06-11T22:22:13Z</published>
    <title>A square root algorithm faster than Newton's method for multiprecision
  numbers, using floating-point arithmetic</title>
    <summary>  In this paper, an optimized version of classical Bombelli's algorithm for
computing integer square roots is presented. In particular, floating-point
arithmetic is used to compute the initial guess of each digit of the root,
following similar ideas to those used in "The Art of Computer Programming" Vol.
2, p. 4.3.1 for division. A program with an implementation of the algorithm in
Java is also presented, and its running time is compared with that of the
algorithm provided by the Java standard library, which uses the Newton's
method. From tests, the algorithm presented here turns out to be much faster.
</summary>
    <author>
      <name>Fabio Romano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.07751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.07751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.10372v1</id>
    <updated>2024-07-15T00:41:02Z</updated>
    <published>2024-07-15T00:41:02Z</published>
    <title>MPAT: Modular Petri Net Assembly Toolkit</title>
    <summary>  We present a Python package called Modular Petri Net Assembly Toolkit (MPAT)
that empowers users to easily create large-scale, modular Petri Nets for
various spatial configurations, including extensive spatial grids or those
derived from shape files, augmented with heterogeneous information layers.
Petri Nets are powerful discrete event system modeling tools in computational
biology and engineering. However, their utility for automated construction of
large-scale spatial models has been limited by gaps in existing modeling
software packages. MPAT addresses this gap by supporting the development of
modular Petri Net models with flexible spatial geometries.
</summary>
    <author>
      <name>Stefano Chiaradonna</name>
    </author>
    <author>
      <name>Petar Jevtic</name>
    </author>
    <author>
      <name>Beckett Sterner</name>
    </author>
    <link href="http://arxiv.org/abs/2407.10372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.10372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.11880v1</id>
    <updated>2024-08-21T03:05:27Z</updated>
    <published>2024-08-21T03:05:27Z</published>
    <title>RAO-SS: A Prototype of Run-time Auto-tuning Facility for Sparse Direct
  Solvers</title>
    <summary>  In this paper, a run-time auto-tuning method for performance parameters
according to input matrices is proposed. RAO-SS (Run-time Auto-tuning Optimizer
for Sparse Solvers), which is a prototype of auto-tuning software using the
proposed method, is also evaluated. The RAO-SS is implemented with the
Autopilot, which is middle-ware to support run-time auto-tuning with fuzzy
logic function. The target numerical library is the SuperLU, which is a sparse
direct solver for linear equations. The result indicated that: (1) the speedup
factors of 1.2 for average and 3.6 for maximum to default executions were
obtained; (2) the software overhead of the Autopilot can be ignored in RAO-SS.
</summary>
    <author>
      <name>Takahiro Katagiri</name>
    </author>
    <author>
      <name>Yoshinori Ishii</name>
    </author>
    <author>
      <name>Hiroki Honda</name>
    </author>
    <link href="http://arxiv.org/abs/2408.11880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.11880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.00568v2</id>
    <updated>2024-09-07T15:39:21Z</updated>
    <published>2024-09-01T00:09:00Z</published>
    <title>Welding R and C++: A Tale of Two Programming Languages</title>
    <summary>  This article compares `cpp11armadillo` and `cpp11eigen`, new R packages that
integrate the powerful Armadillo and Eigen C++ libraries for linear algebra
into the R programming environment. This article provides a detailed comparison
between Armadillo and Eigen speed and syntax. The goal of these packages is to
simplify a part of the process of solving bottlenecks by using C++ within R,
these offer additional ease of integration for users who require
high-performance linear algebra operations in their R workflows. This document
aims to discuss the tradeoff between computational efficiency and
accessibility.
</summary>
    <author>
      <name>Mauricio Vargas Sepulveda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2025.102087</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2025.102087" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 0 figures, 13 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.00568v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.00568v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.15926v1</id>
    <updated>2024-09-24T09:47:28Z</updated>
    <published>2024-09-24T09:47:28Z</published>
    <title>QHyper: an integration library for hybrid quantum-classical optimization</title>
    <summary>  We propose the QHyper library, which is aimed at researchers working on
computational experiments with a variety of quantum combinatorial optimization
solvers. The library offers a simple and extensible interface for formulating
combinatorial optimization problems, selecting and running solvers, and
optimizing hyperparameters. The supported solver set includes variational
gate-based algorithms, quantum annealers, and classical solutions. The solvers
can be combined with provided local and global (hyper)optimizers. The main
features of the library are its extensibility on different levels of use as
well as a straightforward and flexible experiment configuration format
presented in the paper.
</summary>
    <author>
      <name>Tomasz Lamża</name>
    </author>
    <author>
      <name>Justyna Zawalska</name>
    </author>
    <author>
      <name>Kacper Jurek</name>
    </author>
    <author>
      <name>Mariusz Sterzel</name>
    </author>
    <author>
      <name>Katarzyna Rycerz</name>
    </author>
    <link href="http://arxiv.org/abs/2409.15926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.15926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.06631v1</id>
    <updated>2024-11-10T23:46:37Z</updated>
    <published>2024-11-10T23:46:37Z</published>
    <title>SequentialSamplingModels.jl: Simulating and Evaluating Cognitive Models
  of Response Times in Julia</title>
    <summary>  Sequential sampling models (SSMs) are a widely used framework describing
decision-making as a stochastic, dynamic process of evidence accumulation. SSMs
popularity across cognitive science has driven the development of various
software packages that lower the barrier for simulating, estimating, and
comparing existing SSMs. Here, we present a software tool,
SequentialSamplingModels.jl (SSM.jl), designed to make SSM simulations more
accessible to Julia users, and to integrate with the Julia ecosystem. We
demonstrate the basic use of SSM.jl for simulation, plotting, and Bayesian
inference.
</summary>
    <author>
      <name>Kianté Fernandez</name>
    </author>
    <author>
      <name>Dominique Makowski</name>
    </author>
    <author>
      <name>Christopher Fisher</name>
    </author>
    <link href="http://arxiv.org/abs/2411.06631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.06631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.05300v2</id>
    <updated>2024-12-11T21:56:35Z</updated>
    <published>2024-11-25T10:24:29Z</published>
    <title>AD-HOC: A C++ Expression Template package for high-order derivatives
  backpropagation</title>
    <summary>  This document presents a new C++ Automatic Differentiation (AD) tool, AD-HOC
(Automatic Differentiation for High-Order Calculations). This tool aims to have
the following features: -Calculation of user specified derivatives of arbitrary
order -To be able to run with similar speeds as handwritten code -All
derivatives calculations are computed in a single backpropagation tree pass -No
source code generation is used, relying heavily on the C++ compiler to
statically build the computation tree before runtime -A simple interface -The
ability to be used \textit{in conjunction} with other established,
general-purpose dynamic AD tools -Header-only library, with no external
dependencies -Open source, with a business-friendly license
</summary>
    <author>
      <name>Juan Lucas Rey</name>
    </author>
    <link href="http://arxiv.org/abs/2412.05300v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.05300v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.17265v1</id>
    <updated>2024-12-23T04:22:05Z</updated>
    <published>2024-12-23T04:22:05Z</published>
    <title>Evaluating the Design Features of an Intelligent Tutoring System for
  Advanced Mathematics Learning</title>
    <summary>  Xiaomai is an intelligent tutoring system (ITS) designed to help Chinese
college students in learning advanced mathematics and preparing for the
graduate school math entrance exam. This study investigates two distinctive
features within Xiaomai: the incorporation of free-response questions with
automatic feedback and the metacognitive element of reflecting on self-made
errors.
</summary>
    <author>
      <name>Ying Fang</name>
    </author>
    <author>
      <name>Bo He</name>
    </author>
    <author>
      <name>Zhi Liu</name>
    </author>
    <author>
      <name>Sannyuya Liu</name>
    </author>
    <author>
      <name>Zhonghua Yan</name>
    </author>
    <author>
      <name>Jianwen Sun</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-64302-6_24</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-64302-6_24" rel="related"/>
    <link href="http://arxiv.org/abs/2412.17265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.17265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.10831v1</id>
    <updated>2025-02-15T15:18:48Z</updated>
    <published>2025-02-15T15:18:48Z</published>
    <title>A Novel SIMD-Optimized Implementation for Fast and Memory-Efficient
  Trigonometric Computation</title>
    <summary>  This paper proposes a novel set of trigonometric implementations which are 5x
faster than the inbuilt C++ functions. The proposed implementation is also
highly memory efficient requiring no precomputations of any kind. Benchmark
comparisons are done versus inbuilt functions and an optimized taylor
implementation. Further, device usage estimates are also obtained, showing
significant hardware usage reduction compared to inbuilt functions. This
improvement could be particularly useful for low-end FPGAs or other
resource-constrained devices.
</summary>
    <author>
      <name>Nikhil Dev Goyal</name>
    </author>
    <author>
      <name>Parth Arora</name>
    </author>
    <link href="http://arxiv.org/abs/2502.10831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.10831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.10451v1</id>
    <updated>2025-03-13T15:16:57Z</updated>
    <published>2025-03-13T15:16:57Z</published>
    <title>The Willing Kingdon Clifford Algebra Library</title>
    <summary>  Kingdon is an open-source Python package designed to seamlessly integrate
Geometric Algebra (GA) into existing workflows. Unlike previous GA libraries,
kingdon is input-type-agnostic, and hence supports GA's over e.g. PyTorch
tensors, NumPy arrays, or SymPy symbolic expressions, to name but a few.
Despite this refusal to specialize, it delivers high performance by
symbolically optimizing operators and leveraging input sparsity for
Just-In-Time compiled expressions. Additionally, its visualization capabilities
in Jupyter notebooks using ganja align with the rapid prototyping workflow
common to scientific research.
</summary>
    <author>
      <name>Martin Roelfs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.10451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.10451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.04137v1</id>
    <updated>2025-05-07T05:24:14Z</updated>
    <published>2025-05-07T05:24:14Z</published>
    <title>optHIM: Hybrid Iterative Methods for Continuous Optimization in PyTorch</title>
    <summary>  We introduce optHIM, an open-source library of continuous unconstrained
optimization algorithms implemented in PyTorch for both CPU and GPU. By
leveraging PyTorch's autograd, optHIM seamlessly integrates function, gradient,
and Hessian information into flexible line-search and trust-region methods. We
evaluate eleven state-of-the-art variants on benchmark problems spanning convex
and non-convex landscapes. Through a suite of quantitative metrics and
qualitative analyses, we demonstrate each method's strengths and trade-offs.
optHIM aims to democratize advanced optimization by providing a transparent,
extensible, and efficient framework for research and education.
</summary>
    <author>
      <name>Nikhil Sridhar</name>
    </author>
    <author>
      <name>Sajiv Shah</name>
    </author>
    <link href="http://arxiv.org/abs/2505.04137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.04137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.05542v1</id>
    <updated>2025-05-08T16:55:14Z</updated>
    <published>2025-05-08T16:55:14Z</published>
    <title>A Common Interface for Automatic Differentiation</title>
    <summary>  For scientific machine learning tasks with a lot of custom code, picking the
right Automatic Differentiation (AD) system matters. Our Julia package
DifferentiationInterface$.$jl provides a common frontend to a dozen AD
backends, unlocking easy comparison and modular development. In particular, its
built-in preparation mechanism leverages the strengths of each backend by
amortizing one-time computations. This is key to enabling sophisticated
features like sparsity handling without putting additional burdens on the user.
</summary>
    <author>
      <name>Guillaume Dalle</name>
    </author>
    <author>
      <name>Adrian Hill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures, 3 listings, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.05542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.05542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504039v1</id>
    <updated>2005-04-11T16:39:16Z</updated>
    <published>2005-04-11T16:39:16Z</published>
    <title>TeXmacs-maxima interface</title>
    <summary>  This tutorial presents features of the new and improved TeXmacs-maxima
interface. It is designed for running maxima-5.9.2 from TeXmacs-1.0.5 (or
later).
</summary>
    <author>
      <name>A. G. Grozin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">html file, 32 png screenshots</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0504039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702010v1</id>
    <updated>2007-02-01T17:54:50Z</updated>
    <published>2007-02-01T17:54:50Z</published>
    <title>A canonical form for some piecewise defined functions</title>
    <summary>  We define a canonical form for piecewise defined functions. We show that this
has a wider range of application as well as better complexity properties than
previous work.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to ISSAC 2007</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.3689v2</id>
    <updated>2013-02-12T19:44:27Z</updated>
    <published>2010-03-18T22:56:57Z</published>
    <title>A Highly Efficient Parallel Algorithm for Computing the Fiedler Vector</title>
    <summary>  This paper has been withdrawn by the author.
</summary>
    <author>
      <name>Murat Manguoglu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author because it is under
  revision</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.3689v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.3689v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1556v1</id>
    <updated>2014-06-06T01:46:54Z</updated>
    <published>2014-06-06T01:46:54Z</published>
    <title>Enhancements to ACL2 in Versions 6.2, 6.3, and 6.4</title>
    <summary>  We report on improvements to ACL2 made since the 2013 ACL2 Workshop.
</summary>
    <author>
      <name>Matt Kaufmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UT Austin</arxiv:affiliation>
    </author>
    <author>
      <name>J Strother Moore</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UT Austin</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.152.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.152.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ACL2 2014, arXiv:1406.1238</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 152, 2014, pp. 1-7</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.1556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7030v1</id>
    <updated>2014-12-22T15:47:51Z</updated>
    <published>2014-12-22T15:47:51Z</published>
    <title>Proceedings of the 7th European Conference on Python in Science
  (EuroSciPy 2014)</title>
    <summary>  These are the proceedings of the 7th European Conference on Python in
Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).
</summary>
    <author>
      <name>Pierre de Buyl</name>
    </author>
    <author>
      <name>Nelle Varoquaux</name>
    </author>
    <link href="http://arxiv.org/abs/1412.7030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.08162v1</id>
    <updated>2017-12-21T08:20:43Z</updated>
    <published>2017-12-21T08:20:43Z</published>
    <title>A C++ interface to QCDNUM</title>
    <summary>  In this document we report on the recent development of a C++ interface to
the FORTRAN-based evolution program QCDNUM. A short description of the
interface is given with a few basic examples of its usage.
</summary>
    <author>
      <name>Valerio Bertone</name>
    </author>
    <author>
      <name>Michiel Botje</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.08162v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.08162v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.12427v1</id>
    <updated>2019-03-29T10:00:47Z</updated>
    <published>2019-03-29T10:00:47Z</published>
    <title>Computing huge Groebner basis like cyclic10 over $\Q$ with Giac</title>
    <summary>  We present a short description on how to fine-tune the modular algorithm
implemented in the Giac computer algebra system to reconstruct huge Groebner
basis over $\Q$.The classical cyclic10 benchmark will serve as example.
</summary>
    <author>
      <name>Bernard Parisse</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1903.12427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.12427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5526v1</id>
    <updated>2013-06-24T07:33:16Z</updated>
    <published>2013-06-24T07:33:16Z</published>
    <title>Programs in C++ for matrix computations in min plus algebra</title>
    <summary>  The main purpose of this paper is to propose six programs in C++ for matrix
computations and solving recurrent equations systems with entries in min plus
algebra.
</summary>
    <author>
      <name>Mihai Ivan</name>
    </author>
    <author>
      <name>Gheorghe Ivan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">73 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A80, 68-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.16161v1</id>
    <updated>2024-10-31T16:31:26Z</updated>
    <published>2024-10-31T16:31:26Z</published>
    <title>Antiassociative algebra in R: introducing the evitaicossa package</title>
    <summary>  In this short article I introduce the evitaicossa package which provides
functionality for antiassociative algebras in the R programming language; it is
available on CRAN at https://CRAN.R-project.org/package=evitaicossa.
</summary>
    <author>
      <name>Robin K. S. Hankinn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2412.16161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.16161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612126v1</id>
    <updated>2006-12-22T19:19:41Z</updated>
    <published>2006-12-22T19:19:41Z</published>
    <title>The virtual reality framework for engineering objects</title>
    <summary>  A framework for virtual reality of engineering objects has been developed.
This framework may simulate different equipment related to virtual reality.
Framework supports 6D dynamics, ordinary differential equations, finite
formulas, vector and matrix operations. The framework also supports embedding
of external software.
</summary>
    <author>
      <name>Petr R. Ivankov</name>
    </author>
    <author>
      <name>Nikolay P. Ivankov</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0612126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3208v1</id>
    <updated>2009-02-18T17:59:47Z</updated>
    <published>2009-02-18T17:59:47Z</published>
    <title>A Fast Multigrid Algorithm for Energy Minimization Under Planar Density
  Constraints</title>
    <summary>  The two-dimensional layout optimization problem reinforced by the efficient
space utilization demand has a wide spectrum of practical applications.
Formulating the problem as a nonlinear minimization problem under planar
equality and/or inequality density constraints, we present a linear time
multigrid algorithm for solving correction to this problem. The method is
demonstrated on various graph drawing (visualization) instances.
</summary>
    <author>
      <name>Dorit Ron</name>
    </author>
    <author>
      <name>Ilya Safro</name>
    </author>
    <author>
      <name>Achi Brandt</name>
    </author>
    <link href="http://arxiv.org/abs/0902.3208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.1272v3</id>
    <updated>2013-03-13T18:13:53Z</updated>
    <published>2009-06-06T12:44:23Z</published>
    <title>The alternative operad is not Koszul</title>
    <summary>  Using computer calculations, we prove the statement in the title.
</summary>
    <author>
      <name>Askar Dzhumadil'daev</name>
    </author>
    <author>
      <name>Pasha Zusmanovich</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/10586458.2011.544558 10.1080/10586458.2012.738538</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/10586458.2011.544558" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.1080/10586458.2012.738538" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v3: added corrigendum</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Experiment. Math. 20 (2011), 138-144; Corrigendum: 21 (2012), 418</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.1272v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.1272v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="17D05, 17D15, 05A05, 16N40, 16S37, 17-04, 18D50, 65F99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3091v2</id>
    <updated>2014-10-14T05:09:35Z</updated>
    <published>2009-08-21T10:37:52Z</published>
    <title>Computational Understanding and Manipulation of Symmetries</title>
    <summary>  For natural and artificial systems with some symmetry structure,
computational understanding and manipulation can be achieved without learning
by exploiting the algebraic structure. Here we describe this algebraic
coordinatization method and apply it to permutation puzzles. Coordinatization
yields a structural understanding, not just solutions for the puzzles.
</summary>
    <author>
      <name>Attila Egri-Nagy</name>
    </author>
    <author>
      <name>Chrystopher L. Nehaniv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, v2 major revision of computational examples</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.3091v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3091v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="20B40" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4950v2</id>
    <updated>2010-08-26T13:30:08Z</updated>
    <published>2009-09-27T16:54:34Z</published>
    <title>Implementing Gröbner bases for operads</title>
    <summary>  We present an implementation of the algorithm for computing Groebner bases
for operads due to the first author and A. Khoroshkin. We discuss the actual
algorithms, the choices made for the implementation platform and the data
representation, and strengths and weaknesses of our approach.
</summary>
    <author>
      <name>Vladimir Dotsenko</name>
    </author>
    <author>
      <name>Mikael Vejdemo-Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.4950v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4950v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.QA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5192v1</id>
    <updated>2010-03-26T17:32:10Z</updated>
    <published>2010-03-26T17:32:10Z</published>
    <title>wiki.openmath.org - how it works, how you can participate</title>
    <summary>  At http://wiki.openmath.org, the OpenMath 2 and 3 Content Dictionaries are
accessible via a semantic wiki interface, powered by the SWiM system. We
shortly introduce the inner workings of the system, then describe how to use
it, and conclude with first experiences gained from OpenMath society members
working with the system and an outlook to further development plans.
</summary>
    <author>
      <name>Christoph Lange</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">OpenMath workshop 2009 (http://staff.bath.ac.uk/masjhd/OM2009.html)</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T35, 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.m; H.3.5; H.5.3; H.5.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.1548v3</id>
    <updated>2013-05-08T14:41:36Z</updated>
    <published>2011-08-07T15:09:34Z</published>
    <title>Some Software Packages for Partial SVD Computation</title>
    <summary>  This technical report introduces some software packages for partial SVD
computation, including optimized PROPACK, modified PROPACK for computing
singular values above a threshold and the corresponding singular vectors, and
block Lanczos with warm start (BLWS). The current version is preliminary. The
details will be enriched soon.
</summary>
    <author>
      <name>Zhouchen Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1108.1548v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.1548v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.2263v1</id>
    <updated>2011-10-11T04:03:22Z</updated>
    <published>2011-10-11T04:03:22Z</published>
    <title>Asymptotic Methods of ODEs: Exploring Singularities of the Second Kind</title>
    <summary>  We develop symbolic methods of asymptotic approximations for solutions of
linear ordinary differential equations and use to them stabilize numerical
calculations. Our method follows classical analysis for first-order systems and
higher-order scalar equations where growth behavior is expressed in terms of
elementary functions. We then recast our equations in mollified form - thereby
obtaining stability.
</summary>
    <author>
      <name>Christopher J. Winfield</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.2263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.2263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34E05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4061v2</id>
    <updated>2012-04-24T07:27:24Z</updated>
    <published>2012-02-18T06:49:39Z</published>
    <title>Implementation of a Unimodularity Test</title>
    <summary>  This paper describes implementation and computational results of a polynomial
test of total unimodularity. The test is a simplified version of a prior
method. The program also decides two related unimodularity properties. The
software is available free of charge in source code form under the Boost
Software License.
</summary>
    <author>
      <name>Matthias Walter</name>
    </author>
    <author>
      <name>Klaus Truemper</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, minor reformulations</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4061v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4061v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80 (Primary), 90C57 (Secondary), 52B40 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.1; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.3761v2</id>
    <updated>2013-05-14T07:51:31Z</updated>
    <published>2013-03-15T13:03:40Z</published>
    <title>Update report: LEO-II version 1.5</title>
    <summary>  Recent improvements of the LEO-II theorem prover are presented. These
improvements include a revised ATP interface, new translations into first-order
logic, rule support for the axiom of choice, detection of defined equality, and
more flexible strategy scheduling.
</summary>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <author>
      <name>Nik Sultana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.3761v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.3761v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03B35, 68T15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.3; F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6899v1</id>
    <updated>2013-04-25T12:59:31Z</updated>
    <published>2013-04-25T12:59:31Z</published>
    <title>An implementation of the relational k-means algorithm</title>
    <summary>  A C# implementation of a generalized k-means variant called relational
k-means is described here. Relational k-means is a generalization of the
well-known k-means clustering method which works for non-Euclidean scenarios as
well. The input is an arbitrary distance matrix, as opposed to the traditional
k-means method, where the clustered objects need to be identified with vectors.
</summary>
    <author>
      <name>Balázs Szalkai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0622v1</id>
    <updated>2014-02-04T05:52:47Z</updated>
    <published>2014-02-04T05:52:47Z</published>
    <title>Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition</title>
    <summary>  We present a divide-and-conquer version of the Cylindrical Algebraic
Decomposition (CAD) algorithm. The algorithm represents the input as a Boolean
combination of subformulas, computes cylindrical algebraic decompositions of
solution sets of the subformulas, and combines the results. We propose a
graph-based heuristic to find a suitable partitioning of the input and present
empirical comparison with direct CAD computation.
</summary>
    <author>
      <name>Adam Strzebonski</name>
    </author>
    <link href="http://arxiv.org/abs/1402.0622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5086v1</id>
    <updated>2014-02-20T17:34:49Z</updated>
    <published>2014-02-20T17:34:49Z</published>
    <title>Symmetric QR Algorithm with Permutations</title>
    <summary>  In this paper, we present the QR Algorithm with Permutations that shows an
improved convergence rate compared to the classical QR algorithm. We determine
a bound for performance based on best instantaneous convergence, and develop
low complexity methods for computing the permutation matrices at every
iteration. We use simulations to verify the improvement, and to compare the
performance of proposed algorithms to the classical QR algorithm.
</summary>
    <author>
      <name>Aravindh Krishnamoorthy</name>
    </author>
    <link href="http://arxiv.org/abs/1402.5086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6924v2</id>
    <updated>2018-11-05T07:59:45Z</updated>
    <published>2014-06-26T15:35:00Z</published>
    <title>Strongly stable ideals and Hilbert polynomials</title>
    <summary>  The \texttt{StronglyStableIdeals} package for \textit{Macaulay2} provides a
method to compute all saturated strongly stable ideals in a given polynomial
ring with a fixed Hilbert polynomial. A description of the main method and
auxiliary tools is given.
</summary>
    <author>
      <name>Davide Alberelli</name>
    </author>
    <author>
      <name>Paolo Lella</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2140/jsag.2019.9.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2140/jsag.2019.9.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Source code available as an ancillary file. Final version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Softw. Alg. Geom. 9 (2019) 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.6924v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6924v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="13P10, 13P99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2905v1</id>
    <updated>2014-07-10T19:08:32Z</updated>
    <published>2014-07-10T19:08:32Z</published>
    <title>Run-time extensibility and librarization of simulation software</title>
    <summary>  Build-time configuration and environment assumptions are hampering progress
and usability in scientific software. That which would be utterly unacceptable
in non-scientific software somehow passes for the norm in scientific packages.
The community needs reusable software packages that are easy use and flexible
enough to accommodate next-generation simulation and analysis demands.
</summary>
    <author>
      <name>Jed Brown</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06017v2</id>
    <updated>2021-05-25T23:20:24Z</updated>
    <published>2016-03-18T23:53:10Z</published>
    <title>Automatic Theorem Proving in Walnut</title>
    <summary>  Walnut is a software package that implements a mechanical decision procedure
for deciding certain combinatorial properties of some special words referred to
as automatic words or automatic sequences. Walnut is written in Java and is
open source. It is licensed under GNU General Public License.
</summary>
    <author>
      <name>Hamoon Mousavi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added a few more sections</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06017v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06017v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.08713v1</id>
    <updated>2016-10-27T11:14:53Z</updated>
    <published>2016-10-27T11:14:53Z</published>
    <title>The Probabilistic Model Checker Storm (Extended Abstract)</title>
    <summary>  We present a new probabilistic model checker Storm. Using state-of-the-art
libraries, we aim for both high performance and versatility. This extended
abstract gives a brief overview of the features of Storm.
</summary>
    <author>
      <name>Christian Dehnert</name>
    </author>
    <author>
      <name>Sebastian Junges</name>
    </author>
    <author>
      <name>Joost-Pieter Katoen</name>
    </author>
    <author>
      <name>Matthias Volk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.08713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.08713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05778v1</id>
    <updated>2016-12-17T14:54:52Z</updated>
    <published>2016-12-17T14:54:52Z</published>
    <title>Parallel Integer Polynomial Multiplication</title>
    <summary>  We propose a new algorithm for multiplying dense polynomials with integer
coefficients in a parallel fashion, targeting multi-core processor
architectures. Complexity estimates and experimental comparisons demonstrate
the advantages of this new approach.
</summary>
    <author>
      <name>Changbo Chen</name>
    </author>
    <author>
      <name>Svyatoslav Covanov</name>
    </author>
    <author>
      <name>Farnam Mansouri</name>
    </author>
    <author>
      <name>Marc Moreno Maza</name>
    </author>
    <author>
      <name>Ning Xie</name>
    </author>
    <author>
      <name>Yuzhen Xie</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00722v1</id>
    <updated>2017-01-02T23:21:43Z</updated>
    <published>2017-01-02T23:21:43Z</published>
    <title>The Unum Number Format: Mathematical Foundations, Implementation and
  Comparison to IEEE 754 Floating-Point Numbers</title>
    <summary>  This thesis examines a modern concept for machine numbers based on interval
arithmetic called 'Unums' and compares it to IEEE 754 floating-point
arithmetic, evaluating possible uses of this format where floating-point
numbers are inadequate. In the course of this examination, this thesis builds
theoretical foundations for IEEE 754 floating-point numbers, interval
arithmetic based on the projectively extended real numbers and Unums.
</summary>
    <author>
      <name>Laslo Hunhold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">95 pages, 7 figures, 14 code listings</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.00722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05788v1</id>
    <updated>2017-08-19T00:43:04Z</updated>
    <published>2017-08-19T00:43:04Z</published>
    <title>Computer Algebra for Microhydrodynamics</title>
    <summary>  I describe a method for computer algebra that helps with laborious
calculations typically encountered in theoretical microhydrodynamics. The
program mimics how humans calculate by matching patterns and making
replacements according to the rules of algebra and calculus. This note gives an
overview and walks through an example, while the accompanying code repository
contains the implementation details, a tutorial, and more examples. The code
repository is attached as supplementary material to this note, and maintained
at https://github.com/jeinarsson/matte
</summary>
    <author>
      <name>Jonas Einarsson</name>
    </author>
    <link href="http://arxiv.org/abs/1708.05788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08018v1</id>
    <updated>2017-09-23T08:00:31Z</updated>
    <published>2017-09-23T08:00:31Z</published>
    <title>A new indexed approach to render the attractors of Kleinian groups</title>
    <summary>  One widespread procedure to render the attractor of Kleinian groups,
published in the renown book "Indra's Pearls" and based upon a combinatorial
tree model, wants huge memory resources to compute and store all the words
required. We will present here a new faster and lighter version which drops the
original words array and pulls out words from integer numbers.
</summary>
    <author>
      <name>Alessandro Rosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.08018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.09108v1</id>
    <updated>2017-09-26T16:11:43Z</updated>
    <published>2017-09-26T16:11:43Z</published>
    <title>Tensors Come of Age: Why the AI Revolution will help HPC</title>
    <summary>  This article discusses how the automation of tensor algorithms, based on A
Mathematics of Arrays and Psi Calculus, and a new way to represent numbers,
Unum Arithmetic, enables mechanically provable, scalable, portable, and more
numerically accurate software.
</summary>
    <author>
      <name>John L. Gustafson</name>
    </author>
    <author>
      <name>Lenore M. Mullin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in this years 30th anniversary edition of HPCwire</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.09108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.09108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.00826v1</id>
    <updated>2018-01-02T20:35:23Z</updated>
    <published>2018-01-02T20:35:23Z</published>
    <title>ruptures: change point detection in Python</title>
    <summary>  ruptures is a Python library for offline change point detection. This package
provides methods for the analysis and segmentation of non-stationary signals.
Implemented algorithms include exact and approximate detection for various
parametric and non-parametric models. ruptures focuses on ease of use by
providing a well-documented and consistent interface. In addition, thanks to
its modular structure, different algorithms and models can be connected and
extended within this package.
</summary>
    <author>
      <name>Charles Truong</name>
    </author>
    <author>
      <name>Laurent Oudre</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <link href="http://arxiv.org/abs/1801.00826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.00826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08252v1</id>
    <updated>2018-02-22T14:29:30Z</updated>
    <published>2018-02-22T14:29:30Z</published>
    <title>The iisignature library: efficient calculation of iterated-integral
  signatures and log signatures</title>
    <summary>  Iterated-integral signatures and log signatures are vectors calculated from a
path that characterise its shape. They come from the theory of differential
equations driven by rough paths, and also have applications in statistics and
machine learning. We present algorithms for efficiently calculating these
signatures, and benchmark their performance. We release the methods as a Python
package.
</summary>
    <author>
      <name>Jeremy Reizenstein</name>
    </author>
    <author>
      <name>Benjamin Graham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.08252v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08252v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.01592v1</id>
    <updated>2018-03-05T10:33:50Z</updated>
    <published>2018-03-05T10:33:50Z</published>
    <title>OpenMath and SMT-LIB</title>
    <summary>  OpenMath and SMT-LIB are languages with very different origins, but both
"represent mathematics". We describe SMT-LIB for the OpenMath community and
consider adaptations for both languages to support the growing SC-Square
initiative.
</summary>
    <author>
      <name>James H. Davenport</name>
    </author>
    <author>
      <name>Matthew England</name>
    </author>
    <author>
      <name>Roberto Sebastiani</name>
    </author>
    <author>
      <name>Patrick Trentin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented in the OpenMath 2017 Workshop, at CICM 2017, Edinburgh, UK</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.01592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.01592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.02883v1</id>
    <updated>2018-06-07T19:42:58Z</updated>
    <published>2018-06-07T19:42:58Z</published>
    <title>Generalized Polylogarithms in Maple</title>
    <summary>  This paper describes generalized polylogarithms, multiple polylogarithms, and
multiple zeta values, along with their implementation in Maple 2018. This set
of related functions is of interest in high energy physics as well as in number
theory. Algorithms for the analytical manipulation and numerical evaluation of
these functions are described, along with the way these features are
implemented in Maple.
</summary>
    <author>
      <name>Hjalte Frellesvig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.02883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.02883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.06725v1</id>
    <updated>2018-06-18T14:19:18Z</updated>
    <published>2018-06-18T14:19:18Z</published>
    <title>Numerical Evaluation of Elliptic Functions, Elliptic Integrals and
  Modular Forms</title>
    <summary>  We describe algorithms to compute elliptic functions and their relatives
(Jacobi theta functions, modular forms, elliptic integrals, and the
arithmetic-geometric mean) numerically to arbitrary precision with rigorous
error bounds for arbitrary complex variables. Implementations in ball
arithmetic are available in the open source Arb library. We discuss the
algorithms from a concrete implementation point of view, with focus on
performance at tens to thousands of digits of precision.
</summary>
    <author>
      <name>Fredrik Johansson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LFANT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1806.06725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.06725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.03122v1</id>
    <updated>2021-03-03T10:31:44Z</updated>
    <published>2021-03-03T10:31:44Z</published>
    <title>Machine Learning using Stata/Python</title>
    <summary>  We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting
popular Machine Learning (ML) methods both in regression and classification
settings. Using the recent Stata/Python integration platform (sfi) of Stata 16,
these commands provide hyper-parameters' optimal tuning via K-fold
cross-validation using greed search. More specifically, they make use of the
Python Scikit-learn API to carry out both cross-validation and outcome/label
prediction.
</summary>
    <author>
      <name>Giovanni Cerulli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Machine Learning, Stata, Python, Optimal tuning</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.03122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.03122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.11615v2</id>
    <updated>2021-07-05T03:21:00Z</updated>
    <published>2021-03-22T06:54:32Z</published>
    <title>A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra
  Computation</title>
    <summary>  We propose a functional implementation of \emph{Multivariate Tower Automatic
Differentiation}. Our implementation is intended to be used in implementing
$C^\infty$-structure computation of an arbitrary Weil algebra, which we
discussed in the previous work.
</summary>
    <author>
      <name>Hiromi Ishii</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Algebra - Theory and its Applications,RIMS K\^oky\^uroku,
  No.2185 (2021). pp.104-112</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2103.11615v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.11615v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.06807v1</id>
    <updated>2021-11-12T16:38:49Z</updated>
    <published>2021-11-12T16:38:49Z</published>
    <title>Verified Optimization</title>
    <summary>  Optimization is used extensively in engineering, industry, and finance, and
various methods are used to transform problems to the point where they are
amenable to solution by numerical methods. We describe progress towards
developing a framework, based on the Lean interactive proof assistant, for
designing and applying such reductions in reliable and flexible ways.
</summary>
    <author>
      <name>Alexander Bentkamp</name>
    </author>
    <author>
      <name>Jeremy Avigad</name>
    </author>
    <link href="http://arxiv.org/abs/2111.06807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.06807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4662v1</id>
    <updated>2012-10-17T08:09:08Z</updated>
    <published>2012-10-17T08:09:08Z</published>
    <title>A New Recursive Algorithm For Inverting A General Comrade Matrix</title>
    <summary>  In this paper, the author present a reliable symbolic computational algorithm
for inverting a general comrade matrix by using parallel computing along with
recursion. The computational cost of our algorithm is O(n^2). The algorithm is
implementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and
MATHEMATICA. Three examples are presented for the sake of illustration.
</summary>
    <author>
      <name>A. A. Karawia</name>
    </author>
    <link href="http://arxiv.org/abs/1210.4662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A15, 15A23, 68W30, 11Y05, 33F10, F.2.1, G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1036v1</id>
    <updated>2013-06-05T09:53:29Z</updated>
    <published>2013-06-05T09:53:29Z</published>
    <title>swMATH - a new information service for mathematical software</title>
    <summary>  An information service for mathematical software is presented. Publications
and software are two closely connected facets of mathematical knowledge. This
relation can be used to identify mathematical software and find relevant
information about it. The approach and the state of the art of the information
service are described here.
</summary>
    <author>
      <name>Sebastian Bönisch</name>
    </author>
    <author>
      <name>Michael Brickenstein</name>
    </author>
    <author>
      <name>Hagen Chrapary</name>
    </author>
    <author>
      <name>Gert-Martin Greuel</name>
    </author>
    <author>
      <name>Wolfram Sperber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">see also: http://www.swmath.org</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.1036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.07097v1</id>
    <updated>2020-10-14T13:53:54Z</updated>
    <published>2020-10-14T13:53:54Z</published>
    <title>CAPD::DynSys: a flexible C++ toolbox for rigorous numerical analysis of
  dynamical systems</title>
    <summary>  We present the CAPD::DynSys library for rigorous numerical analysis of
dynamical systems. The basic interface is described together with several
interesting case studies illustrating how it can be used for computer-assisted
proofs in dynamics of ODEs.
</summary>
    <author>
      <name>Tomasz Kapela</name>
    </author>
    <author>
      <name>Marian Mrozek</name>
    </author>
    <author>
      <name>Daniel Wilczak</name>
    </author>
    <author>
      <name>Piotr Zgliczyński</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cnsns.2020.105578</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cnsns.2020.105578" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 4 figures, 11 full C++ examples</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.07097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.07097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.01678v1</id>
    <updated>2022-01-05T16:06:49Z</updated>
    <published>2022-01-05T16:06:49Z</published>
    <title>Comparison of methods for the calculation of the real dilogarithm
  regarding instruction-level parallelism</title>
    <summary>  We compare different methods for the computation of the real dilogarithm
regarding their ability for using instruction-level parallelism when executed
on appropriate CPUs. As a result we present an instruction-level-aware method
and compare it to existing implementations.
</summary>
    <author>
      <name>Alexander Voigt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.01678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.01678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="33-04, 33E20, 33F05, 65D20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.14314v3</id>
    <updated>2024-11-16T09:20:17Z</updated>
    <published>2022-08-30T14:52:44Z</published>
    <title>Cardinal Optimizer (COPT) User Guide</title>
    <summary>  Cardinal Optimizer is a high-performance mathematical programming solver for
efficiently solving largescale optimization problem. This documentation
provides basic introduction to the Cardinal Optimizer.
</summary>
    <author>
      <name>Dongdong Ge</name>
    </author>
    <author>
      <name>Qi Huangfu</name>
    </author>
    <author>
      <name>Zizhuo Wang</name>
    </author>
    <author>
      <name>Jian Wu</name>
    </author>
    <author>
      <name>Yinyu Ye</name>
    </author>
    <link href="http://arxiv.org/abs/2208.14314v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.14314v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.07693v1</id>
    <updated>2022-10-14T10:35:54Z</updated>
    <published>2022-10-14T10:35:54Z</published>
    <title>Designing a general library for convolutions</title>
    <summary>  We will discuss our experiences and design decisions obtained from building a
formal library for the convolution of two functions. Convolution is a
fundamental concept with applications throughout mathematics. We will focus on
the design decisions we made to make the convolution general and easy to use,
and the incorporation of this development in Lean's mathematical library
mathlib.
</summary>
    <author>
      <name>Floris van Doorn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, submitted to CPP 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.07693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.07693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68V20, 42A85, 44A35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.11409v1</id>
    <updated>2022-10-19T10:24:17Z</updated>
    <published>2022-10-19T10:24:17Z</published>
    <title>Development of information system suited for statistical analysis of
  global brands distributions</title>
    <summary>  This qualification work studies methods of statistical analysis of global
brands distributions and development process of information system which is
represented by computer program. Algorithm of estimation of correspondance to
distribution laws was shown. Correspondance of datasets (3) to Pareto Law and
Zipf's Law were defined.
  Key words: analysis, method, distribution, data, function, statistics,
solution, program.
</summary>
    <author>
      <name>Vladyslav Solohub</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, in Ukranian language, 24 figures. Specialty 122 Computer
  science. Vasyl' Stus Donetsk National University, Vinnytsia, 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.11409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.11409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.03170v1</id>
    <updated>2023-04-05T10:39:39Z</updated>
    <published>2023-04-05T10:39:39Z</published>
    <title>Spectral Toolkit of Algorithms for Graphs: Technical Report (1)</title>
    <summary>  Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user's guide to STAG, showcase
studies, and several technical considerations behind our development.
</summary>
    <author>
      <name>Peter Macgregor</name>
    </author>
    <author>
      <name>He Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2304.03170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.03170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.05244v2</id>
    <updated>2024-07-08T13:54:29Z</updated>
    <published>2023-08-09T22:31:17Z</published>
    <title>Hybrid approach to the joint spectral radius computation</title>
    <summary>  In this paper we propose a modification to the invariant polytope algorithm
(ipa) using ideas of the finite expressible tree algorithm (feta) by M\"oller
and Reif. We show that our new feta-flavoured-ipa applies to a wider range of
matrix families.
</summary>
    <author>
      <name>Thomas Mejstrik</name>
    </author>
    <author>
      <name>Ulrich Reif</name>
    </author>
    <link href="http://arxiv.org/abs/2308.05244v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.05244v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A18 15A60 15-04 90C90" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.08080v1</id>
    <updated>2024-01-16T03:13:02Z</updated>
    <published>2024-01-16T03:13:02Z</published>
    <title>Approximations of the integral of a class of sinusoidal composite
  functions</title>
    <summary>  Two approximations of the integral of a class of sinusoidal composite
functions, for which an explicit form does not exist, are derived. Numerical
experiments show that the proposed approximations yield an error that does not
depend on the width of the integration interval. Using such approximations,
definite integrals can be computed in almost real-time.
</summary>
    <author>
      <name>Alberto Costa</name>
    </author>
    <link href="http://arxiv.org/abs/2401.08080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.08080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.00065v1</id>
    <updated>2024-05-30T11:24:11Z</updated>
    <published>2024-05-30T11:24:11Z</published>
    <title>Parallel Redundancy Removal in lrslib with Application to Projections</title>
    <summary>  We describe a parallel implementation in lrslib for removing redundant
halfspaces and finding a minimum representation for an H-representation of a
convex polyhedron. By a standard transformation, the same code works for
V-representations. We use this approach to speed up the redundancy removal step
in Fourier-Motzkin elimination. Computational results are given including a
comparison with Clarkson's algorithm, which is particularly fast on highly
redundant inputs.
</summary>
    <author>
      <name>David Avis</name>
    </author>
    <author>
      <name>Charles Jordan</name>
    </author>
    <link href="http://arxiv.org/abs/2406.00065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.00065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.13434v1</id>
    <updated>2024-08-24T02:12:31Z</updated>
    <published>2024-08-24T02:12:31Z</published>
    <title>The applicability of equal area partitions of the unit sphere</title>
    <summary>  This paper addresses the idea of the applicability of mathematics, using, as
a case study, a construction and software package that partition the unit
sphere into regions of equal area. The paper assesses the applicability of this
construction and software by examining citing works, including papers,
dissertations and software.
</summary>
    <author>
      <name>Paul Leopardi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 24 figures, accepted by Journal of Approximation Software</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.13434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.13434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="41-02, 65-02, 65D15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.09053v2</id>
    <updated>2024-12-12T18:54:49Z</updated>
    <published>2024-09-18T06:59:39Z</published>
    <title>Fast Symbolic Integer-Linear Spectra</title>
    <summary>  Here we contribute a fast symbolic eigenvalue solver for matrices whose
eigenvalues are $\mathbb{Z}$-linear combinations of their entries, alongside
efficient general and stochastic $M^{X}$ generators. Users can interact with a
few degrees of freedom to create linear operators, making high-dimensional
symbolic analysis feasible for when numerical analyses are insufficient.
</summary>
    <author>
      <name>Jonny Luntzel</name>
    </author>
    <author>
      <name>Abraham Miller</name>
    </author>
    <link href="http://arxiv.org/abs/2410.09053v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.09053v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.09764v1</id>
    <updated>2024-10-13T07:41:44Z</updated>
    <published>2024-10-13T07:41:44Z</published>
    <title>Adaptive finite element methods based on flux and stress equilibration
  using FEniCSx</title>
    <summary>  This contribution shows how a-posteriori error estimators based on
equilibrated fluxes - H(div) functions fulfilling the underlying conservation
law - can be implemented in FEniCSx. Therefore, dolfinx_eqlb is introduced, its
algorithmic structure is described and classical benchmarks for adaptive
solution procedures for the Poisson problem and linear elasticity are
presented.
</summary>
    <author>
      <name>Maximilian Brodbeck</name>
    </author>
    <author>
      <name>Fleurianne Bertrand</name>
    </author>
    <author>
      <name>Tim Ricken</name>
    </author>
    <link href="http://arxiv.org/abs/2410.09764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.09764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.11355v1</id>
    <updated>2025-03-14T12:44:11Z</updated>
    <published>2025-03-14T12:44:11Z</published>
    <title>TypedMatrices.jl: An Extensible and Type-Based Matrix Collection for
  Julia</title>
    <summary>  TypedMatrices.jl is a Julia package to organize test matrices. By default,
the package comes with a number of built-in matrices and interfaces to help
users select test cases based on their properties. The package is designed to
be extensible, allowing users to define their own matrix types. We discuss the
design and implementation of the package and demonstrate its usage with a
number of examples.
</summary>
    <author>
      <name>Anzhi Zhang</name>
    </author>
    <author>
      <name>Massimiliano Fasi</name>
    </author>
    <link href="http://arxiv.org/abs/2503.11355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.11355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809009v1</id>
    <updated>1998-09-02T19:27:07Z</updated>
    <published>1998-09-02T19:27:07Z</published>
    <title>Developing numerical libraries in Java</title>
    <summary>  The rapid and widespread adoption of Java has created a demand for reliable
and reusable mathematical software components to support the growing number of
compute-intensive applications now under development, particularly in science
and engineering. In this paper we address practical issues of the Java language
and environment which have an effect on numerical library design and
development. Benchmarks which illustrate the current levels of performance of
key numerical kernels on a variety of Java platforms are presented. Finally, a
strategy for the development of a fundamental numerical toolkit for Java is
proposed and its current status is described.
</summary>
    <author>
      <name>Ronald F. Boisvert</name>
    </author>
    <author>
      <name>Jack J. Dongarra</name>
    </author>
    <author>
      <name>Roldan Pozo</name>
    </author>
    <author>
      <name>Karin Remington</name>
    </author>
    <author>
      <name>G. W. Stewart</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages. Revised version of paper presented to the 1998 ACM
  Conference on Java for High Performance Network Computing. To appear in
  Concurrency: Practice and Experience</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9912021v2</id>
    <updated>2000-06-11T16:24:10Z</updated>
    <published>1999-12-31T18:36:38Z</published>
    <title>Seeing the Forest in the Tree: Applying VRML to Mathematical Problems in
  Number Theory</title>
    <summary>  We show how VRML (Virtual Reality Modeling Language) can provide potentially
powerful insight into the 3x + 1 problem via the introduction of a unique
geometrical object, called the 'G-cell', akin to a fractal generator. We
present an example of a VRML world developed programmatically with the G-cell.
The role of VRML as a tool for furthering the understanding the 3x+1 problem is
potentially significant for several reasons: a) VRML permits the observer to
zoom into the geometric structure at all scales (up to limitations of the
computing platform). b) VRML enables rotation to alter comparative visual
perspective (similar to Tukey's data-spinning concept). c) VRML facilitates the
demonstration of interesting tree features between collaborators on the
internet who might otherwise have difficulty conveying their ideas
unambiguously. d) VRML promises to reveal any dimensional dependencies among
3x+1 sequences.
</summary>
    <author>
      <name>Neil J. Gunther</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.373461</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.373461" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. Published in Proc. IEEE-SPIE 2000 12th International
  Symposium on Internet Imaging. Condensed online abstract. Extended discusson
  in sections 3.1 and 3.2; edited section 5; edited references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. IEEE-SPIE 2000 12th International Symposium on Internet
  Imaging</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9912021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9912021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2;G.4;H.5.1;I.3.2;I.3.7;I.6.8;I.7.2;J.2;K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106051v1</id>
    <updated>2001-06-25T19:30:10Z</updated>
    <published>2001-06-25T19:30:10Z</published>
    <title>Users Guide for SnadiOpt: A Package Adding Automatic Differentiation to
  Snopt</title>
    <summary>  SnadiOpt is a package that supports the use of the automatic differentiation
package ADIFOR with the optimization package Snopt. Snopt is a general-purpose
system for solving optimization problems with many variables and constraints.
It minimizes a linear or nonlinear function subject to bounds on the variables
and sparse linear or nonlinear constraints. It is suitable for large-scale
linear and quadratic programming and for linearly constrained optimization, as
well as for general nonlinear programs. The method used by Snopt requires the
first derivatives of the objective and constraint functions to be available.
The SnadiOpt package allows users to avoid the time-consuming and error-prone
process of evaluating and coding these derivatives. Given Fortran code for
evaluating only the values of the objective and constraints, SnadiOpt
automatically generates the code for evaluating the derivatives and builds the
relevant Snopt input files and sparse data structures.
</summary>
    <author>
      <name>E. Michael Gertz</name>
    </author>
    <author>
      <name>Philip E. Gill</name>
    </author>
    <author>
      <name>Julia Muetherig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pages i-iv, 1-23</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0106051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107025v2</id>
    <updated>2001-10-30T16:11:45Z</updated>
    <published>2001-07-19T13:18:31Z</published>
    <title>Computer validated proofs of a toolset for adaptable arithmetic</title>
    <summary>  Most existing implementations of multiple precision arithmetic demand that
the user sets the precision {\em a priori}. Some libraries are said adaptable
in the sense that they dynamically change the precision of each intermediate
operation individually to deliver the target accuracy according to the actual
inputs. We present in this text a new adaptable numeric core inspired both from
floating point expansions and from on-line arithmetic.
  The numeric core is cut down to four tools. The tool that contains arithmetic
operations is proved to be correct. The proofs have been formally checked by
the Coq assistant. Developing the proofs, we have formally proved many results
published in the literature and we have extended a few of them. This work may
let users (i) develop application specific adaptable libraries based on the
toolset and / or (ii) write new formal proofs based on the set of validated
facts.
</summary>
    <author>
      <name>Sylvie Boldo</name>
    </author>
    <author>
      <name>Marc Daumas</name>
    </author>
    <author>
      <name>Claire Moreau-Finot</name>
    </author>
    <author>
      <name>Laurent Thery</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, web links</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0107025v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107025v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306127v1</id>
    <updated>2003-06-24T12:37:26Z</updated>
    <published>2003-06-24T12:37:26Z</published>
    <title>Development of a Java Package for Matrix Programming</title>
    <summary>  We had assembled a Java package, known as MatrixPak, of four classes for the
purpose of numerical matrix computation. The classes are matrix,
matrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited
from java.lang.Object class. Class matrix defines a matrix as a two-dimensional
array of float types, and contains the following mathematical methods:
transpose, adjoint, determinant, inverse, minor and cofactor. Class
matrix_operations contains the following mathematical methods: matrix addition,
matrix subtraction, matrix multiplication, and matrix exponential. Class
StrToMatrix contains methods necessary to parse a string representation (for
example, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class
MatrixToStr does the reverse.
</summary>
    <author>
      <name>Ngee-Peng Lim</name>
    </author>
    <author>
      <name>Maurice HT Ling</name>
    </author>
    <author>
      <name>Shawn YC Lim</name>
    </author>
    <author>
      <name>Ji-Hee Choi</name>
    </author>
    <author>
      <name>Henry BK Teo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Secondary school (high school) student project report. Foundation for
  JMaths project</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.0; G.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307009v1</id>
    <updated>2003-07-04T13:15:09Z</updated>
    <published>2003-07-04T13:15:09Z</published>
    <title>Finding the "truncated" polynomial that is closest to a function</title>
    <summary>  When implementing regular enough functions (e.g., elementary or special
functions) on a computing system, we frequently use polynomial approximations.
In most cases, the polynomial that best approximates (for a given distance and
in a given interval) a function has coefficients that are not exactly
representable with a finite number of bits. And yet, the polynomial
approximations that are actually implemented do have coefficients that are
represented with a finite - and sometimes small - number of bits: this is due
to the finiteness of the floating-point representations (for software
implementations), and to the need to have small, hence fast and/or inexpensive,
multipliers (for hardware implementations). We then have to consider polynomial
approximations for which the degree-$i$ coefficient has at most $m_i$
fractional bits (in other words, it is a rational number with denominator
$2^{m_i}$). We provide a general method for finding the best polynomial
approximation under this constraint. Then, we suggest refinements than can be
used to accelerate our method.
</summary>
    <author>
      <name>Nicolas Brisebarre</name>
    </author>
    <author>
      <name>Jean-Michel Muller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0, G.1.2, B.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0401008v1</id>
    <updated>2004-01-13T14:29:26Z</updated>
    <published>2004-01-13T14:29:26Z</published>
    <title>Algorithm xxx: Modified Bessel functions of imaginary order and positive
  argument</title>
    <summary>  Fortran 77 programs for the computation of modified Bessel functions of
purely imaginary order are presented. The codes compute the functions
$K_{ia}(x)$, $L_{ia}(x)$ and their derivatives for real $a$ and positive $x$;
these functions are independent solutions of the differential equation $x^2 w''
+x w' +(a^2 -x^2)w=0$. The code also computes exponentially scaled functions.
The range of computation is $(x,a)\in (0,1500]\times [-1500,1500]$ when scaled
functions are considered and it is larger than $(0,500]\times [-400,400]$ for
standard IEEE double precision arithmetic. The relative accuracy is better than
$10^{-13}$ in the range $(0,200]\times [-200,200]$ and close to $10^{-12}$ in
$(0,1500]\times [-1500,1500]$.
</summary>
    <author>
      <name>Amparo Gil</name>
    </author>
    <author>
      <name>Javier Segura</name>
    </author>
    <author>
      <name>Nico M. Temme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures. To appear in ACM T. Math. Software</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0401008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0401008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410044v5</id>
    <updated>2005-12-09T13:19:43Z</updated>
    <published>2004-10-18T17:39:51Z</published>
    <title>An Example of Clifford Algebras Calculations with GiNaC</title>
    <summary>  This example of Clifford algebras calculations uses GiNaC
(http://www.ginac.de/) library, which includes a support for generic Clifford
algebra starting from version~1.3.0. Both symbolic and numeric calculation are
possible and can be blended with other functions of GiNaC. This calculations
was made for the paper math.CV/0410399.
  Described features of GiNaC are already available at PyGiNaC
(http://sourceforge.net/projects/pyginac/) and due to course should propagate
into other software like GNU Octave (http://www.octave.org/), gTybalt
(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as
their back-end.
</summary>
    <author>
      <name>Vladimir V. Kisil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, LaTeX2e, 12 PS graphics in one figure; v3 code
  improvements; v4 small code correction for new libraries; v5 comments are
  redesined to be more readable</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Applied Clifford Algebras, 15(2005), no. 2, pp.
  239-269</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410044v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410044v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503014v1</id>
    <updated>2005-03-04T19:20:04Z</updated>
    <published>2005-03-04T19:20:04Z</published>
    <title>ADF95: Tool for automatic differentiation of a FORTRAN code designed for
  large numbers of independent variables</title>
    <summary>  ADF95 is a tool to automatically calculate numerical first derivatives for
any mathematical expression as a function of user defined independent
variables. Accuracy of derivatives is achieved within machine precision. ADF95
may be applied to any FORTRAN 77/90/95 conforming code and requires minimal
changes by the user. It provides a new derived data type that holds the value
and derivatives and applies forward differencing by overloading all FORTRAN
operators and intrinsic functions. An efficient indexing technique leads to a
reduced memory usage and a substantially increased performance gain over other
available tools with operator overloading. This gain is especially pronounced
for sparse systems with large number of independent variables. A wide class of
numerical simulations, e.g., those employing implicit solvers, can profit from
ADF95.
</summary>
    <author>
      <name>Christian W. Straka</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2005.01.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2005.01.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 2 figures, 4 tables, accepted in Computer Physics
  Communications</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0503014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.5; G1.7; G1.8; G.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512056v1</id>
    <updated>2005-12-14T09:54:01Z</updated>
    <published>2005-12-14T09:54:01Z</published>
    <title>PURRS: Towards Computer Algebra Support for Fully Automatic Worst-Case
  Complexity Analysis</title>
    <summary>  Fully automatic worst-case complexity analysis has a number of applications
in computer-assisted program manipulation. A classical and powerful approach to
complexity analysis consists in formally deriving, from the program syntax, a
set of constraints expressing bounds on the resources required by the program,
which are then solved, possibly applying safe approximations. In several
interesting cases, these constraints take the form of recurrence relations.
While techniques for solving recurrences are known and implemented in several
computer algebra systems, these do not completely fulfill the needs of fully
automatic complexity analysis: they only deal with a somewhat restricted class
of recurrence relations, or sometimes require user intervention, or they are
restricted to the computation of exact solutions that are often so complex to
be unmanageable, and thus useless in practice. In this paper we briefly
describe PURRS, a system and software library aimed at providing all the
computer algebra services needed by applications performing or exploiting the
results of worst-case complexity analyses. The capabilities of the system are
illustrated by means of examples derived from the analysis of programs written
in a domain-specific functional programming language for real-time embedded
systems.
</summary>
    <author>
      <name>Roberto Bagnara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Parma</arxiv:affiliation>
    </author>
    <author>
      <name>Andrea Pescetti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Parma</arxiv:affiliation>
    </author>
    <author>
      <name>Alessandro Zaccagnini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Parma</arxiv:affiliation>
    </author>
    <author>
      <name>Enea Zaffanella</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Parma</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0512056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0602005v1</id>
    <updated>2006-02-03T18:29:52Z</updated>
    <published>2006-02-03T18:29:52Z</published>
    <title>A library of Taylor models for PVS automatic proof checker</title>
    <summary>  We present in this paper a library to compute with Taylor models, a technique
extending interval arithmetic to reduce decorrelation and to solve differential
equations. Numerical software usually produces only numerical results. Our
library can be used to produce both results and proofs. As seen during the
development of Fermat's last theorem reported by Aczel 1996, providing a proof
is not sufficient. Our library provides a proof that has been thoroughly
scrutinized by a trustworthy and tireless assistant. PVS is an automatic proof
assistant that has been fairly developed and used and that has no internal
connection with interval arithmetic or Taylor models. We built our library so
that PVS validates each result as it is produced. As producing and validating a
proof, is and will certainly remain a bigger task than just producing a
numerical result our library will never be a replacement to imperative
implementations of Taylor models such as Cosy Infinity. Our library should
mainly be used to validate small to medium size results that are involved in
safety or life critical applications.
</summary>
    <author>
      <name>Francisco Cháves</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM, LP2A</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0602005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0602005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603005v4</id>
    <updated>2008-10-20T04:52:26Z</updated>
    <published>2006-03-01T14:29:19Z</published>
    <title>A Basic Introduction on Math-Link in Mathematica</title>
    <summary>  Starting from the basic ideas of mathematica, we give a detailed description
about the way of linking of external programs with mathematica through proper
mathlink commands. This article may be quite helpful for the beginners to start
with and write programs in mathematica.
  In the first part, we illustrate how to use a mathemtica notebook and write a
complete program in the notebook. Following with this, we also mention
elaborately about the utility of the local and global variables those are very
essential for writing a program in mathematica. All the commands needed for
doing different mathematical operations can be found with some proper examples
in the mathematica book written by Stephen Wolfram \cite{wolfram}.
  In the rest of this article, we concentrate our study on the most significant
issue which is the process of linking of {\em external programs} with
mathematica, so-called the mathlink operation. By using proper mathlink
commands one can run very tedious jobs efficiently and the operations become
extremely fast.
</summary>
    <author>
      <name>Santanu K. Maiti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603005v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603005v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606101v4</id>
    <updated>2006-12-19T17:10:57Z</updated>
    <published>2006-06-23T08:26:56Z</published>
    <title>Stochastic Formal Methods: An application to accuracy of numeric
  software</title>
    <summary>  This paper provides a bound on the number of numeric operations (fixed or
floating point) that can safely be performed before accuracy is lost. This work
has important implications for control systems with safety-critical software,
as these systems are now running fast enough and long enough for their errors
to impact on their functionality. Furthermore, worst-case analysis would
blindly advise the replacement of existing systems that have been successfully
running for years. We present here a set of formal theorems validated by the
PVS proof assistant. These theorems will allow code analyzing tools to produce
formal certificates of accurate behavior. For example, FAA regulations for
aircraft require that the probability of an error be below $10^{-9}$ for a 10
hour flight.
</summary>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM, Lp2a</arxiv:affiliation>
    </author>
    <author>
      <name>David Lester</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A, University of Manchester</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0606101v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606101v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610110v4</id>
    <updated>2009-02-24T13:26:33Z</updated>
    <published>2006-10-18T19:57:11Z</published>
    <title>Stochastic Formal Methods for Hybrid Systems</title>
    <summary>  We provide a framework to bound the probability that accumulated errors were
never above a given threshold on hybrid systems. Such systems are used for
example to model an aircraft or a nuclear power plant on one side and its
software on the other side. This report contains simple formulas based on
L\'evy's and Markov's inequalities and it presents a formal theory of random
variables with a special focus on producing concrete results. We selected four
very common applications that fit in our framework and cover the common
practices of hybrid systems that evolve for a long time. We compute the number
of bits that remain continuously significant in the first two applications with
a probability of failure around one against a billion, where worst case
analysis considers that no significant bit remains. We are using PVS as such
formal tools force explicit statement of all hypotheses and prevent incorrect
uses of theorems.
</summary>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ELIAUS</arxiv:affiliation>
    </author>
    <author>
      <name>David Lester</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Manchester</arxiv:affiliation>
    </author>
    <author>
      <name>Erik Martin-Dorel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ELIAUS, Lamps</arxiv:affiliation>
    </author>
    <author>
      <name>Annick Truffert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAMPS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0610110v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610110v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612085v1</id>
    <updated>2006-12-18T10:15:38Z</updated>
    <published>2006-12-18T10:15:38Z</published>
    <title>The Parma Polyhedra Library: Toward a Complete Set of Numerical
  Abstractions for the Analysis and Verification of Hardware and Software
  Systems</title>
    <summary>  Since its inception as a student project in 2001, initially just for the
handling (as the name implies) of convex polyhedra, the Parma Polyhedra Library
has been continuously improved and extended by joining scrupulous research on
the theoretical foundations of (possibly non-convex) numerical abstractions to
a total adherence to the best available practices in software development. Even
though it is still not fully mature and functionally complete, the Parma
Polyhedra Library already offers a combination of functionality, reliability,
usability and performance that is not matched by similar, freely available
libraries. In this paper, we present the main features of the current version
of the library, emphasizing those that distinguish it from other similar
libraries and those that are important for applications in the field of
analysis and verification of hardware and software systems.
</summary>
    <author>
      <name>Roberto Bagnara</name>
    </author>
    <author>
      <name>Patricia M. Hill</name>
    </author>
    <author>
      <name>Enea Zaffanella</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 2 figures, 3 listings, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0612085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701186v2</id>
    <updated>2007-05-24T11:57:26Z</updated>
    <published>2007-01-29T15:36:47Z</published>
    <title>Certification of bounds on expressions involving rounded operators</title>
    <summary>  Gappa uses interval arithmetic to certify bounds on mathematical expressions
that involve rounded as well as exact operators. Gappa generates a theorem with
its proof for each bound treated. The proof can be checked with a higher order
logic automatic proof checker, either Coq or HOL Light, and we have developed a
large companion library of verified facts for Coq dealing with the addition,
multiplication, division, and square root, in fixed- and floating-point
arithmetics. Gappa uses multiple-precision dyadic fractions for the endpoints
of intervals and performs forward error analysis on rounded operators when
necessary. When asked, Gappa reports the best bounds it is able to reach for a
given expression in a given context. This feature is used to quickly obtain
coarse bounds. It can also be used to identify where the set of facts and
automatic techniques implemented in Gappa becomes insufficient. Gappa handles
seamlessly additional properties expressed as interval properties or rewriting
rules in order to establish more intricate bounds. Recent work showed that
Gappa is perfectly suited to the proof of correctness of small pieces of
software. Proof obligations can be written by designers, produced by
third-party tools or obtained by overloading arithmetic operators.
</summary>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM, LP2A</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Melquiond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP, INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0701186v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701186v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703025v1</id>
    <updated>2007-03-06T14:05:28Z</updated>
    <published>2007-03-06T14:05:28Z</published>
    <title>LIBOPT - An environment for testing solvers on heterogeneous collections
  of problems - Version 1.0</title>
    <summary>  The Libopt environment is both a methodology and a set of tools that can be
used for testing, comparing, and profiling solvers on problems belonging to
various collections. These collections can be heterogeneous in the sense that
their problems can have common features that differ from one collection to the
other. Libopt brings a unified view on this composite world by offering, for
example, the possibility to run any solver on any problem compatible with it,
using the same Unix/Linux command. The environment also provides tools for
comparing the results obtained by solvers on a specified set of problems. Most
of the scripts going with the Libopt environment have been written in Perl.
</summary>
    <author>
      <name>Jean Charles Gilbert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Xavier Jonsson</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0703025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.2347v5</id>
    <updated>2009-05-18T13:49:23Z</updated>
    <published>2007-07-16T16:02:50Z</published>
    <title>Memory efficient scheduling of Strassen-Winograd's matrix multiplication
  algorithm</title>
    <summary>  We propose several new schedules for Strassen-Winograd's matrix
multiplication algorithm, they reduce the extra memory allocation requirements
by three different means: by introducing a few pre-additions, by overwriting
the input matrices, or by using a first recursive level of classical
multiplication. In particular, we show two fully in-place schedules: one having
the same number of operations, if the input matrices can be overwritten; the
other one, slightly increasing the constant of the leading term of the
complexity, if the input matrices are read-only. Many of these schedules have
been found by an implementation of an exhaustive search algorithm based on a
pebble game.
</summary>
    <author>
      <name>Brice Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Guillaume Dumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Clément Pernet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Wei Zhou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Symbolic Computation Group</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(International Symposium on Symbolic and Algebraic Computation
  2009), S\'eoul : Cor\'ee, R\'epublique de (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.2347v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.2347v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3721v1</id>
    <updated>2007-08-28T07:14:29Z</updated>
    <published>2007-08-28T07:14:29Z</published>
    <title>Verified Real Number Calculations: A Library for Interval Arithmetic</title>
    <summary>  Real number calculations on elementary functions are remarkably difficult to
handle in mechanical proofs. In this paper, we show how these calculations can
be performed within a theorem prover or proof assistant in a convenient and
highly automated as well as interactive way. First, we formally establish upper
and lower bounds for elementary functions. Then, based on these bounds, we
develop a rational interval arithmetic where real number calculations take
place in an algebraic setting. In order to reduce the dependency effect of
interval arithmetic, we integrate two techniques: interval splitting and taylor
series expansions. This pragmatic approach has been developed, and formally
verified, in a theorem prover. The formal development also includes a set of
customizable strategies to automate proofs involving explicit calculations over
real numbers. Our ultimate goal is to provide guaranteed proofs of numerical
properties with minimal human theorem-prover interaction.
</summary>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM, Eliaus</arxiv:affiliation>
    </author>
    <author>
      <name>David Lester</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UNIVERSITY of Manchester</arxiv:affiliation>
    </author>
    <author>
      <name>César Muñoz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NIA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0708.3721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3722v1</id>
    <updated>2007-08-28T07:15:08Z</updated>
    <published>2007-08-28T07:15:08Z</published>
    <title>Formally Verified Argument Reduction with a Fused-Multiply-Add</title>
    <summary>  Cody &amp; Waite argument reduction technique works perfectly for reasonably
large arguments but as the input grows there are no bit left to approximate the
constant with enough accuracy. Under mild assumptions, we show that the result
computed with a fused-multiply-add provides a fully accurate result for many
possible values of the input with a constant almost accurate to the full
working precision. We also present an algorithm for a fully accurate second
reduction step to reach double full accuracy (all the significand bits of two
numbers are significant) even in the worst cases of argument reduction. Our
work recalls the common algorithms and presents proofs of correctness. All the
proofs are formally verified using the Coq automatic proof checker.
</summary>
    <author>
      <name>Sylvie Boldo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Daumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM, Eliaus</arxiv:affiliation>
    </author>
    <author>
      <name>Ren Cang Li</name>
    </author>
    <link href="http://arxiv.org/abs/0708.3722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.1272v3</id>
    <updated>2008-06-12T18:09:13Z</updated>
    <published>2007-09-09T16:32:46Z</published>
    <title>A Class of Parallel Tiled Linear Algebra Algorithms for Multicore
  Architectures</title>
    <summary>  As multicore systems continue to gain ground in the High Performance
Computing world, linear algebra algorithms have to be reformulated or new
algorithms have to be developed in order to take advantage of the architectural
features on these new processors. Fine grain parallelism becomes a major
requirement and introduces the necessity of loose synchronization in the
parallel execution of an operation. This paper presents an algorithm for the
Cholesky, LU and QR factorization where the operations can be represented as a
sequence of small tasks that operate on square blocks of data. These tasks can
be dynamically scheduled for execution based on the dependencies among them and
on the availability of computational resources. This may result in an out of
order execution of the tasks which will completely hide the presence of
intrinsically sequential tasks in the factorization. Performance comparisons
are presented with the LAPACK algorithms where parallelism can only be
exploited at the level of the BLAS operations and vendor implementations.
</summary>
    <author>
      <name>Alfredo Buttari</name>
    </author>
    <author>
      <name>Julien Langou</name>
    </author>
    <author>
      <name>Jakub Kurzak</name>
    </author>
    <author>
      <name>Jack Dongarra</name>
    </author>
    <link href="http://arxiv.org/abs/0709.1272v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.1272v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.4444v2</id>
    <updated>2007-11-29T09:09:27Z</updated>
    <published>2007-11-28T08:04:18Z</published>
    <title>Building the Tangent and Adjoint codes of the Ocean General Circulation
  Model OPA with the Automatic Differentiation tool TAPENADE</title>
    <summary>  The ocean general circulation model OPA is developed by the LODYC team at
Paris VI university. OPA has recently undergone a major rewriting, migrating to
FORTRAN95, and its adjoint code needs to be rebuilt. For earlier versions, the
adjoint of OPA was written by hand at a high development cost. We use the
Automatic Differentiation tool TAPENADE to build mechanicaly the tangent and
adjoint codes of OPA. We validate the differentiated codes by comparison with
divided differences, and also with an identical twin experiment. We apply
state-of-the-art methods to improve the performance of the adjoint code. In
particular we implement the Griewank and Walther's binomial checkpointing
algorithm which gives us an optimal trade-off between time and memory
consumption. We apply a specific strategy to differentiate the iterative linear
solver that comes from the implicit time stepping scheme
</summary>
    <author>
      <name>Moulay Hicham Tber</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Hascoet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis, SEMA</arxiv:affiliation>
    </author>
    <author>
      <name>Arthur Vidard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LJK Laboratoire Jean Kuntzmann</arxiv:affiliation>
    </author>
    <author>
      <name>Benjamin Dauvergne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0711.4444v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.4444v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.0754v1</id>
    <updated>2008-08-06T01:05:09Z</updated>
    <published>2008-08-06T01:05:09Z</published>
    <title>A Functional Hitchhiker's Guide to Hereditarily Finite Sets, Ackermann
  Encodings and Pairing Functions</title>
    <summary>  The paper is organized as a self-contained literate Haskell program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The code, tested under GHC
6.6.1, is available at http://logic.csci.unt.edu/tarau/research/2008/fSET.zip .
  We introduce ranking and unranking functions generalizing Ackermann's
encoding to the universe of Hereditarily Finite Sets with Urelements. Then we
build a lazy enumerator for Hereditarily Finite Sets with Urelements that
matches the unranking function provided by the inverse of Ackermann's encoding
and we describe functors between them resulting in arithmetic encodings for
powersets, hypergraphs, ordinals and choice functions. After implementing a
digraph representation of Hereditarily Finite Sets we define {\em decoration
functions} that can recover well-founded sets from encodings of their
associated acyclic digraphs. We conclude with an encoding of arbitrary digraphs
and discuss a concept of duality induced by the set membership relation.
  Keywords: hereditarily finite sets, ranking and unranking functions,
executable set theory, arithmetic encodings, Haskell data representations,
functional programming and computational mathematics
</summary>
    <author>
      <name>Paul Tarau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">unpublished draft</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.0754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.0754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.2794v1</id>
    <updated>2008-08-20T17:50:36Z</updated>
    <published>2008-08-20T17:50:36Z</published>
    <title>Accelerating Scientific Computations with Mixed Precision Algorithms</title>
    <summary>  On modern architectures, the performance of 32-bit operations is often at
least twice as fast as the performance of 64-bit operations. By using a
combination of 32-bit and 64-bit floating point arithmetic, the performance of
many dense and sparse linear algebra algorithms can be significantly enhanced
while maintaining the 64-bit accuracy of the resulting solution. The approach
presented here can apply not only to conventional processors but also to other
technologies such as Field Programmable Gate Arrays (FPGA), Graphical
Processing Units (GPU), and the STI Cell BE processor. Results on modern
processor architectures and the STI Cell BE are presented.
</summary>
    <author>
      <name>Marc Baboulin</name>
    </author>
    <author>
      <name>Alfredo Buttari</name>
    </author>
    <author>
      <name>Jack Dongarra</name>
    </author>
    <author>
      <name>Jakub Kurzak</name>
    </author>
    <author>
      <name>Julie Langou</name>
    </author>
    <author>
      <name>Julien Langou</name>
    </author>
    <author>
      <name>Piotr Luszczek</name>
    </author>
    <author>
      <name>Stanimire Tomov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2008.11.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2008.11.005" rel="related"/>
    <link href="http://arxiv.org/abs/0808.2794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.2794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.1714v1</id>
    <updated>2008-11-11T14:23:49Z</updated>
    <published>2008-11-11T14:23:49Z</published>
    <title>Efficient Multiplication of Dense Matrices over GF(2)</title>
    <summary>  We describe an efficient implementation of a hierarchy of algorithms for
multiplication of dense matrices over the field with two elements (GF(2)). In
particular we present our implementation -- in the M4RI library -- of
Strassen-Winograd matrix multiplication and the "Method of the Four Russians"
multiplication (M4RM) and compare it against other available implementations.
Good performance is demonstrated on on AMD's Opteron and particulary good
performance on Intel's Core 2 Duo. The open-source M4RI library is available
stand-alone as well as part of the Sage mathematics software.
  In machine terms, addition in GF(2) is logical-XOR, and multiplication is
logical-AND, thus a machine word of 64-bits allows one to operate on 64
elements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions
or multiplications. As such, element-wise operations over GF(2) are relatively
cheap. In fact, in this paper, we conclude that the actual bottlenecks are
memory reads and writes and issues of data locality. We present our empirical
findings in relation to minimizing these and give an analysis thereof.
</summary>
    <author>
      <name>Martin Albrecht</name>
    </author>
    <author>
      <name>Gregory Bard</name>
    </author>
    <author>
      <name>William Hart</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1644001.1644010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1644001.1644010" rel="related"/>
    <link href="http://arxiv.org/abs/0811.1714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.1714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3088v1</id>
    <updated>2009-02-18T10:28:45Z</updated>
    <published>2009-02-18T10:28:45Z</published>
    <title>Automatic generation of non-uniform random variates for arbitrary
  pointwise computable probability densities by tiling</title>
    <summary>  We present a rejection method based on recursive covering of the probability
density function with equal tiles. The concept works for any probability
density function that is pointwise computable or representable by tabular data.
By the implicit construction of piecewise constant majorizing and minorizing
functions that are arbitrarily close to the density function the production of
random variates is arbitrarily independent of the computation of the density
function and extremely fast. The method works unattended for probability
densities with discontinuities (jumps and poles). The setup time is short,
marginally independent of the shape of the probability density and linear in
table size. Recently formulated requirements to a general and automatic
non-uniform random number generator are topped. We give benchmarks together
with a similar rejection method and with a transformation method.
</summary>
    <author>
      <name>Daniel Fulger</name>
    </author>
    <author>
      <name>Guido Germano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 3 figures, submitted to a peer-reviewed journal</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.3088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3207v1</id>
    <updated>2009-02-18T17:53:36Z</updated>
    <published>2009-02-18T17:53:36Z</published>
    <title>Random numbers from the tails of probability distributions using the
  transformation method</title>
    <summary>  The speed of many one-line transformation methods for the production of, for
example, Levy alpha-stable random numbers, which generalize Gaussian ones, and
Mittag-Leffler random numbers, which generalize exponential ones, is very high
and satisfactory for most purposes. However, for the class of decreasing
probability densities fast rejection implementations like the Ziggurat by
Marsaglia and Tsang promise a significant speed-up if it is possible to
complement them with a method that samples the tails of the infinite support.
This requires the fast generation of random numbers greater or smaller than a
certain value. We present a method to achieve this, and also to generate random
numbers within any arbitrary interval. We demonstrate the method showing the
properties of the transform maps of the above mentioned distributions as
examples of stable and geometric stable random numbers used for the stochastic
solution of the space-time fractional diffusion equation.
</summary>
    <author>
      <name>Daniel Fulger</name>
    </author>
    <author>
      <name>Enrico Scalas</name>
    </author>
    <author>
      <name>Guido Germano</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2478/s13540-013-0021-z</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2478/s13540-013-0021-z" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures, submitted to a peer-reviewed journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fractional Calculus and Applied Analysis 16 (2), 332-353, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.3207v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3207v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4152v1</id>
    <updated>2009-04-27T13:00:36Z</updated>
    <published>2009-04-27T13:00:36Z</published>
    <title>HONEI: A collection of libraries for numerical computations targeting
  multiple processor architectures</title>
    <summary>  We present HONEI, an open-source collection of libraries offering a hardware
oriented approach to numerical calculations. HONEI abstracts the hardware, and
applications written on top of HONEI can be executed on a wide range of
computer architectures such as CPUs, GPUs and the Cell processor. We
demonstrate the flexibility and performance of our approach with two test
applications, a Finite Element multigrid solver for the Poisson problem and a
robust and fast simulation of shallow water waves. By linking against HONEI's
libraries, we achieve a twofold speedup over straight forward C++ code using
HONEI's SSE backend, and additional 3-4 and 4-16 times faster execution on the
Cell and a GPU. A second important aspect of our approach is that the full
performance capabilities of the hardware under consideration can be exploited
by adding optimised application-specific operations to the HONEI libraries.
HONEI provides all necessary infrastructure for development and evaluation of
such kernels, significantly simplifying their development.
</summary>
    <author>
      <name>Danny van Dyk</name>
    </author>
    <author>
      <name>Markus Geveler</name>
    </author>
    <author>
      <name>Sven Mallach</name>
    </author>
    <author>
      <name>Dirk Ribbrock</name>
    </author>
    <author>
      <name>Dominik Goeddeke</name>
    </author>
    <author>
      <name>Carsten Gutwenger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2009.04.018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2009.04.018" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 180(12), pp. 2534-2543, December
  2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.4152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0586v1</id>
    <updated>2009-05-05T12:04:12Z</updated>
    <published>2009-05-05T12:04:12Z</published>
    <title>WinBioinfTools: Bioinformatics Tools for Windows High Performance
  Computing Server 2008</title>
    <summary>  Open source bioinformatics tools running under MS Windows are rare to find,
and those running under Windows HPC cluster are almost non-existing. This is
despite the fact that the Windows is the most popular operating system used
among life scientists. Therefore, we introduce in this initiative
WinBioinfTools, a toolkit containing a number of bioinformatics tools running
under Windows High Performance Computing Server 2008. It is an open source code
package, where users and developers can share and add to. We currently start
with three programs from the area of sequence analysis: 1) CoCoNUT for pairwise
genome comparison, 2) parallel BLAST for biological database search, and 3)
parallel global pairwise sequence alignment. In this report, we focus on
technical aspects concerning how some components of these tools were ported
from Linux/Unix environment to run under Windows. We also show the advantages
of using the Windows HPC Cluster 2008. We demonstrate by experiments the
performance gain achieved when using a computer cluster against a single
machine. Furthermore, we show the results of comparing the performance of
WinBioinfTools on the Windows and Linux Cluster.
</summary>
    <author>
      <name>Mohamed Abouelhoda</name>
    </author>
    <author>
      <name>Hisham Mohamed</name>
    </author>
    <link href="http://arxiv.org/abs/0905.0586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0796v1</id>
    <updated>2009-07-04T20:38:39Z</updated>
    <published>2009-07-04T20:38:39Z</published>
    <title>Tensors and n-d Arrays:A Mathematics of Arrays (MoA), psi-Calculus and
  the Composition of Tensor and Array Operations</title>
    <summary>  The Kronecker product is a key algorithm and is ubiquitous across the
physical, biological, and computation social sciences. Thus considerations of
optimal implementation are important. The need to have high performance and
computational reproducibility is paramount. Moreover, due to the need to
compose multiple Kronecker products, issues related to data structures, layout
and indexing algebra require a new look at an old problem. This paper discusses
the outer product/tensor product and a special case of the tensor product: the
Kronecker product, along with optimal implementation when composed, and mapped
to complex processor/memory hierarchies. We discuss how the use of ``A
Mathematics of Arrays" (MoA), and the psi-Calculus, (a calculus of indexing
with shapes), provides optimal, verifiable, reproducible, scalable, and
portable implementations of both hardware and software.
</summary>
    <author>
      <name>Lenore M. Mullin</name>
    </author>
    <author>
      <name>James E. Raynolds</name>
    </author>
    <link href="http://arxiv.org/abs/0907.0796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4888v1</id>
    <updated>2009-09-26T18:52:59Z</updated>
    <published>2009-09-26T18:52:59Z</published>
    <title>Approximating Mathematical Semantic Web Services Using Approximation
  Formulas and Numerical Methods</title>
    <summary>  Mathematical semantic web services are very useful in practice, but only a
small number of research results are reported in this area. In this paper we
present a method of obtaining an approximation of a mathematical semantic web
service, from its semantic description, using existing mathematical semantic
web services, approximation formulas, and numerical methods techniques. We also
give a method for automatic comparison of two complexity functions. In
addition, we present a method for classifying the numerical methods
mathematical semantic web services from a library.
</summary>
    <author>
      <name>Andrei-Horia Mogos</name>
    </author>
    <author>
      <name>Mugurel Ionut Andreica</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The International Workshop on Multi-Agent Systems Technology and
  Semantics - MASTS 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 2, pp. 533-538, Bucharest, Romania, 26-29 May, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.4888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.3; H.3.5; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1845v1</id>
    <updated>2009-10-09T20:11:36Z</updated>
    <published>2009-10-09T20:11:36Z</published>
    <title>Parallel Computation of Finite Element Navier-Stokes codes using MUMPS
  Solver</title>
    <summary>  The study deals with the parallelization of 2D and 3D finite element based
Navier-Stokes codes using direct solvers. Development of sparse direct solvers
using multifrontal solvers has significantly reduced the computational time of
direct solution methods. Although limited by its stringent memory requirements,
multifrontal solvers can be computationally efficient. First the performance of
MUltifrontal Massively Parallel Solver (MUMPS) is evaluated for both 2D and 3D
codes in terms of memory requirements and CPU times. The scalability of both
Newton and modified Newton algorithms is tested.
</summary>
    <author>
      <name>Mandhapati P. Raju</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">"International Journal of Computer Science Issues, IJCSI, Volume 4,
  Issue 2, pp20-24, September 2009"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">M. P. Raju," Parallel Computation of Finite Element Navier-Stokes
  codes using MUMPS Solver",International Journal of Computer Science Issues,
  IJCSI, Volume 4, Issue 2, pp20-24, September 2009"</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.1845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.3398v1</id>
    <updated>2009-12-17T13:49:59Z</updated>
    <published>2009-12-17T13:49:59Z</published>
    <title>NetEvo: A computational framework for the evolution of dynamical complex
  networks</title>
    <summary>  NetEvo is a computational framework designed to help understand the evolution
of dynamical complex networks. It provides flexible tools for the simulation of
dynamical processes on networks and methods for the evolution of underlying
topological structures. The concept of a supervisor is used to bring together
both these aspects in a coherent way. It is the job of the supervisor to rewire
the network topology and alter model parameters such that a user specified
performance measure is minimised. This performance measure can make use of
current topological information and simulated dynamical output from the system.
Such an abstraction provides a suitable basis in which to study many
outstanding questions related to complex system design and evolution.
</summary>
    <author>
      <name>Thomas E. Gorochowski</name>
    </author>
    <author>
      <name>Mario di Bernardo</name>
    </author>
    <author>
      <name>Claire S. Grierson</name>
    </author>
    <link href="http://arxiv.org/abs/0912.3398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.3398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1435v9</id>
    <updated>2019-09-25T13:56:45Z</updated>
    <published>2010-01-09T18:26:00Z</published>
    <title>JBotSim, a Tool for Fast Prototyping of Distributed Algorithms in
  Dynamic Networks</title>
    <summary>  JBotSim is a java library that offers basic primitives for prototyping,
running, and visualizing distributed algorithms in dynamic networks. With
JBotSim, one can implement an idea in minutes and interact with it ({\it e.g.
}, add, move, or delete nodes) while it is running. JBotSim is well suited to
prepare live demonstrations of your algorithms to colleagues or students; it
can also be used to evaluate performance at the algorithmic level (number of
messages, number of rounds, etc.). Unlike most tools, JBotSim is not an
integrated environment. It is a lightweight library to be used in your program.
In this paper, we present an overview of its distinctive features and
architecture.
</summary>
    <author>
      <name>Arnaud Casteigts</name>
    </author>
    <author>
      <name>Rémi Laplace</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A shorter version appeared in SIMUTOOLS 2015. For up to date
  information and tutorials, visit http://jbotsim.io</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.1435v9" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1435v9" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4057v1</id>
    <updated>2010-02-22T06:11:41Z</updated>
    <published>2010-02-22T06:11:41Z</published>
    <title>Towards an Efficient Tile Matrix Inversion of Symmetric Positive
  Definite Matrices on Multicore Architectures</title>
    <summary>  The algorithms in the current sequential numerical linear algebra libraries
(e.g. LAPACK) do not parallelize well on multicore architectures. A new family
of algorithms, the tile algorithms, has recently been introduced. Previous
research has shown that it is possible to write efficient and scalable tile
algorithms for performing a Cholesky factorization, a (pseudo) LU
factorization, and a QR factorization. In this extended abstract, we attack the
problem of the computation of the inverse of a symmetric positive definite
matrix. We observe that, using a dynamic task scheduler, it is relatively
painless to translate existing LAPACK code to obtain a ready-to-be-executed
tile algorithm. However we demonstrate that non trivial compiler techniques
(array renaming, loop reversal and pipelining) need then to be applied to
further increase the parallelism of our application. We present preliminary
experimental results.
</summary>
    <author>
      <name>Emmanuel Agullo</name>
    </author>
    <author>
      <name>Henricus Bouwmeester</name>
    </author>
    <author>
      <name>Jack Dongarra</name>
    </author>
    <author>
      <name>Jakub Kurzak</name>
    </author>
    <author>
      <name>Julien Langou</name>
    </author>
    <author>
      <name>Lee Rosenberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, extended abstract submitted to VecPar10 on 12/11/09,
  notification of acceptance received on 02/05/10. See:
  http://vecpar.fe.up.pt/2010/</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.4057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1320v1</id>
    <updated>2010-05-08T05:14:00Z</updated>
    <published>2010-05-08T05:14:00Z</published>
    <title>The myth of equidistribution for high-dimensional simulation</title>
    <summary>  A pseudo-random number generator (RNG) might be used to generate w-bit random
samples in d dimensions if the number of state bits is at least dw. Some RNGs
perform better than others and the concept of equidistribution has been
introduced in the literature in order to rank different RNGs. We define what it
means for a RNG to be (d,w)-equidistributed, and then argue that
(d,w)-equidistribution is not necessarily a desirable property.
</summary>
    <author>
      <name>Richard P. Brent</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Based on material presented at a Workshop on High
  Dimensional Approximation held at the Australian National University,
  Canberra, 19 February 2007. For further details, see
  http://wwwmaths.anu.edu.au/~brent/pub/pub240.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C10 (Primary) 11K36, 11K38, 11K45 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4661v2</id>
    <updated>2013-04-21T23:19:28Z</updated>
    <published>2010-05-22T22:21:10Z</published>
    <title>Nonsingular Efficient Modeling of Rotations in 3-space using three
  components</title>
    <summary>  This article introduces yet another representation of rotations in 3-space.
The rotations form a 3-dimensional projective space, which fact has not been
exploited in Computer Science. We use the four affine patches of this
projective space to parametrize the rotations. This affine patch representation
is more compact than quaternions (which require 4 components for calculations),
encompasses the entire rotation group without singularities (unlike the Euler
angles and rotation vector approaches), and requires only ratios of linear or
quadratic polynomials for basic computations (unlike the Euler angles and
rotation vector approaches which require transcendental functions).
  As an example, we derive the differential equation for the integration of
angular velocity using this affine patch representation of rotations. We remark
that the complexity of this equation is the same as the corresponding
quaternion equation, but has advantages over the quaternion approach e.g.
renormalization to unit length is not required, and state space has no dead
directions.
</summary>
    <author>
      <name>Norman J. Goldstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, no figures, presented at ICIAM 2011, July 18-21, Vancouver,
  BC</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4661v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4661v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4762v1</id>
    <updated>2010-05-26T09:19:51Z</updated>
    <published>2010-05-26T09:19:51Z</published>
    <title>Adapting Mathematical Domain Reasoners</title>
    <summary>  Mathematical learning environments help students in mastering mathematical
knowledge. Mature environments typically offer thousands of interactive
exercises. Providing feedback to students solving interactive exercises
requires domain reasoners for doing the exercise-specific calculations. Since a
domain reasoner has to solve an exercise in the same way a student should solve
it, the structure of domain reasoners should follow the layered structure of
the mathematical domains. Furthermore, learners, teachers, and environment
builders have different requirements for adapting domain reasoners, such as
providing more details, disallowing or enforcing certain solutions, and
combining multiple mathematical domains in a new domain. In previous work we
have shown how domain reasoners for solving interactive exercises can be
expressed in terms of rewrite strategies, rewrite rules, and views. This paper
shows how users can adapt and configure such domain reasoners to their own
needs. This is achieved by enabling users to explicitly communicate the
components that are used for solving an exercise.
</summary>
    <author>
      <name>Bastiaan Heeren</name>
    </author>
    <author>
      <name>Johan Jeuring</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in The 9th International Conference on Mathematical
  Knowledge Management: MKM 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4973v3</id>
    <updated>2012-03-21T08:12:08Z</updated>
    <published>2010-05-27T01:06:54Z</published>
    <title>Variants of Mersenne Twister Suitable for Graphic Processors</title>
    <summary>  This paper proposes a type of pseudorandom number generator, Mersenne Twister
for Graphic Processor (MTGP), for efficient generation on graphic processessing
units (GPUs). MTGP supports large state sizes such as 11213 bits, and uses the
high parallelism of GPUs in computing many steps of the recursion in parallel.
The second proposal is a parameter-set generator for MTGP, named MTGP Dynamic
Creator (MTGPDC). MT- GPDC creates up to 2^32 distinct parameter sets which
generate sequences with high-dimensional uniformity. This facility is suitable
for a large grid of GPUs where each GPU requires separate random number
streams. MTGP is based on linear recursion over the two-element field, and has
better high-dimensional equidistribution than the Mersenne Twister pseudorandom
number generator.
</summary>
    <author>
      <name>Mutsuo Saito</name>
    </author>
    <author>
      <name>Makoto Matsumoto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Transactions on Mathematical Software, 39 (2013), 12:1--12:20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4973v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4973v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0758v2</id>
    <updated>2011-06-10T20:34:59Z</updated>
    <published>2010-06-04T00:16:09Z</published>
    <title>LSMR: An iterative algorithm for sparse least-squares problems</title>
    <summary>  An iterative method LSMR is presented for solving linear systems $Ax=b$ and
least-squares problem $\min \norm{Ax-b}_2$, with $A$ being sparse or a fast
linear operator. LSMR is based on the Golub-Kahan bidiagonalization process. It
is analytically equivalent to the MINRES method applied to the normal equation
$A\T Ax = A\T b$, so that the quantities $\norm{A\T r_k}$ are monotonically
decreasing (where $r_k = b - Ax_k$ is the residual for the current iterate
$x_k$). In practice we observe that $\norm{r_k}$ also decreases monotonically.
Compared to LSQR, for which only $\norm{r_k}$ is monotonic, it is safer to
terminate LSMR early. Improvements for the new iterative method in the presence
of extra available memory are also explored.
</summary>
    <author>
      <name>David Fong</name>
    </author>
    <author>
      <name>Michael Saunders</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijheatmasstransfer.2011.12.029</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijheatmasstransfer.2011.12.029" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0758v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0758v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A06, 65F10, 65F20, 65F22, 65F25, 65F35, 65F50, 93E24" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.1744v1</id>
    <updated>2010-06-09T08:56:07Z</updated>
    <published>2010-06-09T08:56:07Z</published>
    <title>Efficient Decomposition of Dense Matrices over GF(2)</title>
    <summary>  In this work we describe an efficient implementation of a hierarchy of
algorithms for the decomposition of dense matrices over the field with two
elements (GF(2)). Matrix decomposition is an essential building block for
solving dense systems of linear and non-linear equations and thus much research
has been devoted to improve the asymptotic complexity of such algorithms. In
this work we discuss an implementation of both well-known and improved
algorithms in the M4RI library. The focus of our discussion is on a new variant
of the M4RI algorithm - denoted MMPF in this work -- which allows for
considerable performance gains in practice when compared to the previously
fastest implementation. We provide performance figures on x86_64 CPUs to
demonstrate the viability of our approach.
</summary>
    <author>
      <name>Martin R. Albrecht</name>
    </author>
    <author>
      <name>Clément Pernet</name>
    </author>
    <link href="http://arxiv.org/abs/1006.1744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.1744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3457v2</id>
    <updated>2011-03-01T14:38:07Z</updated>
    <published>2010-09-17T15:47:25Z</published>
    <title>How to obtain efficient GPU kernels: an illustration using FMM &amp; FGT
  algorithms</title>
    <summary>  Computing on graphics processors is maybe one of the most important
developments in computational science to happen in decades. Not since the
arrival of the Beowulf cluster, which combined open source software with
commodity hardware to truly democratize high-performance computing, has the
community been so electrified. Like then, the opportunity comes with
challenges. The formulation of scientific algorithms to take advantage of the
performance offered by the new architecture requires rethinking core methods.
Here, we have tackled fast summation algorithms (fast multipole method and fast
Gauss transform), and applied algorithmic redesign for attaining performance on
gpus. The progression of performance improvements attained illustrates the
exercise of formulating algorithms for the massively parallel architecture of
the gpu. The end result has been gpu kernels that run at over 500 Gigaflops on
one nvidia Tesla C1060 card, thereby reaching close to practical peak. We can
confidently say that gpu computing is not just a vogue, it is truly an
irresistible trend in high-performance computing.
</summary>
    <author>
      <name>Felipe A. Cruz</name>
    </author>
    <author>
      <name>Simon K. Layton</name>
    </author>
    <author>
      <name>Lorena A. Barba</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2011.05.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2011.05.002" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Commun., 182(10):2084-2098 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.3457v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3457v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.1386v1</id>
    <updated>2010-10-07T10:18:32Z</updated>
    <published>2010-10-07T10:18:32Z</published>
    <title>An Elimination Method for Solving Bivariate Polynomial Systems:
  Eliminating the Usual Drawbacks</title>
    <summary>  We present an exact and complete algorithm to isolate the real solutions of a
zero-dimensional bivariate polynomial system. The proposed algorithm
constitutes an elimination method which improves upon existing approaches in a
number of points. First, the amount of purely symbolic operations is
significantly reduced, that is, only resultant computation and square-free
factorization is still needed. Second, our algorithm neither assumes generic
position of the input system nor demands for any change of the coordinate
system. The latter is due to a novel inclusion predicate to certify that a
certain region is isolating for a solution. Our implementation exploits
graphics hardware to expedite the resultant computation. Furthermore, we
integrate a number of filtering techniques to improve the overall performance.
Efficiency of the proposed method is proven by a comparison of our
implementation with two state-of-the-art implementations, that is, LPG and
Maple's isolate. For a series of challenging benchmark instances, experiments
show that our implementation outperforms both contestants.
</summary>
    <author>
      <name>Eric Berberich</name>
    </author>
    <author>
      <name>Pavel Emeliyanenko</name>
    </author>
    <author>
      <name>Michael Sagraloff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages with appendix, 1 figure, submitted to ALENEX 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.1386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.1386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30 (Primary), 13P15 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5151v1</id>
    <updated>2011-01-27T03:16:16Z</updated>
    <published>2011-01-27T03:16:16Z</published>
    <title>Simulation of Self-Assembly in the Abstract Tile Assembly Model with ISU
  TAS</title>
    <summary>  Since its introduction by Erik Winfree in 1998, the abstract Tile Assembly
Model (aTAM) has inspired a wealth of research. As an abstract model for tile
based self-assembly, it has proven to be remarkably powerful and expressive in
terms of the structures which can self-assemble within it. As research has
progressed in the aTAM, the self-assembling structures being studied have
become progressively more complex. This increasing complexity, along with a
need for standardization of definitions and tools among researchers, motivated
the development of the Iowa State University Tile Assembly Simulator (ISU TAS).
ISU TAS is a graphical simulator and tile set editor for designing and building
2-D and 3-D aTAM tile assembly systems and simulating their self-assembly. This
paper reviews the features and functionality of ISU TAS and describes how it
can be used to further research into the complexities of the aTAM. Software and
source code are available at http://www.cs.iastate.edu/~lnsa.
</summary>
    <author>
      <name>Matthew J. Patitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper was in the Proceedings of the 6th Annual Conference of the
  Foundations of Nanoscience: Self-Assembled Architectures and Devices (2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5711v1</id>
    <updated>2011-02-28T17:16:06Z</updated>
    <published>2011-02-28T17:16:06Z</published>
    <title>XMLlab : multimedia publication of simulations applets using XML and
  Scilab</title>
    <summary>  We present an XML-based simulation authoring environment. The proposed
description language allows to describe mathematical objects such as systems of
ordinary differential equations, partial differential equations in two
dimensions, or simple curves and surfaces. It also allows to describe the
parameters on which these objects depend. This language is independent of the
target software and allows to ensure the perennity of author's work, as well as
collaborative work and content reuse. The actual implementation of XMLlab
allows to run the generated simulations within the open source mathematical
software Scilab, either locally when Scilab is installed on the client
machines, or on thin clients running a simple web browser, when XMLlab and
Scilab are installed on a distant server running a standard HTTP server.
</summary>
    <author>
      <name>Stéphane Mottelet</name>
    </author>
    <author>
      <name>André Pauss</name>
    </author>
    <link href="http://arxiv.org/abs/1102.5711v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5711v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.6248v1</id>
    <updated>2011-03-31T17:29:27Z</updated>
    <published>2011-03-31T17:29:27Z</published>
    <title>DOLFIN: Automated Finite Element Computing</title>
    <summary>  We describe here a library aimed at automating the solution of partial
differential equations using the finite element method. By employing novel
techniques for automated code generation, the library combines a high level of
expressiveness with efficient computation. Finite element variational forms may
be expressed in near mathematical notation, from which low-level code is
automatically generated, compiled and seamlessly integrated with efficient
implementations of computational meshes and high-performance linear algebra.
Easy-to-use object-oriented interfaces to the library are provided in the form
of a C++ library and a Python module. This paper discusses the mathematical
abstractions and methods used in the design of the library and its
implementation. A number of examples are presented to demonstrate the use of
the library in application code.
</summary>
    <author>
      <name>Anders Logg</name>
    </author>
    <author>
      <name>Garth N. Wells</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1731022.1731030</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1731022.1731030" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software 37(2), Article 20 (April
  2010), 28 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.6248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.6248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0199v1</id>
    <updated>2011-04-01T15:29:05Z</updated>
    <published>2011-04-01T15:29:05Z</published>
    <title>Optimisations for quadrature representations of finite element tensors
  through automated code generation</title>
    <summary>  We examine aspects of the computation of finite element matrices and vectors
which are made possible by automated code generation. Given a variational form
in a syntax which resembles standard mathematical notation, the low-level
computer code for building finite element tensors, typically matrices, vectors
and scalars, can be generated automatically via a form compiler. In particular,
the generation of code for computing finite element matrices using a quadrature
approach is addressed. For quadrature representations, a number of optimisation
strategies which are made possible by automated code generation are presented.
The relative performance of two different automatically generated
representations of finite element matrices is examined, with a particular
emphasis on complicated variational forms. It is shown that approaches which
perform best for simple forms are not tractable for more complicated problems
in terms of run time performance, the time required to generate the code or the
size of the generated code. The approach and optimisations elaborated here are
effective for a range of variational forms.
</summary>
    <author>
      <name>Kristian B. Ølgaard</name>
    </author>
    <author>
      <name>Garth N. Wells</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1644001.1644009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1644001.1644009" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Math. Softw. 37, 1, Article 8 (January 2010), 23 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1264v1</id>
    <updated>2011-09-06T18:42:48Z</updated>
    <published>2011-09-06T18:42:48Z</published>
    <title>A New Vectorization Technique for Expression Templates in C++</title>
    <summary>  Vector operations play an important role in high performance computing and
are typically provided by highly optimized libraries that implement the BLAS
(Basic Linear Algebra Subprograms) interface. In C++ templates and operator
overloading allow the implementation of these vector operations as expression
templates which construct custom loops at compile time and providing a more
abstract interface. Unfortunately existing expression template libraries lack
the performance of fast BLAS(Basic Linear Algebra Subprograms) implementations.
This paper presents a new approach - Statically Accelerated Loop Templates
(SALT) - to close this performance gap by combining expression templates with
an aggressive loop unrolling technique. Benchmarks were conducted using the
Intel C++ compiler and GNU Compiler Collection to assess the performance of our
library relative to Intel's Math Kernel Library as well as the Eigen template
library. The results show that the approach is able to provide optimization
comparable to the fastest available BLAS implementations, while retaining the
convenience and flexibility of a template library.
</summary>
    <author>
      <name>J. Progsch</name>
    </author>
    <author>
      <name>Y. Ineichen</name>
    </author>
    <author>
      <name>A. Adelmann</name>
    </author>
    <link href="http://arxiv.org/abs/1109.1264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4673v1</id>
    <updated>2011-10-21T00:45:38Z</updated>
    <published>2011-10-21T00:45:38Z</published>
    <title>How Can I Do That with ACL2? Recent Enhancements to ACL2</title>
    <summary>  The last several years have seen major enhancements to ACL2 functionality,
largely driven by requests from its user community, including utilities now in
common use such as 'make-event', 'mbe', and trust tags. In this paper we
provide user-level summaries of some ACL2 enhancements introduced after the
release of Version 3.5 (in May, 2009, at about the time of the 2009 ACL2
workshop) up through the release of Version 4.3 in July, 2011, roughly a couple
of years later. Many of these features are not particularly well known yet, but
most ACL2 users could take advantage of at least some of them. Some of the
changes could affect existing proof efforts, such as a change that treats pairs
of functions such as 'member' and 'member-equal' as the same function.
</summary>
    <author>
      <name>Matt Kaufmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Univ. of Texas at Austin</arxiv:affiliation>
    </author>
    <author>
      <name>J Strother Moore</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Univ. of Texas at Austin</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.70.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.70.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ACL2 2011, arXiv:1110.4473</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 70, 2011, pp. 46-60</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.4673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.3; F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6900v1</id>
    <updated>2011-11-29T17:05:00Z</updated>
    <published>2011-11-29T17:05:00Z</published>
    <title>The M4RIE library for dense linear algebra over small fields with even
  characteristic</title>
    <summary>  In this work, we present the M4RIE library which implements efficient
algorithms for linear algebra with dense matrices over GF(2^e) for 2 &lt;= 2 &lt;=
10. As the name of the library indicates, it makes heavy use of the M4RI
library both directly (i.e., by calling it) and indirectly (i.e., by using its
concepts). We provide an open-source GPLv2+ C library for efficient linear
algebra over GF(2^e) for e small. In this library we implemented an idea due to
Bradshaw and Boothby which reduces matrix multiplication over GF(p^k) to a
series of matrix multiplications over GF(p). Furthermore, we propose a caching
technique - Newton-John tables - to avoid finite field multiplications which is
inspired by Kronrod's method ("M4RM") for matrix multiplication over GF(2).
Using these two techniques we provide asymptotically fast triangular solving
with matrices (TRSM) and PLE-based Gaussian elimination. As a result, we are
able to significantly improve upon the state of the art in dense linear algebra
over GF(2^e) with 2 &lt;= e &lt;= 10.
</summary>
    <author>
      <name>Martin R. Albrecht</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4830v1</id>
    <updated>2012-02-22T06:41:37Z</updated>
    <published>2012-02-22T06:41:37Z</published>
    <title>Automatic Deduction in Dynamic Geometry using Sage</title>
    <summary>  We present a symbolic tool that provides robust algebraic methods to handle
automatic deduction tasks for a dynamic geometry construction. The main
prototype has been developed as two different worksheets for the open source
computer algebra system Sage, corresponding to two different ways of coding a
geometric construction. In one worksheet, diagrams constructed with the open
source dynamic geometry system GeoGebra are accepted. In this worksheet,
Groebner bases are used to either compute the equation of a geometric locus in
the case of a locus construction or to determine the truth of a general
geometric statement included in the GeoGebra construction as a boolean
variable. In the second worksheet, locus constructions coded using the common
file format for dynamic geometry developed by the Intergeo project are accepted
for computation. The prototype and several examples are provided for testing.
Moreover, a third Sage worksheet is presented in which a novel algorithm to
eliminate extraneous parts in symbolically computed loci has been implemented.
The algorithm, based on a recent work on the Groebner cover of parametric
systems, identifies degenerate components and extraneous adherence points in
loci, both natural byproducts of general polynomial algebraic methods. Detailed
examples are discussed.
</summary>
    <author>
      <name>Francisco Botana</name>
    </author>
    <author>
      <name>Miguel A. Abánades</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.79.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.79.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings THedu'11, arXiv:1202.4535</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 79, 2012, pp. 49-62</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.4830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1263v2</id>
    <updated>2012-12-03T19:16:52Z</updated>
    <published>2012-03-06T17:45:07Z</published>
    <title>NLSEmagic: Nonlinear Schrödinger Equation Multidimensional
  Matlab-based GPU-accelerated Integrators using Compact High-order Schemes</title>
    <summary>  We present a simple to use, yet powerful code package called NLSEmagic to
numerically integrate the nonlinear Schr\"odinger equation in one, two, and
three dimensions. NLSEmagic is a high-order finite-difference code package
which utilizes graphic processing unit (GPU) parallel architectures. The codes
running on the GPU are many times faster than their serial counterparts, and
are much cheaper to run than on standard parallel clusters. The codes are
developed with usability and portability in mind, and therefore are written to
interface with MATLAB utilizing custom GPU-enabled C codes with the
MEX-compiler interface. The packages are freely distributed, including user
manuals and set-up files.
</summary>
    <author>
      <name>R. M. Caplan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2012.12.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2012.12.010" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.1263v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1263v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3059v1</id>
    <updated>2012-03-14T12:00:08Z</updated>
    <published>2012-03-14T12:00:08Z</published>
    <title>Set Reduction In Nonlinear Equations</title>
    <summary>  In this paper, an idea to solve nonlinear equations is presented. During the
solution of any problem with Newton's Method, it might happen that some of the
unknowns satisfy the convergence criteria where the others fail. The
convergence happens only when all variables reach to the convergence limit. A
method to reduce the dimension of the overall system by excluding some of the
unknowns that satisfy an intermediate tolerance is introduced. In this
approach, a smaller system is solved in less amount of time and already
established local solutions are preserved and kept as constants while the other
variables that belong to the "set" will be relaxed. To realize the idea, an
algorithm is given that utilizes applications of pointers to reduce and
evaluate the sets. Matrix-free Newton-Krylov Techniques are used on a test
problem and it is shown that proposed idea improves the overall convergence.
</summary>
    <author>
      <name>Erhan Turan</name>
    </author>
    <author>
      <name>Ali Ecder</name>
    </author>
    <link href="http://arxiv.org/abs/1203.3059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.4009v1</id>
    <updated>2012-03-18T23:51:19Z</updated>
    <published>2012-03-18T23:51:19Z</published>
    <title>Scilab and SIP for Image Processing</title>
    <summary>  This paper is an overview of Image Processing and Analysis using Scilab, a
free prototyping environment for numerical calculations similar to Matlab. We
demonstrate the capabilities of SIP -- the Scilab Image Processing Toolbox --
which extends Scilab with many functions to read and write images in over 100
major file formats, including PNG, JPEG, BMP, and TIFF. It also provides
routines for image filtering, edge detection, blurring, segmentation, shape
analysis, and image recognition. Basic directions to install Scilab and SIP are
given, and also a mini-tutorial on Scilab. Three practical examples of image
analysis are presented, in increasing degrees of complexity, showing how
advanced image analysis techniques seems uncomplicated in this environment.
</summary>
    <author>
      <name>Ricardo Fabbri</name>
    </author>
    <author>
      <name>Odemir Martinez Bruno</name>
    </author>
    <author>
      <name>Luciano da Fontoura Costa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.4009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.4009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.4031v3</id>
    <updated>2015-06-16T15:47:52Z</updated>
    <published>2012-03-19T03:47:55Z</published>
    <title>FEAST Eigenvalue Solver v3.0 User Guide</title>
    <summary>  The FEAST eigensolver package is a free high-performance numerical library
for solving the Hermitian and non-Hermitian eigenvalue problems, and obtaining
all the eigenvalues and (right/left) eigenvectors within a given search
interval or arbitrary contour in the complex plane. Its originality lies with a
new transformative numerical approach to the traditional eigenvalue algorithm
design - the FEAST algorithm. The FEAST eigensolver combines simplicity and
efficiency and it offers many important capabilities for achieving high
performance, robustness, accuracy, and scalability on parallel architectures.
FEAST is both a comprehensive library package, and an easy to use software. It
includes flexible reverse communication interfaces and ready to use predefined
interfaces for dense, banded and sparse systems. The current version v3.0 of
the FEAST package can address both Hermitian and non-Hermitian eigenvalue
problems (real symmetric, real non-symmetric, complex Hermitian, complex
symmetric, or complex general systems) on both shared-memory and distributed
memory architectures (i.e contains both FEAST-SMP and FEAST-MPI packages). This
User's guide provides instructions for installation setup, a detailed
description of the FEAST interfaces and a large number of examples.
</summary>
    <author>
      <name>Eric Polizzi</name>
    </author>
    <author>
      <name>James Kestyn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 10 Figures, 12 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.4031v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.4031v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3853v2</id>
    <updated>2013-02-04T15:53:08Z</updated>
    <published>2012-04-17T17:25:52Z</published>
    <title>Block-Structured Adaptive Mesh Refinement Algorithms for Vlasov
  Simulation</title>
    <summary>  Direct discretization of continuum kinetic equations, like the Vlasov
equation, are under-utilized because the distribution function generally exists
in a high-dimensional (&gt;3D) space and computational cost increases
geometrically with dimension. We propose to use high-order finite-volume
techniques with block-structured adaptive mesh refinement (AMR) to reduce the
computational cost. The primary complication comes from a solution state
comprised of variables of different dimensions. We develop the algorithms
required to extend standard single-dimension block structured AMR to the
multi-dimension case. Specifically, algorithms for reduction and injection
operations that transfer data between mesh hierarchies of different dimensions
are explained in detail. In addition, modifications to the basic AMR algorithm
that enable the use of high-order spatial and temporal discretizations are
discussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem
are presented. Results indicate that there is potential for significant savings
for some classes of Vlasov problems.
</summary>
    <author>
      <name>J. A. F. Hittinger</name>
    </author>
    <author>
      <name>J. W. Banks</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2013.01.030</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2013.01.030" rel="related"/>
    <link href="http://arxiv.org/abs/1204.3853v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3853v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.plasm-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5094v2</id>
    <updated>2012-07-10T22:21:16Z</updated>
    <published>2012-04-23T16:05:46Z</published>
    <title>Point-and-write --- Documenting Formal Mathematics by Reference</title>
    <summary>  This paper describes the design and implementation of mechanisms for
light-weight inclusion of formal mathematics in informal mathematical writings,
particularly in a Web-based setting. This is conceptually done in three stages:
(i) by choosing a suitable representation layer (based on RDF) for encoding the
information about available resources of formal mathematics, (ii) by exporting
this information from formal libraries, and (iii) by providing syntax and
implementation for including formal mathematics in informal writings.
  We describe the use case of an author referring to formal text from an
informal narrative, and discuss design choices entailed by this use case.
Furthermore, we describe an implementation of the use case within the Agora
prototype: a Wiki for collaborating on formalized mathematics.
</summary>
    <author>
      <name>Carst Tankink</name>
    </author>
    <author>
      <name>Christoph Lange</name>
    </author>
    <author>
      <name>Josef Urban</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Intelligent Computer Mathematics, July 8--13, Bremen,
  Germany. Published as number 7362 in Lecture Notes in Artificial
  Intelligence, Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.5094v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5094v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T30, 68T35, 03B35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; F.4.m; H.3.5; H.5.3; H.5.4; I.2.4; I.7.1; I.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0790v2</id>
    <updated>2012-05-15T20:19:22Z</updated>
    <published>2012-05-03T18:24:54Z</published>
    <title>Automating embedded analysis capabilities and managing software
  complexity in multiphysics simulation part I: template-based generic
  programming</title>
    <summary>  An approach for incorporating embedded simulation and analysis capabilities
in complex simulation codes through template-based generic programming is
presented. This approach relies on templating and operator overloading within
the C++ language to transform a given calculation into one that can compute a
variety of additional quantities that are necessary for many state-of-the-art
simulation and analysis algorithms. An approach for incorporating these ideas
into complex simulation codes through general graph-based assembly is also
presented. These ideas have been implemented within a set of packages in the
Trilinos framework and are demonstrated on a simple problem from chemical
engineering.
</summary>
    <author>
      <name>Roger P. Pawlowski</name>
    </author>
    <author>
      <name>Eric T. Phipps</name>
    </author>
    <author>
      <name>Andrew G. Salinger</name>
    </author>
    <link href="http://arxiv.org/abs/1205.0790v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0790v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1098v1</id>
    <updated>2012-05-05T04:30:14Z</updated>
    <published>2012-05-05T04:30:14Z</published>
    <title>Reliable Generation of High-Performance Matrix Algebra</title>
    <summary>  Scientific programmers often turn to vendor-tuned Basic Linear Algebra
Subprograms (BLAS) to obtain portable high performance. However, many numerical
algorithms require several BLAS calls in sequence, and those successive calls
result in suboptimal performance. The entire sequence needs to be optimized in
concert. Instead of vendor-tuned BLAS, a programmer could start with source
code in Fortran or C (e.g., based on the Netlib BLAS) and use a
state-of-the-art optimizing compiler. However, our experiments show that
optimizing compilers often attain only one-quarter the performance of
hand-optimized code. In this paper we present a domain-specific compiler for
matrix algebra, the Build to Order BLAS (BTO), that reliably achieves high
performance using a scalable search algorithm for choosing the best combination
of loop fusion, array contraction, and multithreading for data parallelism. The
BTO compiler generates code that is between 16% slower and 39% faster than
hand-optimized code.
</summary>
    <author>
      <name>Geoffrey Belter</name>
    </author>
    <author>
      <name>Elizabeth Jessup</name>
    </author>
    <author>
      <name>Thomas Nelson</name>
    </author>
    <author>
      <name>Boyana Norris</name>
    </author>
    <author>
      <name>Jeremy G. Siek</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2107v2</id>
    <updated>2012-09-26T02:59:01Z</updated>
    <published>2012-05-09T21:20:55Z</published>
    <title>High-Performance Solvers for Dense Hermitian Eigenproblems</title>
    <summary>  We introduce a new collection of solvers - subsequently called EleMRRR - for
large-scale dense Hermitian eigenproblems. EleMRRR solves various types of
problems: generalized, standard, and tridiagonal eigenproblems. Among these,
the last is of particular importance as it is a solver on its own right, as
well as the computational kernel for the first two; we present a fast and
scalable tridiagonal solver based on the Algorithm of Multiple Relatively
Robust Representations - referred to as PMRRR. Like the other EleMRRR solvers,
PMRRR is part of the freely available Elemental library, and is designed to
fully support both message-passing (MPI) and multithreading parallelism (SMP).
As a result, the solvers can equally be used in pure MPI or in hybrid MPI-SMP
fashion. We conducted a thorough performance study of EleMRRR and ScaLAPACK's
solvers on two supercomputers. Such a study, performed with up to 8,192 cores,
provides precise guidelines to assemble the fastest solver within the ScaLAPACK
framework; it also indicates that EleMRRR outperforms even the fastest solvers
built from ScaLAPACK's components.
</summary>
    <author>
      <name>Matthias Petschow</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Elmar Peise</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1205.2107v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2107v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2927v1</id>
    <updated>2012-05-14T01:37:41Z</updated>
    <published>2012-05-14T01:37:41Z</published>
    <title>A Heterogeneous Accelerated Matrix Multiplication: OpenCL + APU + GPU+
  Fast Matrix Multiply</title>
    <summary>  As users and developers, we are witnessing the opening of a new computing
scenario: the introduction of hybrid processors into a single die, such as an
accelerated processing unit (APU) processor, and the plug-and-play of
additional graphics processing units (GPUs) onto a single motherboard. These
APU processors provide multiple symmetric cores with their memory hierarchies
and an integrated GPU. Moreover, these processors are designed to work with
external GPUs that can push the peak performance towards the TeraFLOPS
boundary. We present a case study for the development of dense Matrix
Multiplication (MM) codes for matrix sizes up to 19K\times19K, thus using all
of the above computational engines, and an achievable peak performance of 200
GFLOPS for, literally, a made- at-home built. We present the results of our
experience, the quirks, the pitfalls, the achieved performance, and the
achievable peak performance.
</summary>
    <author>
      <name>Paolo D'Alberto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 Figure, Fusion AMD Fusion Developer Summit 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3952v1</id>
    <updated>2012-05-17T15:18:00Z</updated>
    <published>2012-05-17T15:18:00Z</published>
    <title>Automating embedded analysis capabilities and managing software
  complexity in multiphysics simulation part II: application to partial
  differential equations</title>
    <summary>  A template-based generic programming approach was presented in a previous
paper that separates the development effort of programming a physical model
from that of computing additional quantities, such as derivatives, needed for
embedded analysis algorithms. In this paper, we describe the implementation
details for using the template-based generic programming approach for
simulation and analysis of partial differential equations (PDEs). We detail
several of the hurdles that we have encountered, and some of the software
infrastructure developed to overcome them. We end with a demonstration where we
present shape optimization and uncertainty quantification results for a 3D PDE
application.
</summary>
    <author>
      <name>Roger P. Pawlowski</name>
    </author>
    <author>
      <name>Eric T. Phipps</name>
    </author>
    <author>
      <name>Andrew G. Salinger</name>
    </author>
    <author>
      <name>Steven J. Owen</name>
    </author>
    <author>
      <name>Christopher M. Siefert</name>
    </author>
    <author>
      <name>Matthew L. Staten</name>
    </author>
    <link href="http://arxiv.org/abs/1205.3952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.5975v1</id>
    <updated>2012-05-27T15:22:23Z</updated>
    <published>2012-05-27T15:22:23Z</published>
    <title>A Domain-Specific Compiler for Linear Algebra Operations</title>
    <summary>  We present a prototypical linear algebra compiler that automatically exploits
domain-specific knowledge to generate high-performance algorithms. The input to
the compiler is a target equation together with knowledge of both the structure
of the problem and the properties of the operands. The output is a variety of
high-performance algorithms, and the corresponding source code, to solve the
target equation. Our approach consists in the decomposition of the input
equation into a sequence of library-supported kernels. Since in general such a
decomposition is not unique, our compiler returns not one but a number of
algorithms. The potential of the compiler is shown by means of its application
to a challenging equation arising within the genome-wide association study. As
a result, the compiler produces multiple "best" algorithms that outperform the
best existing libraries.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1205.5975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.5975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1187v2</id>
    <updated>2012-06-22T04:42:05Z</updated>
    <published>2012-06-06T11:30:42Z</published>
    <title>Parallel random variates generator for GPUs based on normal numbers</title>
    <summary>  Pseudorandom number generators are required for many computational tasks,
such as stochastic modelling and simulation. This paper investigates the serial
CPU and parallel GPU implementation of a Linear Congruential Generator based on
the binary representation of the normal number $\alpha_{2,3}$. We adapted two
methods of modular reduction which allowed us to perform most operations in
64-bit integer arithmetic, improving on the original implementation based on
106-bit double-double operations. We found that our implementation is faster
than existing methods in literature, and our generation rate is close to the
limiting rate imposed by the efficiency of writing to a GPU's global memory.
</summary>
    <author>
      <name>Gleb Beliakov</name>
    </author>
    <author>
      <name>Michael Johnstone</name>
    </author>
    <author>
      <name>Doug Creighton</name>
    </author>
    <author>
      <name>Tim Wilkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint, 18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1187v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1187v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11K45, 65C10, 65Y05, 68W10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1380v1</id>
    <updated>2012-07-04T16:10:18Z</updated>
    <published>2012-07-04T16:10:18Z</published>
    <title>Bayes Blocks: An Implementation of the Variational Bayesian Building
  Blocks Framework</title>
    <summary>  A software library for constructing and learning probabilistic models is
presented. The library offers a set of building blocks from which a large
variety of static and dynamic models can be built. These include hierarchical
models for variances of other variables and many nonlinear models. The
underlying variational Bayesian machinery, providing for fast and robust
estimation but being mathematically rather involved, is almost completely
hidden from the user thus making it very easy to use the library. The building
blocks include Gaussian, rectified Gaussian and mixture-of-Gaussians variables
and computational nodes which can be combined rather freely.
</summary>
    <author>
      <name>Markus Harva</name>
    </author>
    <author>
      <name>Tapani Raiko</name>
    </author>
    <author>
      <name>Antti Honkela</name>
    </author>
    <author>
      <name>Harri Valpola</name>
    </author>
    <author>
      <name>Juha Karhunen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1746v1</id>
    <updated>2012-07-06T23:30:06Z</updated>
    <published>2012-07-06T23:30:06Z</published>
    <title>A Generic Library for Stencil Computations</title>
    <summary>  In this era of diverse and heterogeneous computer architectures, the
programmability issues, such as productivity and portable efficiency, are
crucial to software development and algorithm design. One way to approach the
problem is to step away from traditional sequential programming languages and
move toward domain specific programming environments to balance between
expressivity and efficiency. In order to demonstrate this principle, we
developed a domain specific C++ generic library for stencil computations, like
PDE solvers. The library features high level constructs to specify computation
and allows the development of parallel stencil computations with very limited
effort. The high abstraction constructs (like do_all and do_reduce) make the
program shorter and cleaner with increased contextual information for better
performance exploitation. The results show good performance from Windows
multicores, to HPC clusters and machines with accelerators, like GPUs.
</summary>
    <author>
      <name>Mauro Bianco</name>
    </author>
    <author>
      <name>Ugo Varetto</name>
    </author>
    <link href="http://arxiv.org/abs/1207.1746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1916v1</id>
    <updated>2012-07-08T21:52:03Z</updated>
    <published>2012-07-08T21:52:03Z</published>
    <title>How good are MatLab, Octave and Scilab for Computational Modelling?</title>
    <summary>  In this article we test the accuracy of three platforms used in computational
modelling: MatLab, Octave and Scilab, running on i386 architecture and three
operating systems (Windows, Ubuntu and Mac OS). We submitted them to numerical
tests using standard data sets and using the functions provided by each
platform. A Monte Carlo study was conducted in some of the datasets in order to
verify the stability of the results with respect to small departures from the
original input. We propose a set of operations which include the computation of
matrix determinants and eigenvalues, whose results are known. We also used data
provided by NIST (National Institute of Standards and Technology), a protocol
which includes the computation of basic univariate statistics (mean, standard
deviation and first-lag correlation), linear regression and extremes of
probability distributions. The assessment was made comparing the results
computed by the platforms with certified values, that is, known results,
computing the number of correct significant digits.
</summary>
    <author>
      <name>Eliana S. de Almeida</name>
    </author>
    <author>
      <name>Antonio C. Medeiros</name>
    </author>
    <author>
      <name>Alejandro C. Frery</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the Computational and Applied Mathematics
  journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2300v1</id>
    <updated>2012-07-10T10:35:17Z</updated>
    <published>2012-07-10T10:35:17Z</published>
    <title>Towards the Formal Specification and Verification of Maple Programs</title>
    <summary>  In this paper, we present our ongoing work and initial results on the formal
specification and verification of MiniMaple (a substantial subset of Maple with
slight extensions) programs. The main goal of our work is to find behavioral
errors in such programs w.r.t. their specifications by static analysis. This
task is more complex for widely used computer algebra languages like Maple as
these are fundamentally different from classical languages: they support
non-standard types of objects such as symbols, unevaluated expressions and
polynomials and require abstract computer algebraic concepts and objects such
as rings and orderings etc. As a starting point we have defined and formalized
a syntax, semantics, type system and specification language for MiniMaple.
</summary>
    <author>
      <name>Muhammad Taimoor Khan</name>
    </author>
    <author>
      <name>Wolfgang Schreiner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-31374-5_16</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-31374-5_16" rel="related"/>
    <link href="http://arxiv.org/abs/1207.2300v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2300v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1003v5</id>
    <updated>2014-05-30T10:25:54Z</updated>
    <published>2012-09-05T14:58:51Z</published>
    <title>A C++11 implementation of arbitrary-rank tensors for high-performance
  computing</title>
    <summary>  This article discusses an efficient implementation of tensors of arbitrary
rank by using some of the idioms introduced by the recently published C++ ISO
Standard (C++11). With the aims at providing a basic building block for
high-performance computing, a single Array class template is carefully crafted,
from which vectors, matrices, and even higher-order tensors can be created. An
expression template facility is also built around the array class template to
provide convenient mathematical syntax. As a result, by using templates, an
extra high-level layer is added to the C++ language when dealing with algebraic
objects and their operations, without compromising performance. The
implementation is tested running on both CPU and GPU.
</summary>
    <author>
      <name>Alejandro M. Aragón</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2014.01.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2014.01.005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 6 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications, 185(6): 1681 - 1696, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1003v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1003v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80, 97N60" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.5; D.2.3; D.3.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2364v2</id>
    <updated>2012-12-10T01:51:36Z</updated>
    <published>2012-09-11T16:37:20Z</published>
    <title>Performance Modeling for Dense Linear Algebra</title>
    <summary>  It is well known that the behavior of dense linear algebra algorithms is
greatly influenced by factors like target architecture, underlying libraries
and even problem size; because of this, the accurate prediction of their
performance is a real challenge. In this article, we are not interested in
creating accurate models for a given algorithm, but in correctly ranking a set
of equivalent algorithms according to their performance. Aware of the
hierarchical structure of dense linear algebra routines, we approach the
problem by developing a framework for the automatic generation of statistical
performance models for BLAS and LAPACK libraries. This allows us to obtain
predictions through evaluating and combining such models. We demonstrate that
our approach is successful in both single- and multi-core environments, not
only in the ranking of algorithms but also in tuning their parameters.
</summary>
    <author>
      <name>Elmar Peise</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Workshop on Performance Modeling, Benchmarking and
  Simulation of High Performance Computer Systems (PMBS12), International
  Conference for High Performance Computing, Networking, Storage and Analysis
  2012 (SC12)</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.2364v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2364v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0582v1</id>
    <updated>2012-11-02T23:55:22Z</updated>
    <published>2012-11-02T23:55:22Z</published>
    <title>High-Order Discontinuous Galerkin Methods by GPU Metaprogramming</title>
    <summary>  Discontinuous Galerkin (DG) methods for the numerical solution of partial
differential equations have enjoyed considerable success because they are both
flexible and robust: They allow arbitrary unstructured geometries and easy
control of accuracy without compromising simulation stability. In a recent
publication, we have shown that DG methods also adapt readily to execution on
modern, massively parallel graphics processors (GPUs). A number of qualities of
the method contribute to this suitability, reaching from locality of reference,
through regularity of access patterns, to high arithmetic intensity. In this
article, we illuminate a few of the more practical aspects of bringing DG onto
a GPU, including the use of a Python-based metaprogramming infrastructure that
was created specifically to support DG, but has found many uses across all
disciplines of computational science.
</summary>
    <author>
      <name>Andreas Klöckner</name>
    </author>
    <author>
      <name>Timothy Warburton</name>
    </author>
    <author>
      <name>Jan S. Hesthaven</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear as part of "GPU Solutions to Multi-scale Problems in
  Science and Engineering", http://books.google.com/books?vid=9783642164040</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ISBN 9783642164040, Springer, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.0582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3056v2</id>
    <updated>2013-06-05T11:51:55Z</updated>
    <published>2012-11-13T17:28:03Z</published>
    <title>GPU-accelerated generation of correctly-rounded elementary functions</title>
    <summary>  The IEEE 754-2008 standard recommends the correct rounding of some elementary
functions. This requires to solve the Table Maker's Dilemma which implies a
huge amount of CPU computation time. We consider in this paper accelerating
such computations, namely Lefe'vre algorithm on Graphics Processing Units
(GPUs) which are massively parallel architectures with a partial SIMD execution
(Single Instruction Multiple Data). We first propose an analysis of the
Lef\`evre hard-to-round argument search using the concept of continued
fractions. We then propose a new parallel search algorithm much more efficient
on GPU thanks to its more regular control flow. We also present an efficient
hybrid CPU-GPU deployment of the generation of the polynomial approximations
required in Lef\`evre algorithm. In the end, we manage to obtain overall
speedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x
over a multi-core CPU, which enable a much faster solving of the Table Maker's
Dilemma for the double precision format.
</summary>
    <author>
      <name>Pierre Fortin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Mourad Gouicem</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Stef Graillat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1211.3056v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3056v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4047v2</id>
    <updated>2013-04-25T20:18:09Z</updated>
    <published>2012-11-16T21:56:02Z</published>
    <title>Unified Form Language: A domain-specific language for weak formulations
  of partial differential equations</title>
    <summary>  We present the Unified Form Language (UFL), which is a domain-specific
language for representing weak formulations of partial differential equations
with a view to numerical approximation. Features of UFL include support for
variational forms and functionals, automatic differentiation of forms and
expressions, arbitrary function space hierarchies for multi-field problems,
general differential operators and flexible tensor algebra. With these
features, UFL has been used to effortlessly express finite element methods for
complex systems of partial differential equations in near-mathematical
notation, resulting in compact, intuitive and readable programs. We present in
this work the language and its construction. An implementation of UFL is freely
available as an open-source software library. The library generates abstract
syntax tree representations of variational problems, which are used by other
software libraries to generate concrete low-level implementations. Some
application examples are presented and libraries that support UFL are
highlighted.
</summary>
    <author>
      <name>Martin S. Alnaes</name>
    </author>
    <author>
      <name>Anders Logg</name>
    </author>
    <author>
      <name>Kristian B. Oelgaard</name>
    </author>
    <author>
      <name>Marie E. Rognes</name>
    </author>
    <author>
      <name>Garth N. Wells</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ACM Transactions on Mathematical Software</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.4047v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4047v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8; G.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5904v1</id>
    <updated>2012-11-26T10:15:29Z</updated>
    <published>2012-11-26T10:15:29Z</published>
    <title>Application-tailored Linear Algebra Algorithms: A search-based Approach</title>
    <summary>  In this paper, we tackle the problem of automatically generating algorithms
for linear algebra operations by taking advantage of problem-specific
knowledge. In most situations, users possess much more information about the
problem at hand than what current libraries and computing environments accept;
evidence shows that if properly exploited, such information leads to
uncommon/unexpected speedups. We introduce a knowledge-aware linear algebra
compiler that allows users to input matrix equations together with properties
about the operands and the problem itself; for instance, they can specify that
the equation is part of a sequence, and how successive instances are related to
one another. The compiler exploits all this information to guide the generation
of algorithms, to limit the size of the search space, and to avoid redundant
computations. We applied the compiler to equations arising as part of
sensitivity and genome studies; the algorithms produced exhibit, respectively,
100- and 1000-fold speedups.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1211.5904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6326v2</id>
    <updated>2013-04-26T07:50:28Z</updated>
    <published>2012-12-27T08:56:00Z</published>
    <title>Programming CUDA and OpenCL: A Case Study Using Modern C++ Libraries</title>
    <summary>  We present a comparison of several modern C++ libraries providing high-level
interfaces for programming multi- and many-core architectures on top of CUDA or
OpenCL. The comparison focuses on the solution of ordinary differential
equations and is based on odeint, a framework for the solution of systems of
ordinary differential equations. Odeint is designed in a very flexible way and
may be easily adapted for effective use of libraries such as Thrust, MTL4,
VexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and
OpenCL work equally well for problems of large sizes, while OpenCL has higher
overhead for smaller problems. Furthermore, we show that modern high-level
libraries allow to effectively use the computational resources of many-core
GPUs or multi-core CPUs without much knowledge of the underlying technologies.
</summary>
    <author>
      <name>Denis Demidov</name>
    </author>
    <author>
      <name>Karsten Ahnert</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Peter Gottschling</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/120903683</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/120903683" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 4 figures, submitted to SIAM Journal of Scientific
  Computing and accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.6326v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6326v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2707v2</id>
    <updated>2015-03-27T00:44:56Z</updated>
    <published>2013-01-12T19:00:15Z</published>
    <title>ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear
  Equations and Least-Squares Problems</title>
    <summary>  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for
solving symmetric or Hermitian linear systems or least-squares problems. If the
system is singular, MINRES-QLP computes the unique minimum-length solution
(also known as the pseudoinverse solution), which generally eludes MINRES. In
all cases, it overcomes a potential instability in the original MINRES
algorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90
implementation illustrates a design pattern that allows users to make problem
data known to the solver but hidden and secure from other program units. In
particular, we circumvent the need for reverse communication. While we focus
here on a FORTRAN 90 implementation, we also provide and maintain MATLAB
versions of MINRES and MINRES-QLP.
</summary>
    <author>
      <name>Sou-Cheng T. Choi</name>
    </author>
    <author>
      <name>Michael A. Saunders</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2527267</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2527267" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages and 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2707v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2707v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.3894v1</id>
    <updated>2013-02-15T21:30:51Z</updated>
    <published>2013-02-15T21:30:51Z</published>
    <title>A framework for automated PDE-constrained optimisation</title>
    <summary>  A generic framework for the solution of PDE-constrained optimisation problems
based on the FEniCS system is presented. Its main features are an intuitive
mathematical interface, a high degree of automation, and an efficient
implementation of the generated adjoint model. The framework is based upon the
extension of a domain-specific language for variational problems to cleanly
express complex optimisation problems in a compact, high-level syntax. For
example, optimisation problems constrained by the time-dependent Navier-Stokes
equations can be written in tens of lines of code. Based on this high-level
representation, the framework derives the associated adjoint equations in the
same domain-specific language, and uses the FEniCS code generation technology
to emit parallel optimised low-level C++ code for the solution of the forward
and adjoint systems. The functional and gradient information so computed is
then passed to the optimisation algorithm to update the parameter values. This
approach works both for steady-state as well as transient, and for linear as
well as nonlinear governing PDEs and a wide range of functionals and control
parameters. We demonstrate the applicability and efficiency of this approach on
classical textbook optimisation problems and advanced examples.
</summary>
    <author>
      <name>S. W. Funke</name>
    </author>
    <author>
      <name>P. E. Farrell</name>
    </author>
    <link href="http://arxiv.org/abs/1302.3894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.3894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8; G.1.6; I.6.5; J.2; J.6; D.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4928v2</id>
    <updated>2013-04-09T08:08:31Z</updated>
    <published>2013-03-20T13:05:33Z</published>
    <title>Parameter identification in large kinetic networks with BioPARKIN</title>
    <summary>  Modelling, parameter identification, and simulation play an important role in
systems biology. Usually, the goal is to determine parameter values that
minimise the difference between experimental measurement values and model
predictions in a least-squares sense. Large-scale biological networks, however,
often suffer from missing data for parameter identification. Thus, the
least-squares problems are rank-deficient and solutions are not unique. Many
common optimisation methods ignore this detail because they do not take into
account the structure of the underlying inverse problem. These algorithms
simply return a "solution" without additional information on identifiability or
uniqueness. This can yield misleading results, especially if parameters are
co-regulated and data are noisy.
</summary>
    <author>
      <name>Thomas Dierkes</name>
    </author>
    <author>
      <name>Susanna Röblitz</name>
    </author>
    <author>
      <name>Moritz Wade</name>
    </author>
    <author>
      <name>Peter Deuflhard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 7 figures, 4 tables; added 1 figure, and revised section 4</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.4928v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4928v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L09 (Primary) 49M15, 65C20, 65L04, 65L80, 92C42 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.1.7; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5546v1</id>
    <updated>2013-04-19T21:07:10Z</updated>
    <published>2013-04-19T21:07:10Z</published>
    <title>Solving Wave Equations on Unstructured Geometries</title>
    <summary>  Waves are all around us--be it in the form of sound, electromagnetic
radiation, water waves, or earthquakes. Their study is an important basic tool
across engineering and science disciplines. Every wave solver serving the
computational study of waves meets a trade-off of two figures of merit--its
computational speed and its accuracy. Discontinuous Galerkin (DG) methods fall
on the high-accuracy end of this spectrum. Fortuitously, their computational
structure is so ideally suited to GPUs that they also achieve very high
computational speeds. In other words, the use of DG methods on GPUs
significantly lowers the cost of obtaining accurate solutions. This article
aims to give the reader an easy on-ramp to the use of this technology, based on
a sample implementation which demonstrates a highly accurate, GPU-capable,
real-time visualizing finite element solver in about 1500 lines of code.
</summary>
    <author>
      <name>Andreas Klöckner</name>
    </author>
    <author>
      <name>Timothy Warburton</name>
    </author>
    <author>
      <name>Jan S. Hesthaven</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">GPU Computing Gems, edited by Wen-mei Hwu, Elsevier (2011), ISBN
  9780123859631, Chapter 18</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.5546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7053v1</id>
    <updated>2013-04-26T02:22:14Z</updated>
    <published>2013-04-26T02:22:14Z</published>
    <title>A GEMM interface and implementation on NVIDIA GPUs for multiple small
  matrices</title>
    <summary>  We present an interface and an implementation of the General Matrix Multiply
(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA
graphics processing units (GPUs). We focus on matrix sizes under 16. The
implementation can be easily extended to larger sizes. For single precision
matrices, our implementation is 30% to 600% faster than the batched cuBLAS
implementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For
example, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000
independent matrix pairs of size 10 and 16, respectively. Similar improvement
in performance is obtained for other sizes, in single and double precision for
real and complex types, and when the number of matrices is smaller. Apart from
our implementation, our different function interface also plays an important
role in the improved performance. Applications of this software include Finite
Element computation on GPUs.
</summary>
    <author>
      <name>Chetan Jhurani</name>
    </author>
    <author>
      <name>Paul Mullowney</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7054v1</id>
    <updated>2013-04-26T02:22:25Z</updated>
    <published>2013-04-26T02:22:25Z</published>
    <title>Batched Kronecker product for 2-D matrices and 3-D arrays on NVIDIA GPUs</title>
    <summary>  We describe an interface and an implementation for performing Kronecker
product actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays
processed in parallel as a batch. This method is suited to cases where the
Kronecker product component matrices are identical but the operands in a
matrix-free application vary in the batch. Any batched GEMM (General Matrix
Multiply) implementation, for example ours [1] or the one in cuBLAS, can also
be used for performing batched Kronecker products on GPUs. However, the
specialized implementation presented here is faster and uses less memory.
Partly this is because a simple GEMM based approach would require extra copies
to and from main memory. We focus on matrix sizes less than or equal to 16,
since these are the typical polynomial degrees in Finite Elements, but the
implementation can be easily extended for other sizes. We obtain 143 and 285
GFlop/s for single precision real when processing matrices of size 10 and 16,
respectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for
3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double
precision is easily supported using the C++ template mechanism.
</summary>
    <author>
      <name>Chetan Jhurani</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7223v3</id>
    <updated>2013-05-24T09:08:09Z</updated>
    <published>2013-04-26T16:46:48Z</published>
    <title>Understanding Branch Cuts of Expressions</title>
    <summary>  We assume some standard choices for the branch cuts of a group of functions
and consider the problem of then calculating the branch cuts of expressions
involving those functions. Typical examples include the addition formulae for
inverse trigonometric functions. Understanding these cuts is essential for
working with the single-valued counterparts, the common approach to encoding
multi-valued functions in computer algebra systems. While the defining choices
are usually simple (typically portions of either the real or imaginary axes)
the cuts induced by the expression may be surprisingly complicated. We have
made explicit and implemented techniques for calculating the cuts in the
computer algebra programme Maple. We discuss the issues raised, classifying the
different cuts produced. The techniques have been gathered in the BranchCuts
package, along with tools for visualising the cuts. The package is included in
Maple 17 as part of the FunctionAdvisor tool.
</summary>
    <author>
      <name>Matthew England</name>
    </author>
    <author>
      <name>Russell Bradford</name>
    </author>
    <author>
      <name>James H. Davenport</name>
    </author>
    <author>
      <name>David Wilson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-39320-4_9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-39320-4_9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in: Proceedings of Conferences on Intelligent Computer
  Mathematics (CICM '13) - Mathematical Knowledge Management (MKM) strand</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Intelligent Computer Mathematics. Berlin: Springer, pp. 136-151.
  (Lecture Notes in Computer Science; 7961), 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7223v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7223v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30, 33F10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.1; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4452v3</id>
    <updated>2015-07-28T12:52:07Z</updated>
    <published>2013-05-20T07:26:33Z</published>
    <title>PetIGA: A Framework for High-Performance Isogeometric Analysis</title>
    <summary>  We present PetIGA, a code framework to approximate the solution of partial
differential equations using isogeometric analysis. PetIGA can be used to
assemble matrices and vectors which come from a Galerkin weak form, discretized
with Non-Uniform Rational B-spline basis functions. We base our framework on
PETSc, a high-performance library for the scalable solution of partial
differential equations, which simplifies the development of large-scale
scientific codes, provides a rich environment for prototyping, and separates
parallelism from algorithm choice. We describe the implementation of PetIGA,
and exemplify its use by solving a model nonlinear problem. To illustrate the
robustness and flexibility of PetIGA, we solve some challenging nonlinear
partial differential equations that include problems in both solid and fluid
mechanics. We show strong scaling results on up to 4096 cores, which confirm
the suitability of PetIGA for large scale simulations.
</summary>
    <author>
      <name>Lisandro Dalcin</name>
    </author>
    <author>
      <name>Nathan Collier</name>
    </author>
    <author>
      <name>Philippe Vignal</name>
    </author>
    <author>
      <name>Adriano M. A. Cortes</name>
    </author>
    <author>
      <name>V. M. Calo</name>
    </author>
    <link href="http://arxiv.org/abs/1305.4452v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4452v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5710v1</id>
    <updated>2013-05-24T12:26:45Z</updated>
    <published>2013-05-24T12:26:45Z</published>
    <title>Formal Mathematics on Display: A Wiki for Flyspeck</title>
    <summary>  The Agora system is a prototype "Wiki for Formal Mathematics", with an aim to
support developing and documenting large formalizations of mathematics in a
proof assistant. The functions implemented in Agora include in-browser editing,
strong AI/ATP proof advice, verification, and HTML rendering. The HTML
rendering contains hyperlinks and provides on-demand explanation of the proof
state for each proof step. In the present paper we show the prototype Flyspeck
Wiki as an instance of Agora for HOL Light formalizations. The wiki can be used
for formalizations of mathematics and for writing informal wiki pages about
mathematics. Such informal pages may contain islands of formal text, which is
used here for providing an initial cross-linking between Hales's informal
Flyspeck book, and the formal Flyspeck development.
  The Agora platform intends to address distributed wiki-style collaboration on
large formalization projects, in particular both the aspect of immediate
editing, verification and rendering of formal code, and the aspect of gradual
and mutual refactoring and correspondence of the initial informal text and its
formalization. Here, we highlight these features within the Flyspeck Wiki.
</summary>
    <author>
      <name>Carst Tankink</name>
    </author>
    <author>
      <name>Cezary Kaliszyk</name>
    </author>
    <author>
      <name>Josef Urban</name>
    </author>
    <author>
      <name>Herman Geuvers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, published as part of the CICM 2013 conference proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.5710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1352v1</id>
    <updated>2013-07-04T14:33:31Z</updated>
    <published>2013-07-04T14:33:31Z</published>
    <title>A Mathematica package to cope with partially ordered sets</title>
    <summary>  Mathematica offers, by way of the package Combinatorics, many useful
functions to work on graphs and ordered structures, but none of these functions
was specific enough to meet the needs of our research group. Moreover, the
existing functions are not always helpful when one has to work on new concepts.
  In this paper we present a package of features developed in Mathematica which
we consider particularly useful for the study of certain categories of
partially ordered sets. Among the features offered, the package includes: (1)
some basic features to treat partially ordered sets; (2) the ability to
enumerate, create, and display monotone and regular partitions of partially
ordered sets; (3) the capability of constructing the lattices of partitions of
a poset, and of doing some useful computations on these structures; (4) the
possibility of computing products and coproducts in the category of partially
ordered sets and monotone maps; (5) the possibility of computing products and
coproducts in the category of forests (disjoint union of trees) and open maps
(cf. [DM06] for the product between forests).
</summary>
    <author>
      <name>Pietro Codara</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematica Italia User Group Meeting (UGM) 2010, ISBN
  9788896810002. (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1352v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1352v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1945v1</id>
    <updated>2013-07-08T04:42:02Z</updated>
    <published>2013-07-08T04:42:02Z</published>
    <title>Theorema 2.0: A Graphical User Interface for a Mathematical Assistant
  System</title>
    <summary>  Theorema 2.0 stands for a re-design including a complete re-implementation of
the Theorema system, which was originally designed, developed, and implemented
by Bruno Buchberger and his Theorema group at RISC. In this paper, we present
the first prototype of a graphical user interface (GUI) for the new system. It
heavily relies on powerful interactive capabilities introduced in recent
releases of the underlying Mathematica system, most importantly the possibility
of having dynamic objects connected to interface elements like sliders, menus,
check-boxes, radio-buttons and the like. All these features are fully
integrated into the Mathematica programming environment and allow the
implementation of a modern user interface.
</summary>
    <author>
      <name>Wolfgang Windsteiger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RISC, JKU Linz, Austria</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.118.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.118.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings UITP 2012, arXiv:1307.1528</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 118, 2013, pp. 72-82</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1472v1</id>
    <updated>2013-08-07T04:15:42Z</updated>
    <published>2013-08-07T04:15:42Z</published>
    <title>ForestClaw: Hybrid forest-of-octrees AMR for hyperbolic conservation
  laws</title>
    <summary>  We present a new hybrid paradigm for parallel adaptive mesh refinement (AMR)
that combines the scalability and lightweight architecture of tree-based AMR
with the computational efficiency of patch-based solvers for hyperbolic
conservation laws. The key idea is to interpret each leaf of the AMR hierarchy
as one uniform compute patch in $\sR^d$ with $m^d$ degrees of freedom, where
$m$ is customarily between 8 and 32. Thus, computation on each patch can be
optimized for speed, while we inherit the flexibility of adaptive meshes. In
our work we choose to integrate with the p4est AMR library since it allows us
to compose the mesh from multiple mapped octrees and enables the cubed sphere
and other nontrivial multiblock geometries. We describe aspects of the parallel
implementation and close with scalings for both MPI-only and OpenMP/MPI hybrid
runs, where the largest MPI run executes on 16,384 CPU cores.
</summary>
    <author>
      <name>Carsten Burstedde</name>
    </author>
    <author>
      <name>Donna Calhoun</name>
    </author>
    <author>
      <name>Kyle Mandli</name>
    </author>
    <author>
      <name>Andy R. Terrel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3233/978-1-61499-381-0-253</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3233/978-1-61499-381-0-253" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to International Conference on Parallel Computing -
  ParCo2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Adv. Par. Comp. 25 (2014) 253-262</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.1472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8; D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5200v1</id>
    <updated>2013-08-23T18:35:59Z</updated>
    <published>2013-08-23T18:35:59Z</published>
    <title>Manopt, a Matlab toolbox for optimization on manifolds</title>
    <summary>  Optimization on manifolds is a rapidly developing branch of nonlinear
optimization. Its focus is on problems where the smooth geometry of the search
space can be leveraged to design efficient numerical algorithms. In particular,
optimization on manifolds is well-suited to deal with rank and orthogonality
constraints. Such structured constraints appear pervasively in machine learning
applications, including low-rank matrix completion, sensor network
localization, camera network registration, independent component analysis,
metric learning, dimensionality reduction and so on. The Manopt toolbox,
available at www.manopt.org, is a user-friendly, documented piece of software
dedicated to simplify experimenting with state of the art Riemannian
optimization algorithms. We aim particularly at reaching practitioners outside
our field.
</summary>
    <author>
      <name>Nicolas Boumal</name>
    </author>
    <author>
      <name>Bamdev Mishra</name>
    </author>
    <author>
      <name>P. -A. Absil</name>
    </author>
    <author>
      <name>Rodolphe Sepulchre</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Machine Learning Research, 15(1), 1455-1459 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.5200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.6029v3</id>
    <updated>2015-06-12T08:35:08Z</updated>
    <published>2013-08-28T02:14:20Z</published>
    <title>Algorithm 950: Ncpol2sdpa---Sparse Semidefinite Programming Relaxations
  for Polynomial Optimization Problems of Noncommuting Variables</title>
    <summary>  A hierarchy of semidefinite programming (SDP) relaxations approximates the
global optimum of polynomial optimization problems of noncommuting variables.
Generating the relaxation, however, is a computationally demanding task, and
only problems of commuting variables have efficient generators. We develop an
implementation for problems of noncommuting problems that creates the
relaxation to be solved by SDPA -- a high-performance solver that runs in a
distributed environment. We further exploit the inherent sparsity of
optimization problems in quantum physics to reduce the complexity of the
resulting relaxations. Constrained problems with a relaxation of order two may
contain up to a hundred variables. The implementation is available in Python.
The tool helps solve problems such as finding the ground state energy or
testing quantum correlations.
</summary>
    <author>
      <name>Peter Wittek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2699464</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2699464" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures, 1 table, 2 algorithms, the algorithm is
  available at http://peterwittek.github.io/ncpol2sdpa/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, 2015, 41(3), 21</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.6029v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.6029v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5479v1</id>
    <updated>2013-09-21T14:00:40Z</updated>
    <published>2013-09-21T14:00:40Z</published>
    <title>Higher-order Reverse Automatic Differentiation with emphasis on the
  third-order</title>
    <summary>  It is commonly assumed that calculating third order information is too
expensive for most applications. But we show that the directional derivative of
the Hessian ($D^3f(x)\cdot d$) can be calculated at a cost proportional to that
of a state-of-the-art method for calculating the Hessian matrix. We do this by
first presenting a simple procedure for designing high order reverse methods
and applying it to deduce several methods including a reverse method that
calculates $D^3f(x)\cdot d$. We have implemented this method taking into
account symmetry and sparsity, and successfully calculated this derivative for
functions with a million variables. These results indicate that the use of
third order information in a general nonlinear solver, such as Halley-Chebyshev
methods, could be a practical alternative to Newton's method.
</summary>
    <author>
      <name>Robert M. Gower</name>
    </author>
    <author>
      <name>Artur L. Gower</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10107-014-0827-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10107-014-0827-4" rel="related"/>
    <link href="http://arxiv.org/abs/1309.5479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5498v1</id>
    <updated>2013-09-21T16:45:13Z</updated>
    <published>2013-09-21T16:45:13Z</published>
    <title>High Precision Arithmetic for Scientific Applications</title>
    <summary>  All but a few digital computers used for scientific computations have
supported floating-point and digital arithmetic of rather limited numerical
precision. The underlying assumptions were that the systems being studied were
basically deterministic and of limited complexity. The ideal scientific
paradigm was the orbits of the major planets, which could be observed with high
precision, predicted for thousands of years into the future, and extrapolated
for thousands of years into the past. Much the same technology that has made
computers possible has also provided instrumentation that has vastly expanded
the scope and precision of scientific analysis. Complex nonlinear systems
exhibiting so-called chaotic dynamics are now fair game for scientists and
engineers in every discipline. Today it seems that computers need to enhance
the precision of their numerical computations to support the needs of science.
However, there is no need to wait for the necessary updates in both hardware
and software; it is easy enough to monitor numerical precision with a few minor
modifications to existing software.
</summary>
    <author>
      <name>Foster Morrison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.5498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1194v1</id>
    <updated>2013-10-04T08:08:04Z</updated>
    <published>2013-10-04T08:08:04Z</published>
    <title>Vectorized OpenCL implementation of numerical integration for higher
  order finite elements</title>
    <summary>  In our work we analyze computational aspects of the problem of numerical
integration in finite element calculations and consider an OpenCL
implementation of related algorithms for processors with wide vector registers.
  As a platform for testing the implementation we choose the PowerXCell
processor, being an example of the Cell Broadband Engine (CellBE) architecture.
Although the processor is considered old for today's standards (its design
dates back to year 2001), we investigate its performance due to two features
that it shares with recent Xeon Phi family of coprocessors: wide vector units
and relatively slow connection of computing cores with main global memory. The
performed analysis of parallelization options can also be used for designing
numerical integration algorithms for other processors with vector registers,
such as contemporary x86 microprocessors.
</summary>
    <author>
      <name>Filip Krużel</name>
    </author>
    <author>
      <name>Krzysztof Banaś</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2013.08.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2013.08.026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published online in Computers and Mathematics with Applications:
  http://www.sciencedirect.com/science/article/pii/S089812211300521X</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers &amp; Mathematics with Applications, Volume 66, Issue 10,
  December 2013, Pages 2030-2044</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.1194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0681v1</id>
    <updated>2013-11-04T12:50:09Z</updated>
    <published>2013-11-04T12:50:09Z</published>
    <title>Computation of the Marcum Q-function</title>
    <summary>  Methods and an algorithm for computing the generalized Marcum $Q-$function
($Q_{\mu}(x,y)$) and the complementary function ($P_{\mu}(x,y)$) are described.
These functions appear in problems of different technical and scientific areas
such as, for example, radar detection and communications, statistics and
probability theory, where they are called the non-central chi-square or the non
central gamma cumulative distribution functions.
  The algorithm for computing the Marcum functions combines different methods
of evaluation in different regions: series expansions, integral
representations, asymptotic expansions, and use of three-term homogeneous
recurrence relations. A relative accuracy close to $10^{-12}$ can be obtained
in the parameter region $(x,y,\mu) \in [0,\,A]\times [0,\,A]\times [1,\,A]$,
$A=200$, while for larger parameters the accuracy decreases (close to
$10^{-11}$ for $A=1000$ and close to $5\times 10^{-11}$ for $A=10000$).
</summary>
    <author>
      <name>A. Gil</name>
    </author>
    <author>
      <name>J. Segura</name>
    </author>
    <author>
      <name>N. M. Temme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in ACM Trans. Math. Softw</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6182v1</id>
    <updated>2013-12-21T00:38:02Z</updated>
    <published>2013-12-21T00:38:02Z</published>
    <title>Large-Scale Paralleled Sparse Principal Component Analysis</title>
    <summary>  Principal component analysis (PCA) is a statistical technique commonly used
in multivariate data analysis. However, PCA can be difficult to interpret and
explain since the principal components (PCs) are linear combinations of the
original variables. Sparse PCA (SPCA) aims to balance statistical fidelity and
interpretability by approximating sparse PCs whose projections capture the
maximal variance of original data. In this paper we present an efficient and
paralleled method of SPCA using graphics processing units (GPUs), which can
process large blocks of data in parallel. Specifically, we construct parallel
implementations of the four optimization formulations of the generalized power
method of SPCA (GP-SPCA), one of the most efficient and effective SPCA
approaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)
is up to eleven times faster than the corresponding CPU implementation (using
CBLAS), and up to 107 times faster than a MatLab implementation. Extensive
comparative experiments in several real-world datasets confirm that SPCA offers
a practical advantage.
</summary>
    <author>
      <name>W. Liu</name>
    </author>
    <author>
      <name>H. Zhang</name>
    </author>
    <author>
      <name>D. Tao</name>
    </author>
    <author>
      <name>Y. Wang</name>
    </author>
    <author>
      <name>K. Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Multimedia Tools and Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.6182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.0827v1</id>
    <updated>2014-01-04T16:42:05Z</updated>
    <published>2014-01-04T16:42:05Z</published>
    <title>Interaction entre mathématique et informatique Libre/Open Source par
  le logiciel mathématique</title>
    <summary>  This article focuses on the application of model development and opening the
source code available and implemented by the Free Software and Open Source
FLOSS to the instructional and teaching has both mathematics and computer by
the read-write(R/W) of mathematical software, including the most famous cases
are numerical and symbolic computation. The article analysis the development of
the mathematical model of Free/Open Source(math FLOSS) software has proven its
importance in the area of research in mathematics and computer science .
However, although their actual use, is very readable in higher education
courses. We discuss the feasibility of this model to the characteristics of the
domain, actors, interaction they have and the communities they form during the
development of the software. Finally, we propose a mathematical example of
Free/Open Source(Math FlOSS) software as analysis device .
</summary>
    <author>
      <name>K. I. A. Derouiche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, written in French, In Proceedings of the S\'eminaire
  National sur la didactique des Math\'ematiques, 25-26 Novembre Tebessa,
  Alg\'erie (SNDM'13). 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.0827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.0827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1942v3</id>
    <updated>2016-08-16T16:28:15Z</updated>
    <published>2014-01-09T10:22:26Z</published>
    <title>Test Problem Construction for Single-Objective Bilevel Optimization</title>
    <summary>  In this paper, we propose a procedure for designing controlled test problems
for single-objective bilevel optimization. The construction procedure is
flexible and allows its user to control the different complexities that are to
be included in the test problems independently of each other. In addition to
properties that control the difficulty in convergence, the procedure also
allows the user to introduce difficulties caused by interaction of the two
levels. As a companion to the test problem construction framework, the paper
presents a standard test suite of twelve problems, which includes eight
unconstrained and four constrained problems. Most of the problems are scalable
in terms of variables and constraints. To provide baseline results, we have
solved the proposed test problems using a nested bilevel evolutionary
algorithm. The results can be used for comparison, while evaluating the
performance of any other bilevel optimization algorithm. The codes related to
the paper may be accessed from the website \url{http://bilevel.org}.
</summary>
    <author>
      <name>Ankur Sinha</name>
    </author>
    <author>
      <name>Pekka Malo</name>
    </author>
    <author>
      <name>Kalyanmoy Deb</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1303.3901</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.1942v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1942v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3013v1</id>
    <updated>2014-01-13T21:18:48Z</updated>
    <published>2014-01-13T21:18:48Z</published>
    <title>Resilience in Numerical Methods: A Position on Fault Models and
  Methodologies</title>
    <summary>  Future extreme-scale computer systems may expose silent data corruption (SDC)
to applications, in order to save energy or increase performance. However,
resilience research struggles to come up with useful abstract programming
models for reasoning about SDC. Existing work randomly flips bits in running
applications, but this only shows average-case behavior for a low-level,
artificial hardware model. Algorithm developers need to understand worst-case
behavior with the higher-level data types they actually use, in order to make
their algorithms more resilient. Also, we know so little about how SDC may
manifest in future hardware, that it seems premature to draw conclusions about
the average case. We argue instead that numerical algorithms can benefit from a
numerical unreliability fault model, where faults manifest as unbounded
perturbations to floating-point data. Algorithms can use inexpensive "sanity"
checks that bound or exclude error in the results of computations. Given a
selective reliability programming model that requires reliability only when and
where needed, such checks can make algorithms reliable despite unbounded
faults. Sanity checks, and in general a healthy skepticism about the
correctness of subroutines, are wise even if hardware is perfectly reliable.
</summary>
    <author>
      <name>James Elliott</name>
    </author>
    <author>
      <name>Mark Hoemmen</name>
    </author>
    <author>
      <name>Frank Mueller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Position Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.3013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.6870v2</id>
    <updated>2014-04-21T17:28:01Z</updated>
    <published>2014-03-26T21:51:41Z</published>
    <title>A modified ziggurat algorithm for generating exponentially- and
  normally-distributed pseudorandom numbers</title>
    <summary>  The Ziggurat Algorithm is a very fast rejection sampling method for
generating PseudoRandom Numbers (PRNs) from common statistical distributions.
The algorithm divides a distribution into rectangular layers that stack on top
of each other (resembling a Ziggurat), subsuming the desired distribution.
Random values within these rectangular layers are then sampled by rejection.
This implementation splits layers into two types: those constituting the
majority that fall completely under the distribution and can be sampled
extremely fast without a rejection test, and a few additional layers that
encapsulate the fringe of the distribution and require a rejection test. This
method offers speedups of 65% for exponentially- and 82% for
normally-distributed PRNs when compared to the best available C implementations
of these generators. Even greater speedups are obtained when the algorithm is
extended to the Python and MATLAB/OCTAVE programming environments.
</summary>
    <author>
      <name>Christopher D McFarland</name>
    </author>
    <link href="http://arxiv.org/abs/1403.6870v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.6870v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6383v2</id>
    <updated>2014-04-29T14:16:55Z</updated>
    <published>2014-04-25T10:53:23Z</published>
    <title>Bloscpack: a compressed lightweight serialization format for numerical
  data</title>
    <summary>  This paper introduces the Bloscpack file format and the accompanying Python
reference implementation. Bloscpack is a lightweight, compressed binary
file-format based on the Blosc codec and is designed for lightweight, fast
serialization of numerical data. This article presents the features of the
file-format and some some API aspects of the reference implementation, in
particular the ability to handle Numpy ndarrays. Furthermore, in order to
demonstrate its utility, the format is compared both feature- and
performance-wise to a few alternative lightweight serialization solutions for
Numpy ndarrays. The performance comparisons take the form of some comprehensive
benchmarks over a range of different artificial datasets with varying size and
complexity, the results of which are presented as the last section of this
article.
</summary>
    <author>
      <name>Valentin Haenel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6383v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6383v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6388v2</id>
    <updated>2014-04-29T14:21:46Z</updated>
    <published>2014-04-25T10:55:48Z</published>
    <title>Performance of Python runtimes on a non-numeric scientific code</title>
    <summary>  The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational
homology of the moduli space of Riemann surfaces is an example of a non-numeric
scientific code: most of the processing it does is generating graphs
(represented by complex Python objects) and computing their isomorphisms (a
triple of Python lists; again a nested data structure). These operations are
repeated many times over: for example, the spaces and are triangulated by
4'583'322 and 747'664 graphs, respectively. This is an opportunity for every
Python runtime to prove its strength in optimization. The purpose of this
experiment was to assess the maturity of alternative Python runtimes, in terms
of: compatibility with the language as implemented in CPython 2.7, and
performance speedup. This paper compares the results and experiences from
running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython
0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.
</summary>
    <author>
      <name>Riccardo Murri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6388v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6388v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4644v1</id>
    <updated>2014-05-19T09:03:58Z</updated>
    <published>2014-05-19T09:03:58Z</published>
    <title>Changing Computing Paradigms Towards Power Efficiency</title>
    <summary>  Power awareness is fast becoming immensely important in computing, ranging
from the traditional High Performance Computing applications, to the new
generation of data centric workloads.
  In this work we describe our efforts towards a power efficient computing
paradigm that combines low precision and high precision arithmetic. We showcase
our ideas for the widely used kernel of solving systems of linear equations
that finds numerous applications in scientific and engineering disciplines as
well as in large scale data analytics, statistics and machine learning.
  Towards this goal we developed tools for the seamless power profiling of
applications at a fine grain level. In addition, we verify here previous work
on post FLOPS/Watt metrics and show that these can shed much more light in the
power/energy profile of important applications.
</summary>
    <author>
      <name>Pavel Klavík</name>
    </author>
    <author>
      <name>A. Cristiano I. Malossi</name>
    </author>
    <author>
      <name>Constantin Bekas</name>
    </author>
    <author>
      <name>Alessandro Curioni</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rsta.2013.0278</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rsta.2013.0278" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Philosophical Transactions of the Royal Society A: Physical,
  Mathematical and Engineering Sciences. 372(2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.4644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5956v1</id>
    <updated>2014-05-23T03:05:42Z</updated>
    <published>2014-05-23T03:05:42Z</published>
    <title>Realms: A Structure for Consolidating Knowledge about Mathematical
  Theories</title>
    <summary>  Since there are different ways of axiomatizing and developing a mathematical
theory, knowledge about a such a theory may reside in many places and in many
forms within a library of formalized mathematics. We introduce the notion of a
realm as a structure for consolidating knowledge about a mathematical theory. A
realm contains several axiomatizations of a theory that are separately
developed. Views interconnect these developments and establish that the
axiomatizations are equivalent in the sense of being mutually interpretable. A
realm also contains an external interface that is convenient for users of the
library who want to apply the concepts and facts of the theory without delving
into the details of how the concepts and facts were developed. We illustrate
the utility of realms through a series of examples. We also give an outline of
the mechanisms that are needed to create and maintain realms.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <author>
      <name>William M. Farmer</name>
    </author>
    <author>
      <name>Michael Kohlhase</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">As accepted for CICM 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7012v4</id>
    <updated>2017-02-01T15:53:42Z</updated>
    <published>2014-05-27T19:01:57Z</published>
    <title>A formally verified proof of the Central Limit Theorem</title>
    <summary>  We describe a proof of the Central Limit Theorem that has been formally
verified in the Isabelle proof assistant. Our formalization builds upon and
extends Isabelle's libraries for analysis and measure-theoretic probability.
The proof of the theorem uses characteristic functions, which are a kind of
Fourier transform, to demonstrate that, under suitable hypotheses, sums of
random variables converge weakly to the standard normal distribution. We also
discuss the libraries and infrastructure that supported the formalization, and
reflect on some of the lessons we have learned from the effort.
</summary>
    <author>
      <name>Jeremy Avigad</name>
    </author>
    <author>
      <name>Johannes Hölzl</name>
    </author>
    <author>
      <name>Luke Serafin</name>
    </author>
    <link href="http://arxiv.org/abs/1405.7012v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7012v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F05, 03B35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5369v1</id>
    <updated>2014-06-20T12:46:27Z</updated>
    <published>2014-06-20T12:46:27Z</published>
    <title>A Scala Prototype to Generate Multigrid Solver Implementations for
  Different Problems and Target Multi-Core Platforms</title>
    <summary>  Many problems in computational science and engineering involve partial
differential equations and thus require the numerical solution of large, sparse
(non)linear systems of equations. Multigrid is known to be one of the most
efficient methods for this purpose. However, the concrete multigrid algorithm
and its implementation highly depend on the underlying problem and hardware.
Therefore, changes in the code or many different variants are necessary to
cover all relevant cases. In this article we provide a prototype implementation
in Scala for a framework that allows abstract descriptions of PDEs, their
discretization, and their numerical solution via multigrid algorithms. From
these, one is able to generate data structures and implementations of multigrid
components required to solve elliptic PDEs on structured grids. Two different
test problems showcase our proposed automatic generation of multigrid solvers
for both CPU and GPU target platforms.
</summary>
    <author>
      <name>Harald Koestler</name>
    </author>
    <author>
      <name>Christian Schmitt</name>
    </author>
    <author>
      <name>Sebastian Kuckuk</name>
    </author>
    <author>
      <name>Frank Hannig</name>
    </author>
    <author>
      <name>Juergen Teich</name>
    </author>
    <author>
      <name>Ulrich Ruede</name>
    </author>
    <link href="http://arxiv.org/abs/1406.5369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5550v2</id>
    <updated>2014-06-27T14:40:04Z</updated>
    <published>2014-06-20T22:31:25Z</published>
    <title>ViDaExpert: user-friendly tool for nonlinear visualization and analysis
  of multidimensional vectorial data</title>
    <summary>  ViDaExpert is a tool for visualization and analysis of multidimensional
vectorial data. ViDaExpert is able to work with data tables of "object-feature"
type that might contain numerical feature values as well as textual labels for
rows (objects) and columns (features). ViDaExpert implements several
statistical methods such as standard and weighted Principal Component Analysis
(PCA) and the method of elastic maps (non-linear version of PCA), Linear
Discriminant Analysis (LDA), multilinear regression, K-Means clustering, a
variant of decision tree construction algorithm. Equipped with several
user-friendly dialogs for configuring data point representations (size, shape,
color) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an
interactive 3D-scene representing a table of data in multidimensional space and
perform its quick and insightfull statistical analysis, from basic to advanced
methods.
</summary>
    <author>
      <name>Alexander N. Gorban</name>
    </author>
    <author>
      <name>Alexander Pitenko</name>
    </author>
    <author>
      <name>Andrei Zinovyev</name>
    </author>
    <link href="http://arxiv.org/abs/1406.5550v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5550v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N01, 68W25" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2925v1</id>
    <updated>2014-07-09T10:45:40Z</updated>
    <published>2014-07-09T10:45:40Z</published>
    <title>A data porting tool for coupling models with different discretization
  needs</title>
    <summary>  The presented work is part of a larger research program dealing with
developing tools for coupling biogeochemical models in contaminated landscapes.
The specific objective of this article is to provide the researchers a tool to
build hexagonal raster using information from a rectangular raster data (e.g.
GIS format), data porting. This tool involves a computational algorithm and an
open source software (written in C). The method of extending the reticulated
functions defined on 2D networks is an essential key of this algorithm and can
also be used for other purposes than data porting. The algorithm allows one to
build the hexagonal raster with a cell size independent from the geometry of
the rectangular raster. The extended function is a bi-cubic spline which can
exactly reconstruct polynomials up to degree three in each variable. We
validate the method by analyzing errors in some theoretical case studies
followed by other studies with real terrain elevation data. We also introduce
and briefly present an iterative water routing method and use it for validation
on a case with concrete terrain data.
</summary>
    <author>
      <name>Stelian Ion</name>
    </author>
    <author>
      <name>Dorin Marinescu</name>
    </author>
    <author>
      <name>Stefan-Gicu Cruceanu</name>
    </author>
    <author>
      <name>Virgil Iordache</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.envsoft.2014.09.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.envsoft.2014.09.012" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Environmental Modelling &amp; Software 62 (2014) 240-252</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1407.2925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3262v1</id>
    <updated>2014-06-25T19:38:09Z</updated>
    <published>2014-06-25T19:38:09Z</published>
    <title>Elements of Design for Containers and Solutions in the LinBox Library</title>
    <summary>  We describe in this paper new design techniques used in the \cpp exact linear
algebra library \linbox, intended to make the library safer and easier to use,
while keeping it generic and efficient. First, we review the new simplified
structure for containers, based on our \emph{founding scope allocation} model.
We explain design choices and their impact on coding: unification of our matrix
classes, clearer model for matrices and submatrices, \etc Then we present a
variation of the \emph{strategy} design pattern that is comprised of a
controller--plugin system: the controller (solution) chooses among plug-ins
(algorithms) that always call back the controllers for subtasks. We give
examples using the solution \mul. Finally we present a benchmark architecture
that serves two purposes: Providing the user with easier ways to produce
graphs; Creating a framework for automatically tuning the library and
supporting regression testing.
</summary>
    <author>
      <name>Brice Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Guillaume Dumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Pascal Giorgi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM</arxiv:affiliation>
    </author>
    <author>
      <name>Clément Pernet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>B. David Saunders</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CIS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4th International Congress on Mathematical Software, Seoul :
  Korea, Republic Of (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.3262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6245v1</id>
    <updated>2014-07-23T14:55:21Z</updated>
    <published>2014-07-23T14:55:21Z</published>
    <title>scikit-image: Image processing in Python</title>
    <summary>  scikit-image is an image processing library that implements algorithms and
utilities for use in research, education and industry applications. It is
released under the liberal "Modified BSD" open source license, provides a
well-documented API in the Python programming language, and is developed by an
active, international team of collaborators. In this paper we highlight the
advantages of open source to achieve the goals of the scikit-image library, and
we showcase several real-world image processing applications that use
scikit-image.
</summary>
    <author>
      <name>Stefan van der Walt</name>
    </author>
    <author>
      <name>Johannes L. Schönberger</name>
    </author>
    <author>
      <name>Juan Nunez-Iglesias</name>
    </author>
    <author>
      <name>François Boulogne</name>
    </author>
    <author>
      <name>Joshua D. Warner</name>
    </author>
    <author>
      <name>Neil Yager</name>
    </author>
    <author>
      <name>Emmanuelle Gouillart</name>
    </author>
    <author>
      <name>Tony Yu</name>
    </author>
    <author>
      <name>the scikit-image contributors</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7717/peerj.453</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7717/peerj.453" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Distributed under Creative Commons CC-BY 4.0. Published in PeerJ</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6954v3</id>
    <updated>2015-08-15T11:23:22Z</updated>
    <published>2014-07-25T16:12:26Z</published>
    <title>The DUNE-ALUGrid Module</title>
    <summary>  In this paper we present the new DUNE-ALUGrid module. This module contains a
major overhaul of the sources from the ALUgrid library and the binding to the
DUNE software framework. The main changes include user defined load balancing,
parallel grid construction, and an redesign of the 2d grid which can now also
be used for parallel computations. In addition many improvements have been
introduced into the code to increase the parallel efficiency and to decrease
the memory footprint.
  The original ALUGrid library is widely used within the DUNE community due to
its good parallel performance for problems requiring local adaptivity and
dynamic load balancing. Therefore, this new model will benefit a number of DUNE
users. In addition we have added features to increase the range of problems for
which the grid manager can be used, for example, introducing a 3d tetrahedral
grid using a parallel newest vertex bisection algorithm for conforming grid
refinement. In this paper we will discuss the new features, extensions to the
DUNE interface, and explain for various examples how the code is used in
parallel environments.
</summary>
    <author>
      <name>Martin Alkämper</name>
    </author>
    <author>
      <name>Andreas Dedner</name>
    </author>
    <author>
      <name>Robert Klöfkorn</name>
    </author>
    <author>
      <name>Martin Nolte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6954v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6954v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0074v1</id>
    <updated>2014-08-01T04:29:30Z</updated>
    <published>2014-08-01T04:29:30Z</published>
    <title>Software for Computing the Spheroidal Wave Functions Using Arbitrary
  Precision Arithmetic</title>
    <summary>  The spheroidal wave functions, which are the solutions to the Helmholtz
equation in spheroidal coordinates, are notoriously difficult to compute.
Because of this, practically no programming language comes equipped with the
means to compute them. This makes problems that require their use hard to
tackle. We have developed computational software for calculating these special
functions. Our software is called spheroidal and includes several novel
features, such as: using arbitrary precision arithmetic; adaptively choosing
the number of expansion coefficients to compute and use; and using the
Wronskian to choose from several different methods for computing the spheroidal
radial functions to improve their accuracy. There are two types of spheroidal
wave functions: the prolate kind when prolate spheroidal coordinates are used;
and the oblate kind when oblate spheroidal coordinate are used. In this paper,
we describe both, methods for computing them, and our software. We have made
our software freely available on our webpage.
</summary>
    <author>
      <name>Ross Adelman</name>
    </author>
    <author>
      <name>Nail A. Gumerov</name>
    </author>
    <author>
      <name>Ramani Duraiswami</name>
    </author>
    <link href="http://arxiv.org/abs/1408.0074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0393v1</id>
    <updated>2014-08-02T16:17:40Z</updated>
    <published>2014-08-02T16:17:40Z</published>
    <title>Standards for Graph Algorithm Primitives</title>
    <summary>  It is our view that the state of the art in constructing a large collection
of graph algorithms in terms of linear algebraic operations is mature enough to
support the emergence of a standard set of primitive building blocks. This
paper is a position paper defining the problem and announcing our intention to
launch an open effort to define this standard.
</summary>
    <author>
      <name>Tim Mattson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intel Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>David Bader</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Georgia Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Jon Berry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Sandia National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Aydin Buluc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lawrence Berkeley National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Jack Dongarra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Tennessee</arxiv:affiliation>
    </author>
    <author>
      <name>Christos Faloutsos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Melon University</arxiv:affiliation>
    </author>
    <author>
      <name>John Feo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pacific Northwest National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>John Gilbert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of California at Santa Barbara</arxiv:affiliation>
    </author>
    <author>
      <name>Joseph Gonzalez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of California at Berkeley</arxiv:affiliation>
    </author>
    <author>
      <name>Bruce Hendrickson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Sandia National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Jeremy Kepner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Massachusetts Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Charles Leiserson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Massachusetts Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Andrew Lumsdaine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Indiana University</arxiv:affiliation>
    </author>
    <author>
      <name>David Padua</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Illinois at Urbana-Champaign</arxiv:affiliation>
    </author>
    <author>
      <name>Stephen Poole</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Oak Ridge National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Steve Reinhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cray Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Mike Stonebraker</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Massachusetts Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Steve Wallach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Convey Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Andrew Yoo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lawrence Livermore National Laboratory</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HPEC.2013.6670338</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HPEC.2013.6670338" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, IEEE HPEC 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.0393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1363v1</id>
    <updated>2014-08-06T17:37:03Z</updated>
    <published>2014-08-06T17:37:03Z</published>
    <title>Lighthouse: A User-Centered Web Service for Linear Algebra Software</title>
    <summary>  Various fields of science and engineering rely on linear algebra for large
scale data analysis, modeling and simulation, machine learning, and other
applied problems. Linear algebra computations often dominate the execution time
of such applications. Meanwhile, experts in these domains typically lack the
training or time required to develop efficient, high-performance
implementations of linear algebra algorithms. In the Lighthouse project, we
enable developers with varied backgrounds to readily discover and effectively
apply the best available numerical software for their problems. We have
developed a search-based expert system that combines expert knowledge, machine
learningbased classification of existing numerical software collections, and
automated code generation and optimization. Lighthouse provides a novel
software engineering environment aimed at maximizing both developer
productivity and application performance for dense and sparse linear algebra
computations.
</summary>
    <author>
      <name>Boyana Norris</name>
    </author>
    <author>
      <name>Sa-Lin Bernstein</name>
    </author>
    <author>
      <name>Ramya Nair</name>
    </author>
    <author>
      <name>Elizabeth Jessup</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; H.4; D.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1900v1</id>
    <updated>2014-08-07T07:16:07Z</updated>
    <published>2014-08-07T07:16:07Z</published>
    <title>A Report of a Significant Error On a Frequently Used Pseudo Random
  Number Generator</title>
    <summary>  Emergence of stochastic simulations as an extensively used computational tool
for scientific purposes intensified the need for more accurate ways of
generating sufficiently long sequences of uncorrelated random numbers. Even
though several different methods have been proposed for this end, deterministic
algorithms known as pseudo-random number generators (PRNGs) emerged to be the
most widely used tool as a replicable, portable and easy to use method to
generate such random number sequences. Here, we introduce a simple Poisson
process whose simulation gives systematic errors when the very commonly used
random number generator of the GNU C Library (Glibc) is utilised. The PRNG of
Glibc is an additive lagged Fibonacci generator, the family of such PRNGs are
accepted as relatively safe among other PRNGs. The systematic errors indicate
complex correlation relations among random numbers which requires a further
explanation.
</summary>
    <author>
      <name>Ayse Ferhan Yesil</name>
    </author>
    <author>
      <name>M. Cemal Yalabik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.3082v2</id>
    <updated>2015-04-24T19:36:57Z</updated>
    <published>2014-08-13T18:42:01Z</published>
    <title>Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators</title>
    <summary>  Revisionist integral deferred correction (RIDC) methods are a family of
parallel--in--time methods to solve systems of initial values problems. The
approach is able to bootstrap lower order time integrators to provide high
order approximations in approximately the same wall clock time, hence providing
a multiplicative increase in the number of compute cores utilized. Here we
provide a C++ framework which automatically produces a parallel--in--time
solution of a system of initial value problems given user supplied code for the
right hand side of the system and a sequential code for a first-order time
step. The user supplied time step routine may be explicit or implicit and may
make use of any auxiliary libraries which take care of the solution of any
nonlinear algebraic systems which may arise or the numerical linear algebra
required. The code contains six examples of increasing complexity which also
serve as templates to solve user defined problems.
</summary>
    <author>
      <name>Benjamin Ong</name>
    </author>
    <author>
      <name>Ronald Haynes</name>
    </author>
    <author>
      <name>Kyle Ladd</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2964377</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2964377" rel="related"/>
    <link href="http://arxiv.org/abs/1408.3082v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.3082v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0669v1</id>
    <updated>2014-09-02T11:21:13Z</updated>
    <published>2014-09-02T11:21:13Z</published>
    <title>Performance Portability Study of Linear Algebra Kernels in OpenCL</title>
    <summary>  The performance portability of OpenCL kernel implementations for common
memory bandwidth limited linear algebra operations across different hardware
generations of the same vendor as well as across vendors is studied. Certain
combinations of kernel implementations and work sizes are found to exhibit good
performance across compute kernels, hardware generations, and, to a lesser
degree, vendors. As a consequence, it is demonstrated that the optimization of
a single kernel is often sufficient to obtain good performance for a large
class of more complicated operations.
</summary>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Philippe Tillet</name>
    </author>
    <author>
      <name>Florian Rudolf</name>
    </author>
    <author>
      <name>Josef Weinbub</name>
    </author>
    <author>
      <name>Tibor Grasser</name>
    </author>
    <author>
      <name>Ansgar Jüngel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2664666.2664674</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2664666.2664674" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures, 2 tables, International Workshop on OpenCL 2014</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Workshop on OpenCL 2013 &amp; 2014
  (IWOCL)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.0669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.8186v1</id>
    <updated>2014-09-29T16:48:16Z</updated>
    <published>2014-09-29T16:48:16Z</published>
    <title>$μ$-diff: an open-source Matlab toolbox for computing multiple
  scattering problems by disks</title>
    <summary>  The aim of this paper is to describe a Matlab toolbox, called $\mu$-diff, for
modeling and numerically solving two-dimensional complex multiple scattering by
a large collection of circular cylinders. The approximation methods in
$\mu$-diff are based on the Fourier series expansions of the four basic
integral operators arising in scattering theory. Based on these expressions, an
efficient spectrally accurate finite-dimensional solution of multiple
scattering problems can be simply obtained for complex media even when many
scatterers are considered as well as large frequencies. The solution of the
global linear system to solve can use either direct solvers or preconditioned
iterative Krylov subspace solvers for block Toeplitz matrices. Based on this
approach, this paper explains how the code is built and organized. Some
complete numerical examples of applications (direct and inverse scattering) are
provided to show that $\mu$-diff is a flexible, efficient and robust toolbox
for solving some complex multiple scattering problems.
</summary>
    <author>
      <name>Bertrand Thierry</name>
    </author>
    <author>
      <name>Xavier Antoine</name>
    </author>
    <author>
      <name>Chokri Chniti</name>
    </author>
    <author>
      <name>Hasan Alzubaidi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2015.03.013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2015.03.013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 15 figures, associated code available online at
  http://mu-diff.math.cnrs.fr</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.8186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.8186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35J05, 78A45, 78A48, 76Q05, 65M70, 31A10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0564v1</id>
    <updated>2014-10-02T14:27:17Z</updated>
    <published>2014-10-02T14:27:17Z</published>
    <title>Automatic Generation of Loop-Invariants for Matrix Operations</title>
    <summary>  In recent years it has been shown that for many linear algebra operations it
is possible to create families of algorithms following a very systematic
procedure. We do not refer to the fine tuning of a known algorithm, but to a
methodology for the actual generation of both algorithms and routines to solve
a given target matrix equation. Although systematic, the methodology relies on
complex algebraic manipulations and non-obvious pattern matching, making the
procedure challenging to be performed by hand, our goal is the development of a
fully automated system that from the sole description of a target equation
creates multiple algorithms and routines. We present CL1ck, a symbolic system
written in Mathematica, that starts with an equation, decomposes it into
multiple equations, and returns a set of loop-invariants for the algorithms --
yet to be generated -- that will solve the equation. In a successive step each
loop-invariant is then mapped to its corresponding algorithm and routine. For a
large class of equations, the methodology generates known algorithms as well as
many previously unknown ones. Most interestingly, the methodology unifies
algorithms traditionally developed in isolation. As an example, the five well
known algorithms for the LU factorization are for the first time unified under
a common root.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <link href="http://arxiv.org/abs/1410.0564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1726v1</id>
    <updated>2014-10-07T13:43:53Z</updated>
    <published>2014-10-07T13:43:53Z</published>
    <title>KBLAS: An Optimized Library for Dense Matrix-Vector Multiplication on
  GPU Accelerators</title>
    <summary>  KBLAS is a new open source high performance library that provides optimized
kernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.
Since performance of dense matrix-vector multiplication is hindered by the
overhead of memory accesses, a double-buffering optimization technique is
employed to overlap data motion with computation. After identifying a proper
set of tuning parameters, KBLAS is able to efficiently run on various GPU
architectures across different generations, avoiding the time-consuming step of
code rewriting, while still being compliant with the standard BLAS API. Another
advanced optimization technique allows to ensure coalesced memory access when
dealing with submatrices, especially in the context of high level dense linear
algebra algorithms. All four precisions KBLAS kernels have been leveraged to
multi-GPUs environment, which requires the introduction of new APIs to ease
users' experiences on these challenging systems. The KBLAS performance
outperforms existing state-of-the-art implementations on all matrix sizes,
achieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs
systems, respectively, and validates our performance model. A subset of KBLAS
high performance kernels has been integrated into NVIDIA's standard BLAS
implementation (cuBLAS) for larger dissemination, starting version 6.0.
</summary>
    <author>
      <name>Ahmad Abdelfattah</name>
    </author>
    <author>
      <name>David Keyes</name>
    </author>
    <author>
      <name>Hatem Ltaief</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the ACM Transactions on Mathematical Software</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.1726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1764v1</id>
    <updated>2014-10-03T20:53:26Z</updated>
    <published>2014-10-03T20:53:26Z</published>
    <title>Chemora: A PDE Solving Framework for Modern HPC Architectures</title>
    <summary>  Modern HPC architectures consist of heterogeneous multi-core, many-node
systems with deep memory hierarchies. Modern applications employ ever more
advanced discretisation methods to study multi-physics problems. Developing
such applications that explore cutting-edge physics on cutting-edge HPC systems
has become a complex task that requires significant HPC knowledge and
experience. Unfortunately, this combined knowledge is currently out of reach
for all but a few groups of application developers.
  Chemora is a framework for solving systems of Partial Differential Equations
(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which
sees prominent usage in the computational relativistic astrophysics community.
In Chemora, PDEs are expressed either in a high-level \LaTeX-like language or
in Mathematica. Discretisation stencils are defined separately from equations,
and can include Finite Differences, Discontinuous Galerkin Finite Elements
(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.
  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on
CPUs and on accelerators, and study astrophysical systems such as black hole
binaries, neutron stars, and core-collapse supernovae.
</summary>
    <author>
      <name>Erik Schnetter</name>
    </author>
    <author>
      <name>Marek Blazewicz</name>
    </author>
    <author>
      <name>Steven R. Brandt</name>
    </author>
    <author>
      <name>David M. Koppelman</name>
    </author>
    <author>
      <name>Frank Löffler</name>
    </author>
    <link href="http://arxiv.org/abs/1410.1764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4054v3</id>
    <updated>2016-11-04T11:18:16Z</updated>
    <published>2014-10-15T13:23:31Z</published>
    <title>Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing
  Units</title>
    <summary>  We revisit the implementation of iterative solvers on discrete graphics
processing units and demonstrate the benefit of implementations using extensive
kernel fusion for pipelined formulations over conventional implementations of
classical formulations. The proposed implementations with both CUDA and OpenCL
are freely available in ViennaCL and are shown to be competitive with or even
superior to other solver packages for graphics processing units. Highest
performance gains are obtained for small to medium-sized systems, while our
implementations are on par with vendor-tuned implementations for very large
systems. Our results are especially beneficial for transient problems, where
many small to medium-sized systems instead of a single big system need to be
solved.
</summary>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Josef Weinbub</name>
    </author>
    <author>
      <name>Ansgar Jüngel</name>
    </author>
    <author>
      <name>Tibor Grasser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2907944</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2907944" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 9 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software (TOMS), Volume 43, Issue
  2, Article No. 11 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.4054v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4054v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F10 (Secondary), 65F50, 65Y05 (Primary), 65Y10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1607v4</id>
    <updated>2015-07-19T19:58:28Z</updated>
    <published>2014-11-06T13:39:40Z</published>
    <title>Julia: A Fresh Approach to Numerical Computing</title>
    <summary>  Bridging cultures that have often been distant, Julia combines expertise from
the diverse fields of computer science and computational science to create a
new approach to numerical computing. Julia is designed to be easy and fast.
Julia questions notions generally held as "laws of nature" by practitioners of
numerical computing:
  1. High-level dynamic programs have to be slow.
  2. One must prototype in one language and then rewrite in another language
for speed or deployment, and
  3. There are parts of a system for the programmer, and other parts best left
untouched as they are built by the experts.
  We introduce the Julia programming language and its design --- a dance
between specialization and abstraction. Specialization allows for custom
treatment. Multiple dispatch, a technique from computer science, picks the
right algorithm for the right circumstance. Abstraction, what good computation
is really about, recognizes what remains the same after differences are
stripped away. Abstractions in mathematics are captured as code through another
technique from computer science, generic programming.
  Julia shows that one can have machine performance without sacrificing human
convenience.
</summary>
    <author>
      <name>Jeff Bezanson</name>
    </author>
    <author>
      <name>Alan Edelman</name>
    </author>
    <author>
      <name>Stefan Karpinski</name>
    </author>
    <author>
      <name>Viral B. Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1607v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1607v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1830v2</id>
    <updated>2015-01-29T17:21:36Z</updated>
    <published>2014-11-07T05:10:34Z</published>
    <title>Introduction to the R package TDA</title>
    <summary>  We present a short tutorial and introduction to using the R package TDA,
which provides some tools for Topological Data Analysis. In particular, it
includes implementations of functions that, given some data, provide
topological information about the underlying space, such as the distance
function, the distance to a measure, the kNN density estimator, the kernel
density estimator, and the kernel distance. The salient topological features of
the sublevel sets (or superlevel sets) of these functions can be quantified
with persistent homology. We provide an R interface for the efficient
algorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function
for the persistent homology of the Rips filtration, and one for the persistent
homology of sublevel sets (or superlevel sets) of arbitrary functions evaluated
over a grid of points. The significance of the features in the resulting
persistence diagrams can be analyzed with functions that implement recently
developed statistical methods. The R package TDA also includes the
implementation of an algorithm for density clustering, which allows us to
identify the spatial organization of the probability mass associated to a
density function and visualize it by means of a dendrogram, the cluster tree.
</summary>
    <author>
      <name>Brittany Terese Fasy</name>
    </author>
    <author>
      <name>Jisu Kim</name>
    </author>
    <author>
      <name>Fabrizio Lecci</name>
    </author>
    <author>
      <name>Clément Maria</name>
    </author>
    <link href="http://arxiv.org/abs/1411.1830v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1830v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0436v4</id>
    <updated>2015-09-07T15:03:45Z</updated>
    <published>2014-12-01T11:35:47Z</published>
    <title>An Infra-Structure for Performance Estimation and Experimental
  Comparison of Predictive Models in R</title>
    <summary>  This document describes an infra-structure provided by the R package
performanceEstimation that allows to estimate the predictive performance of
different approaches (workflows) to predictive tasks. The infra-structure is
generic in the sense that it can be used to estimate the values of any
performance metrics, for any workflow on different predictive tasks, namely,
classification, regression and time series tasks. The package also includes
several standard workflows that allow users to easily set up their experiments
limiting the amount of work and information they need to provide. The overall
goal of the infra-structure provided by our package is to facilitate the task
of estimating the predictive performance of different modeling approaches to
predictive tasks in the R environment.
</summary>
    <author>
      <name>Luis Torgo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Updated to version 1.0.2 of the R package. Added a small section on
  package installation. Made explicit the reference to the R package version
  number within the document</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.0436v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0436v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6407v1</id>
    <updated>2014-12-19T16:03:26Z</updated>
    <published>2014-12-19T16:03:26Z</published>
    <title>Enhancing SfePy with Isogeometric Analysis</title>
    <summary>  In the paper a recent enhancement to the open source package SfePy (Simple
Finite Elements in Python, http://sfepy.org) is introduced, namely the addition
of another numerical discretization scheme, the isogeometric analysis, to the
original implementation based on the nowadays standard and well-established
numerical solution technique, the finite element method. The isogeometric
removes the need of the solution domain approximation by a piece-wise polygonal
domain covered by the finite element mesh, and allows approximation of unknown
fields with a higher smoothness then the finite element method, which can be
advantageous in many applications. Basic numerical examples illustrating the
implementation and use of the isogeometric analysis in SfePy are shown.
</summary>
    <author>
      <name>Robert Cimrman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01578v1</id>
    <updated>2015-01-07T18:06:17Z</updated>
    <published>2015-01-07T18:06:17Z</published>
    <title>GammaCHI: a package for the inversion and computation of the gamma and
  chi-square cumulative distribution functions (central and noncentral)</title>
    <summary>  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and
chi-square cumulative distribution functions (central and noncentral) is
presented. The main novelty of this package are the reliable and accurate
inversion routines for the noncentral cumulative distribution functions.
Additionally, the package also provides routines for computing the gamma
function, the error function and other functions related to the gamma function.
The module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,
errorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation
of the central gamma distribution function (and its complementary function),
the inversion of the central gamma distribution function, the computation of
the noncentral gamma distribution function (and its complementary function),
the inversion of the noncentral gamma distribution function, the computation of
the error function and its complementary function, the inversion of the
complementary error function, the computation of: the gamma function, the
logarithm of the gamma function, the regulated gamma function and the ratio of
two gamma functions, respectively.
</summary>
    <author>
      <name>A. Gil</name>
    </author>
    <author>
      <name>J. Segura</name>
    </author>
    <author>
      <name>N. M. Temme</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2015.01.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2015.01.004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Computer Physics Communications</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06625v3</id>
    <updated>2015-06-12T15:08:55Z</updated>
    <published>2015-01-26T23:54:20Z</published>
    <title>Accelerating Polynomial Homotopy Continuation on a Graphics Processing
  Unit with Double Double and Quad Double Arithmetic</title>
    <summary>  Numerical continuation methods track a solution path defined by a homotopy.
The systems we consider are defined by polynomials in several variables with
complex coefficients. For larger dimensions and degrees, the numerical
conditioning worsens and hardware double precision becomes often insufficient
to reach the end of the solution path. With double double and quad double
arithmetic, we can solve larger problems that we could not solve with hardware
double arithmetic, but at a higher computational cost. This cost overhead can
be compensated by acceleration on a Graphics Processing Unit (GPU). We describe
our implementation and report on computational results on benchmark polynomial
systems.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <author>
      <name>Xiangcheng Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the Proceedings of the 7th International
  Workshop on Parallel Symbolic Computation (PASCO 2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06625v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06625v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07350v2</id>
    <updated>2015-08-26T06:29:34Z</updated>
    <published>2015-01-29T06:12:52Z</published>
    <title>Performance Tuning of a Parallel 3-D FFT Package OpenFFT</title>
    <summary>  The fast Fourier transform (FFT) is a primitive kernel in numerous fields of
science and engineering. OpenFFT is an open-source parallel package for 3-D
FFTs, built on a communication-optimal domain decomposition method for
achieving minimal volume of communication. In this paper, we analyze and tune
the performance of OpenFFT, paying a particular attention to tuning of
communication that dominates the run time of large-scale calculations. We first
analyze its performance on different machines for an understanding of the
behaviors of the package and machines. Based on the performance analysis, we
develop six communication methods for performing communication with the aim of
covering varied calculation scales on a variety of computational platforms.
OpenFFT is then augmented with an auto-tuning of communication to select the
best method in run time depending on their performance. Numerical results
demonstrate that the optimized OpenFFT is able to deliver relatively good
performance in comparison with other state-of-the-art packages at different
computational scales on a number of parallel machines.
</summary>
    <author>
      <name>Truong Vinh Truong Duy</name>
    </author>
    <author>
      <name>Taisuke Ozaki</name>
    </author>
    <link href="http://arxiv.org/abs/1501.07350v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07350v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01367v2</id>
    <updated>2015-02-11T23:47:10Z</updated>
    <published>2015-02-04T21:48:25Z</published>
    <title>Visualizing Marden's theorem with Scilab</title>
    <summary>  A theorem which is named after the American Mathematician Moris Marden states
a very surprising and interesting fact concerning the relationship between the
points of a triangle in the complex plane and the zeros of two complex
polynomials related to this triangle: "Suppose the zeroes z1, z2, and z3 of a
third-degree polynomial p(z) are non-collinear. There is a unique ellipse
inscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at
their midpoints: the Steiner in-ellipse. The foci of that ellipse are the
zeroes of the derivative p'(z)." (Wikipedia contributors, "Marden's theorem",
http://en.wikipedia.org/wiki/Marden%27s_theorem). This document describes how
Scilab, a popular and powerful open source alternative to MATLAB, can be used
to visualize the above stated theorem for arbitrary complex numbers z1, z2, and
z3 which are not collinear. It is further demonstrated how the equations of the
Steiner ellipses of a triangle in the complex plane can be calculated and
plotted by applying this theorem.
</summary>
    <author>
      <name>Klaus Rohe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Scilab, Marden's theorem, 2D implicit plots, geometry of complex
  numbers, Steiner ellipses</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.01367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.07405v1</id>
    <updated>2015-02-25T23:54:16Z</updated>
    <published>2015-02-25T23:54:16Z</published>
    <title>An efficient multi-core implementation of a novel HSS-structured
  multifrontal solver using randomized sampling</title>
    <summary>  We present a sparse linear system solver that is based on a multifrontal
variant of Gaussian elimination, and exploits low-rank approximation of the
resulting dense frontal matrices. We use hierarchically semiseparable (HSS)
matrices, which have low-rank off-diagonal blocks, to approximate the frontal
matrices. For HSS matrix construction, a randomized sampling algorithm is used
together with interpolative decompositions. The combination of the randomized
compression with a fast ULV HSS factorization leads to a solver with lower
computational complexity than the standard multifrontal method for many
applications, resulting in speedups up to 7 fold for problems in our test
suite. The implementation targets many-core systems by using task parallelism
with dynamic runtime scheduling. Numerical experiments show performance
improvements over state-of-the-art sparse direct solvers. The implementation
achieves high performance and good scalability on a range of modern shared
memory parallel systems, including the Intel Xeon Phi (MIC). The code is part
of a software package called STRUMPACK -- STRUctured Matrices PACKage, which
also has a distributed memory component for dense rank-structured matrices.
</summary>
    <author>
      <name>Pieter Ghysels</name>
    </author>
    <author>
      <name>Xiaoye S. Li</name>
    </author>
    <author>
      <name>Francois-Henry Rouet</name>
    </author>
    <author>
      <name>Samuel Williams</name>
    </author>
    <author>
      <name>Artem Napov</name>
    </author>
    <link href="http://arxiv.org/abs/1502.07405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.07405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01023v1</id>
    <updated>2015-04-04T16:56:02Z</updated>
    <published>2015-04-04T16:56:02Z</published>
    <title>Finite element numerical integration for first order approximations on
  multi-core architectures</title>
    <summary>  The paper presents investigations on the implementation and performance of
the finite element numerical integration algorithm for first order
approximations and three processor architectures, popular in scientific
computing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying
programming model and portable OpenCL implementation is considered for all
architectures. Variations of the algorithm due to different problems solved and
different element types are investigated and several optimizations aimed at
proper optimization and mapping of the algorithm to computer architectures are
demonstrated. Performance models of execution are developed for different
processors and tested in practical experiments. The results show the varying
levels of performance for different architectures, but indicate that the
algorithm can be effectively ported to all of them. The general conclusion is
that the finite element numerical integration can achieve sufficient
performance on different multi- and many-core architectures and should not
become a performance bottleneck for finite element simulation codes. Specific
observations lead to practical advises on how to optimize the kernels and what
performance can be expected for the tested architectures.
</summary>
    <author>
      <name>Krzysztof Banaś</name>
    </author>
    <author>
      <name>Filip Krużel</name>
    </author>
    <author>
      <name>Jan Bielański</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2016.03.038</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2016.03.038" rel="related"/>
    <link href="http://arxiv.org/abs/1504.01023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06474v2</id>
    <updated>2015-09-14T09:59:24Z</updated>
    <published>2015-04-24T11:23:38Z</published>
    <title>Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on
  Heterogeneous Processors</title>
    <summary>  Sparse matrix-vector multiplication (SpMV) is a central building block for
scientific software and graph applications. Recently, heterogeneous processors
composed of different types of cores attracted much attention because of their
flexible core configuration and high energy efficiency. In this paper, we
propose a compressed sparse row (CSR) format based SpMV algorithm utilizing
both types of cores in a CPU-GPU heterogeneous processor. We first
speculatively execute segmented sum operations on the GPU part of a
heterogeneous processor and generate a possibly incorrect results. Then the CPU
part of the same chip is triggered to re-arrange the predicted partial sums for
a correct resulting vector. On three heterogeneous processors from Intel, AMD
and nVidia, using 20 sparse matrices as a benchmark suite, the experimental
results show that our method obtains significant performance improvement over
the best existing CSR-based SpMV algorithms. The source code of this work is
downloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR
</summary>
    <author>
      <name>Weifeng Liu</name>
    </author>
    <author>
      <name>Brian Vinter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.parco.2015.04.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.parco.2015.04.004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 8 figures, Published at Parallel Computing (PARCO)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.06474v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06474v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00383v1</id>
    <updated>2015-05-03T00:50:23Z</updated>
    <published>2015-05-03T00:50:23Z</published>
    <title>Tracking Many Solution Paths of a Polynomial Homotopy on a Graphics
  Processing Unit</title>
    <summary>  Polynomial systems occur in many areas of science and engineering. Unlike
general nonlinear systems, the algebraic structure enables to compute all
solutions of a polynomial system. We describe our massive parallel
predictor-corrector algorithms to track many solution paths of a polynomial
homotopy. The data parallelism that provides the speedups stems from the
evaluation and differentiation of the monomials in the same polynomial system
at different data points, which are the points on the solution paths.
Polynomial homotopies that have tens of thousands of solution paths can keep a
sufficiently large amount of threads occupied. Our accelerated code combines
the reverse mode of algorithmic differentiation with double double and quad
double precision to compute more accurate results faster.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <author>
      <name>Xiangcheng Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00838v2</id>
    <updated>2021-05-12T22:22:54Z</updated>
    <published>2015-05-04T23:05:54Z</published>
    <title>Sparse Automatic Differentiation for Complex Networks of
  Differential-Algebraic Equations Using Abstract Elementary Algebra</title>
    <summary>  Most numerical solvers and libraries nowadays are implemented to use
mathematical models created with language-specific built-in data types (e.g.
real in Fortran or double in C) and their respective elementary algebra
implementations. However, the built-in elementary algebra typically has limited
functionality and often restricts the flexibility of mathematical models and
the analysis types that can be applied to those models. To overcome this
limitation, a number of domain-specific languages such as gPROMS or Modelica
with more feature-rich built-in data types have been proposed. In this paper,
we argue that if numerical libraries and solvers are designed to use abstract
elementary algebra rather than the language-specific built-in algebra, modern
mainstream languages can be as effective as any domain-specific language. We
illustrate our ideas using the example of sparse Jacobian matrix computation.
We implement an automatic differentiation method that takes advantage of sparse
system structures and is straightforward to parallelize in a distributed memory
setting. Furthermore, we show that the computational cost scales linearly with
the size of the system.
</summary>
    <author>
      <name>Slaven Peles</name>
    </author>
    <author>
      <name>Stefan Klus</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Numerical Analysis and Modeling. 14 (6).
  pp. 916-934 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.00838v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00838v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03357v3</id>
    <updated>2015-12-11T17:24:01Z</updated>
    <published>2015-05-13T12:34:54Z</published>
    <title>A parallel edge orientation algorithm for quadrilateral meshes</title>
    <summary>  One approach to achieving correct finite element assembly is to ensure that
the local orientation of facets relative to each cell in the mesh is consistent
with the global orientation of that facet. Rognes et al. have shown how to
achieve this for any mesh composed of simplex elements, and deal.II contains a
serial algorithm to construct a consistent orientation of any quadrilateral
mesh of an orientable manifold.
  The core contribution of this paper is the extension of this algorithm for
distributed memory parallel computers, which facilitates its seamless
application as part of a parallel simulation system.
  Furthermore, our analysis establishes a link between the well-known
Union-Find algorithm and the construction of a consistent orientation of a
quadrilateral mesh. As a result, existing work on the parallelisation of the
Union-Find algorithm can be easily adapted to construct further parallel
algorithms for mesh orientations.
</summary>
    <author>
      <name>Miklós Homolya</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/15M1021325</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/15M1021325" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Second revision: minor changes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing, 38 (2016), pp. S48-S61</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.03357v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03357v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04633v1</id>
    <updated>2015-05-18T13:35:50Z</updated>
    <published>2015-05-18T13:35:50Z</published>
    <title>Flexible, Scalable Mesh and Data Management using PETSc DMPlex</title>
    <summary>  Designing a scientific software stack to meet the needs of the
next-generation of mesh-based simulation demands, not only scalable and
efficient mesh and data management on a wide range of platforms, but also an
abstraction layer that makes it useful for a wide range of application codes.
Common utility tasks, such as file I/O, mesh distribution, and work
partitioning, should be delegated to external libraries in order to promote
code re-use, extensibility and software interoperability. In this paper we
demonstrate the use of PETSc's DMPlex data management API to perform mesh input
and domain partitioning in Fluidity, a large scale CFD application. We
demonstrate that raising the level of abstraction adds new functionality to the
application code, such as support for additional mesh file formats and mesh re-
ordering, while improving simulation startup cost through more efficient mesh
distribution. Moreover, the separation of concerns accomplished through this
interface shifts critical performance and interoperability issues, such as
scalable I/O and file format support, to a widely used and supported open
source community library, improving the sustainability, performance, and
functionality of Fluidity.
</summary>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Gerard J. Gorman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures, to appear in EASC 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07570v6</id>
    <updated>2015-11-03T03:26:49Z</updated>
    <published>2015-05-28T07:33:21Z</published>
    <title>A Practical Guide to Randomized Matrix Computations with MATLAB
  Implementations</title>
    <summary>  Matrix operations such as matrix inversion, eigenvalue decomposition,
singular value decomposition are ubiquitous in real-world applications.
Unfortunately, many of these matrix operations so time and memory expensive
that they are prohibitive when the scale of data is large. In real-world
applications, since the data themselves are noisy, machine-precision matrix
operations are not necessary at all, and one can sacrifice a reasonable amount
of accuracy for computational efficiency.
  In recent years, a bunch of randomized algorithms have been devised to make
matrix computations more scalable. Mahoney (2011) and Woodruff (2014) have
written excellent but very technical reviews of the randomized algorithms.
Differently, the focus of this manuscript is on intuition, algorithm
derivation, and implementation. This manuscript should be accessible to people
with knowledge in elementary matrix algebra but unfamiliar with randomized
matrix computations. The algorithms introduced in this manuscript are all
summarized in a user-friendly way, and they can be implemented in lines of
MATLAB code. The readers can easily follow the implementations even if they do
not understand the maths and algorithms.
</summary>
    <author>
      <name>Shusen Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1505.07570v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07570v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07589v3</id>
    <updated>2016-11-01T23:54:16Z</updated>
    <published>2015-05-28T08:25:45Z</published>
    <title>SYM-ILDL: Incomplete $LDL^{T}$ Factorization of Symmetric Indefinite and
  Skew-Symmetric Matrices</title>
    <summary>  SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$
(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric
matrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),
originally introduced and implemented for symmetric matrices by [Li and Saad,
Crout versions of ILU factorization with pivoting for sparse symmetric
matrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is
economical in terms of storage and it deals with real skew-symmetric matrices
as well, in addition to symmetric ones. The package is written in C++ and it is
templated, open source, and includes a MATLAB interface. The code includes
built-in RCM and AMD reordering, two equilibration strategies, threshold
Bunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a
popular matching based equilibration and reordering algorithm. We also include
two built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES
preconditioned with a symmetric positive definite preconditioner based on the
ILDL factorization.
</summary>
    <author>
      <name>Chen Greif</name>
    </author>
    <author>
      <name>Shiwen He</name>
    </author>
    <author>
      <name>Paul Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.07589v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07589v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.0; G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06102v1</id>
    <updated>2015-06-19T18:04:01Z</updated>
    <published>2015-06-19T18:04:01Z</published>
    <title>GRINS: A Multiphysics Framework Based on the libMesh Finite Element
  Library</title>
    <summary>  The progression of scientific computing resources has enabled the numerical
approximation of mathematical models describing complex physical phenomena. A
significant portion of researcher time is typically dedicated to the
development of software to compute the numerical solutions. This work describes
a flexible C++ software framework, built on the libMesh finite element library,
designed to alleviate developer burden and provide easy access to modern
computational algorithms, including quantity-of-interest-driven parallel
adaptive mesh refinement on unstructured grids and adjoint-based sensitivities.
Other software environments are highlighted and the current work motivated; in
particular, the present work is an attempt to balance software infrastructure
and user flexibility. The applicable class of problems and design of the
software components is discussed in detail. Several examples demonstrate the
effectiveness of the design, including applications that incorporate
uncertainty. Current and planned developments are discussed.
</summary>
    <author>
      <name>Paul T. Bauman</name>
    </author>
    <author>
      <name>Roy H. Stogner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to SISC CSE Special Issue</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.06102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06185v1</id>
    <updated>2015-06-20T00:03:16Z</updated>
    <published>2015-06-20T00:03:16Z</published>
    <title>Resilience for Multigrid Software at the Extreme Scale</title>
    <summary>  Fault tolerant algorithms for the numerical approximation of elliptic partial
differential equations on modern supercomputers play a more and more important
role in the future design of exa-scale enabled iterative solvers. Here, we
combine domain partitioning with highly scalable geometric multigrid schemes to
obtain fast and fault-robust solvers in three dimensions. The recovery strategy
is based on a hierarchical hybrid concept where the values on lower dimensional
primitives such as faces are stored redundantly and thus can be recovered
easily in case of a failure. The lost volume unknowns in the faulty region are
re-computed approximately with multigrid cycles by solving a local Dirichlet
problem on the faulty subdomain. Different strategies are compared and
evaluated with respect to performance, computational cost, and speed up.
Especially effective are strategies in which the local recovery in the faulty
region is executed in parallel with global solves and when the local recovery
is additionally accelerated. This results in an asynchronous multigrid
iteration that can fully compensate faults. Excellent parallel performance on a
current peta-scale system is demonstrated.
</summary>
    <author>
      <name>Markus Huber</name>
    </author>
    <author>
      <name>Björn Gmeiner</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <author>
      <name>Barbara Wohlmuth</name>
    </author>
    <link href="http://arxiv.org/abs/1506.06185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N55, 65Y05, 68Q85" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06194v1</id>
    <updated>2015-06-20T02:25:14Z</updated>
    <published>2015-06-20T02:25:14Z</published>
    <title>Unstructured Overlapping Mesh Distribution in Parallel</title>
    <summary>  We present a simple mathematical framework and API for parallel mesh and data
distribution, load balancing, and overlap generation. It relies on viewing the
mesh as a Hasse diagram, abstracting away information such as cell shape,
dimension, and coordinates. The high level of abstraction makes our interface
both concise and powerful, as the same algorithm applies to any representable
mesh, such as hybrid meshes, meshes embedded in higher dimension, and
overlapped meshes in parallel. We present evidence, both theoretical and
experimental, that the algorithms are scalable and efficient. A working
implementation can be found in the latest release of the PETSc libraries.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Gerard J. Gorman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures, submitted to TOMS</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.06194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07094v3</id>
    <updated>2016-03-31T10:10:11Z</updated>
    <published>2015-06-23T17:08:59Z</published>
    <title>pyMOR - Generic Algorithms and Interfaces for Model Order Reduction</title>
    <summary>  Reduced basis methods are projection-based model order reduction techniques
for reducing the computational complexity of solving parametrized partial
differential equation problems. In this work we discuss the design of pyMOR, a
freely available software library of model order reduction algorithms, in
particular reduced basis methods, implemented with the Python programming
language. As its main design feature, all reduction algorithms in pyMOR are
implemented generically via operations on well-defined vector array, operator
and discretization interface classes. This allows for an easy integration with
existing open-source high-performance partial differential equation solvers
without adding any model reduction specific code to these solvers. Besides an
in-depth discussion of pyMOR's design philosophy and architecture, we present
several benchmark results and numerical examples showing the feasibility of our
approach.
</summary>
    <author>
      <name>René Milk</name>
    </author>
    <author>
      <name>Stephan Rave</name>
    </author>
    <author>
      <name>Felix Schindler</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/15M1026614</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/15M1026614" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM J. Sci. Comput., 38 (2016), pp. S194-S216</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.07094v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07094v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04, 35J20, 35L03, 65-04, 65N30, 65Y05, 68N01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07749v1</id>
    <updated>2015-06-25T13:42:29Z</updated>
    <published>2015-06-25T13:42:29Z</published>
    <title>Efficient mesh management in Firedrake using PETSc-DMPlex</title>
    <summary>  The use of composable abstractions allows the application of new and
established algorithms to a wide range of problems while automatically
inheriting the benefits of well-known performance optimisations. This work
highlights the composition of the PETSc DMPlex domain topology abstraction with
the Firedrake automated finite element system to create a PDE solving
environment that combines expressiveness, flexibility and high performance. We
describe how Firedrake utilises DMPlex to provide the indirection maps required
for finite element assembly, while supporting various mesh input formats and
runtime domain decomposition. In particular, we describe how DMPlex and its
accompanying data structures allow the generic creation of user-defined
discretisations, while utilising data layout optimisations that improve cache
coherency and ensure overlapped communication during assembly computation.
</summary>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Lawrence Mitchell</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Gerard J. Gorman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/15M1026092</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/15M1026092" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures, submitted to SISC CSE Special Issue</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing 38(5):S143-S155 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.07749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08694v1</id>
    <updated>2015-06-26T07:53:57Z</updated>
    <published>2015-06-26T07:53:57Z</published>
    <title>A Java Implementation of Parameter-less Evolutionary Algorithms</title>
    <summary>  The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in
1999 as an alternative to the usual trial-and-error method of finding, for each
given problem, an acceptable set-up of the parameter values of the genetic
algorithm. Since then, the same strategy has been successfully applied to
create parameter-less versions of other population-based search algorithms such
as the Extended Compact Genetic Algorithm and the Hierarchical Bayesian
Optimization Algorithm. This report describes a Java implementation,
Parameter-less Evolutionary Algorithm (P-EAJava), that integrates several
parameter-less evolutionary algorithms into a single platform. Along with a
brief description of P-EAJava, we also provide detailed instructions on how to
use it, how to implement new problems, and how to generate new parameter-less
versions of evolutionary algorithms.
  At present time, P-EAJava already includes parameter-less versions of the
Simple Genetic Algorithm, the Extended Compact Genetic Algorithm, the
Univariate Marginal Distribution Algorithm, and the Hierarchical Bayesian
Optimization Algorithm. The source and binary files of the Java implementation
of P-EAJava are available for free download at
https://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava.
</summary>
    <author>
      <name>José C. Pereira</name>
    </author>
    <author>
      <name>Fernando G. Lobo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. arXiv admin note: text overlap with arXiv:1506.07980</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08867v1</id>
    <updated>2015-06-26T07:58:32Z</updated>
    <published>2015-06-26T07:58:32Z</published>
    <title>Java Implementation of a Parameter-less Evolutionary Portfolio</title>
    <summary>  The Java implementation of a portfolio of parameter-less evolutionary
algorithms is presented. The Parameter-less Evolutionary Portfolio implements a
heuristic that performs adaptive selection of parameter-less evolutionary
algorithms in accordance with performance criteria that are measured during
running time. At present time, the portfolio includes three parameter-less
evolutionary algorithms: Parameter-less Univariate Marginal Distribution
Algorithm, Parameter-less Extended Compact Genetic Algorithm, and
Parameter-less Hierarchical Bayesian Optimization Algorithm. Initial
experiments showed that the parameter-less portfolio can solve various classes
of problems without the need for any prior parameter setting technique and with
an increase in computational effort that can be considered acceptable.
</summary>
    <author>
      <name>José C. Pereira</name>
    </author>
    <author>
      <name>Fernando G. Lobo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. arXiv admin note: substantial text overlap with
  arXiv:1506.08694, arXiv:1506.07980</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02470v1</id>
    <updated>2015-08-11T02:06:01Z</updated>
    <published>2015-08-11T02:06:01Z</published>
    <title>Support for Non-conformal Meshes in PETSc's DMPlex Interface</title>
    <summary>  PETSc's DMPlex interface for unstructured meshes has been extended to support
non-conformal meshes. The topological construct that DMPlex implements---the
CW-complex---is by definition conformal, so representing non- conformal meshes
in a way that hides complexity requires careful attention to the interface
between DMPlex and numerical methods such as the finite element method. Our
approach---which combines a tree structure for subset- superset relationships
and a "reference tree" describing the types of non-conformal
interfaces---allows finite element code written for conformal meshes to extend
automatically: in particular, all "hanging-node" constraint calculations are
handled behind the scenes. We give example code demonstrating the use of this
extension, and use it to convert forests of quadtrees and forests of octrees
from the p4est library to DMPlex meshes.
</summary>
    <author>
      <name>Tobin Isaac</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 13 figures, 5 code examples</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01347v4</id>
    <updated>2018-11-09T07:55:49Z</updated>
    <published>2015-09-04T06:20:18Z</published>
    <title>Verificarlo: checking floating point accuracy through Monte Carlo
  Arithmetic</title>
    <summary>  Numerical accuracy of floating point computation is a well studied topic
which has not made its way to the end-user in scientific computing. Yet, it has
become a critical issue with the recent requirements for code modernization to
harness new highly parallel hardware and perform higher resolution computation.
To democratize numerical accuracy analysis, it is important to propose tools
and methodologies to study large use cases in a reliable and automatic way. In
this paper, we propose verificarlo, an extension to the LLVM compiler to
automatically use Monte Carlo Arithmetic in a transparent way for the end-user.
It supports all the major languages including C, C++, and Fortran. Unlike
source-to-source approaches, our implementation captures the influence of
compiler optimizations on the numerical accuracy. We illustrate how Monte Carlo
Arithmetic using the verificarlo tool outperforms the existing approaches on
various use cases and is a step toward automatic numerical analysis.
</summary>
    <author>
      <name>Christophe Denis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMLA</arxiv:affiliation>
    </author>
    <author>
      <name>Pablo De Oliveira Castro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LI-PaRAD, UVSQ</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Petit</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UVSQ</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1509.01347v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01347v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06935v3</id>
    <updated>2019-11-11T15:20:23Z</updated>
    <published>2015-09-23T12:04:23Z</published>
    <title>Shared Memory Pipelined Parareal</title>
    <summary>  For the parallel-in-time integration method Parareal, pipelining can be used
to hide some of the cost of the serial correction step and improve its
efficiency. The paper introduces a basic OpenMP implementation of pipelined
Parareal and compares it to a standard MPI-based variant. Both versions yield
almost identical runtimes, but, depending on the compiler, the OpenMP variant
consumes about 7% less energy and has a significantly smaller memory footprint.
However, its higher implementation complexity might make it difficult to use in
legacy codes and in combination with spatial parallelisation.
</summary>
    <author>
      <name>Daniel Ruprecht</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-64203-1_48</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-64203-1_48" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Rivera F., Pena T., Cabaleiro J. (eds) Euro-Par 2017: Parallel
  Processing. Lecture Notes in Computer Science, vol 10417. Springer</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.06935v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06935v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10, 65Y05, 68N19" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02545v3</id>
    <updated>2016-06-14T01:45:20Z</updated>
    <published>2015-10-09T02:07:10Z</published>
    <title>Comparative computational results for some vertex and facet enumeration
  codes</title>
    <summary>  We report some computational results comparing parallel and sequential codes
for vertex/facet enumeration problems for convex polyhedra. The problems chosen
span the range from simple to highly degenerate polytopes. We tested one code
(lrs) based on pivoting and four codes (cddr+, ppl, normaliz, PORTA) based on
the double description method. normaliz employs parallelization as do the codes
plrs and mplrs which are based on lrs. We tested these codes using various
hardware configurations with up to 1200 cores. Major speedups were obtained by
parallelization, particularly by the code mplrs which uses MPI and can operate
on clusters of machines.
</summary>
    <author>
      <name>David Avis</name>
    </author>
    <author>
      <name>Charles Jordan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 tables. Revised version now includes PORTA, normaliz and
  v6.2 of lrslib. The cluster and test set used were also expanded. Broken
  table footnote fixed</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.02545v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02545v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02171v1</id>
    <updated>2015-11-06T17:36:20Z</updated>
    <published>2015-11-06T17:36:20Z</published>
    <title>Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric
  Multicore Processors</title>
    <summary>  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant
collection of numerical tools for many scientific and engineering applications.
While there exist high performance implementations of the BLAS (and LAPACK)
functionality for many current multi-threaded architectures,the adaption of
these libraries for asymmetric multicore processors (AMPs)is still pending. In
this paper we address this challenge by developing an asymmetry-aware
implementation of the BLAS, based on the BLIS framework, and tailored for AMPs
equipped with two types of cores: fast/power hungry versus slow/energy
efficient. For this purpose, we integrate coarse-grain and fine-grain
parallelization strategies into the library routines which, respectively,
dynamically distribute the workload between the two core types and statically
repartition this work among the cores of the same type.
  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,
using the asymmetry-aware version of the BLAS and a plain migration of the
legacy version of LAPACK, experimentally assess the benefits, limitations, and
potential of this approach.
</summary>
    <author>
      <name>Sandra Catalán</name>
    </author>
    <author>
      <name>José R. Herrero</name>
    </author>
    <author>
      <name>Francisco D. Igual</name>
    </author>
    <author>
      <name>Rafael Rodríguez-Sánchez</name>
    </author>
    <author>
      <name>Enrique S. Quintana-Ortí</name>
    </author>
    <link href="http://arxiv.org/abs/1511.02171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03415v1</id>
    <updated>2015-11-11T08:23:46Z</updated>
    <published>2015-11-11T08:23:46Z</published>
    <title>The Dune FoamGrid implementation for surface and network grids</title>
    <summary>  We present FoamGrid, a new implementation of the DUNE grid interface.
FoamGrid implements one- and two-dimensional grids in a physical space of
arbitrary dimension, which allows for grids for curved domains. Even more, the
grids are not expected to have a manifold structure, i.e., more than two
elements can share a common facet. This makes FoamGrid the grid data structure
of choice for simulating structures such as foams, discrete fracture networks,
or network flow problems. FoamGrid implements adaptive non-conforming
refinement with element parametrizations. As an additional feature it allows
removal and addition of elements in an existing grid, which makes FoamGrid
suitable for network growth problems. We show how to use FoamGrid, with
particular attention to the extensions of the grid interface needed to handle
non-manifold topology and grid growth. Three numerical examples demonstrate the
possibilities offered by FoamGrid.
</summary>
    <author>
      <name>Oliver Sander</name>
    </author>
    <author>
      <name>Timo Koch</name>
    </author>
    <author>
      <name>Natalie Schröder</name>
    </author>
    <author>
      <name>Bernd Flemisch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.11588/ans.2017.1.28490</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.11588/ans.2017.1.28490" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archive of Numerical Software Vol 5 No 1 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.03415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03742v2</id>
    <updated>2015-11-17T21:28:05Z</updated>
    <published>2015-11-12T01:02:58Z</published>
    <title>GEMMbench: a framework for reproducible and collaborative benchmarking
  of matrix multiplication</title>
    <summary>  The generic matrix-matrix multiplication (GEMM) is arguably the most popular
computational kernel of the 20th century. Yet, surprisingly, no common
methodology for evaluating GEMM performance has been established over the many
decades of using GEMM for comparing architectures, compilers and ninja-class
programmers.
  We introduce GEMMbench, a framework and methodology for evaluating
performance of GEMM implementations. GEMMbench is implemented on top of
Collective Knowledge (CK), a lightweight framework for reproducible and
collaborative R&amp;D in computer systems. Using CK allows the R&amp;D community to
crowdsource hand-written and compiler-generated GEMM implementations and to
study their performance across multiple platforms, data sizes and data types.
  Our initial implementation supports hand-written OpenCL kernels operating on
matrices consisting of single- and double-precision floating-point values, and
producing single or multiple output elements per work-item (via thread
coarsening and vectorization).
</summary>
    <author>
      <name>Anton Lokhmotov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ADAPT'16</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.03742v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03742v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07727v2</id>
    <updated>2015-11-26T16:32:40Z</updated>
    <published>2015-11-24T14:28:13Z</published>
    <title>DiffSharp: Automatic Differentiation Library</title>
    <summary>  In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented.
</summary>
    <author>
      <name>Atilim Gunes Baydin</name>
    </author>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <author>
      <name>Jeffrey Mark Siskind</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, minor fixes, added coauthor</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07727v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07727v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05, 68W30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; G.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.00066v1</id>
    <updated>2015-11-30T22:08:23Z</updated>
    <published>2015-11-30T22:08:23Z</published>
    <title>Sparse Tensor Algebra as a Parallel Programming Model</title>
    <summary>  Dense and sparse tensors allow the representation of most bulk data
structures in computational science applications. We show that sparse tensor
algebra can also be used to express many of the transformations on these
datasets, especially those which are parallelizable. Tensor computations are a
natural generalization of matrix and graph computations. We extend the usual
basic operations of tensor summation and contraction to arbitrary functions,
and further operations such as reductions and mapping. The expression of these
transformations in a high-level sparse linear algebra domain specific language
allows our framework to understand their properties at runtime to select the
preferred communication-avoiding algorithm. To demonstrate the efficacy of our
approach, we show how key graph algorithms as well as common numerical kernels
can be succinctly expressed using our interface and provide performance results
of a general library implementation.
</summary>
    <author>
      <name>Edgar Solomonik</name>
    </author>
    <author>
      <name>Torsten Hoefler</name>
    </author>
    <link href="http://arxiv.org/abs/1512.00066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.00066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06136v1</id>
    <updated>2015-12-18T21:09:10Z</updated>
    <published>2015-12-18T21:09:10Z</published>
    <title>The interface for functions in the dune-functions module</title>
    <summary>  The dune-functions dune module introduces a new programmer interface for
discrete and non-discrete functions. Unlike the previous interfaces considered
in the existing dune modules, it is based on overloading operator(), and
returning values by-value. This makes user code much more readable, and allows
the incorporation of newer C++ features such as lambda expressions. Run-time
polymorphism is implemented not by inheritance, but by type erasure,
generalizing the ideas of the std::function class from the C++11 standard
library. We describe the new interface, show its possibilities, and measure the
performance impact of type erasure and return-by-value.
</summary>
    <author>
      <name>Christian Engwer</name>
    </author>
    <author>
      <name>Carsten Gräser</name>
    </author>
    <author>
      <name>Steffen Müthing</name>
    </author>
    <author>
      <name>Oliver Sander</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.11588/ans.2017.1.27683</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.11588/ans.2017.1.27683" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The C++ source code of tests is attached to pdf file of the paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archive of Numerical Software 5 (2017) 95-109</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1512.06136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08790v1</id>
    <updated>2015-12-26T18:18:54Z</updated>
    <published>2015-12-26T18:18:54Z</published>
    <title>Dynamic Computation of Runge Kutta Fourth Order Algorithm for First and
  Second Order Ordinary Differential Equation Using Java</title>
    <summary>  Differential equations arise in mathematics, physics,medicine, pharmacology,
communications, image processing and animation, etc. An Ordinary Differential
Equation (ODE) is a differential equation if it involves derivatives with
respect to only one independent variable which can be studied from different
perspectives, such as: analytical methods, graphical methods and numerical
methods. This research paper therefore revises the standard Runge - Kutta
fourth order algorithm by using compiler techniques to dynamically evaluate the
inputs and implement the algorithm for both first and second order derivatives
of the ODE. We have been able to develop and implement the software that can be
used to evaluate inputs and compute solutions (approximately and analytically)
for the ODE function at a more efficient rate than the traditional method.
</summary>
    <author>
      <name>A. O. Anidu</name>
    </author>
    <author>
      <name>S. A. Arekete</name>
    </author>
    <author>
      <name>A. O. Adedayo</name>
    </author>
    <author>
      <name>A. O. Adekoya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.08790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05871v1</id>
    <updated>2016-01-22T03:19:45Z</updated>
    <published>2016-01-22T03:19:45Z</published>
    <title>Task Parallel Incomplete Cholesky Factorization using 2D
  Partitioned-Block Layout</title>
    <summary>  We introduce a task-parallel algorithm for sparse incomplete Cholesky
factorization that utilizes a 2D sparse partitioned-block layout of a matrix.
Our factorization algorithm follows the idea of algorithms-by-blocks by using
the block layout. The algorithm-by-blocks approach induces a task graph for the
factorization. These tasks are inter-related to each other through their data
dependences in the factorization algorithm. To process the tasks on various
manycore architectures in a portable manner, we also present a portable tasking
API that incorporates different tasking backends and device-specific features
using an open-source framework for manycore platforms i.e., Kokkos. A
performance evaluation is presented on both Intel Sandybridge and Xeon Phi
platforms for matrices from the University of Florida sparse matrix collection
to illustrate merits of the proposed task-based factorization. Experimental
results demonstrate that our task-parallel implementation delivers about 26.6x
speedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and
19.2x speedup over serial Cholesky performance which does not carry tasking
overhead using 56 threads on the Intel Xeon Phi processor for sparse matrices
arising from various application problems.
</summary>
    <author>
      <name>Kyungjoo Kim</name>
    </author>
    <author>
      <name>Sivasankaran Rajamanickam</name>
    </author>
    <author>
      <name>George Stelle</name>
    </author>
    <author>
      <name>H. Carter Edwards</name>
    </author>
    <author>
      <name>Stephen L. Olivier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.05871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.03643v1</id>
    <updated>2016-02-11T08:56:43Z</updated>
    <published>2016-02-11T08:56:43Z</published>
    <title>Oasis: a high-level/high-performance open source Navier-Stokes solver</title>
    <summary>  Oasis is a high-level/high-performance finite element Navier-Stokes solver
written from scratch in Python using building blocks from the FEniCS project
(fenicsproject.org). The solver is unstructured and targets large-scale
applications in complex geometries on massively parallel clusters. Oasis
utilizes MPI and interfaces, through FEniCS, to the linear algebra backend
PETSc. Oasis advocates a high-level, programmable user interface through the
creation of highly flexible Python modules for new problems. Through the
high-level Python interface the user is placed in complete control of every
aspect of the solver. A version of the solver, that is using piecewise linear
elements for both velocity and pressure, is shown reproduce very well the
classical, spectral, turbulent channel simulations of Moser, Kim and Mansour at
$Re_{\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is
strongly dominated by the iterative solvers provided by the linear algebra
backend, which is arguably the best performance any similar implicit solver
using PETSc may hope for. Higher order accuracy is also demonstrated and new
solvers may be easily added within the same framework.
</summary>
    <author>
      <name>Mikael Mortensen</name>
    </author>
    <author>
      <name>Kristian Valen-Sendstad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2014.10.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2014.10.026" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications, Volume 188, p 177-188, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.03643v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.03643v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02297v1</id>
    <updated>2016-03-07T21:13:00Z</updated>
    <published>2016-03-07T21:13:00Z</published>
    <title>TTC: A high-performance Compiler for Tensor Transpositions</title>
    <summary>  We present TTC, an open-source parallel compiler for multidimensional tensor
transpositions. In order to generate high-performance C++ code, TTC explores a
number of optimizations, including software prefetching, blocking,
loop-reordering, and explicit vectorization. To evaluate the performance of
multidimensional transpositions across a range of possible use-cases, we also
release a benchmark covering arbitrary transpositions of up to six dimensions.
Performance results show that the routines generated by TTC achieve close to
peak memory bandwidth on both the Intel Haswell and the AMD Steamroller
architectures, and yield significant performance gains over modern compilers.
By implementing a set of pruning heuristics, TTC allows users to limit the
number of potential solutions; this option is especially useful when dealing
with high-dimensional tensors, as the search space might become prohibitively
large. Experiments indicate that when only 100 potential solutions are
considered, the resulting performance is about 99% of that achieved with
exhaustive search.
</summary>
    <author>
      <name>Paul Springer</name>
    </author>
    <author>
      <name>Jeff R. Hammond</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <link href="http://arxiv.org/abs/1603.02297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03236v4</id>
    <updated>2016-09-08T09:23:08Z</updated>
    <published>2016-03-10T12:23:12Z</published>
    <title>Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic
  Differentiation</title>
    <summary>  Optimization on manifolds is a class of methods for optimization of an
objective function, subject to constraints which are smooth, in the sense that
the set of points which satisfy the constraints admits the structure of a
differentiable manifold. While many optimization problems are of the described
form, technicalities of differential geometry and the laborious calculation of
derivatives pose a significant barrier for experimenting with these methods.
  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox
for optimization on manifolds, implemented in Python, that---similarly to the
Manopt Matlab toolbox---implements several manifold geometries and optimization
algorithms. Moreover, we lower the barriers to users further by using automated
differentiation for calculating derivative information, saving users time and
saving them from potential calculation and implementation errors.
</summary>
    <author>
      <name>James Townsend</name>
    </author>
    <author>
      <name>Niklas Koep</name>
    </author>
    <author>
      <name>Sebastian Weichwald</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research, 17(137):1-5, 2016 (
  https://jmlr.org/papers/v17/16-177.html )</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.03236v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03236v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06424v1</id>
    <updated>2016-03-21T13:18:44Z</updated>
    <published>2016-03-21T13:18:44Z</published>
    <title>Interoperability in the OpenDreamKit Project: The Math-in-the-Middle
  Approach</title>
    <summary>  OpenDreamKit --- "Open Digital Research Environment Toolkit for the
Advancement of Mathematics" --- is an H2020 EU Research Infrastructure project
that aims at supporting, over the period 2015--2019, the ecosystem of
open-source mathematical software systems. From that, OpenDreamKit will deliver
a flexible toolkit enabling research groups to set up Virtual Research
Environments, customised to meet the varied needs of research projects in pure
mathematics and applications.
  An important step in the OpenDreamKit endeavor is to foster the
interoperability between a variety of systems, ranging from computer algebra
systems over mathematical databases to front-ends. This is the mission of the
integration work package (WP6). We report on experiments and future plans with
the \emph{Math-in-the-Middle} approach. This information architecture consists
in a central mathematical ontology that documents the domain and fixes a joint
vocabulary, combined with specifications of the functionalities of the various
systems. Interaction between systems can then be enriched by pivoting off this
information architecture.
</summary>
    <author>
      <name>Paul-Olivier Dehaye</name>
    </author>
    <author>
      <name>Michael Kohlhase</name>
    </author>
    <author>
      <name>Alexander Konovalov</name>
    </author>
    <author>
      <name>Samuel Lelièvre</name>
    </author>
    <author>
      <name>Markus Pfeiffer</name>
    </author>
    <author>
      <name>Nicolas M. Thiéry</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-42547-4_9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-42547-4_9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06907v5</id>
    <updated>2017-02-21T19:06:05Z</updated>
    <published>2016-03-22T18:57:41Z</published>
    <title>micompr: An R Package for Multivariate Independent Comparison of
  Observations</title>
    <summary>  The R package micompr implements a procedure for assessing if two or more
multivariate samples are drawn from the same distribution. The procedure uses
principal component analysis to convert multivariate observations into a set of
linearly uncorrelated statistical measures, which are then compared using a
number of statistical methods. This technique is independent of the
distributional properties of samples and automatically selects features that
best explain their differences. The procedure is appropriate for comparing
samples of time series, images, spectrometric measures or similar
high-dimension multivariate observations.
</summary>
    <author>
      <name>Nuno Fachada</name>
    </author>
    <author>
      <name>João Rodrigues</name>
    </author>
    <author>
      <name>Vitor V. Lopes</name>
    </author>
    <author>
      <name>Rui C. Martins</name>
    </author>
    <author>
      <name>Agostinho C. Rosa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.32614/RJ-2016-055</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.32614/RJ-2016-055" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The peer-reviewed version of this paper is published in The R Journal
  at
  https://journal.r-project.org/archive/2016-2/fachada-rodrigues-lopes-etal.pdf
  . This version is typeset by the authors and differs only in pagination and
  typographical detail</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The R Journal, 8(2): 405-420 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.06907v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06907v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62-07, 62H15, 62H25" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06914v4</id>
    <updated>2017-01-06T12:10:24Z</updated>
    <published>2016-03-22T19:11:07Z</published>
    <title>SimOutUtils - Utilities for analyzing time series simulation output</title>
    <summary>  SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing
time series-like output from stochastic simulation models. More specifically,
SimOutUtils allows modelers to study and visualize simulation output dynamics,
perform distributional analysis of output statistical summaries, as well as
compare these summaries in order to assert the statistical equivalence of two
or more model implementations. Additionally, the provided functions are able to
produce publication quality figures and tables showcasing results from the
specified simulation output studies.
</summary>
    <author>
      <name>Nuno Fachada</name>
    </author>
    <author>
      <name>Vitor V. Lopes</name>
    </author>
    <author>
      <name>Rui C. Martins</name>
    </author>
    <author>
      <name>Agostinho C. Rosa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.110</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.110" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The peer-reviewed version of this paper is published in the Journal
  of Open Research Software at http://doi.org/10.5334/jors.110 . This version
  is typeset by the authors and differs only in pagination and typographical
  detail</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Open Research Software. 4(1), p.e38, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.06914v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06914v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62-07" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; G.3; I.6.4; I.6.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07916v2</id>
    <updated>2016-10-06T14:38:23Z</updated>
    <published>2016-03-25T14:07:49Z</published>
    <title>A Subdivision Solver for Systems of Large Dense Polynomials</title>
    <summary>  We describe here the package {\tt subdivision\\_solver} for the mathematical
software {\tt SageMath}. It provides a solver on real numbers for square
systems of large dense polynomials. By large polynomials we mean multivariate
polynomials with large degrees, which coefficients have large bit-size. While
staying robust, symbolic approaches to solve systems of polynomials see their
performances dramatically affected by high degree and bit-size of input
polynomials.Available numeric approaches suffer from the cost of the evaluation
of large polynomials and their derivatives.Our solver is based on interval
analysis and bisections of an initial compact domain of $\R^n$ where solutions
are sought. Evaluations on intervals with Horner scheme is performed by the
package {\tt fast\\_polynomial} for {\tt SageMath}.The non-existence of a
solution within a box is certified by an evaluation scheme that uses a Taylor
expansion at order 2, and existence and uniqueness of a solution within a box
is certified with krawczyk operator.The precision of the working arithmetic is
adapted on the fly during the subdivision process and we present a new
heuristic criterion to decide if the arithmetic precision has to be increased.
</summary>
    <author>
      <name>Rémi Imbach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VEGAS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1603.07916v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07916v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03570v1</id>
    <updated>2016-04-12T20:13:04Z</updated>
    <published>2016-04-12T20:13:04Z</published>
    <title>BoxLib with Tiling: An AMR Software Framework</title>
    <summary>  In this paper we introduce a block-structured adaptive mesh refinement (AMR)
software framework that incorporates tiling, a well-known loop transformation.
Because the multiscale, multiphysics codes built in BoxLib are designed to
solve complex systems at high resolution, performance on current and next
generation architectures is essential. With the expectation of many more cores
per node on next generation architectures, the ability to effectively utilize
threads within a node is essential, and the current model for parallelization
will not be sufficient. We describe a new version of BoxLib in which the tiling
constructs are embedded so that BoxLib-based applications can easily realize
expected performance gains without extra effort on the part of the application
developer. We also discuss a path forward to enable future versions of BoxLib
to take advantage of NUMA-aware optimizations using the TiDA portable library.
</summary>
    <author>
      <name>Weiqun Zhang</name>
    </author>
    <author>
      <name>Ann Almgren</name>
    </author>
    <author>
      <name>Marcus Day</name>
    </author>
    <author>
      <name>Tan Nguyen</name>
    </author>
    <author>
      <name>John Shalf</name>
    </author>
    <author>
      <name>Didem Unat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in SIAM J. on Scientific Computing</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.03570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07163v1</id>
    <updated>2016-04-25T08:35:12Z</updated>
    <published>2016-04-25T08:35:12Z</published>
    <title>Extreme-scale Multigrid Components within PETSc</title>
    <summary>  Elliptic partial differential equations (PDEs) frequently arise in continuum
descriptions of physical processes relevant to science and engineering.
Multilevel preconditioners represent a family of scalable techniques for
solving discrete PDEs of this type and thus are the method of choice for
high-resolution simulations. The scalability and time-to-solution of massively
parallel multilevel preconditioners can be adversely effected by using a
coarse-level solver with sub-optimal algorithmic complexity. To maintain
scalability, agglomeration techniques applied to the coarse level have been
shown to be necessary.
  In this work, we present a new software component introduced within the
Portable Extensible Toolkit for Scientific computation (PETSc) which permits
agglomeration. We provide an overview of the design and implementation of this
functionality, together with several use cases highlighting the benefits of
agglomeration. Lastly, we demonstrate via numerical experiments employing
geometric multigrid with structured meshes, the flexibility and performance
gains possible using our MPI-rank agglomeration implementation.
</summary>
    <author>
      <name>Dave A. May</name>
    </author>
    <author>
      <name>Patrick Sanan</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08079v2</id>
    <updated>2016-07-12T23:08:46Z</updated>
    <published>2016-04-27T14:13:11Z</published>
    <title>UBL: an R package for Utility-based Learning</title>
    <summary>  This document describes the R package UBL that allows the use of several
methods for handling utility-based learning problems. Classification and
regression problems that assume non-uniform costs and/or benefits pose serious
challenges to predictive analytic tasks. In the context of meteorology,
finance, medicine, ecology, among many other, specific domain information
concerning the preference bias of the users must be taken into account to
enhance the models predictive performance. To deal with this problem, a large
number of techniques was proposed by the research community for both
classification and regression tasks. The main goal of UBL package is to
facilitate the utility-based predictive analytic task by providing a set of
methods to deal with this type of problems in the R environment. It is a
versatile tool that provides mechanisms to handle both regression and
classification (binary and multiclass) tasks. Moreover, UBL package allows the
user to specify his domain preferences, but it also provides some automatic
methods that try to infer those preference bias from the domain, considering
some common known settings.
</summary>
    <author>
      <name>Paula Branco</name>
    </author>
    <author>
      <name>Rita P. Ribeiro</name>
    </author>
    <author>
      <name>Luis Torgo</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08079v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08079v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01078v1</id>
    <updated>2016-05-03T20:28:00Z</updated>
    <published>2016-05-03T20:28:00Z</published>
    <title>Implementing Strassen's Algorithm with BLIS</title>
    <summary>  We dispel with "street wisdom" regarding the practical implementation of
Strassen's algorithm for matrix-matrix multiplication (DGEMM). Conventional
wisdom: it is only practical for very large matrices. Our implementation is
practical for small matrices. Conventional wisdom: the matrices being
multiplied should be relatively square. Our implementation is practical for
rank-k updates, where k is relatively small (a shape of importance for
libraries like LAPACK). Conventional wisdom: it inherently requires substantial
workspace. Our implementation requires no workspace beyond buffers already
incorporated into conventional high-performance DGEMM implementations.
Conventional wisdom: a Strassen DGEMM interface must pass in workspace. Our
implementation requires no such workspace and can be plug-compatible with the
standard DGEMM interface. Conventional wisdom: it is hard to demonstrate
speedup on multi-core architectures. Our implementation demonstrates speedup
over conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing
240 threads. We show how a distributed memory matrix-matrix multiplication also
benefits from these advances.
</summary>
    <author>
      <name>Jianyu Huang</name>
    </author>
    <author>
      <name>Tyler M. Smith</name>
    </author>
    <author>
      <name>Greg M. Henry</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <link href="http://arxiv.org/abs/1605.01078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.06381v1</id>
    <updated>2016-05-20T14:44:55Z</updated>
    <published>2016-05-20T14:44:55Z</published>
    <title>OPESCI-FD: Automatic Code Generation Package for Finite Difference
  Models</title>
    <summary>  In this project, we introduce OPESCI-FD, a Python package built on symbolic
mathematics to automatically generate Finite Difference models from a
high-level description of the model equations. We investigate applying this
framework to generate the propagator program used in seismic imaging. We
implement the 3D velocity-stress FD scheme as an example and demonstrate the
advantages of usability, flexibility and accuracy of the framework. The design
of OPESCI-FD aims to allow rapid development, analysis and optimisation of
Finite Difference programs. OPESCI-FD is the foundation for continuing
development by the OPESCI project team, building on the research presented in
this report. This report concludes by reviewing the further developments that
are already under way, as well as the scope for extension to cater for other
equations and numerical schemes.
</summary>
    <author>
      <name>Tianjiao Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1605.06381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.06381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05385v2</id>
    <updated>2016-08-13T08:28:59Z</updated>
    <published>2016-06-16T23:19:58Z</published>
    <title>D2O - a distributed data object for parallel high-performance computing
  in Python</title>
    <summary>  We introduce D2O, a Python module for cluster-distributed multi-dimensional
numerical arrays. It acts as a layer of abstraction between the algorithm code
and the data-distribution logic. The main goal is to achieve usability without
losing numerical performance and scalability. D2O's global interface is similar
to the one of a numpy.ndarray, whereas the cluster node's local data is
directly accessible for use in customized high-performance modules. D2O is
written in pure Python which makes it portable and easy to use and modify.
Expensive operations are carried out by dedicated external libraries like numpy
and mpi4py. The performance of D2O is on a par with numpy for serial
applications and scales well when moving to an MPI cluster. D2O is open-source
software available under the GNU General Public License v3 (GPL-3) at
https://gitlab.mpcdf.mpg.de/ift/D2O
</summary>
    <author>
      <name>T. Steininger</name>
    </author>
    <author>
      <name>M. Greiner</name>
    </author>
    <author>
      <name>F. Beaujean</name>
    </author>
    <author>
      <name>T. Enßlin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/s40537-016-0052-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/s40537-016-0052-5" rel="related"/>
    <link href="http://arxiv.org/abs/1606.05385v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05385v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06977v2</id>
    <updated>2016-07-05T11:58:14Z</updated>
    <published>2016-06-22T15:07:11Z</published>
    <title>Computing hypergeometric functions rigorously</title>
    <summary>  We present an efficient implementation of hypergeometric functions in
arbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,
${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for
unrestricted complex parameters and argument, and by extension, we cover
exponential and trigonometric integrals, error functions, Fresnel integrals,
incomplete gamma and beta functions, Bessel functions, Airy functions, Legendre
functions, Jacobi polynomials, complete elliptic integrals, and other special
functions. The output can be used directly for interval computations or to
generate provably correct floating-point approximations in any format.
Performance is competitive with earlier arbitrary-precision software, and
sometimes orders of magnitude faster. We also partially cover the generalized
hypergeometric function ${}_pF_q$ and computation of high-order parameter
derivatives.
</summary>
    <author>
      <name>Fredrik Johansson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v2: corrected example in section 3.1; corrected timing data for case
  E-G in section 8.5 (table 6, figure 2); adjusted paper size</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.06977v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06977v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="33F05, 33C20, 33C05, 33C10, 33C15, 65G30, 65Y20, 65D20, 97N80,&#10;  33B15, 33B20, 33C45" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.07399v2</id>
    <updated>2016-12-14T07:58:27Z</updated>
    <published>2016-06-23T18:37:41Z</published>
    <title>jInv -- a flexible Julia package for PDE parameter estimation</title>
    <summary>  Estimating parameters of Partial Differential Equations (PDEs) from noisy and
indirect measurements often requires solving ill-posed inverse problems. These
so called parameter estimation or inverse medium problems arise in a variety of
applications such as geophysical, medical imaging, and nondestructive testing.
Their solution is computationally intense since the underlying PDEs need to be
solved numerous times until the reconstruction of the parameters is
sufficiently accurate. Typically, the computational demand grows significantly
when more measurements are available, which poses severe challenges to
inversion algorithms as measurement devices become more powerful.
  In this paper we present jInv, a flexible framework and open source software
that provides parallel algorithms for solving parameter estimation problems
with many measurements. Being written in the expressive programming language
Julia, jInv is portable, easy to understand and extend, cross-platform tested,
and well-documented. It provides novel parallelization schemes that exploit the
inherent structure of many parameter estimation problems and can be used to
solve multiphysics inversion problems as is demonstrated using numerical
experiments motivated by geophysical imaging.
</summary>
    <author>
      <name>Lars Ruthotto</name>
    </author>
    <author>
      <name>Eran Treister</name>
    </author>
    <author>
      <name>Eldad Haber</name>
    </author>
    <link href="http://arxiv.org/abs/1606.07399v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.07399v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00291v4</id>
    <updated>2017-07-11T15:03:52Z</updated>
    <published>2016-07-01T15:37:59Z</published>
    <title>High-Performance Tensor Contraction without Transposition</title>
    <summary>  Tensor computations--in particular tensor contraction (TC)--are important
kernels in many scientific computing applications. Due to the fundamental
similarity of TC to matrix multiplication (MM) and to the availability of
optimized implementations such as the BLAS, tensor operations have
traditionally been implemented in terms of BLAS operations, incurring both a
performance and a storage overhead. Instead, we implement TC using the flexible
BLIS framework, which allows for transposition (reshaping) of the tensor to be
fused with internal partitioning and packing operations, requiring no explicit
transposition operations or additional workspace. This implementation, TBLIS,
achieves performance approaching that of MM, and in some cases considerably
higher than that of traditional TC. Our implementation supports multithreading
using an approach identical to that used for MM in BLIS, with similar
performance characteristics. The complexity of managing tensor-to-matrix
transformations is also handled automatically in our approach, greatly
simplifying its use in scientific applications.
</summary>
    <author>
      <name>Devin A. Matthews</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/16M108968X</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/16M108968X" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 8 figures, uses pgfplots</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing 2018 40:1, C1-C24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.00291v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00291v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A69" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00844v1</id>
    <updated>2016-07-01T18:59:11Z</updated>
    <published>2016-07-01T18:59:11Z</published>
    <title>Using the pyMIC Offload Module in PyFR</title>
    <summary>  PyFR is an open-source high-order accurate computational fluid dynamics
solver for unstructured grids. It is designed to efficiently solve the
compressible Navier-Stokes equations on a range of hardware platforms,
including GPUs and CPUs. In this paper we will describe how the Python Offload
Infrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used
to enable PyFR to run with near native performance on the Intel Xeon Phi
coprocessor. We will introduce the architecture of both pyMIC and PyFR and
present a variety of examples showcasing the capabilities of pyMIC. Further, we
will also compare the contrast pyMIC to other approaches including native
execution and OpenCL. The process of adding support for pyMIC into PyFR will be
described in detail. Benchmark results show that for a standard cylinder flow
problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double
precision floating point performance; for a 1.85 times improvement over PyFR
with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.
</summary>
    <author>
      <name>Michael Klemm</name>
    </author>
    <author>
      <name>Freddie Witherden</name>
    </author>
    <author>
      <name>Peter Vincent</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00844v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00844v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00850v1</id>
    <updated>2016-07-01T19:05:11Z</updated>
    <published>2016-07-01T19:05:11Z</published>
    <title>Massively parallel implementation in Python of a pseudo-spectral DNS
  code for turbulent flows</title>
    <summary>  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a
valuable research tool in fluid dynamics, but there are very few publicly
available codes and, due to heavy number crunching, codes are usually written
in low-level languages. In this work a \textasciitilde{}100 line standard
scientific Python DNS code is described that nearly matches the performance of
pure C for thousands of processors and billions of unknowns. With optimization
of a few routines in Cython, it is found to match the performance of a more or
less identical solver implemented from scratch in C++. Keys to the efficiency
of the solver are the mesh decomposition and three dimensional FFT routines,
implemented directly in Python using MPI, wrapped through MPI for Python, and a
serial FFT module (both numpy.fft or pyFFTW may be used). Two popular
decomposition strategies, slab and pencil, have been implemented and tested.
</summary>
    <author>
      <name>Mikael Mortensen</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01191v1</id>
    <updated>2016-07-05T11:02:45Z</updated>
    <published>2016-07-05T11:02:45Z</published>
    <title>Best Practices for Replicability, Reproducibility and Reusability of
  Computer-Based Experiments Exemplified by Model Reduction Software</title>
    <summary>  Over the recent years the importance of numerical experiments has gradually
been more recognized. Nonetheless, sufficient documentation of how
computational results have been obtained is often not available. Especially in
the scientific computing and applied mathematics domain this is crucial, since
numerical experiments are usually employed to verify the proposed hypothesis in
a publication. This work aims to propose standards and best practices for the
setup and publication of numerical experiments. Naturally, this amounts to a
guideline for development, maintenance, and publication of numerical research
software. Such a primer will enable the replicability and reproducibility of
computer-based experiments and published results and also promote the
reusability of the associated software.
</summary>
    <author>
      <name>Jörg Fehr</name>
    </author>
    <author>
      <name>Jan Heiland</name>
    </author>
    <author>
      <name>Christian Himpe</name>
    </author>
    <author>
      <name>Jens Saak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3934/Math.2016.3.261</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3934/Math.2016.3.261" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AIMS Mathematics 2016, Volume 1, Issue 3</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.01191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01249v1</id>
    <updated>2016-07-05T13:53:57Z</updated>
    <published>2016-07-05T13:53:57Z</published>
    <title>TTC: A Tensor Transposition Compiler for Multiple Architectures</title>
    <summary>  We consider the problem of transposing tensors of arbitrary dimension and
describe TTC, an open source domain-specific parallel compiler. TTC generates
optimized parallel C++/CUDA C code that achieves a significant fraction of the
system's peak memory bandwidth. TTC exhibits high performance across multiple
architectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD
Steamroller), Intel's Knights Corner as well as different CUDA-based GPUs such
as NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a
meaningful baseline implementation generated by external C++ compilers; the
results suggest that a domain-specific compiler can outperform its general
purpose counterpart significantly: For instance, comparing with Intel's latest
C++ compiler on the Haswell and Knights Corner architecture, TTC yields
speedups of up to $8\times$ and $32\times$, respectively. We also showcase
TTC's support for multiple leading dimensions, making it a suitable candidate
for the generation of performance-critical packing functions that are at the
core of the ubiquitous BLAS 3 routines.
</summary>
    <author>
      <name>Paul Springer</name>
    </author>
    <author>
      <name>Aravind Sankaran</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2935323.2935328</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2935323.2935328" rel="related"/>
    <link href="http://arxiv.org/abs/1607.01249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.3.4; I.1.2; I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01404v2</id>
    <updated>2017-01-24T18:27:56Z</updated>
    <published>2016-07-05T20:15:56Z</published>
    <title>PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate
  Large-Scale Computations</title>
    <summary>  The increasing number of applications requiring the solution of large scale
singular value problems have rekindled interest in iterative methods for the
SVD. Some promising recent ad- vances in large scale iterative methods are
still plagued by slow convergence and accuracy limitations for computing
smallest singular triplets. Furthermore, their current implementations in
MATLAB cannot address the required large problems. Recently, we presented a
preconditioned, two-stage method to effectively and accurately compute a small
number of extreme singular triplets. In this research, we present a
high-performance software, PRIMME SVDS, that implements our hybrid method based
on the state-of-the-art eigensolver package PRIMME for both largest and
smallest singular values. PRIMME SVDS fills a gap in production level software
for computing the partial SVD, especially with preconditioning. The numerical
experiments demonstrate its superior performance compared to other
state-of-the-art software and its good parallel performance under strong and
weak scaling.
</summary>
    <author>
      <name>Lingfei Wu</name>
    </author>
    <author>
      <name>Eloy Romero</name>
    </author>
    <author>
      <name>Andreas Stathopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01404v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01404v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02835v1</id>
    <updated>2016-07-11T06:51:50Z</updated>
    <published>2016-07-11T06:51:50Z</published>
    <title>Form Follows Function -- Do algorithms and applications challenge or
  drag behind the hardware evolution?</title>
    <summary>  We summarise some of the key statements made at the workshop Form Follows
Function at ISC High Performance 2016. The summary highlights what type of
co-design the presented projects experience; often in the absence of an
explicit co-design agenda. Their software development picks up hardware trends
but it also influences the hardware development. Observations illustrate that
this cycle not always is optimal for both sides as it is not proactively
steered. Key statements characterise ideas how it might be possible to
integrate both hardware and software creation closer to the best of both
worlds---again even without classic co-design in mind where new pieces of
hardware are created. The workshop finally identified three development idioms
that might help to improve software and system design with respect to emerging
hardware.
</summary>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04245v1</id>
    <updated>2016-07-14T18:53:48Z</updated>
    <published>2016-07-14T18:53:48Z</published>
    <title>Finite Element Integration with Quadrature on the GPU</title>
    <summary>  We present a novel, quadrature-based finite element integration method for
low-order elements on GPUs, using a pattern we call \textit{thread
transposition} to avoid reductions while vectorizing aggressively. On the
NVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s
and a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element
integration on first-order discretization of the Laplacian operator with
variable coefficients in two dimensions, and over 400 GF/s in three dimensions.
From our performance model we find that this corresponds to 90\% of our
measured achievable bandwidth peak of 310 GF/s. Further experimental results
also match the predicted performance when used with double precision (120 GF/s
in two dimensions, 150 GF/s in three dimensions). Results obtained for the
linear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s
and 60 GF/s in three dimensions) also demonstrate the applicability of our
method to vector-valued partial differential equations.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Andy R. Terrel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07892v1</id>
    <updated>2016-07-26T20:32:29Z</updated>
    <published>2016-07-26T20:32:29Z</published>
    <title>Forward-Mode Automatic Differentiation in Julia</title>
    <summary>  We present ForwardDiff, a Julia package for forward-mode automatic
differentiation (AD) featuring performance competitive with low-level languages
like C++. Unlike recently developed AD tools in other popular high-level
languages such as Python and MATLAB, ForwardDiff takes advantage of
just-in-time (JIT) compilation to transparently recompile AD-unaware user code,
enabling efficient support for higher-order differentiation and differentiation
using custom number types (including complex numbers). For gradient and
Jacobian calculations, ForwardDiff provides a variant of vector-forward mode
that avoids expensive heap allocation and makes better use of memory bandwidth
than traditional vector mode. In our numerical experiments, we demonstrate that
for nontrivially large dimensions, ForwardDiff's gradient computations can be
faster than a reverse-mode implementation from the Python-based autograd
package. We also illustrate how ForwardDiff is used effectively within JuMP, a
modeling language for optimization. According to our usage statistics, 41
unique repositories on GitHub depend on ForwardDiff, with users from diverse
fields such as astronomy, optimization, finite element analysis, and
statistics.
  This document is an extended abstract that has been accepted for presentation
at the AD2016 7th International Conference on Algorithmic Differentiation.
</summary>
    <author>
      <name>Jarrett Revels</name>
    </author>
    <author>
      <name>Miles Lubin</name>
    </author>
    <author>
      <name>Theodore Papamarkou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.07892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04815v3</id>
    <updated>2016-11-04T08:20:36Z</updated>
    <published>2016-08-17T00:06:48Z</published>
    <title>A Functional Package for Automatic Solution of Ordinary Differential
  Equations with Spectral Methods</title>
    <summary>  We present a Python module named PyCheb, to solve the ordinary differential
equations by using spectral collocation method. PyCheb incorporates
discretization using Chebyshev points, barycentric interpolation and iterate
methods. With this Python module, users can initialize the ODEsolver class by
passing attributes, including the both sides of a given differential equation,
boundary conditions, and the number of Chebyshev points, which can also be
generated automatically by the ideal precision, to the constructor of ODEsolver
class. Then, the instance of the ODEsolver class can be used to automatically
determine the resolution of the differential equation as well as generate the
graph of the high-precision approximate solution. (If you have any questions,
please send me an email and I will reply ASAP.
e-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)
</summary>
    <author>
      <name>Shaohui Liu</name>
    </author>
    <author>
      <name>Tianshi Wang</name>
    </author>
    <author>
      <name>Youran Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to some serious
  mistakes made in the context since it is for the first time for all the
  authors to do independent research. Hope that we can fix all the problems
  soon and come back with some better results</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04815v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04815v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.08658v2</id>
    <updated>2016-10-10T13:15:52Z</updated>
    <published>2016-08-30T21:05:21Z</published>
    <title>Devito: automated fast finite difference computation</title>
    <summary>  Domain specific languages have successfully been used in a variety of fields
to cleanly express scientific problems as well as to simplify implementation
and performance opti- mization on different computer architectures. Although a
large number of stencil languages are available, finite differ- ence domain
specific languages have proved challenging to design because most practical use
cases require additional features that fall outside the finite difference
abstraction. Inspired by the complexity of real-world seismic imaging problems,
we introduce Devito, a domain specific language in which high level equations
are expressed using symbolic expressions from the SymPy package. Complex
equations are automatically manipulated, optimized, and translated into highly
optimized C code that aims to perform compa- rably or better than hand-tuned
code. All this is transpar- ent to users, who only see concise symbolic
mathematical expressions.
</summary>
    <author>
      <name>Navjot Kukreja</name>
    </author>
    <author>
      <name>Mathias Louboutin</name>
    </author>
    <author>
      <name>Felippe Vieira</name>
    </author>
    <author>
      <name>Fabio Luporini</name>
    </author>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Gerard Gorman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at WolfHPC 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.08658v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.08658v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00076v1</id>
    <updated>2016-09-01T01:11:48Z</updated>
    <published>2016-09-01T01:11:48Z</published>
    <title>BLISlab: A Sandbox for Optimizing GEMM</title>
    <summary>  Matrix-matrix multiplication is a fundamental operation of great importance
to scientific computing and, increasingly, machine learning. It is a simple
enough concept to be introduced in a typical high school algebra course yet in
practice important enough that its implementation on computers continues to be
an active research topic. This note describes a set of exercises that use this
operation to illustrate how high performance can be attained on modern CPUs
with hierarchical memories (multiple caches). It does so by building on the
insights that underly the BLAS-like Library Instantiation Software (BLIS)
framework by exposing a simplified "sandbox" that mimics the implementation in
BLIS. As such, it also becomes a vehicle for the "crowd sourcing" of the
optimization of BLIS. We call this set of exercises BLISlab.
</summary>
    <author>
      <name>Jianyu Huang</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">FLAME Working Note #80</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.00076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01277v2</id>
    <updated>2016-11-14T17:17:48Z</updated>
    <published>2016-09-05T10:11:31Z</published>
    <title>OpenSBLI: A framework for the automated derivation and parallel
  execution of finite difference solvers on a range of computer architectures</title>
    <summary>  Exascale computing will feature novel and potentially disruptive hardware
architectures. Exploiting these to their full potential is non-trivial.
Numerical modelling frameworks involving finite difference methods are
currently limited by the 'static' nature of the hand-coded discretisation
schemes and repeatedly may have to be re-written to run efficiently on new
hardware. In contrast, OpenSBLI uses code generation to derive the model's code
from a high-level specification. Users focus on the equations to solve, whilst
not concerning themselves with the detailed implementation. Source-to-source
translation is used to tailor the code and enable its execution on a variety of
hardware.
</summary>
    <author>
      <name>Christian T. Jacobs</name>
    </author>
    <author>
      <name>Satya P. Jammy</name>
    </author>
    <author>
      <name>Neil D. Sandham</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jocs.2016.11.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jocs.2016.11.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Author accepted version, with a small amendment: the link in the
  "Code Availability" section has been updated, and now refers to the OpenSBLI
  source code repository on GitHub. Accepted for publication in the Journal of
  Computational Science on 8 November 2016</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Science 18 (2017) 12-23</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.01277v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01277v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03361v1</id>
    <updated>2016-09-12T12:15:36Z</updated>
    <published>2016-09-12T12:15:36Z</published>
    <title>Devito: Towards a generic Finite Difference DSL using Symbolic Python</title>
    <summary>  Domain specific languages (DSL) have been used in a variety of fields to
express complex scientific problems in a concise manner and provide automated
performance optimization for a range of computational architectures. As such
DSLs provide a powerful mechanism to speed up scientific Python computation
that goes beyond traditional vectorization and pre-compilation approaches,
while allowing domain scientists to build applications within the comforts of
the Python software ecosystem. In this paper we present Devito, a new finite
difference DSL that provides optimized stencil computation from high-level
problem specifications based on symbolic Python expressions. We demonstrate
Devito's symbolic API and performance advantages over traditional Python
acceleration methods before highlighting its use in the scientific context of
seismic inversion problems.
</summary>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Navjot Kukreja</name>
    </author>
    <author>
      <name>Mathias Louboutin</name>
    </author>
    <author>
      <name>Fabio Luporini</name>
    </author>
    <author>
      <name>Felippe Vieira</name>
    </author>
    <author>
      <name>Vincenzo Pandolfo</name>
    </author>
    <author>
      <name>Paulius Velesko</name>
    </author>
    <author>
      <name>Paulius Kazakas</name>
    </author>
    <author>
      <name>Gerard Gorman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pyHPC 2016 conference submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04809v1</id>
    <updated>2016-09-15T05:05:29Z</updated>
    <published>2016-09-15T05:05:29Z</published>
    <title>An object oriented parallel finite element scheme for computations of
  PDEs: Design and implementation</title>
    <summary>  Parallel finite element algorithms based on object-oriented concepts are
presented. Moreover, the design and implementation of a data structure proposed
are utilized in realizing a parallel geometric multigrid method. The
ParFEMapper and the ParFECommunicator are the key components of the data
structure in the proposed parallel scheme. These classes are constructed based
on the type of finite elements (continuous or nonconforming or discontinuous)
used. The proposed solver is compared with the open source direct solvers,
MUMPS and PasTiX. Further, the performance of the parallel multigrid solver is
analyzed up to 1080 processors. The solver shows a very good speedup up to 960
processors and the problem size has to be increased in order to maintain the
good speedup when the number of processors are increased further. As a result,
the parallel solver is able to handle large scale problems on massively
parallel supercomputers. The proposed parallel finite element algorithms and
multigrid solver are implemented in our in-house package ParMooN.
</summary>
    <author>
      <name>Sashikumaar Ganesan</name>
    </author>
    <author>
      <name>Volker John</name>
    </author>
    <author>
      <name>Gunar Matthies</name>
    </author>
    <author>
      <name>Raviteja Meesala</name>
    </author>
    <author>
      <name>Shamim Abdus</name>
    </author>
    <author>
      <name>Ulrich Wilbrandt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.04809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03423v1</id>
    <updated>2016-11-10T17:50:06Z</updated>
    <published>2016-11-10T17:50:06Z</published>
    <title>DiffSharp: An AD Library for .NET Languages</title>
    <summary>  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)
library for the .NET ecosystem, which is targeted by the C# and F# languages,
among others. The library has been designed with machine learning applications
in mind, allowing very succinct implementations of models and optimization
routines. DiffSharp is implemented in F# and exposes forward and reverse AD
operators as general nestable higher-order functions, usable by any .NET
language. It provides high-performance linear algebra primitives---scalars,
vectors, and matrices, with a generalization to tensors underway---that are
fully supported by all the AD operators, and which use a BLAS/LAPACK backend
via the highly optimized OpenBLAS library. DiffSharp currently uses operator
overloading, but we are developing a transformation-based version of the
library using F#'s "code quotation" metaprogramming facility. Work on a
CUDA-based GPU backend is also underway.
</summary>
    <author>
      <name>Atılım Güneş Baydin</name>
    </author>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <author>
      <name>Jeffrey Mark Siskind</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.03423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06892v1</id>
    <updated>2016-11-18T15:11:48Z</updated>
    <published>2016-11-18T15:11:48Z</published>
    <title>Bidiagonalization with Parallel Tiled Algorithms</title>
    <summary>  We consider algorithms for going from a "full" matrix to a condensed "band
bidiagonal" form using orthogonal transformations. We use the framework of
"algorithms by tiles". Within this framework, we study: (i) the tiled
bidiagonalization algorithm BiDiag, which is a tiled version of the standard
scalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm
R-BiDiag, which is a tiled version of the algorithm which consists in first
performing the QR factorization of the initial matrix, then performing the
band-bidiagonalization of the R-factor. For both bidiagonalization algorithms
BiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,
FlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a
study of critical path lengths for these tiled algorithms, which shows that (i)
R-BiDiag has a shorter critical path length than BiDiag for tall and skinny
matrices, and (ii) Greedy based schemes are much better than earlier proposed
variants with unbounded resources. We provide experiments on a single multicore
node, and on a few multicore nodes of a parallel distributed shared-memory
system, to show the superiority of the new algorithms on a variety of matrix
sizes, matrix shapes and core counts.
</summary>
    <author>
      <name>Mathieu Faverge</name>
    </author>
    <author>
      <name>Julien Langou</name>
    </author>
    <author>
      <name>Yves Robert</name>
    </author>
    <author>
      <name>Jack Dongarra</name>
    </author>
    <link href="http://arxiv.org/abs/1611.06892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03772v1</id>
    <updated>2016-12-09T19:13:03Z</updated>
    <published>2016-12-09T19:13:03Z</published>
    <title>SimTensor: A synthetic tensor data generator</title>
    <summary>  SimTensor is a multi-platform, open-source software for generating artificial
tensor data (either with CP/PARAFAC or Tucker structure) for reproducible
research on tensor factorization algorithms. SimTensor is a stand-alone
application based on MATALB. It provides a wide range of facilities for
generating tensor data with various configurations. It comes with a
user-friendly graphical user interface, which enables the user to generate
tensors with complicated settings in an easy way. It also has this facility to
export generated data to universal formats such as CSV and HDF5, which can be
imported via a wide range of programming languages (C, C++, Java, R, Fortran,
MATLAB, Perl, Python, and many more). The most innovative part of SimTensor is
this that can generate temporal tensors with periodic waves, seasonal effects
and streaming structure. it can apply constraints such as non-negativity and
different kinds of sparsity to the data. SimTensor also provides this facility
to simulate different kinds of change-points and inject various types of
anomalies. The source code and binary versions of SimTensor is available for
download in http://www.simtensor.org.
</summary>
    <author>
      <name>Hadi Fanaee-T</name>
    </author>
    <author>
      <name>Joao Gama</name>
    </author>
    <link href="http://arxiv.org/abs/1612.03772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07526v1</id>
    <updated>2016-12-22T10:19:09Z</updated>
    <published>2016-12-22T10:19:09Z</published>
    <title>An efficient hybrid tridiagonal divide-and-conquer algorithm on
  distributed memory architectures</title>
    <summary>  In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for
the symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically
semiseparable (HSS) matrices. HSS is an important type of rank-structured
matrices.Most time of the DC algorithm is cost by computing the eigenvectors
via the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)
algorithm, MMM is accelerated by using the HSS matrix techniques when the
intermediate matrix is large. All the HSS algorithms are done via the package
STRUMPACK. PHDC has been tested by using many different matrices. Compared with
the DC implementation in MKL, PHDC can be faster for some matrices with few
deflations when using hundreds of processes. However, the gains decrease as the
number of processes increases. The comparisons of PHDC with ELPA (the
Eigenvalue soLvers for Petascale Applications library) are similar. PHDC is
usually slower than MKL and ELPA when using 300 or more processes on Tianhe-2
supercomputer.
</summary>
    <author>
      <name>Shengguo Li</name>
    </author>
    <author>
      <name>Francois-Henry Rouet</name>
    </author>
    <author>
      <name>Jie Liu</name>
    </author>
    <author>
      <name>Chun Huang</name>
    </author>
    <author>
      <name>Xingyu Gao</name>
    </author>
    <author>
      <name>Xuebin Chi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05913v1</id>
    <updated>2017-01-20T19:37:44Z</updated>
    <published>2017-01-20T19:37:44Z</published>
    <title>Scalable linear solvers for sparse linear systems from large-scale
  numerical simulations</title>
    <summary>  This paper presents our work on designing scalable linear solvers for
large-scale reservoir simulations. The main objective is to support
implementation of parallel reservoir simulators on distributed-memory parallel
systems, where MPI (Message Passing Interface) is employed for communications
among computation nodes. Distributed matrix and vector modules are designed,
which are the base of our parallel linear systems. Commonly-used Krylov
subspace linear solvers are implemented, including the restarted GMRES method,
the LGMRES method, and the BiCGSTAB method. It also has an interface to a
parallel algebraic multigrid solver, BoomerAMG from HYPRE. Parallel
general-purpose preconditioners and special preconditioners for reservoir
simulations are also developed. The numerical experiments show that our linear
solvers have excellent scalability using thousands of CPU cores.
</summary>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1602.05901</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.05913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04715v1</id>
    <updated>2017-02-14T20:49:22Z</updated>
    <published>2017-02-14T20:49:22Z</published>
    <title>Simflowny 2: An upgraded platform for scientific modeling and simulation</title>
    <summary>  Simflowny is an open platform which automatically generates parallel code of
scientific dynamical models for different simulation frameworks. Here we
present major upgrades on this software to support an extended set of families
of models, in particular: i) a new generic family for partial differential
equations, which can include spatial derivatives of any order, ii) a new family
for agent based models to study complex phenomena --either on a spatial domain
or on a graph--. Additionally we introduce a flexible graphical user interface
(GUI) to accommodate these and future families of equations. This paper
describes the new GUI architecture and summarizes the formal representation and
implementation of these new families, providing several validation results.
</summary>
    <author>
      <name>A. Arbona</name>
    </author>
    <author>
      <name>B. Miñano</name>
    </author>
    <author>
      <name>A. Rigo</name>
    </author>
    <author>
      <name>C. Bona</name>
    </author>
    <author>
      <name>C. Palenzuela</name>
    </author>
    <author>
      <name>A. Artigues</name>
    </author>
    <author>
      <name>C. Bona-Casas</name>
    </author>
    <author>
      <name>J. Massó</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2018.03.015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2018.03.015" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.04715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06898v2</id>
    <updated>2017-10-02T18:51:52Z</updated>
    <published>2017-02-22T17:12:49Z</published>
    <title>Enhancing speed and scalability of the ParFlow simulation code</title>
    <summary>  Regional hydrology studies are often supported by high resolution simulations
of subsurface flow that require expensive and extensive computations. Efficient
usage of the latest high performance parallel computing systems becomes a
necessity. The simulation software ParFlow has been demonstrated to meet this
requirement and shown to have excellent solver scalability for up to 16,384
processes. In the present work we show that the code requires further
enhancements in order to fully take advantage of current petascale machines. We
identify ParFlow's way of parallelization of the computational mesh as a
central bottleneck. We propose to reorganize this subsystem using fast mesh
partition algorithms provided by the parallel adaptive mesh refinement library
p4est. We realize this in a minimally invasive manner by modifying selected
parts of the code to reinterpret the existing mesh data structures. We evaluate
the scaling performance of the modified version of ParFlow, demonstrating good
weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test
an example application at large scale.
</summary>
    <author>
      <name>Carsten Burstedde</name>
    </author>
    <author>
      <name>Jose A. Fonseca</name>
    </author>
    <author>
      <name>Stefan Kollet</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10596-017-9696-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10596-017-9696-2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The final publication is available at link.springer.com</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Geosciences 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.06898v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06898v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03116v1</id>
    <updated>2017-03-09T03:01:31Z</updated>
    <published>2017-03-09T03:01:31Z</published>
    <title>ForestClaw: A parallel algorithm for patch-based adaptive mesh
  refinement on a forest of quadtrees</title>
    <summary>  We describe a parallel, adaptive, multi-block algorithm for explicit
integration of time dependent partial differential equations on two-dimensional
Cartesian grids. The grid layout we consider consists of a nested hierarchy of
fixed size, non-overlapping, logically Cartesian grids stored as leaves in a
quadtree. Dynamic grid refinement and parallel partitioning of the grids is
done through the use of the highly scalable quadtree/octree library p4est.
Because our concept is multi-block, we are able to easily solve on a variety of
geometries including the cubed sphere. In this paper, we pay special attention
to providing details of the parallel ghost-filling algorithm needed to ensure
that both corner and edge ghost regions around each grid hold valid values.
  We have implemented this algorithm in the ForestClaw code using single-grid
solvers from ClawPack, a software package for solving hyperbolic PDEs using
finite volumes methods. We show weak and strong scalability results for scalar
advection problems on two-dimensional manifold domains on 1 to 64Ki MPI
processes, demonstrating neglible regridding overhead.
</summary>
    <author>
      <name>Donna Calhoun</name>
    </author>
    <author>
      <name>Carsten Burstedde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.03116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M08, 65M50, 68W10, 65Y05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07206v1</id>
    <updated>2017-03-16T15:35:08Z</updated>
    <published>2017-03-16T15:35:08Z</published>
    <title>A GPU-based Multi-level Algorithm for Boundary Value Problems</title>
    <summary>  A novel and scalable geometric multi-level algorithm is presented for the
numerical solution of elliptic partial differential equations, specially
designed to run with high occupancy of streaming processors inside Graphics
Processing Units(GPUs). The algorithm consists of iterative, superposed
operations on a single grid, and it is composed of two simple full-grid
routines: a restriction and a coarsened interpolation-relaxation. The
restriction is used to collect sources using recursive coarsened averages, and
the interpolation-relaxation simultaneously applies coarsened finite-difference
operators and interpolations. The routines are scheduled in a saw-like refining
cycle. Convergence to machine precision is achieved repeating the full cycle
using accumulated residuals and successively collecting the solution. Its total
number of operations scale linearly with the number of nodes. It provides an
attractive fast solver for Boundary Value Problems (BVPs), specially for
simulations running entirely in the GPU. Applications shown in this work
include the deformation of two-dimensional grids, the computation of
three-dimensional streamlines for a singular trifoil-knot vortex and the
calculation of three-dimensional electric potentials in heterogeneous
dielectric media.
</summary>
    <author>
      <name>J. T. Becerra-Sagredo</name>
    </author>
    <author>
      <name>F. Mandujano</name>
    </author>
    <author>
      <name>C. Malaga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.07206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.00605v5</id>
    <updated>2018-06-14T21:02:13Z</updated>
    <published>2017-03-30T19:04:09Z</published>
    <title>Faster Base64 Encoding and Decoding Using AVX2 Instructions</title>
    <summary>  Web developers use base64 formats to include images, fonts, sounds and other
resources directly inside HTML, JavaScript, JSON and XML files. We estimate
that billions of base64 messages are decoded every day. We are motivated to
improve the efficiency of base64 encoding and decoding. Compared to
state-of-the-art implementations, we multiply the speeds of both the encoding
(~10x) and the decoding (~7x). We achieve these good results by using the
single-instruction-multiple-data (SIMD) instructions available on recent Intel
processors (AVX2). Our accelerated software abides by the specification and
reports errors when encountering characters outside of the base64 set. It is
available online as free software under a liberal license.
</summary>
    <author>
      <name>Wojciech Muła</name>
    </author>
    <author>
      <name>Daniel Lemire</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3132709</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3132709" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">software at https://github.com/lemire/fastbase64</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on the Web 12 (3), 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.00605v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.00605v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02457v3</id>
    <updated>2018-01-07T17:38:05Z</updated>
    <published>2017-04-08T09:00:22Z</published>
    <title>BLASFEO: basic linear algebra subroutines for embedded optimization</title>
    <summary>  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization. A key difference with respect to existing high-performance
implementations of BLAS is that the computational performance is optimized for
small to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO
comes with three different implementations: a high-performance implementation
aiming at providing the highest performance for matrices fitting in cache, a
reference implementation providing portability and embeddability and optimized
for very small matrices, and a wrapper to standard BLAS and LAPACK providing
high-performance on large matrices. The three implementations of BLASFEO
together provide high-performance dense linear algebra routines for matrices
ranging from very small to large. Compared to both open-source and proprietary
highly-tuned BLAS libraries, for matrices of size up to about one hundred the
high-performance implementation of BLASFEO is about 20-30% faster than the
corresponding level 3 BLAS routines and 2-3 times faster than the corresponding
LAPACK routines.
</summary>
    <author>
      <name>Gianluca Frison</name>
    </author>
    <author>
      <name>Dimitris Kouzoupis</name>
    </author>
    <author>
      <name>Tommaso Sartor</name>
    </author>
    <author>
      <name>Andrea Zanelli</name>
    </author>
    <author>
      <name>Moritz Diehl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3210754</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3210754" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software (TOMS): Volume 44 Issue
  4, August 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.02457v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02457v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03092v1</id>
    <updated>2017-04-11T00:37:59Z</updated>
    <published>2017-04-11T00:37:59Z</published>
    <title>Strassen's Algorithm for Tensor Contraction</title>
    <summary>  Tensor contraction (TC) is an important computational kernel widely used in
numerous applications. It is a multi-dimensional generalization of matrix
multiplication (GEMM). While Strassen's algorithm for GEMM is well studied in
theory and practice, extending it to accelerate TC has not been previously
pursued. Thus, we believe this to be the first paper to demonstrate how one can
in practice speed up tensor contraction with Strassen's algorithm. By adopting
a Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can
conceptually view TC as GEMM for a general stride storage, with an implicit
tensor-to-matrix transformation. This insight enables us to tailor a recent
state-of-the-art implementation of Strassen's algorithm to TC, avoiding
explicit transpositions (permutations) and extra workspace, and reducing the
overhead of memory movement that is incurred. Performance benefits are
demonstrated with a performance model as well as in practice on modern single
core, multicore, and distributed memory parallel architectures, achieving up to
1.3x speedup. The resulting implementations can serve as a drop-in replacement
for various applications with significant speedup.
</summary>
    <author>
      <name>Jianyu Huang</name>
    </author>
    <author>
      <name>Devin A. Matthews</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <link href="http://arxiv.org/abs/1704.03092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08579v2</id>
    <updated>2018-03-12T11:39:00Z</updated>
    <published>2017-04-24T12:34:29Z</published>
    <title>A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel
  Skylake</title>
    <summary>  The modern CPU's design, which is composed of hierarchical memory and
SIMD/vectorization capability, governs the potential for algorithms to be
transformed into efficient implementations. The release of the AVX-512 changed
things radically, and motivated us to search for an efficient sorting algorithm
that can take advantage of it. In this paper, we describe the best strategy we
have found, which is a novel two parts hybrid sort, based on the well-known
Quicksort algorithm. The central partitioning operation is performed by a new
algorithm, and small partitions/arrays are sorted using a branch-free
Bitonic-based sort. This study is also an illustration of how classical
algorithms can be adapted and enhanced by the AVX-512 extension. We evaluate
the performance of our approach on a modern Intel Xeon Skylake and assess the
different layers of our implementation by sorting/partitioning integers, double
floating-point numbers, and key/value pairs of integers. Our results
demonstrate that our approach is faster than two libraries of reference: the
GNU \emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP
library by a speedup factor of 1.4.
</summary>
    <author>
      <name>Berenger Bramas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14569/IJACSA.2017.081044</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14569/IJACSA.2017.081044" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, research paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Article Published in International Journal of Advanced Computer
  Science and Applications(IJACSA), Volume 8 Issue 10, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.08579v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08579v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00720v2</id>
    <updated>2017-07-01T23:04:37Z</updated>
    <published>2017-05-01T21:34:00Z</published>
    <title>Computing Tropical Prevarieties in Parallel</title>
    <summary>  The computation of the tropical prevariety is the first step in the
application of polyhedral methods to compute positive dimensional solution sets
of polynomial systems. In particular, pretropisms are candidate leading
exponents for the power series developments of the solutions. The computation
of the power series may start as soon as one pretropism is available, so our
parallel computation of the tropical prevariety has an application in a
pipelined solver.
  We present a parallel implementation of dynamic enumeration. Our first
distributed memory implementation with forked processes achieved good speedups,
but quite often resulted in large variations in the execution times of the
processes. The shared memory multithreaded version applies work stealing to
reduce the variability of the run time. Our implementation applies the thread
safe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU
Multiprecision Arithmetic Library (GMP), aided by the fast memory allocations
of TCMalloc.
  Our parallel implementation is capable of computing the tropical prevariety
of the cyclic 16-roots problem. We also report on computational experiments on
the $n$-body and $n$-vortex problems; our computational results compare
favorably with Gfan.
</summary>
    <author>
      <name>Anders Jensen</name>
    </author>
    <author>
      <name>Jeff Sommars</name>
    </author>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the proceedings of PASCO 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.00720v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00720v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01598v1</id>
    <updated>2017-05-03T19:58:00Z</updated>
    <published>2017-05-03T19:58:00Z</published>
    <title>cuTT: A High-Performance Tensor Transpose Library for CUDA Compatible
  GPUs</title>
    <summary>  We introduce the CUDA Tensor Transpose (cuTT) library that implements
high-performance tensor transposes for NVIDIA GPUs with Kepler and above
architectures. cuTT achieves high performance by (a) utilizing two
GPU-optimized transpose algorithms that both use a shared memory buffer in
order to reduce global memory access scatter, and by (b) computing memory
positions of tensor elements using a thread-parallel algorithm. We evaluate the
performance of cuTT on a variety of benchmarks with tensor ranks ranging from 2
to 12 and show that cuTT performance is independent of the tensor rank and that
it performs no worse than an approach based on code generation. We develop a
heuristic scheme for choosing the optimal parameters for tensor transpose
algorithms by implementing an analytical GPU performance model that can be used
at runtime without need for performance measurements or profiling. Finally, by
integrating cuTT into the tensor algebra library TAL-SH, we significantly
reduce the tensor transpose overhead in tensor contractions, achieving as low
as just one percent overhead for arithmetically intensive tensor contractions.
</summary>
    <author>
      <name>Antti-Pekka Hynninen</name>
    </author>
    <author>
      <name>Dmitry I. Lyakh</name>
    </author>
    <link href="http://arxiv.org/abs/1705.01598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03625v2</id>
    <updated>2017-09-15T00:00:52Z</updated>
    <published>2017-05-10T06:51:15Z</published>
    <title>A performance spectrum for parallel computational frameworks that solve
  PDEs</title>
    <summary>  Important computational physics problems are often large-scale in nature, and
it is highly desirable to have robust and high performing computational
frameworks that can quickly address these problems. However, it is no trivial
task to determine whether a computational framework is performing efficiently
or is scalable. The aim of this paper is to present various strategies for
better understanding the performance of any parallel computational frameworks
for solving PDEs. Important performance issues that negatively impact
time-to-solution are discussed, and we propose a performance spectrum analysis
that can enhance one's understanding of critical aforementioned performance
issues. As proof of concept, we examine commonly used finite element simulation
packages and software and apply the performance spectrum to quickly analyze the
performance and scalability across various hardware platforms, software
implementations, and numerical discretizations. It is shown that the proposed
performance spectrum is a versatile performance model that is not only
extendable to more complex PDEs such as hydrostatic ice sheet flow equations,
but also useful for understanding hardware performance in a massively parallel
computing environment. Potential applications and future extensions of this
work are also discussed.
</summary>
    <author>
      <name>J. Chang</name>
    </author>
    <author>
      <name>K. B. Nakshatrala</name>
    </author>
    <author>
      <name>M. G. Knepley</name>
    </author>
    <author>
      <name>L. Johnsson</name>
    </author>
    <link href="http://arxiv.org/abs/1705.03625v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03625v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03667v2</id>
    <updated>2018-04-09T13:51:11Z</updated>
    <published>2017-05-10T09:21:24Z</published>
    <title>TSFC: a structure-preserving form compiler</title>
    <summary>  A form compiler takes a high-level description of the weak form of partial
differential equations and produces low-level code that carries out the finite
element assembly. In this paper we present the Two-Stage Form Compiler (TSFC),
a new form compiler with the main motivation to maintain the structure of the
input expression as long as possible. This facilitates the application of
optimizations at the highest possible level of abstraction. TSFC features a
novel, structure-preserving method for separating the contributions of a form
to the subblocks of the local tensor in discontinuous Galerkin problems. This
enables us to preserve the tensor structure of expressions longer through the
compilation process than other form compilers. This is also achieved in part by
a two-stage approach that cleanly separates the lowering of finite element
constructs to tensor algebra in the first stage, from the scheduling of those
tensor operations in the second stage. TSFC also efficiently traverses
complicated expressions, and experimental evaluation demonstrates good
compile-time performance even for highly complex forms.
</summary>
    <author>
      <name>Miklós Homolya</name>
    </author>
    <author>
      <name>Lawrence Mitchell</name>
    </author>
    <author>
      <name>Fabio Luporini</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/17M1130642</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/17M1130642" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted version. 28 pages plus 5 pages supplement</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing, 40 (2018), pp. C401-C428</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.03667v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03667v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N20, 65M60, 65N30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05249v2</id>
    <updated>2018-04-27T09:10:16Z</updated>
    <published>2017-05-12T17:16:59Z</published>
    <title>CLBlast: A Tuned OpenCL BLAS Library</title>
    <summary>  This work introduces CLBlast, an open-source BLAS library providing optimized
OpenCL routines to accelerate dense linear algebra for a wide variety of
devices. It is targeted at machine learning and HPC applications and thus
provides a fast matrix-multiplication routine (GEMM) to accelerate the core of
many applications (e.g. deep learning, iterative solvers, astrophysics,
computational fluid dynamics, quantum chemistry). CLBlast has five main
advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested
on a large variety of OpenCL devices including less commonly used devices such
as embedded and low-power GPUs, 2) it can be explicitly tuned for specific
problem-sizes on specific hardware platforms, 3) it can perform operations in
half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has
an optional CUDA back-end, 5) and it can combine multiple operations in a
single batched routine, accelerating smaller problems significantly. This paper
describes the library and demonstrates the advantages of CLBlast experimentally
for different use-cases on a wide variety of OpenCL hardware.
</summary>
    <author>
      <name>Cedric Nugteren</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3204919.3204924</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3204919.3204924" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference paper in: IWOCL '18, the International Workshop on OpenCL</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.05249v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05249v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06661v1</id>
    <updated>2017-05-18T15:48:46Z</updated>
    <published>2017-05-18T15:48:46Z</published>
    <title>Spin Summations: A High-Performance Perspective</title>
    <summary>  Besides tensor contractions, one of the most pronounced computational
bottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry
methods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and
CCSDT(Q)---are spin summations. At a first sight, spin summations are
operations similar to tensor transpositions; a closer look instead reveals
additional challenges to high-performance calculations, including temporal
locality as well as scattered memory accesses. This publication explores a
sequence of algorithmic solutions for spin summations, each exploiting
individual properties of either the underlying hardware (e.g. caches,
vectorization), or the problem itself (e.g. factorizability). The final
algorithm combines the advantages of all the solutions, while avoiding their
drawbacks; this algorithm, achieves high-performance through parallelization,
vectorization, and by exploiting the temporal locality inherent to spin
summations. Combined, these optimizations result in speedups between 2.4x and
5.5x over the NCC quantum chemistry software package. In addition to such a
performance boost, our algorithm can perform the spin summations in-place, thus
reducing the memory footprint by 2x over an out-of-place variant.
</summary>
    <author>
      <name>Paul Springer</name>
    </author>
    <author>
      <name>Devin Matthews</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <link href="http://arxiv.org/abs/1705.06661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06668v1</id>
    <updated>2017-05-18T16:05:54Z</updated>
    <published>2017-05-18T16:05:54Z</published>
    <title>Introducing Geometric Algebra to Geometric Computing Software
  Developers: A Computational Thinking Approach</title>
    <summary>  Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems.
</summary>
    <author>
      <name>Ahmad Hosny Eid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Tutorial, 43 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.06668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07282v1</id>
    <updated>2017-05-20T09:07:04Z</updated>
    <published>2017-05-20T09:07:04Z</published>
    <title>Sparse Matrix Multiplication On An Associative Processor</title>
    <summary>  Sparse matrix multiplication is an important component of linear algebra
computations. Implementing sparse matrix multiplication on an associative
processor (AP) enables high level of parallelism, where a row of one matrix is
multiplied in parallel with the entire second matrix, and where the execution
time of vector dot product does not depend on the vector size. Four sparse
matrix multiplication algorithms are explored in this paper, combining AP and
baseline CPU processing to various levels. They are evaluated by simulation on
a large set of sparse matrices. The computational complexity of sparse matrix
multiplication on AP is shown to be an O(nnz) where nnz is the number of
nonzero elements. The AP is found to be especially efficient in binary sparse
matrix multiplication. AP outperforms conventional solutions in power
efficiency.
</summary>
    <author>
      <name>L. Yavits</name>
    </author>
    <author>
      <name>A. Morad</name>
    </author>
    <author>
      <name>R. Ginosar</name>
    </author>
    <link href="http://arxiv.org/abs/1705.07282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09905v1</id>
    <updated>2017-05-28T07:41:22Z</updated>
    <published>2017-05-28T07:41:22Z</published>
    <title>A Unified Optimization Approach for Sparse Tensor Operations on GPUs</title>
    <summary>  Sparse tensors appear in many large-scale applications with multidimensional
and sparse data. While multidimensional sparse data often need to be processed
on manycore processors, attempts to develop highly-optimized GPU-based
implementations of sparse tensor operations are rare. The irregular computation
patterns and sparsity structures as well as the large memory footprints of
sparse tensor operations make such implementations challenging. We leverage the
fact that sparse tensor operations share similar computation patterns to
propose a unified tensor representation called F-COO. Combined with
GPU-specific optimizations, F-COO provides highly-optimized implementations of
sparse tensor computations on GPUs. The performance of the proposed unified
approach is demonstrated for tensor-based kernels such as the Sparse Matricized
Tensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix
Multiply (SpTTM) and is used in tensor decomposition algorithms. Compared to
state-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to
3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a
CANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using
the unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs.
</summary>
    <author>
      <name>Bangtian Liu</name>
    </author>
    <author>
      <name>Chengyao Wen</name>
    </author>
    <author>
      <name>Anand D. Sarwate</name>
    </author>
    <author>
      <name>Maryam Mehri Dehnavi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CLUSTER.2017.75</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CLUSTER.2017.75" rel="related"/>
    <link href="http://arxiv.org/abs/1705.09905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00231v1</id>
    <updated>2017-06-01T09:55:10Z</updated>
    <published>2017-06-01T09:55:10Z</published>
    <title>Automatic Differentiation using Constraint Handling Rules in Prolog</title>
    <summary>  Automatic differentiation is a technique which allows a programmer to define
a numerical computation via compositions of a broad range of numeric and
computational primitives and have the underlying system support the computation
of partial derivatives of the result with respect to any of its inputs, without
making any finite difference approximations, and without manipulating large
symbolic expressions representing the computation. This note describes a novel
approach to reverse mode automatic differentiation using constraint logic
programmming, specifically, the constraint handling rules (CHR) library of SWI
Prolog, resulting in a very small (50 lines of code) implementation. When
applied to a differentiation-based implementation of the inside-outside
algorithm for parameter learning in probabilistic grammars, the CHR based
implementations outperformed two well-known frameworks for optimising
differentiable functions, Theano and TensorFlow, by a large margin.
</summary>
    <author>
      <name>Samer Abdallah</name>
    </author>
    <link href="http://arxiv.org/abs/1706.00231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05141v1</id>
    <updated>2017-07-13T12:25:52Z</updated>
    <published>2017-07-13T12:25:52Z</published>
    <title>Batched QR and SVD Algorithms on GPUs with Applications in Hierarchical
  Matrix Compression</title>
    <summary>  We present high performance implementations of the QR and the singular value
decomposition of a batch of small matrices hosted on the GPU with applications
in the compression of hierarchical matrices. The one-sided Jacobi algorithm is
used for its simplicity and inherent parallelism as a building block for the
SVD of low rank blocks using randomized methods. We implement multiple kernels
based on the level of the GPU memory hierarchy in which the matrices can reside
and show substantial speedups against streamed cuSOLVER SVDs. The resulting
batched routine is a key component of hierarchical matrix compression, opening
up opportunities to perform H-matrix arithmetic efficiently on GPUs.
</summary>
    <author>
      <name>Wajih Halim Boukaram</name>
    </author>
    <author>
      <name>George Turkiyyah</name>
    </author>
    <author>
      <name>Hatem Ltaief</name>
    </author>
    <author>
      <name>David E. Keyes</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05943v2</id>
    <updated>2018-09-04T02:51:39Z</updated>
    <published>2017-07-19T06:06:13Z</published>
    <title>FDTD: solving 1+1D delay PDE in parallel</title>
    <summary>  We present a proof of concept for solving a 1+1D complex-valued, delay
partial differential equation (PDE) that emerges in the study of waveguide
quantum electrodynamics (QED) by adapting the finite-difference time-domain
(FDTD) method. The delay term is spatially non-local, rendering conventional
approaches such as the method of lines inapplicable. We show that by properly
designing the grid and by supplying the (partial) exact solution as the
boundary condition, the delay PDE can be numerically solved. In addition, we
demonstrate that while the delay imposes strong data dependency, multi-thread
parallelization can nevertheless be applied to such a problem. Our code
provides a numerically exact solution to the time-dependent multi-photon
scattering problem in waveguide QED.
</summary>
    <author>
      <name>Yao-Lung L. Fang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2018.08.018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2018.08.018" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Introduced two parallelization approaches along with other
  improvements in the presentation. Code open sourced at
  https://github.com/leofang/FDTD. To appear in Computer Physics Communications</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 235, 422 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.05943v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05943v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09094v1</id>
    <updated>2017-07-28T03:15:22Z</updated>
    <published>2017-07-28T03:15:22Z</published>
    <title>An Open Source C++ Implementation of Multi-Threaded Gaussian Mixture
  Models, k-Means and Expectation Maximisation</title>
    <summary>  Modelling of multivariate densities is a core component in many signal
processing, pattern recognition and machine learning applications. The
modelling is often done via Gaussian mixture models (GMMs), which use
computationally expensive and potentially unstable training algorithms. We
provide an overview of a fast and robust implementation of GMMs in the C++
language, employing multi-threaded versions of the Expectation Maximisation
(EM) and k-means training algorithms. Multi-threading is achieved through
reformulation of the EM and k-means algorithms into a MapReduce-like framework.
Furthermore, the implementation uses several techniques to improve numerical
stability and modelling accuracy. We demonstrate that the multi-threaded
implementation achieves a speedup of an order of magnitude on a recent 16 core
machine, and that it can achieve higher modelling accuracy than a previously
well-established publically accessible implementation. The multi-threaded
implementation is included as a user-friendly class in recent releases of the
open source Armadillo C++ linear algebra library. The library is provided under
the permissive Apache~2.0 license, allowing unencumbered use in commercial
products.
</summary>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <author>
      <name>Ryan Curtin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICSPCS.2017.8270510</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICSPCS.2017.8270510" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Signal Processing and Communication
  Systems, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.09094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05, 68N99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1; J.2; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01873v1</id>
    <updated>2017-08-02T19:12:50Z</updated>
    <published>2017-08-02T19:12:50Z</published>
    <title>Practically efficient methods for performing bit-reversed permutation in
  C++11 on the x86-64 architecture</title>
    <summary>  The bit-reversed permutation is a famous task in signal processing and is key
to efficient implementation of the fast Fourier transform. This paper presents
optimized C++11 implementations of five extant methods for computing the
bit-reversed permutation: Stockham auto-sort, naive bitwise swapping, swapping
via a table of reversed bytes, local pairwise swapping of bits, and swapping
via a cache-localized matrix buffer. Three new strategies for performing the
bit-reversed permutation in C++11 are proposed: an inductive method using the
bitwise XOR operation, a template-recursive closed form, and a cache-oblivious
template-recursive approach, which reduces the bit-reversed permutation to
smaller bit-reversed permutations and a square matrix transposition. These new
methods are compared to the extant approaches in terms of theoretical runtime,
empirical compile time, and empirical runtime. The template-recursive
cache-oblivious method is shown to be competitive with the fastest known
method; however, we demonstrate that the cache-oblivious method can more
readily benefit from parallelization on multiple cores and on the GPU.
</summary>
    <author>
      <name>Christian Knauth</name>
    </author>
    <author>
      <name>Boran Adas</name>
    </author>
    <author>
      <name>Daniel Whitfield</name>
    </author>
    <author>
      <name>Xuesong Wang</name>
    </author>
    <author>
      <name>Lydia Ickler</name>
    </author>
    <author>
      <name>Tim Conrad</name>
    </author>
    <author>
      <name>Oliver Serang</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03438v4</id>
    <updated>2018-12-24T01:02:58Z</updated>
    <published>2017-08-11T05:39:36Z</published>
    <title>Veamy: an extensible object-oriented C++ library for the virtual element
  method</title>
    <summary>  This paper summarizes the development of Veamy, an object-oriented C++
library for the virtual element method (VEM) on general polygonal meshes, whose
modular design is focused on its extensibility. The linear elastostatic and
Poisson problems in two dimensions have been chosen as the starting stage for
the development of this library. The theory of the VEM, upon which Veamy is
built, is presented using a notation and a terminology that resemble the
language of the finite element method (FEM) in engineering analysis. Several
examples are provided to demonstrate the usage of Veamy, and in particular, one
of them features the interaction between Veamy and the polygonal mesh generator
PolyMesher. A computational performance comparison between VEM and FEM is also
conducted. Veamy is free and open source software.
</summary>
    <author>
      <name>Alejandro Ortiz-Bernardin</name>
    </author>
    <author>
      <name>Catalina Alvarez</name>
    </author>
    <author>
      <name>Nancy Hitschfeld-Kahler</name>
    </author>
    <author>
      <name>Alessandro Russo</name>
    </author>
    <author>
      <name>Rodrigo Silva-Valenzuela</name>
    </author>
    <author>
      <name>Edgardo Olate-Sanzana</name>
    </author>
    <link href="http://arxiv.org/abs/1708.03438v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03438v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04539v1</id>
    <updated>2017-08-14T00:18:41Z</updated>
    <published>2017-08-14T00:18:41Z</published>
    <title>PSelInv - A Distributed Memory Parallel Algorithm for Selected
  Inversion: the non-symmetric Case</title>
    <summary>  This paper generalizes the parallel selected inversion algorithm called
PSelInv to sparse non- symmetric matrices. We assume a general sparse matrix A
has been decomposed as PAQ = LU on a distributed memory parallel machine, where
L, U are lower and upper triangular matrices, and P, Q are permutation
matrices, respectively. The PSelInv method computes selected elements of A-1.
The selection is confined by the sparsity pattern of the matrix AT . Our
algorithm does not assume any symmetry properties of A, and our parallel
implementation is memory efficient, in the sense that the computed elements of
A-T overwrites the sparse matrix L+U in situ. PSelInv involves a large number
of collective data communication activities within different processor groups
of various sizes. In order to minimize idle time and improve load balancing,
tree-based asynchronous communication is used to coordinate all such collective
communication. Numerical results demonstrate that PSelInv can scale efficiently
to 6,400 cores for a variety of matrices.
</summary>
    <author>
      <name>Mathias Jacquelin</name>
    </author>
    <author>
      <name>Lin Lin</name>
    </author>
    <author>
      <name>Chao Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1404.0447</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.04539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05279v2</id>
    <updated>2017-08-30T15:41:17Z</updated>
    <published>2017-08-17T13:59:48Z</published>
    <title>Designing and building the mlpack open-source machine learning library</title>
    <summary>  mlpack is an open-source C++ machine learning library with an emphasis on
speed and flexibility. Since its original inception in 2007, it has grown to be
a large project implementing a wide variety of machine learning algorithms,
from standard techniques such as decision trees and logistic regression to
modern techniques such as deep neural networks as well as other
recently-published cutting-edge techniques not found in any other library.
mlpack is quite fast, with benchmarks showing mlpack outperforming other
libraries' implementations of the same methods. mlpack has an active community,
with contributors from around the world---including some from PUST. This short
paper describes the goals and design of mlpack, discusses how the open-source
community functions, and shows an example usage of mlpack for a simple data
science problem.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to ICOPUST 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.05279v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05279v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00302v2</id>
    <updated>2017-11-06T12:52:00Z</updated>
    <published>2017-09-01T13:34:32Z</published>
    <title>Look-Ahead in the Two-Sided Reduction to Compact Band Forms for
  Symmetric Eigenvalue Problems and the SVD</title>
    <summary>  We address the reduction to compact band forms, via unitary similarity
transformations, for the solution of symmetric eigenvalue problems and the
computation of the singular value decomposition (SVD). Concretely, in the first
case we revisit the reduction to symmetric band form while, for the second
case, we propose a similar alternative, which transforms the original matrix to
(unsymmetric) band form, replacing the conventional reduction method that
produces a triangular--band output. In both cases, we describe algorithmic
variants of the standard Level-3 BLAS-based procedures, enhanced with
look-ahead, to overcome the performance bottleneck imposed by the panel
factorization. Furthermore, our solutions employ an algorithmic block size that
differs from the target bandwidth, illustrating the important performance
benefits of this decision. Finally, we show that our alternative compact band
form for the SVD is key to introduce an effective look-ahead strategy into the
corresponding reduction procedure.
</summary>
    <author>
      <name>Rafael Rodríguez-Sánchez</name>
    </author>
    <author>
      <name>Sandra Catalán</name>
    </author>
    <author>
      <name>José R. Herrero</name>
    </author>
    <author>
      <name>Enrique S. Quintana-Ortí</name>
    </author>
    <author>
      <name>Andrés E. Tomás</name>
    </author>
    <link href="http://arxiv.org/abs/1709.00302v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00302v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01126v2</id>
    <updated>2017-12-29T21:49:27Z</updated>
    <published>2017-09-04T19:26:03Z</published>
    <title>From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for
  the spherical Laplace equation</title>
    <summary>  A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned
Conjugate Gradient code is described, and timing results for multi-node
multi-GPU runs are shown. The code is used to obtain three-dimensional
spherical solutions to the Laplace equation. Its application is finding
potential field solutions of the solar corona, a useful tool in space weather
modeling. We highlight key tips, strategies, and challenges faced when adding
OpenACC. Performance results are shown for running the code with MPI-only on
multiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.
</summary>
    <author>
      <name>Ronald M. Caplan</name>
    </author>
    <author>
      <name>Zoran Mikic</name>
    </author>
    <author>
      <name>Jon A. Linker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures. Work presented at the 2017 NVIDIA GPU Technology
  Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01126v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01126v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07229v1</id>
    <updated>2017-09-21T09:28:36Z</updated>
    <published>2017-09-21T09:28:36Z</published>
    <title>High-Performance Derivative Computations using CoDiPack</title>
    <summary>  There are several AD tools available, which all implement different
strategies for the reverse mode of AD. The major strategies are primal value
taping (implemented e.g. by ADOL-c) and Jacobi taping (implemented e.g. by
adept and dco/c++). Especially for Jacobi taping, recent advances by using
expression templates make this approach very attractive for large scale
software. The current implementations are either closed source or miss
essential features and flexibility. Therefore, we present the new AD tool
CoDiPack (Code Differentiation Package) in this paper. It is specifically
designed for a minimal memory consumption and optimal runtime, such that it can
be used for the differentiation of large scale software. An essential part of
the design of CoDiPack is the modular layout and the recursive data structures,
which do not only allow the efficient implementation of the Jacobi taping
approach, but will also enable other approaches like the primal value taping or
new research ideas. We will also present the performance value of CoDiPack on a
generic PDE example and on the SU2 code.
</summary>
    <author>
      <name>Max Sagebaum</name>
    </author>
    <author>
      <name>Tim Albring</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 11 figures, 6 tables, CoDiPack:
  https://github.com/SciCompKL/CoDiPack</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.07229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4; G.4; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.04286v1</id>
    <updated>2017-10-11T20:04:43Z</updated>
    <published>2017-10-11T20:04:43Z</published>
    <title>Deriving Correct High-Performance Algorithms</title>
    <summary>  Dijkstra observed that verifying correctness of a program is difficult and
conjectured that derivation of a program hand-in-hand with its proof of
correctness was the answer. We illustrate this goal-oriented approach by
applying it to the domain of dense linear algebra libraries for distributed
memory parallel computers. We show that algorithms that underlie the
implementation of most functionality for this domain can be systematically
derived to be correct. The benefit is that an entire family of algorithms for
an operation is discovered so that the best algorithm for a given architecture
can be chosen. This approach is very practical: Ideas inspired by it have been
used to rewrite the dense linear algebra software stack starting below the
Basic Linear Algebra Subprograms (BLAS) and reaching up through the Elemental
distributed memory library, and every level in between. The paper demonstrates
how formal methods and rigorous mathematical techniques for correctness impact
HPC.
</summary>
    <author>
      <name>Devangi N. Parikh</name>
    </author>
    <author>
      <name>Maggie E. Myers</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <link href="http://arxiv.org/abs/1710.04286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.04286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.04985v1</id>
    <updated>2017-10-13T16:15:41Z</updated>
    <published>2017-10-13T16:15:41Z</published>
    <title>On Parallel Solution of Sparse Triangular Linear Systems in CUDA</title>
    <summary>  The acceleration of sparse matrix computations on modern many-core
processors, such as the graphics processing units (GPUs), has been recognized
and studied over a decade. Significant performance enhancements have been
achieved for many sparse matrix computational kernels such as sparse
matrix-vector products and sparse matrix-matrix products. Solving linear
systems with sparse triangular structured matrices is another important sparse
kernel as demanded by a variety of scientific and engineering applications such
as sparse linear solvers. However, the development of efficient parallel
algorithms in CUDA for solving sparse triangular linear systems remains a
challenging task due to the inherently sequential nature of the computation. In
this paper, we will revisit this problem by reviewing the existing
level-scheduling methods and proposing algorithms with self-scheduling
techniques. Numerical results have indicated that the CUDA implementations of
the proposed algorithms can outperform the state-of-the-art solvers in cuSPARSE
by a factor of up to $2.6$ for structured model problems and general sparse
matrices.
</summary>
    <author>
      <name>Ruipeng Li</name>
    </author>
    <link href="http://arxiv.org/abs/1710.04985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.04985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.08259v2</id>
    <updated>2018-04-14T16:41:41Z</updated>
    <published>2017-10-23T13:27:36Z</published>
    <title>Nauticle: a general-purpose particle-based simulation tool</title>
    <summary>  Nauticle is a general-purpose simulation tool for the flexible and highly
configurable application of particle-based methods of either discrete or
continuum phenomena. It is presented that Nauticle has three distinct layers
for users and developers, then the top two layers are discussed in detail. The
paper introduces the Symbolic Form Language (SFL) of Nauticle, which
facilitates the formulation of user-defined numerical models at the top level
in text-based configuration files and provides simple application examples of
use. On the other hand, at the intermediate level, it is shown that the SFL can
be intuitively extended with new particle methods without tedious recoding or
even the knowledge of the bottom level. Finally, the efficiency of the code is
also tested through a performance benchmark.
</summary>
    <author>
      <name>Balazs Toth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted manuscript</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.08259v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.08259v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.08826v1</id>
    <updated>2017-10-21T11:43:33Z</updated>
    <published>2017-10-21T11:43:33Z</published>
    <title>GooFit 2.0</title>
    <summary>  The GooFit package provides physicists a simple, familiar syntax for
manipulating probability density functions and performing fits, and is highly
optimized for data analysis on NVIDIA GPUs and multithreaded CPU backends.
GooFit was updated to version 2.0, bringing a host of new features. A
completely revamped and redesigned build system makes GooFit easier to install,
develop with, and run on virtually any system. Unit testing, continuous
integration, and advanced logging options are improving the stability and
reliability of the system. Developing new PDFs now uses standard CUDA
terminology and provides a lower barrier for new users. The system now has
built-in support for multiple graphics cards or nodes using MPI, and is being
tested on a wide range of different systems. GooFit also has significant
improvements in performance on some GPU architectures due to optimized memory
access. Support for time-dependent four-body amplitude analyses has also been
added.
</summary>
    <author>
      <name>Henry Schreiner</name>
    </author>
    <author>
      <name>Christoph Hasse</name>
    </author>
    <author>
      <name>Bradley Hittle</name>
    </author>
    <author>
      <name>Himadri Pandey</name>
    </author>
    <author>
      <name>Michael Sokoloff</name>
    </author>
    <author>
      <name>Karen Tomko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the ACAT 2017 proceedings, 6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.08826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.08826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.09578v2</id>
    <updated>2021-11-29T14:10:54Z</updated>
    <published>2017-10-26T08:16:04Z</published>
    <title>Fast Linear Transformations in Python</title>
    <summary>  Scientific computing requires handling large linear models, which are often
composed of structured matrices. With increasing model size, dense
representations quickly become infeasible to compute or store. Matrix-free
implementations are suited to mitigate this problem but usually complicate
research and development effort by months, when applied to practical research
problems.
  Fastmat is a framework for handling large composed or structured matrices by
offering an easy-to-use abstraction model. It allows expressing and using
linear operators in a mathematically intuitive way, while maintaining a strong
focus on efficient computation and memory storage. The implemented user
interface allows for very readable code implementation with very close
relationship to the actual mathematical notation of a given problem. Further it
provides means for quickly testing new implementations and also allows for
run-time execution path optimization.
  Summarizing, fastmat provides a flexible and extensible framework for
handling matrix-free linear structured operators efficiently, while being
intuitive and generating easy-to-reuse results.
</summary>
    <author>
      <name>Christoph Wilfried Wagner</name>
    </author>
    <author>
      <name>Sebastian Semper</name>
    </author>
    <author>
      <name>Jan Kirchhof</name>
    </author>
    <link href="http://arxiv.org/abs/1710.09578v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.09578v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.10230v1</id>
    <updated>2017-12-29T13:53:03Z</updated>
    <published>2017-12-29T13:53:03Z</published>
    <title>On quality of implementation of Fortran 2008 complex intrinsic functions
  on branch cuts</title>
    <summary>  Branch cuts in complex functions in combination with signed zero and signed
infinity have important uses in fracture mechanics, jet flow and aerofoil
analysis. We present benchmarks for validating Fortran 2008 complex functions -
LOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with
arguments of all 3 IEEE floating point binary formats: binary32, binary64 and
binary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,
Cray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,
e.g. wrong signs of results or unexpected overflow, underflow, or NaN. We
conclude that the quality of implementation of these Fortran 2008 intrinsics in
many compilers is not yet sufficient to remove the need for special code for
branch cuts. The test results are complemented by conformal maps of the branch
cuts and detailed derivations of the values of these functions on branch cuts,
to be used as a reference. The benchmarks are freely available from
cmplx.sf.net. This work will be of interest to engineers who use complex
functions, as well as to compiler and maths library developers.
</summary>
    <author>
      <name>Anton Shterenlikht</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 10 figures, 13 tables, original work</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.10230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.10230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="30-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.03614v2</id>
    <updated>2018-01-14T19:12:21Z</updated>
    <published>2018-01-11T02:16:35Z</published>
    <title>Review of theory and implementation of hyper-dual numbers for first and
  second order automatic differentiation</title>
    <summary>  In this review we present hyper-dual numbers as a tool for the automatic
differentiation of computer programs via operator overloading.
  We start with a motivational introduction into the ideas of algorithmic
differentiation. Then we illuminate the concepts behind operator overloading
and dual numbers.
  Afterwards, we present hyper-dual numbers (and vectors) as an extension of
dual numbers for the computation of the Jacobian and the Hessian matrices of a
computer program. We review a mathematical theorem that proves the correctness
of the derivative information that is obtained from hyper-dual numbers.
  Finally, we refer to a freely available implementation of a hyper-dual number
class in Matlab. We explain an interface that can be called with a function as
argument such that the Jacobian and Hessian of this function are returned.
</summary>
    <author>
      <name>Martin Neuenhofen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.03614v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.03614v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.08682v1</id>
    <updated>2018-01-26T05:56:11Z</updated>
    <published>2018-01-26T05:56:11Z</published>
    <title>Stop talking to me -- a communication-avoiding ADER-DG realisation</title>
    <summary>  We present a communication- and data-sensitive formulation of ADER-DG for
hyperbolic differential equation systems. Sensitive here has multiple flavours:
First, the formulation reduces the persistent memory footprint. This reduces
pressure on the memory subsystem. Second, the formulation realises the
underlying predictor-corrector scheme with single-touch semantics, i.e., each
degree of freedom is read on average only once per time step from the main
memory. This reduces communication through the memory controllers. Third, the
formulation breaks up the tight coupling of the explicit time stepping's
algorithmic steps to mesh traversals. This averages out data access peaks.
Different operations and algorithmic steps are ran on different grid entities.
Finally, the formulation hides distributed memory data transfer behind the
computation aligned with the mesh traversal. This reduces pressure on the
machine interconnects. All techniques applied by our formulation are elaborated
by means of a rigorous task formalism. They break up ADER-DG's tight causal
coupling of compute steps and can be generalised to other predictor-corrector
schemes.
</summary>
    <author>
      <name>Dominic E. Charrier</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <link href="http://arxiv.org/abs/1801.08682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.08682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.02474v1</id>
    <updated>2018-01-12T16:02:09Z</updated>
    <published>2018-01-12T16:02:09Z</published>
    <title>High-level python abstractions for optimal checkpointing in inversion
  problems</title>
    <summary>  Inversion and PDE-constrained optimization problems often rely on solving the
adjoint problem to calculate the gradient of the objec- tive function. This
requires storing large amounts of intermediate data, setting a limit to the
largest problem that might be solved with a given amount of memory available.
Checkpointing is an approach that can reduce the amount of memory required by
redoing parts of the computation instead of storing intermediate results. The
Revolve checkpointing algorithm o ers an optimal schedule that trades
computational cost for smaller memory footprints. Integrat- ing Revolve into a
modern python HPC code and combining it with code generation is not
straightforward. We present an API that makes checkpointing accessible from a
DSL-based code generation environment along with some initial performance gures
with a focus on seismic applications.
</summary>
    <author>
      <name>Navjot Kukreja</name>
    </author>
    <author>
      <name>Jan Hückelheim</name>
    </author>
    <author>
      <name>Michael Lange</name>
    </author>
    <author>
      <name>Mathias Louboutin</name>
    </author>
    <author>
      <name>Andrea Walther</name>
    </author>
    <author>
      <name>Simon W. Funke</name>
    </author>
    <author>
      <name>Gerard Gorman</name>
    </author>
    <link href="http://arxiv.org/abs/1802.02474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.02474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.03433v1</id>
    <updated>2018-02-09T19:56:16Z</updated>
    <published>2018-02-09T19:56:16Z</published>
    <title>GPU Accelerated Finite Element Assembly with Runtime Compilation</title>
    <summary>  In recent years, high performance scientific computing on graphics processing
units (GPUs) have gained widespread acceptance. These devices are designed to
offer massively parallel threads for running code with general purpose. There
are many researches focus on finite element method with GPUs. However, most of
the works are specific to certain problems and applications. Some works propose
methods for finite element assembly that is general for a wide range of finite
element models. But the development of finite element code is dependent on the
hardware architectures. It is usually complicated and error prone using the
libraries provided by the hardware vendors. In this paper, we present
architecture and implementation of finite element assembly for partial
differential equations (PDEs) based on symbolic computation and runtime
compilation technique on GPU. User friendly programming interface with symbolic
computation is provided. At the same time, high computational efficiency is
achieved by using runtime compilation technique. As far as we know, it is the
first work using this technique to accelerate finite element assembly for
solving PDEs. Experiments show that a one to two orders of speedup is achieved
for the problems studied in the paper.
</summary>
    <author>
      <name>Tao Cui</name>
    </author>
    <author>
      <name>Xiaohu Guo</name>
    </author>
    <author>
      <name>Hui Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 8 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.03433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.03433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.03650v1</id>
    <updated>2018-02-10T20:51:30Z</updated>
    <published>2018-02-10T20:51:30Z</published>
    <title>Achieving Efficient Realization of Kalman Filter on CGRA through
  Algorithm-Architecture Co-design</title>
    <summary>  In this paper, we present efficient realization of Kalman Filter (KF) that
can achieve up to 65% of the theoretical peak performance of underlying
architecture platform. KF is realized using Modified Faddeeva Algorithm (MFA)
as a basic building block due to its versatility and REDEFINE Coarse Grained
Reconfigurable Architecture (CGRA) is used as a platform for experiments since
REDEFINE is capable of supporting realization of a set algorithmic compute
structures at run-time on a Reconfigurable Data-path (RDP). We perform several
hardware and software based optimizations in the realization of KF to achieve
116% improvement in terms of Gflops over the first realization of KF. Overall,
with the presented approach for KF, 4-105x performance improvement in terms of
Gflops/watt over several academically and commercially available realizations
of KF is attained. In REDEFINE, we show that our implementation is scalable and
the performance attained is commensurate with the underlying hardware resources
</summary>
    <author>
      <name>Farhad Merchant</name>
    </author>
    <author>
      <name>Tarun Vatwani</name>
    </author>
    <author>
      <name>Anupam Chattopadhyay</name>
    </author>
    <author>
      <name>Soumyendu Raha</name>
    </author>
    <author>
      <name>S K Nandy</name>
    </author>
    <author>
      <name>Ranjani Narayan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ARC 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.03650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.03650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.10574v2</id>
    <updated>2018-04-24T17:55:16Z</updated>
    <published>2018-02-28T18:28:10Z</published>
    <title>Sparse Tensor Algebra Optimizations with Workspaces</title>
    <summary>  This paper shows how to optimize sparse tensor algebraic expressions by
introducing temporary tensors, called workspaces, into the resulting loop
nests. We develop a new intermediate language for tensor operations called
concrete index notation that extends tensor index notation. Concrete index
notation expresses when and where sub-computations occur and what tensor they
are stored into. We then describe the workspace optimization in this language,
and how to compile it to sparse code by building on prior work in the
literature.
  We demonstrate the importance of the optimization on several important sparse
tensor kernels, including sparse matrix-matrix multiplication (SpMM), sparse
tensor addition (SpAdd), and the matricized tensor times Khatri-Rao product
(MTTKRP) used to factorize tensors. Our results show improvements over prior
work on tensor algebra compilation and brings the performance of these kernels
on par with state-of-the-art hand-optimized implementations. For example, SpMM
was not supported by prior tensor algebra compilers, the performance of MTTKRP
on the nell-2 data set improves by 35%, and MTTKRP can for the first time have
sparse results.
</summary>
    <author>
      <name>Fredrik Kjolstad</name>
    </author>
    <author>
      <name>Willow Ahrens</name>
    </author>
    <author>
      <name>Shoaib Kamil</name>
    </author>
    <author>
      <name>Saman Amarasinghe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.10574v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.10574v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.02156v1</id>
    <updated>2018-03-06T13:13:23Z</updated>
    <published>2018-03-06T13:13:23Z</published>
    <title>Chebyshev Filter Diagonalization on Modern Manycore Processors and
  GPGPUs</title>
    <summary>  Chebyshev filter diagonalization is well established in quantum chemistry and
quantum physics to compute bulks of eigenvalues of large sparse matrices.
Choosing a block vector implementation, we investigate optimization
opportunities on the new class of high-performance compute devices featuring
both high-bandwidth and low-bandwidth memory. We focus on the transparent
access to the full address space supported by both architectures under
consideration: Intel Xeon Phi "Knights Landing" and Nvidia "Pascal."
  We propose two optimizations: (1) Subspace blocking is applied for improved
performance and data access efficiency. We also show that it allows
transparently handling problems much larger than the high-bandwidth memory
without significant performance penalties. (2) Pipelining of communication and
computation phases of successive subspaces is implemented to hide communication
costs without extra memory traffic.
  As an application scenario we use filter diagonalization studies on
topological insulator materials. Performance numbers on up to 512 nodes of the
OakForest-PACS and Piz Daint supercomputers are presented, achieving beyond 100
Tflop/s for computing 100 inner eigenvalues of sparse matrices of dimension one
billion.
</summary>
    <author>
      <name>Moritz Kreutzer</name>
    </author>
    <author>
      <name>Georg Hager</name>
    </author>
    <author>
      <name>Dominik Ernst</name>
    </author>
    <author>
      <name>Holger Fehske</name>
    </author>
    <author>
      <name>Alan R. Bishop</name>
    </author>
    <author>
      <name>Gerhard Wellein</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-92040-5_17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-92040-5_17" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.02156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.02156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.04154v1</id>
    <updated>2018-03-12T08:39:30Z</updated>
    <published>2018-03-12T08:39:30Z</published>
    <title>Algorithmic Differentiation for Domain Specific Languages</title>
    <summary>  Algorithmic Differentiation (AD) can be used to automate the generation of
derivatives in arbitrary software projects. This will generate maintainable
derivatives, that are always consistent with the computation of the software.
If a domain specific language (DSL) is used in a software the state of the art
approach is to differentiate the DSL library with the same AD tool. The
drawback of this solution is the reduced performance since the compiler is no
longer able to optimize the e.g. SIMD operations. The new approach in this
paper integrates the types and operations of the DSL into the AD tool. It will
be an operator overloading tool that is generated from an abstract definition
of a DSL. This approach enables the compiler to optimize again e.g. for SIMD
operation since all calculations are still performed with the original data
types. This will also reduce the required memory for AD since the statements
inside the DLS implementation are no longer seen by the AD tool. The
implementation is presented in the paper and first results for the performance
of the solution are presented.
</summary>
    <author>
      <name>Max Sagebaum</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.04154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.04154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D25 (Primary), 68N30 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4; G.4; D.2.2; D.2.11" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.06226v2</id>
    <updated>2018-03-21T10:06:54Z</updated>
    <published>2018-03-13T21:57:49Z</published>
    <title>Glyph: Symbolic Regression Tools</title>
    <summary>  We present Glyph - a Python package for genetic programming based symbolic
regression. Glyph is designed for usage let by numerical simulations let by
real world experiments. For experimentalists, glyph-remote provides a
separation of tasks: a ZeroMQ interface splits the genetic programming
optimization task from the evaluation of an experimental (or numerical) run.
Glyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are
be able to employ symbolic regression in their experiments with ease, even if
they are not expert programmers. The reuse potential is kept high by a generic
interface design. Glyph is available on PyPI and Github.
</summary>
    <author>
      <name>Markus Quade</name>
    </author>
    <author>
      <name>Julien Gout</name>
    </author>
    <author>
      <name>Markus Abel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to JOSR. arXiv admin note: text overlap with
  arXiv:1612.05276</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.06226v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.06226v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.06934v1</id>
    <updated>2018-03-19T14:02:44Z</updated>
    <published>2018-03-19T14:02:44Z</published>
    <title>PyGOM - A Python Package for Simplifying Modelling with Systems of
  Ordinary Differential Equations</title>
    <summary>  Ordinary Differential Equations (ODE) are used throughout science where the
capture of rates of change in states is sought. While both pieces of commercial
and open software exist to study such systems, their efficient and accurate
usage frequently requires deep understanding of mathematics and programming.
The package we present here, PyGOM, seeks to remove these obstacles for models
based on ODE systems. We provide a simple interface for the construction of
such systems backed by a comprehensive and easy to use tool--box. This
tool--box implements functions to easily perform common operations for ODE
systems such as solving, parameter estimation, and stochastic simulation. The
package source is freely available and organized in a way that permits easy
extension. With both the algebraic and numeric calculations performed
automatically (but still accessible), the end user is freed to focus on model
development.
</summary>
    <author>
      <name>Edwin Tye</name>
    </author>
    <author>
      <name>Tom Finnie</name>
    </author>
    <author>
      <name>Ian Hall</name>
    </author>
    <author>
      <name>Steve Leach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.06934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.06934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.10120v1</id>
    <updated>2018-04-24T15:54:12Z</updated>
    <published>2018-04-24T15:54:12Z</published>
    <title>Automatic generation of CUDA code performing tensor manipulations using
  C++ expression templates</title>
    <summary>  We present a C++ library, TLoops, which uses a hierarchy of expression
templates to represent operations upon tensorial quantities in single lines of
C++ code that resemble analytic equations. These expressions may be run as-is,
but may also be used to emit equivalent low-level C or CUDA code, which either
performs the operations more quickly on the CPU, or allows them to be rapidly
ported to run on NVIDIA GPUs. We detail the expression template and C++-class
hierarchy that represents the expressions and which makes automatic
code-generation possible. We then present benchmarks of the expression-template
code, the automatically generated C code, and the automatically generated CUDA
code running on several generations of NVIDIA GPU.
</summary>
    <author>
      <name>Adam G. M. Lewis</name>
    </author>
    <author>
      <name>Harald P. Pfeiffer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.10120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.10120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.04941v1</id>
    <updated>2018-06-13T10:46:32Z</updated>
    <published>2018-06-13T10:46:32Z</published>
    <title>Far-HO: A Bilevel Programming Package for Hyperparameter Optimization
  and Meta-Learning</title>
    <summary>  In (Franceschi et al., 2018) we proposed a unified mathematical framework,
grounded on bilevel programming, that encompasses gradient-based hyperparameter
optimization and meta-learning. We formulated an approximate version of the
problem where the inner objective is solved iteratively, and gave sufficient
conditions ensuring convergence to the exact problem. In this work we show how
to optimize learning rates, automatically weight the loss of single examples
and learn hyper-representations with Far-HO, a software package based on the
popular deep learning framework TensorFlow that allows to seamlessly tackle
both HO and ML problems.
</summary>
    <author>
      <name>Luca Franceschi</name>
    </author>
    <author>
      <name>Riccardo Grazzi</name>
    </author>
    <author>
      <name>Massimiliano Pontil</name>
    </author>
    <author>
      <name>Saverio Salzo</name>
    </author>
    <author>
      <name>Paolo Frasconi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This submission is a reduced version of (Franceschi et al.,
  arXiv:1806.04910) which has been accepted at the main ICML 2018 conference.
  In this paper we illustrate the software framework, material that could not
  be included in the conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.04941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.04941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.07984v3</id>
    <updated>2020-02-24T08:17:01Z</updated>
    <published>2018-06-19T14:09:42Z</published>
    <title>Enclave Tasking for Discontinuous Galerkin Methods on Dynamically
  Adaptive Meshes</title>
    <summary>  High-order Discontinuous Galerkin (DG) methods promise to be an excellent
discretisation paradigm for partial differential equation solvers by combining
high arithmetic intensity with localised data access. They also facilitate
dynamic adaptivity without the need for conformal meshes. A parallel evaluation
of DG's weak formulation within a mesh traversal is non-trivial, as dependency
graphs over dynamically adaptive meshes change, as causal constraints along
resolution transitions have to be preserved, and as data sends along MPI domain
boundaries have to be triggered in the correct order. We propose to process
mesh elements subject to constraints with high priority or, where needed,
serially throughout a traversal. The remaining cells form enclaves and are
spawned into a task system. This introduces concurrency, mixes memory-intensive
DG integrations with compute-bound Riemann solves, and overlaps computation and
communication. We discuss implications on MPI and show that MPI parallelisation
improves by a factor of three through enclave tasking, while we obtain an
additional factor of two from shared memory if grids are dynamically adaptive.
</summary>
    <author>
      <name>Dominic E. Charrier</name>
    </author>
    <author>
      <name>Benjamin Hazelwood</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/19M1276194</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/19M1276194" rel="related"/>
    <link href="http://arxiv.org/abs/1806.07984v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.07984v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.11558v1</id>
    <updated>2018-06-20T07:39:20Z</updated>
    <published>2018-06-20T07:39:20Z</published>
    <title>A scalable H-matrix approach for the solution of boundary integral
  equations on multi-GPU clusters</title>
    <summary>  In this work, we consider the solution of boundary integral equations by
means of a scalable hierarchical matrix approach on clusters equipped with
graphics hardware, i.e. graphics processing units (GPUs). To this end, we
extend our existing single-GPU hierarchical matrix library hmglib such that it
is able to scale on many GPUs and such that it can be coupled to arbitrary
application codes. Using a model GPU implementation of a boundary element
method (BEM) solver, we are able to achieve more than 67 percent relative
parallel speed-up going from 128 to 1024 GPUs for a model geometry test case
with 1.5 million unknowns and a real-world geometry test case with almost 1.2
million unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6
minutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the
setup phase and 20 seconds for the iterative solver. To the best of the
authors' knowledge, we here discuss the first fully GPU-based
distributed-memory parallel hierarchical matrix Open Source library using the
traditional H-matrix format and adaptive cross approximation with an
application to BEM problems.
</summary>
    <author>
      <name>Helmut Harbrecht</name>
    </author>
    <author>
      <name>Peter Zaspel</name>
    </author>
    <link href="http://arxiv.org/abs/1806.11558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.11558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.01417v2</id>
    <updated>2019-03-27T21:09:34Z</updated>
    <published>2018-07-04T01:04:27Z</published>
    <title>The Implementation of the Colored Abstract Simplicial Complex and its
  Application to Mesh Generation</title>
    <summary>  We introduce CASC: a new, modern, and header-only C++ library which provides
a data structure to represent arbitrary dimension abstract simplicial complexes
(ASC) with user-defined classes stored directly on the simplices at each
dimension. This is accomplished by using the latest C++ language features
including variadic template parameters introduced in C++11 and automatic
function return type deduction from C++14. Effectively CASC decouples the
representation of the topology from the interactions of user data. We present
the innovations and design principles of the data structure and related
algorithms. This includes a metadata aware decimation algorithm which is
general for collapsing simplices of any dimension. We also present an example
application of this library to represent an orientable surface mesh.
</summary>
    <author>
      <name>C. T. Lee</name>
    </author>
    <author>
      <name>J. B. Moody</name>
    </author>
    <author>
      <name>R. E. Amaro</name>
    </author>
    <author>
      <name>J. A. McCammon</name>
    </author>
    <author>
      <name>M. Holst</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3321515</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3321515" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Math. Softw. 45, 3, Article 28 (August 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1807.01417v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.01417v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.01775v1</id>
    <updated>2018-07-03T09:52:57Z</updated>
    <published>2018-07-03T09:52:57Z</published>
    <title>FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC
  libraries</title>
    <summary>  The Python package fluidfft provides a common Python API for performing Fast
Fourier Transforms (FFT) in sequential, in parallel and on GPU with different
FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT
framework which allows Python users to easily and efficiently perform FFT and
the associated tasks, such as as computing linear operators and energy spectra.
We describe the architecture of the package composed of C++ and Cython FFT
classes, Python "operator" classes and Pythran functions. The package supplies
utilities to easily test itself and benchmark the different FFT solutions for a
particular case and on a particular machine. We present a performance scaling
analysis on three different computing clusters and a microbenchmark showing
that fluidfft is an interesting solution to write efficient Python applications
using FFT.
</summary>
    <author>
      <name>Ashwin Vishnu Mohanan</name>
    </author>
    <author>
      <name>Cyrille Bonamy</name>
    </author>
    <author>
      <name>Pierre Augier</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.238</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.238" rel="related"/>
    <link href="http://arxiv.org/abs/1807.01775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.01775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.05252v1</id>
    <updated>2018-07-13T19:17:48Z</updated>
    <published>2018-07-13T19:17:48Z</published>
    <title>The Dune Python Module</title>
    <summary>  In this paper we present the new Dune-Python module which provides Python
bindings for the Dune core, which is a C++ environment for solving partial
differential equations. The aim of this new module is to firstly provide the
general infrastructure for exporting realizations of statically polymorphic
interfaces based on just-in-time compilation and secondly to provide bindings
for the central interfaces of the dune core modules. In the first release we
focus on the grid interface. Our aim is to only introduce a thin layer when
passing objects into Python which can be removed when the object is passed back
into a C++ algorithm. Thus no efficiency is lost and little additional code
maintenance cost is incurred. To make the transition for Dune users to the
Python environment straightforward the Python classes provide a very similar
interface to their C++ counterparts. In addition, vectorized versions of many
interfaces allow for more efficient code on the Python side. The infrastructure
for exporting these interfaces and the resulting bindings for a Dune grid are
explained in detail in this paper for both experienced Dune users and others
interested in a flexible Python environment for implementing grid based schemes
for solving partial differential equations.
</summary>
    <author>
      <name>Andreas Dedner</name>
    </author>
    <author>
      <name>Martin Nolte</name>
    </author>
    <link href="http://arxiv.org/abs/1807.05252v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.05252v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.07643v3</id>
    <updated>2018-08-03T04:28:40Z</updated>
    <published>2018-07-17T13:12:32Z</published>
    <title>Physical-type correctness in scientific Python</title>
    <summary>  The representation of units and dimensions in informatics systems is barely
codified and often ignored. For instance, the major languages used in
scientific computing (Fortran, C and Python), have no type for dimension or
unit, and so physical quantities are represented in a program by variables of
type real, resulting in the possibility of unit or dimensional errors. In view
of this danger, many authors have proposed language schemes for unit-checking
and conversion. However, since many physical quantities have the same units, it
is possible for a block of code to be unit-compatible, but still physically
meaningless. We demonstrate the limitations of three Python unit-libraries and
present a justification and method for checking kind-of-quantity.
</summary>
    <author>
      <name>Marcus Foster</name>
    </author>
    <author>
      <name>Sean Tregeagle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. v2 expanded Abstract only. v3 added reference to/description
  of/code example for recent units library unyt arXiv:1806.02417; fixed typos</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.07643v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.07643v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.02638v1</id>
    <updated>2018-08-08T06:21:56Z</updated>
    <published>2018-08-08T06:21:56Z</published>
    <title>Accelerating wave-propagation algorithms with adaptive mesh refinement
  using the Graphics Processing Unit (GPU)</title>
    <summary>  Clawpack is a library for solving nonlinear hyperbolic partial differential
equations using high-resolution finite volume methods based on Riemann solvers
and limiters. It supports Adaptive Mesh Refinement (AMR), which is essential in
solving multi-scale problems. Recently, we added capabilities to accelerate the
code by using the Graphics Process Unit (GPU). Routines that manage CPU and GPU
AMR data and facilitate the execution of GPU kernels are added. Customized and
CPU thread-safe memory managers are designed to manage GPU and CPU memory
pools, which is essential in eliminating the overhead of memory allocation and
de-allocation. A global reduction is conducted every time step for dynamically
adjusting the time step based on Courant number restrictions. Some small GPU
kernels are merged into bigger kernels, which greatly reduces kernel launching
overhead. A speed-up between $2$ and $3$ for the total running time is observed
in an acoustics benchmark problem.
</summary>
    <author>
      <name>Xinsheng Qin</name>
    </author>
    <author>
      <name>Randall J. LeVeque</name>
    </author>
    <author>
      <name>Michael R. Motley</name>
    </author>
    <link href="http://arxiv.org/abs/1808.02638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.02638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.02731v1</id>
    <updated>2018-08-08T11:44:27Z</updated>
    <published>2018-08-08T11:44:27Z</published>
    <title>pySDC - Prototyping spectral deferred corrections</title>
    <summary>  In this paper we present the Python framework pySDC for solving collocation
problems with spectral deferred correction methods (SDC) and their
time-parallel variant PFASST, the parallel full approximation scheme in space
and time. pySDC features many implementations of SDC and PFASST, from simple
implicit time-stepping to high-order implicit-explicit or multi-implicit
splitting and multi-level spectral deferred corrections. It comes with many
different, pre-implemented examples and has seven tutorials to help new users
with their first steps. Time-parallelism is implemented either in an emulated
way for debugging and prototyping as well as using MPI for benchmarking. The
code is fully documented and tested using continuous integration, including
most results of previous publications. Here, we describe the structure of the
code by taking two different perspectives: the user's and the developer's
perspective. While the first sheds light on the front-end, the examples and the
tutorials, the second is used to describe the underlying implementation and the
data structures. We show three different examples to highlight various aspects
of the implementation, the capabilities and the usage of pySDC. Also, couplings
to the FEniCS framework and PETSc, the latter including spatial parallelism
with MPI, are described.
</summary>
    <author>
      <name>Robert Speck</name>
    </author>
    <link href="http://arxiv.org/abs/1808.02731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.02731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.05513v2</id>
    <updated>2019-09-06T10:30:57Z</updated>
    <published>2018-08-16T14:30:14Z</published>
    <title>Code generation for generally mapped finite elements</title>
    <summary>  Many classical finite elements such as the Argyris and Bell elements have
long been absent from high-level PDE software. Building on recent theoretical
work, we describe how to implement very general finite element transformations
in FInAT and hence into the Firedrake finite element system. Numerical results
evaluate the new elements, comparing them to existing methods for classical
problems. For a second order model problem, we find that new elements give
smooth solutions at a mild increase in cost over standard Lagrange elements.
For fourth-order problems, however, the newly-enabled methods significantly
outperform interior penalty formulations. We also give some advanced use cases,
solving the nonlinear Cahn-Hilliard equation and some biharmonic eigenvalue
problems (including Chladni plates) using $C^1$ discretizations.
</summary>
    <author>
      <name>Robert C. Kirby</name>
    </author>
    <author>
      <name>Lawrence Mitchell</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3361745</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3361745" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software 45(41):1-23 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1808.05513v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.05513v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.07984v1</id>
    <updated>2018-08-24T02:28:51Z</updated>
    <published>2018-08-24T02:28:51Z</published>
    <title>Implementing Strassen's Algorithm with CUTLASS on NVIDIA Volta GPUs</title>
    <summary>  Conventional GPU implementations of Strassen's algorithm (Strassen) typically
rely on the existing high-performance matrix multiplication (GEMM), trading
space for time. As a result, such approaches can only achieve practical speedup
for relatively large, "squarish" matrices due to the extra memory overhead, and
their usages are limited due to the considerable workspace. We present novel
Strassen primitives for GPUs that can be composed to generate a family of
Strassen algorithms. Our algorithms utilize both the memory and thread
hierarchies on GPUs, reusing shared memory and register files inherited from
GEMM, fusing additional operations, and avoiding extra workspace. We further
exploit intra- and inter-kernel parallelism by batching, streaming, and
employing atomic operations. We also develop a performance model for NVIDIA
Volta GPUs to select the appropriate blocking parameters and predict the
performance for GEMM and Strassen. Overall, our 1-level Strassen can achieve up
to 1.11x speedup with a crossover point as small as 1,536 compared to
cublasSgemm on a NVIDIA Tesla V100 GPU. With additional workspace, our 2-level
Strassen can achieve 1.19x speedup with a crossover point at 7,680.
</summary>
    <author>
      <name>Jianyu Huang</name>
    </author>
    <author>
      <name>Chenhan D. Yu</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <link href="http://arxiv.org/abs/1808.07984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.07984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.00674v1</id>
    <updated>2018-10-01T12:41:29Z</updated>
    <published>2018-10-01T12:41:29Z</published>
    <title>Multiscale finite element calculations in Python using SfePy</title>
    <summary>  SfePy (Simple finite elements in Python) is a software for solving various
kinds of problems described by partial differential equations in one, two or
three spatial dimensions by the finite element method. Its source code is
mostly (85\%) Python and relies on fast vectorized operations provided by the
NumPy package. For a particular problem two interfaces can be used: a
declarative application programming interface (API), where problem
description/definition files (Python modules) are used to define a calculation,
and an imperative API, that can be used for interactive commands, or in scripts
and libraries. After outlining the SfePy package development, the paper
introduces its implementation, structure and general features. The components
for defining a partial differential equation are described using an example of
a simple heat conduction problem. Specifically, the declarative API of SfePy is
presented in the example. To illustrate one of SfePy's main assets, the
framework for implementing complex multiscale models based on the theory of
homogenization, an example of a two-scale piezoelastic model is presented,
showing both the mathematical description of the problem and the corresponding
code.
</summary>
    <author>
      <name>Robert Cimrman</name>
    </author>
    <author>
      <name>Vladimír Lukeš</name>
    </author>
    <author>
      <name>Eduard Rohan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10444-019-09666-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10444-019-09666-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript version is made available under the CC-BY-NC-ND 4.0
  license</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Computational Mathematics, 45(4): 1897-1921 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1810.00674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.00674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35Qxx, 65N30, 65M60, 65Y05, 74S05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.02561v3</id>
    <updated>2019-03-08T15:24:29Z</updated>
    <published>2018-10-05T08:02:28Z</published>
    <title>GPdoemd: a Python package for design of experiments for model
  discrimination</title>
    <summary>  Model discrimination identifies a mathematical model that usefully explains
and predicts a given system's behaviour. Researchers will often have several
models, i.e. hypotheses, about an underlying system mechanism, but insufficient
experimental data to discriminate between the models, i.e. discard inaccurate
models. Given rival mathematical models and an initial experimental data set,
optimal design of experiments suggests maximally informative experimental
observations that maximise a design criterion weighted by prediction
uncertainty. The model uncertainty requires gradients, which may not be readily
available for black-box models. This paper (i) proposes a new design criterion
using the Jensen-R\'enyi divergence, and (ii) develops a novel method replacing
black-box models with Gaussian process surrogates. Using the surrogates, we
marginalise out the model parameters with approximate inference. Results show
these contributions working well for both classical and new test instances. We
also (iii) introduce and discuss GPdoemd, the open-source implementation of the
Gaussian process surrogate method.
</summary>
    <author>
      <name>Simon Olofsson</name>
    </author>
    <author>
      <name>Lukas Hebing</name>
    </author>
    <author>
      <name>Sebastian Niedenführ</name>
    </author>
    <author>
      <name>Marc Peter Deisenroth</name>
    </author>
    <author>
      <name>Ruth Misener</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compchemeng.2019.03.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compchemeng.2019.03.010" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers &amp; Chemical Engineering, Volume 125, 2019, Pages 54-70</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1810.02561v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.02561v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.07517v1</id>
    <updated>2018-10-12T18:37:06Z</updated>
    <published>2018-10-12T18:37:06Z</published>
    <title>Expressing Sparse Matrix Computations for Productive Performance on
  Spatial Architectures</title>
    <summary>  This paper addresses spatial programming of sparse matrix computations for
productive performance. The challenge is how to express an irregular
computation and its optimizations in a regular way.
  A sparse matrix has (non-zero) values and a structure. In this paper, we
propose to classify the implementations of a computation on a sparse matrix
into two categories: (1) structure-driven, or top-down, approach, which
traverses the structure with given row and column indices and locates the
corresponding values, and (2) values-driven, or bottom-up, approach, which
loads and processes the values in parallel streams, and decodes the structure
for the values' corresponding row and column indices.
  On a spatial architecture like FPGAs, the values-driven approach is the norm.
We show how to express a sparse matrix computation and its optimizations for a
values-driven implementation. A compiler automatically synthesizes a code to
decode the structure. In this way, programmers focus on optimizing the
processing of the values, using familiar optimizations for dense matrices,
while leaving the complex, irregular structure traversal to an automatic
compiler. We also attempt to regularize the optimizations of the reduction for
a dynamic number of values, which is common in a sparse matrix computation.
</summary>
    <author>
      <name>Hongbo Rong</name>
    </author>
    <link href="http://arxiv.org/abs/1810.07517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.07517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.08297v3</id>
    <updated>2018-10-24T21:05:28Z</updated>
    <published>2018-10-18T22:52:52Z</published>
    <title>Dynamic Automatic Differentiation of GPU Broadcast Kernels</title>
    <summary>  We show how forward-mode automatic differentiation (AD) can be employed
within larger reverse-mode computations to dynamically differentiate broadcast
operations in a GPU-friendly manner. Our technique fully exploits the broadcast
Jacobian's inherent sparsity structure, and unlike a pure reverse-mode
approach, this "mixed-mode" approach does not require a backwards pass over the
broadcasted operation's subgraph, obviating the need for several
reverse-mode-specific programmability restrictions on user-authored broadcast
operations. Most notably, this approach allows broadcast fusion in primal code
despite the presence of data-dependent control flow. We discuss an experiment
in which a Julia implementation of our technique outperformed pure reverse-mode
TensorFlow and Julia implementations for differentiating through broadcast
operations within an HM-LSTM cell update calculation.
</summary>
    <author>
      <name>Jarrett Revels</name>
    </author>
    <author>
      <name>Tim Besard</name>
    </author>
    <author>
      <name>Valentin Churavy</name>
    </author>
    <author>
      <name>Bjorn De Sutter</name>
    </author>
    <author>
      <name>Juan Pablo Vielma</name>
    </author>
    <link href="http://arxiv.org/abs/1810.08297v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.08297v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.08723v1</id>
    <updated>2018-10-20T00:56:12Z</updated>
    <published>2018-10-20T00:56:12Z</published>
    <title>The Ocean Tensor Package</title>
    <summary>  Matrix and tensor operations form the basis of a wide range of fields and
applications, and in many cases constitute a substantial part of the overall
computational complexity. The ability of general-purpose GPUs to speed up many
of these operations and enable others has resulted in a widespread adaptation
of these devices. In order for tensor operations to take full advantage of the
computational power, specialized software is required, and currently there
exist several packages (predominantly in the area of deep learning) that
incorporate tensor operations on both CPU and GPU. Nevertheless, a stand-alone
framework that supports general tensor operations is still missing. In this
paper we fill this gap and propose the Ocean Tensor Library: a modular
tensor-support package that is designed to serve as a foundational layer for
applications that require dense tensor operations on a variety of device types.
The API is carefully designed to be powerful, extensible, and at the same time
easy to use. The package is available as open source.
</summary>
    <author>
      <name>Ewout van den Berg</name>
    </author>
    <link href="http://arxiv.org/abs/1810.08723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.08723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.09361v2</id>
    <updated>2018-12-10T04:37:09Z</updated>
    <published>2018-10-22T15:26:35Z</published>
    <title>ensmallen: a flexible C++ library for efficient function optimization</title>
    <summary>  We present ensmallen, a fast and flexible C++ library for mathematical
optimization of arbitrary user-supplied functions, which can be applied to many
machine learning problems. Several types of optimizations are supported,
including differentiable, separable, constrained, and categorical objective
functions. The library provides many pre-built optimizers (including numerous
variants of SGD and Quasi-Newton optimizers) as well as a flexible framework
for implementing new optimizers and objective functions. Implementation of a
new optimizer requires only one method and a new objective function requires
typically one or two C++ functions. This can aid in the quick implementation
and prototyping of new machine learning algorithms. Due to the use of C++
template metaprogramming, ensmallen is able to support compiler optimizations
that provide fast runtimes. Empirical comparisons show that ensmallen is able
to outperform other optimization frameworks (like Julia and SciPy), sometimes
by large margins. The library is distributed under the BSD license and is ready
for use in production environments.
</summary>
    <author>
      <name>Shikhar Bhardwaj</name>
    </author>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Yannis Mentekidis</name>
    </author>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5281/zenodo.2008650</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5281/zenodo.2008650" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Systems for ML and Open Source Software at NIPS /
  NeurIPS, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.09361v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.09361v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65K10, 68N99, 68W99, 90C53" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6, G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.05031v2</id>
    <updated>2019-01-14T11:37:12Z</updated>
    <published>2018-11-12T22:52:46Z</published>
    <title>A Review of automatic differentiation and its efficient implementation</title>
    <summary>  Derivatives play a critical role in computational statistics, examples being
Bayesian inference using Hamiltonian Monte Carlo sampling and the training of
neural networks. Automatic differentiation is a powerful tool to automate the
calculation of derivatives and is preferable to more traditional methods,
especially when differentiating complex algorithms and mathematical functions.
The implementation of automatic differentiation however requires some care to
insure efficiency. Modern differentiation packages deploy a broad range of
computational techniques to improve applicability, run time, and memory
management. Among these techniques are operation overloading, region based
memory, and expression templates. There also exist several mathematical
techniques which can yield high performance gains when applied to complex
algorithms. For example, semi-analytical derivatives can reduce by orders of
magnitude the runtime required to numerically solve and differentiate an
algebraic equation. Open problems include the extension of current packages to
provide more specialized routines, and efficient methods to perform
higher-order differentiation.
</summary>
    <author>
      <name>Charles C. Margossian</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/WIDM.1305</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/WIDM.1305" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 5 figures, submitted for publication. WIREs Data Mining
  Knowl Discov, March 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.05031v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.05031v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.08309v2</id>
    <updated>2019-02-21T02:11:33Z</updated>
    <published>2018-11-19T00:07:34Z</published>
    <title>Modeling Deep Learning Accelerator Enabled GPUs</title>
    <summary>  The efficacy of deep learning has resulted in its use in a growing number of
applications. The Volta graphics processor unit (GPU) architecture from NVIDIA
introduced a specialized functional unit, the "tensor core", that helps meet
the growing demand for higher performance for deep learning. In this paper we
study the design of the tensor cores in NVIDIA's Volta and Turing
architectures. We further propose an architectural model for the tensor cores
in Volta. When implemented a GPU simulator, GPGPU-Sim, our tensor core model
achieves 99.6\% correlation versus an NVIDIA Titan~V GPU in terms of average
instructions per cycle when running tensor core enabled GEMM workloads. We also
describe support added to enable GPGPU-Sim to run CUTLASS, an open-source CUDA
C++ template library providing customizable GEMM templates that utilize tensor
cores.
</summary>
    <author>
      <name>Md Aamir Raihan</name>
    </author>
    <author>
      <name>Negar Goli</name>
    </author>
    <author>
      <name>Tor Aamodt</name>
    </author>
    <link href="http://arxiv.org/abs/1811.08309v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.08309v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.02874v4</id>
    <updated>2021-01-14T17:46:20Z</updated>
    <published>2019-01-09T18:52:01Z</published>
    <title>DUNEuro -- A software toolbox for forward modeling in
  bioelectromagnetism</title>
    <summary>  Accurate and efficient source analysis in electro- and magnetoencephalography
using sophisticated realistic head geometries requires advanced numerical
approaches. This paper presents DUNEuro, a free and open source C++ software
toolbox for forward modeling in bioelectromagnetism. Building upon the DUNE
framework, it provides implementations of modern fitted and unfitted finite
element methods to efficiently solve the forward problems in electro- and
magnetoencephalography. The user can choose between a variety of different
source models that are implemented. The software's aim is to provide interfaces
that are extendible and easy-to-use. In order to enable a closer integration
into existing analysis pipelines, interfaces to Python and Matlab are provided.
The practical use is demonstrated by a source analysis example of somatosensory
evoked potentials using a realistic six compartment head model.
</summary>
    <author>
      <name>Sophie Schrader</name>
    </author>
    <author>
      <name>Andreas Westhoff</name>
    </author>
    <author>
      <name>Maria Carla Piastra</name>
    </author>
    <author>
      <name>Tuuli Miinalainen</name>
    </author>
    <author>
      <name>Sampsa Pursiainen</name>
    </author>
    <author>
      <name>Johannes Vorwerk</name>
    </author>
    <author>
      <name>Heinrich Brinck</name>
    </author>
    <author>
      <name>Carsten H. Wolters</name>
    </author>
    <author>
      <name>Christian Engwer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0252431</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0252431" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 16.6 (2021): e0252431</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.02874v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.02874v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04289v2</id>
    <updated>2019-05-10T13:26:16Z</updated>
    <published>2019-01-14T13:25:49Z</published>
    <title>Faster arbitrary-precision dot product and matrix multiplication</title>
    <summary>  We present algorithms for real and complex dot product and matrix
multiplication in arbitrary-precision floating-point and ball arithmetic. A
low-overhead dot product is implemented on the level of GMP limb arrays; it is
about twice as fast as previous code in MPFR and Arb at precision up to several
hundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per
term for floating-point evaluation and 40-50 cycles per term for balls. We
handle large matrix multiplications even more efficiently via blocks of scaled
integer matrices. The new methods are implemented in Arb and significantly
speed up polynomial operations and linear algebra.
</summary>
    <author>
      <name>Fredrik Johansson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LFANT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">26th IEEE Symposium on Computer Arithmetic (ARITH26), Jun 2019,
  Kyoto, Japan</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.04289v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04289v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.09699v2</id>
    <updated>2019-03-07T09:11:03Z</updated>
    <published>2019-02-26T01:52:07Z</published>
    <title>Algorithms and software for projections onto intersections of convex and
  non-convex sets with applications to inverse problems</title>
    <summary>  We propose algorithms and software for computing projections onto the
intersection of multiple convex and non-convex constraint sets. The software
package, called SetIntersectionProjection, is intended for the regularization
of inverse problems in physical parameter estimation and image processing. The
primary design criterion is working with multiple sets, which allows us to
solve inverse problems with multiple pieces of prior knowledge. Our algorithms
outperform the well known Dykstra's algorithm when individual sets are not easy
to project onto because we exploit similarities between constraint sets. Other
design choices that make the software fast and practical to use, include
recently developed automatic selection methods for auxiliary algorithm
parameters, fine and coarse grained parallelism, and a multilevel acceleration
scheme. We provide implementation details and examples that show how the
software can be used to regularize inverse problems. Results show that we
benefit from working with all available prior information and are not limited
to one or two regularizers because of algorithmic, computational, or
hyper-parameter selection issues.
</summary>
    <author>
      <name>Bas Peters</name>
    </author>
    <author>
      <name>Felix J. Herrmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1902.09699v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.09699v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 86A22, 90C06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.02153v3</id>
    <updated>2021-04-27T17:12:22Z</updated>
    <published>2019-03-06T03:33:18Z</published>
    <title>PBBFMM3D: a parallel black-box algorithm for kernel matrix-vector
  multiplication</title>
    <summary>  Kernel matrix-vector product is ubiquitous in many science and engineering
applications. However, a naive method requires $O(N^2)$ operations, which
becomes prohibitive for large-scale problems. We introduce a parallel method
that provably requires $O(N)$ operations to reduce the computation cost. The
distinct feature of our method is that it requires only the ability to evaluate
the kernel function, offering a black-box interface to users. Our parallel
approach targets multi-core shared-memory machines and is implemented using
OpenMP. Numerical results demonstrate up to $19\times$ speedup on 32 cores. We
also present a real-world application in geostatistics, where our parallel
method was used to deliver fast principle component analysis of covariance
matrices.
</summary>
    <author>
      <name>Ruoxi Wang</name>
    </author>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Jonghyun Lee</name>
    </author>
    <author>
      <name>Eric Darve</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jpdc.2021.04.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jpdc.2021.04.005" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Parallel and Distributed Computing Volume 154, August
  2021, Pages 64-73</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1903.02153v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.02153v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.05567v1</id>
    <updated>2019-03-13T16:09:08Z</updated>
    <published>2019-03-13T16:09:08Z</published>
    <title>GNA: new framework for statistical data analysis</title>
    <summary>  We report on the status of GNA --- a new framework for fitting large-scale
physical models. GNA utilizes the data flow concept within which a model is
represented by a directed acyclic graph. Each node is an operation on an array
(matrix multiplication, derivative or cross section calculation, etc). The
framework enables the user to create flexible and efficient large-scale lazily
evaluated models, handle large numbers of parameters, propagate parameters'
uncertainties while taking into account possible correlations between them, fit
models, and perform statistical analysis. The main goal of the paper is to give
an overview of the main concepts and methods as well as reasons behind their
design. Detailed technical information is to be published in further works.
</summary>
    <author>
      <name>Anna Fatkina</name>
    </author>
    <author>
      <name>Maxim Gonchar</name>
    </author>
    <author>
      <name>Anastasia Kalitkina</name>
    </author>
    <author>
      <name>Liudmila Kolupaeva</name>
    </author>
    <author>
      <name>Dmitry Naumov</name>
    </author>
    <author>
      <name>Dmitry Selivanov</name>
    </author>
    <author>
      <name>Konstantin Treskov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/epjconf/201921405024</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/epjconf/201921405024" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, CHEP 2018, submitted to EPJ Web of Conferences</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.05567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.05567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.05575v1</id>
    <updated>2019-03-13T16:19:27Z</updated>
    <published>2019-03-13T16:19:27Z</published>
    <title>On the Efficacy and High-Performance Implementation of Quaternion Matrix
  Multiplication</title>
    <summary>  Quaternion symmetry is ubiquitous in the physical sciences. As such, much
work has been afforded over the years to the development of efficient schemes
to exploit this symmetry using real and complex linear algebra. Recent years
have also seen many advances in the formal theoretical development of
explicitly quaternion linear algebra with promising applications in image
processing and machine learning. Despite these advances, there do not currently
exist optimized software implementations of quaternion linear algebra. The
leverage of optimized linear algebra software is crucial in the achievement of
high levels of performance on modern computing architectures, and thus provides
a central tool in the development of high-performance scientific software. In
this work, a case will be made for the efficacy of high-performance quaternion
linear algebra software for appropriate problems. In this pursuit, an optimized
software implementation of quaternion matrix multiplication will be presented
and will be shown to outperform a vendor tuned implementation for the analogous
complex matrix operation. The results of this work pave the path for further
development of high-performance quaternion linear algebra software which will
improve the performance of the next generation of applicable scientific
applications.
</summary>
    <author>
      <name>David Williams-Young</name>
    </author>
    <author>
      <name>Xiaosong Li</name>
    </author>
    <link href="http://arxiv.org/abs/1903.05575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.05575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08243v2</id>
    <updated>2020-05-19T14:23:13Z</updated>
    <published>2019-03-19T20:15:03Z</published>
    <title>A study of vectorization for matrix-free finite element methods</title>
    <summary>  Vectorization is increasingly important to achieve high performance on modern
hardware with SIMD instructions. Assembly of matrices and vectors in the finite
element method, which is characterized by iterating a local assembly kernel
over unstructured meshes, poses difficulties to effective vectorization.
Maintaining a user-friendly high-level interface with a suitable degree of
abstraction while generating efficient, vectorized code for the finite element
method is a challenge for numerical software systems and libraries. In this
work, we study cross-element vectorization in the finite element framework
Firedrake via code transformation and demonstrate the efficacy of such an
approach by evaluating a wide range of matrix-free operators spanning different
polynomial degrees and discretizations on two recent CPUs using three
mainstream compilers. Our experiments show that our approaches for
cross-element vectorization achieve 30\% of theoretical peak performance for
many examples of practical significance, and exceed 50\% for cases with high
arithmetic intensities, with consistent speed-up over (intra-element)
vectorization restricted to the local assembly kernels.
</summary>
    <author>
      <name>Tianjiao Sun</name>
    </author>
    <author>
      <name>Lawrence Mitchell</name>
    </author>
    <author>
      <name>Kaushik Kulkarni</name>
    </author>
    <author>
      <name>Andreas Klöckner</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <author>
      <name>Paul H. J. Kelly</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1177/1094342020945005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1177/1094342020945005" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of High Performance Computing Applications
  (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1903.08243v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08243v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.11521v1</id>
    <updated>2019-03-27T16:17:01Z</updated>
    <published>2019-03-27T16:17:01Z</published>
    <title>Yet Another Tensor Toolbox for discontinuous Galerkin methods and other
  applications</title>
    <summary>  The numerical solution of partial differential equations is at the heart of
many grand challenges in supercomputing. Solvers based on high-order
discontinuous Galerkin (DG) discretisation have been shown to scale on large
supercomputers with excellent performance and efficiency, if the implementation
exploits all levels of parallelism and is tailored to the specific
architecture. However, every year new supercomputers emerge and the list of
hardware-specific considerations grows, simultaneously with the list of desired
features in a DG code. Thus we believe that a sustainable DG code needs an
abstraction layer to implement the numerical scheme in a suitable language. We
explore the possibility to abstract the numerical scheme as small tensor
operations, describe them in a domain-specific language (DSL) resembling the
Einstein notation, and to map them to existing code generators which generate
small matrix matrix multiplication routines. The compiler for our DSL
implements classic optimisations that are used for large tensor contractions,
and we present novel optimisation techniques such as equivalent sparsity
patterns and optimal index permutations for temporary tensors. Our application
examples, which include the earthquake simulation software SeisSol, show that
the generated kernels achieve over 50 % peak performance while the DSL
considerably simplifies the implementation.
</summary>
    <author>
      <name>Carsten Uphoff</name>
    </author>
    <author>
      <name>Michael Bader</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3406835</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3406835" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM TOMS</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.11521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.11521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.12482v2</id>
    <updated>2019-07-04T06:47:49Z</updated>
    <published>2019-03-29T12:40:01Z</published>
    <title>COFFEE -- An MPI-parallelized Python package for the numerical evolution
  of differential equations</title>
    <summary>  COFFEE (ConFormal Field Equation Evolver) is a Python package primarily
developed to numerically evolve systems of partial differential equations over
time using the method of lines. It includes a variety of time integrators and
finite differencing stencils with the summation-by-parts property, as well as
pseudo-spectral functionality for angular derivatives of spin-weighted
functions. Some additional capabilities include being MPI-parallelisable on a
variety of different geometries, HDF data output and post processing scripts to
visualize data, and an actions class that allows users to create code for
analysis after each timestep.
</summary>
    <author>
      <name>Georgios Doulis</name>
    </author>
    <author>
      <name>Jörg Frauendiener</name>
    </author>
    <author>
      <name>Chris Stevens</name>
    </author>
    <author>
      <name>Ben Whale</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2019.100283</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2019.100283" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure, accepted to be published in SoftwareX</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SoftwareX 10, 100283 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1903.12482v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.12482v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05717v1</id>
    <updated>2019-04-11T14:25:27Z</updated>
    <published>2019-04-11T14:25:27Z</published>
    <title>The MOMMS Family of Matrix Multiplication Algorithms</title>
    <summary>  As the ratio between the rate of computation and rate with which data can be
retrieved from various layers of memory continues to deteriorate, a question
arises: Will the current best algorithms for computing matrix-matrix
multiplication on future CPUs continue to be (near) optimal? This paper
provides compelling analytical and empirical evidence that the answer is "no".
The analytical results guide us to a new family of algorithms of which the
current state-of-the-art "Goto's algorithm" is but one member. The empirical
results, on architectures that were custom built to reduce the amount of
bandwidth to main memory, show that under different circumstances, different
and particular members of the family become more superior. Thus, this family
will likely start playing a prominent role going forward.
</summary>
    <author>
      <name>Tyler M. Smith</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <link href="http://arxiv.org/abs/1904.05717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10405v2</id>
    <updated>2019-10-22T05:02:06Z</updated>
    <published>2019-04-23T16:15:52Z</published>
    <title>Big Math and the One-Brain Barrier A Position Paper and Architecture
  Proposal</title>
    <summary>  Over the last decades, a class of important mathematical results have
required an ever increasing amount of human effort to carry out. For some, the
help of computers is now indispensable. We analyze the implications of this
trend towards "big mathematics", its relation to human cognition, and how
machine support for big math can be organized. The central contribution of this
position paper is an information model for "doing mathematics", which posits
that humans very efficiently integrate four aspects: inference, computation,
tabulation, and narration around a well-organized core of mathematical
knowledge. The challenge for mathematical software systems is that these four
aspects need to be integrated as well. We briefly survey the state of the art.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <author>
      <name>William M. Farmer</name>
    </author>
    <author>
      <name>Michael Kohlhase</name>
    </author>
    <author>
      <name>Florian Rabe</name>
    </author>
    <link href="http://arxiv.org/abs/1904.10405v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10405v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.03136v2</id>
    <updated>2020-02-18T15:54:31Z</updated>
    <published>2019-05-08T15:11:46Z</published>
    <title>Performance Engineering for Real and Complex Tall &amp; Skinny Matrix
  Multiplication Kernels on GPUs</title>
    <summary>  General matrix-matrix multiplications with double-precision real and complex
entries (DGEMM and ZGEMM) in vendor-supplied BLAS libraries are best optimized
for square matrices but often show bad performance for tall &amp; skinny matrices,
which are much taller than wide. NVIDIA's current CUBLAS implementation
delivers only a fraction of the potential performance as indicated by the
roofline model in this case. We describe the challenges and key characteristics
of an implementation that can achieve close to optimal performance. We further
evaluate different strategies of parallelization and thread distribution, and
devise a flexible, configurable mapping scheme. To ensure flexibility and allow
for highly tailored implementations we use code generation combined with
autotuning. For a large range of matrix sizes in the domain of interest we
achieve at least 2/3 of the roofline performance and often substantially
outperform state-of-the art CUBLAS results on an NVIDIA Volta GPGPU.
</summary>
    <author>
      <name>Dominik Ernst</name>
    </author>
    <author>
      <name>Georg Hager</name>
    </author>
    <author>
      <name>Jonas Thies</name>
    </author>
    <author>
      <name>Gerhard Wellein</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-43229-4_43</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-43229-4_43" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 22 figures. Extended version of arXiv:1905.03136v1 for
  journal submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.03136v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.03136v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10206v1</id>
    <updated>2019-05-24T12:52:05Z</updated>
    <published>2019-05-24T12:52:05Z</published>
    <title>Landau: language for dynamical systems with automatic differentiation</title>
    <summary>  Most numerical solvers used to determine free variables of dynamical systems
rely on first-order derivatives of the state of the system w.r.t. the free
variables. The number of the free variables can be fairly large. One of the
approaches of obtaining those derivatives is the integration of the derivatives
simultaneously with the dynamical equations, which is best done with the
automatic differentiation technique. Even though there exist many automatic
differentiation tools, none have been found to be scalable and usable for
practical purposes of dynamic systems modeling. Landau is a Turing incomplete
statically typed domain-specific language aimed to fill this gap. The Turing
incompleteness provides the ability of sophisticated source code analysis and,
as a result, a highly optimized compiled code. Among other things, the language
syntax supports functions, compile-time ranged for loops, if/else branching
constructions, real variables and arrays, and the ability to manually discard
calculation where the automatic derivatives values are expected to be
negligibly small. In spite of reasonable restrictions, the language is rich
enough to express and differentiate any cumbersome paper-equation with
practically no effort.
</summary>
    <author>
      <name>Ivan Dolgakov</name>
    </author>
    <author>
      <name>Dmitry Pavlov</name>
    </author>
    <link href="http://arxiv.org/abs/1905.10206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.10574v1</id>
    <updated>2019-05-25T11:31:17Z</updated>
    <published>2019-05-25T11:31:17Z</published>
    <title>Robust Task-Parallel Solution of the Triangular Sylvester Equation</title>
    <summary>  The Bartels-Stewart algorithm is a standard approach to solving the dense
Sylvester equation. It reduces the problem to the solution of the triangular
Sylvester equation. The triangular Sylvester equation is solved with a variant
of backward substitution. Backward substitution is prone to overflow. Overflow
can be avoided by dynamic scaling of the solution matrix. An algorithm which
prevents overflow is said to be robust. The standard library LAPACK contains
the robust scalar sequential solver dtrsyl. This paper derives a robust,
level-3 BLAS-based task-parallel solver. By adding overflow protection, our
robust solver closes the gap between problems solvable by LAPACK and problems
solvable by existing non-robust task-parallel solvers. We demonstrate that our
robust solver achieves a similar performance as non-robust solvers.
</summary>
    <author>
      <name>Angelika Schwarz</name>
    </author>
    <author>
      <name>Carl Christian Kjelgaard Mikkelsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.10574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.10574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00096v1</id>
    <updated>2019-06-28T22:19:04Z</updated>
    <published>2019-06-28T22:19:04Z</published>
    <title>Solving Polynomial Systems with phcpy</title>
    <summary>  The solutions of a system of polynomials in several variables are often
needed, e.g.: in the design of mechanical systems, and in phase-space analyses
of nonlinear biological dynamics. Reliable, accurate, and comprehensive
numerical solutions are available through PHCpack, a FOSS package for solving
polynomial systems with homotopy continuation. This paper explores new
developments in phcpy, a scripting interface for PHCpack, over the past five
years. For instance, phcpy is now available online through a JupyterHub server
featuring Python2, Python3, and SageMath kernels. As small systems are solved
in real-time by phcpy, they are suitable for interactive exploration through
the notebook interface. Meanwhile, phcpy supports GPU parallelization,
improving the speed and quality of solutions to much larger polynomial systems.
From various model design and analysis problems in STEM, certain classes of
polynomial system frequently arise, to which phcpy is well-suited.
</summary>
    <author>
      <name>Jasmine Otto</name>
    </author>
    <author>
      <name>Angus Forbes</name>
    </author>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the SciPy 2019 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.00096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.06470v1</id>
    <updated>2019-07-15T12:41:47Z</updated>
    <published>2019-07-15T12:41:47Z</published>
    <title>Out-of-core singular value decomposition</title>
    <summary>  Singular value decomposition (SVD) is a standard matrix factorization
technique that produces optimal low-rank approximations of matrices. It has
diverse applications, including machine learning, data science and signal
processing. However, many common problems involve very large matrices that
cannot fit in the main memory of commodity computers, making it impractical to
use standard SVD algorithms that assume fast random access or large amounts of
space for intermediate calculations. To address this issue, we have implemented
an out-of-core (external memory) randomized SVD solution that is fully scalable
and efficiently parallelizable. This solution factors both dense and sparse
matrices of arbitrarily large size within arbitrarily small memory limits,
efficiently using out-of-core storage as needed. It uses an innovative
technique for partitioning matrices that lends itself to out-of-core and
parallel processing, as well as memory and I/O use planning, automatic load
balancing, performance tuning, and makes possible a number of other practical
enhancements to the current state-of-the-art. Furthermore, by using persistent
external storage (generally HDDs or SSDs), users can resume interrupted
operations without having to recalculate previously performed steps, solving a
major practical problem in factoring very large matrices.
</summary>
    <author>
      <name>Vadim Demchik</name>
    </author>
    <author>
      <name>Miroslav Bačák</name>
    </author>
    <author>
      <name>Stefan Bordag</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.06470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12349v1</id>
    <updated>2019-07-29T11:53:46Z</updated>
    <published>2019-07-29T11:53:46Z</published>
    <title>PyLops -- A Linear-Operator Python Library for large scale optimization</title>
    <summary>  Linear operators and optimisation are at the core of many algorithms used in
signal and image processing, remote sensing, and inverse problems. For small to
medium-scale problems, existing software packages (e.g., MATLAB, Python numpy
and scipy) allow for explicitly building dense (or sparse) matrices and
performing algebraic operations (e.g., computation of matrix-vector products
and manipulation of matrices) with syntax that closely represents their
corresponding analytical forms. However, many real application, large-scale
operators do not lend themselves to explicit matrix representations, usually
forcing practitioners to forego of the convenient linear-algebra syntax
available for their explicit-matrix counterparts. PyLops is an open-source
Python library providing a flexible and scalable framework for the creation and
combination of so-called linear operators, class-based entities that represent
matrices and inherit their associated syntax convenience, but do not rely on
the creation of explicit matrices. We show that PyLops operators can
dramatically reduce the memory load and CPU computations compared to
explicit-matrix calculations, while still allowing users to seamlessly use
their existing knowledge of compact matrix-based syntax that scales to any
problem size because no explicit matrices are required.
</summary>
    <author>
      <name>Matteo Ravasi</name>
    </author>
    <author>
      <name>Ivan Vasconcelos</name>
    </author>
    <link href="http://arxiv.org/abs/1907.12349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.13419v2</id>
    <updated>2020-04-23T15:46:33Z</updated>
    <published>2019-07-31T11:18:54Z</published>
    <title>Characteristics-based Simulink implementation of first-order quasilinear
  partial differential equations</title>
    <summary>  The paper deals with solving first-order quasilinear partial differential
equations in an online simulation environment, such as Simulink, utilizing the
well-known and well-recommended method of characteristics. Compared to the
commonly applied space discretization methods on static grids, the
characteristics-based approach provides better numerical stability. Simulink
subsystem implementing the method of characteristics is developed. It employs
Simulink's built-in solver and its zero-crossing detection algorithm to perform
simultaneous integration of a pool of characteristics as well as to create new
characteristics dynamically and discard the old ones. Numerical accuracy of the
solution thus obtained is established. The subsystem has been tested on a
full-state feedback example and produced better results than the space
discretization-based "method of lines". The implementation is available for
download and can be used in a wide range of models.
</summary>
    <author>
      <name>Anton Ponomarev</name>
    </author>
    <author>
      <name>Julian Hofmann</name>
    </author>
    <author>
      <name>Lutz Gröll</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5220/0009569001390146</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5220/0009569001390146" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Abridged and updated conference version. Accepted to SIMULTECH 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.13419v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.13419v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04009v1</id>
    <updated>2019-08-12T05:46:21Z</updated>
    <published>2019-08-12T05:46:21Z</published>
    <title>Open Traffic Models -- A framework for hybrid simulation of
  transportation networks</title>
    <summary>  This paper introduces a new approach to hybrid traffic modeling, along with
its implementation in software. The software allows modelers to assign traffic
models to individual links in a network. Each model implements a series of
methods, refered to as the modeling interface. These methods are used by the
program to exchange information between adjacent models. Traffic controllers
are implemented in a similar manner. The paper outlines the important
components of the method: the network description, the description of demands,
and the modeling and control interfaces. We include tests demonstrating the
propagation of congestion between pairs of macroscpoic, mesoscopic, and
microscopic models. Open Traffic Models is an open source implementation of
these concepts, and is available at https://github.com/ggomes/otm-sim.
</summary>
    <author>
      <name>Gabriel Gomes</name>
    </author>
    <link href="http://arxiv.org/abs/1908.04009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.01412v2</id>
    <updated>2020-04-22T12:19:57Z</updated>
    <published>2019-10-03T11:42:32Z</published>
    <title>A user-guide to Gridap -- grid-based approximation of partial
  differential equations in Julia</title>
    <summary>  We present Gridap, a new scientific software library for the numerical
approximation of partial differential equations (PDEs) using grid-based
approximations. Gridap is an open-source software project exclusively written
in the Julia programming language. The main motivation behind the development
of this library is to provide an easy-to-use framework for the development of
complex PDE solvers in a dynamically typed style without sacrificing the
performance of statically typed languages. This work is a tutorial-driven user
guide to the library. It covers some popular linear and nonlinear PDE systems
for scalar and vector fields, single and multi-field problems, conforming and
nonconforming finite element discretizations, on structured and unstructured
meshes of simplices and hexahedra.
</summary>
    <author>
      <name>Francesc Verdugo</name>
    </author>
    <author>
      <name>Santiago Badia</name>
    </author>
    <link href="http://arxiv.org/abs/1910.01412v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.01412v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.01972v2</id>
    <updated>2020-04-10T15:04:13Z</updated>
    <published>2019-10-04T14:41:10Z</published>
    <title>GPU Fast Convolution via the Overlap-and-Save Method in Shared Memory</title>
    <summary>  We present an implementation of the overlap-and-save method, a method for the
convolution of very long signals with short response functions, which is
tailored to GPUs. We have implemented several FFT algorithms (using the CUDA
programming language) which exploit GPU shared memory, allowing for GPU
accelerated convolution. We compare our implementation with an implementation
of the overlap-and-save algorithm utilizing the NVIDIA FFT library (cuFFT). We
demonstrate that by using a shared memory based FFT we can achieved significant
speed-ups for certain problem sizes and lower the memory requirements of the
overlap-and-save method on GPUs.
</summary>
    <author>
      <name>Karel Adámek</name>
    </author>
    <author>
      <name>Sofia Dimoudi</name>
    </author>
    <author>
      <name>Mike Giles</name>
    </author>
    <author>
      <name>Wesley Armour</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3394116</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3394116" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted to ACM TACO</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Archit. Code Optim. 17, 3, Article 18 (September 2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.01972v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.01972v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.05623v1</id>
    <updated>2019-10-12T18:43:25Z</updated>
    <published>2019-10-12T18:43:25Z</published>
    <title>New robust ScaLAPACK routine for computing the QR factorization with
  column pivoting</title>
    <summary>  In this note we describe two modifications of the ScaLAPACK subroutines
PxGEQPF for computing the QR factorization with the Businger-Golub column
pivoting. First, we resolve a subtle numerical instability in the same way as
we have done it for the LAPACK subroutines xGEQPF, xGEQP3 in 2006. [LAPACK
Working Note 176 (2006); ACM Trans. Math. Softw. 2008]. The problem originates
in the first release of LINPACK in the 1970's: due to severe cancellations in
the down-dating of partial column norms, the pivoting procedure may be in the
dark completely about the true norms of the pivot column candidates. This may
cause miss-pivoting, and as a result loss of the important rank revealing
structure of the computed triangular factor, with severe consequences on other
solvers that rely on the rank revealing pivoting. The instability is so subtle
that, e.g., inserting a WRITE statement or changing the process topology can
drastically change the result. Secondly, we also correct a programming error in
the complex subroutines PCGEQPF, PZGEQPF, which also causes wrong pivoting
because of erroneous use of PSCNRM2, PDZNRM2 for the explicit norm computation.
</summary>
    <author>
      <name>Zvonimir Bujanović</name>
    </author>
    <author>
      <name>Zlatko Drmač</name>
    </author>
    <link href="http://arxiv.org/abs/1910.05623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.05623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.06117v1</id>
    <updated>2019-10-14T12:59:45Z</updated>
    <published>2019-10-14T12:59:45Z</published>
    <title>Some remarks on the performance of Matlab, Python and Octave in
  simulating dynamical systems</title>
    <summary>  Matlab has been considered as a leader computational platform for many
engineering fields. Well documented and reliable, Matlab presents as a great
advantage its ability to increase the user productivity. However, Python and
Octave are among some of the languages that have challenged Matlab. Octave and
Python are well known examples of high-level scripting languages, with a great
advantage of being open source software. The novelty of this paper is devoted
to offer a comparison among these tree languages in the simulation of dynamical
systems. We have applied the lower bound error to estimate the error of
simulation. The comparison was performed with the chaotic systems Duffing-Ueda
oscillator and the Chua's circuit, both identified with polynomial NARMAX.
Octave presents the best reliable outcome. Nevertheless, Matlab needs the
lowest time to undertake the same activity. Python has presented the worse
result for the stop simulation criterion.
</summary>
    <author>
      <name>P. F. S. Guedes</name>
    </author>
    <author>
      <name>E. G. Nepomuceno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.11712v3</id>
    <updated>2021-01-15T16:46:13Z</updated>
    <published>2019-10-25T13:28:04Z</published>
    <title>NEP: a module for the parallel solution of nonlinear eigenvalue problems
  in SLEPc</title>
    <summary>  SLEPc is a parallel library for the solution of various types of large-scale
eigenvalue problems. In the last years we have been developing a module within
SLEPc, called NEP, that is intended for solving nonlinear eigenvalue problems.
These problems can be defined by means of a matrix-valued function that depends
nonlinearly on a single scalar parameter. We do not consider the particular
case of polynomial eigenvalue problems (which are implemented in a different
module in SLEPc) and focus here on rational eigenvalue problems and other
general nonlinear eigenproblems involving square roots or any other nonlinear
function. The paper discusses how the NEP module has been designed to fit the
needs of applications and provides a description of the available solvers,
including some implementation details such as parallelization. Several test
problems coming from real applications are used to evaluate the performance and
reliability of the solvers.
</summary>
    <author>
      <name>Carmen Campos</name>
    </author>
    <author>
      <name>Jose E. Roman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3447544</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3447544" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Math. Software, 47(3), Article 23, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.11712v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11712v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.13247v2</id>
    <updated>2020-02-17T11:06:13Z</updated>
    <published>2019-10-24T13:40:13Z</published>
    <title>The deal.II finite element library: design, features, and insights</title>
    <summary>  deal.II is a state-of-the-art finite element library focused on generality,
dimension-independent programming, parallelism, and extensibility. Herein, we
outline its primary design considerations and its sophisticated features such
as distributed meshes, $hp$-adaptivity, support for complex geometries, and
matrix-free algorithms. But deal.II is more than just a software library: It is
also a diverse and worldwide community of developers and users, as well as an
educational platform. We therefore also discuss some of the technical and
social challenges and lessons learned in running a large community software
project over the course of two decades.
</summary>
    <author>
      <name>Daniel Arndt</name>
    </author>
    <author>
      <name>Wolfgang Bangerth</name>
    </author>
    <author>
      <name>Denis Davydov</name>
    </author>
    <author>
      <name>Timo Heister</name>
    </author>
    <author>
      <name>Luca Heltai</name>
    </author>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <author>
      <name>Matthias Maier</name>
    </author>
    <author>
      <name>Jean-Paul Pelteret</name>
    </author>
    <author>
      <name>Bruno Turcksin</name>
    </author>
    <author>
      <name>David Wells</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2020.02.022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2020.02.022" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers {\&amp;} Mathematics with Applications, 81: 407--422, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.13247v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13247v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.00093v1</id>
    <updated>2019-10-30T04:07:52Z</updated>
    <published>2019-10-30T04:07:52Z</published>
    <title>Effect of Mixed Precision Computing on H-Matrix Vector Multiplication in
  BEM Analysis</title>
    <summary>  Hierarchical Matrix (H-matrix) is an approximation technique which splits a
target dense matrix into multiple submatrices, and where a selected portion of
submatrices are low-rank approximated. The technique substantially reduces both
time and space complexity of dense matrix vector multiplication, and hence has
been applied to numerous practical problems.
  In this paper, we aim to accelerate the H-matrix vector multiplication by
introducing mixed precision computing, where we employ both binary64 (FP64) and
binary32 (FP32) arithmetic operations. We propose three methods to introduce
mixed precision computing to H-matrix vector multiplication, and then evaluate
them in a boundary element method (BEM) analysis. The numerical tests examine
the effects of mixed precision computing, particularly on the required
simulation time and rate of convergence of the iterative (BiCG-STAB) linear
solver. We confirm the effectiveness of the proposed methods.
</summary>
    <author>
      <name>Rise Ooi</name>
    </author>
    <author>
      <name>Takeshi Iwashita</name>
    </author>
    <author>
      <name>Takeshi Fukaya</name>
    </author>
    <author>
      <name>Akihiro Ida</name>
    </author>
    <author>
      <name>Rio Yokota</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3368474.3368479</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3368474.3368479" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted manuscript to International Conference on High Performance
  Computing in Asia-Pacific Region (HPCAsia2020), January 15--17, 2020,
  Fukuoka, Japan</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.01166v1</id>
    <updated>2019-11-04T12:42:42Z</updated>
    <published>2019-11-04T12:42:42Z</published>
    <title>Abstractions and automated algorithms for mixed domain finite element
  methods</title>
    <summary>  Mixed dimensional partial differential equations (PDEs) are equations
coupling unknown fields defined over domains of differing topological
dimension. Such equations naturally arise in a wide range of scientific fields
including geology, physiology, biology and fracture mechanics. Mixed
dimensional PDEs are also commonly encountered when imposing non-standard
conditions over a subspace of lower dimension e.g. through a Lagrange
multiplier. In this paper, we present general abstractions and algorithms for
finite element discretizations of mixed domain and mixed dimensional PDEs of
co-dimension up to one (i.e. nD-mD with |n-m| &lt;= 1). We introduce high level
mathematical software abstractions together with lower level algorithms for
expressing and efficiently solving such coupled systems. The concepts
introduced here have also been implemented in the context of the FEniCS finite
element software. We illustrate the new features through a range of examples,
including a constrained Poisson problem, a set of Stokes-type flow models and a
model for ionic electrodiffusion.
</summary>
    <author>
      <name>Cécile Daversin-Catty</name>
    </author>
    <author>
      <name>Chris N. Richardson</name>
    </author>
    <author>
      <name>Ada J. Ellingsrud</name>
    </author>
    <author>
      <name>Marie E. Rognes</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.06055v5</id>
    <updated>2020-07-17T14:11:37Z</updated>
    <published>2019-11-14T12:09:31Z</published>
    <title>The RaPID-OMEGA system: Room and Proctor Intelligent Decider for large
  scale tests programming</title>
    <summary>  We present the mathematical modeling for the problem of choosing rooms and
proctoring crews for massive tests, together with its implementation as the
open-box system RaPID-Omega. The mathematical model is a binary integer
programming problem: a combination of the 0-1 Knapsack problem and the
job-assignment problem. The model makes decisions according the following
criteria in order of priority: minimization of labor-hours, maximization of
equity in the distribution of duties and maximization of the proctoring
quality. The software is a digital solution for the aforementioned problem,
which is a common need in educational institutions offering large, coordinated,
lower-division courses. The system can be downloaded from
\url{https://sites.google.com/a/unal.edu.co/fernando-a-morales-j/home/research/software}
</summary>
    <author>
      <name>Fernando A. Morales</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2298/YJOR191115019M</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2298/YJOR191115019M" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 12 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Yugolav Journal of Operations Research, 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.06055v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06055v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C10, 90B80, 68N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07531v1</id>
    <updated>2019-11-18T10:36:43Z</updated>
    <published>2019-11-18T10:36:43Z</published>
    <title>Semi-Automatic Task Graph Construction for $\mathcal{H}$-Matrix
  Arithmetic</title>
    <summary>  A new method to construct task graphs for \mcH-matrix arithmetic is
introduced, which uses the information associated with all tasks of the
standard recursive \mcH-matrix algorithms, e.g., the block index set of the
matrix blocks involved in the computation. Task refinement, i.e., the
replacement of tasks by sub-computations, is then used to proceed in the
\mcH-matrix hierarchy until the matrix blocks containing the actual matrix data
are reached. This process is a natural extension of the classical, recursive
way in which \mcH-matrix arithmetic is defined and thereby simplifies the
efficient usage of many-core systems. Examples for standard and accumulator
based \mcH-arithmetic are shown for model problems with different block
structures.
</summary>
    <author>
      <name>Steffen Börm</name>
    </author>
    <author>
      <name>Sven Christophersen</name>
    </author>
    <author>
      <name>Ronald Kriemann</name>
    </author>
    <link href="http://arxiv.org/abs/1911.07531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F05, 65Y05, 65Y20, 68W10, 68W40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09220v2</id>
    <updated>2020-07-13T18:16:51Z</updated>
    <published>2019-11-20T23:49:09Z</published>
    <title>MFEM: a modular finite element methods library</title>
    <summary>  MFEM is an open-source, lightweight, flexible and scalable C++ library for
modular finite element methods that features arbitrary high-order finite
element meshes and spaces, support for a wide variety of discretization
approaches and emphasis on usability, portability, and high-performance
computing efficiency. MFEM's goal is to provide application scientists with
access to cutting-edge algorithms for high-order finite element meshing,
discretizations and linear solvers, while enabling researchers to quickly and
easily develop and test new algorithms in very general, fully unstructured,
high-order, parallel and GPU-accelerated settings. In this paper we describe
the underlying algorithms and finite element abstractions provided by MFEM,
discuss the software implementation, and illustrate various applications of the
library.
</summary>
    <author>
      <name>Robert Anderson</name>
    </author>
    <author>
      <name>Julian Andrej</name>
    </author>
    <author>
      <name>Andrew Barker</name>
    </author>
    <author>
      <name>Jamie Bramwell</name>
    </author>
    <author>
      <name>Jean-Sylvain Camier</name>
    </author>
    <author>
      <name>Jakub Cerveny</name>
    </author>
    <author>
      <name>Veselin Dobrev</name>
    </author>
    <author>
      <name>Yohann Dudouit</name>
    </author>
    <author>
      <name>Aaron Fisher</name>
    </author>
    <author>
      <name>Tzanio Kolev</name>
    </author>
    <author>
      <name>Will Pazner</name>
    </author>
    <author>
      <name>Mark Stowell</name>
    </author>
    <author>
      <name>Vladimir Tomov</name>
    </author>
    <author>
      <name>Johann Dahm</name>
    </author>
    <author>
      <name>David Medina</name>
    </author>
    <author>
      <name>Stefano Zampini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2020.06.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2020.06.009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09220v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09220v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.12604v2</id>
    <updated>2020-06-22T12:42:13Z</updated>
    <published>2019-11-28T09:07:08Z</published>
    <title>Eigen-AD: Algorithmic Differentiation of the Eigen Library</title>
    <summary>  In this work we present useful techniques and possible enhancements when
applying an Algorithmic Differentiation (AD) tool to the linear algebra library
Eigen using our in-house AD by overloading (AD-O) tool dco/c++ as a case study.
After outlining performance and feasibility issues when calculating derivatives
for the official Eigen release, we propose Eigen-AD, which enables different
optimization options for an AD-O tool by providing add-on modules for Eigen.
The range of features includes a better handling of expression templates for
general performance improvements, as well as implementations of symbolically
derived expressions for calculating derivatives of certain core operations. The
software design allows an AD-O tool to provide specializations to automatically
include symbolic operations and thereby keep the look and feel of plain AD by
overloading. As a showcase, dco/c++ is provided with such a module and its
significant performance improvements are validated by benchmarks.
</summary>
    <author>
      <name>Patrick Peltzer</name>
    </author>
    <author>
      <name>Johannes Lotz</name>
    </author>
    <author>
      <name>Uwe Naumann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-50371-0_51</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-50371-0_51" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Updated with accepted version for ICCS 2020 conference proceedings.
  The final authenticated publication is available online at
  https://doi.org/10.1007/978-3-030-50371-0_51. See v1 for the original,
  extended preprint. 14 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Science - ICCS 2020: 20th International Conference,
  Amsterdam, The Netherlands, June 3-5, 2020, Proceedings, Part I, 12137,
  690-704</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.12604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00702v1</id>
    <updated>2019-12-02T12:00:03Z</updated>
    <published>2019-12-02T12:00:03Z</published>
    <title>PFASST-ER: Combining the Parallel Full Approximation Scheme in Space and
  Time with parallelization across the method</title>
    <summary>  To extend prevailing scaling limits when solving time-dependent partial
differential equations, the parallel full approximation scheme in space and
time (PFASST) has been shown to be a promising parallel-in-time integrator.
Similar to a space-time multigrid, PFASST is able to compute multiple
time-steps simultaneously and is therefore in particular suitable for
large-scale applications on high performance computing systems. In this work we
couple PFASST with a parallel spectral deferred correction (SDC) method,
forming an unprecedented doubly time-parallel integrator. While PFASST provides
global, large-scale "parallelization across the step", the inner parallel SDC
method allows to integrate each individual time-step "parallel across the
method" using a diagonalized local Quasi-Newton solver. This new method, which
we call "PFASST with Enhanced concuRrency" (PFASST-ER), therefore exposes even
more temporal parallelism. For two challenging nonlinear reaction-diffusion
problems, we show that PFASST-ER works more efficiently than the classical
variants of PFASST and can be used to run parallel-in-time beyond the number of
time-steps.
</summary>
    <author>
      <name>Ruth Schöbel</name>
    </author>
    <author>
      <name>Robert Speck</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 12 figures, CVS PinT Workshop Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05303v1</id>
    <updated>2019-12-03T21:22:29Z</updated>
    <published>2019-12-03T21:22:29Z</published>
    <title>differint: A Python Package for Numerical Fractional Calculus</title>
    <summary>  Fractional calculus has become widely studied and applied to physical
problems in recent years. As a result, many methods for the numerical
computation of fractional derivatives and integrals have been defined. However,
these algorithms are often programmed in an ad hoc manner, requiring
researchers to implement and debug their own code. This work introduces the
\textit{differint} software package, which offers a single repository for
multiple numerical algorithms for the computation of fractional derivatives and
integrals. This package is coded in the open-source Python programming
language. The Gr\"unwald-Letnikov, improved Gr\"unwald-Letnikov, and
Riemann-Liouville algorithms from the fractional calculus are included in this
package. The algorithms presented are computed from their descriptions found in
[2]. This work concludes with suggestions for the application of the
\textit{differint} software package.
</summary>
    <author>
      <name>Matthew Adams</name>
    </author>
    <link href="http://arxiv.org/abs/1912.05303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.05508v1</id>
    <updated>2019-12-11T18:14:52Z</updated>
    <published>2019-12-11T18:14:52Z</published>
    <title>High Accuracy Low Precision QR Factorization and Least Square Solver on
  GPU with TensorCore</title>
    <summary>  Driven by the insatiable needs to process ever larger amount of data with
more complex models, modern computer processors and accelerators are beginning
to offer half precision floating point arithmetic support, and extremely
optimized special units such as NVIDIA TensorCore on GPU and Google Tensor
Processing Unit (TPU) that does half precision matrix-matrix multiplication
exceptionally efficiently. In this paper we present a large scale mixed
precision linear least square solver that achieves high accuracy using the low
precision TensorCore GPU. The mixed precision system consists of both
innovative algorithms and implementations, and is shown to be up to 14x faster
than single precision cuSOLVER at QR matrix factorization at large scale with
slightly lower accuracy, and up to 10x faster than double precision direct QR
least square solver with comparable accuracy.
</summary>
    <author>
      <name>Shaoshuai Zhang</name>
    </author>
    <author>
      <name>Panruo Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.05508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.05508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.07696v2</id>
    <updated>2021-10-26T20:44:57Z</updated>
    <published>2019-12-16T20:45:42Z</published>
    <title>PETSc TSAdjoint: a discrete adjoint ODE solver for first-order and
  second-order sensitivity analysis</title>
    <summary>  We present a new software system PETSc TSAdjoint for first-order and
second-order adjoint sensitivity analysis of time-dependent nonlinear
differential equations. The derivative calculation in PETSc TSAdjoint is
essentially a high-level algorithmic differentiation process. The adjoint
models are derived by differentiating the timestepping algorithms and
implemented based on the parallel infrastructure in PETSc. Full differentiation
of the library code including MPI routines thus is avoided, and users do not
need to derive their own adjoint models for their specific applications. PETSc
TSAdjoint can compute the first-order derivative, that is, the gradient of a
scalar functional, and the Hessian-vector product that carries second-order
derivative information, while requiring minimal input (a few callbacks) from
the users. Optimal checkpointing schemes are employed by the adjoint model in a
manner that is transparent to users. Usability, efficiency, and scalability are
demonstrated through examples from a variety of applications.
</summary>
    <author>
      <name>Hong Zhang</name>
    </author>
    <author>
      <name>Emil M. Constantinescu</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1912.07696v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.07696v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08516v4</id>
    <updated>2021-07-05T16:21:35Z</updated>
    <published>2019-12-18T11:03:11Z</published>
    <title>PCPATCH: software for the topological construction of multigrid
  relaxation methods</title>
    <summary>  Effective relaxation methods are necessary for good multigrid convergence.
For many equations, standard Jacobi and Gau{\ss}-Seidel are inadequate, and
more sophisticated space decompositions are required; examples include problems
with semidefinite terms or saddle point structure. In this paper we present a
unifying software abstraction, PCPATCH, for the topological construction of
space decompositions for multigrid relaxation methods. Space decompositions are
specified by collecting topological entities in a mesh (such as all vertices or
faces) and applying a construction rule (such as taking all degrees of freedom
in the cells around each entity). The software is implemented in PETSc and
facilitates the elegant expression of a wide range of schemes merely by varying
solver options at runtime. In turn, this allows for the very rapid development
of fast solvers for difficult problems.
</summary>
    <author>
      <name>Patrick E. Farrell</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Lawrence Mitchell</name>
    </author>
    <author>
      <name>Florian Wechsung</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3445791</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3445791" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, minor fixes in bibliography</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software 47(3):25 (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.08516v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08516v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.12924v1</id>
    <updated>2019-12-30T13:39:46Z</updated>
    <published>2019-12-30T13:39:46Z</published>
    <title>Linnea: Automatic Generation of Efficient Linear Algebra Programs</title>
    <summary>  The translation of linear algebra computations into efficient sequences of
library calls is a non-trivial task that requires expertise in both linear
algebra and high-performance computing. Almost all high-level languages and
libraries for matrix computations (e.g., Matlab, Eigen) internally use
optimized kernels such as those provided by BLAS and LAPACK; however, their
translation algorithms are often too simplistic and thus lead to a suboptimal
use of said kernels, resulting in significant performance losses. In order to
combine the productivity offered by high-level languages, and the performance
of low-level kernels, we are developing Linnea, a code generator for linear
algebra problems. As input, Linnea takes a high-level description of a linear
algebra problem; as output, it returns an efficient sequence of calls to
high-performance kernels. Linnea uses a custom best-first search algorithm to
find a first solution in less than a second, and increasingly better solutions
when given more time. In 125 test problems, the code generated by Linnea almost
always outperforms Matlab, Julia, Eigen and Armadillo, with speedups up to and
exceeding 10x.
</summary>
    <author>
      <name>Henrik Barthels</name>
    </author>
    <author>
      <name>Christos Psarras</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of arXiv:1907.02778</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.12924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.12924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13282v1</id>
    <updated>2019-12-31T12:11:17Z</updated>
    <published>2019-12-31T12:11:17Z</published>
    <title>Medusa: A C++ Library for solving PDEs using Strong Form Mesh-Free
  methods</title>
    <summary>  Medusa, a novel library for implementation of strong form mesh-free methods,
is described. We identify and present common parts and patterns among many such
methods reported in the literature, such as node positioning, stencil selection
and stencil weight computation. Many different algorithms exist for each part
and the possible combinations offer a plethora of possibilities for
improvements of solution procedures that are far from fully understood. As a
consequence there are still many unanswered questions in mesh-free community
resulting in vivid ongoing research in the field. Medusa implements the core
mesh-free elements as independent blocks, which offers users great flexibility
in experimenting with the method they are developing, as well as easily
comparing it with other existing methods. The paper describes the chosen
abstractions and their usage, illustrates aspects of the philosophy and design,
offers some executions time benchmarks and demonstrates the application of the
library on cases from linear elasticity and fluid flow in irregular 2D and 3D
domains.
</summary>
    <author>
      <name>Jure Slak</name>
    </author>
    <author>
      <name>Gregor Kosec</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3450966</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3450966" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software 47(3), June 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.13282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.13375v2</id>
    <updated>2020-05-29T07:37:53Z</updated>
    <published>2019-12-23T21:26:49Z</published>
    <title>LEoPart: a particle library for FEniCS</title>
    <summary>  This paper introduces LEoPart, an add-on for the open source finite element
software library FEniCS to seamlessly integrate Lagrangian particle
functionality with (Eulerian) mesh-based finite element (FE) approaches.
LEoPart - which is so much as to say: `Lagrangian-Eulerian on Particles' -
contains tools for efficient, accurate and scalable advection of Lagrangian
particles on arbitrary polyhedral meshes. In addition, LEoPart comes with
several projection operators for exchanging information between the scattered
particles and the mesh and \textit{vice versa}. These projection operators are
based on a variational framework, which allows extension to high-order
accuracy. In particular, by implementing a dedicated PDE-constrained
particle-mesh projection operator, LEoPart provides all the tools for
diffusion-free advection, while simultaneously achieving optimal convergence
and ensuring conservation of the projected particle quantities on the
underlying mesh. A range of numerical examples that are prototypical to passive
and active tracer methods highlight the properties and the parallel performance
of the different tools in LEoPart. Finally, future developments are identified.
The source code for LEoPart is actively maintained and available under an open
source license at https://bitbucket.org/jakob_maljaars/leopart.
</summary>
    <author>
      <name>Jakob M. Maljaars</name>
    </author>
    <author>
      <name>Chris N. Richardson</name>
    </author>
    <author>
      <name>Nathan Sime</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2020.04.023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2020.04.023" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.13375v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.13375v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01895v2</id>
    <updated>2020-04-07T04:33:03Z</updated>
    <published>2020-01-31T11:20:04Z</published>
    <title>A toolbox of Equation-Free functions in Matlab\Octave for efficient
  system level simulation</title>
    <summary>  The `equation-free toolbox' empowers the computer-assisted analysis of
complex, multiscale systems. Its aim is to enable you to immediately use
microscopic simulators to perform macro-scale system level tasks and analysis,
because micro-scale simulations are often the best available description of a
system. The methodology bypasses the derivation of macroscopic evolution
equations by computing the micro-scale simulator only over short bursts in time
on small patches in space, with bursts and patches well-separated in time and
space respectively. We introduce the suite of coded equation-free functions in
an accessible way, link to more detailed descriptions, discuss their
mathematical support, and introduce a novel and efficient algorithm for
Projective Integration. Some facets of toolbox development of equation-free
functions are then detailed. Download the toolbox functions
(https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient
and accurate simulation in a wide range of your science and engineering
problems.
</summary>
    <author>
      <name>John Maclean</name>
    </author>
    <author>
      <name>J. E. Bunder</name>
    </author>
    <author>
      <name>A. J. Roberts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01895v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01895v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05024v1</id>
    <updated>2020-02-12T14:28:55Z</updated>
    <published>2020-02-12T14:28:55Z</published>
    <title>Task-based, GPU-accelerated and Robust Library for Solving Dense
  Nonsymmetric Eigenvalue Problems</title>
    <summary>  In this paper, we present the StarNEig library for solving dense nonsymmetric
standard and generalized eigenvalue problems. The library is built on top of
the StarPU runtime system and targets both shared and distributed memory
machines. Some components of the library have support for GPU acceleration. The
library is currently in an early beta state and supports only real matrices.
Support for complex matrices is planned for a future release. This paper is
aimed at potential users of the library. We describe the design choices and
capabilities of the library, and contrast them to existing software such as
ScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should
assist new users in the transition to StarNEig. We demonstrate the performance
of the library with a sample of computational experiments.
</summary>
    <author>
      <name>Mirko Myllykoski</name>
    </author>
    <author>
      <name>Carl Christian Kjelgaard Mikkelsen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/cpe.5915</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/cpe.5915" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 11 figures (18 when counting sub-figures), 1 tex-files.
  Invited article submitted to Concurrency and Computation: Practice and
  Experience. Second author's first name is "Carl Christian" and last name
  "Kjelgaard Mikkelsen"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Concurrency Computat Pract Exper. (2020) e5915</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.05024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.08110v1</id>
    <updated>2020-02-19T11:25:35Z</updated>
    <published>2020-02-19T11:25:35Z</published>
    <title>hyper.deal: An efficient, matrix-free finite-element library for
  high-dimensional partial differential equations</title>
    <summary>  This work presents the efficient, matrix-free finite-element library
hyper.deal for solving partial differential equations in two to six dimensions
with high-order discontinuous Galerkin methods. It builds upon the
low-dimensional finite-element library deal.II to create complex
low-dimensional meshes and to operate on them individually. These meshes are
combined via a tensor product on the fly and the library provides new
special-purpose highly optimized matrix-free functions exploiting domain
decomposition as well as shared memory via MPI-3.0 features. Both node-level
performance analyses and strong/weak-scaling studies on up to 147,456 CPU cores
confirm the efficiency of the implementation. Results of the library hyper.deal
are reported for high-dimensional advection problems and for the solution of
the Vlasov--Poisson equation in up to 6D phase space.
</summary>
    <author>
      <name>Peter Munch</name>
    </author>
    <author>
      <name>Katharina Kormann</name>
    </author>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 18 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12323v1</id>
    <updated>2020-02-27T18:43:07Z</updated>
    <published>2020-02-27T18:43:07Z</published>
    <title>SplineLib: A Modern Multi-Purpose C++ Spline Library</title>
    <summary>  This paper provides the description of a novel, multi-purpose spline library.
In accordance with the increasingly diverse modes of usage of splines, it is
multi-purpose in the sense that it supports geometry representation, finite
element analysis, and optimization. The library features reading and writing
for various file formats and a wide range of spline manipulation algorithms.
Further, a new efficient and objective-oriented algorithm for B-spline basis
function evaluation is included. All features are available by a spline-type
independent interface. The library is written in modern C++ with CMake as build
system. This enables it for usage in typical scientific applications. It is
provided as open-source library.
</summary>
    <author>
      <name>Markus Frings</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Norbert Hosters</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Corinna Müller</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Max Spahn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Christoph Susen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Konstantin Key</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Stefanie Elgeti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chair for Computational Analysis of Technical Systems, Aachen, Germany</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures, submitted to Advances in Engineering Software</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.1; D.1.5; D.3.3; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.12682v1</id>
    <updated>2020-02-28T12:42:26Z</updated>
    <published>2020-02-28T12:42:26Z</published>
    <title>MORLAB -- The Model Order Reduction LABoratory</title>
    <summary>  For an easy use of model order reduction techniques in applications, software
solutions are needed. In this paper, we describe the MORLAB, Model Order
Reduction LABoratory, toolbox as an efficient implementation of model reduction
techniques for dense, medium-scale linear time-invariant systems. Giving an
introduction to the underlying programming principles of the toolbox, we show
the basic idea of spectral splitting and present an overview about implemented
model reduction techniques. Two numerical examples are used to illustrate
different use cases of the MORLAB toolbox.
</summary>
    <author>
      <name>Peter Benner</name>
    </author>
    <author>
      <name>Steffen W. R. Werner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-72983-7_19</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-72983-7_19" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 6 figures, 5 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Series of Numerical Mathematics, 171:393-415, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.12682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.02088v2</id>
    <updated>2020-05-09T12:42:10Z</updated>
    <published>2020-03-04T14:02:21Z</published>
    <title>Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,
  Features and Application for (Parametric) Model</title>
    <summary>  Matrix equations are omnipresent in (numerical) linear algebra and systems
theory. Especially in model order reduction (MOR) they play a key role in many
balancing based reduction methods for linear dynamical systems. When these
systems arise from spatial discretizations of evolutionary partial differential
equations, their coefficient matrices are typically large and sparse. Moreover,
the numbers of inputs and outputs of these systems are typically far smaller
than the number of spatial degrees of freedom. Then, in many situations the
solutions of the corresponding large-scale matrix equations are observed to
have low (numerical) rank. This feature is exploited by M-M.E.S.S. to find
successively larger low-rank factorizations approximating the solutions. This
contribution describes the basic philosophy behind the implementation and the
features of the package, as well as its application in the model order
reduction of large-scale linear time-invariant (LTI) systems and parametric LTI
systems.
</summary>
    <author>
      <name>Peter Benner</name>
    </author>
    <author>
      <name>Martin Köhler</name>
    </author>
    <author>
      <name>Jens Saak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02088v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02088v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04103v4</id>
    <updated>2023-11-15T14:51:17Z</updated>
    <published>2020-03-09T12:57:42Z</published>
    <title>Flexible numerical optimization with ensmallen</title>
    <summary>  This report provides an introduction to the ensmallen numerical optimization
library, as well as a deep dive into the technical details of how it works. The
library provides a fast and flexible C++ framework for mathematical
optimization of arbitrary user-supplied functions. A large set of pre-built
optimizers is provided, including many variants of Stochastic Gradient Descent
and Quasi-Newton optimizers. Several types of objective functions are
supported, including differentiable, separable, constrained, and categorical
objective functions. Implementation of a new optimizer requires only one
method, while a new objective function requires typically only one or two C++
methods. Through internal use of C++ template metaprogramming, ensmallen
provides support for arbitrary user-supplied callbacks and automatic inference
of unsupplied methods without any runtime overhead. Empirical comparisons show
that ensmallen outperforms other optimization frameworks (such as Julia and
SciPy), sometimes by large margins. The library is available at
https://ensmallen.org and is distributed under the permissive BSD license.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Rahul Ganesh Prabhu</name>
    </author>
    <author>
      <name>Suryoday Basak</name>
    </author>
    <author>
      <name>Zhihao Lou</name>
    </author>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://ensmallen.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.04103v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04103v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04776v1</id>
    <updated>2020-03-10T14:37:39Z</updated>
    <published>2020-03-10T14:37:39Z</published>
    <title>Parallel Robust Computation of Generalized Eigenvectors of Matrix
  Pencils</title>
    <summary>  In this paper we consider the problem of computing generalized eigenvectors
of a matrix pencil in real Schur form. In exact arithmetic, this problem can be
solved using substitution. In practice, substitution is vulnerable to
floating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow
by dynamically scaling the eigenvectors. These subroutines are sequential
scalar codes which compute the eigenvectors one by one. In this paper we
discuss how to derive robust blocked algorithms. The new StarNEig library
contains a robust task-parallel solver Zazamoukh which runs on top of StarPU.
Our numerical experiments show that Zazamoukh achieves a super-linear speedup
compared with DTGEVC for sufficiently large matrices.
</summary>
    <author>
      <name>Carl Christian Kjelgaard Mikkelsen</name>
    </author>
    <author>
      <name>Mirko Myllykoski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-43229-4_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-43229-4_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript was accepted to 13th International Conference on
  Parallel Processing and Applied Mathematics (PPAM2019), Bialystok, Poland,
  September 8-11, 2019. The final authenticated version is available online at
  https://doi.org/10.1007/978-3-030-43229-4_6 (DOI valid from May 8, 2020
  onward). First author's first name is "Carl Christian" and last name
  "Kjelgaard Mikkelsen"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNCS 12043 (2020) 58-69</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.04776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.09956v2</id>
    <updated>2020-08-21T06:12:56Z</updated>
    <published>2020-03-22T17:44:23Z</published>
    <title>Scalable parallel algorithm for solving non-stationary systems of linear
  inequalities</title>
    <summary>  In this paper, a scalable iterative projection-type algorithm for solving
non-stationary systems of linear inequalities is considered. A non-stationary
system is understood as a large-scale system of inequalities in which
coefficients and constant terms can change during the calculation process. The
proposed parallel algorithm uses the concept of pseudo-projection which
generalizes the notion of orthogonal projection. The parallel pseudo-projection
algorithm is implemented using the parallel BSF-skeleton. An analytical
estimation of the algorithm scalability boundary is obtained on the base of the
BSF cost metric. The large-scale computational experiments were performed on a
cluster computing system. The obtained results confirm the efficiency of the
proposed approach.
</summary>
    <author>
      <name>Leonid B. Sokolinsky</name>
    </author>
    <author>
      <name>Irina M. Sokolinskaya</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S1995080220080181</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S1995080220080181" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This a preprint of the Work accepted for publication in Lobachevskii
  Journal of Mathematics, \c{opyright} 2020, Springer Nature</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lobachevskii J. Math. 41 (2020) 1571-1580</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.09956v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.09956v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90-08" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.12861v1</id>
    <updated>2020-03-28T18:22:20Z</updated>
    <published>2020-03-28T18:22:20Z</published>
    <title>Making RooFit Ready for Run 3</title>
    <summary>  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used
in most searches and measurements at the Large Hadron Collider. The data to be
collected in Run 3 will enable measurements with higher precision and models
with larger complexity, but also require faster data processing. In this work,
first results on modernising RooFit's collections, restructuring data flow and
vectorising likelihood fits in RooFit will be discussed. These improvements
will enable the LHC experiments to process larger datasets without having to
compromise with respect to model complexity, as fitting times would increase
significantly with the large datasets to be expected in Run 3.
</summary>
    <author>
      <name>Stephan Hageboeck</name>
    </author>
    <author>
      <name>Lorenzo Moneta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-6596/1525/1/012114</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-6596/1525/1/012114" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures. Proceedings of ACAT 2019. Submitted to Journal Of
  Physics: Conference Series</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2020 J. Phys.: Conf. Ser. 1525 012114</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2003.12861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.12861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.01463v2</id>
    <updated>2021-05-03T18:02:27Z</updated>
    <published>2020-04-03T10:40:08Z</published>
    <title>Interpolation of Dense and Sparse Rational Functions and other
  Improvements in $\texttt{FireFly}$</title>
    <summary>  We present the main improvements and new features in version $\texttt{2.0}$
of the open-source $\texttt{C++}$ library $\texttt{FireFly}$ for the
interpolation of rational functions. This includes algorithmic improvements,
e.g. a hybrid algorithm for dense and sparse rational functions and an
algorithm to identify and remove univariate factors. The new version is applied
to a Feynman-integral reduction to showcase the runtime improvements achieved.
Moreover, $\texttt{FireFly}$ now supports parallelization with $\texttt{MPI}$
and offers new tools like a parser for expressions or an executable for the
insertion of replacement tables.
</summary>
    <author>
      <name>Jonas Klappert</name>
    </author>
    <author>
      <name>Sven Yannick Klein</name>
    </author>
    <author>
      <name>Fabian Lange</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2021.107968</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2021.107968" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 10 tables, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Commun. 264 (2021) 107968</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2004.01463v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.01463v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.04435v1</id>
    <updated>2020-04-09T09:18:50Z</updated>
    <published>2020-04-09T09:18:50Z</published>
    <title>Automatic Differentiation in ROOT</title>
    <summary>  In mathematics and computer algebra, automatic differentiation (AD) is a set
of techniques to evaluate the derivative of a function specified by a computer
program. AD exploits the fact that every computer program, no matter how
complicated, executes a sequence of elementary arithmetic operations (addition,
subtraction, multiplication, division, etc.), elementary functions (exp, log,
sin, cos, etc.) and control flow statements. AD takes source code of a function
as input and produces source code of the derived function. By applying the
chain rule repeatedly to these operations, derivatives of arbitrary order can
be computed automatically, accurately to working precision, and using at most a
small constant factor more arithmetic operations than the original program.
  This paper presents AD techniques available in ROOT, supported by Cling, to
produce derivatives of arbitrary C/C++ functions through implementing source
code transformation and employing the chain rule of differential calculus in
both forward mode and reverse mode. We explain its current integration for
gradient computation in TFormula. We demonstrate the correctness and
performance improvements in ROOT's fitting algorithms.
</summary>
    <author>
      <name>Vassil Vassilev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <author>
      <name>Aleksandr Efremov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <author>
      <name>Oksana Shadura</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Nebraska Lincoln</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/epjconf/202024502015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/epjconf/202024502015" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted as a proceeding for CHEP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.04435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.04435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.08729v2</id>
    <updated>2020-09-15T11:48:01Z</updated>
    <published>2020-04-18T23:26:04Z</published>
    <title>Fully Parallel Mesh I/O using PETSc DMPlex with an Application to
  Waveform Modeling</title>
    <summary>  Large-scale PDE simulations using high-order finite-element methods on
unstructured meshes are an indispensable tool in science and engineering. The
widely used open-source PETSc library offers an efficient representation of
generic unstructured meshes within its DMPlex module. This paper details our
recent implementation of parallel mesh reading and topological interpolation
(computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply
these developments to seismic wave propagation scenarios on Mars as an example
application. The principal motivation is to overcome single-node memory limits
and reach mesh sizes which were impossible before. Moreover, we demonstrate
that scalability of I/O and topological interpolation goes beyond 12'000 cores,
and memory-imposed limits on mesh size vanish.
</summary>
    <author>
      <name>Vaclav Hapla</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Michael Afanasiev</name>
    </author>
    <author>
      <name>Christian Boehm</name>
    </author>
    <author>
      <name>Martin van Driel</name>
    </author>
    <author>
      <name>Lion Krischer</name>
    </author>
    <author>
      <name>Andreas Fichtner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/20M1332748</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/20M1332748" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM J. Sci. Comput. 43 (2021) C127-C153</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2004.08729v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.08729v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65-04, 65Y05, 65M50, 05C90, 35L05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.08913v1</id>
    <updated>2020-04-19T17:19:19Z</updated>
    <published>2020-04-19T17:19:19Z</published>
    <title>A practical approach to testing random number generators in computer
  algebra systems</title>
    <summary>  This paper has a practical aim. For a long time, implementations of
pseudorandom number generators in standard libraries of programming languages
had poor quality. The situation started to improve only recently. Up to now, a
large number of libraries and weakly supported mathematical packages use
outdated algorithms for random number generation. Four modern sets of
statistical tests that can be used for verifying random number generators are
described. It is proposed to use command line utilities, which makes it
possible to avoid low-level programming in such languages as C or C++. Only
free open source systems are considered.
</summary>
    <author>
      <name>Migran N. Gevorkyan</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <author>
      <name>Anastasia V. Demidova</name>
    </author>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S096554252001008X</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S096554252001008X" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.08913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.08913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.02732v1</id>
    <updated>2020-05-06T11:06:11Z</updated>
    <published>2020-05-06T11:06:11Z</published>
    <title>Custom-Precision Mathematical Library Explorations for Code Profiling
  and Optimization</title>
    <summary>  The typical processors used for scientific computing have fixed-width
data-paths. This implies that mathematical libraries were specifically
developed to target each of these fixed precisions (binary16, binary32,
binary64). However, to address the increasing energy consumption and throughput
requirements of scientific applications, library and hardware designers are
moving beyond this one-size-fits-all approach. In this article we propose to
study the effects and benefits of using user-defined floating-point formats and
target accuracies in calculations involving mathematical functions. Our tool
collects input-data profiles and iteratively explores lower precisions for each
call-site of a mathematical function in user applications. This profiling data
will be a valuable asset for specializing and fine-tuning mathematical function
implementations for a given application. We demonstrate the tool's capabilities
on SGP4, a satellite tracking application. The profile data shows the potential
for specialization and provides insight into answering where it is useful to
provide variable-precision designs for elementary function evaluation.
</summary>
    <author>
      <name>David Defour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A</arxiv:affiliation>
    </author>
    <author>
      <name>Pablo de Oliveira Castro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PRISM, LI-PaRAD</arxiv:affiliation>
    </author>
    <author>
      <name>Matei Istoan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UVSQ, LI-PaRAD</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Petit</name>
    </author>
    <link href="http://arxiv.org/abs/2005.02732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.02732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.04540v2</id>
    <updated>2020-12-24T20:18:57Z</updated>
    <published>2020-05-10T01:15:37Z</published>
    <title>AutoHOOT: Automatic High-Order Optimization for Tensors</title>
    <summary>  High-order optimization methods, including Newton's method and its variants
as well as alternating minimization methods, dominate the optimization
algorithms for tensor decompositions and tensor networks. These tensor methods
are used for data analysis and simulation of quantum systems. In this work, we
introduce AutoHOOT, the first automatic differentiation (AD) framework
targeting at high-order optimization for tensor computations. AutoHOOT takes
input tensor computation expressions and generates optimized derivative
expressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian
expression generation kernel whose outputs maintain the input tensors'
granularity and are easy to optimize. The expressions are then optimized by
both the traditional compiler optimization techniques and specific tensor
algebra transformations. Experimental results show that AutoHOOT achieves
competitive CPU and GPU performance for both tensor decomposition and tensor
network applications compared to existing AD software and other tensor
computation libraries with manually written kernels. The tensor methods
generated by AutoHOOT are also well-parallelizable, and we demonstrate good
scalability on a distributed memory supercomputer.
</summary>
    <author>
      <name>Linjian Ma</name>
    </author>
    <author>
      <name>Jiayu Ye</name>
    </author>
    <author>
      <name>Edgar Solomonik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.04540v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.04540v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.12992v3</id>
    <updated>2023-08-15T12:10:56Z</updated>
    <published>2020-06-23T13:40:46Z</published>
    <title>Assign optimization for algorithmic differentiation reuse index
  management strategies</title>
    <summary>  The identification of primal variables and adjoint variables is usually done
via indices in operator overloading algorithmic differentiation tools. One
approach is a linear management scheme, which is easy to implement and supports
memory optimization for copy statements. An alternative approach performs a
reuse of indices, which requires more implementation effort but results in much
smaller adjoint vectors. Therefore, the vector mode of algorithmic
differentiation scales better with the reuse management scheme. In this paper,
we present a novel approach that reuses the indices and allows the copy
optimization, thus combining the advantages of the two aforementioned schemes.
The new approach is compared to the known approaches on a simple synthetic test
case and a real-world example using the computational fluid dynamics solver
SU2.
</summary>
    <author>
      <name>Max Sagebaum</name>
    </author>
    <author>
      <name>Johannes Blühdorn</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.12992v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.12992v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4; G.4; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.14290v1</id>
    <updated>2020-06-25T10:22:02Z</updated>
    <published>2020-06-25T10:22:02Z</published>
    <title>Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to
  HIP</title>
    <summary>  With AMD reinforcing their ambition in the scientific high performance
computing ecosystem, we extend the hardware scope of the Ginkgo linear algebra
package to feature a HIP backend for AMD GPUs. In this paper, we report and
discuss the porting effort from CUDA, the extension of the HIP framework to add
missing features such as cooperative groups, the performance price of compiling
HIP code for AMD architectures, and the design of a library providing native
backends for NVIDIA and AMD GPUs while minimizing code duplication by using a
shared code base.
</summary>
    <author>
      <name>Yuhsiang M. Tsai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Karlsruhe Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Terry Cojean</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Karlsruhe Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Tobias Ribizel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Karlsruhe Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Hartwig Anzt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Karlsruhe Institute of Technology</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Tennessee, Innovative Computing Lab</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint submitted to HeteroPar</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.14290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.14290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.16852v2</id>
    <updated>2020-07-01T08:31:08Z</updated>
    <published>2020-06-30T14:42:48Z</published>
    <title>Ginkgo: A Modern Linear Operator Algebra Framework for High Performance
  Computing</title>
    <summary>  In this paper, we present Ginkgo, a modern C++ math library for scientific
high performance computing. While classical linear algebra libraries act on
matrix and vector objects, Ginkgo's design principle abstracts all
functionality as "linear operators", motivating the notation of a "linear
operator algebra library". Ginkgo's current focus is oriented towards providing
sparse linear algebra functionality for high performance GPU architectures, but
given the library design, this focus can be easily extended to accommodate
other algorithms and hardware architectures. We introduce this sophisticated
software architecture that separates core algorithms from architecture-specific
back ends and provide details on extensibility and sustainability measures. We
also demonstrate Ginkgo's usability by providing examples on how to use its
functionality inside the MFEM and deal.ii finite element ecosystems. Finally,
we offer a practical demonstration of Ginkgo's high performance on
state-of-the-art GPU architectures.
</summary>
    <author>
      <name>Hartwig Anzt</name>
    </author>
    <author>
      <name>Terry Cojean</name>
    </author>
    <author>
      <name>Goran Flegar</name>
    </author>
    <author>
      <name>Fritz Göbel</name>
    </author>
    <author>
      <name>Thomas Grützmacher</name>
    </author>
    <author>
      <name>Pratik Nayak</name>
    </author>
    <author>
      <name>Tobias Ribizel</name>
    </author>
    <author>
      <name>Yuhsiang Mike Tsai</name>
    </author>
    <author>
      <name>Enrique S. Quintana-Ortí</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint submitted to ACM Transactions on Mathematical Software</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.16852v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.16852v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2; G.1.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.00056v1</id>
    <updated>2020-06-30T18:39:50Z</updated>
    <published>2020-06-30T18:39:50Z</published>
    <title>SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and
  preconditioned iterative methods</title>
    <summary>  Hybrid CPU-GPU algorithms for Algebraic Multigrid methods (AMG) to
efficiently utilize both CPU and GPU resources are presented. In particular,
hybrid AMG framework focusing on minimal utilization of GPU memory with
performance on par with GPU-only implementations is developed. The hybrid AMG
framework can be tuned to operate at a significantly lower GPU-memory,
consequently, enables to solve large algebraic systems. Combining the hybrid
AMG framework as a preconditioner with Krylov Subspace solvers like Conjugate
Gradient, BiCG methods provides a solver stack to solve a large class of
problems. The performance of the proposed hybrid AMG framework is analysed for
an array of matrices with different properties and size. Further, the
performance of CPU-GPU algorithms are compared with the GPU-only
implementations to illustrate the significantly lower memory requirements.
</summary>
    <author>
      <name>Sashikumaar Ganesan</name>
    </author>
    <author>
      <name>Manan Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.00056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.00056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F10, 65F50, 65N55, 65Y05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.00094v2</id>
    <updated>2021-02-02T21:07:20Z</updated>
    <published>2020-06-30T20:19:45Z</published>
    <title>Efficient parallel 3D computation of the compressible Euler equations
  with an invariant-domain preserving second-order finite-element scheme</title>
    <summary>  We discuss the efficient implementation of a high-performance second-order
collocation-type finite-element scheme for solving the compressible Euler
equations of gas dynamics on unstructured meshes. The solver is based on the
convex limiting technique introduced by Guermond et al. (SIAM J. Sci. Comput.
40, A3211-A3239, 2018). As such it is invariant-domain preserving, i.e., the
solver maintains important physical invariants and is guaranteed to be stable
without the use of ad-hoc tuning parameters. This stability comes at the
expense of a significantly more involved algorithmic structure that renders
conventional high-performance discretizations challenging. We develop an
algorithmic design that allows SIMD vectorization of the compute kernel,
identify the main ingredients for a good node-level performance, and report
excellent weak and strong scaling of a hybrid thread/MPI parallelization.
</summary>
    <author>
      <name>Matthias Maier</name>
    </author>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <link href="http://arxiv.org/abs/2007.00094v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.00094v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.00202v2</id>
    <updated>2021-10-18T16:48:34Z</updated>
    <published>2020-07-01T03:27:33Z</published>
    <title>Sparse Approximate Multifrontal Factorization with Butterfly Compression
  for High Frequency Wave Equations</title>
    <summary>  We present a fast and approximate multifrontal solver for large-scale sparse
linear systems arising from finite-difference, finite-volume or finite-element
discretization of high-frequency wave equations. The proposed solver leverages
the butterfly algorithm and its hierarchical matrix extension for compressing
and factorizing large frontal matrices via graph-distance guided entry
evaluation or randomized matrix-vector multiplication-based schemes. Complexity
analysis and numerical experiments demonstrate $\mathcal{O}(N\log^2 N)$
computation and $\mathcal{O}(N)$ memory complexity when applied to an $N\times
N$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.
</summary>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Pieter Ghysels</name>
    </author>
    <author>
      <name>Lisa Claus</name>
    </author>
    <author>
      <name>Xiaoye Sherry Li</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/20M1349667</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/20M1349667" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing. 2021(0):S367-91</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.00202v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.00202v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A23, 65F50, 65R10, 65R20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.07539v1</id>
    <updated>2020-07-15T08:27:33Z</updated>
    <published>2020-07-15T08:27:33Z</published>
    <title>Accelerating Geometric Multigrid Preconditioning with Half-Precision
  Arithmetic on GPUs</title>
    <summary>  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,
high-performance computing applications can benefit from lower precision at
appropriate spots to speed up the overall execution time. In this paper, we
investigate a mixed-precision geometric multigrid method to solve large sparse
systems of equations stemming from discretization of elliptic PDEs. While the
final solution is always computed with high-precision accuracy, an iterative
refinement approach with multigrid preconditioning in lower precision and
residuum scaling is employed. We compare the FP64 baseline for Poisson's
equation to purely FP16 multigrid preconditioning and to the employment of
FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count
is almost not affected by using lower accuracy, the solver runtime is
considerably decreased due to the reduced memory transfer and a speedup of up
to 2.5x is gained for the overall solver. We investigate the performance of
selected kernels with the hierarchical Roofline model.
</summary>
    <author>
      <name>Kyaw L. Oo</name>
    </author>
    <author>
      <name>Andreas Vogel</name>
    </author>
    <link href="http://arxiv.org/abs/2007.07539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.07539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.09737v1</id>
    <updated>2020-07-19T18:24:08Z</updated>
    <published>2020-07-19T18:24:08Z</published>
    <title>Approaches to the implementation of generalized complex numbers in the
  Julia language</title>
    <summary>  In problems of mathematical physics, to study the structures of spaces using
the Cayley-Klein models in theoretical calculations, the use of generalized
complex numbers is required. In the case of computational experiments, such
tasks require their high-quality implementation in a programming language. The
proposed small implementation of generalized complex numbers in modern
programming languages have several disadvantages. In this article, we propose
using the Julia language as the language for implementing generalized complex
numbers, not least because it supports the multiple dispatch mechanism. The
paper demonstrates the approach to the implementation of one of the types of
generalized complex numbers, namely dual numbers. We place particular emphasis
on the description of the use of the multiple dispatch mechanism to implement a
new numerical type. The resulting implementation of dual numbers can be
considered as a prototype for a complete software module for supporting
generalized complex numbers.
</summary>
    <author>
      <name>Migran N. Gevorkyan</name>
    </author>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English; in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in CEUR Workshop Proceedings, vol. 2639, 141-157 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.09737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.09737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.14822v2</id>
    <updated>2021-12-20T22:16:09Z</updated>
    <published>2020-07-28T15:38:57Z</published>
    <title>The ITensor Software Library for Tensor Network Calculations</title>
    <summary>  ITensor is a system for programming tensor network calculations with an
interface modeled on tensor diagram notation, which allows users to focus on
the connectivity of a tensor network without manually bookkeeping tensor
indices. The ITensor interface rules out common programming errors and enables
rapid prototyping of tensor network algorithms. After discussing the philosophy
behind the ITensor approach, we show examples of each part of the interface
including Index objects, the ITensor product operator, tensor factorizations,
tensor storage types, algorithms for matrix product state (MPS) and matrix
product operator (MPO) tensor networks, quantum number conserving block-sparse
tensors, and the NDTensors library. We also review publications that have used
ITensor for quantum many-body physics and for other areas where tensor networks
are increasingly applied. To conclude we discuss promising features and
optimizations to be added in the future.
</summary>
    <author>
      <name>Matthew Fishman</name>
    </author>
    <author>
      <name>Steven R. White</name>
    </author>
    <author>
      <name>E. Miles Stoudenmire</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21468/SciPostPhysCodeb.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21468/SciPostPhysCodeb.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to SciPost Physics Codebases. Version 2 contains benchmarks
  of ITensor C++ and Julia versions, and link to external benchmarks including
  TeNPy software</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SciPost Phys. Codebases 4 (2022)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.14822v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.14822v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.12696v3</id>
    <updated>2021-07-01T08:21:31Z</updated>
    <published>2020-12-22T11:41:24Z</published>
    <title>NetworkDynamics.jl -- Composing and simulating complex networks in Julia</title>
    <summary>  NetworkDynamics.jl is an easy-to-use and computationally efficient package
for working with heterogeneous dynamical systems on complex networks, written
in Julia, a high-level, high-performance, dynamic programming language. By
combining state of the art solver algorithms from DifferentialEquations.jl with
efficient data structures, NetworkDynamics.jl achieves top performance while
supporting advanced features like events, algebraic constraints, time-delays,
noise terms and automatic differentiation.
</summary>
    <author>
      <name>Michael Lindner</name>
    </author>
    <author>
      <name>Lucas Lincoln</name>
    </author>
    <author>
      <name>Fenja Drauschke</name>
    </author>
    <author>
      <name>Julia Monika Koulen</name>
    </author>
    <author>
      <name>Hans Würfel</name>
    </author>
    <author>
      <name>Anton Plietzsch</name>
    </author>
    <author>
      <name>Frank Hellmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/5.0051387</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/5.0051387" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in Chaos 31, 063133 (2021) and may be found at
  https://aip.scitation.org/doi/10.1063/5.0051387</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 31, 063133 (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2012.12696v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.12696v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.00086v1</id>
    <updated>2020-12-31T21:52:19Z</updated>
    <published>2020-12-31T21:52:19Z</published>
    <title>calculus: High Dimensional Numerical and Symbolic Calculus in R</title>
    <summary>  The R package calculus implements C++ optimized functions for numerical and
symbolic calculus, such as the Einstein summing convention, fast computation of
the Levi-Civita symbol and generalized Kronecker delta, Taylor series
expansion, multivariate Hermite polynomials, high-order derivatives, ordinary
differential equations, differential operators and numerical integration in
arbitrary orthogonal coordinate systems. The library applies numerical methods
when working with R functions or symbolic programming when working with
characters or expressions. The package handles multivariate numerical calculus
in arbitrary dimensions and coordinates and implements the symbolic counterpart
of the numerical methods whenever possible, without depending on external
computer algebra systems. Except for Rcpp, the package has no strict
dependencies in order to provide a stable self-contained toolbox that invites
re-use.
</summary>
    <author>
      <name>Emanuele Guidotti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18637/jss.v104.i05</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18637/jss.v104.i05" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Software (2022), 104(5), 1-37</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2101.00086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.00086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.05063v1</id>
    <updated>2021-01-13T13:49:38Z</updated>
    <published>2021-01-13T13:49:38Z</published>
    <title>Robust level-3 BLAS Inverse Iteration from the Hessenberg Matrix</title>
    <summary>  Inverse iteration is known to be an effective method for computing
eigenvectors corresponding to simple and well-separated eigenvalues. In the
non-symmetric case, the solution of shifted Hessenberg systems is a central
step. Existing inverse iteration solvers approach the solution of the shifted
Hessenberg systems with either RQ or LU factorizations and, once factored,
solve the corresponding systems. This approach has limited level-3 BLAS
potential since distinct shifts have distinct factorizations. This paper
rearranges the RQ approach such that data shared between distinct shifts is
exposed. Thereby the backward substitution with the triangular R factor can be
expressed mostly with matrix-matrix multiplications (level-3 BLAS). The
resulting algorithm computes eigenvectors in a tiled, overflow-free, and
task-parallel fashion. The numerical experiments show that the new algorithm
outperforms existing inverse iteration solvers for the computation of both real
and complex eigenvectors.
</summary>
    <author>
      <name>Angelika Schwarz</name>
    </author>
    <link href="http://arxiv.org/abs/2101.05063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.05063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.10881v3</id>
    <updated>2021-03-13T00:22:10Z</updated>
    <published>2021-01-22T19:42:43Z</published>
    <title>Accelerated Polynomial Evaluation and Differentiation at Power Series in
  Multiple Double Precision</title>
    <summary>  The problem is to evaluate a polynomial in several variables and its gradient
at a power series truncated to some finite degree with multiple double
precision arithmetic. To compensate for the cost overhead of multiple double
precision and power series arithmetic, data parallel algorithms for general
purpose graphics processing units are presented. The reverse mode of
algorithmic differentiation is organized into a massively parallel computation
of many convolutions and additions of truncated power series. Experimental
results demonstrate that teraflop performance is obtained in deca double
precision with power series truncated at degree 152. The algorithms scale well
for increasing precision and increasing degrees.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Improved the introduction, adding two citations to related work;
  fixed error, added table on the fluctuations of wall clock times. To appear
  in the Proceedings of the 2021 IEEE International Parallel and Distributed
  Processing Symposium Workshops (IPDPSW)</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.10881v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.10881v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.12425v1</id>
    <updated>2021-01-29T06:40:53Z</updated>
    <published>2021-01-29T06:40:53Z</published>
    <title>lrsarith: a small fixed/hybrid arithmetic C library</title>
    <summary>  We describe lrsarith which is a small fixed precision and hybrid arithmetic C
library for integers and rationals that we developed for use in the lrslib
library for polyhedral computation. Using a generic set of operations, a
program can be compiled with either 64-bit or 128-bit (if available) fixed
precision, with an extended precision library such as GMP or the built-in MP
routines. A simple scheme checks for overflow and either terminates the program
or, in hybrid mode, changes to a higher precision arithmetic. Implementing
these arithmetics in lrslib resulted in only minimal changes to the original
code. We give computational results using lrs and mplrs, vertex/facet
enumeration codes in lrslib, using 64 and 128 bit fixed integer arithmetic with
and without overflow checking, GMP arithmetic, lrsarith hybrid arithmetic with
both GMP and MP, and FLINT hybrid arithmetic. We give a small self-contained
example C program using the lrsarith package in both fixed precision and hybrid
mode.
</summary>
    <author>
      <name>David Avis</name>
    </author>
    <author>
      <name>Charles Jordan</name>
    </author>
    <link href="http://arxiv.org/abs/2101.12425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.12425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.03646v1</id>
    <updated>2021-03-05T13:20:47Z</updated>
    <published>2021-03-05T13:20:47Z</published>
    <title>Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs
  -- A MAPLE Package</title>
    <summary>  There exist several methods for computing exact solutions of algebraic
differential equations. Most of the methods, however, do not ensure existence
and uniqueness of the solutions and might fail after several steps, or are
restricted to linear equations. The authors have presented in previous works a
method to overcome this problem for autonomous first order algebraic ordinary
differential equations and formal Puiseux series solutions and algebraic
solutions. In the first case, all solutions can uniquely be represented by a
sufficiently large truncation and in the latter case by its minimal polynomial.
The main contribution of this paper is the implementation, in a MAPLE-package
named FirstOrderSolve, of the algorithmic ideas presented therein. More
precisely, all formal Puiseux series and algebraic solutions, including the
generic and singular solutions, are computed and described uniquely. The
computation strategy is to reduce the given differential equation to a simpler
one by using local parametrizations and the already known degree bounds.
</summary>
    <author>
      <name>Francois Boulier</name>
    </author>
    <author>
      <name>Jose Cano</name>
    </author>
    <author>
      <name>Sebastian Falkensteiner</name>
    </author>
    <author>
      <name>Rafael Sendra</name>
    </author>
    <link href="http://arxiv.org/abs/2103.03646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.03646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.07329v1</id>
    <updated>2021-03-12T14:54:09Z</updated>
    <published>2021-03-12T14:54:09Z</published>
    <title>XAMG: A library for solving linear systems with multiple right-hand side
  vectors</title>
    <summary>  This paper presents the XAMG library for solving large sparse systems of
linear algebraic equations with multiple right-hand side vectors. The library
specializes but is not limited to the solution of linear systems obtained from
the discretization of elliptic differential equations. A corresponding set of
numerical methods includes Krylov subspace, algebraic multigrid, Jacobi,
Gauss-Seidel, and Chebyshev iterative methods. The parallelization is
implemented with MPI+POSIX shared memory hybrid programming model, which
introduces a three-level hierarchical decomposition using the corresponding
per-level synchronization and communication primitives. The code contains a
number of optimizations, including the multilevel data segmentation,
compression of indices, mixed-precision floating-point calculations, vector
status flags, and others. The XAMG library uses the program code of the
well-known hypre library to construct the multigrid matrix hierarchy. The
XAMG's own implementation for the solve phase of the iterative methods provides
up to a twofold speedup compared to hypre for the tests performed.
Additionally, XAMG provides extended functionality to solve systems with
multiple right-hand side vectors.
</summary>
    <author>
      <name>Boris Krasnopolsky</name>
    </author>
    <author>
      <name>Alexey Medvedev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2021.100695</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2021.100695" rel="related"/>
    <link href="http://arxiv.org/abs/2103.07329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.07329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.11191v2</id>
    <updated>2021-03-23T10:58:39Z</updated>
    <published>2021-03-20T14:51:46Z</published>
    <title>FEniCS-preCICE: Coupling FEniCS to other Simulation Software</title>
    <summary>  The new software FEniCS-preCICE is a middle software layer, sitting in
between the existing finite-element library FEniCS and the coupling library
preCICE. The middle layer simplifies coupling (existing) FEniCS application
codes to other simulation software via preCICE. To this end, FEniCS-preCICE
converts between FEniCS and preCICE mesh and data structures, provides
easy-to-use coupling conditions, and manages data checkpointing for implicit
coupling. The new software is a library itself and follows a FEniCS-native
style. Only a few lines of additional code are necessary to prepare a FEniCS
application code for coupling. We illustrate the functionality of
FEniCS-preCICE by two examples: a FEniCS heat conduction code coupled to
OpenFOAM and a FEniCS linear elasticity code coupled to SU2. The results of
both scenarios are compared with other simulation software showing good
agreement.
</summary>
    <author>
      <name>Benjamin Rodenberg</name>
    </author>
    <author>
      <name>Ishaan Desai</name>
    </author>
    <author>
      <name>Richard Hertrich</name>
    </author>
    <author>
      <name>Alexander Jaust</name>
    </author>
    <author>
      <name>Benjamin Uekermann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to SoftwareX, fixed layout of Fig. 3 &amp; 4, updated reference
  to code examples to https://github.com/precice/tutorials/tree/a166efa</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.11191v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.11191v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.11991v1</id>
    <updated>2021-03-22T16:36:12Z</updated>
    <published>2021-03-22T16:36:12Z</published>
    <title>Kokkos Kernels: Performance Portable Sparse/Dense Linear Algebra and
  Graph Kernels</title>
    <summary>  As hardware architectures are evolving in the push towards exascale,
developing Computational Science and Engineering (CSE) applications depend on
performance portable approaches for sustainable software development. This
paper describes one aspect of performance portability with respect to
developing a portable library of kernels that serve the needs of several CSE
applications and software frameworks. We describe Kokkos Kernels, a library of
kernels for sparse linear algebra, dense linear algebra and graph kernels. We
describe the design principles of such a library and demonstrate portable
performance of the library using some selected kernels. Specifically, we
demonstrate the performance of four sparse kernels, three dense batched
kernels, two graph kernels and one team level algorithm.
</summary>
    <author>
      <name>Sivasankaran Rajamanickam</name>
    </author>
    <author>
      <name>Seher Acer</name>
    </author>
    <author>
      <name>Luc Berger-Vergiat</name>
    </author>
    <author>
      <name>Vinh Dang</name>
    </author>
    <author>
      <name>Nathan Ellingwood</name>
    </author>
    <author>
      <name>Evan Harvey</name>
    </author>
    <author>
      <name>Brian Kelley</name>
    </author>
    <author>
      <name>Christian R. Trott</name>
    </author>
    <author>
      <name>Jeremiah Wilke</name>
    </author>
    <author>
      <name>Ichitaro Yamazaki</name>
    </author>
    <link href="http://arxiv.org/abs/2103.11991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.11991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.12067v1</id>
    <updated>2021-03-21T16:27:51Z</updated>
    <published>2021-03-21T16:27:51Z</published>
    <title>Understanding performance variability in standard and pipelined parallel
  Krylov solvers</title>
    <summary>  In this work, we collect data from runs of Krylov subspace methods and
pipelined Krylov algorithms in an effort to understand and model the impact of
machine noise and other sources of variability on performance. We find large
variability of Krylov iterations between compute nodes for standard methods
that is reduced in pipelined algorithms, directly supporting conjecture, as
well as large variation between statistical distributions of runtimes across
iterations. Based on these results, we improve upon a previously introduced
nondeterministic performance model by allowing iterations to fluctuate over
time. We present our data from runs of various Krylov algorithms across
multiple platforms as well as our updated non-stationary model that provides
good agreement with observations. We also suggest how it can be used as a
predictive tool.
</summary>
    <author>
      <name>Hannah Morgan</name>
    </author>
    <author>
      <name>Patrick Sanan</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Richard Tran Mills</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1177/1094342020966835</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1177/1094342020966835" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 12 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJHPCA, 35(1), 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2103.12067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.12067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.13756v3</id>
    <updated>2022-06-29T10:33:18Z</updated>
    <published>2021-03-25T11:13:27Z</published>
    <title>The landscape of software for tensor computations</title>
    <summary>  Tensors (also commonly seen as multi-linear operators or as multi-dimensional
arrays) are ubiquitous in scientific computing and in data science, and so are
the software efforts for tensor operations. Particularly in recent years, we
have observed an explosion in libraries, compilers, packages, and toolboxes;
unfortunately these efforts are very much scattered among the different
scientific domains, and inevitably suffer from replication, suboptimal
implementations, and in many cases, limited visibility. As a first step towards
countering these inefficiencies, here we survey and loosely classify software
packages related to tensor computations. Our aim is to assemble a comprehensive
and up-to-date snapshot of the tensor software landscape, with the intention of
helping both users and developers. Aware of the difficulties inherent in any
multi-discipline survey, we very much welcome the reader's help in amending and
expanding our software list, which currently features 80 projects.
</summary>
    <author>
      <name>Christos Psarras</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Lars Karlsson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Umeå University</arxiv:affiliation>
    </author>
    <author>
      <name>Jiajia Li</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pacific Northwest National Laboratory</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">College of William and Mary</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Umeå University</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/2103.13756v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.13756v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.15203v1</id>
    <updated>2021-03-28T19:11:28Z</updated>
    <published>2021-03-28T19:11:28Z</published>
    <title>Mathematics of Digital Hyperspace</title>
    <summary>  Social media, e-commerce, streaming video, e-mail, cloud documents, web
pages, traffic flows, and network packets fill vast digital lakes, rivers, and
oceans that we each navigate daily. This digital hyperspace is an amorphous
flow of data supported by continuous streams that stretch standard concepts of
type and dimension. The unstructured data of digital hyperspace can be
elegantly represented, traversed, and transformed via the mathematics of
hypergraphs, hypersparse matrices, and associative array algebra. This paper
explores a novel mathematical concept, the semilink, that combines pairs of
semirings to provide the essential operations for graph analytics, database
operations, and machine learning. The GraphBLAS standard currently supports
hypergraphs, hypersparse matrices, the mathematics required for semilinks, and
seamlessly performs graph, network, and matrix operations. With the addition of
key based indices (such as pointers to strings) and semilinks, GraphBLAS can
become a richer associative array algebra and be a plug-in replacement for
spreadsheets, database tables, and data centric operating systems, enhancing
the navigation of unstructured data found in digital hyperspace.
</summary>
    <author>
      <name>Jeremy Kepner</name>
    </author>
    <author>
      <name>Timothy Davis</name>
    </author>
    <author>
      <name>Vijay Gadepally</name>
    </author>
    <author>
      <name>Hayden Jananthan</name>
    </author>
    <author>
      <name>Lauren Milechin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/IPDPSW52791.2021.00048</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/IPDPSW52791.2021.00048" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures, 2 tables, accepted to GrAPL 2021. arXiv admin
  note: text overlap with arXiv:1807.03165, arXiv:2004.01181, arXiv:1909.05631,
  arXiv:1708.02937</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.15203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.15203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.16034v1</id>
    <updated>2021-03-30T02:41:40Z</updated>
    <published>2021-03-30T02:41:40Z</published>
    <title>TensorDiffEq: Scalable Multi-GPU Forward and Inverse Solvers for Physics
  Informed Neural Networks</title>
    <summary>  Physics-Informed Neural Networks promise to revolutionize science and
engineering practice, by introducing domain-aware deep machine learning models
into scientific computation. Several software suites have emerged to make the
implementation and usage of these architectures available to the research and
industry communities. Here we introduce\linebreak TensorDiffEq, built on
Tensorflow 2.x, which presents an intuitive Keras-like interface for problem
domain definition, model definition, and solution of forward and inverse
problems using physics-aware deep learning methods. TensorDiffEq takes full
advantage of Tensorflow 2.x infrastructure for deployment on multiple GPUs,
allowing the implementation of large high-dimensional and complex models.
Simultaneously, TensorDiffEq supports the Keras API for custom neural network
architecture definitions. In the case of smaller or simpler models, the package
allows for rapid deployment on smaller-scale CPU platforms with negligible
changes to the implementation scripts. We demonstrate the basic usage and
capabilities of TensorDiffEq in solving forward, inverse, and data assimilation
problems of varying sizes and levels of complexity. The source code is
available at https://github.com/tensordiffeq.
</summary>
    <author>
      <name>Levi D. McClenny</name>
    </author>
    <author>
      <name>Mulugeta A. Haile</name>
    </author>
    <author>
      <name>Ulisses M. Braga-Neto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Source Code: https://github.com/tensordiffeq/TensorDiffEq,
  Documentation: https://docs.tensordiffeq.io</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.16034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.16034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.01661v1</id>
    <updated>2021-04-04T18:49:58Z</updated>
    <published>2021-04-04T18:49:58Z</published>
    <title>LAGraph: Linear Algebra, Network Analysis Libraries, and the Study of
  Graph Algorithms</title>
    <summary>  Graph algorithms can be expressed in terms of linear algebra. GraphBLAS is a
library of low-level building blocks for such algorithms that targets algorithm
developers. LAGraph builds on top of the GraphBLAS to target users of graph
algorithms with high-level algorithms common in network analysis. In this
paper, we describe the first release of the LAGraph library, the design
decisions behind the library, and performance using the GAP benchmark suite.
LAGraph, however, is much more than a library. It is also a project to document
and analyze the full range of algorithms enabled by the GraphBLAS. To that end,
we have developed a compact and intuitive notation for describing these
algorithms. In this paper, we present that notation with examples from the GAP
benchmark suite.
</summary>
    <author>
      <name>Gábor Szárnyas</name>
    </author>
    <author>
      <name>David A. Bader</name>
    </author>
    <author>
      <name>Timothy A. Davis</name>
    </author>
    <author>
      <name>James Kitchen</name>
    </author>
    <author>
      <name>Timothy G. Mattson</name>
    </author>
    <author>
      <name>Scott McMillan</name>
    </author>
    <author>
      <name>Erik Welch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to GrAPL 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.01661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.01661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.01965v1</id>
    <updated>2021-04-05T15:36:17Z</updated>
    <published>2021-04-05T15:36:17Z</published>
    <title>AuTO: A Framework for Automatic differentiation in Topology Optimization</title>
    <summary>  A critical step in topology optimization (TO) is finding sensitivities.
Manual derivation and implementation of the sensitivities can be quite
laborious and error-prone, especially for non-trivial objectives, constraints
and material models. An alternate approach is to utilize automatic
differentiation (AD). While AD has been around for decades, and has also been
applied in TO, wider adoption has largely been absent.
  In this educational paper, we aim to reintroduce AD for TO, and make it
easily accessible through illustrative codes. In particular, we employ JAX, a
high-performance Python library for automatically computing sensitivities from
a user defined TO problem. The resulting framework, referred to here as AuTO,
is illustrated through several examples in compliance minimization, compliant
mechanism design and microstructural design.
</summary>
    <author>
      <name>Aaditya Chandrasekhar</name>
    </author>
    <author>
      <name>Saketh Sridhara</name>
    </author>
    <author>
      <name>Krishnan Suresh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00158-021-03025-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00158-021-03025-8" rel="related"/>
    <link href="http://arxiv.org/abs/2104.01965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.01965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.04043v1</id>
    <updated>2021-04-08T20:37:17Z</updated>
    <published>2021-04-08T20:37:17Z</published>
    <title>RLIBM-32: High Performance Correctly Rounded Math Libraries for 32-bit
  Floating Point Representations</title>
    <summary>  This paper proposes a set of techniques to develop correctly rounded math
libraries for 32-bit float and posit types. It enhances our RLibm approach that
frames the problem of generating correctly rounded libraries as a linear
programming problem in the context of 16-bit types to scale to 32-bit types.
Specifically, this paper proposes new algorithms to (1) generate polynomials
that produce correctly rounded outputs for all inputs using counterexample
guided polynomial generation, (2) generate efficient piecewise polynomials with
bit-pattern based domain splitting, and (3) deduce the amount of freedom
available to produce correct results when range reduction involves multiple
elementary functions. The resultant math library for the 32-bit float type is
faster than state-of-the-art math libraries while producing the correct output
for all inputs. We have also developed a set of correctly rounded elementary
functions for 32-bit posits.
</summary>
    <author>
      <name>Jay P. Lim</name>
    </author>
    <author>
      <name>Santosh Nagarakatte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.04043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.04043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.05782v1</id>
    <updated>2021-04-12T19:15:36Z</updated>
    <published>2021-04-12T19:15:36Z</published>
    <title>Efficient algorithms for computing a rank-revealing UTV factorization on
  parallel computing architectures</title>
    <summary>  The randomized singular value decomposition (RSVD) is by now a well
established technique for efficiently computing an approximate singular value
decomposition of a matrix. Building on the ideas that underpin the RSVD, the
recently proposed algorithm "randUTV" computes a FULL factorization of a given
matrix that provides low-rank approximations with near-optimal error. Because
the bulk of randUTV is cast in terms of communication-efficient operations like
matrix-matrix multiplication and unpivoted QR factorizations, it is faster than
competing rank-revealing factorization methods like column pivoted QR in most
high performance computational settings. In this article, optimized randUTV
implementations are presented for both shared memory and distributed memory
computing environments. For shared memory, randUTV is redesigned in terms of an
"algorithm-by-blocks" that, together with a runtime task scheduler, eliminates
bottlenecks from data synchronization points to achieve acceleration over the
standard "blocked algorithm", based on a purely fork-join approach. The
distributed memory implementation is based on the ScaLAPACK library. The
performances of our new codes compare favorably with competing factorizations
available on both shared memory and distributed memory architectures.
</summary>
    <author>
      <name>N. Heavner</name>
    </author>
    <author>
      <name>F. D. Igual</name>
    </author>
    <author>
      <name>G. Quintana-Ortí</name>
    </author>
    <author>
      <name>P. G. Martinsson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages and 20 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.05782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.05782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.4; C.4; D.1.3; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.05999v1</id>
    <updated>2021-04-13T08:06:48Z</updated>
    <published>2021-04-13T08:06:48Z</published>
    <title>Parallelized Discrete Exterior Calculus for Three-Dimensional Elliptic
  Problems</title>
    <summary>  A formulation of elliptic boundary value problems is used to develop the
first discrete exterior calculus (DEC) library for massively parallel
computations with 3D domains. This can be used for steady-state analysis of any
physical process driven by the gradient of a scalar quantity, e.g. temperature,
concentration, pressure or electric potential, and is easily extendable to
transient analysis. In addition to offering this library to the community, we
demonstrate one important benefit from the DEC formulation: effortless
introduction of strong heterogeneities and discontinuities. These are typical
for real materials, but challenging for widely used domain discretization
schemes, such as finite elements. Specifically, we demonstrate the efficiency
of the method for calculating the evolution of thermal conductivity of a solid
with a growing crack population. Future development of the library will deal
with transient problems, and more importantly with processes driven by
gradients of vector quantities.
</summary>
    <author>
      <name>Pieter D. Boom</name>
    </author>
    <author>
      <name>Ashley Seepujak</name>
    </author>
    <author>
      <name>Odysseas Kosmas</name>
    </author>
    <author>
      <name>Lee Margetts</name>
    </author>
    <author>
      <name>Andrey Jivkov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2022.108456</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2022.108456" rel="related"/>
    <link href="http://arxiv.org/abs/2104.05999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.05999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.08416v1</id>
    <updated>2021-04-17T01:27:38Z</updated>
    <published>2021-04-17T01:27:38Z</published>
    <title>Boosting Memory Access Locality of the Spectral Element Method with
  Hilbert Space-Filling Curves</title>
    <summary>  We propose an algorithm based on Hilbert space-filling curves to reorder mesh
elements in memory for use with the Spectral Element Method, aiming to attain
fewer cache misses, better locality of data reference and faster execution. We
present a technique to numerically simulate acoustic wave propagation in 2D
domains using the Spectral Element Method, and discuss computational
performance aspects of this procedure. We reorder mesh-related data via Hilbert
curves to achieve sizable reductions in execution time under several mesh
configurations in shared-memory systems. Our experiments show that the Hilbert
curve approach works well with meshes of several granularities and also with
small and large variations in element sizes, achieving reductions between 9%
and 25% in execution time when compared to three other ordering schemes.
</summary>
    <author>
      <name>Roger R. F. Araújo</name>
    </author>
    <author>
      <name>Lutz Gross</name>
    </author>
    <author>
      <name>Samuel Xavier-de-Souza</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cageo.2021.104938</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cageo.2021.104938" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.08416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.08416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86-08 (Primary), 35Q68, 35Q86 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.00385v2</id>
    <updated>2021-05-29T04:20:30Z</updated>
    <published>2021-05-02T03:08:53Z</published>
    <title>pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models</title>
    <summary>  Bayesian Knowledge Tracing, a model used for cognitive mastery estimation,
has been a hallmark of adaptive learning research and an integral component of
deployed intelligent tutoring systems (ITS). In this paper, we provide a brief
history of knowledge tracing model research and introduce pyBKT, an accessible
and computationally efficient library of model extensions from the literature.
The library provides data generation, fitting, prediction, and cross-validation
routines, as well as a simple to use data helper interface to ingest typical
tutor log dataset formats. We evaluate the runtime with various dataset sizes
and compare to past implementations. Additionally, we conduct sanity checks of
the model using experiments with simulated data to evaluate the accuracy of its
EM parameter learning and use real-world data to validate its predictions,
comparing pyBKT's supported model variants with results from the papers in
which they were originally introduced. The library is open source and open
license for the purpose of making knowledge tracing more accessible to
communities of research and practice and to facilitate progress in the field
through easier replication of past approaches.
</summary>
    <author>
      <name>Anirudhan Badrinath</name>
    </author>
    <author>
      <name>Frederic Wang</name>
    </author>
    <author>
      <name>Zachary Pardos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 2021 Conference on Educational Data Mining (EDM '21)</arxiv:comment>
    <link href="http://arxiv.org/abs/2105.00385v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.00385v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.11534v1</id>
    <updated>2021-05-07T11:22:13Z</updated>
    <published>2021-05-07T11:22:13Z</published>
    <title>ReLie: a Reduce program for Lie group analysis of differential equations</title>
    <summary>  Lie symmetry analysis provides a general theoretical framework for
investigating ordinary and partial differential equations. The theory is
completely algorithmic even if it usually involves lengthy computations. For
this reason, many computer algebra packages have been developed along the years
to automate the computation. In this paper, we describe the program ReLie,
written in the Computer Algebra System Reduce, which since 2008 is an open
source program (http://www.reduce-algebra.com) and is available for all
platforms. \relie is able to perform almost automatically the needed
computations for Lie symmetry analysis of differential equations. Its source
code is freely available at the url http://mat521.unime.it/oliveri. The use of
the program is illustrated by means of some simple examples; nevertheless, it
is to be underlined that it provides effective also for more complex
computations where one has to deal with very large expressions.
</summary>
    <author>
      <name>Francesco Oliveri</name>
    </author>
    <link href="http://arxiv.org/abs/2105.11534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.11534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34-04, 34A05, 35-04, 58J70, 58J72" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.08777v3</id>
    <updated>2023-06-12T07:55:16Z</updated>
    <published>2021-06-16T13:36:17Z</published>
    <title>Manifolds.jl: An Extensible Julia Framework for Data Analysis on
  Manifolds</title>
    <summary>  We present the Julia package Manifolds$.$jl, providing a fast and easy-to-use
library of Riemannian manifolds and Lie groups. This package enables working
with data defined on a Riemannian manifold, such as the circle, the sphere,
symmetric positive definite matrices, or one of the models for hyperbolic
spaces. We introduce a common interface, available in ManifoldsBase$.$jl, with
which new manifolds, applications, and algorithms can be implemented. We
demonstrate the utility of Manifolds$.$jl using B\'ezier splines, an
optimization task on manifolds, and principal component analysis on nonlinear
data. In a benchmark, Manifolds$.$jl outperforms all comparable packages for
low-dimensional manifolds in speed; over Python and Matlab packages, the
improvement is often several orders of magnitude, while over C/C++ packages,
the improvement is two-fold. For high-dimensional manifolds, it outperforms all
packages except for Tensorflow-Riemopt, which is specifically tailored for
high-dimensional manifolds.
</summary>
    <author>
      <name>Seth D. Axen</name>
    </author>
    <author>
      <name>Mateusz Baran</name>
    </author>
    <author>
      <name>Ronny Bergmann</name>
    </author>
    <author>
      <name>Krzysztof Rzecki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3618296</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3618296" rel="related"/>
    <link href="http://arxiv.org/abs/2106.08777v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.08777v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.11594v1</id>
    <updated>2021-06-22T07:59:35Z</updated>
    <published>2021-06-22T07:59:35Z</published>
    <title>Efficient recursive least squares solver for rank-deficient matrices</title>
    <summary>  Updating a linear least squares solution can be critical for near real-time
signalprocessing applications. The Greville algorithm proposes a simple formula
for updating the pseudoinverse of a matrix A $\in$ R nxm with rank r. In this
paper, we explicitly derive a similar formula by maintaining a general rank
factorization, which we call rank-Greville. Based on this formula, we
implemented a recursive least squares algorithm exploiting the rank-deficiency
of A, achieving the update of the minimum-norm least-squares solution in O(mr)
operations and, therefore, solving the linear least-squares problem from
scratch in O(nmr) operations. We empirically confirmed that this algorithm
displays a better asymptotic time complexity than LAPACK solvers for
rank-deficient matrices. The numerical stability of rank-Greville was found to
be comparable to Cholesky-based solvers. Nonetheless, our implementation
supports exact numerical representations of rationals, due to its remarkable
algebraic simplicity.
</summary>
    <author>
      <name>Ruben Staub</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LC</arxiv:affiliation>
    </author>
    <author>
      <name>Stephan N. Steinmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.amc.2021.125996</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.amc.2021.125996" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematics and Computation, Elsevier, 2021, 399,
  pp.125996</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2106.11594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.11594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.13879v2</id>
    <updated>2022-04-28T16:01:59Z</updated>
    <published>2021-06-25T20:41:50Z</published>
    <title>Optimal Checkpointing for Adjoint Multistage Time-Stepping Schemes</title>
    <summary>  We consider checkpointing strategies that minimize the number of
recomputations needed when performing discrete adjoint computations using
multistage time-stepping schemes, which requires computing several substeps
within one complete time step. In this case we propose two algorithms that can
generate optimal checkpointing schedules under weak assumptions. The first is
an extension of the seminal Revolve algorithm adapted to multistage schemes.
The second algorithm, named CAMS, is developed based on dynamic programming,
and it requires the least number of recomputations when compared with other
algorithms. The CAMS algorithm is made publicly available in a library with
bindings to C and Python. Numerical results illustrate that the proposed
algorithms can deliver up to two times the speedup compared with that of
classical Revolve. Moreover, we discuss a tailored implementation of an adjoint
computation that is arguably better suited for mature scientific computing
libraries by avoiding the central control assumed by the original checkpointing
strategy. The proposed algorithms have been adopted by the PETSc TSAdjoint
library. Their performance has been demonstrated with a large-scale
PDE-constrained optimization problem on a leadership-class supercomputer.
</summary>
    <author>
      <name>Hong Zhang</name>
    </author>
    <author>
      <name>Emil Constantinescu</name>
    </author>
    <link href="http://arxiv.org/abs/2106.13879v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.13879v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.02025v1</id>
    <updated>2021-08-04T12:51:12Z</updated>
    <published>2021-08-04T12:51:12Z</published>
    <title>High-Performance Level-1 and Level-2 BLAS</title>
    <summary>  The introduction of the Basic Linear Algebra Subroutine (BLAS) in the 1970s
paved the way for different libraries to solve the same problem with an
improved approach and hardware. The new BLAS implementation led to
High-Performance Computing (HPC) innovation. All the love went to the level 3
BLAS due to its humongous application in different fields, not bounded by
computer science. However, level 1 and level 2 got neglected; we tried to solve
the problem by introducing the new algorithm for the Vector-Vector dot product,
Vector-Vector outer product and Matrix-Vector product, which improves the
performance of these operations in a significant way. We are not introducing
any library but algorithms, which improves upon the current state of art
algorithms. Also, we rely on the FMA instruction, OpenMP, and the compiler to
optimize the code rather than implementing the algorithm in assembly.
Therefore, our current implementation is machine oblivious and depends on the
compilers ability to optimize the code.
</summary>
    <author>
      <name>Amit Singh</name>
    </author>
    <author>
      <name>Cem Bassoy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.02025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.02025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q17(Primary), 15A99(Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.06476v2</id>
    <updated>2022-01-15T09:13:02Z</updated>
    <published>2021-08-14T06:20:32Z</published>
    <title>Adaptive numerical simulations with Trixi.jl: A case study of Julia for
  scientific computing</title>
    <summary>  We present Trixi.jl, a Julia package for adaptive high-order numerical
simulations of hyperbolic partial differential equations. Utilizing Julia's
strengths, Trixi.jl is extensible, easy to use, and fast. We describe the main
design choices that enable these features and compare Trixi.jl with a mature
open source Fortran code that uses the same numerical methods. We conclude with
an assessment of Julia for simulation-focused scientific computing, an area
that is still dominated by traditional high-performance computing languages
such as C, C++, and Fortran.
</summary>
    <author>
      <name>Hendrik Ranocha</name>
    </author>
    <author>
      <name>Michael Schlottke-Lakemper</name>
    </author>
    <author>
      <name>Andrew R. Winters</name>
    </author>
    <author>
      <name>Erik Faulhaber</name>
    </author>
    <author>
      <name>Jesse Chan</name>
    </author>
    <author>
      <name>Gregor J. Gassner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/jcon.00077</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/jcon.00077" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the JuliaCon Conferences, 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2108.06476v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.06476v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.12981v2</id>
    <updated>2024-02-09T13:07:00Z</updated>
    <published>2021-08-30T03:49:21Z</published>
    <title>The ensmallen library for flexible numerical optimization</title>
    <summary>  We overview the ensmallen numerical optimization library, which provides a
flexible C++ framework for mathematical optimization of user-supplied objective
functions. Many types of objective functions are supported, including general,
differentiable, separable, constrained, and categorical. A diverse set of
pre-built optimizers is provided, including Quasi-Newton optimizers and many
variants of Stochastic Gradient Descent. The underlying framework facilitates
the implementation of new optimizers. Optimization of an objective function
typically requires supplying only one or two C++ functions. Custom behavior can
be easily specified via callback functions. Empirical comparisons show that
ensmallen outperforms other frameworks while providing more functionality. The
library is available at https://ensmallen.org and is distributed under the
permissive BSD license.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Rahul Ganesh Prabhu</name>
    </author>
    <author>
      <name>Suryoday Basak</name>
    </author>
    <author>
      <name>Zhihao Lou</name>
    </author>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research, Vol. 22, No. 166, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2108.12981v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.12981v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65K10, 68N99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.3; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.00740v1</id>
    <updated>2021-09-02T06:42:56Z</updated>
    <published>2021-09-02T06:42:56Z</published>
    <title>dbcsp: User-friendly R package for Distance-Based Common Spacial
  Patterns</title>
    <summary>  Common Spacial Patterns (CSP) is a widely used method to analyse
electroencephalography (EEG) data, concerning the supervised classification of
brain's activity. More generally, it can be useful to distinguish between
multivariate signals recorded during a time span for two different classes. CSP
is based on the simultaneous diagonalization of the average covariance matrices
of signals from both classes and it allows to project the data into a
low-dimensional subspace. Once data are represented in a low-dimensional
subspace, a classification step must be carried out. The original CSP method is
based on the Euclidean distance between signals and here, we extend it so that
it can be applied on any appropriate distance for data at hand. Both, the
classical CSP and the new Distance-Based CSP (DB-CSP) are implemented in an R
package, called dbcsp.
</summary>
    <author>
      <name>Itsaso Rodriguez</name>
    </author>
    <author>
      <name>Itziar Irigoien</name>
    </author>
    <author>
      <name>Basilio Sierra</name>
    </author>
    <author>
      <name>Concepcion Arenas</name>
    </author>
    <link href="http://arxiv.org/abs/2109.00740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.00740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.01158v2</id>
    <updated>2022-05-10T11:07:48Z</updated>
    <published>2021-08-22T21:00:21Z</published>
    <title>Fast MATLAB evaluation of nonlinear energies using FEM in 2D and 3D:
  nodal elements</title>
    <summary>  Nonlinear energy functionals appearing in the calculus of variations can be
discretized by the finite element (FE) method and formulated as a sum of energy
contributions from local elements. A fast evaluation of energy functionals
containing the first order gradient terms is a central part of this
contribution. We describe a vectorized implementation using the simplest linear
nodal (P1) elements in which all energy contributions are evaluated all at once
without the loop over triangular or tetrahedral elements. Furthermore, in
connection to the first-order optimization methods, the discrete gradient of
energy functional is assembled in a way that the gradient components are
evaluated over all degrees of freedom all at once. The key ingredient is the
vectorization of exact or approximate energy gradients over nodal patches. It
leads to a time-efficient implementation at higher memory-cost. Provided codes
in MATLAB related to 2D/3D hyperelasticity and 2D p-Laplacian problem are
available for download and structured in a way it can be easily extended to
other types of vector or scalar forms of energies.
</summary>
    <author>
      <name>Alexej Moskovka</name>
    </author>
    <author>
      <name>Jan Valdman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.amc.2022.127048</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.amc.2022.127048" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 9 figures Before the article was published, some minor
  changes were applied based on the reviewers' comments</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematics and Computation, Volume 424, 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2109.01158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.01158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.04193v1</id>
    <updated>2021-09-06T00:31:23Z</updated>
    <published>2021-09-06T00:31:23Z</published>
    <title>OGRe: An Object-Oriented General Relativity Package for Mathematica</title>
    <summary>  We present OGRe, a modern Mathematica package for tensor calculus, designed
to be both powerful and user-friendly. The package can be used in a variety of
contexts where tensor calculations are needed, in both mathematics and physics,
but it is especially suitable for general relativity. By implementing an
object-oriented design paradigm, OGRe allows calculating arbitrarily
complicated tensor formulas easily, and automatically transforms between index
configurations and coordinate systems behind the scenes as needed, eliminating
user errors by making it impossible for the user to combine tensors in
inconsistent ways. Other features include displaying tensors in various forms,
automatic calculation of curvature tensors and geodesic equations, easy
importing and exporting of tensors between sessions, optimized algorithms and
parallelization for improved performance, and more.
</summary>
    <author>
      <name>Barak Shoshany</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/joss.03416</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/joss.03416" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">92 pages, source code available at https://github.com/bshoshany/OGRe</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Open Source Software, 6(65), 3416 (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2109.04193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.04193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.12449v2</id>
    <updated>2022-02-04T22:28:20Z</updated>
    <published>2021-09-25T22:19:12Z</published>
    <title>AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming
  in Julia</title>
    <summary>  No single Automatic Differentiation (AD) system is the optimal choice for all
problems. This means informed selection of an AD system and combinations can be
a problem-specific variable that can greatly impact performance. In the Julia
programming language, the major AD systems target the same input and thus in
theory can compose. Hitherto, switching between AD packages in the Julia
Language required end-users to familiarize themselves with the user-facing API
of the respective packages. Furthermore, implementing a new, usable AD package
required AD package developers to write boilerplate code to define convenience
API functions for end-users. As a response to these issues, we present
AbstractDifferentiation.jl for the automatized generation of an extensive,
unified, user-facing API for any AD package. By splitting the complexity
between AD users and AD developers, AD package developers only need to
implement one or two primitive definitions to support various utilities for AD
users like Jacobians, Hessians and lazy product operators from native
primitives such as pullbacks or pushforwards, thus removing tedious -- but so
far inevitable -- boilerplate code, and enabling the easy switching and
composing between AD implementations for end-users.
</summary>
    <author>
      <name>Frank Schäfer</name>
    </author>
    <author>
      <name>Mohamed Tarek</name>
    </author>
    <author>
      <name>Lyndon White</name>
    </author>
    <author>
      <name>Chris Rackauckas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 figures, 2 tables 15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.12449v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.12449v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.01711v2</id>
    <updated>2021-12-21T17:45:01Z</updated>
    <published>2021-10-04T20:50:47Z</published>
    <title>LazySets.jl: Scalable Symbolic-Numeric Set Computations</title>
    <summary>  LazySets.jl is a Julia library that provides ways to symbolically represent
sets of points as geometric shapes, with a special focus on convex sets and
polyhedral approximations. LazySets provides methods to apply common set
operations, convert between different set representations, and efficiently
compute with sets in high dimensions using specialized algorithms based on the
set types. LazySets is the core library of JuliaReach, a cutting-edge software
addressing the fundamental problem of reachability analysis: computing the set
of states that are reachable by a dynamical system from all initial states and
for all admissible inputs and parameters. While the library was originally
designed for reachability and formal verification, its scope goes beyond such
topics. LazySets is an easy-to-use, general-purpose and scalable library for
computations that mix symbolics and numerics. In this article we showcase the
basic functionality, highlighting some of the key design choices.
</summary>
    <author>
      <name>Marcelo Forets</name>
    </author>
    <author>
      <name>Christian Schilling</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/jcon.00097</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/jcon.00097" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in the Proceedings of the JuliaCon Conferences 2021</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JuliaCon Proceedings (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2110.01711v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.01711v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.06215v1</id>
    <updated>2021-10-12T16:24:39Z</updated>
    <published>2021-10-12T16:24:39Z</published>
    <title>A Cross-Platform Benchmark for Interval Computation Libraries</title>
    <summary>  Interval computation is widely used to certify computations that use floating
point operations to avoid pitfalls related to rounding error introduced by
inaccurate operations. Despite its popularity and practical benefits, support
for interval arithmetic is not standardized nor available in mainstream
programming languages. We propose the first benchmark for interval
computations, coupled with reference solutions computed with exact arithmetic,
and compare popular C and C++ libraries over different architectures, operating
systems, and compilers. The benchmark allows identifying limitations in
existing implementations, and provides a reliable guide on which library to use
on each system. We believe that our benchmark will be useful for developers of
future interval libraries, as a way to test the correctness and performance of
their algorithms.
</summary>
    <author>
      <name>Xuan Tang</name>
    </author>
    <author>
      <name>Zachary Ferguson</name>
    </author>
    <author>
      <name>Teseo Schneider</name>
    </author>
    <author>
      <name>Denis Zorin</name>
    </author>
    <author>
      <name>Shoaib Kamil</name>
    </author>
    <author>
      <name>Daniele Panozzo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-30445-3_35</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-30445-3_35" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 33 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Parallel Processing and Applied Mathematics. PPAM 2022. Lecture
  Notes in Computer Science, vol 13827. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2110.06215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.06215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.10151v1</id>
    <updated>2021-10-18T23:01:07Z</updated>
    <published>2021-10-18T23:01:07Z</published>
    <title>Can Fortran's 'do concurrent' replace directives for accelerated
  computing?</title>
    <summary>  Recently, there has been growing interest in using standard language
constructs (e.g. C++'s Parallel Algorithms and Fortran's do concurrent) for
accelerated computing as an alternative to directive-based APIs (e.g. OpenMP
and OpenACC). These constructs have the potential to be more portable, and some
compilers already (or have plans to) support such standards. Here, we look at
the current capabilities, portability, and performance of replacing directives
with Fortran's do concurrent using a mini-app that currently implements OpenACC
for GPU-acceleration and OpenMP for multi-core CPU parallelism. We replace as
many directives as possible with do concurrent, testing various configurations
and compiler options within three major compilers: GNU's gfortran, NVIDIA's
nvfortran, and Intel's ifort. We find that with the right compiler versions and
flags, many directives can be replaced without loss of performance or
portability, and, in the case of nvfortran, they can all be replaced. We
discuss limitations that may apply to more complicated codes and future
language additions that may mitigate them. The software and Singularity
containers are publicly provided to allow the results to be reproduced.
</summary>
    <author>
      <name>Miko M. Stulajter</name>
    </author>
    <author>
      <name>Ronald M. Caplan</name>
    </author>
    <author>
      <name>Jon A. Linker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 2 figures, Accepted for publication at WACCPD 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2110.10151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.10151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; D.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.12875v1</id>
    <updated>2021-10-17T20:42:18Z</updated>
    <published>2021-10-17T20:42:18Z</published>
    <title>Two-dimensional mesh generator in generalized coordinates implemented in
  Python</title>
    <summary>  Through mathematical models, it is possible to turn a problem of the physical
domain into the computational domain. In this context, the paper presents a
two-dimensional mesh generator in generalized coordinates, which uses the
Parametric Linear Spline method and partial differential equations. The
generator is automated and able to treat real complex domains. The code was
implemented in Python, applying the Numpy and Matplotlib libraries to matrix
manipulations and graphical plots, respectively. Applications are made for
monoblock meshes (two-dimensional shape of a bottle) and multi-block meshes
(geometry of Igap\'o I lake, Londrina, Paran\'a, Brazil).
</summary>
    <author>
      <name>Gustavo Taiji Naozuka</name>
    </author>
    <author>
      <name>Saulo Martiello Mastelini</name>
    </author>
    <author>
      <name>Eliandro Rodrigues Cirilo</name>
    </author>
    <author>
      <name>Neyva Maria Lopes Romeiro</name>
    </author>
    <author>
      <name>Paulo Laerte Natti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5433/1679-0375.2021v42n1p29</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5433/1679-0375.2021v42n1p29" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Semina: Exact and Technological Sciences, v.42, n.1, p.29-44,
  Jan./June2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2110.12875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.12875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.00945v1</id>
    <updated>2021-11-01T13:38:38Z</updated>
    <published>2021-11-01T13:38:38Z</published>
    <title>Escaping the abstraction: a foreign function interface for the Unified
  Form Language [UFL]</title>
    <summary>  High level domain specific languages for the finite element method underpin
high productivity programming environments for simulations based on partial
differential equations (PDE) while employing automatic code generation to
achieve high performance. However, a limitation of this approach is that it
does not support operators that are not directly expressible in the vector
calculus. This is critical in applications where PDEs are not enough to
accurately describe the physical problem of interest. The use of deep learning
techniques have become increasingly popular in filling this knowledge gap, for
example to include features not represented in the differential equations, or
closures for unresolved spatiotemporal scales. We introduce an interface within
the Firedrake finite element system that enables a seamless interface with deep
learning models. This new feature composes with the automatic differentiation
capabilities of Firedrake, enabling the automated solution of inverse problems.
Our implementation interfaces with PyTorch and can be extended to other machine
learning libraries. The resulting framework supports complex models coupling
PDEs and deep learning whilst maintaining separation of concerns between
application scientists and software experts.
</summary>
    <author>
      <name>Nacime Bouziani</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First Workshop on Differentiable Programming (NeurIPS 2021)</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.00945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.00945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.01861v1</id>
    <updated>2021-11-02T19:40:59Z</updated>
    <published>2021-11-02T19:40:59Z</published>
    <title>Source-to-Source Automatic Differentiation of OpenMP Parallel Loops</title>
    <summary>  This paper presents our work toward correct and efficient automatic
differentiation of OpenMP parallel worksharing loops in forward and reverse
mode. Automatic differentiation is a method to obtain gradients of numerical
programs, which are crucial in optimization, uncertainty quantification, and
machine learning. The computational cost to compute gradients is a common
bottleneck in practice. For applications that are parallelized for multicore
CPUs or GPUs using OpenMP, one also wishes to compute the gradients in
parallel. We propose a framework to reason about the correctness of the
generated derivative code, from which we justify our OpenMP extension to the
differentiation model. We implement this model in the automatic differentiation
tool Tapenade and present test cases that are differentiated following our
extended differentiation procedure. Performance of the generated derivative
programs in forward and reverse mode is better than sequential, although our
reverse mode often scales worse than the input programs.
</summary>
    <author>
      <name>Jan Hückelheim</name>
    </author>
    <author>
      <name>Laurent Hascoët</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ACM TOMS</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.01861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.01861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.05207v1</id>
    <updated>2021-11-09T15:33:30Z</updated>
    <published>2021-11-09T15:33:30Z</published>
    <title>Computing Sparse Jacobians and Hessians Using Algorithmic
  Differentiation</title>
    <summary>  Stochastic scientific models and machine learning optimization estimators
have a large number of variables; hence computing large sparse Jacobians and
Hessians is important. Algorithmic differentiation (AD) greatly reduces the
programming effort required to obtain the sparsity patterns and values for
these matrices. We present forward, reverse, and subgraph methods for computing
sparse Jacobians and Hessians. Special attention is given the the subgraph
method because it is new. The coloring and compression steps are not necessary
when computing sparse Jacobians and Hessians using subgraphs. Complexity
analysis shows that for some problems the subgraph method is expected to be
much faster. We compare C++ operator overloading implementations of the methods
in the ADOL-C and CppAD software packages using some of the MINPACK-2 test
problems. The experiments are set up in a way that makes them easy to run on
different hardware, different systems, different compilers, other test problem
and other AD packages. The setup time is the time to record the graph, compute
sparsity, coloring, compression, and optimization of the graph. If the setup is
necessary for each evaluation, the subgraph implementation has similar run
times for sparse Jacobians and faster run times for sparse Hessians.
</summary>
    <author>
      <name>Bradley M. Bell</name>
    </author>
    <author>
      <name>Kasper Kristensen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.05207v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.05207v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C15, 65F50, 90C30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.05269v1</id>
    <updated>2021-11-04T04:02:44Z</updated>
    <published>2021-11-04T04:02:44Z</published>
    <title>A set of R packages to estimate population counts from mobile phone data</title>
    <summary>  In this paper, we describe the software implementation of the methodological
framework designed to incorporate mobile phone data into the current production
chain of official statistics during the ESSnet Big Data II project. We present
an overview of the architecture of the software stack, its components, the
interfaces between them, and show how they can be used. Our software
implementation consists in four R packages: destim for estimation of the
spatial distribution of the mobile devices, deduplication for classification of
the devices as being in 1:1 or 2:1 correspondence with its owner, aggregation
for estimation of the number of individuals detected by the network starting
from the geolocation probabilities and the duplicity probabilities and
inference which combines the number of individuals provided by the previous
package with other information like the population counts from an official
register and the mobile operator penetration rates to provide an estimation of
the target population counts.
</summary>
    <author>
      <name>Bogdan Oancea</name>
    </author>
    <author>
      <name>David Salgado</name>
    </author>
    <author>
      <name>Luis Sanguiao Sande</name>
    </author>
    <author>
      <name>Sandra Barragan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ROMANIAN STATISTICAL REVIEW, Issue 1, Page 17-38, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2111.05269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.05269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.12852v2</id>
    <updated>2022-03-17T04:01:21Z</updated>
    <published>2021-11-25T00:19:27Z</published>
    <title>RLIBM-PROG: Progressive Polynomial Approximations for Fast Correctly
  Rounded Math Libraries</title>
    <summary>  This paper presents a novel method for generating a single polynomial
approximation that produces correctly rounded results for all inputs of an
elementary function for multiple representations. The generated polynomial
approximation has the nice property that the first few lower degree terms
produce correctly rounded results for specific representations of smaller
bitwidths, which we call progressive performance. To generate such progressive
polynomial approximations, we approximate the correctly rounded result and
formulate the computation of correctly rounded polynomial approximations as a
linear program similar to our prior work on the RLibm project. To enable the
use of resulting polynomial approximations in mainstream libraries, we want to
avoid piecewise polynomials with large lookup tables. We observe that the
problem of computing polynomial approximations for elementary functions is a
linear programming problem in low dimensions, i.e., with a small number of
unknowns. We design a fast randomized algorithm for computing polynomial
approximations with progressive performance. Our method produces correct and
fast polynomials that require a small amount of storage. A few polynomial
approximations from our prototype have already been incorporated into LLVM's
math library.
</summary>
    <author>
      <name>Mridul Aanjaneya</name>
    </author>
    <author>
      <name>Jay P. Lim</name>
    </author>
    <author>
      <name>Santosh Nagarakatte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.12852v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.12852v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.15662v1</id>
    <updated>2021-11-30T18:53:54Z</updated>
    <published>2021-11-30T18:53:54Z</published>
    <title>HOTTBOX: Higher Order Tensor ToolBOX</title>
    <summary>  HOTTBOX is a Python library for exploratory analysis and visualisation of
multi-dimensional arrays of data, also known as tensors. The library includes
methods ranging from standard multi-way operations and data manipulation
through to multi-linear algebra based tensor decompositions. HOTTBOX also
comprises sophisticated algorithms for generalised multi-linear classification
and data fusion, such as Support Tensor Machine (STM) and Tensor Ensemble
Learning (TEL). For user convenience, HOTTBOX offers a unifying API which
establishes a self-sufficient ecosystem for various forms of efficient
representation of multi-way data and the corresponding decomposition and
association algorithms. Particular emphasis is placed on scalability and
interactive visualisation, to support multidisciplinary data analysis
communities working on big data and tensors. HOTTBOX also provides means for
integration with other popular data science libraries for visualisation and
data manipulation. The source code, examples and documentation ca be found at
https://github.com/hottbox/hottbox.
</summary>
    <author>
      <name>Ilya Kisil</name>
    </author>
    <author>
      <name>Giuseppe G. Calvi</name>
    </author>
    <author>
      <name>Bruno S. Dees</name>
    </author>
    <author>
      <name>Danilo P. Mandic</name>
    </author>
    <link href="http://arxiv.org/abs/2111.15662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.15662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.02100v1</id>
    <updated>2021-12-03T07:20:50Z</updated>
    <published>2021-12-03T07:20:50Z</published>
    <title>ProbNum: Probabilistic Numerics in Python</title>
    <summary>  Probabilistic numerical methods (PNMs) solve numerical problems via
probabilistic inference. They have been developed for linear algebra,
optimization, integration and differential equation simulation. PNMs naturally
incorporate prior information about a problem and quantify uncertainty due to
finite computational resources as well as stochastic input. In this paper, we
present ProbNum: a Python library providing state-of-the-art probabilistic
numerical solvers. ProbNum enables custom composition of PNMs for specific
problem classes via a modular design as well as wrappers for off-the-shelf use.
Tutorials, documentation, developer guides and benchmarks are available online
at www.probnum.org.
</summary>
    <author>
      <name>Jonathan Wenger</name>
    </author>
    <author>
      <name>Nicholas Krämer</name>
    </author>
    <author>
      <name>Marvin Pförtner</name>
    </author>
    <author>
      <name>Jonathan Schmidt</name>
    </author>
    <author>
      <name>Nathanael Bosch</name>
    </author>
    <author>
      <name>Nina Effenberger</name>
    </author>
    <author>
      <name>Johannes Zenn</name>
    </author>
    <author>
      <name>Alexandra Gessner</name>
    </author>
    <author>
      <name>Toni Karvonen</name>
    </author>
    <author>
      <name>François-Xavier Briol</name>
    </author>
    <author>
      <name>Maren Mahsereci</name>
    </author>
    <author>
      <name>Philipp Hennig</name>
    </author>
    <link href="http://arxiv.org/abs/2112.02100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.02100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.03985v1</id>
    <updated>2021-12-07T20:58:30Z</updated>
    <published>2021-12-07T20:58:30Z</published>
    <title>Accelerating jackknife resampling for the Canonical Polyadic
  Decomposition</title>
    <summary>  The Canonical Polyadic (CP) tensor decomposition is frequently used as a
model in applications in a variety of different fields. Using jackknife
resampling to estimate parameter uncertainties is often desirable but results
in an increase of the already high computational cost. Upon observation that
the resampled tensors, though different, are nearly identical, we show that it
is possible to extend the recently proposed Concurrent ALS (CALS) technique to
a jackknife resampling scenario. This extension gives access to the
computational efficiency advantage of CALS for the price of a modest increase
(typically a few percent) in the number of floating point operations. Numerical
experiments on both synthetic and real-world datasets demonstrate that the new
workflow based on a CALS extension can be several times faster than a
straightforward workflow where the jackknife submodels are processed
individually.
</summary>
    <author>
      <name>Christos Psarras</name>
    </author>
    <author>
      <name>Lars Karlsson</name>
    </author>
    <author>
      <name>Rasmus Bro</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3389/fams.2022.830270</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3389/fams.2022.830270" rel="related"/>
    <link href="http://arxiv.org/abs/2112.03985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.03985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.07075v1</id>
    <updated>2021-12-14T00:25:12Z</updated>
    <published>2021-12-14T00:25:12Z</published>
    <title>Matrix-free approaches for GPU acceleration of a high-order finite
  element hydrodynamics application using MFEM, Umpire, and RAJA</title>
    <summary>  With the introduction of advanced heterogeneous computing architectures based
on GPU accelerators, large-scale production codes have had to rethink their
numerical algorithms and incorporate new programming models and memory
management strategies in order to run efficiently on the latest supercomputers.
In this work we discuss our co-design strategy to address these challenges and
achieve performance and portability with MARBL, a next-generation multi-physics
code in development at Lawrence Livermore National Laboratory. We present a
two-fold approach, wherein new hardware is used to motivate both new algorithms
and new abstraction layers, resulting in a single source application code
suitable for a variety of platforms. Focusing on MARBL's ALE hydrodynamics
package, we demonstrate scalability on different platforms and highlight that
many of our innovations have been contributed back to open-source software
libraries, such as MFEM (finite element algorithms) and RAJA (kernel
abstractions).
</summary>
    <author>
      <name>Arturo Vargas</name>
    </author>
    <author>
      <name>Thomas M. Stitt</name>
    </author>
    <author>
      <name>Kenneth Weiss</name>
    </author>
    <author>
      <name>Vladimir Z. Tomov</name>
    </author>
    <author>
      <name>Jean-Sylvain Camier</name>
    </author>
    <author>
      <name>Tzanio Kolev</name>
    </author>
    <author>
      <name>Robert N. Rieben</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to The International Journal of High Performance Computing
  Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.07075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.07075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.0; F.2; G.4; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.10517v2</id>
    <updated>2023-09-19T06:55:12Z</updated>
    <published>2021-12-20T13:25:37Z</published>
    <title>Efficient implementation of modern entropy stable and kinetic energy
  preserving discontinuous Galerkin methods for conservation laws</title>
    <summary>  Many modern discontinuous Galerkin (DG) methods for conservation laws make
use of summation by parts operators and flux differencing to achieve kinetic
energy preservation or entropy stability. While these techniques increase the
robustness of DG methods significantly, they are also computationally more
demanding than standard weak form nodal DG methods. We present several
implementation techniques to improve the efficiency of flux differencing DG
methods that use tensor product quadrilateral or hexahedral elements, in 2D or
3D respectively. Focus is mostly given to CPUs and DG methods for the
compressible Euler equations, although these techniques are generally also
useful for other physical systems including the compressible Navier-Stokes and
magnetohydrodynamics equations. We present results using two open source codes,
Trixi.jl written in Julia and FLUXO written in Fortran, to demonstrate that our
proposed implementation techniques are applicable to different code bases and
programming languages.
</summary>
    <author>
      <name>Hendrik Ranocha</name>
    </author>
    <author>
      <name>Michael Schlottke-Lakemper</name>
    </author>
    <author>
      <name>Jesse Chan</name>
    </author>
    <author>
      <name>Andrés M. Rueda-Ramírez</name>
    </author>
    <author>
      <name>Andrew R. Winters</name>
    </author>
    <author>
      <name>Florian Hindenlang</name>
    </author>
    <author>
      <name>Gregor J. Gassner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3625559</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3625559" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2112.10517v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.10517v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.11508v2</id>
    <updated>2022-02-08T15:21:40Z</updated>
    <published>2021-12-21T20:22:34Z</published>
    <title>PyTracer: Automatically profiling numerical instabilities in Python</title>
    <summary>  Numerical stability is a crucial requirement of reliable scientific
computing. However, despite the pervasiveness of Python in data science,
analyzing large Python programs remains challenging due to the lack of scalable
numerical analysis tools available for this language. To fill this gap, we
developed PyTracer, a profiler to quantify numerical instability in Python
applications. PyTracer transparently instruments Python code to produce
numerical traces and visualize them interactively in a Plotly dashboard. We
designed PyTracer to be agnostic to numerical noise model, allowing for tool
evaluation through Monte-Carlo Arithmetic, random rounding, random data
perturbation, or structured noise for a particular application. We illustrate
PyTracer's capabilities by testing the numerical stability of key functions in
both SciPy and Scikit-learn, two dominant Python libraries for mathematical
modeling. Through these evaluations, we demonstrate PyTracer as a scalable,
automatic, and generic framework for numerical profiling in Python.
</summary>
    <author>
      <name>Yohan Chatelain</name>
    </author>
    <author>
      <name>Nigel Yong</name>
    </author>
    <author>
      <name>Gregory Kiar</name>
    </author>
    <author>
      <name>Tristan Glatard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been submitted to the IEEE for possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.11508v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.11508v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.11918v1</id>
    <updated>2021-12-17T06:36:58Z</updated>
    <published>2021-12-17T06:36:58Z</published>
    <title>An eXtended Finite Element Method Implementation in COMSOL Multiphysics:
  Thermo-Hydro-Mechanical Modeling of Fluid Flow in Discontinuous Porous Media</title>
    <summary>  This paper presents the implementation of the eXtended Finite Element Method
(XFEM) in the general-purpose commercial software package COMSOL Multiphysics
for multi-field thermo-hydro-mechanical problems in discontinuous porous media.
To this end, an exclusive enrichment strategy is proposed in compliance with
the COMSOL modeling structure. COMSOL modules and physics interfaces are
adopted to take account of the relevant physical processes involved in
thermo-hydro-mechanical coupling analysis, namely: the mechanical deformation,
fluid flow in porous media and heat transfer. Essential changes are made to the
internal variables of the physics interfaces to ensure consistency in the
evaluation of enriched solution fields. The model preprocessing, level-set
updates, coupling of the relevant physics and postprocessing procedures are
performed adopting a coherent utilization of the COMSOL built-in features along
with the COMSOL LiveLink for MATLAB functions. The implementation process,
remedies for the treatment of the enriched zones, XFEM framework setup,
multiphysics coupling, numerical integration and numerical solution strategy
are described in detail. The capabilities and performance of the proposed
approach are investigated by examining several multi-field
thermo-hydro-mechanical simulations involving single/multiple discontinuities
in 2D/3D porous rock settings.
</summary>
    <author>
      <name>Ahmad Jafari</name>
    </author>
    <author>
      <name>Mohammad Vahab</name>
    </author>
    <author>
      <name>Pooyan Broumand</name>
    </author>
    <author>
      <name>Nasser Khalili</name>
    </author>
    <link href="http://arxiv.org/abs/2112.11918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.11918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.09314v3</id>
    <updated>2023-10-09T19:37:45Z</updated>
    <published>2022-03-17T13:36:06Z</published>
    <title>The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids
  for high-dimensional function approximation and uncertainty quantification</title>
    <summary>  The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids,
and can be used for approximating high-dimensional functions and, in
particular, for surrogate-model-based uncertainty quantification. It is
lightweight, high-level and easy to use, good for quick prototyping and
teaching; however, it is equipped with some features that allow its use also in
realistic applications. The goal of this paper is to provide an overview of the
data structure and of the mathematical aspects forming the basis of the
software, as well as comparing the current release of our package to similar
available software.
</summary>
    <author>
      <name>Chiara Piazzola</name>
    </author>
    <author>
      <name>Lorenzo Tamellini</name>
    </author>
    <link href="http://arxiv.org/abs/2203.09314v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.09314v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.03775v1</id>
    <updated>2022-04-07T23:27:51Z</updated>
    <published>2022-04-07T23:27:51Z</published>
    <title>Massively scalable stencil algorithm</title>
    <summary>  Stencil computations lie at the heart of many scientific and industrial
applications. Unfortunately, stencil algorithms perform poorly on machines with
cache based memory hierarchy, due to low re-use of memory accesses. This work
shows that for stencil computation a novel algorithm that leverages a localized
communication strategy effectively exploits the Cerebras WSE-2, which has no
cache hierarchy. This study focuses on a 25-point stencil finite-difference
method for the 3D wave equation, a kernel frequently used in earth modeling as
numerical simulation. In essence, the algorithm trades memory accesses for data
communication and takes advantage of the fast communication fabric provided by
the architecture. The algorithm -- historically memory bound -- becomes compute
bound. This allows the implementation to achieve near perfect weak scaling,
reaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can
eventually yield.
</summary>
    <author>
      <name>Mathias Jacquelin</name>
    </author>
    <author>
      <name>Mauricio Araya-Polo</name>
    </author>
    <author>
      <name>Jie Meng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages excl. bibliography. Submitted to SuperComputing 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.03775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.03775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.12120v2</id>
    <updated>2022-04-27T06:50:57Z</updated>
    <published>2022-04-26T07:26:36Z</published>
    <title>Automated Generation of High-Performance Computational Fluid Dynamics
  Codes</title>
    <summary>  Domain-Specific Languages (DSLs) improve programmers productivity by
decoupling problem descriptions from algorithmic implementations. However, DSLs
for High-Performance Computing (HPC) have two additional critical requirements:
performance and scalability. This paper presents the automated process of
generating, from abstract mathematical specifications of Computational Fluid
Dynamics (CFD) problems, optimised parallel codes that perform and scale as
manually optimised ones. We consciously combine within Saiph, a DSL for solving
CFD problems, low-level optimisations and parallelisation strategies, enabling
high-performance single-core executions which effectively scale to multi-core
and distributed environments. Our results demonstrate how high-level DSLs can
offer competitive performance by transparently leveraging state-of-the-art HPC
techniques.
</summary>
    <author>
      <name>Sandra Macià</name>
    </author>
    <author>
      <name>Pedro J. Martıínez-Ferrer</name>
    </author>
    <author>
      <name>Eduard Ayguadé</name>
    </author>
    <author>
      <name>Vicenç Beltran</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jocs.2022.101664</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jocs.2022.101664" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 18 figures. Postprint submitted to the Journal of
  Computational Science (Elsevier). Article updated with reviewers' comments,
  additional material in section 4.3 including figures and correction of typos</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Science Volume 61, May 2022, 101664</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2204.12120v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.12120v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.2386v1</id>
    <updated>2008-03-17T02:38:49Z</updated>
    <published>2008-03-17T02:38:49Z</published>
    <title>Conformal Computing: Algebraically connecting the hardware/software
  boundary using a uniform approach to high-performance computation for
  software and hardware applications</title>
    <summary>  We present a systematic, algebraically based, design methodology for
efficient implementation of computer programs optimized over multiple levels of
the processor/memory and network hierarchy. Using a common formalism to
describe the problem and the partitioning of data over processors and memory
levels allows one to mathematically prove the efficiency and correctness of a
given algorithm as measured in terms of a set of metrics (such as
processor/network speeds, etc.). The approach allows the average programmer to
achieve high-level optimizations similar to those used by compiler writers
(e.g. the notion of "tiling").
  The approach presented in this monograph makes use of A Mathematics of Arrays
(MoA, Mullin 1988) and an indexing calculus (i.e. the psi-calculus) to enable
the programmer to develop algorithms using high-level compiler-like
optimizations through the ability to algebraically compose and reduce sequences
of array operations. Extensive discussion and benchmark results are presented
for the Fast Fourier Transform and other important algorithms.
</summary>
    <author>
      <name>Lenore R. Mullin</name>
    </author>
    <author>
      <name>James E. Raynolds</name>
    </author>
    <link href="http://arxiv.org/abs/0803.2386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.2386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4136v3</id>
    <updated>2012-01-15T21:34:56Z</updated>
    <published>2011-05-20T17:29:57Z</published>
    <title>A novel parallel algorithm for Gaussian Elimination of sparse
  unsymmetric matrices</title>
    <summary>  We describe a new algorithm for Gaussian Elimination suitable for general
(unsymmetric and possibly singular) sparse matrices, of any entry type, which
has a natural parallel and distributed-memory formulation but degrades
gracefully to sequential execution.
  We present a sample MPI implementation of a program computing the rank of a
sparse integer matrix using the proposed algorithm. Some preliminary
performance measurements are presented and discussed, and the performance of
the algorithm is compared to corresponding state-of-the-art algorithms for
floating-point and integer matrices.
</summary>
    <author>
      <name>Riccardo Murri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages; 2 PDF figures; LaTeX2e; final version submitted for the
  PPAM2011 conference proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4136v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4136v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F50, 65F05, 68W10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.4; I.1.2; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0530v4</id>
    <updated>2013-09-26T12:09:42Z</updated>
    <published>2012-10-01T01:04:04Z</published>
    <title>Best Practices for Scientific Computing</title>
    <summary>  Scientists spend an increasing amount of time building and using software.
However, most scientists are never taught how to do this efficiently. As a
result, many are unaware of tools and practices that would allow them to write
more reliable and maintainable code with less effort. We describe a set of best
practices for scientific software development that have solid foundations in
research and experience, and that improve scientists' productivity and the
reliability of their software.
</summary>
    <author>
      <name>Greg Wilson</name>
    </author>
    <author>
      <name>D. A. Aruliah</name>
    </author>
    <author>
      <name>C. Titus Brown</name>
    </author>
    <author>
      <name>Neil P. Chue Hong</name>
    </author>
    <author>
      <name>Matt Davis</name>
    </author>
    <author>
      <name>Richard T. Guy</name>
    </author>
    <author>
      <name>Steven H. D. Haddock</name>
    </author>
    <author>
      <name>Katy Huff</name>
    </author>
    <author>
      <name>Ian M. Mitchell</name>
    </author>
    <author>
      <name>Mark Plumbley</name>
    </author>
    <author>
      <name>Ben Waugh</name>
    </author>
    <author>
      <name>Ethan P. White</name>
    </author>
    <author>
      <name>Paul Wilson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pbio.1001745</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pbio.1001745" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLOS Biology 12(1): e1001745, Jan 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.0530v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0530v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2536v1</id>
    <updated>2012-10-09T09:19:43Z</updated>
    <published>2012-10-09T09:19:43Z</published>
    <title>SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner</title>
    <summary>  Sparse matrix vector multiplication (SpMV) is an important kernel in
scientific and engineering applications. The previous optimizations are sparse
matrix format specific and expose the choice of the best format to application
programmers. In this work we develop an auto-tuning framework to bridge gap
between the specific optimized kernels and their general-purpose use. We
propose an SpMV auto-tuner (SMAT) that provides an unified interface based on
compressed sparse row (CSR) to programmers by implicitly choosing the best
format and the fastest implementation of any input sparse matrix in runtime.
SMAT leverage a data mining model, which is formulated based on a set of
performance parameters extracted from 2373 matrices in UF sparse matrix
collection, to fast search the best combination. The experiments show that SMAT
achieves the maximum performance of 75 GFLOP/s in single-precision and 33
GFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34
GFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL
library, SMAT runs faster by more than 3 times.
</summary>
    <author>
      <name>Jiajia Li</name>
    </author>
    <author>
      <name>Xiuxia Zhang</name>
    </author>
    <author>
      <name>Guangming Tan</name>
    </author>
    <author>
      <name>Mingyu Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1210.2536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6293v1</id>
    <updated>2012-10-23T17:15:03Z</updated>
    <published>2012-10-23T17:15:03Z</published>
    <title>MLPACK: A Scalable C++ Machine Learning Library</title>
    <summary>  MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning
library released in late 2011 offering both a simple, consistent API accessible
to novice users and high performance and flexibility to expert users by
leveraging modern features of C++. MLPACK provides cutting-edge algorithms
whose benchmarks exhibit far better performance than other leading machine
learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available
at http://www.mlpack.org.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>James R. Cline</name>
    </author>
    <author>
      <name>N. P. Slagle</name>
    </author>
    <author>
      <name>William B. March</name>
    </author>
    <author>
      <name>Parikshit Ram</name>
    </author>
    <author>
      <name>Nishant A. Mehta</name>
    </author>
    <author>
      <name>Alexander G. Gray</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to JMLR MLOSS (http://jmlr.csail.mit.edu/mloss/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research 14 (2013) 801-805</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7325v1</id>
    <updated>2012-10-27T14:26:32Z</updated>
    <published>2012-10-27T14:26:32Z</published>
    <title>Solving Sequences of Generalized Least-Squares Problems on
  Multi-threaded Architectures</title>
    <summary>  Generalized linear mixed-effects models in the context of genome-wide
association studies (GWAS) represent a formidable computational challenge: the
solution of millions of correlated generalized least-squares problems, and the
processing of terabytes of data. We present high performance in-core and
out-of-core shared-memory algorithms for GWAS: By taking advantage of
domain-specific knowledge, exploiting multi-core parallelism, and handling data
efficiently, our algorithms attain unequalled performance. When compared to
GenABEL, one of the most widely used libraries for GWAS, on a 12-core processor
we obtain 50-fold speedups. As a consequence, our routines enable genome
studies of unprecedented size.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Yurii Aulchenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute of Cytology and Genetics SD RAS</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1210.7325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1295v3</id>
    <updated>2016-12-07T00:50:35Z</updated>
    <published>2013-06-06T05:08:44Z</published>
    <title>MathGR: a tensor and GR computation package to keep it simple</title>
    <summary>  We introduce the MathGR package, written in Mathematica. The package can
manipulate tensor and GR calculations with either abstract or explicit indices,
simplify tensors with permutational symmetries, decompose tensors from abstract
indices to partially or completely explicit indices and convert partial
derivatives into total derivatives. Frequently used GR tensors and a model of
FRW universe with ADM type perturbations are predefined. The package is built
around the philosophy to "keep it simple", and makes use of latest tensor
technologies of Mathematica.
</summary>
    <author>
      <name>Yi Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures; v2: version to match updated software; v3: Ibp
  part updated to match behavior of code</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.1295v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1295v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01073v1</id>
    <updated>2015-02-27T08:48:24Z</updated>
    <published>2015-02-27T08:48:24Z</published>
    <title>T3PS: Tool for Parallel Processing in Parameter Scans</title>
    <summary>  T3PS is a program that can be used to quickly design and perform parameter
scans while easily taking advantage of the multi-core architecture of current
processors. It takes an easy to read and write parameter scan definition file
format as input. Based on the parameter ranges and other options contained
therein, it distributes the calculation of the parameter space over multiple
processes and possibly computers. The derived data is saved in a plain text
file format readable by most plotting software. The supported scanning
strategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical
optimization. Several example parameter scans are shown and compared with
results in the literature.
</summary>
    <author>
      <name>Vinzenz Maurer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, 7 figures, available for download at
  http://t3ps.hepforge.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.01073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06544v2</id>
    <updated>2015-03-24T00:53:39Z</updated>
    <published>2015-03-23T07:45:09Z</published>
    <title>GAIL---Guaranteed Automatic Integration Library in MATLAB: Documentation
  for Version 2.1</title>
    <summary>  Automatic and adaptive approximation, optimization, or integration of
functions in a cone with guarantee of accuracy is a relatively new paradigm.
Our purpose is to create an open-source MATLAB package, Guaranteed Automatic
Integration Library (GAIL), following the philosophy of reproducible research
and sustainable practices of robust scientific software development. For our
conviction that true scholarship in computational sciences are characterized by
reliable reproducibility, we employ the best practices in mathematical research
and software engineering known to us and available in MATLAB. This document
describes the key features of functions in GAIL, which includes one-dimensional
function approximation and minimization using linear splines, one-dimensional
numerical integration using trapezoidal rule, and last but not least, mean
estimation and multidimensional integration by Monte Carlo methods or Quasi
Monte Carlo methods.
</summary>
    <author>
      <name>Sou-Cheng T. Choi</name>
    </author>
    <author>
      <name>Yuhan Ding</name>
    </author>
    <author>
      <name>Fred J. Hickernell</name>
    </author>
    <author>
      <name>Lan Jiang</name>
    </author>
    <author>
      <name>Lluís Antoni Jiménez Rugama</name>
    </author>
    <author>
      <name>Xin Tong</name>
    </author>
    <author>
      <name>Yizhi Zhang</name>
    </author>
    <author>
      <name>Xuan Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1503.06544v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06544v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.08376v1</id>
    <updated>2015-03-29T01:51:49Z</updated>
    <published>2015-03-29T01:51:49Z</published>
    <title>Assessing Excel VBA Suitability for Monte Carlo Simulation</title>
    <summary>  Monte Carlo (MC) simulation includes a wide range of stochastic techniques
used to quantitatively evaluate the behavior of complex systems or processes.
Microsoft Excel spreadsheets with Visual Basic for Applications (VBA) software
is, arguably, the most commonly employed general purpose tool for MC
simulation. Despite the popularity of the Excel in many industries and
educational institutions, it has been repeatedly criticized for its flaws and
often described as questionable, if not completely unsuitable, for statistical
problems. The purpose of this study is to assess suitability of the Excel
(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC
simulation. The results of the study indicate that Microsoft Excel (versions
2010 and 2013) is a strong Monte Carlo simulation application offering a solid
framework of core simulation components including spreadsheets for data input
and output, VBA development environment and summary statistics functions. This
framework should be complemented with an external high-quality pseudo-random
number generator added as a VBA module. A large and diverse category of Excel
incidental simulation components that includes statistical distributions,
linear and non-linear regression and other statistical, engineering and
business functions require execution of due diligence to determine their
suitability for a specific MC project.
</summary>
    <author>
      <name>Alexei Botchkarev</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Spreadsheets in Education (eJSiE): 2015, Vol. 8: Iss. 2, Article 3</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.08376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.08376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.00903v2</id>
    <updated>2017-11-13T15:18:19Z</updated>
    <published>2017-11-02T19:45:33Z</published>
    <title>Acceleration of tensor-product operations for high-order finite element
  methods</title>
    <summary>  This paper is devoted to GPU kernel optimization and performance analysis of
three tensor-product operators arising in finite element methods. We provide a
mathematical background to these operations and implementation details.
Achieving close-to-the-peak performance for these operators requires extensive
optimization because of the operators' properties: low arithmetic intensity,
tiered structure, and the need to store intermediate results inside the kernel.
We give a guided overview of optimization strategies and we present a
performance model that allows us to compare the efficacy of these optimizations
against an empirically calibrated roofline.
</summary>
    <author>
      <name>Kasia Świrydowicz</name>
    </author>
    <author>
      <name>Noel Chalmers</name>
    </author>
    <author>
      <name>Ali Karakus</name>
    </author>
    <author>
      <name>Timothy Warburton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.00903v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.00903v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.02473v1</id>
    <updated>2017-11-07T14:18:07Z</updated>
    <published>2017-11-07T14:18:07Z</published>
    <title>Exposing and exploiting structure: optimal code generation for
  high-order finite element methods</title>
    <summary>  Code generation based software platforms, such as Firedrake, have become
popular tools for developing complicated finite element discretisations of
partial differential equations. We extended the code generation infrastructure
in Firedrake with optimisations that can exploit the structure inherent to some
finite elements. This includes sum factorisation on cuboid cells for
continuous, discontinuous, H(div) and H(curl) conforming elements. Our
experiments confirm optimal algorithmic complexity for high-order finite
element assembly. This is achieved through several novel contributions: the
introduction of a more powerful interface between the form compiler and the
library providing the finite elements; a more abstract, smarter library of
finite elements called FInAT that explicitly communicates the structure of
elements; and form compiler algorithms to automatically exploit this exposed
structure.
</summary>
    <author>
      <name>Miklós Homolya</name>
    </author>
    <author>
      <name>Robert C. Kirby</name>
    </author>
    <author>
      <name>David A. Ham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM Transactions on Mathematical Software</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.02473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.02473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.02712v1</id>
    <updated>2017-11-07T20:15:24Z</updated>
    <published>2017-11-07T20:15:24Z</published>
    <title>Tangent: Automatic Differentiation Using Source Code Transformation in
  Python</title>
    <summary>  Automatic differentiation (AD) is an essential primitive for machine learning
programming systems. Tangent is a new library that performs AD using source
code transformation (SCT) in Python. It takes numeric functions written in a
syntactic subset of Python and NumPy as input, and generates new Python
functions which calculate a derivative. This approach to automatic
differentiation is different from existing packages popular in machine
learning, such as TensorFlow and Autograd. Advantages are that Tangent
generates gradient code in Python which is readable by the user, easy to
understand and debug, and has no runtime overhead. Tangent also introduces
abstractions for easily injecting logic into the generated gradient code,
further improving usability.
</summary>
    <author>
      <name>Bart van Merriënboer</name>
    </author>
    <author>
      <name>Alexander B. Wiltschko</name>
    </author>
    <author>
      <name>Dan Moldovan</name>
    </author>
    <link href="http://arxiv.org/abs/1711.02712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.02712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.03590v1</id>
    <updated>2017-11-09T20:36:06Z</updated>
    <published>2017-11-09T20:36:06Z</published>
    <title>Fast matrix-free evaluation of discontinuous Galerkin finite element
  operators</title>
    <summary>  We present an algorithmic framework for matrix-free evaluation of
discontinuous Galerkin finite element operators based on sum factorization on
quadrilateral and hexahedral meshes. We identify a set of kernels for fast
quadrature on cells and faces targeting a wide class of weak forms originating
from linear and nonlinear partial differential equations. Different algorithms
and data structures for the implementation of operator evaluation are compared
in an in-depth performance analysis. The sum factorization kernels are
optimized by vectorization over several cells and faces and an even-odd
decomposition of the one-dimensional compute kernels. In isolation our
implementation then reaches up to 60\% of arithmetic peak on Intel Haswell and
Broadwell processors and up to 50\% of arithmetic peak on Intel Knights
Landing. The full operator evaluation reaches only about half that throughput
due to memory bandwidth limitations from loading the input and output vectors,
MPI ghost exchange, as well as handling variable coefficients and the geometry.
Our performance analysis shows that the results are often within 10\% of the
available memory bandwidth for the proposed implementation, with the exception
of the Cartesian mesh case where the cost of gather operations and MPI
communication are more substantial.
</summary>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <author>
      <name>Katharina Kormann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3325864</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3325864" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software 45(3), 29/1-29/40, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1711.03590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.03590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.05677v2</id>
    <updated>2017-11-23T10:09:02Z</updated>
    <published>2017-11-15T17:13:36Z</published>
    <title>PQSER: A Matlab package for spectral seriation</title>
    <summary>  The seriation problem is an important ordering issue which consists of
finding the best ordering of a set of units whose interrelationship is defined
by a bipartite graph. It has important applications in, e.g., archaeology,
anthropology, psychology, and biology. This paper presents a Matlab
implementation of an algorithm for spectral seriation by Atkins et al., based
on the use of the Fiedler vector of the Laplacian matrix associated to the
problem, which encodes the set of admissible solutions into a PQ-tree. We
introduce some numerical technicalities in the original algorithm to improve
its performance, and point out that the presence of a multiple Fiedler value
may have a substantial influence on the computation of an approximated
solution, in the presence of inconsistent data sets. Practical examples and
numerical experiments show how to use the toolbox to process data sets deriving
from real-world applications.
</summary>
    <author>
      <name>Anna Concas</name>
    </author>
    <author>
      <name>Caterina Fenu</name>
    </author>
    <author>
      <name>Giuseppe Rodriguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.05677v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.05677v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F15, 65F50, 05C82, 91D30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.05683v2</id>
    <updated>2017-11-16T01:44:12Z</updated>
    <published>2017-11-15T17:19:29Z</published>
    <title>Hydra: a C++11 framework for data analysis in massively parallel
  platforms</title>
    <summary>  Hydra is a header-only, templated and C++11-compliant framework designed to
perform the typical bottleneck calculations found in common HEP data analyses
on massively parallel platforms. The framework is implemented on top of the
C++11 Standard Library and a variadic version of the Thrust library and is
designed to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.
This contribution summarizes the main features of Hydra. A basic description of
the overall design, functionality and user interface is provided, along with
some code examples and measurements of performance.
</summary>
    <author>
      <name>A. A. Alves Jr</name>
    </author>
    <author>
      <name>M. D. Sokoloff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACAT 2017 Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.05683v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.05683v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.06581v1</id>
    <updated>2017-11-17T15:10:25Z</updated>
    <published>2017-11-17T15:10:25Z</published>
    <title>A generic and fast C++ optimization framework</title>
    <summary>  The development of the mlpack C++ machine learning library
(http://www.mlpack.org/) has required the design and implementation of a
flexible, robust optimization system that is able to solve the types of
arbitrary optimization problems that may arise all throughout machine learning
problems. In this paper, we present the generic optimization framework that we
have designed for mlpack. A key priority in the design was ease of
implementation of both new optimizers and new objective functions to be
optimized; therefore, implementation of a new optimizer requires only one
method and implementation of a new objective function requires at most four
functions. This leads to simple and intuitive code, which, for fast prototyping
and experimentation, is of paramount importance. When compared to optimization
frameworks of other libraries, we find that mlpack's supports more types of
objective functions, is able to make optimizations that other frameworks do
not, and seamlessly supports user-defined objective functions and optimizers.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Shikhar Bhardwaj</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Yannis Mentekidis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages + references submitted to MLSYS 2017 workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.06581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.06581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.09886v2</id>
    <updated>2018-03-22T13:52:09Z</updated>
    <published>2017-11-25T18:25:44Z</published>
    <title>Efficiently and easily integrating differential equations with JiTCODE,
  JiTCDDE, and JiTCSDE</title>
    <summary>  We present a family of Python modules for the numerical integration of
ordinary, delay, or stochastic differential equations. The key features are
that the user enters the derivative symbolically and it is
just-in-time-compiled, allowing the user to efficiently integrate differential
equations from a higher-level interpreted language. The presented modules are
particularly suited for large systems of differential equations such as used to
describe dynamics on complex networks. Through the selected method of input,
the presented modules also allow to almost completely automatize the process of
estimating regular as well as transversal Lyapunov exponents for ordinary and
delay differential equations. We conceptually discuss the modules' design,
analyze their performance, and demonstrate their capabilities by application to
timely problems.
</summary>
    <author>
      <name>Gerrit Ansmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.5019320</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.5019320" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 28, 043116 (2018)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1711.09886v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.09886v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.10188v1</id>
    <updated>2017-11-28T09:06:44Z</updated>
    <published>2017-11-28T09:06:44Z</published>
    <title>Abaqus2Matlab: A suitable tool for finite element post-processing</title>
    <summary>  A suitable piece of software is presented to connect Abaqus, a sophisticated
finite element package, with Matlab, the most comprehensive program for
mathematical analysis. This interface between these well-known codes not only
benefits from the image processing and the integrated graph-plotting features
of Matlab but also opens up new opportunities in results post-processing,
statistical analysis and mathematical optimization, among many other
possibilities. The software architecture and usage are appropriately described
and two problems of particular engineering significance are addressed to
demonstrate its capabilities. Firstly, the software is employed to assess
cleavage fracture through a novel 3-parameter Weibull probabilistic framework.
Then, its potential to create and train neural networks is used to identify
damage parameters through a hybrid experimental-numerical scheme, and model
crack propagation in structural materials by means of a cohesive zone approach.
The source code, detailed documentation and a large number of tutorials can be
freely downloaded from www.abaqus2matlab.com.
</summary>
    <author>
      <name>George Papazafeiropoulos</name>
    </author>
    <author>
      <name>Miguel Muñiz-Calvente</name>
    </author>
    <author>
      <name>Emilio Martínez-Pañeda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advengsoft.2017.01.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advengsoft.2017.01.006" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Engineering Software 105, pp. 9-16 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1711.10188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.10188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.10912v1</id>
    <updated>2017-11-28T14:36:59Z</updated>
    <published>2017-11-28T14:36:59Z</published>
    <title>TLib: A Flexible C++ Tensor Framework for Numerical Tensor Calculus</title>
    <summary>  Numerical tensor calculus comprise basic tensor operations such as the
entrywise addition and contraction of higher-order tensors. We present, TLib,
flexible tensor framework with generic tensor functions and tensor classes that
assists users to implement generic and flexible tensor algorithms in C++. The
number of dimensions, the extents of the dimensions of the tensors and the
contraction modes of the tensor operations can be runtime variable. Our
framework provides tensor classes that simplify the management of
multidimensional data and utilization of tensor operations using
object-oriented and generic programming techniques. Additional stream classes
help the user to verify and compare of numerical results with MATLAB. Tensor
operations are implemented with generic tensor functions and in terms of
multidimensional iterator types only, decoupling data storage representation
and computation. The user can combine tensor functions with different tensor
types and extend the framework without further modification of the classes or
functions. We discuss the design and implementation of the framework and
demonstrate its usage with examples that have been discussed in the literature.
</summary>
    <author>
      <name>Cem Bassoy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.10912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.10912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.08846v1</id>
    <updated>2018-05-21T14:21:51Z</updated>
    <published>2018-05-21T14:21:51Z</published>
    <title>CUDACLAW: A high-performance programmable GPU framework for the solution
  of hyperbolic PDEs</title>
    <summary>  We present cudaclaw, a CUDA-based high performance data-parallel framework
for the solution of multidimensional hyperbolic partial differential equation
(PDE) systems, equations describing wave motion. cudaclaw allows computational
scientists to solve such systems on GPUs without being burdened by the need to
write CUDA code, worry about thread and block details, data layout, and data
movement between the different levels of the memory hierarchy. The user defines
the set of PDEs to be solved via a CUDA- independent serial Riemann solver and
the framework takes care of orchestrating the computations and data transfers
to maximize arithmetic throughput. cudaclaw treats the different spatial
dimensions separately to allow suitable block sizes and dimensions to be used
in the different directions, and includes a number of optimizations to minimize
access to global memory.
</summary>
    <author>
      <name>H. Gorune Ohannessian</name>
    </author>
    <author>
      <name>George Turkiyyah</name>
    </author>
    <author>
      <name>Aron Ahmadia</name>
    </author>
    <author>
      <name>David Ketcheson</name>
    </author>
    <link href="http://arxiv.org/abs/1805.08846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.08846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.10167v1</id>
    <updated>2018-05-25T14:10:59Z</updated>
    <published>2018-05-25T14:10:59Z</published>
    <title>A Scalable and Modular Software Architecture for Finite Elements on
  Hierarchical Hybrid Grids</title>
    <summary>  In this article, a new generic higher-order finite-element framework for
massively parallel simulations is presented. The modular software architecture
is carefully designed to exploit the resources of modern and future
supercomputers. Combining an unstructured topology with structured grid
refinement facilitates high geometric adaptability and matrix-free multigrid
implementations with excellent performance. Different abstraction levels and
fully distributed data structures additionally ensure high flexibility,
extensibility, and scalability. The software concepts support sophisticated
load balancing and flexibly combining finite element spaces. Example scenarios
with coupled systems of PDEs show the applicability of the concepts to
performing geophysical simulations.
</summary>
    <author>
      <name>Nils Kohl</name>
    </author>
    <author>
      <name>Dominik Thönnes</name>
    </author>
    <author>
      <name>Daniel Drzisga</name>
    </author>
    <author>
      <name>Dominik Bartuschat</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of an article submitted to International Journal of
  Parallel, Emergent and Distributed Systems (Taylor &amp; Francis)</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.10167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.10167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.10211v1</id>
    <updated>2018-05-25T15:50:15Z</updated>
    <published>2018-05-25T15:50:15Z</published>
    <title>COREclust: a new package for a robust and scalable analysis of complex
  data</title>
    <summary>  In this paper, we present a new R package COREclust dedicated to the
detection of representative variables in high dimensional spaces with a
potentially limited number of observations. Variable sets detection is based on
an original graph clustering strategy denoted CORE-clustering algorithm that
detects CORE-clusters, i.e. variable sets having a user defined size range and
in which each variable is very similar to at least another variable.
Representative variables are then robustely estimate as the CORE-cluster
centers. This strategy is entirely coded in C++ and wrapped by R using the Rcpp
package. A particular effort has been dedicated to keep its algorithmic cost
reasonable so that it can be used on large datasets. After motivating our work,
we will explain the CORE-clustering algorithm as well as a greedy extension of
this algorithm. We will then present how to use it and results obtained on
synthetic and real data.
</summary>
    <author>
      <name>Camille Champion</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMT</arxiv:affiliation>
    </author>
    <author>
      <name>Anne-Claire Brunet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Michel Loubes</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMT</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Risser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1805.10211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.10211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.06520v3</id>
    <updated>2018-11-13T17:25:07Z</updated>
    <published>2018-09-18T03:46:47Z</published>
    <title>Random problems with R</title>
    <summary>  R (Version 3.5.1 patched) has an issue with its random sampling
functionality. R generates random integers between $1$ and $m$ by multiplying
random floats by $m$, taking the floor, and adding $1$ to the result.
Well-known quantization effects in this approach result in a non-uniform
distribution on $\{ 1, \ldots, m\}$. The difference, which depends on $m$, can
be substantial. Because the sample function in R relies on generating random
integers, random sampling in R is biased. There is an easy fix: construct
random integers directly from random bits, rather than multiplying a random
float by $m$. That is the strategy taken in Python's numpy.random.randint()
function, among others. Example source code in Python is available at
https://github.com/statlab/cryptorandom/blob/master/cryptorandom/cryptorandom.py
(see functions getrandbits() and randbelow_from_randbits()).
</summary>
    <author>
      <name>Kellie Ottoboni</name>
    </author>
    <author>
      <name>Philip B. Stark</name>
    </author>
    <link href="http://arxiv.org/abs/1809.06520v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.06520v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.09851v1</id>
    <updated>2018-09-26T08:50:08Z</updated>
    <published>2018-09-26T08:50:08Z</published>
    <title>FDBB: Fluid Dynamics Building Blocks</title>
    <summary>  High-performance computing platforms are becoming more and more
heterogeneous, which makes it very difficult for researchers and scientific
software developers to keep up with the rapid changes on the hardware market.
In this paper, the open-source project FDBB (Fluid Dynamics Building Blocks) is
presented, which eases the development of fluid dynamics applications for
heterogeneous systems. It consists of a low-level API that provides a unified
interface to many different linear algebra back-ends and a lightweight and
extendible high-level expression template library, which provides largely
customizable fluid dynamics building blocks, like transformations between
primary and secondary variables as well as expressions for Riemann invariants,
equations of state, inviscid fluxes and their flux-Jacobians. The performance
of the developed approach is assessed both for synthetic micro-benchmarks and
within mini-applications.
</summary>
    <author>
      <name>Matthias Möller</name>
    </author>
    <author>
      <name>Andrzej Jaeschke</name>
    </author>
    <link href="http://arxiv.org/abs/1809.09851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.09851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00904v1</id>
    <updated>2018-12-03T17:03:15Z</updated>
    <published>2018-12-03T17:03:15Z</published>
    <title>Efficient Distributed-Memory Parallel Matrix-Vector Multiplication with
  Wide or Tall Unstructured Sparse Matrices</title>
    <summary>  This paper presents an efficient technique for matrix-vector and
vector-transpose-matrix multiplication in distributed-memory parallel computing
environments, where the matrices are unstructured, sparse, and have a
substantially larger number of columns than rows or vice versa. Our method
allows for parallel I/O, does not require extensive preprocessing, and has the
same communication complexity as matrix-vector multiplies with column or row
partitioning. Our implementation of the method uses MPI. We partition the
matrix by individual nonzero elements, rather than by row or column, and use an
"overlapped" vector representation that is matched to the matrix. The transpose
multiplies use matrix-specific MPI communicators and reductions that we show
can be set up in an efficient manner. The proposed technique achieves a good
work per processor balance even if some of the columns are dense, while keeping
communication costs relatively low.
</summary>
    <author>
      <name>Jonathan Eckstein</name>
    </author>
    <author>
      <name>Gyorgy Matyasfalvi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, IEEE format</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06160v3</id>
    <updated>2019-05-02T22:34:10Z</updated>
    <published>2018-12-13T15:20:41Z</published>
    <title>Javelin: A Scalable Implementation for Sparse Incomplete LU
  Factorization</title>
    <summary>  In this work, we present a new scalable incomplete LU factorization framework
called Javelin to be used as a preconditioner for solving sparse linear systems
with iterative methods. Javelin allows for improved parallel factorization on
shared-memory many-core systems by packaging the coefficient matrix into a
format that allows for high performance sparse matrix-vector multiplication and
sparse triangular solves with minimal overheads. The framework achieves these
goals by using a collection of traditional permutations, point-to-point thread
synchronizations, tasking, and segmented prefix scans in a conventional
compressed sparse row format. Moreover, this framework stresses the importance
of co-designing dependent tasks, such as sparse factorization and triangular
solves, on highly-threaded architectures. Using these changes, traditional
fill-in and drop tolerance methods can be used, while still being able to have
observed speedups of up to ~42x on 68 Intel Knights Landing cores and ~12x on
14 Intel Haswell cores.
</summary>
    <author>
      <name>Joshua Dennis Booth</name>
    </author>
    <author>
      <name>Gregory Bolet</name>
    </author>
    <link href="http://arxiv.org/abs/1812.06160v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06160v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.07908v2</id>
    <updated>2019-01-07T12:17:36Z</updated>
    <published>2018-12-19T12:25:06Z</published>
    <title>Pocket Guide to Solve Inverse Problems with GlobalBioIm</title>
    <summary>  GlobalBioIm is an open-source MATLAB library for solving inverse problems.
The library capitalizes on the strong commonalities between forward models to
standardize the resolution of a wide range of imaging inverse problems. Endowed
with an operator-algebra mechanism, GlobalBioIm allows one to easily solve
inverse problems by combining elementary modules in a lego-like fashion. This
user-friendly toolbox gives access to cutting-edge reconstruction algorithms,
while its high modularity makes it easily extensible to new modalities and
novel reconstruction methods. We expect GlobalBioIm to respond to the needs of
imaging scientists looking for reliable and easy-to-use computational tools for
solving their inverse problems. In this paper, we present in detail the
structure and main features of the library. We also illustrate its flexibility
with examples from multichannel deconvolution microscopy.
</summary>
    <author>
      <name>Emmanuel Soubies</name>
    </author>
    <author>
      <name>Ferréol Soulez</name>
    </author>
    <author>
      <name>Michael T. McCann</name>
    </author>
    <author>
      <name>Thanh-an Pham</name>
    </author>
    <author>
      <name>Laurène Donati</name>
    </author>
    <author>
      <name>Thomas Debarre</name>
    </author>
    <author>
      <name>Daniel Sage</name>
    </author>
    <author>
      <name>Michael Unser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1361-6420/ab2ae9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1361-6420/ab2ae9" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Inverse Problems 35 (2019) 104006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.07908v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07908v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.08558v1</id>
    <updated>2018-12-20T13:43:20Z</updated>
    <published>2018-12-20T13:43:20Z</published>
    <title>Efficient and scalable data structures and algorithms for goal-oriented
  adaptivity of space-time FEM codes</title>
    <summary>  The cost- and memory-efficient numerical simulation of coupled volume-based
multi-physics problems like flow, transport, wave propagation and others
remains a challenging task with finite element method (FEM) approaches.
Goal-oriented space and time adaptive methods derived from the dual weighted
residual (DWR) method appear to be a shiny key technology to generate optimal
space-time meshes to minimise costs. Current implementations for challenging
problems of numerical screening tools including the DWR technology broadly
suffer in their extensibility to other problems, in high memory consumption or
in missing system solver technologies. This work contributes to the efficient
embedding of DWR space-time adaptive methods into numerical screening tools for
challenging problems of physically relevance with a new approach of flexible
data structures and algorithms on them, a modularised and complete
implementation as well as illustrative examples to show the performance and
efficiency.
</summary>
    <author>
      <name>Uwe Köcher</name>
    </author>
    <author>
      <name>Marius Paul Bruchhäuser</name>
    </author>
    <author>
      <name>Markus Bause</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2019.100239</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2019.100239" rel="related"/>
    <link href="http://arxiv.org/abs/1812.08558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.08558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00874v1</id>
    <updated>2019-06-03T15:29:17Z</updated>
    <published>2019-06-03T15:29:17Z</published>
    <title>Exploiting nested task-parallelism in the $\mathcal{H}-LU$ factorization</title>
    <summary>  We address the parallelization of the LU factorization of hierarchical
matrices ($\mathcal{H}$-matrices) arising from boundary element methods. Our
approach exploits task-parallelism via the OmpSs programming model and runtime,
which discovers the data-flow parallelism intrinsic to the operation at
execution time, via the analysis of data dependencies based on the memory
addresses of the tasks' operands. This is especially challenging for
$\mathcal{H}$-matrices, as the structures containing the data vary in dimension
during the execution. We tackle this issue by decoupling the data structure
from that used to detect dependencies. Furthermore, we leverage the support for
weak operands and early release of dependencies, recently introduced in
OmpSs-2, to accelerate the execution of parallel codes with nested
task-parallelism and fine-grain tasks.
</summary>
    <author>
      <name>Rocío Carratalá-Sáez</name>
    </author>
    <author>
      <name>Sven Christophersen</name>
    </author>
    <author>
      <name>José I. Aliaga</name>
    </author>
    <author>
      <name>Vicenç Beltran</name>
    </author>
    <author>
      <name>Steffen Börm</name>
    </author>
    <author>
      <name>Enrique S. Quintana-Ortí</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jocs.2019.02.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jocs.2019.02.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Science, volume 33, pages 20-33 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.00874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10, 65N38, 65F05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.09964v1</id>
    <updated>2019-06-20T21:18:49Z</updated>
    <published>2019-06-20T21:18:49Z</published>
    <title>SPSMAT: GNU Octave software package for spectral and pseudospectral
  methods</title>
    <summary>  SPSMAT (Spectral/Pseudospectral matrix method) is an add-on for Octave, that
helps you solve nonfractional-/fractional ordinary/partial
differential/integral equations. In this version, as the first version, the
well-defined spectral or pseudospectral algorithms are considered to solve
differential and integral equations. The motivation is that there are few
software packages available that make such methods easy to use for
practitioners in the field of scientific computing. Additionally, one of the
most practical platforms in computation, MATLAB, is currently not supporting
beneficial and free numerical method for the solution of differential
equations--to the best author's knowledge. To remedy this situation, this paper
provides a description of its relevant uploaded open source software package
and is a broad guidance to describe how to work with this toolbox.
</summary>
    <author>
      <name>Sobhan Latifi</name>
    </author>
    <author>
      <name>Mehdi Delkhosh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10575v2</id>
    <updated>2020-01-21T12:18:59Z</updated>
    <published>2019-06-25T14:47:23Z</published>
    <title>Parallel Performance of Algebraic Multigrid Domain Decomposition
  (AMG-DD)</title>
    <summary>  Algebraic multigrid (AMG) is a widely used scalable solver and preconditioner
for large-scale linear systems resulting from the discretization of a wide
class of elliptic PDEs. While AMG has optimal computational complexity, the
cost of communication has become a significant bottleneck that limits its
scalability as processor counts continue to grow on modern machines. This paper
examines the design, implementation, and parallel performance of a novel
algorithm, Algebraic Multigrid Domain Decomposition (AMG-DD), designed
specifically to limit communication. The goal of AMG-DD is to provide a
low-communication alternative to standard AMG V-cycles by trading some
additional computational overhead for a significant reduction in communication
cost. Numerical results show that AMG-DD achieves superior accuracy per
communication cost compared to AMG, and speedup over AMG is demonstrated on a
large GPU cluster.
</summary>
    <author>
      <name>Wayne B. Mitchell</name>
    </author>
    <author>
      <name>Robert Strzodka</name>
    </author>
    <author>
      <name>Robert D. Falgout</name>
    </author>
    <link href="http://arxiv.org/abs/1906.10575v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10575v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.10944v2</id>
    <updated>2020-06-16T10:02:14Z</updated>
    <published>2019-06-26T09:59:13Z</published>
    <title>A High-Performance Implementation of a Robust Preconditioner for
  Heterogeneous Problems</title>
    <summary>  We present an efficient implementation of the highly robust and scalable
GenEO preconditioner in the high-performance PDE framework DUNE. The GenEO
coarse space is constructed by combining low energy solutions of a local
generalised eigenproblem using a partition of unity. In this paper we
demonstrate both weak and strong scaling for the GenEO solver on over 15,000
cores by solving an industrially motivated problem with over 200 million
degrees of freedom. Further, we show that for highly complex parameter
distributions arising in certain real-world applications, established methods
become intractable while GenEO remains fully effective. The purpose of this
paper is two-fold: to demonstrate the robustness and high parallel efficiency
of the solver and to document the technical details that are crucial to the
efficiency of the code.
</summary>
    <author>
      <name>Linus Seelinger</name>
    </author>
    <author>
      <name>Anne Reinarz</name>
    </author>
    <author>
      <name>Robert Scheichl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fixed error in definition of partition of unity</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.10944v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10944v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02408v1</id>
    <updated>2019-09-05T13:43:32Z</updated>
    <published>2019-09-05T13:43:32Z</published>
    <title>A Low-Memory Time-Efficient Implementation of Outermorphisms for
  Higher-Dimensional Geometric Algebras</title>
    <summary>  From the beginning of David Hestenes rediscovery of geometric algebra in the
1960s, outermorphisms have been a cornerstone in the mathematical development
of GA. Many important mathematical formulations in GA can be expressed as
outermorphisms such as versor products, linear projection operators, and
mapping between related coordinate frames. Over the last two decades, GA-based
mathematical models and software implementations have been developed in many
fields of science and engineering. As such, efficient implementations of
outermorphisms are of significant importance within this context. This work
attempts to shed some light on the problem of optimizing software
implementations of outermorphisms for practical prototyping applications using
geometric algebra. The approach we propose here for implementing outermorphisms
requires orders of magnitude less memory compared to other common approaches,
while being comparable in time performance, especially for high-dimensional
geometric algebras.
</summary>
    <author>
      <name>Ahmad Hosny Eid</name>
    </author>
    <link href="http://arxiv.org/abs/1909.02408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02836v1</id>
    <updated>2019-09-06T11:53:02Z</updated>
    <published>2019-09-06T11:53:02Z</published>
    <title>Computing Derivatives for PETSc Adjoint Solvers using Algorithmic
  Differentiation</title>
    <summary>  Most nonlinear partial differential equation (PDE) solvers require the
Jacobian matrix associated to the differential operator. In PETSc, this is
typically achieved by either an analytic derivation or numerical approximation
method such as finite differences. For complex applications, hand-coding the
Jacobian can be time-consuming and error-prone, yet computationally efficient.
Whilst finite difference approximations are straight-forward to implement, they
have high arithmetic complexity and low accuracy. Alternatively, one may
compute Jacobians using algorithmic differentiation (AD), yielding the same
derivatives as an analytic derivation, with the added benefit that the
implementation is problem independent. In this work, the operator overloading
AD tool ADOL-C is applied to generate Jacobians for time-dependent, nonlinear
PDEs and their adjoints. Various strategies are considered, including
compressed and matrix-free approaches. In numerical experiments with a 2D
diffusion-reaction model, the performance of these strategies has been studied
and compared to the hand-derived version.
</summary>
    <author>
      <name>J. G. Wallwork</name>
    </author>
    <author>
      <name>P. Hovland</name>
    </author>
    <author>
      <name>H. Zhang</name>
    </author>
    <author>
      <name>O. Marin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, 2 listings, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04029v1</id>
    <updated>2019-09-08T06:42:21Z</updated>
    <published>2019-09-08T06:42:21Z</published>
    <title>The surrogate matrix methodology: A reference implementation for
  low-cost assembly in isogeometric analysis</title>
    <summary>  A reference implementation of a new method in isogeometric analysis (IGA) is
presented. It delivers low-cost variable-scale approximations (surrogates) of
the matrices which IGA conventionally requires to be computed by element-scale
quadrature. To generate surrogate matrices, quadrature must only be performed
on a fraction of the elements in the computational domain. In this way,
quadrature determines only a subset of the entries in the final matrix. The
remaining matrix entries are computed by a simple B-spline interpolation
procedure. We present the modifications and extensions required for a reference
implementation in the open-source IGA software library GeoPDEs. The exposition
is fashioned to help facilitate similar modifications in other contemporary
software libraries.
</summary>
    <author>
      <name>Daniel Drzisga</name>
    </author>
    <author>
      <name>Brendan Keith</name>
    </author>
    <author>
      <name>Barbara Wohlmuth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.mex.2020.100813</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.mex.2020.100813" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">MethodsX, 7:100813 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.04029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.13672v3</id>
    <updated>2020-06-22T16:27:51Z</updated>
    <published>2019-09-30T13:15:53Z</published>
    <title>The DUNE Framework: Basic Concepts and Recent Developments</title>
    <summary>  This paper presents the basic concepts and the module structure of the
Distributed and Unified Numerics Environment and reflects on recent
developments and general changes that happened since the release of the first
Dune version in 2007 and the main papers describing that state [1, 2]. This
discussion is accompanied with a description of various advanced features, such
as coupling of domains and cut cells, grid modifications such as adaptation and
moving domains, high order discretizations and node level performance,
non-smooth multigrid methods, and multiscale methods. A brief discussion on
current and future development directions of the framework concludes the paper.
</summary>
    <author>
      <name>Peter Bastian</name>
    </author>
    <author>
      <name>Markus Blatt</name>
    </author>
    <author>
      <name>Andreas Dedner</name>
    </author>
    <author>
      <name>Nils-Arne Dreier</name>
    </author>
    <author>
      <name>Christian Engwer</name>
    </author>
    <author>
      <name>René Fritze</name>
    </author>
    <author>
      <name>Carsten Gräser</name>
    </author>
    <author>
      <name>Christoph Grüninger</name>
    </author>
    <author>
      <name>Dominic Kempf</name>
    </author>
    <author>
      <name>Robert Klöfkorn</name>
    </author>
    <author>
      <name>Mario Ohlberger</name>
    </author>
    <author>
      <name>Oliver Sander</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">69 pages, 14 figures, 4 tables and various code examples</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.13672v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.13672v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="76S05, 68N01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.00532v1</id>
    <updated>2019-12-28T23:17:48Z</updated>
    <published>2019-12-28T23:17:48Z</published>
    <title>A Unified Iteration Space Transformation Framework for Sparse and Dense
  Tensor Algebra</title>
    <summary>  We address the problem of optimizing mixed sparse and dense tensor algebra in
a compiler. We show that standard loop transformations, such as strip-mining,
tiling, collapsing, parallelization and vectorization, can be applied to
irregular loops over sparse iteration spaces. We also show how these
transformations can be applied to the contiguous value arrays of sparse tensor
data structures, which we call their position space, to unlock load-balanced
tiling and parallelism.
  We have prototyped these concepts in the open-source TACO system, where they
are exposed as a scheduling API similar to the Halide domain-specific language
for dense computations. Using this scheduling API, we show how to optimize
mixed sparse/dense tensor algebra expressions, how to generate load-balanced
code by scheduling sparse tensor algebra in position space, and how to generate
sparse tensor algebra GPU code. Our evaluation shows that our transformations
let us generate good code that is competitive with many hand-optimized
implementations from the literature.
</summary>
    <author>
      <name>Ryan Senanayake</name>
    </author>
    <author>
      <name>Fredrik Kjolstad</name>
    </author>
    <author>
      <name>Changwan Hong</name>
    </author>
    <author>
      <name>Shoaib Kamil</name>
    </author>
    <author>
      <name>Saman Amarasinghe</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.01496v3</id>
    <updated>2020-04-30T09:58:03Z</updated>
    <published>2020-01-06T11:37:04Z</published>
    <title>Issues with rounding in the GCC implementation of the ISO 18037:2008
  standard fixed-point arithmetic</title>
    <summary>  We describe various issues caused by the lack of round-to-nearest mode in the
\textit{gcc} compiler implementation of the fixed-point arithmetic data types
and operations. We demonstrate that round-to-nearest is not performed in the
conversion of constants, conversion from one numerical type to a less precise
type and results of multiplications. Furthermore, we show that mixed-precision
operations in fixed-point arithmetic lose precision on arguments, even before
carrying out arithmetic operations. The ISO 18037:2008 standard was created to
standardize C language extensions, including fixed-point arithmetic, for
embedded systems. Embedded systems are usually based on ARM processors, of
which approximately 100 billion have been manufactured by now. Therefore, the
observations about numerical issues that we discuss in this paper can be rather
dangerous and are important to address, given the wide ranging type of
applications that these embedded systems are running.
</summary>
    <author>
      <name>Mantas Mikaitis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ARITH48897.2020.00028</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ARITH48897.2020.00028" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the proceedings of the 27th IEEE Symposium on Computer
  Arithmetic</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01496v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01496v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06307v2</id>
    <updated>2020-07-02T20:46:11Z</updated>
    <published>2020-01-15T16:48:07Z</published>
    <title>Awkward Arrays in Python, C++, and Numba</title>
    <summary>  The Awkward Array library has been an important tool for physics analysis in
Python since September 2018. However, some interface and implementation issues
have been raised in Awkward Array's first year that argue for a
reimplementation in C++ and Numba. We describe those issues, the new
architecture, and present some examples of how the new interface will look to
users. Of particular importance is the separation of kernel functions from data
structure management, which allows a C++ implementation and a Numba
implementation to share kernel functions, and the algorithm that transforms
record-oriented data into columnar Awkward Arrays.
</summary>
    <author>
      <name>Jim Pivarski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <author>
      <name>Peter Elmer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <author>
      <name>David Lange</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/epjconf/202024505023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/epjconf/202024505023" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in CHEP 2019 proceedings, EPJ Web of Conferences;
  post-review update</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.06307v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06307v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.07625v1</id>
    <updated>2020-01-21T16:03:57Z</updated>
    <published>2020-01-21T16:03:57Z</published>
    <title>MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary
  Multivariate Distributions by means of Method Overloading</title>
    <summary>  This manuscript outlines a software package that facilitates working with
probability distributions by means of Monte-Carlo methods, in a way that allows
for propagation of multivariate probability distributions through arbitrary
functions. We provide a \emph{type} that represents probability distributions
by an internal vector of unweighted samples, \texttt{Particles}, which is a
subtype of a \texttt{Real} number and behaves just like a regular real number
in calculations by means of method overloading. This makes the software easy to
work with and presents minimal friction for the user. We highlight how this
design facilitates optimal usage of SIMD instructions and showcase the package
for uncertainty propagation through an off-the-shelf ODE solver, as well as for
robust probabilistic optimization with automatic differentiation.
</summary>
    <author>
      <name>Fredrik Bagge Carlson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figure, 5 code blocks, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.07625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.07625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09253v1</id>
    <updated>2020-01-25T02:06:31Z</updated>
    <published>2020-01-25T02:06:31Z</published>
    <title>Fast Cubic Spline Interpolation</title>
    <summary>  The Numerical Recipes series of books are a useful resource, but all the
algorithms they contain cannot be used within open-source projects. In this
paper we develop drop-in alternatives to the two algorithms they present for
cubic spline interpolation, showing as much of our work as possible to allow
for replication or criticsm. The output of the new algorithms is compared to
the old, and found to be no different within the limits imposed by
floating-point precision. Benchmarks of all these algorithms, plus variations
which may run faster in certain instances, are performed. In general, all these
algorithms have approximately the same execution time when interpolating curves
with few control points on feature-rich Intel processors; as the number of
control points increases or processor features are removed, the new algorithms
become consistently faster than the old. Exceptions to that generalization are
explored to create implementation guidelines, such as when to expect division
to be faster than multiplication.
</summary>
    <author>
      <name>Haysn Hornbeck</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09253v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09253v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09258v1</id>
    <updated>2020-01-25T03:05:52Z</updated>
    <published>2020-01-25T03:05:52Z</published>
    <title>SLEEF: A Portable Vectorized Library of C Standard Mathematical
  Functions</title>
    <summary>  In this paper, we present techniques used to implement our portable
vectorized library of C standard mathematical functions written entirely in C
language. In order to make the library portable while maintaining good
performance, intrinsic functions of vector extensions are abstracted by inline
functions or preprocessor macros. We implemented the functions so that they can
use sub-features of vector extensions such as fused multiply-add, mask
registers and extraction of mantissa. In order to make computation with SIMD
instructions efficient, the library only uses a small number of conditional
branches, and all the computation paths are vectorized. We devised a variation
of the Payne-Hanek argument reduction for trigonometric functions and a
floating point remainder, both of which are suitable for vector computation. We
compare the performance of our library to Intel SVML.
</summary>
    <author>
      <name>Naoki Shibata</name>
    </author>
    <author>
      <name>Francesco Petrogalli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPDS.2019.2960333</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPDS.2019.2960333" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in IEEE Transactions on Parallel and Distributed Systems. This is a
  version with all appendices included in a PDF. Accompanying software can be
  accessed at https://sleef.org or https://codeocean.com/capsule/6861013</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.09258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.11806v2</id>
    <updated>2020-04-11T09:09:36Z</updated>
    <published>2020-01-31T13:00:26Z</published>
    <title>lbmpy: Automatic code generation for efficient parallel lattice
  Boltzmann methods</title>
    <summary>  Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic
computational fluid dynamics solvers. Many variants have been developed that
vary in complexity, accuracy, and computational cost. Extensions are available
to simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In
this work we present lbmpy, a code generation package that supports a wide
variety of different methods and provides a generic development environment for
new schemes as well. A high-level domain-specific language allows the user to
formulate, extend and test various lattice Boltzmann schemes. The method
specification is represented in a symbolic intermediate representation.
Transformations that operate on this intermediate representation optimize and
parallelize the method, yielding highly efficient lattice Boltzmann compute
kernels not only for single- and two-relaxation-time schemes but also for
multi-relaxation-time, cumulant, and entropically stabilized methods. An
integration into the HPC framework waLBerla makes massively parallel,
distributed simulations possible, which is demonstrated through scaling
experiments on the SuperMUC-NG supercomputing system
</summary>
    <author>
      <name>Martin Bauer</name>
    </author>
    <author>
      <name>Harald Köstler</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11806v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11806v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.05172v1</id>
    <updated>2020-08-12T08:38:07Z</updated>
    <published>2020-08-12T08:38:07Z</published>
    <title>PyMGRIT: A Python Package for the parallel-in-time method MGRIT</title>
    <summary>  In this paper, we introduce the Python framework PyMGRIT, which implements
the multigrid-reduction-in-time (MGRIT) algorithm for solving the (non-)linear
systems arising from the discretization of time-dependent problems. The MGRIT
algorithm is a reduction-based iterative method that allows parallel-in-time
simulations, i. e., calculating multiple time steps simultaneously in a
simulation, by using a time-grid hierarchy. The PyMGRIT framework features many
different variants of the MGRIT algorithm, ranging from different multigrid
cycle types and relaxation schemes, as well as various coarsening strategies,
including time-only and space-time coarsening, to using different time
integrators on different levels in the multigrid hierachy. PyMGRIT allows
serial runs for prototyping and testing of new approaches, as well as parallel
runs using the Message Passing Interface (MPI). Here, we describe the
implementation of the MGRIT algorithm in PyMGRIT and present the usage from
both user and developer point of views. Three examples illustrate different
aspects of the package, including pure time parallelism as well as space-time
parallelism by coupling PyMGRIT with PETSc or Firedrake, which enable spatial
parallelism through MPI.
</summary>
    <author>
      <name>Jens Hahne</name>
    </author>
    <author>
      <name>Stephanie Friedhoff</name>
    </author>
    <author>
      <name>Matthias Bolten</name>
    </author>
    <link href="http://arxiv.org/abs/2008.05172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.05172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.00761v1</id>
    <updated>2020-09-02T00:34:54Z</updated>
    <published>2020-09-02T00:34:54Z</published>
    <title>A Survey of Singular Value Decomposition Methods for Distributed
  Tall/Skinny Data</title>
    <summary>  The Singular Value Decomposition (SVD) is one of the most important matrix
factorizations, enjoying a wide variety of applications across numerous
application domains. In statistics and data analysis, the common applications
of SVD such as Principal Components Analysis (PCA) and linear regression.
Usually these applications arise on data that has far more rows than columns,
so-called "tall/skinny" matrices. In the big data analytics context, this may
take the form of hundreds of millions to billions of rows with only a few
hundred columns. There is a need, therefore, for fast, accurate, and scalable
tall/skinny SVD implementations which can fully utilize modern computing
resources. To that end, we present a survey of three different algorithms for
computing the SVD for these kinds of tall/skinny data layouts using MPI for
communication. We contextualize these with common big data analytics
techniques, principally PCA. Finally, we present both CPU and GPU timing
results from the Summit supercomputer, and discuss possible alternative
approaches.
</summary>
    <author>
      <name>Drew Schmidt</name>
    </author>
    <link href="http://arxiv.org/abs/2009.00761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.00761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.08805v1</id>
    <updated>2020-09-16T21:28:09Z</updated>
    <published>2020-09-16T21:28:09Z</published>
    <title>HDGlab: An open-source implementation of the hybridisable discontinuous
  Galerkin method in MATLAB</title>
    <summary>  This paper presents HDGlab, an open source MATLAB implementation of the
hybridisable discontinuous Galerkin (HDG) method. The main goal is to provide a
detailed description of both the HDG method for elliptic problems and its
implementation available in HDGlab. Ultimately, this is expected to make this
relatively new advanced discretisation method more accessible to the
computational engineering community. HDGlab presents some features not
available in other implementations of the HDG method that can be found in the
free domain. First, it implements high-order polynomial shape functions up to
degree nine, with both equally-spaced and Fekete nodal distributions. Second,
it supports curved isoparametric simplicial elements in two and three
dimensions. Third, it supports non-uniform degree polynomial approximations and
it provides a flexible structure to devise degree adaptivity strategies.
Finally, an interface with the open-source high-order mesh generator Gmsh is
provided to facilitate its application to practical engineering problems.
</summary>
    <author>
      <name>Matteo Giacomini</name>
    </author>
    <author>
      <name>Ruben Sevilla</name>
    </author>
    <author>
      <name>Antonio Huerta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11831-020-09502-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11831-020-09502-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">90 pages, 51 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archives of Computational Methods in Engineering, Vol. 28, Issue
  3, pp. 1941-1986, 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2009.08805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.08805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65-04, 35-04, 76-04, 65N30, 76M10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.10917v1</id>
    <updated>2020-09-23T03:11:10Z</updated>
    <published>2020-09-23T03:11:10Z</published>
    <title>Portable high-order finite element kernels I: Streaming Operations</title>
    <summary>  This paper is devoted to the development of highly efficient kernels
performing vector operations relevant in linear system solvers. In particular,
we focus on the low arithmetic intensity operations (i.e., streaming
operations) performed within the conjugate gradient iterative method, using the
parameters specified in the CEED benchmark problems for high-order hexahedral
finite elements. We propose a suite of new Benchmark Streaming tests to focus
on the distinct streaming operations which must be performed. We implemented
these new tests using the OCCA abstraction framework to demonstrate portability
of these streaming operations on different GPU architectures, and propose a
simple performance model for such kernels which can accurately capture data
movement rates as well as kernel launch costs.
</summary>
    <author>
      <name>Noel Chalmers</name>
    </author>
    <author>
      <name>Tim Warburton</name>
    </author>
    <link href="http://arxiv.org/abs/2009.10917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.10917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.12638v1</id>
    <updated>2020-09-26T16:44:34Z</updated>
    <published>2020-09-26T16:44:34Z</published>
    <title>A highly scalable approach to solving linear systems using two-stage
  multisplitting</title>
    <summary>  Iterative methods for solving large sparse systems of linear equations are
widely used in many HPC applications. Extreme scaling of these methods can be
difficult, however, since global communication to form dot products is
typically required at every iteration.
  To try to overcome this limitation we propose a hybrid approach, where the
matrix is partitioned into blocks. Within each block, we use a highly optimised
(parallel) conventional solver, but we then couple the blocks together using
block Jacobi or some other multisplitting technique that can be implemented in
either a synchronous or an asynchronous fashion. This allows us to limit the
block size to the point where the conventional iterative methods no longer
scale, and to avoid global communication (and possibly synchronisation) across
all processes.
  Our block framework has been built to use PETSc, a popular scientific suite
for solving sparse linear systems, as the synchronous intra-block solver, and
we demonstrate results on up to 32768 cores of a Cray XE6 system. At this
scale, the conventional solvers are still more efficient, though trends suggest
that the hybrid approach may be beneficial at higher core counts.
</summary>
    <author>
      <name>Nick Brown</name>
    </author>
    <author>
      <name>J. Mark Bull</name>
    </author>
    <author>
      <name>Iain Bethune</name>
    </author>
    <link href="http://arxiv.org/abs/2009.12638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.12638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.13416v2</id>
    <updated>2021-03-29T09:28:39Z</updated>
    <published>2020-09-25T16:23:57Z</published>
    <title>Extendible and Efficient Python Framework for Solving Evolution
  Equations with Stabilized Discontinuous Galerkin Method</title>
    <summary>  This paper discusses a Python interface for the recently published
DUNE-FEM-DG module which provides highly efficient implementations of the
Discontinuous Galerkin (DG) method for solving a wide range of non linear
partial differential equations (PDE). Although the C++ interfaces of
DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is
necessary to make use of this powerful tool. With this work easier user
interfaces based on Python and the Unified Form Language are provided to open
DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for
both parabolic and first order hyperbolic PDEs.
</summary>
    <author>
      <name>Andreas Dedner</name>
    </author>
    <author>
      <name>Robert Klöfkorn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 15 figures, various Python code examples</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.13416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.13416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M08, 65M60, 35Q31, 35Q90, 68N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.14229v1</id>
    <updated>2020-09-29T18:04:02Z</updated>
    <published>2020-09-29T18:04:02Z</published>
    <title>ParaMonte: A high-performance serial/parallel Monte Carlo simulation
  library for C, C++, Fortran</title>
    <summary>  ParaMonte (standing for Parallel Monte Carlo) is a serial and
MPI/Coarray-parallelized library of Monte Carlo routines for sampling
mathematical objective functions of arbitrary-dimensions, in particular, the
posterior distributions of Bayesian models in data science, Machine Learning,
and scientific inference. The ParaMonte library has been developed with the
design goal of unifying the **automation**, **accessibility**,
**high-performance**, **scalability**, and **reproducibility** of Monte Carlo
simulations. The current implementation of the library includes **ParaDRAM**, a
**Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain
Monte Carlo sampler, accessible from a wide range of programming languages
including C, C++, Fortran, with a unified Application Programming Interface and
simulation environment across all supported programming languages. The
ParaMonte library is MIT-licensed and is permanently located and maintained at
[https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).
</summary>
    <author>
      <name>Amir Shahmoradi</name>
    </author>
    <author>
      <name>Fatemeh Bagheri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to JOSS</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.14229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.14229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.14276v5</id>
    <updated>2021-02-23T12:19:51Z</updated>
    <published>2020-08-23T14:07:07Z</published>
    <title>Compact 200 line MATLAB code for inverse design in photonics by topology
  optimization: tutorial</title>
    <summary>  We provide a compact 200 line MATLAB code demonstrating how topology
optimization (TopOpt) as an inverse design tool may be used in photonics,
targeting the design of two-dimensional dielectric metalenses and a metallic
reflector as examples. The physics model is solved using the finite element
method, and the code utilizes MATLAB's fmincon algorithm to solve the
optimization problem. In addition to presenting the code itself, we briefly
discuss a number of extensions and provide the code required to implement some
of these. Finally, we demonstrate the superiority of using a gradient-based
method compared to a genetic-algorithm-based method (using MATLAB's ga
algorithm) for solving inverse design problems in photonics. The MATLAB
software is freely available in the paper and may be downloaded from
https://www.topopt.mek.dtu.dk.
</summary>
    <author>
      <name>Rasmus E. Christiansen</name>
    </author>
    <author>
      <name>Ole Sigmund</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1364/JOSAB.405955</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1364/JOSAB.405955" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Figures, 17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.14276v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.14276v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.14600v1</id>
    <updated>2020-09-29T14:10:15Z</updated>
    <published>2020-09-29T14:10:15Z</published>
    <title>Accelerating Sparse Matrix-Matrix Multiplication with GPU Tensor Cores</title>
    <summary>  Sparse general matrix-matrix multiplication (spGEMM) is an essential
component in many scientific and data analytics applications. However, the
sparsity pattern of the input matrices and the interaction of their patterns
make spGEMM challenging. Modern GPUs include Tensor Core Units (TCUs), which
specialize in dense matrix multiplication. Our aim is to re-purpose TCUs for
sparse matrices. The key idea of our spGEMM algorithm, tSparse, is to multiply
sparse rectangular blocks using the mixed precision mode of TCUs. tSparse
partitions the input matrices into tiles and operates only on tiles which
contain one or more elements. It creates a task list of the tiles, and performs
matrix multiplication of these tiles using TCUs. To the best of our knowledge,
this is the first time that TCUs are used in the context of spGEMM. We show
that spGEMM, with our tiling approach, benefits from TCUs. Our approach
significantly improves the performance of spGEMM in comparison to cuSPARSE,
CUSP, RMerge2, Nsparse, AC-SpGEMM and spECK.
</summary>
    <author>
      <name>Orestis Zachariadis</name>
    </author>
    <author>
      <name>Nitin Satpute</name>
    </author>
    <author>
      <name>Juan Gómez-Luna</name>
    </author>
    <author>
      <name>Joaquín Olivares</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compeleceng.2020.106848</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compeleceng.2020.106848" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in CAEE</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Electr. Eng. 88 (2020) 106848</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2009.14600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.14600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.00724v1</id>
    <updated>2020-10-01T23:26:42Z</updated>
    <published>2020-10-01T23:26:42Z</published>
    <title>Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations
  and visualizations via ParaMonte::Python library</title>
    <summary>  ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial
and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for
sampling mathematical objective functions, in particular, the posterior
distributions of parameters in Bayesian modeling and analysis in data science,
Machine Learning, and scientific inference in general. In addition to providing
access to fast high-performance serial/parallel Monte Carlo and MCMC sampling
routines, the ParaMonte::Python library provides extensive post-processing and
visualization tools that aim to automate and streamline the process of model
calibration and uncertainty quantification in Bayesian data analysis.
Furthermore, the automatically-enabled restart functionality of
ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future
restart of Monte Carlo simulations, should any interruptions happen. The
ParaMonte::Python library is MIT-licensed and is permanently maintained on
GitHub at
https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.
</summary>
    <author>
      <name>Amir Shahmoradi</name>
    </author>
    <author>
      <name>Fatemeh Bagheri</name>
    </author>
    <author>
      <name>Joshua Alexander Osborne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be submitted to JOSS</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.00724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.00724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.01709v1</id>
    <updated>2020-10-04T22:32:51Z</updated>
    <published>2020-10-04T22:32:51Z</published>
    <title>Instead of Rewriting Foreign Code for Machine Learning, Automatically
  Synthesize Fast Gradients</title>
    <summary>  Applying differentiable programming techniques and machine learning
algorithms to foreign programs requires developers to either rewrite their code
in a machine learning framework, or otherwise provide derivatives of the
foreign code. This paper presents Enzyme, a high-performance automatic
differentiation (AD) compiler plugin for the LLVM compiler framework capable of
synthesizing gradients of statically analyzable programs expressed in the LLVM
intermediate representation (IR). Enzyme synthesizes gradients for programs
written in any language whose compiler targets LLVM IR including C, C++,
Fortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD
capabilities in these languages. Unlike traditional source-to-source and
operator-overloading tools, Enzyme performs AD on optimized IR. On a
machine-learning focused benchmark suite including Microsoft's ADBench, AD on
optimized IR achieves a geometric mean speedup of 4.5x over AD on IR before
optimization allowing Enzyme to achieve state-of-the-art performance. Packaging
Enzyme for PyTorch and TensorFlow provides convenient access to gradients of
foreign code with state-of-the art performance, enabling foreign code to be
directly incorporated into existing machine learning workflows.
</summary>
    <author>
      <name>William S. Moses</name>
    </author>
    <author>
      <name>Valentin Churavy</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5555/3495724.3496770</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5555/3495724.3496770" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in NeurIPS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.01709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.01709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.04868v1</id>
    <updated>2020-10-10T01:47:34Z</updated>
    <published>2020-10-10T01:47:34Z</published>
    <title>Temporal Vectorization for Stencils</title>
    <summary>  Stencil computations represent a very common class of nested loops in
scientific and engineering applications. Exploiting vector units in modern CPUs
is crucial to achieving peak performance. Previous vectorization approaches
often consider the data space, in particular the innermost unit-strided loop.
It leads to the well-known data alignment conflict problem that vector loads
are overlapped due to the data sharing between continuous stencil computations.
This paper proposes a novel temporal vectorization scheme for stencils. It
vectorizes the stencil computation in the iteration space and assembles points
with different time coordinates in one vector. The temporal vectorization leads
to a small fixed number of vector reorganizations that is irrelevant to the
vector length, stencil order, and dimension. Furthermore, it is also applicable
to Gauss-Seidel stencils, whose vectorization is not well-studied. The
effectiveness of the temporal vectorization is demonstrated by various Jacobi
and Gauss-Seidel stencils.
</summary>
    <author>
      <name>Liang Yuan</name>
    </author>
    <author>
      <name>Hang Cao</name>
    </author>
    <author>
      <name>Yunquan Zhang</name>
    </author>
    <author>
      <name>Kun Li</name>
    </author>
    <author>
      <name>Pengqi Lu</name>
    </author>
    <author>
      <name>Yue Yue</name>
    </author>
    <link href="http://arxiv.org/abs/2010.04868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.04868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.07906v1</id>
    <updated>2020-10-15T17:36:48Z</updated>
    <published>2020-10-15T17:36:48Z</published>
    <title>DSLib: An open source library for the dominant set clustering method</title>
    <summary>  DSLib is an open-source implementation of the Dominant Set (DS) clustering
algorithm written entirely in Matlab. The DS method is a graph-based clustering
technique rooted in the evolutionary game theory that starts gaining lots of
interest in the computer science community. Thanks to its duality with game
theory and its strict relation to the notion of maximal clique, has been
explored in several directions not only related to clustering problems.
Applications in graph matching, segmentation, classification and medical
imaging are common in literature. This package provides an implementation of
the original DS clustering algorithm since no code has been officially released
yet, together with a still growing collection of methods and variants related
to it. Our library is integrable into a Matlab pipeline without dependencies,
it is simple to use and easily extendable for upcoming works. The latest source
code, the documentation and some examples can be downloaded from
https://xwasco.github.io/DominantSetLibrary.
</summary>
    <author>
      <name>Sebastiano Vascon</name>
    </author>
    <author>
      <name>Samuel Rota Bulò</name>
    </author>
    <author>
      <name>Vittorio Murino</name>
    </author>
    <author>
      <name>Marcello Pelillo</name>
    </author>
    <link href="http://arxiv.org/abs/2010.07906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.07906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.13887v4</id>
    <updated>2021-04-22T09:37:37Z</updated>
    <published>2020-10-23T13:45:26Z</published>
    <title>LightSeq: A High Performance Inference Library for Transformers</title>
    <summary>  Transformer, BERT and their variants have achieved great success in natural
language processing. Since Transformer models are huge in size, serving these
models is a challenge for real industrial applications. In this paper, we
propose LightSeq, a highly efficient inference library for models in the
Transformer family. LightSeq includes a series of GPU optimization techniques
to to streamline the computation of neural layers and to reduce memory
footprint. LightSeq can easily import models trained using PyTorch and
Tensorflow. Experimental results on machine translation benchmarks show that
LightSeq achieves up to 14x speedup compared with TensorFlow and 1.4x compared
with FasterTransformer, a concurrent CUDA implementation. The code is available
at https://github.com/bytedance/lightseq.
</summary>
    <author>
      <name>Xiaohui Wang</name>
    </author>
    <author>
      <name>Ying Xiong</name>
    </author>
    <author>
      <name>Yang Wei</name>
    </author>
    <author>
      <name>Mingxuan Wang</name>
    </author>
    <author>
      <name>Lei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures, accepted by NAACL 2021 Industry Track</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.13887v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.13887v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.14734v3</id>
    <updated>2020-11-17T23:59:48Z</updated>
    <published>2020-10-28T03:57:27Z</published>
    <title>Generalized eigen, singular value, and partial least squares
  decompositions: The GSVD package</title>
    <summary>  The generalized singular value decomposition (GSVD, a.k.a. "SVD triplet",
"duality diagram" approach) provides a unified strategy and basis to perform
nearly all of the most common multivariate analyses (e.g., principal
components, correspondence analysis, multidimensional scaling, canonical
correlation, partial least squares). Though the GSVD is ubiquitous, powerful,
and flexible, it has very few implementations. Here I introduce the GSVD
package for R. The general goal of GSVD is to provide a small set of accessible
functions to perform the GSVD and two other related decompositions (generalized
eigenvalue decomposition, generalized partial least squares-singular value
decomposition). Furthermore, GSVD helps provide a more unified conceptual
approach and nomenclature to many techniques. I first introduce the concept of
the GSVD, followed by a formal definition of the generalized decompositions.
Next I provide some key decisions made during development, and then a number of
examples of how to use GSVD to implement various statistical techniques. These
examples also illustrate one of the goals of GSVD: how others can (or should)
build analysis packages that depend on GSVD. Finally, I discuss the possible
future of GSVD.
</summary>
    <author>
      <name>Derek Beaton</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Rotman Research Institute, Baycrest Health Sciences</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 9 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.14734v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.14734v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.14993v3</id>
    <updated>2020-11-27T17:42:38Z</updated>
    <published>2020-10-26T09:28:08Z</published>
    <title>Parallelizing multiple precision Taylor series method for integrating
  the Lorenz system</title>
    <summary>  A hybrid MPI+OpenMP strategy for parallelizing multiple precision Taylor
series method is proposed, realized and tested. To parallelize the algorithm we
combine MPI and OpenMP parallel technologies together with GMP library (GNU
miltiple precision libary) and the tiny MPIGMP library. The details of the
parallelization are explained on the paradigmatic model of the Lorenz system.
We succeed to obtain a correct reference solution in the rather long time
interval - [0,7000]. The solution is verified by comparing the results for
2700-th order Taylor series method and precision of ~ 3374 decimal digits, and
those with 2800-th order and precision of ~ 3510 decimal digits. With 192 CPU
cores in Nestum cluster, Sofia, Bulgaria, the 2800-th order computation was ~
145 hours with speedup ~ 105.
</summary>
    <author>
      <name>I. Hristov</name>
    </author>
    <author>
      <name>R. Hristova</name>
    </author>
    <author>
      <name>S. Dimova</name>
    </author>
    <author>
      <name>P. Armyanov</name>
    </author>
    <author>
      <name>N. Shegunov</name>
    </author>
    <author>
      <name>I. Puzynin</name>
    </author>
    <author>
      <name>T. Puzynina</name>
    </author>
    <author>
      <name>Z. Sharipov</name>
    </author>
    <author>
      <name>Z. Tukhliev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-20951-2_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-20951-2_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1908.09301</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advanced Computing in Industrial Mathematics. BGSIAM 2020. Studies
  in Computational Intelligence, vol 1076. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2010.14993v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.14993v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L05, 65Y05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7; G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.00715v2</id>
    <updated>2021-09-29T18:39:39Z</updated>
    <published>2020-11-02T04:05:29Z</published>
    <title>Toward Performance-Portable PETSc for GPU-based Exascale Systems</title>
    <summary>  The Portable Extensible Toolkit for Scientific computation (PETSc) library
delivers scalable solvers for nonlinear time-dependent differential and
algebraic equations and for numerical optimization.The PETSc design for
performance portability addresses fundamental GPU accelerator challenges and
stresses flexibility and extensibility by separating the programming model used
by the application from that used by the library, and it enables application
developers to use their preferred programming model, such as Kokkos, RAJA,
SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using
GPUs from PETSc-based codes is provided, and case studies emphasize the
flexibility and high performance achieved on current GPU-based systems.
</summary>
    <author>
      <name>Richard Tran Mills</name>
    </author>
    <author>
      <name>Mark F. Adams</name>
    </author>
    <author>
      <name>Satish Balay</name>
    </author>
    <author>
      <name>Jed Brown</name>
    </author>
    <author>
      <name>Alp Dener</name>
    </author>
    <author>
      <name>Matthew Knepley</name>
    </author>
    <author>
      <name>Scott E. Kruger</name>
    </author>
    <author>
      <name>Hannah Morgan</name>
    </author>
    <author>
      <name>Todd Munson</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <author>
      <name>Stefano Zampini</name>
    </author>
    <author>
      <name>Hong Zhang</name>
    </author>
    <author>
      <name>Junchao Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 10 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2011.00715v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.00715v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F10, 65F50, 68N99, 68W10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.07119v2</id>
    <updated>2021-09-08T13:42:27Z</updated>
    <published>2020-11-12T16:14:09Z</published>
    <title>tvopt: A Python Framework for Time-Varying Optimization</title>
    <summary>  This paper introduces tvopt, a Python framework for prototyping and
benchmarking time-varying (or online) optimization algorithms. The paper first
describes the theoretical approach that informed the development of tvopt. Then
it discusses the different components of the framework and their use for
modeling and solving time-varying optimization problems. In particular, tvopt
provides functionalities for defining both centralized and distributed online
problems, and a collection of built-in algorithms to solve them, for example
gradient-based methods, ADMM and other splitting methods. Moreover, the
framework implements prediction strategies to improve the accuracy of the
online solvers. The paper then proposes some numerical results on a benchmark
problem and discusses their implementation using tvopt. The code for tvopt is
available at https://github.com/nicola-bastianello/tvopt.
</summary>
    <author>
      <name>Nicola Bastianello</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CDC45484.2021.9683695</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CDC45484.2021.9683695" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code available here: https://github.com/nicola-bastianello/tvopt --
  IEEE CDC'21 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2011.07119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.07119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.10073v2</id>
    <updated>2021-09-23T03:35:54Z</updated>
    <published>2020-11-19T19:13:38Z</published>
    <title>Enabling New Flexibility in the SUNDIALS Suite of Nonlinear and
  Differential/Algebraic Equation Solvers</title>
    <summary>  In recent years, the SUite of Nonlinear and DIfferential/ALgebraic equation
Solvers (SUNDIALS) has been redesigned to better enable the use of
application-specific and third-party algebraic solvers and data structures.
Throughout this work, we have adhered to specific guiding principles that
minimized the impact to current users while providing maximum flexibility for
later evolution of solvers and data structures. The redesign was done through
the addition of new linear and nonlinear solvers classes, enhancements to the
vector class, and the creation of modern Fortran interfaces. The vast majority
of this work has been performed "behind-the-scenes," with minimal changes to
the user interface and no reduction in solver capabilities or performance.
These changes allow SUNDIALS users to more easily utilize external solver
libraries and create highly customized solvers, enabling greater flexibility on
extreme-scale, heterogeneous computational architectures.
</summary>
    <author>
      <name>David J. Gardner</name>
    </author>
    <author>
      <name>Daniel R. Reynolds</name>
    </author>
    <author>
      <name>Carol S. Woodward</name>
    </author>
    <author>
      <name>Cody J. Balos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539801</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539801" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, Volume 48, Issue 3,
  September 2022, Article No.: 31</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2011.10073v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.10073v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.10214v1</id>
    <updated>2020-11-20T04:53:16Z</updated>
    <published>2020-11-20T04:53:16Z</published>
    <title>PIFE-PIC: Parallel Immersed-Finite-Element Particle-In-Cell For 3-D
  Kinetic Simulations of Plasma-Material Interactions</title>
    <summary>  This paper presents a recently developed particle simulation code package
PIFE-PIC, which is a novel three-dimensional (3-D) Parallel
Immersed-Finite-Element (IFE) Particle-in-Cell (PIC) simulation model for
particle simulations of plasma-material interactions. This framework is based
on the recently developed non-homogeneous electrostatic IFE-PIC algorithm,
which is designed to handle complex plasma-material interface conditions
associated with irregular geometries using a Cartesian-mesh-based PIC.
Three-dimensional domain decomposition is utilized for both the electrostatic
field solver with IFE and the particle operations in PIC to distribute the
computation among multiple processors. A simulation of the
orbital-motion-limited (OML) sheath of a dielectric sphere immersed in a
stationary plasma is carried out to validate PIFE-PIC and profile the parallel
performance of the code package. Furthermore, a large-scale simulation of
plasma charging at a lunar crater containing 2 million PIC cells (10 million
FE/IFE cells) and about 520 million particles, running for 20,000 PIC steps in
about 109 wall-clock hours, is presented to demonstrate the high-performance
computing capability of PIFE-PIC.
</summary>
    <author>
      <name>Daoru Han</name>
    </author>
    <author>
      <name>Xiaoming He</name>
    </author>
    <author>
      <name>David Lund</name>
    </author>
    <author>
      <name>Xu Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2011.10214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.10214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.10570v1</id>
    <updated>2020-11-19T21:44:23Z</updated>
    <published>2020-11-19T21:44:23Z</published>
    <title>Scalable Local Timestepping on Octree Grids</title>
    <summary>  Numerical solutions of hyperbolic partial differential equations(PDEs) are
ubiquitous in science and engineering. Method of lines is a popular approach to
discretize PDEs defined in spacetime, where space and time are discretized
independently. When using explicit timesteppers on adaptive grids, the use of a
global timestep-size dictated by the finest grid-spacing leads to
inefficiencies in the coarser regions. Even though adaptive space
discretizations are widely used in computational sciences, temporal adaptivity
is less common due to its sophisticated nature. In this paper, we present
highly scalable algorithms to enable local timestepping (LTS) for explicit
timestepping schemes on fully adaptive octrees. We demonstrate the accuracy of
our methods as well as the scalability of our framework across 16K cores in
TACC's Frontera. We also present a speed up estimation model for LTS, which
predicts the speedup compared to global timestepping (GTS) with an average of
0.1 relative error.
</summary>
    <author>
      <name>Milinda Fernando</name>
    </author>
    <author>
      <name>Hari Sundar</name>
    </author>
    <link href="http://arxiv.org/abs/2011.10570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.10570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.06570v3</id>
    <updated>2021-10-07T20:12:01Z</updated>
    <published>2021-02-12T15:10:39Z</published>
    <title>User manual for bch, a program for the fast computation of the
  Baker-Campbell-Hausdorff and similar series</title>
    <summary>  This manual describes bch, an efficient program written in the C programming
language for the fast computation of the Baker-Campbell-Hausdorff (BCH) and
similar Lie series. The Lie series can be represented in the Lyndon basis, in
the classical Hall basis, or in the right-normed basis of E.S. Chibrikov. In
the Lyndon basis, which proves to be particularly efficient for this purpose,
the computation of 111013 coefficients for the BCH series up to terms of degree
20 takes less than half a second on an ordinary personal computer and requires
negligible 11MB of memory. Up to terms of degree 30, which is the maximum
degree the program can handle, the computation of 74248451 coefficients takes
55 hours but still requires only a modest 5.5GB of memory.
</summary>
    <author>
      <name>Harald Hofstätter</name>
    </author>
    <link href="http://arxiv.org/abs/2102.06570v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.06570v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.06827v1</id>
    <updated>2021-02-13T00:25:13Z</updated>
    <published>2021-02-13T00:25:13Z</published>
    <title>COMET: A Domain-Specific Compilation of High-Performance Computational
  Chemistry</title>
    <summary>  The computational power increases over the past decades havegreatly enhanced
the ability to simulate chemical reactions andunderstand ever more complex
transformations. Tensor contractions are the fundamental computational building
block of these simulations. These simulations have often been tied to one
platform and restricted in generality by the interface provided to the user.
The expanding prevalence of accelerators and researcher demands necessitate a
more general approach which is not tied to specific hardware or requires
contortion of algorithms to specific hardware platforms. In this paper we
present COMET, a domain-specific programming language and compiler
infrastructure for tensor contractions targeting heterogeneous accelerators. We
present a system of progressive lowering through multiple layers of abstraction
and optimization that achieves up to 1.98X speedup for 30 tensor contractions
commonly used in computational chemistry and beyond.
</summary>
    <author>
      <name>Erdal Mutlu</name>
    </author>
    <author>
      <name>Ruiqin Tian</name>
    </author>
    <author>
      <name>Bin Ren</name>
    </author>
    <author>
      <name>Sriram Krishnamoorthy</name>
    </author>
    <author>
      <name>Roberto Gioiosa</name>
    </author>
    <author>
      <name>Jacques Pienaar</name>
    </author>
    <author>
      <name>Gokcen Kestor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceeding of the 33rd the Workshop on Languages and Compilers for
  Parallel Computing (LCPC), October 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2102.06827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.06827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.07833v3</id>
    <updated>2021-10-14T17:44:05Z</updated>
    <published>2021-02-15T20:21:05Z</published>
    <title>Quasi-Monte Carlo Software</title>
    <summary>  Practitioners wishing to experience the efficiency gains from using low
discrepancy sequences need correct, robust, well-written software. This
article, based on our MCQMC 2020 tutorial, describes some of the better
quasi-Monte Carlo (QMC) software available. We highlight the key software
components required by QMC to approximate multivariate integrals or
expectations of functions of vector random variables. We have combined these
components in QMCPy, a Python open-source library, which we hope will draw the
support of the QMC community. Here we introduce QMCPy.
</summary>
    <author>
      <name>Sou-Cheng T. Choi</name>
    </author>
    <author>
      <name>Fred J. Hickernell</name>
    </author>
    <author>
      <name>R. Jagadeeswaran</name>
    </author>
    <author>
      <name>Michael J. McCourt</name>
    </author>
    <author>
      <name>Aleksei G. Sorokin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 7 figures, to be published in the MCQMC2020 Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/2102.07833v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.07833v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.09562v1</id>
    <updated>2021-02-18T14:20:15Z</updated>
    <published>2021-02-18T14:20:15Z</published>
    <title>Using Jupyter for reproducible scientific workflows</title>
    <summary>  Literate computing has emerged as an important tool for computational studies
and open science, with growing folklore of best practices. In this work, we
report two case studies - one in computational magnetism and another in
computational mathematics - where domain-specific software was exposed to the
Jupyter environment. This enables high-level control of simulations and
computation, interactive exploration of computational results, batch processing
on HPC resources, and reproducible workflow documentation in Jupyter notebooks.
In the first study, Ubermag drives existing computational micromagnetics
software through a domain-specific language embedded in Python. In the second
study, a dedicated Jupyter kernel interfaces with the GAP system for
computational discrete algebra and its dedicated programming language. In light
of these case studies, we discuss the benefits of this approach, including
progress toward more reproducible and reusable research results and outputs,
notably through the use of infrastructure such as JupyterHub and Binder.
</summary>
    <author>
      <name>Marijan Beg</name>
    </author>
    <author>
      <name>Juliette Taka</name>
    </author>
    <author>
      <name>Thomas Kluyver</name>
    </author>
    <author>
      <name>Alexander Konovalov</name>
    </author>
    <author>
      <name>Min Ragan-Kelley</name>
    </author>
    <author>
      <name>Nicolas M. Thiéry</name>
    </author>
    <author>
      <name>Hans Fangohr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MCSE.2021.3052101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MCSE.2021.3052101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computing in Science &amp; Engineering 23, 36-46 (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2102.09562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.09562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.01243v1</id>
    <updated>2021-07-02T19:28:27Z</updated>
    <published>2021-07-02T19:28:27Z</published>
    <title>Neko: A Modern, Portable, and Scalable Framework for High-Fidelity
  Computational Fluid Dynamics</title>
    <summary>  Recent trends and advancement in including more diverse and heterogeneous
hardware in High-Performance Computing is challenging software developers in
their pursuit for good performance and numerical stability. The well-known
maxim "software outlives hardware" may no longer necessarily hold true, and
developers are today forced to re-factor their codebases to leverage these
powerful new systems. CFD is one of the many application domains affected. In
this paper, we present Neko, a portable framework for high-order spectral
element flow simulations. Unlike prior works, Neko adopts a modern
object-oriented approach, allowing multi-tier abstractions of the solver stack
and facilitating hardware backends ranging from general-purpose processors down
to exotic vector processors and FPGAs. We show that Neko's performance and
accuracy are comparable to NekRS, and thus on-par with Nek5000's successor on
modern CPU machines. Furthermore, we develop a performance model, which we use
to discuss challenges and opportunities for high-order solvers on emerging
hardware.
</summary>
    <author>
      <name>Niclas Jansson</name>
    </author>
    <author>
      <name>Martin Karp</name>
    </author>
    <author>
      <name>Artur Podobas</name>
    </author>
    <author>
      <name>Stefano Markidis</name>
    </author>
    <author>
      <name>Philipp Schlatter</name>
    </author>
    <link href="http://arxiv.org/abs/2107.01243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.01243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.04121v1</id>
    <updated>2021-07-07T15:08:24Z</updated>
    <published>2021-07-07T15:08:24Z</published>
    <title>Fast Evaluation of Finite Element Weak Forms Using Python Tensor
  Contraction Packages</title>
    <summary>  In finite element calculations, the integral forms are usually evaluated
using nested loops over elements, and over quadrature points. Many such forms
(e.g. linear or multi-linear) can be expressed in a compact way, without the
explicit loops, using a single tensor contraction expression by employing the
Einstein summation convention. To automate this process and leverage existing
high performance codes, we first introduce a notation allowing trivial
differentiation of multi-linear finite element forms. Based on that we propose
and describe a new transpiler from Einstein summation based expressions,
augmented to allow defining multi-linear finite element weak forms, to regular
tensor contraction expressions. The resulting expressions are compatible with a
number of Python scientific computing packages, that implement, optimize and in
some cases parallelize the general tensor contractions. We assess the
performance of those packages, as well as the influence of operand memory
layouts and tensor contraction paths optimizations on the elapsed time and
memory requirements of the finite element form evaluations. We also compare the
efficiency of the transpiled weak form implementations to the C-based functions
available in the finite element package SfePy.
</summary>
    <author>
      <name>Robert Cimrman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advengsoft.2021.103033</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advengsoft.2021.103033" rel="related"/>
    <link href="http://arxiv.org/abs/2107.04121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.04121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.04632v1</id>
    <updated>2021-07-09T19:00:33Z</updated>
    <published>2021-07-09T19:00:33Z</published>
    <title>Algorithmic Causal Effect Identification with causaleffect</title>
    <summary>  Our evolution as a species made a huge step forward when we understood the
relationships between causes and effects. These associations may be trivial for
some events, but they are not in complex scenarios. To rigorously prove that
some occurrences are caused by others, causal theory and causal inference were
formalized, introducing the $do$-operator and its associated rules. The main
goal of this report is to review and implement in Python some algorithms to
compute conditional and non-conditional causal queries from observational data.
To this end, we first present some basic background knowledge on probability
and graph theory, before introducing important results on causal theory, used
in the construction of the algorithms. We then thoroughly study the
identification algorithms presented by Shpitser and Pearl in 2006, explaining
our implementation in Python alongside. The main identification algorithm can
be seen as a repeated application of the rules of $do$-calculus, and it
eventually either returns an expression for the causal query from experimental
probabilities or fails to identify the causal effect, in which case the effect
is non-identifiable. We introduce our newly developed Python library and give
some usage examples.
</summary>
    <author>
      <name>Martí Pedemonte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat de Barcelona</arxiv:affiliation>
    </author>
    <author>
      <name>Jordi Vitrià</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat de Barcelona</arxiv:affiliation>
    </author>
    <author>
      <name>Álvaro Parafita</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat de Barcelona</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 27 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.04632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.04632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62D20 (Primary), 62H22 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.05761v1</id>
    <updated>2021-07-12T22:12:33Z</updated>
    <published>2021-07-12T22:12:33Z</published>
    <title>Faster Math Functions, Soundly</title>
    <summary>  Standard library implementations of functions like sin and exp optimize for
accuracy, not speed, because they are intended for general-purpose use. But
applications tolerate inaccuracy from cancellation, rounding error, and
singularities-sometimes even very high error-and many application could
tolerate error in function implementations as well. This raises an intriguing
possibility: speeding up numerical code by tuning standard function
implementations. This paper thus introduces OpTuner, an automatic method for
selecting the best implementation of mathematical functions at each use site.
OpTuner assembles dozens of implementations for the standard mathematical
functions from across the speed-accuracy spectrum. OpTuner then uses error
Taylor series and integer linear programming to compute optimal assignments of
function implementation to use site and presents the user with a speed-accuracy
Pareto curve they can use to speed up their code. In a case study on the
POV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a
whole program speedup of 9% with no change in the program output (whereas human
efforts result in slower code and lower-quality output). On a broader study of
37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and
demonstrates speed-ups of 107% for negligible decreases in accuracy and of up
to 438% for error-tolerant applications.
</summary>
    <author>
      <name>Ian Briggs</name>
    </author>
    <author>
      <name>Pavel Panchekha</name>
    </author>
    <link href="http://arxiv.org/abs/2107.05761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.05761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.14027v2</id>
    <updated>2021-11-15T17:19:30Z</updated>
    <published>2021-07-22T18:22:27Z</published>
    <title>Hyperbolic Diffusion in Flux Reconstruction: Optimisation through Kernel
  Fusion within Tensor-Product Elements</title>
    <summary>  Novel methods are presented in this initial study for the fusion of GPU
kernels in the artificial compressibility method (ACM), using tensor product
elements with constant Jacobians and flux reconstruction. This is made possible
through the hyperbolisation of the diffusion terms, which eliminates the
expensive algorithmic steps needed to form the viscous stresses. Two fusion
approaches are presented, which offer differing levels of parallelism. This is
found to be necessary for the change in workload as the order of accuracy of
the elements is increased. Several further optimisations of these approaches
are demonstrated, including a generation time memory manager which maximises
resource usage. The fused kernels are able to achieve 3-4 times speedup, which
compares favourably with a theoretical maximum speedup of 4. In three
dimensional test cases, the generated fused kernels are found to reduce total
runtime by ${\sim}25\%$, and, when compared to the standard ACM formulation,
simulations demonstrate that a speedup of $2.3$ times can be achieved.
</summary>
    <author>
      <name>Will Trojak</name>
    </author>
    <author>
      <name>Rob Watson</name>
    </author>
    <author>
      <name>Freddie Witherden</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2021.108235</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2021.108235" rel="related"/>
    <link href="http://arxiv.org/abs/2107.14027v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.14027v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.14552v1</id>
    <updated>2021-07-30T11:09:23Z</updated>
    <published>2021-07-30T11:09:23Z</published>
    <title>High Performance Uncertainty Quantification with Parallelized Multilevel
  Markov Chain Monte Carlo</title>
    <summary>  Numerical models of complex real-world phenomena often necessitate High
Performance Computing (HPC). Uncertainties increase problem dimensionality
further and pose even greater challenges.
  We present a parallelization strategy for multilevel Markov chain Monte
Carlo, a state-of-the-art, algorithmically scalable Uncertainty Quantification
(UQ) algorithm for Bayesian inverse problems, and a new software framework
allowing for large-scale parallelism across forward model evaluations and the
UQ algorithms themselves. The main scalability challenge presents itself in the
form of strong data dependencies introduced by the MLMCMC method, prohibiting
trivial parallelization.
  Our software is released as part of the modular and open-source MIT UQ
Library (MUQ), and can easily be coupled with arbitrary user codes. We
demonstrate it using the DUNE and the ExaHyPE Engine. The latter provides a
realistic, large-scale tsunami model in which identify the source of a tsunami
from buoy-elevation data.
</summary>
    <author>
      <name>Linus Seelinger</name>
    </author>
    <author>
      <name>Anne Reinarz</name>
    </author>
    <author>
      <name>Leonhard Rannabauer</name>
    </author>
    <author>
      <name>Michael Bader</name>
    </author>
    <author>
      <name>Peter Bastian</name>
    </author>
    <author>
      <name>Robert Scheichl</name>
    </author>
    <link href="http://arxiv.org/abs/2107.14552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.14552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00241v1</id>
    <updated>2022-01-01T20:53:09Z</updated>
    <published>2022-01-01T20:53:09Z</published>
    <title>Batched Second-Order Adjoint Sensitivity for Reduced Space Methods</title>
    <summary>  This paper presents an efficient method for extracting the second-order
sensitivities from a system of implicit nonlinear equations on upcoming
graphical processing units (GPU) dominated computer systems. We design a custom
automatic differentiation (AutoDiff) backend that targets highly parallel
architectures by extracting the second-order information in batch. When the
nonlinear equations are associated to a reduced space optimization problem, we
leverage the parallel reverse-mode accumulation in a batched adjoint-adjoint
algorithm to compute efficiently the reduced Hessian of the problem. We apply
the method to extract the reduced Hessian associated to the balance equations
of a power network, and show on the largest instances that a parallel GPU
implementation is 30 times faster than a sequential CPU reference based on
UMFPACK.
</summary>
    <author>
      <name>François Pacaud</name>
    </author>
    <author>
      <name>Michel Schanen</name>
    </author>
    <author>
      <name>Daniel Adrian Maldonado</name>
    </author>
    <author>
      <name>Alexis Montoison</name>
    </author>
    <author>
      <name>Valentin Churavy</name>
    </author>
    <author>
      <name>Julian Samaroo</name>
    </author>
    <author>
      <name>Mihai Anitescu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/1.9781611977141.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/1.9781611977141.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM-PP22</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.00241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.01189v1</id>
    <updated>2021-12-31T17:08:08Z</updated>
    <published>2021-12-31T17:08:08Z</published>
    <title>Olsson.wl : a Mathematica package for the computation of linear
  transformations of multivariable hypergeometric functions</title>
    <summary>  We present the Olsson$.$wl Mathematica package which aims to find linear
transformations for some classes of multivariable hypergeometric functions. It
is based on a well-known method developed by P. O. M. Olsson in J. Math. Phys.
5, 420 (1964) in order to derive the analytic continuations of the Appell $F_1$
double hypergeometric series from the linear transformations of the Gauss
$_2F_1$ hypergeometric function. We provide a brief description of Olsson's
method and demonstrate the commands of the package, along with examples. We
also provide a companion package, called ROC2$.$wl and dedicated to the
derivation of the regions of convergence of double hypergeometric series. This
package can be used independently of Olsson$.$wl.
</summary>
    <author>
      <name>B. Ananthanarayan</name>
    </author>
    <author>
      <name>Souvik Bera</name>
    </author>
    <author>
      <name>S. Friot</name>
    </author>
    <author>
      <name>Tanay Pathak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 1 figure and 2 ancillary files</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.01189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.01189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.06504v1</id>
    <updated>2022-01-17T16:29:28Z</updated>
    <published>2022-01-17T16:29:28Z</published>
    <title>MUPen2DTool: a Matlab Tool for 2D Nuclear Magnetic Resonance relaxation
  data inversion</title>
    <summary>  Accurate and efficient analysis of materials properties from Nuclear Magnetic
Resonance (NMR) relaxation data requires robust and efficient inversion
procedures. Despite the great variety of applications requiring to process
two-dimensional NMR data (2DNMR), a few software tools are freely available.
The aim of this paper is to present MUPen2DTool, an open-source MATLAB based
software tool for 2DNMR data inversion. The user can choose among several types
of NMR experiments, and the software provides codes that can be used and
extended easily. Furthermore, a MATLAB interface makes it easier to include
users own data. The practical use is demonstrated in the reported examples of
both synthetic and real NMR data.
</summary>
    <author>
      <name>Villiam Bortolotti</name>
    </author>
    <author>
      <name>Leonardo Brizi</name>
    </author>
    <author>
      <name>Germana Landi</name>
    </author>
    <author>
      <name>Anastasiia Nagmutdinova</name>
    </author>
    <author>
      <name>Fabiana Zama</name>
    </author>
    <link href="http://arxiv.org/abs/2201.06504v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.06504v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Z05, 68V35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.0; G.1; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.06968v1</id>
    <updated>2022-01-12T07:32:36Z</updated>
    <published>2022-01-12T07:32:36Z</published>
    <title>PyHHMM: A Python Library for Heterogeneous Hidden Markov Models</title>
    <summary>  We introduce PyHHMM, an object-oriented open-source Python implementation of
Heterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core
functionalities, such as different initialization algorithms and classical
observations models, i.e., continuous and multinoulli, PyHHMM distinctively
emphasizes features not supported in similar available frameworks: a
heterogeneous observation model, missing data inference, different model order
selection criterias, and semi-supervised training. These characteristics result
in a feature-rich implementation for researchers working with sequential data.
PyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages,
and is distributed under the Apache-2.0 License. PyHHMM's source code is
publicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM)
to facilitate adoptions and future contributions. A detailed documentation
(https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and
models' theoretical explanation, is available. The package can be installed
through the Python Package Index (PyPI), via 'pip install pyhhmm'.
</summary>
    <author>
      <name>Fernando Moreno-Pino</name>
    </author>
    <author>
      <name>Emese Sükei</name>
    </author>
    <author>
      <name>Pablo M. Olmos</name>
    </author>
    <author>
      <name>Antonio Artés-Rodríguez</name>
    </author>
    <link href="http://arxiv.org/abs/2201.06968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.06968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.09056v1</id>
    <updated>2022-02-18T07:45:39Z</updated>
    <published>2022-02-18T07:45:39Z</published>
    <title>Efficient solution of 3D elasticity problems with smoothed aggregation
  algebraic multigrid and block arithmetics</title>
    <summary>  Efficient solution of 3D elasticity problems is an important part of many
industrial and scientific applications. Smoothed aggregation algebraic
multigrid using rigid body modes for the tentative prolongation operator
construction is an efficient and robust choice for the solution of linear
systems arising from the discretization of elasticity equations. The system
matrices on every level of the multigrid hierarchy have block structure, so
using block representation and block arithmetics should significantly improve
the solver efficiency. However, the tentative prolongation operator
construction may only be done using scalar representation. The paper proposes a
couple of practical approaches for enabling the use of block arithmetics with
smoothed aggregation algebraic multigrid based on the open-source AMGCL
library. It is shown on the example of two real-world model problems that the
suggested improvements may speed up the solution by 50% and reduce the memory
requirements for the preconditioner by 30%. The implementation is
straightforward and only requires a minimal amount of code.
</summary>
    <author>
      <name>Denis Demidov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.09056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.09056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.07824v1</id>
    <updated>2022-05-16T17:28:28Z</updated>
    <published>2022-05-16T17:28:28Z</published>
    <title>Exasim: Generating Discontinuous Galerkin Codes for Numerical Solutions
  of Partial Differential Equations on Graphics Processors</title>
    <summary>  This paper presents an overview of the functionalities and applications of
Exasim, an open-source code for generating high-order discontinuous Galerkin
codes to numerically solve parametrized partial differential equations (PDEs).
The software combines high-level and low-level languages to construct
parametrized PDE models via Julia, Python or Matlab scripts and produce
high-performance C++ codes for solving the PDE models on CPU and Nvidia GPU
processors with distributed memory. Exasim provides matrix-free discontinuous
Galerkin discretization schemes together with scalable reduced basis
preconditioners and Newton-GMRES solvers, making it suitable for accurate and
efficient approximation of wide-ranging classes of PDEs.
</summary>
    <author>
      <name>Jordi Vila-Pérez</name>
    </author>
    <author>
      <name>R. Loek Van Heyningen</name>
    </author>
    <author>
      <name>Ngoc-Cuong Nguyen</name>
    </author>
    <author>
      <name>Jaume Peraire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.07824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.07824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M60, 65Y05, 65Y10, 65Z05, 68N99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.08909v1</id>
    <updated>2022-05-18T13:04:00Z</updated>
    <published>2022-05-18T13:04:00Z</published>
    <title>Enhancing data locality of the conjugate gradient method for high-order
  matrix-free finite-element implementations</title>
    <summary>  This work investigates a variant of the conjugate gradient (CG) method and
embeds it into the context of high-order finite-element schemes with fast
matrix-free operator evaluation and cheap preconditioners like the matrix
diagonal. Relying on a data-dependency analysis and appropriate enumeration of
degrees of freedom, we interleave the vector updates and inner products in a CG
iteration with the matrix-vector product with only minor organizational
overhead. As a result, around 90% of the vector entries of the three active
vectors of the CG method are transferred from slow RAM memory exactly once per
iteration, with all additional access hitting fast cache memory. Node-level
performance analyses and scaling studies on up to 147k cores show that the CG
method with the proposed performance optimizations is around two times faster
than a standard CG solver as well as optimized pipelined CG and s-step CG
methods for large sizes that exceed processor caches, and provides similar
performance near the strong scaling limit.
</summary>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <author>
      <name>Dmytro Sashko</name>
    </author>
    <author>
      <name>Peter Munch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.08909v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.08909v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.12721v2</id>
    <updated>2022-12-02T00:39:59Z</updated>
    <published>2022-05-24T00:50:44Z</published>
    <title>Accelerating High-Order Mesh Optimization Using Finite Element Partial
  Assembly on GPUs</title>
    <summary>  In this paper we present a new GPU-oriented mesh optimization method based on
high-order finite elements. Our approach relies on node movement with fixed
topology, through the Target-Matrix Optimization Paradigm (TMOP) and uses a
global nonlinear solve over the whole computational mesh, i.e., all mesh nodes
are moved together. A key property of the method is that the mesh optimization
process is recast in terms of finite element operations, which allows us to
utilize recent advances in the field of GPU-accelerated high-order finite
element algorithms. For example, we reduce data motion by using tensor
factorization and matrix-free methods, which have superior performance
characteristics compared to traditional full finite element matrix assembly and
offer advantages for GPU-based HPC hardware. We describe the major mathematical
components of the method along with their efficient GPU-oriented
implementation. In addition, we propose an easily reproducible mesh
optimization test that can serve as a performance benchmark for the mesh
optimization community.
</summary>
    <author>
      <name>Jean-Sylvain Camier</name>
    </author>
    <author>
      <name>Veselin Dobrev</name>
    </author>
    <author>
      <name>Patrick Knupp</name>
    </author>
    <author>
      <name>Tzanio Kolev</name>
    </author>
    <author>
      <name>Ketan Mittal</name>
    </author>
    <author>
      <name>Robert Rieben</name>
    </author>
    <author>
      <name>Vladimir Tomov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2022.111808</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2022.111808" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 10 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.12721v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.12721v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.14077v2</id>
    <updated>2022-12-21T21:50:25Z</updated>
    <published>2022-05-27T16:16:19Z</published>
    <title>ARKODE: a flexible IVP solver infrastructure for one-step methods</title>
    <summary>  We describe the ARKODE library of one-step time integration methods for
ordinary differential equation (ODE) initial-value problems (IVPs). In addition
to providing standard explicit and diagonally implicit Runge--Kutta methods,
ARKODE also supports one-step methods designed to treat additive splittings of
the IVP, including implicit-explicit (ImEx) additive Runge--Kutta methods and
multirate infinitesimal (MRI) methods. We present the role of ARKODE within the
SUNDIALS suite of time integration and nonlinear solver libraries, the core
ARKODE infrastructure for utilities common to large classes of one-step
methods, as well as its use of ``time stepper'' modules enabling easy
incorporation of novel algorithms into the library. Numerical results show
example problems of increasing complexity, highlighting the algorithmic
flexibility afforded through this infrastructure, and include a larger
multiphysics application leveraging multiple algorithmic features from ARKODE
and SUNDIALS.
</summary>
    <author>
      <name>Daniel R. Reynolds</name>
    </author>
    <author>
      <name>David J. Gardner</name>
    </author>
    <author>
      <name>Carol S. Woodward</name>
    </author>
    <author>
      <name>Rujeko Chinomona</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3594632</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3594632" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, Volume 49, Issue 2,
  June 2023, Article No.: 19</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2205.14077v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.14077v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.07098v1</id>
    <updated>2022-06-23T12:41:19Z</updated>
    <published>2022-06-23T12:41:19Z</published>
    <title>Large-Scale Direct Numerical Simulations of Turbulence Using GPUs and
  Modern Fortran</title>
    <summary>  We present our approach to making direct numerical simulations of turbulence
with applications in sustainable shipping. We use modern Fortran and the
spectral element method to leverage and scale on supercomputers powered by the
Nvidia A100 and the recent AMD Instinct MI250X GPUs, while still providing
support for user software developed in Fortran. We demonstrate the efficiency
of our approach by performing the world's first direct numerical simulation of
the flow around a Flettner rotor at Re=30'000 and its interaction with a
turbulent boundary layer. We present one of the first performance comparisons
between the AMD Instinct MI250X and Nvidia A100 GPUs for scalable computational
fluid dynamics. Our results show that one MI250X offers performance on par with
two A100 GPUs and has a similar power efficiency.
</summary>
    <author>
      <name>Martin Karp</name>
    </author>
    <author>
      <name>Daniele Massaro</name>
    </author>
    <author>
      <name>Niclas Jansson</name>
    </author>
    <author>
      <name>Alistair Hart</name>
    </author>
    <author>
      <name>Jacob Wahlgren</name>
    </author>
    <author>
      <name>Philipp Schlatter</name>
    </author>
    <author>
      <name>Stefano Markidis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2207.07098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.07098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.13862v2</id>
    <updated>2023-11-09T01:35:10Z</updated>
    <published>2022-07-28T02:35:08Z</published>
    <title>HDSDP: Software for Semidefinite Programming</title>
    <summary>  HDSDP is a numerical software solving the semidefinite programming problems.
The main framework of HDSDP resembles the dual-scaling interior point solver
DSDP [BY2008] and several new features, including a dual method based on the
simplified homogeneous self-dual embedding, have been implemented. The
embedding technique enhances stability of the dual method and several new
heuristics and computational techniques are designed to accelerate its
convergence. HDSDP aims to show how dual-scaling algorithm benefits from the
self-dual embedding and it is developed in parallel to DSDP5.8. Numerical
experiments over several classical benchmark datasets exhibit its robustness
and efficiency, and particularly its advantages on SDP instances featuring
low-rank structure and sparsity. HDSDP is open-sourced under MIT license and
available at https://github.com/COPT-Public/HDSDP.
</summary>
    <author>
      <name>Wenzhi Gao</name>
    </author>
    <author>
      <name>Dongdong Ge</name>
    </author>
    <author>
      <name>Yinyu Ye</name>
    </author>
    <link href="http://arxiv.org/abs/2207.13862v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.13862v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.14668v3</id>
    <updated>2022-11-11T13:25:20Z</updated>
    <published>2022-07-29T13:24:30Z</published>
    <title>lifex: a flexible, high performance library for the numerical solution
  of complex finite element problems</title>
    <summary>  Numerical simulations are ubiquitous in mathematics and computational
science. Several industrial and clinical applications entail modeling complex
multiphysics systems that evolve over a variety of spatial and temporal scales.
  This study introduces the design and capabilities of lifex, an open source
C++ library for high performance finite element simulations of multiphysics,
multiscale, and multidomain problems. lifex meets the emerging need for
versatile, efficient computational tools that are easily accessed by users and
developers. We showcase its flexibility and effectiveness on a number of
illustrative examples and advanced applications of use and demonstrate its
parallel performance up to thousands of cores.
</summary>
    <author>
      <name>Pasquale Claudio Africa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2022.101252</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2022.101252" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SoftwareX 20 (2022), p. 101252. issn: 2352-7110</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2207.14668v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.14668v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04 (Primary) 65-04, 65Y05, 65Y20, 68-04, 68N30 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.00049v2</id>
    <updated>2023-01-28T07:05:39Z</updated>
    <published>2022-07-29T19:32:48Z</published>
    <title>NFFT.jl: Generic and Fast Julia Implementation of the Nonequidistant
  Fast Fourier Transform</title>
    <summary>  The non-equidistant fast Fourier transform (NFFT) is an extension of the
famous fast Fourier transform (FFT), which can be applied to non-equidistantly
sampled data in time/space or frequency domain. It is an approximative
algorithm that allows to control the approximation error in such a way that
machine precision is reached while keeping the algorithmic complexity in the
same order as a regular FFT. The NFFT plays a major role in many signal
processing applications and has been intensively studied from a theoretical and
computational perspective. The fastest CPU implementations of the NFFT are
implemented in the low-level programming languages C and C++ and require a
compromise between code generalizability, code readability, and code
efficiency. The programming language Julia promises new opportunities in
optimizing these three conflicting goals. In this work we show that Julia
indeed allows to develop an NFFT implementation, which is completely generic,
dimension-agnostic and requires about 2-3 times less code than other famous
libraries while still being one of the fastest NFFT implementations developed
to date.
</summary>
    <author>
      <name>Tobias Knopp</name>
    </author>
    <author>
      <name>Marija Boberg</name>
    </author>
    <author>
      <name>Mirco Grosser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.00049v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.00049v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65T50, 65T40, 65Y05, 68N01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.08530v1</id>
    <updated>2022-08-17T20:52:46Z</updated>
    <published>2022-08-17T20:52:46Z</published>
    <title>Survey of Methods for Solving Systems of Nonlinear Equations, Part I:
  Root-finding Approaches</title>
    <summary>  This paper presents a comprehensive survey of methods which can be utilized
to search for solutions to systems of nonlinear equations (SNEs). Our
objectives with this survey are to synthesize pertinent literature in this
field by presenting a thorough description and analysis of the known methods
capable of finding one or many solutions to SNEs, and to assist interested
readers seeking to identify solution techniques which are well suited for
solving the various classes of SNEs which one may encounter in real world
applications.
  To accomplish these objectives, we present a multi-part survey. In part one,
we focus on root-finding approaches which can be used to search for solutions
to a SNE without transforming it into an optimization problem. In part two, we
will introduce the various transformations which have been utilized to
transform a SNE into an optimization problem, and we discuss optimization
algorithms which can then be used to search for solutions. In part three, we
will present a robust quantitative comparative analysis of methods capable of
searching for solutions to SNEs.
</summary>
    <author>
      <name>Ilias S. Kotsireas</name>
    </author>
    <author>
      <name>Panos M. Pardalos</name>
    </author>
    <author>
      <name>Alexander Semenov</name>
    </author>
    <author>
      <name>William T. Trevena</name>
    </author>
    <author>
      <name>Michael N. Vrahatis</name>
    </author>
    <link href="http://arxiv.org/abs/2208.08530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.08530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.08532v1</id>
    <updated>2022-08-17T20:58:11Z</updated>
    <published>2022-08-17T20:58:11Z</published>
    <title>Survey of Methods for Solving Systems of Nonlinear Equations, Part II:
  Optimization Based Approaches</title>
    <summary>  This paper presents a comprehensive survey of methods which can be utilized
to search for solutions to systems of nonlinear equations (SNEs). Our
objectives with this survey are to synthesize pertinent literature in this
field by presenting a thorough description and analysis of the known methods
capable of finding one or many solutions to SNEs, and to assist interested
readers seeking to identify solution techniques which are well suited for
solving the various classes of SNEs which one may encounter in real world
applications.
  To accomplish these objectives, we present a multi-part survey. In part one,
we focused on root-finding approaches which can be used to search for solutions
to a SNE without transforming it into an optimization problem. In part two, we
introduce the various transformations which have been utilized to transform a
SNE into an optimization problem, and we discuss optimization algorithms which
can then be used to search for solutions. We emphasize the important
characteristics of each method, and we discuss promising directions for future
research. In part three, we will present a robust quantitative comparative
analysis of methods capable of searching for solutions to SNEs.
</summary>
    <author>
      <name>Ilias S. Kotsireas</name>
    </author>
    <author>
      <name>Panos M. Pardalos</name>
    </author>
    <author>
      <name>Alexander Semenov</name>
    </author>
    <author>
      <name>William T. Trevena</name>
    </author>
    <author>
      <name>Michael N. Vrahatis</name>
    </author>
    <link href="http://arxiv.org/abs/2208.08532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.08532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.11395v1</id>
    <updated>2022-08-24T09:34:44Z</updated>
    <published>2022-08-24T09:34:44Z</published>
    <title>Distributed Objective Function Evaluation for Optimization of Radiation
  Therapy Treatment Plans</title>
    <summary>  The modern workflow for radiation therapy treatment planning involves
mathematical optimization to determine optimal treatment machine parameters for
each patient case. The optimization problems can be computationally expensive,
requiring iterative optimization algorithms to solve. In this work, we
investigate a method for distributing the calculation of objective functions
and gradients for radiation therapy optimization problems across computational
nodes. We test our approach on the TROTS dataset -- which consists of
optimization problems from real clinical patient cases -- using the IPOPT
optimization solver in a leader/follower type approach for parallelization. We
show that our approach can utilize multiple computational nodes efficiently,
with a speedup of approximately 2-3.5 times compared to the serial version.
</summary>
    <author>
      <name>Felix Liu</name>
    </author>
    <author>
      <name>Måns I. Andersson</name>
    </author>
    <author>
      <name>Albin Fredriksson</name>
    </author>
    <author>
      <name>Stefano Markidis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-30442-2_29</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-30442-2_29" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at the PPAM22 conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Parallel Processing and Applied Mathematics. PPAM 2022. Lecture
  Notes in Computer Science, vol 13826. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2208.11395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.11395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.01877v1</id>
    <updated>2022-09-05T10:23:30Z</updated>
    <published>2022-09-05T10:23:30Z</published>
    <title>Performance optimization and analysis of the unstructured Discontinuous
  Galerkin solver on multi-core and many-core architectures</title>
    <summary>  The discontinuous Galerkin (DG) algorithm is a representative high order
method in Computational Fluid Dynamics (CFD) area which possesses considerable
mathematical advantages such as high resolution, low dissipation, and
dispersion. However, DG is rather computationally intensive to demonstrate
practical engineering problems. This paper discusses the implementation of our
in-house practical DG application in three different programming models, as
well as some optimization techniques, including grid renumbering and mixed
precision to maximize the performance improvements in a single node system. The
experiment on CPU and GPU shows that our CUDA, OpenACC, and OpenMP-based code
obtains a maximum speedup of 42.9x, 35.3x, and 8.1x compared with serial
execution by the original application, respectively. Besides, we systematically
compare the programming models in two aspects: performance and productivity.
Our empirical conclusions facilitate the programmers to select the right
platform with a suitable programming model according to their target
applications.
</summary>
    <author>
      <name>Zhe Dai</name>
    </author>
    <author>
      <name>Liang D</name>
    </author>
    <author>
      <name>Yueqin Wang</name>
    </author>
    <author>
      <name>Fang Wang</name>
    </author>
    <author>
      <name>Li Ming</name>
    </author>
    <author>
      <name>Jian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8pages,conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.01877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.01877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.06934v1</id>
    <updated>2022-11-13T15:59:17Z</updated>
    <published>2022-11-13T15:59:17Z</published>
    <title>TorchOpt: An Efficient Library for Differentiable Optimization</title>
    <summary>  Recent years have witnessed the booming of various differentiable
optimization algorithms. These algorithms exhibit different execution patterns,
and their execution needs massive computational resources that go beyond a
single CPU and GPU. Existing differentiable optimization libraries, however,
cannot support efficient algorithm development and multi-CPU/GPU execution,
making the development of differentiable optimization algorithms often
cumbersome and expensive. This paper introduces TorchOpt, a PyTorch-based
efficient library for differentiable optimization. TorchOpt provides a unified
and expressive differentiable optimization programming abstraction. This
abstraction allows users to efficiently declare and analyze various
differentiable optimization programs with explicit gradients, implicit
gradients, and zero-order gradients. TorchOpt further provides a
high-performance distributed execution runtime. This runtime can fully
parallelize computation-intensive differentiation operations (e.g. tensor tree
flattening) on CPUs / GPUs and automatically distribute computation to
distributed devices. Experimental results show that TorchOpt achieves
$5.2\times$ training time speedup on an 8-GPU server. TorchOpt is available at:
https://github.com/metaopt/torchopt/.
</summary>
    <author>
      <name>Jie Ren</name>
    </author>
    <author>
      <name>Xidong Feng</name>
    </author>
    <author>
      <name>Bo Liu</name>
    </author>
    <author>
      <name>Xuehai Pan</name>
    </author>
    <author>
      <name>Yao Fu</name>
    </author>
    <author>
      <name>Luo Mai</name>
    </author>
    <author>
      <name>Yaodong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2022 OPT Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2211.06934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.06934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.13760v1</id>
    <updated>2022-12-28T09:27:02Z</updated>
    <published>2022-12-28T09:27:02Z</published>
    <title>Reverse-Mode Automatic Differentiation of Compiled Programs</title>
    <summary>  Tools for algorithmic differentiation (AD) provide accurate derivatives of
computer-implemented functions for use in, e. g., optimization and machine
learning (ML). However, they often require the source code of the function to
be available in a restricted set of programming languages. As a step towards
making AD accessible for code bases with cross-language or closed-source
components, we recently presented the forward-mode AD tool Derivgrind. It
inserts forward-mode AD logic into the machine code of a compiled program using
the Valgrind dynamic binary instrumentation framework. This work extends
Derivgrind, adding the capability to record the real-arithmetic evaluation
tree, and thus enabling operator overloading style reverse-mode AD for compiled
programs. We maintain the high level of correctness reported for Derivgrind's
forward mode, failing the same few testcases in an extensive test suite for the
same well-understood reasons. Runtime-wise, the recording slows down the
execution of a compiled 64-bit benchmark program by a factor of about 180.
</summary>
    <author>
      <name>Max Aehle</name>
    </author>
    <author>
      <name>Johannes Blühdorn</name>
    </author>
    <author>
      <name>Max Sagebaum</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures, 1 listing</arxiv:comment>
    <link href="http://arxiv.org/abs/2212.13760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.13760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.01707v1</id>
    <updated>2023-01-04T17:10:39Z</updated>
    <published>2023-01-04T17:10:39Z</published>
    <title>Implementation of hyperbolic complex numbers in Julia language</title>
    <summary>  Background: Hyperbolic complex numbers are used in the description of
hyperbolic spaces. One of the well-known examples of such spaces is the
Minkowski space, which plays a leading role in the problems of the special
theory of relativity and electrodynamics. However, such numbers are not very
common in different programming languages. Purpose: Of interest is the
implementation of hyperbolic complex in scientific programming languages, in
particular, in the Julia language. Methods: The Julia language is based on the
concept of multiple dispatch. This concept is an extension of the concept of
polymorphism for object-oriented programming languages. To implement hyperbolic
complex numbers, the multiple dispatching approach of the Julia language was
used. Results: The result is a library that implements hyperbolic numbers.
Conclusions: Based on the results of the study, we can conclude that the
concept of multiple dispatching in scientific programming languages is
convenient and natural.
</summary>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <author>
      <name>Migran N. Gevorkyan</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.22363/2658-4670-2022-30-4-318-329</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.22363/2658-4670-2022-30-4-318-329" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English; in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/2301.01707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.01707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.05455v1</id>
    <updated>2023-01-13T09:48:36Z</updated>
    <published>2023-01-13T09:48:36Z</published>
    <title>DarSIA: An open-source Python toolbox for two-scale image processing of
  dynamics in porous media</title>
    <summary>  Understanding porous media flow is inherently a multi-scale challenge, where
at the core lies the aggregation of pore-level processes to a continuum, or
Darcy-scale, description. This challenge is directly mirrored in image
processing, where grains and interfaces may be clearly visible, yet continuous
parameters are desirable to measure. Classical image processing is poorly
adapted to this setting, as most techniques do not explicitly utilize the fact
that the image contains explicit physical processes.
  Here, we adapt classical image processing concepts to what we define as
physical images of porous materials and processes within them. This is realized
through the development of a new open-source image analysis toolbox
specifically adapted to time-series of images of porous materials.
</summary>
    <author>
      <name>Jan Martin Nordbotten</name>
    </author>
    <author>
      <name>Benyamine Benali</name>
    </author>
    <author>
      <name>Jakub Wiktor Both</name>
    </author>
    <author>
      <name>Bergit Brattekås</name>
    </author>
    <author>
      <name>Erlend Storvik</name>
    </author>
    <author>
      <name>Martin A. Fernø</name>
    </author>
    <link href="http://arxiv.org/abs/2301.05455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.05455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.00820v1</id>
    <updated>2023-02-02T02:03:22Z</updated>
    <published>2023-02-02T02:03:22Z</published>
    <title>mlpack 4: a fast, header-only C++ machine learning library</title>
    <summary>  For over 15 years, the mlpack machine learning library has served as a "swiss
army knife" for C++-based machine learning. Its efficient implementations of
common and cutting-edge machine learning algorithms have been used in a wide
variety of scientific and industrial applications. This paper overviews mlpack
4, a significant upgrade over its predecessor. The library has been
significantly refactored and redesigned to facilitate an easier
prototyping-to-deployment pipeline, including bindings to other languages
(Python, Julia, R, Go, and the command line) that allow prototyping to be
seamlessly performed in environments other than C++. mlpack is open-source
software, distributed under the permissive 3-clause BSD license; it can be
obtained at https://mlpack.org
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Omar Shrit</name>
    </author>
    <author>
      <name>Shubham Agrawal</name>
    </author>
    <author>
      <name>Suryoday Basak</name>
    </author>
    <author>
      <name>James J. Balamuta</name>
    </author>
    <author>
      <name>Ryan Birmingham</name>
    </author>
    <author>
      <name>Kartik Dutt</name>
    </author>
    <author>
      <name>Dirk Eddelbuettel</name>
    </author>
    <author>
      <name>Rishabh Garg</name>
    </author>
    <author>
      <name>Shikhar Jaiswal</name>
    </author>
    <author>
      <name>Aakash Kaushik</name>
    </author>
    <author>
      <name>Sangyeon Kim</name>
    </author>
    <author>
      <name>Anjishnu Mukherjee</name>
    </author>
    <author>
      <name>Nanubala Gnana Sai</name>
    </author>
    <author>
      <name>Nippun Sharma</name>
    </author>
    <author>
      <name>Yashwant Singh Parihar</name>
    </author>
    <author>
      <name>Roshan Swain</name>
    </author>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/joss.05026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/joss.05026" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Open Source Software, Vol. 8, No. 82, 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2302.00820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.00820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.04180v1</id>
    <updated>2023-02-08T16:39:01Z</updated>
    <published>2023-02-08T16:39:01Z</published>
    <title>General framework for re-assuring numerical reliability in parallel
  Krylov solvers: A case of BiCGStab methods</title>
    <summary>  Parallel implementations of Krylov subspace methods often help to accelerate
the procedure of finding an approximate solution of a linear system. However,
such parallelization coupled with asynchronous and out-of-order execution often
enlarge the non-associativity impact in floating-point operations. These
problems are even amplified when communication-hiding pipelined algorithms are
used to improve the parallelization of Krylov subspace methods. Introducing
reproducibility in the implementations avoids these problems by getting more
robust and correct solutions. This paper proposes a general framework for
deriving reproducible and accurate variants of Krylov subspace methods. The
proposed algorithmic strategies are reinforced by programmability suggestions
to assure deterministic and accurate executions. The framework is illustrated
on the preconditioned BiCGStab method and its pipelined modification, which in
fact is a distinctive method from the Krylov subspace family, for the solution
of non-symmetric linear systems with message-passing. Finally, we verify the
numerical behaviour of the two reproducible variants of BiCGStab on a set of
matrices from the SuiteSparse Matrix Collection and a 3D Poisson's equation.
</summary>
    <author>
      <name>Roman Iakymchuk</name>
    </author>
    <author>
      <name>Jose I. Aliaga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2005.07282</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.04180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.04180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.08417v2</id>
    <updated>2023-02-17T03:24:04Z</updated>
    <published>2023-02-16T16:52:49Z</published>
    <title>GEMMFIP: Unifying GEMM in BLIS</title>
    <summary>  Matrix libraries often focus on achieving high performance for problems
considered to be either "small" or "large", as these two scenarios tend to
respond best to different optimization strategies. We propose a unified
technique for implementing matrix operations like general matrix multiplication
(GEMM) that can achieve high performance for both small and large problem
sizes. The key is to fuse packing -- an operation that copies data to a
contiguous layout in memory and which is critical for large matrix performance
-- with the first computational "pass" over that data. This boosts performance
across the problem size spectrum. As a result, tuning general-purpose libraries
becomes simpler since it obviates the need to carefully express and
parameterize logic that chooses between a "small matrix" strategy and a "large
matrix" strategy. A prototype implementation of the technique built with the
BLAS-like Library Instantiation Software (BLIS) framework is described and
performance on a range of architectures is reported.
</summary>
    <author>
      <name>RuQing G. Xu</name>
    </author>
    <author>
      <name>Field G. Van Zee</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures, 2 algorithms</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.08417v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.08417v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.09005v1</id>
    <updated>2023-02-17T17:19:41Z</updated>
    <published>2023-02-17T17:19:41Z</published>
    <title>GPU Offloading in ExaHyPE Through C++ Standard Algorithms</title>
    <summary>  The ISO C++17 standard introduces \emph{parallel algorithms}, a parallel
programming model promising portability across a wide variety of parallel
hardware including multi-core CPUs, GPUs, and FPGAs. Since 2019, the NVIDIA HPC
SDK compiler suite supports this programming model for multi-core CPUs and
GPUs. ExaHyPE is a solver engine for hyperbolic partial differential equations
for complex wave phenomena. It supports multiple numerical methods including
Finite Volumes and ADER-DG, and employs adaptive mesh refinement with dynamic
load balancing via space-filling curves as well as task-based parallelism and
offloading to GPUs. This study ports ExaHyPE's tasks over blocks of Finite
Volumes to the ISO C++ parallel algorithms programming model, and compares its
performance and usability against an OpenMP implementation with offloading via
OpenMP target directives. It shows that ISO C++ is a feasible programming model
for non-trivial applications like our task-based AMR code. The realisation is
bare of vendor-specific or non-C++ extensions. It however is slower than its
OpenMP counterpart. \vspace{-1cm}
</summary>
    <author>
      <name>Uzmar Gomez</name>
    </author>
    <author>
      <name>Gonzalo Brito Gadeschi</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <link href="http://arxiv.org/abs/2302.09005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.09005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.12054v1</id>
    <updated>2023-02-23T14:27:50Z</updated>
    <published>2023-02-23T14:27:50Z</published>
    <title>PNet: A Python Library for Petri Net Modeling and Simulation</title>
    <summary>  Petri Net is a formalism to describe changes between 2 or more states across
discrete time and has been used to model many systems. We present PNet - a pure
Python library for Petri Net modeling and simulation in Python programming
language. The design of PNet focuses on reducing the learning curve needed to
define a Petri Net by using a text-based language rather than programming
constructs to define transition rules. Complex transition rules can be refined
as regular Python functions. To demonstrate the simplicity of PNet, we present
2 examples - bread baking, and epidemiological models.
</summary>
    <author>
      <name>Zhu En Chay</name>
    </author>
    <author>
      <name>Bing Feng Goh</name>
    </author>
    <author>
      <name>Maurice HT Ling</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Computer Science: an international journal 5(4): 24-30
  (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2302.12054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.12054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.12056v1</id>
    <updated>2023-02-23T14:30:20Z</updated>
    <published>2023-02-23T14:30:20Z</published>
    <title>TAPPS Release 1: Plugin-Extensible Platform for Technical Analysis and
  Applied Statistics</title>
    <summary>  We present the first release of TAPPS (Technical Analysis and Applied
Statistics System); a Python implementation of a thin software platform aimed
towards technical analyses and applied statistics. The core of TAPPS is a
container for 2-dimensional data frame objects and a TAPPS command language.
TAPPS language is not meant to be a programming language for script and plugin
development but for the operational purposes. In this aspect, TAPPS language
takes on the flavor of SQL rather than R, resulting in a shallower learning
curve. All analytical functions are implemented as plugins. This results in a
defined plugin system, which enables rapid development and incorporation of
analysis functions. TAPPS Release 1 is released under GNU General Public
License 3 for academic and non-commercial use. TAPPS code repository can be
found at http://github.com/mauriceling/tapps.
</summary>
    <author>
      <name>Justin Sam Chew</name>
    </author>
    <author>
      <name>Maurice HT Ling</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Computer Science: an international journal 5(1):
  132-141 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2302.12056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.12056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.04353v2</id>
    <updated>2024-12-30T16:01:27Z</updated>
    <published>2023-03-08T03:26:12Z</published>
    <title>Cascading GEMM: High Precision from Low Precision</title>
    <summary>  This paper lays out insights and opportunities for implementing
higher-precision matrix-matrix multiplication (GEMM) from (in terms of)
lower-precision high-performance GEMM. The driving case study approximates
double-double precision (FP64x2) GEMM in terms of double precision (FP64) GEMM,
leveraging how the BLAS-like Library Instantiation Software (BLIS) framework
refactors the Goto Algorithm. With this, it is shown how approximate FP64x2
GEMM accuracy can be cast in terms of ten ``cascading'' FP64 GEMMs. Promising
results from preliminary performance and accuracy experiments are reported. The
demonstrated techniques open up new research directions for more general
cascading of higher-precision computation in terms of lower-precision
computation for GEMM-like functionality.
</summary>
    <author>
      <name>Devangi N. Parikh</name>
    </author>
    <author>
      <name>Robert A. van de Geijn</name>
    </author>
    <author>
      <name>Greg M. Henry</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.04353v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.04353v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.05592v1</id>
    <updated>2023-04-12T03:38:22Z</updated>
    <published>2023-04-12T03:38:22Z</published>
    <title>Learned multiphysics inversion with differentiable programming and
  machine learning</title>
    <summary>  We present the Seismic Laboratory for Imaging and Modeling/Monitoring (SLIM)
open-source software framework for computational geophysics and, more
generally, inverse problems involving the wave-equation (e.g., seismic and
medical ultrasound), regularization with learned priors, and learned neural
surrogates for multiphase flow simulations. By integrating multiple layers of
abstraction, our software is designed to be both readable and scalable. This
allows researchers to easily formulate their problems in an abstract fashion
while exploiting the latest developments in high-performance computing. We
illustrate and demonstrate our design principles and their benefits by means of
building a scalable prototype for permeability inversion from time-lapse
crosswell seismic data, which aside from coupling of wave physics and
multiphase flow, involves machine learning.
</summary>
    <author>
      <name>Mathias Louboutin</name>
    </author>
    <author>
      <name>Ziyi Yin</name>
    </author>
    <author>
      <name>Rafael Orozco</name>
    </author>
    <author>
      <name>Thomas J. Grady II</name>
    </author>
    <author>
      <name>Ali Siahkoohi</name>
    </author>
    <author>
      <name>Gabrio Rizzuti</name>
    </author>
    <author>
      <name>Philipp A. Witte</name>
    </author>
    <author>
      <name>Olav Møyner</name>
    </author>
    <author>
      <name>Gerard J. Gorman</name>
    </author>
    <author>
      <name>Felix J. Herrmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1190/tle42070474.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1190/tle42070474.1" rel="related"/>
    <link href="http://arxiv.org/abs/2304.05592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.05592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.06145v2</id>
    <updated>2024-04-29T18:22:17Z</updated>
    <published>2023-04-12T20:03:44Z</published>
    <title>R-Shiny Applications for Local Clustering to be Included in the
  growclusters for R Package</title>
    <summary>  growclusters for R is a package that estimates a partition structure for
multivariate data. It does this by implementing a hierarchical version of
k-means clustering that accounts for possible known dependencies in a
collection of datasets, where each set draws its cluster means from a single,
global partition. Each component data set in the collection corresponds to a
known group in the data. This paper focuses on R Shiny applications that
implement the clustering methodology and simulate data sets with known group
structures. These Shiny applications implement novel ways of visualizing the
results of the clustering. These visualizations include scatterplots of
individual data sets in the context of the entire collection and cluster
distributions versus component (or sub-domain) datasets. Data obtained from a
collection of 2000-2013 articles from the Bureau of Labor Statistics (BLS)
Monthly Labor Review (MLR) will be used to illustrate the R-Shiny applications.
Here, the known grouping in the collection is the year of publication.
</summary>
    <author>
      <name>Randall Powers</name>
    </author>
    <author>
      <name>Wendy Martinez</name>
    </author>
    <author>
      <name>Terrance Savitsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 10 figures, paper presented at 2023 Joint Statistical
  Meetings</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.06145v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.06145v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3; I.3.8; J.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.11165v2</id>
    <updated>2023-10-16T09:40:18Z</updated>
    <published>2023-04-17T13:34:11Z</published>
    <title>An open-source pipeline for solving continuous reaction-diffusion models
  in image-based geometries of porous media</title>
    <summary>  We present a versatile open-source pipeline for simulating inhomogeneous
reaction-diffusion processes in highly resolved, image-based geometries of
porous media with reactive boundaries. Resolving realistic pore-scale
geometries in numerical models is challenging and computationally demanding, as
the scale differences between the sizes of the interstitia and the whole system
can lead to prohibitive memory requirements. The present pipeline combines a
level-set method with geometry-adapted sparse block grids on GPUs to
efficiently simulate reaction-diffusion processes in image-based geometries. We
showcase the method by applying it to fertilizer diffusion in soil, heat
transfer in porous ceramics, and determining effective diffusion coefficients
and tortuosity. The present approach enables solving reaction-diffusion partial
differential equations in real-world geometries applicable to porous media
across fields such as engineering, environmental science, and biology.
</summary>
    <author>
      <name>Justina Stark</name>
    </author>
    <author>
      <name>Ivo F. Sbalzarini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jocs.2023.102118</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jocs.2023.102118" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 figures, 1 appendix figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Comput. Sci., 72:102118, 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2304.11165v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.11165v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.11274v1</id>
    <updated>2023-04-21T23:41:22Z</updated>
    <published>2023-04-21T23:41:22Z</published>
    <title>Massively Distributed Finite-Volume Flux Computation</title>
    <summary>  Designing large-scale geological carbon capture and storage projects and
ensuring safe long-term CO2 containment - as a climate change mitigation
strategy - requires fast and accurate numerical simulations. These simulations
involve solving complex PDEs governing subsurface fluid flow using implicit
finite-volume schemes widely based on Two-Point Flux Approximation (TPFA). This
task is computationally and memory expensive, especially when performed on
highly detailed geomodels. In most current HPC architectures, memory hierarchy
and data management mechanism are insufficient to overcome the challenges of
large scale numerical simulations. Therefore, it is crucial to design
algorithms that can exploit alternative and more balanced paradigms, such as
dataflow and in-memory computing. This work introduces an algorithm for TPFA
computations that leverages effectively a dataflow architecture, such as
Cerebras CS2, which helps to significantly minimize memory bottlenecks. Our
implementation achieves two orders of magnitude speedup compared to multiple
reference implementations running on NVIDIA A100 GPUs.
</summary>
    <author>
      <name>Ryuichi Sai</name>
    </author>
    <author>
      <name>Mathias Jacquelin</name>
    </author>
    <author>
      <name>François P. Hamon</name>
    </author>
    <author>
      <name>Mauricio Araya-Polo</name>
    </author>
    <author>
      <name>Randolph R. Settgast</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages excl. bibliography. Submitted to SuperComputing 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.11274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.11274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.16731v5</id>
    <updated>2023-10-31T21:43:49Z</updated>
    <published>2023-06-29T07:14:17Z</published>
    <title>SYCL compute kernels for ExaHyPE</title>
    <summary>  We discuss three SYCL realisations of a simple Finite Volume scheme over
multiple Cartesian patches. The realisation flavours differ in the way how they
map the compute steps onto loops and tasks: We compare an implementation that
is exclusively using a sequence of for-loops to a version that uses nested
parallelism, and finally benchmark these against a version modelling the
calculations as task graph. Our work proposes realisation idioms to realise
these flavours within SYCL. The results suggest that a mixture of classic task
and data parallelism performs if we map this hybrid onto a solely data-parallel
SYCL implementation, taking into account SYCL specifics and the problem size.
</summary>
    <author>
      <name>Chung Ming Loi</name>
    </author>
    <author>
      <name>Heinrich Bockhorst</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/1.9781611977967</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/1.9781611977967" rel="related"/>
    <link href="http://arxiv.org/abs/2306.16731v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.16731v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.17541v3</id>
    <updated>2025-05-22T18:18:47Z</updated>
    <published>2023-06-30T10:53:27Z</published>
    <title>Rigorous Function Calculi in Ariadne</title>
    <summary>  Almost all problems in applied mathematics, including the analysis of
dynamical systems, deal with spaces of real-valued functions on Euclidean
domains in their formulation and solution. In this paper, we describe the the
tool Ariadne, which provides a rigorous calculus for working with Euclidean
functions. We first introduce the Ariadne framework, which is based on a clean
separation of objects as providing exact, effective, validated and approximate
information. We then discuss the function calculus as implemented in Ariadne,
including polynomial function models which are the fundamental class for
concrete computations. We then consider solution of some core problems of
functional analysis, namely solution of algebraic equations and differential
equations, and briefly discuss their use for the analysis of hybrid systems. We
will give examples of C++ and Python code for performing the various
calculations. Finally, we will discuss progress on extensions, including
improvements to the function calculus and extensions to more complicated
classes of system.
</summary>
    <author>
      <name>Pieter Collins</name>
    </author>
    <author>
      <name>Luca Geretti</name>
    </author>
    <author>
      <name>Sanja Zivanovic Gonzalez</name>
    </author>
    <author>
      <name>Davide Bresolin</name>
    </author>
    <author>
      <name>Tiziano Villa</name>
    </author>
    <link href="http://arxiv.org/abs/2306.17541v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.17541v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.06075v1</id>
    <updated>2023-07-12T10:53:02Z</updated>
    <published>2023-07-12T10:53:02Z</published>
    <title>Integrating Enzyme-generated functions into CoDiPack</title>
    <summary>  In operator overloading algorithmic differentiation, it can be beneficial to
create custom derivative functions for some parts of the code base. For manual
implementations of the derivative functions, it can be quite cumbersome to
derive, implement, test, and maintain these. The process can be automated with
source transformation algorithmic differentiation tools like Tapenade or
compiler-based algorithmic differentiation tools like Enzyme. This eliminates
most of the work required from a manual implementation but usually has the same
efficiency with respect to timing and memory. We present a new helper in
CoDiPack that allows Enzyme-generated derivative functions to be automatically
added during the recording process of CoDiPack. The validity of the approach is
demonstrated on a synthetic benchmark, which shows promising results.
</summary>
    <author>
      <name>M. Sagebaum</name>
    </author>
    <author>
      <name>M. Aehle</name>
    </author>
    <author>
      <name>N. R. Gauger</name>
    </author>
    <link href="http://arxiv.org/abs/2307.06075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.06075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D25 (Primary), 68N30 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.4; G.4; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.06953v1</id>
    <updated>2023-07-12T19:48:29Z</updated>
    <published>2023-07-12T19:48:29Z</published>
    <title>A framework to test interval arithmetic libraries and their IEEE
  1788-2015 compliance</title>
    <summary>  As developers of libraries implementing interval arithmetic, we faced the
same difficulties when it comes to testing our libraries. What must be tested?
How can we devise relevant test cases for unit testing? How can we ensure a
high (and possibly 100%) test coverage? Before considering these questions, we
briefly recall the main features of interval arithmetic and of the IEEE
1788-2015 standard for interval arithmetic. After listing the different aspects
that, in our opinion, must be tested, we contribute a first step towards
offering a test suite for an interval arithmetic library. First we define a
format that enables the exchange of test cases, so that they can be read and
tried easily. Then we offer a first set of test cases, for a selected set of
mathematical functions. Next, we examine how the Julia interval arithmetic
library, IntervalArithmetic.jl, actually performs to these tests. As this is an
ongoing work, we list extra tests that we deem important to perform.
</summary>
    <author>
      <name>Luis Benet</name>
    </author>
    <author>
      <name>Luca Ferranti</name>
    </author>
    <author>
      <name>Nathalie Revol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.06953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.06953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65G99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.07931v1</id>
    <updated>2023-07-16T03:33:19Z</updated>
    <published>2023-07-16T03:33:19Z</published>
    <title>ProtoX: A First Look</title>
    <summary>  We present a first look at ProtoX, a code generation framework for stencil
and pointwise operations that occur frequently in the numerical solution of
partial differential equations. ProtoX has Proto as its library frontend and
SPIRAL as the backend. Proto is a C++ based domain specific library which
optimizes the algorithms used to compute the numerical solution of partial
differential equations. Meanwhile, SPIRAL is a code generation system that
focuses on generating highly optimized target code. Although the current design
layout of Proto and its high level of abstractions provide a user friendly set
up, there is still a room for improving it's performance by applying various
techniques either at a compiler level or at an algorithmic level. Hence, in
this paper we propose adding SPIRAL as the library backend for Proto enabling
abstraction fusion, which is usually difficult to perform by any compiler. We
demonstrate the construction of ProtoX by considering the 2D Poisson equation
as a model problem from Proto. We provide the final generated code for CPU,
Multi-core CPU, and GPU as well as some performance numbers for CPU.
</summary>
    <author>
      <name>Het Mankad</name>
    </author>
    <author>
      <name>Sanil Rao</name>
    </author>
    <author>
      <name>Brian Van Straalen</name>
    </author>
    <author>
      <name>Phillip Colella</name>
    </author>
    <author>
      <name>Franz Franchetti</name>
    </author>
    <link href="http://arxiv.org/abs/2307.07931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.07931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.08085v1</id>
    <updated>2023-07-16T15:57:25Z</updated>
    <published>2023-07-16T15:57:25Z</published>
    <title>MindOpt Tuner: Boost the Performance of Numerical Software by Automatic
  Parameter Tuning</title>
    <summary>  Numerical software is usually shipped with built-in hyperparameters. By
carefully tuning those hyperparameters, significant performance enhancements
can be achieved for specific applications. We developed MindOpt Tuner, a new
automatic tuning tool that supports a wide range of numerical software,
including optimization and other solvers. MindOpt Tuner uses elastic cloud
resources, features a web-based task management panel and integration with
ipython notebook with both command-line tools and Python APIs. Our experiments
with COIN-OR Cbc, an open-source mixed-integer optimization solver, demonstrate
remarkable improvements with the tuned parameters compared to the default ones
on the MIPLIB2017 test set, resulting in over 100x acceleration on several
problem instances. Additionally, the results demonstrate that Tuner has a
higher tuning efficiency compared to the state-of-the-art automatic tuning tool
SMAC3.
</summary>
    <author>
      <name>Mengyuan Zhang</name>
    </author>
    <author>
      <name>Wotao Yin</name>
    </author>
    <author>
      <name>Mengchang Wang</name>
    </author>
    <author>
      <name>Yangbin Shen</name>
    </author>
    <author>
      <name>Peng Xiang</name>
    </author>
    <author>
      <name>You Wu</name>
    </author>
    <author>
      <name>Liang Zhao</name>
    </author>
    <author>
      <name>Junqiu Pan</name>
    </author>
    <author>
      <name>Hu Jiang</name>
    </author>
    <author>
      <name>KuoLing Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2307.08085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.08085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.03120v1</id>
    <updated>2023-08-06T14:01:12Z</updated>
    <published>2023-08-06T14:01:12Z</published>
    <title>Bandicoot: C++ Library for GPU Linear Algebra and Scientific Computing</title>
    <summary>  This report provides an introduction to the Bandicoot C++ library for linear
algebra and scientific computing on GPUs, overviewing its user interface and
performance characteristics, as well as the technical details of its internal
design. Bandicoot is the GPU-enabled counterpart to the well-known Armadillo
C++ linear algebra library, aiming to allow users to take advantage of
GPU-accelerated computation for their existing codebases without significant
changes. Adapting the same internal template meta-programming techniques that
Armadillo uses, Bandicoot is able to provide compile-time optimisation of
mathematical expressions within user code. The library is ready for production
use and is available at https://coot.sourceforge.io. Bandicoot is distributed
under the Apache 2.0 License.
</summary>
    <author>
      <name>Ryan R. Curtin</name>
    </author>
    <author>
      <name>Marcus Edel</name>
    </author>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <link href="http://arxiv.org/abs/2308.03120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.03120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05, 65F45, 15-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.4; I.3.1; I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.07346v1</id>
    <updated>2023-08-13T16:29:05Z</updated>
    <published>2023-08-13T16:29:05Z</published>
    <title>Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for
  Tetrad Causal Search</title>
    <summary>  We give novel Python and R interfaces for the (Java) Tetrad project for
causal modeling, search, and estimation. The Tetrad project is a mainstay in
the literature, having been under consistent development for over 30 years.
Some of its algorithms are now classics, like PC and FCI; others are recent
developments. It is increasingly the case, however, that researchers need to
access the underlying Java code from Python or R. Existing methods for doing
this are inadequate. We provide new, up-to-date methods using the JPype
Python-Java interface and the Reticulate Python-R interface, directly solving
these issues. With the addition of some simple tools and the provision of
working examples for both Python and R, using JPype and Reticulate to interface
Python and R with Tetrad is straightforward and intuitive.
</summary>
    <author>
      <name>Joseph D. Ramsey</name>
    </author>
    <author>
      <name>Bryan Andrews</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Causal Analysis Workshop Series (CAWS) 2023, 12 pages, 4 Figures, 2
  Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.07346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.07346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62D20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.5; D.1.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.09920v1</id>
    <updated>2023-08-19T06:08:24Z</updated>
    <published>2023-08-19T06:08:24Z</published>
    <title>Graph4J -- A computationally efficient Java library for graph algorithms</title>
    <summary>  Graph algorithms play an important role in many computer science areas. In
order to solve problems that can be modeled using graphs, it is necessary to
use a data structure that can represent those graphs in an efficient manner. On
top of this, an infrastructure should be build that will assist in implementing
common algorithms or developing specialized ones. Here, a new Java library is
introduced, called Graph4J, that uses a different approach when compared to
existing, well-known Java libraries such as JGraphT, JUNG and Guava Graph.
Instead of using object-oriented data structures for graph representation, a
lower-level model based on arrays of primitive values is utilized, that
drastically reduces the required memory and the running times of the algorithm
implementations. The design of the library, the space complexity of the graph
structures and the time complexity of the most common graph operations are
presented in detail, along with an experimental study that evaluates its
performance, when compared to the other libraries. Emphasis is given to
infrastructure related aspects, that is graph creation, inspection, alteration
and traversal. The improvements obtained for other implemented algorithms are
also analyzed and it is shown that the proposed library significantly
outperforms the existing ones.
</summary>
    <author>
      <name>Cristian Frăsinaru</name>
    </author>
    <author>
      <name>Emanuel Florentin Olariu</name>
    </author>
    <link href="http://arxiv.org/abs/2308.09920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.09920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.05331v1</id>
    <updated>2023-09-11T09:26:37Z</updated>
    <published>2023-09-11T09:26:37Z</published>
    <title>A Distributed Algebra System for Time Integration on Parallel Computers</title>
    <summary>  We present a distributed algebra system for efficient and compact
implementation of numerical time integration schemes on parallel computers and
graphics processing units (GPU). The software implementation combines the time
integration library Odeint from Boost with the OpenFPM framework for scalable
scientific computing. Implementing multi-stage, multi-step, or adaptive time
integration methods in distributed-memory parallel codes or on GPUs is
challenging. The present algebra system addresses this by making the time
integration methods from Odeint available in a concise template-expression
language for numerical simulations distributed and parallelized using OpenFPM.
This allows using state-of-the-art time integration schemes, or switching
between schemes, by changing one line of code, while maintaining parallel
scalability. This enables scalable time integration with compact code and
facilitates rapid rewriting and deployment of simulation algorithms. We
benchmark the present software for exponential and sigmoidal dynamics and
present an application example to the 3D Gray-Scott reaction-diffusion problem
on both CPUs and GPUs in only 60 lines of code.
</summary>
    <author>
      <name>Abhinav Singh</name>
    </author>
    <author>
      <name>Landfried Kraatz</name>
    </author>
    <author>
      <name>Pietro Incardona</name>
    </author>
    <author>
      <name>Ivo F. Sbalzarini</name>
    </author>
    <link href="http://arxiv.org/abs/2309.05331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.05331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.07137v1</id>
    <updated>2023-08-31T10:35:24Z</updated>
    <published>2023-08-31T10:35:24Z</published>
    <title>Bringing PDEs to JAX with forward and reverse modes automatic
  differentiation</title>
    <summary>  Partial differential equations (PDEs) are used to describe a variety of
physical phenomena. Often these equations do not have analytical solutions and
numerical approximations are used instead. One of the common methods to solve
PDEs is the finite element method. Computing derivative information of the
solution with respect to the input parameters is important in many tasks in
scientific computing. We extend JAX automatic differentiation library with an
interface to Firedrake finite element library. High-level symbolic
representation of PDEs allows bypassing differentiating through low-level
possibly many iterations of the underlying nonlinear solvers. Differentiating
through Firedrake solvers is done using tangent-linear and adjoint equations.
This enables the efficient composition of finite element solvers with arbitrary
differentiable programs. The code is available at
github.com/IvanYashchuk/jax-firedrake.
</summary>
    <author>
      <name>Ivan Yashchuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a workshop paper at ICLR 2020 DeepDiffEq workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.07137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.07137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.15417v1</id>
    <updated>2023-09-27T05:46:57Z</updated>
    <published>2023-09-27T05:46:57Z</published>
    <title>Parallel local time stepping for rigid bodies represented by
  triangulated meshes</title>
    <summary>  Discrete Element Methods (DEM), i.e.~the simulation of many rigid particles,
suffer from very stiff differential equations plus multiscale challenges in
space and time. The particles move smoothly through space until they interact
almost instantaneously due to collisions. Dense particle packings hence require
tiny time step sizes, while free particles can advance with large time steps.
Admissible time step sizes can span multiple orders of magnitudes. We propose
an adaptive local time stepping algorithm which identifies clusters of
particles that can be updated independently, advances them optimistically and
independently in time, determines collision time stamps in space-time such that
we maximise the time step sizes used, and resolves the momentum exchange
implicitly. It is combined with various acceleration techniques which exploit
multiscale geometry representations and multiscale behaviour in time. The
collision time stamp detection in space-time in combination with the implicit
solve of the actual collision equations avoids that particles get locked into
tiny time step sizes, the clustering yields a high concurrency level, and the
acceleration techniques plus local time stepping avoid unnecessary
computations. This brings a scaling, adaptive time stepping for DEM for
real-world challenges into reach.
</summary>
    <author>
      <name>Peter Noble</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <link href="http://arxiv.org/abs/2309.15417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.15417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.09797v1</id>
    <updated>2023-10-15T10:59:41Z</updated>
    <published>2023-10-15T10:59:41Z</published>
    <title>A Number Representation Systems Library Supporting New Representations
  Based on Morris Tapered Floating-point with Hidden Exponent Bit</title>
    <summary>  The introduction of posit reopened the debate about the utility of IEEE754 in
specific domains. In this context, we propose a high-level language (Scala)
library that aims to reduce the effort of designing and testing new number
representation systems (NRSs). The library's efficiency is tested with three
new NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent
bit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB,
respectively. We show that they offer a better dynamic range, better decimal
accuracy for unary operations, more exact results for addition (37.61% in the
case of MorrisUnaryHEB), and better average decimal accuracy for inexact
results on binary operations than posit and IEEE754. Going through existing
benchmarks in the literature, and favorable/unfavorable examples for
IEEE754/posit, we show that these new NRSs produce similar (less than one
decimal accuracy difference) or even better results than IEEE754 and posit.
Given the entire spectrum of results, there are arguments for MorrisBiasHEB to
be used as a replacement for IEEE754 in general computations. MorrisUnaryHEB
has a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X)
than posit, making it a candidate for machine learning computations.
</summary>
    <author>
      <name>Stefan-Dan Ciocirlan</name>
    </author>
    <author>
      <name>Dumitrel Loghin</name>
    </author>
    <link href="http://arxiv.org/abs/2310.09797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.09797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.11626v1</id>
    <updated>2023-10-17T23:24:11Z</updated>
    <published>2023-10-17T23:24:11Z</published>
    <title>HyperNetX: A Python package for modeling complex network data as
  hypergraphs</title>
    <summary>  HyperNetX (HNX) is an open source Python library for the analysis and
visualization of complex network data modeled as hypergraphs. Initially
released in 2019, HNX facilitates exploratory data analysis of complex networks
using algebraic topology, combinatorics, and generalized hypergraph and graph
theoretical methods on structured data inputs. With its 2023 release, the
library supports attaching metadata, numerical and categorical, to nodes
(vertices) and hyperedges, as well as to node-hyperedge pairings (incidences).
HNX has a customizable Matplotlib-based visualization module as well as
HypernetX-Widget, its JavaScript addon for interactive exploration and
visualization of hypergraphs within Jupyter Notebooks. Both packages are
available on GitHub and PyPI. With a growing community of users and
collaborators, HNX has become a preeminent tool for hypergraph analysis.
</summary>
    <author>
      <name>Brenda Praggastis</name>
    </author>
    <author>
      <name>Sinan Aksoy</name>
    </author>
    <author>
      <name>Dustin Arendt</name>
    </author>
    <author>
      <name>Mark Bonicillo</name>
    </author>
    <author>
      <name>Cliff Joslyn</name>
    </author>
    <author>
      <name>Emilie Purvine</name>
    </author>
    <author>
      <name>Madelyn Shapiro</name>
    </author>
    <author>
      <name>Ji Young Yun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2310.11626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.11626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.17408v2</id>
    <updated>2023-10-27T08:28:03Z</updated>
    <published>2023-10-26T14:09:57Z</published>
    <title>Tackling the Matrix Multiplication Micro-kernel Generation with Exo</title>
    <summary>  The optimization of the matrix multiplication (or GEMM) has been a need
during the last decades. This operation is considered the flagship of current
linear algebra libraries such as BLIS, OpenBLAS, or Intel OneAPI because of its
widespread use in a large variety of scientific applications. The GEMM is
usually implemented following the GotoBLAS philosophy, which tiles the GEMM
operands and uses a series of nested loops for performance improvement. These
approaches extract the maximum computational power of the architectures through
small pieces of hardware-oriented, high-performance code called micro-kernel.
However, this approach forces developers to generate, with a non-negligible
effort, a dedicated micro-kernel for each new hardware.
  In this work, we present a step-by-step procedure for generating
micro-kernels with the Exo compiler that performs close to (or even better
than) manually developed microkernels written with intrinsic functions or
assembly language. Our solution also improves the portability of the generated
code, since a hardware target is fully specified by a concise library-based
description of its instructions.
</summary>
    <author>
      <name>Adrián Castelló</name>
    </author>
    <author>
      <name>Julian Bellavita</name>
    </author>
    <author>
      <name>Grace Dinh</name>
    </author>
    <author>
      <name>Yuka Ikarashi</name>
    </author>
    <author>
      <name>Héctor Martínez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 18 figures. Presented at CGO 2024. It includes a software
  artifact step-by-step execution</arxiv:comment>
    <link href="http://arxiv.org/abs/2310.17408v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.17408v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.11348v1</id>
    <updated>2023-11-19T15:19:59Z</updated>
    <published>2023-11-19T15:19:59Z</published>
    <title>p-adaptive discontinuous Galerkin method for the shallow water equations
  on heterogeneous computing architectures</title>
    <summary>  Heterogeneous computing and exploiting integrated CPU-GPU architectures has
become a clear current trend since the flattening of Moore's Law. In this work,
we propose a numerical and algorithmic re-design of a p-adaptive
quadrature-free discontinuous Galerkin method (DG) for the shallow water
equations (SWE). Our new approach separates the computations of the
non-adaptive (lower-order) and adaptive (higher-order) parts of the
discretization form each other. Thereby, we can overlap computations of the
lower-order and the higher-order DG solution components. Furthermore, we
investigate execution times of main computational kernels and use automatic
code generation to optimize their distribution between the CPU and GPU. Several
setups, including a prototype of a tsunami simulation in a tide-driven flow
scenario, are investigated, and the results show that significant performance
improvements can be achieved in suitable setups.
</summary>
    <author>
      <name>Sara Faghih-Naini</name>
    </author>
    <author>
      <name>Vadym Aizinger</name>
    </author>
    <author>
      <name>Sebastian Kuckuk</name>
    </author>
    <author>
      <name>Richard Angersbach</name>
    </author>
    <author>
      <name>Harald Köstler</name>
    </author>
    <link href="http://arxiv.org/abs/2311.11348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.11348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.03315v1</id>
    <updated>2023-12-06T06:48:16Z</updated>
    <published>2023-12-06T06:48:16Z</published>
    <title>Impact of parallel code optimization on computer power consumption</title>
    <summary>  The increase in performance and power of computing systems requires the wider
use of program optimizations. The goal of performing optimizations is not only
to reduce program runtime, but also to reduce other computer resources
including power consumption. The goal of the study was to evaluate the impact
of different optimization levels and various optimization strategies on power
consumption. In a series of experiments, it was established that the average
power consumption tends to peak for the programs with optimized source code.
The articles also describes the impact of changing computer architecture on
power consumption graphs. The relationships between the average and median
values of power consumption by example programs are considered. The possibility
of creating program energy consumption profile for a parallel program is shown.
</summary>
    <author>
      <name>E. A. Kiselev</name>
    </author>
    <author>
      <name>P. N. Telegin</name>
    </author>
    <author>
      <name>A. V. Baranov</name>
    </author>
    <link href="http://arxiv.org/abs/2312.03315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.03315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68M20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.12732v1</id>
    <updated>2023-12-20T03:09:50Z</updated>
    <published>2023-12-20T03:09:50Z</published>
    <title>Strassen's Matrix Multiplication Algorithm Is Still Faster</title>
    <summary>  Recently, reinforcement algorithms discovered new algorithms that really
jump-started a wave of excitements and a flourishing of publications. However,
there is little on implementations, applications, and, especially, no absolute
performance and, we show here they are not here to replace Strassen's original
fast matrix multiplication yet. We present Matrix Flow, this is a simple Python
project for the automatic formulation, design, implementation, code generation,
and execution of fast matrix multiplication algorithms for CPUs, using BLAS
interface GPUs, and in the future other accelerators. We shall not play with
module-2 (Z2) algorithms and, for simplicity, we present only square
double-precision matrices. By means of factorizing the operand matrices we can
express many algorithms and prove them correct. These algorithms are
represented by Data Flows and matrix data partitions: a Directed Acyclic Graph.
We show that Strassen's original algorithm is still the top choice even for
modern GPUs. We also address error analysis in double precision, because
integer computations are correct, always
</summary>
    <author>
      <name>Paolo D'Alberto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 images, mathematical software</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.12732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.12732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.13527v4</id>
    <updated>2024-02-01T03:09:51Z</updated>
    <published>2023-12-21T01:59:33Z</published>
    <title>MindOpt Adapter for CPLEX Benchmarking Performance Analysis</title>
    <summary>  This report provides a comprehensive analysis of the performance of MindOpt
Adapter for CPLEX 12.9 in benchmark testing. CPLEX, recognized as a robust
Mixed Integer Programming (MIP) solver, has faced some scrutiny regarding its
performance on MIPLIB 2017 when configured to default settings. MindOpt Adapter
aims to enhance CPLEX's performance by automatically applying improved
configurations for solving optimization problems. Our testing demonstrates that
MindOpt Adapter for CPLEX yields successfully solved 232 of the 240 problems in
the MIPLIB 2017 benchmark set. This performance surpasses all the other solvers
in terms of the number of problems solved and the geometric mean of running
times. The report provides a comparison of the benchmark results against the
outcomes achieved by CPLEX under its default configuration.
</summary>
    <author>
      <name>Mou Sun</name>
    </author>
    <author>
      <name>Tao Li</name>
    </author>
    <author>
      <name>Wotao Yin</name>
    </author>
    <link href="http://arxiv.org/abs/2312.13527v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.13527v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.01921v2</id>
    <updated>2025-01-20T14:30:01Z</updated>
    <published>2024-01-03T14:59:50Z</published>
    <title>The Cytnx Library for Tensor Networks</title>
    <summary>  We introduce a tensor network library designed for classical and quantum
physics simulations called Cytnx (pronounced as sci-tens). This library
provides almost an identical interface and syntax for both C++ and Python,
allowing users to effortlessly switch between two languages. Aiming at a quick
learning process for new users of tensor network algorithms, the interfaces
resemble the popular Python scientific libraries like NumPy, Scipy, and
PyTorch. Not only multiple global Abelian symmetries can be easily defined and
implemented, Cytnx also provides a new tool called Network that allows users to
store large tensor networks and perform tensor network contractions in an
optimal order automatically. With the integration of cuQuantum, tensor
calculations can also be executed efficiently on GPUs. We present benchmark
results for tensor operations on both devices, CPU and GPU. We also discuss
features and higher-level interfaces to be added in the future.
</summary>
    <author>
      <name>Kai-Hsin Wu</name>
    </author>
    <author>
      <name>Chang-Teng Lin</name>
    </author>
    <author>
      <name>Ke Hsu</name>
    </author>
    <author>
      <name>Hao-Ti Hung</name>
    </author>
    <author>
      <name>Manuel Schneider</name>
    </author>
    <author>
      <name>Chia-Min Chung</name>
    </author>
    <author>
      <name>Ying-Jer Kao</name>
    </author>
    <author>
      <name>Pochung Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21468/SciPostPhysCodeb.53</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21468/SciPostPhysCodeb.53" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SciPost Phys. Codebases 53 (2025)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2401.01921v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.01921v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.11737v2</id>
    <updated>2024-03-10T16:22:03Z</updated>
    <published>2024-01-22T07:29:22Z</published>
    <title>Sphractal: Estimating the Fractal Dimension of Surfaces Computed from
  Precise Atomic Coordinates via Box-Counting Algorithm</title>
    <summary>  The fractal dimension of a surface allows its degree of roughness to be
characterized quantitatively. However, limited effort is attempted to calculate
the fractal dimension of surfaces computed from precisely known atomic
coordinates from computational biomolecular and nanomaterial studies. This work
proposes methods to estimate the fractal dimension of the surface of any 3D
object composed of spheres, by representing the surface as either a voxelized
point cloud or a mathematically exact surface, and computing its box-counting
dimension. Sphractal is published as a Python package that provides these
functionalities, and its utility is demonstrated on a set of simulated
palladium nanoparticle data.
</summary>
    <author>
      <name>Jonathan Yik Chang Ting</name>
    </author>
    <author>
      <name>Andrew Thomas Agars Wood</name>
    </author>
    <author>
      <name>Amanda Susan Barnard</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/adts.202301227</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/adts.202301227" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 13 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Adv. Theory Simul. 2024, 2301227</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2401.11737v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.11737v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.atom-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.14077v1</id>
    <updated>2024-01-25T10:55:38Z</updated>
    <published>2024-01-25T10:55:38Z</published>
    <title>LongMemory.jl: Generating, Estimating, and Forecasting Long Memory
  Models in Julia</title>
    <summary>  LongMemory.jl is a package for time series long memory modelling in Julia.
The package provides functions to generate long memory, estimate model
parameters, and forecast. Generating methods include fractional differencing,
stochastic error duration, and cross-sectional aggregation. Estimators include
the classic ones used to estimate the Hurst effect, those inspired by
log-periodogram regression, and parametric ones. Forecasting is provided for
all parametric estimators. Moreover, the package adds plotting capabilities to
illustrate long memory dynamics and forecasting. This article presents the
theoretical developments for long memory modelling, show examples using the
data included with the package, and compares the properties of LongMemory.jl
with current alternatives, including benchmarks. For some of the theoretical
developments, LongMemory.jl provides the first publicly available
implementation in any programming language. A notable feature of this package
is that all functions are implemented in the same programming language, taking
advantage of the ease of use and speed provided by Julia. Therefore, all code
is accessible to the user. Multiple dispatch, a novel feature of the language,
is used to speed computations and provide consistent calls to related methods.
The package is related to the R packages LongMemoryTS and fracdiff.
</summary>
    <author>
      <name>J. Eduardo Vera-Valdés</name>
    </author>
    <link href="http://arxiv.org/abs/2401.14077v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.14077v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.02301v2</id>
    <updated>2024-04-26T16:09:10Z</updated>
    <published>2024-02-03T23:49:08Z</published>
    <title>MATLAB Simulator of Level-Index Arithmetic</title>
    <summary>  Level-index arithmetic appeared in the 1980s. One of its principal purposes
is to abolish the issues caused by underflows and overflows in floating point.
However, level-index arithmetic does not expand the set of numbers but spaces
out the numbers of large magnitude even more than floating-point
representations to move the infinities further away from zero: gaps between
numbers on both ends of the range become very large. We revisit level index by
presenting a custom precision simulator in MATLAB. This toolbox is useful for
exploring performance of level-index arithmetic in research projects, such as
using 8-bit and 16-bit representations in machine learning algorithms where
narrow bit-width is desired but overflow/underflow of floating-point
representations causes difficulties.
</summary>
    <author>
      <name>Mantas Mikaitis</name>
    </author>
    <link href="http://arxiv.org/abs/2402.02301v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.02301v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.15940v1</id>
    <updated>2024-02-25T00:01:00Z</updated>
    <published>2024-02-25T00:01:00Z</published>
    <title>High-performance finite elements with MFEM</title>
    <summary>  The MFEM (Modular Finite Element Methods) library is a high-performance C++
library for finite element discretizations. MFEM supports numerous types of
finite element methods and is the discretization engine powering many
computational physics and engineering applications across a number of domains.
This paper describes some of the recent research and development in MFEM,
focusing on performance portability across leadership-class supercomputing
facilities, including exascale supercomputers, as well as new capabilities and
functionality, enabling a wider range of applications. Much of this work was
undertaken as part of the Department of Energy's Exascale Computing Project
(ECP) in collaboration with the Center for Efficient Exascale Discretizations
(CEED).
</summary>
    <author>
      <name>Julian Andrej</name>
    </author>
    <author>
      <name>Nabil Atallah</name>
    </author>
    <author>
      <name>Jan-Phillip Bäcker</name>
    </author>
    <author>
      <name>John Camier</name>
    </author>
    <author>
      <name>Dylan Copeland</name>
    </author>
    <author>
      <name>Veselin Dobrev</name>
    </author>
    <author>
      <name>Yohann Dudouit</name>
    </author>
    <author>
      <name>Tobias Duswald</name>
    </author>
    <author>
      <name>Brendan Keith</name>
    </author>
    <author>
      <name>Dohyun Kim</name>
    </author>
    <author>
      <name>Tzanio Kolev</name>
    </author>
    <author>
      <name>Boyan Lazarov</name>
    </author>
    <author>
      <name>Ketan Mittal</name>
    </author>
    <author>
      <name>Will Pazner</name>
    </author>
    <author>
      <name>Socratis Petrides</name>
    </author>
    <author>
      <name>Syun'ichi Shiraiwa</name>
    </author>
    <author>
      <name>Mark Stowell</name>
    </author>
    <author>
      <name>Vladimir Tomov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1177/10943420241261981</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1177/10943420241261981" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.15940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.15940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.04273v2</id>
    <updated>2024-07-28T07:50:50Z</updated>
    <published>2024-03-07T07:13:12Z</published>
    <title>GenML: A Python Library to Generate the Mittag-Leffler Correlated Noise</title>
    <summary>  Mittag-Leffler correlated noise (M-L noise) plays a crucial role in the
dynamics of complex systems, yet the scientific community has lacked tools for
its direct generation. Addressing this gap, our work introduces GenML, a Python
library specifically designed for generating M-L noise. We detail the
architecture and functionalities of GenML and its underlying algorithmic
approach, which enables the precise simulation of M-L noise. The effectiveness
of GenML is validated through quantitative analyses of autocorrelation
functions and diffusion behaviors, showcasing its capability to accurately
replicate theoretical noise properties. Our contribution with GenML enables the
effective application of M-L noise data in numerical simulation and data-driven
methods for describing complex systems, moving beyond mere theoretical
modeling.
</summary>
    <author>
      <name>Xiang Qu</name>
    </author>
    <author>
      <name>Hui Zhao</name>
    </author>
    <author>
      <name>Wenjie Cai</name>
    </author>
    <author>
      <name>Gongyi Wang</name>
    </author>
    <author>
      <name>Zihan Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.04273v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.04273v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.05048v2</id>
    <updated>2024-07-26T13:07:06Z</updated>
    <published>2024-03-08T04:50:04Z</published>
    <title>Efficient Calculations for Inverse of $k$-diagonal Circulant Matrices
  and Cyclic Banded Matrices</title>
    <summary>  $k$-diagonal circulant matrices and cyclic banded matrices are widely used in
numerical simulations and signal processing of circular linear systems.
Algorithms that directly involve or specify linear or quadratic complexity for
the inverses of these two types of matrices are rare. We find that the inverse
of a $k$-diagonal circulant matrix can be uniquely determined by a recursive
formula, which can be derived within $O(k^3 \log n+k^4)$. Similarly for the
inverse of a cyclic banded matrix, its inverse can be uniquely determined by a
series of recursive formulas, with the initial terms of these recursions
computable within $O(k^3 n+k^5)$. The additional costs for solving the complete
inverses of these two types of matrices are $kn$ and $kn^2$. Our calculations
enable rapid representation with most processes defined by explicit formulas.
Additionally, most algorithms for inverting $k$-diagonal circulant matrices
rely on the Fast Fourier Transform, which is not applicable to finite fields,
while our algorithms can be applied to computations in finite fields.
</summary>
    <author>
      <name>Chen Wang</name>
    </author>
    <author>
      <name>Hailong Yu</name>
    </author>
    <author>
      <name>Chao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2403.05048v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.05048v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.14844v2</id>
    <updated>2024-05-01T19:04:28Z</updated>
    <published>2024-03-21T21:28:47Z</published>
    <title>Extrapolating Solution Paths of Polynomial Homotopies towards
  Singularities with PHCpack and phcpy</title>
    <summary>  PHCpack is a software package for polynomial homotopy continuation, which
provides a robust path tracker [Telen, Van Barel, Verschelde, SISC 2020]. This
tracker computes the radius of convergence of Newton's method, estimates the
distance to the nearest path, and then applies Pad\'{e} approximants to predict
the next point on the path. A priori step size control is less sensitive to
finely tuned tolerances than a posteriori step size control, and is therefore
robust. The Python interface phcpy is extended with a new step-by-step tracker
and is applied to experiment with extrapolation methods to accurately locate
the singular points at the end of solution paths.
</summary>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <author>
      <name>Kylash Viswanathan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 8th International Congress on Mathematical Software
  2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.14844v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.14844v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.05303v1</id>
    <updated>2024-04-08T08:46:40Z</updated>
    <published>2024-04-08T08:46:40Z</published>
    <title>SARIS: Accelerating Stencil Computations on Energy-Efficient RISC-V
  Compute Clusters with Indirect Stream Registers</title>
    <summary>  Stencil codes are performance-critical in many compute-intensive
applications, but suffer from significant address calculation and irregular
memory access overheads. This work presents SARIS, a general and highly
flexible methodology for stencil acceleration using register-mapped indirect
streams. We demonstrate SARIS for various stencil codes on an eight-core RISC-V
compute cluster with indirect stream registers, achieving significant speedups
of 2.72x, near-ideal FPU utilizations of 81%, and energy efficiency
improvements of 1.58x over an RV32G baseline on average. Scaling out to a
256-core manycore system, we estimate an average FPU utilization of 64%, an
average speedup of 2.14x, and up to 15% higher fractions of peak compute than a
leading GPU code generator.
</summary>
    <author>
      <name>Paul Scheffler</name>
    </author>
    <author>
      <name>Luca Colagrande</name>
    </author>
    <author>
      <name>Luca Benini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures, 2 tables. Accepted at DAC 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.05303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.05303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.05563v1</id>
    <updated>2024-04-08T14:36:45Z</updated>
    <published>2024-04-08T14:36:45Z</published>
    <title>Predefined Software Environment Runtimes As A Measure For
  Reproducibility</title>
    <summary>  As part of Mathematical Research Data Initiative (MaRDI), we have developed a
way to preserve a software package into an easy to deploy and use sandbox
environment we call a "runtime", via a program we developed called MaPS : MaRDI
Packaging System. The program relies on Linux user namespaces to isolate a
library environment from the host system, making the sandboxed software
reproducible on other systems, with minimal effort. Moreover an overlay
filesystem makes local edits persistent. This project will aid reproducibility
efforts of research papers: both mathematical and from other disciplines. As a
proof of concept, we provide runtimes for the OSCAR Computer Algebra System,
polymake software for research in polyhedral geometry, and VIBRANT Virus
Identification By iteRative ANnoTation. The software is in a prerelease state:
the interface for creating, deploying, and executing runtimes is final, and an
interface for easily publishing runtimes is under active development. We thus
propose publishing predefined, distributable software environment runtimes
along with research papers in an effort to make research with software based
results reproducible.
</summary>
    <author>
      <name>Aaruni Kaushik</name>
    </author>
    <link href="http://arxiv.org/abs/2404.05563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.05563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.09276v1</id>
    <updated>2024-04-14T14:58:02Z</updated>
    <published>2024-04-14T14:58:02Z</published>
    <title>Algorithm xxx: Faster Randomized SVD with Dynamic Shifts</title>
    <summary>  Aiming to provide a faster and convenient truncated SVD algorithm for large
sparse matrices from real applications (i.e. for computing a few of largest
singular values and the corresponding singular vectors), a dynamically shifted
power iteration technique is applied to improve the accuracy of the randomized
SVD method. This results in a dynamic shifts based randomized SVD (dashSVD)
algorithm, which also collaborates with the skills for handling sparse
matrices. An accuracy-control mechanism is included in the dashSVD algorithm to
approximately monitor the per vector error bound of computed singular vectors
with negligible overhead. Experiments on real-world data validate that the
dashSVD algorithm largely improves the accuracy of randomized SVD algorithm or
attains same accuracy with fewer passes over the matrix, and provides an
efficient accuracy-control mechanism to the randomized SVD computation, while
demonstrating the advantages on runtime and parallel efficiency. A bound of the
approximation error of the randomized SVD with the shifted power iteration is
also proved.
</summary>
    <author>
      <name>Xu Feng</name>
    </author>
    <author>
      <name>Wenjian Yu</name>
    </author>
    <author>
      <name>Yuyang Xie</name>
    </author>
    <author>
      <name>Jie Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, accepted by ACM Transactions on Mathematical Software</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.09276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.09276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.13216v1</id>
    <updated>2024-04-19T23:49:04Z</updated>
    <published>2024-04-19T23:49:04Z</published>
    <title>Robustness and Accuracy in Pipelined Bi-Conjugate Gradient Stabilized
  Method: A Comparative Study</title>
    <summary>  In this article, we propose an accuracy-assuring technique for finding a
solution for unsymmetric linear systems. Such problems are related to different
areas such as image processing, computer vision, and computational fluid
dynamics. Parallel implementation of Krylov subspace methods speeds up finding
approximate solutions for linear systems. In this context, the refined approach
in pipelined BiCGStab enhances scalability on distributed memory machines,
yielding to substantial speed improvements compared to the standard BiCGStab
method. However, it's worth noting that the pipelined BiCGStab algorithm
sacrifices some accuracy, which is stabilized with the residual replacement
technique. This paper aims to address this issue by employing the ExBLAS-based
reproducible approach. We validate the idea on a set of matrices from the
SuiteSparse Matrix Collection.
</summary>
    <author>
      <name>Mykhailo Havdiak</name>
    </author>
    <author>
      <name>Jose I. Aliaga</name>
    </author>
    <author>
      <name>Roman Iakymchuk</name>
    </author>
    <link href="http://arxiv.org/abs/2404.13216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.13216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.01562v1</id>
    <updated>2024-04-03T06:03:09Z</updated>
    <published>2024-04-03T06:03:09Z</published>
    <title>Discrete Event Simulation: It's Easy with SimPy!</title>
    <summary>  This paper introduces the practicalities and benefits of using SimPy, a
discrete event simulation (DES) module written in Python, for modeling and
simulating complex systems. Through a step-by-step exploration of the classical
Dining Philosophers Problem, we demonstrate how SimPy enables the efficient
construction of discrete event models, emphasizing system states, transitions,
and event handling. We extend the scenario to introduce resources, such as
chopsticks, to model contention and deadlock conditions, and showcase SimPy's
capabilities in managing these scenarios. Furthermore, we explore the
integration of SimPy with other Python libraries for statistical analysis,
showcasing how simulation results inform system design and optimization. The
versatility of SimPy is further highlighted through additional modeling
scenarios, including resource constraints and customer service interactions,
providing insights into the process of building, debugging, simulating, and
optimizing models for a wide range of applications. This paper aims to make DES
accessible to practitioners and researchers alike, emphasizing the ease with
which complex simulations can be constructed, analyzed, and visualized using
SimPy and the broader Python ecosystem.
</summary>
    <author>
      <name>Dmitry Zinoviev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages; 5 figures; first published in PragPub in 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.01562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.01562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.01599v1</id>
    <updated>2024-05-01T00:14:47Z</updated>
    <published>2024-05-01T00:14:47Z</published>
    <title>Xabclib:A Fully Auto-tuned Sparse Iterative Solver</title>
    <summary>  In this paper, we propose a general application programming interface named
OpenATLib for auto-tuning (AT). OpenATLib is designed to establish the
reusability of AT functions. By using OpenATLib, we develop a fully auto-tuned
sparse iterative solver named Xabclib. Xabclib has several novel run-time AT
functions. First, the following new implementations of sparse matrix-vector
multiplication (SpMV) for thread processing are implemented:(1) non-zero
elements; (2) omission of zero-elements computation for vector reduction; (3)
branchless segmented scan (BSS). According to the performance evaluation and
the comparison with conventional implementations, the following results are
obtained: (1) 14x speedup for non-zero elements and zero-elements computation
omission for symmetric SpMV; (2) 4.62x speedup by using BSS. We also develop a
"numerical computation policy" that can optimize memory space and computational
accuracy. Using the policy, we obtain the following: (1) an averaged 1/45
memory space reduction; (2) avoidance of the "fault convergence" situation,
which is a problem of conventional solvers.
</summary>
    <author>
      <name>Takahiro Katagiri</name>
    </author>
    <author>
      <name>Takao Sakurai</name>
    </author>
    <author>
      <name>Mitsuyoshi Igai</name>
    </author>
    <author>
      <name>Shoji Itoh</name>
    </author>
    <author>
      <name>Satoshi Ohshima</name>
    </author>
    <author>
      <name>Hisayasu Kuroda</name>
    </author>
    <author>
      <name>Ken Naono</name>
    </author>
    <author>
      <name>Kengo Nakajima</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This article was submitted to SC11, and also was published as a
  preprint for Research Gate in April 2011. Please refer to:
  https://www.researchgate.net/publication/258223774_Xabclib_A_Fully_Auto-tuned_Sparse_Iterative_Solver</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.01599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.01599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.04944v2</id>
    <updated>2025-03-10T05:06:10Z</updated>
    <published>2024-05-08T10:28:20Z</published>
    <title>A Sparse Tensor Generator with Efficient Feature Extraction</title>
    <summary>  Sparse tensor operations are increasingly important in diverse applications
such as social networks, deep learning, diagnosis, crime, and review analysis.
However, a major obstacle in sparse tensor research is the lack of large-scale
sparse tensor datasets. Another challenge lies in analyzing sparse tensor
features, which are essential not only for understanding the nonzero pattern
but also for selecting the most suitable storage format, decomposition
algorithm, and reordering methods. However, due to the large size of real-world
tensors, even extracting these features can be computationally expensive
without careful optimization. To address these limitations, we have developed a
smart sparse tensor generator that replicates key characteristics of real
sparse tensors. Additionally, we propose efficient methods for extracting a
comprehensive set of sparse tensor features. The effectiveness of our generator
is validated through the quality of extracted features and the performance of
decomposition on the generated tensors. Both the sparse tensor feature
extractor and the tensor generator are open source with all the artifacts
available at https://github.com/sparcityeu/FeaTensor and
https://github.com/sparcityeu/GenTensor, respectively.
</summary>
    <author>
      <name>Tugba Torun</name>
    </author>
    <author>
      <name>Ameer Taweel</name>
    </author>
    <author>
      <name>Didem Unat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.04944v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.04944v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.06056v2</id>
    <updated>2024-08-07T22:21:57Z</updated>
    <published>2024-05-09T19:00:48Z</published>
    <title>Hybrid parallel discrete adjoints in SU2</title>
    <summary>  The open-source multiphysics suite SU2 features discrete adjoints by means of
operator overloading automatic differentiation (AD). While both primal and
discrete adjoint solvers support MPI parallelism, hybrid parallelism using both
MPI and OpenMP has only been introduced for the primal solvers so far. In this
work, we enable hybrid parallel discrete adjoint solvers. Coupling SU2 with
OpDiLib, an add-on for operator overloading AD tools that extends AD to OpenMP
parallelism, marks a key step in this endeavour. We identify the affected parts
of SU2's advanced AD workflow and discuss the required changes and their
tradeoffs. Detailed performance studies compare MPI parallel and hybrid
parallel discrete adjoints in terms of memory and runtime and unveil key
performance characteristics. We showcase the effectiveness of performance
optimizations and highlight perspectives for future improvements. At the same
time, this study demonstrates the applicability of OpDiLib in a large code base
and its scalability on large test cases, providing valuable insights for future
applications both within and beyond SU2.
</summary>
    <author>
      <name>Johannes Blühdorn</name>
    </author>
    <author>
      <name>Pedro Gomes</name>
    </author>
    <author>
      <name>Max Aehle</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compfluid.2024.106528</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compfluid.2024.106528" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 9 figures, 2 listings; new layout, revised section
  structure, polishing and small updates</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.06056v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.06056v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; G.1.4; G.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.07819v2</id>
    <updated>2024-10-27T19:11:54Z</updated>
    <published>2024-05-13T15:01:18Z</published>
    <title>Local Adjoints for Simultaneous Preaccumulations with Shared Inputs</title>
    <summary>  In shared-memory parallel automatic differentiation, inputs that are shared
among simultaneous thread-local preaccumulations lead to data races if
Jacobians are accumulated with a single, shared vector of adjoint variables. In
this work, we discuss the benefits and tradeoffs of re-enabling such
preaccumulations by a transition to suitable local adjoints. We propose
different vector- and map-based approaches for storing local adjoint variables
and analyze them with respect to memory consumption, memory allocation, and
adjoint variable access times in the context of simultaneous preaccumulations
in multiple threads. We implement the approaches in CoDiPack and benchmark them
in parallel discrete adjoint computations in the multiphysics simulation suite
SU2.
</summary>
    <author>
      <name>Johannes Blühdorn</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures. Updated and extended all parts of the paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.07819v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.07819v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; G.1.4; G.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.11065v1</id>
    <updated>2024-05-17T19:42:10Z</updated>
    <published>2024-05-17T19:42:10Z</published>
    <title>Enabling mixed-precision with the help of tools: A Nekbone case study</title>
    <summary>  Mixed-precision computing has the potential to significantly reduce the cost
of exascale computations, but determining when and how to implement it in
programs can be challenging. In this article, we consider Nekbone, a
mini-application for the CFD solver Nek5000, as a case study, and propose a
methodology for enabling mixed-precision with the help of computer arithmetic
tools and roofline model. We evaluate the derived mixed-precision program by
combining metrics in three dimensions: accuracy, time-to-solution, and
energy-to-solution. Notably, the introduction of mixed-precision in Nekbone,
reducing time-to-solution by 40.7% and energy-to-solution by 47% on 128 MPI
ranks.
</summary>
    <author>
      <name>Yanxiang Chen</name>
    </author>
    <author>
      <name>Pablo de Oliveira Castro</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <author>
      <name>Roman Iakymchuk</name>
    </author>
    <link href="http://arxiv.org/abs/2405.11065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.11065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.14321v2</id>
    <updated>2024-05-24T06:46:31Z</updated>
    <published>2024-05-23T08:53:24Z</published>
    <title>An 808 Line Phasor-Based Dehomogenisation Matlab Code For Multi-Scale
  Topology Optimisation</title>
    <summary>  This work presents an 808-line Matlab educational code for combined
multi-scale topology optimisation and phasor-based dehomogenisation titled
deHomTop808. The multi-scale formulation utilises homogenisation of optimal
microstructures to facilitate efficient coarse-scale optimisation.
Dehomogenisation allows for a high-resolution single-scale reconstruction of
the optimised multi-scale structure, achieving minor losses in structural
performance, at a fraction of the computational cost, compared to its
large-scale topology optimisation counterpart. The presented code utilises
stiffness optimal Rank-2 microstructures to minimise the compliance of a
single-load case problem, subject to a volume fraction constraint. By
exploiting the inherent efficiency benefits of the phasor-based
dehomogenisation procedure, on-the-fly dehomogenisation to a single-scale
structure is obtained. The presented code includes procedures for structural
verification of the final dehomogenised structure by comparison to the
multi-scale solution. The code is introduced in terms of the underlying theory
and its major components, including examples and potential extensions, and can
be downloaded from https://github.com/peterdorffler/deHomTop808.git.
</summary>
    <author>
      <name>Rebekka Varum Woldseth</name>
    </author>
    <author>
      <name>Ole Sigmund</name>
    </author>
    <author>
      <name>Peter Dørffler Ladegaard Jensen</name>
    </author>
    <link href="http://arxiv.org/abs/2405.14321v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.14321v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.18966v1</id>
    <updated>2024-05-29T10:24:56Z</updated>
    <published>2024-05-29T10:24:56Z</published>
    <title>svds-C: A Multi-Thread C Code for Computing Truncated Singular Value
  Decomposition</title>
    <summary>  This article presents svds-C, an open-source and high-performance C program
for accurately and robustly computing truncated SVD, e.g. computing several
largest singular values and corresponding singular vectors. We have
re-implemented the algorithm of svds in Matlab in C based on MKL or OpenBLAS
and multi-thread computing to obtain the parallel program named svds-C. svds-C
running on shared-memory computer consumes less time and memory than svds
thanks to careful implementation of multi-thread parallelization and memory
management. Numerical experiments on different test cases which are
synthetically generated or directly from real world datasets show that, svds-C
runs remarkably faster than svds with averagely 4.7X and at most 12X speedup
for 16-thread parallel computing on a computer with Intel CPU, while preserving
same accuracy and consuming about half memory space. Experimental results also
demonstrate that svds-C has similar advantages over svds on the computer with
AMD CPU, and outperforms other state-of-the-art algorithms for truncated SVD on
computing time and robustness.
</summary>
    <author>
      <name>Xu Feng</name>
    </author>
    <author>
      <name>Wenjian Yu</name>
    </author>
    <author>
      <name>Yuyang Xie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, accepted by SoftwareX</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.18966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.18966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.10862v1</id>
    <updated>2024-06-16T09:12:54Z</updated>
    <published>2024-06-16T09:12:54Z</published>
    <title>OpenCAEPoro: A Parallel Simulation Framework for Multiphase and
  Multicomponent Porous Media Flows</title>
    <summary>  OpenCAEPoro is a parallel numerical simulation software developed in C++ for
simulating multiphase and multicomponent flows in porous media. The software
utilizes a set of general-purpose compositional model equations, enabling it to
handle a diverse range of fluid dynamics, including the black oil model,
compositional model, and thermal recovery models. OpenCAEPoro establishes a
unified solving framework that integrates many widely used methods, such as
IMPEC, FIM, and AIM. This framework allows dynamic collaboration between
different methods. Specifically, based on this framework, we have developed an
adaptively coupled domain decomposition method, which can provide initial
solutions for global methods to accelerate the simulation. The reliability of
OpenCAEPoro has been validated through benchmark testing with the SPE
comparative solution project. Furthermore, its robust parallel efficiency has
been tested in distributed parallel environments, demonstrating its suitability
for large-scale simulation problems.
</summary>
    <author>
      <name>Shizhe Li</name>
    </author>
    <author>
      <name>Chen-Song Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.10862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.10862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.14933v2</id>
    <updated>2025-01-23T10:04:29Z</updated>
    <published>2024-06-21T07:41:46Z</published>
    <title>ASTERIX: Module for modelling the water flow on vegetated hillslopes</title>
    <summary>  The paper presents an open source software for numerical integration of an
extended Saint-Venant model used as a mathematical tool to simulate the water
flow from laboratory up to large-scale spatial domains applying
physically-based principles of fluid mechanics. Many in-situ observations have
shown that vegetation plays a key role in controlling the hydrological flux at
catchment scale. In case of heavy rains, the infiltration and interception
processes cease quickly, the remaining rainfall gives rise to the Hortonian
overland flow and the flash flood is thus initiated. In this context, we also
address the following problem: how do the gradient of soil surface and the
vegetation influence the water dynamics in the Hortonian flow? The mathematical
model and ASTERIX were kept as simple as possible in order to be accessible to
a wide range of stakeholders interested in understanding the complex processes
behind the water flow on hillslopes covered by plants.
</summary>
    <author>
      <name>Stelian Ion</name>
    </author>
    <author>
      <name>Dorin Marinescu</name>
    </author>
    <author>
      <name>Stefan-Gicu Cruceanu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.envsoft.2025.106336</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.envsoft.2025.106336" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Environmental Modelling &amp; Software 186 (2025)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2406.14933v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.14933v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04, 76-04 (Primary), 76-10, 35Q35, 74F10, 65M08 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.16154v1</id>
    <updated>2024-06-23T16:28:46Z</updated>
    <published>2024-06-23T16:28:46Z</published>
    <title>Automating Variational Differentiation</title>
    <summary>  Many problems in Physics and Chemistry are formulated as the minimization of
a functional. Therefore, methods for solving these problems typically require
differentiating maps whose input and/or output are functions -- commonly
referred to as variational differentiation. Such maps are not addressed at the
mathematical level by the chain rule, which underlies modern symbolic and
algorithmic differentiation (AD) systems. Although there are algorithmic
solutions such as tracing and reverse accumulation, they do not provide human
readability and introduce strict programming constraints that bottleneck
performance, especially in high-performance computing (HPC) environments. In
this manuscript, we propose a new computer theoretic model of differentiation
by combining the pullback of the $\mathbf{B}$ and $\mathbf{C}$ combinators from
the combinatory logic. Unlike frameworks based on the chain rule, this model
differentiates a minimal complete basis for the space of computable functions.
Consequently, the model is capable of analytic backpropagation and variational
differentiation while supporting complex numbers. To demonstrate the generality
of this approach we build a system named CombDiff, which can differentiate
nontrivial variational problems such as Hartree-Fock (HF) theory and multilayer
perceptrons.
</summary>
    <author>
      <name>Kangbo Li</name>
    </author>
    <author>
      <name>Anil Damle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.16154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.16154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68V99, 49-04, 15-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.04706v1</id>
    <updated>2024-05-03T12:51:59Z</updated>
    <published>2024-05-03T12:51:59Z</published>
    <title>Minimization of Nonlinear Energies in Python Using FEM and Automatic
  Differentiation Tools</title>
    <summary>  This contribution examines the capabilities of the Python ecosystem to solve
nonlinear energy minimization problems, with a particular focus on
transitioning from traditional MATLAB methods to Python's advanced
computational tools, such as automatic differentiation. We demonstrate Python's
streamlined approach to minimizing nonlinear energies by analyzing three
problem benchmarks - the p-Laplacian, the Ginzburg-Landau model, and the
Neo-Hookean hyperelasticity. This approach merely requires the provision of the
energy functional itself, making it a simple and efficient way to solve this
category of problems. The results show that the implementation is about ten
times faster than the MATLAB implementation for large-scale problems. Our
findings highlight Python's efficiency and ease of use in scientific computing,
establishing it as a preferable choice for implementing sophisticated
mathematical models and accelerating the development of numerical simulations.
</summary>
    <author>
      <name>Michal Béreš</name>
    </author>
    <author>
      <name>Jan Valdman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figure, conference PPAM 2024, Ostrava</arxiv:comment>
    <link href="http://arxiv.org/abs/2407.04706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.04706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.09621v1</id>
    <updated>2024-07-12T18:16:38Z</updated>
    <published>2024-07-12T18:16:38Z</published>
    <title>Acceleration of Tensor-Product Operations with Tensor Cores</title>
    <summary>  In this paper, we explore the acceleration of tensor product operations in
finite element methods, leveraging the computational power of the NVIDIA A100
GPU Tensor Cores. We provide an accessible overview of the necessary
mathematical background and discuss our implementation strategies. Our study
focuses on two common programming approaches for NVIDIA Tensor Cores: the C++
Warp Matrix Functions in nvcuda::wmma and the inline Parallel Thread Execution
(PTX) instructions mma.sync.aligned. A significant focus is placed on the
adoption of the versatile inline PTX instructions combined with a conflict-free
shared memory access pattern, a key to unlocking superior performance. When
benchmarked against traditional CUDA Cores, our approach yields a remarkable
2.3-fold increase in double precision performance, achieving 8 TFLOPS/s-45% of
the theoretical maximum. Furthermore, in half-precision computations, numerical
experiments demonstrate a fourfold enhancement in solving the Poisson equation
using the flexible GMRES (FGMRES) method, preconditioned by a multigrid method
in 3D. This is achieved while maintaining the same discretization error as
observed in double precision computations. These results highlight the
considerable benefits of using Tensor Cores for finite element operators with
tensor products, achieving an optimal balance between computational speed and
precision.
</summary>
    <author>
      <name>Cu Cui</name>
    </author>
    <link href="http://arxiv.org/abs/2407.09621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.09621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.19987v1</id>
    <updated>2024-07-29T13:20:11Z</updated>
    <published>2024-07-29T13:20:11Z</published>
    <title>HOBOTAN: Efficient Higher Order Binary Optimization Solver with Tensor
  Networks and PyTorch</title>
    <summary>  In this study, we introduce HOBOTAN, a new solver designed for Higher Order
Binary Optimization (HOBO). HOBOTAN supports both CPU and GPU, with the GPU
version developed based on PyTorch, offering a fast and scalable system. This
solver utilizes tensor networks to solve combinatorial optimization problems,
employing a HOBO tensor that maps the problem and performs tensor contractions
as needed. Additionally, by combining techniques such as batch processing for
tensor optimization and binary-based integer encoding, we significantly enhance
the efficiency of combinatorial optimization. In the future, the utilization of
increased GPU numbers is expected to harness greater computational power,
enabling efficient collaboration between multiple GPUs for high scalability.
Moreover, HOBOTAN is designed within the framework of quantum computing, thus
providing insights for future quantum computer applications. This paper details
the design, implementation, performance evaluation, and scalability of HOBOTAN,
demonstrating its effectiveness.
</summary>
    <author>
      <name>Shoya Yasuda</name>
    </author>
    <author>
      <name>Shunsuke Sotobayashi</name>
    </author>
    <author>
      <name>Yuichiro Minato</name>
    </author>
    <link href="http://arxiv.org/abs/2407.19987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.19987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.20026v1</id>
    <updated>2024-07-29T14:02:33Z</updated>
    <published>2024-07-29T14:02:33Z</published>
    <title>JAX-SSO: Differentiable Finite Element Analysis Solver for Structural
  Optimization and Seamless Integration with Neural Networks</title>
    <summary>  Differentiable numerical simulations of physical systems have gained rising
attention in the past few years with the development of automatic
differentiation tools. This paper presents JAX-SSO, a differentiable finite
element analysis solver built with JAX, Google's high-performance computing
library, to assist efficient structural design in the built environment. With
the adjoint method and automatic differentiation feature, JAX-SSO can
efficiently evaluate gradients of physical quantities in an automatic way,
enabling accurate sensitivity calculation in structural optimization problems.
Written in Python and JAX, JAX-SSO is naturally within the machine learning
ecosystem so it can be seamlessly integrated with neural networks to train
machine learning models with inclusion of physics. Moreover, JAX-SSO supports
GPU acceleration to further boost finite element analysis. Several examples are
presented to showcase the capabilities and efficiency of JAX-SSO: i) shape
optimization of grid-shells and continuous shells; ii) size (thickness)
optimization of continuous shells; iii) simultaneous shape and topology
optimization of continuous shells; and iv) training of physics-informed neural
networks for structural optimization. We believe that JAX-SSO can facilitate
research related to differentiable physics and machine learning to further
address problems in structural and architectural design.
</summary>
    <author>
      <name>Gaoyuan Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2407.20026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.20026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.03452v1</id>
    <updated>2024-08-06T21:18:51Z</updated>
    <published>2024-08-06T21:18:51Z</published>
    <title>Matrix-Free Finite Volume Kernels on a Dataflow Architecture</title>
    <summary>  Fast and accurate numerical simulations are crucial for designing large-scale
geological carbon storage projects ensuring safe long-term CO2 containment as a
climate change mitigation strategy. These simulations involve solving numerous
large and complex linear systems arising from the implicit Finite Volume (FV)
discretization of PDEs governing subsurface fluid flow. Compounded with highly
detailed geomodels, solving linear systems is computationally and memory
expensive, and accounts for the majority of the simulation time. Modern memory
hierarchies are insufficient to meet the latency and bandwidth needs of
large-scale numerical simulations. Therefore, exploring algorithms that can
leverage alternative and balanced paradigms, such as dataflow and in-memory
computing is crucial. This work introduces a matrix-free algorithm to solve
FV-based linear systems using a dataflow architecture to significantly minimize
memory latency and bandwidth bottlenecks. Our implementation achieves two
orders of magnitude speedup compared to a GPGPU-based reference implementation,
and up to 1.2 PFlops on a single dataflow device.
</summary>
    <author>
      <name>Ryuichi Sai</name>
    </author>
    <author>
      <name>Francois P. Hamon</name>
    </author>
    <author>
      <name>John Mellor-Crummey</name>
    </author>
    <author>
      <name>Mauricio Araya-Polo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:2304.11274</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.03452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.03452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.05217v1</id>
    <updated>2024-07-24T16:47:01Z</updated>
    <published>2024-07-24T16:47:01Z</published>
    <title>Implementing a Restricted Function Space Class in Firedrake</title>
    <summary>  The implementation process of a $\texttt{RestrictedFunctionSpace}$ class in
Firedrake, a Python library which numerically solves partial differential
equations through the use of the finite element method, is documented. This
includes an introduction to the current $\texttt{FunctionSpace}$ class in
Firedrake, and the key features that it has. With the current
$\texttt{FunctionSpace}$ class, the limitations of the capabilities of the
solvers in Firedrake when imposing Dirichlet boundary conditions are explored,
as well as what the $\texttt{RestrictedFunctionSpace}$ class does differently
to remove these issues. These will be considered in both a mathematical way,
and in the code as an abstraction of the mathematical ideas presented. Finally,
the benefits to the user of the $\texttt{RestrictedFunctionSpace}$ class are
considered, and demonstrated through tests and comparisons. This leads to the
conclusion that in particular, the eigensolver in Firedrake is improved through
the use of the $\texttt{RestrictedFunctionSpace}$, through the removal of
eigenvalues associated with the Dirichlet boundary conditions for a system.
</summary>
    <author>
      <name>Emma Rothwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MSci Research Project, 51 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.05217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.05217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.11074v3</id>
    <updated>2024-09-01T00:17:42Z</updated>
    <published>2024-08-19T00:07:39Z</published>
    <title>cpp11armadillo: An R Package to Use the Armadillo C++ Library</title>
    <summary>  This article introduces 'cpp11armadillo', a new R package that integrates the
powerful Armadillo C++ library for linear algebra into the R programming
environment. Targeted primarily at social scientists and other non-programmers,
this article explains the computational benefits of moving code to C++ in terms
of speed and syntax. We provide a comprehensive overview of Armadillo's
capabilities, highlighting its user-friendly syntax akin to MATLAB and its
efficiency for computationally intensive tasks. The 'cpp11armadillo' package
simplifies a part of the process of using C++ within R by offering additional
ease of integration for those who require high-performance linear algebra
operations in their R workflows. This work aims to bridge the gap between
computational efficiency and accessibility, making advanced linear algebra
operations more approachable for R users without extensive programming
backgrounds.
</summary>
    <author>
      <name>Mauricio Vargas Sepúlveda</name>
    </author>
    <author>
      <name>Jonathan Schneider Malamud</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.softx.2025.102087.</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.softx.2025.102087." rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.11074v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.11074v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.5; D.3.3; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.13420v1</id>
    <updated>2024-08-24T01:24:11Z</updated>
    <published>2024-08-24T01:24:11Z</published>
    <title>PySLSQP: A transparent Python package for the SLSQP optimization
  algorithm modernized with utilities for visualization and post-processing</title>
    <summary>  PySLSQP is a seamless interface for using the SLSQP algorithm from Python. It
wraps the original SLSQP Fortran code sourced from the SciPy repository and
provides a host of new features to improve the research utility of the original
algorithm. Some of the additional features offered by PySLSQP include
auto-generation of unavailable derivatives using finite differences,
independent scaling of the problem variables and functions, access to internal
optimization data, live-visualization, saving optimization data from each
iteration, warm/hot restarting of optimization, and various other utilities for
post-processing.
</summary>
    <author>
      <name>Anugrah Jo Joshy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of California San Diego</arxiv:affiliation>
    </author>
    <author>
      <name>John T. Hwang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of California San Diego</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages with 2 figures. For associated code, see
  https://github.com/anugrahjo/PySLSQP</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.13420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.13420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.00244v1</id>
    <updated>2024-08-30T20:30:34Z</updated>
    <published>2024-08-30T20:30:34Z</published>
    <title>TorchDA: A Python package for performing data assimilation with deep
  learning forward and transformation functions</title>
    <summary>  Data assimilation techniques are often confronted with challenges handling
complex high dimensional physical systems, because high precision simulation in
complex high dimensional physical systems is computationally expensive and the
exact observation functions that can be applied in these systems are difficult
to obtain. It prompts growing interest in integrating deep learning models
within data assimilation workflows, but current software packages for data
assimilation cannot handle deep learning models inside. This study presents a
novel Python package seamlessly combining data assimilation with deep neural
networks to serve as models for state transition and observation functions. The
package, named TorchDA, implements Kalman Filter, Ensemble Kalman Filter
(EnKF), 3D Variational (3DVar), and 4D Variational (4DVar) algorithms, allowing
flexible algorithm selection based on application requirements. Comprehensive
experiments conducted on the Lorenz 63 and a two-dimensional shallow water
system demonstrate significantly enhanced performance over standalone model
predictions without assimilation. The shallow water analysis validates data
assimilation capabilities mapping between different physical quantity spaces in
either full space or reduced order space. Overall, this innovative software
package enables flexible integration of deep learning representations within
data assimilation, conferring a versatile tool to tackle complex high
dimensional dynamical systems across scientific domains.
</summary>
    <author>
      <name>Sibo Cheng</name>
    </author>
    <author>
      <name>Jinyang Min</name>
    </author>
    <author>
      <name>Che Liu</name>
    </author>
    <author>
      <name>Rossella Arcucci</name>
    </author>
    <link href="http://arxiv.org/abs/2409.00244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.00244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.01272v1</id>
    <updated>2024-09-02T14:10:26Z</updated>
    <published>2024-09-02T14:10:26Z</published>
    <title>A prony method variant which surpasses the Adaptive LMS filter in the
  output signal's representation of input</title>
    <summary>  The Prony method for approximating signals comprising sinusoidal/exponential
components is known through the pioneering work of Prony in his seminal
dissertation in the year 1795. However, the Prony method saw the light of real
world application only upon the advent of the computational era, which made
feasible the extensive numerical intricacies and labor which the method demands
inherently. The Adaptive LMS Filter which has been the most pervasive method
for signal filtration and approximation since its inception in 1965 does not
provide a consistently assured level of highly precise results as the extended
experiment in this work proves. As a remedy this study improvises upon the
Prony method by observing that a better (more precise) computational
approximation can be obtained under the premise that adjustment can be made for
computational error , in the autoregressive model setup in the initial step of
the Prony computation itself. This adjustment is in proportion to the deviation
of the coefficients in the same autoregressive model. The results obtained by
this improvisation live up to the expectations of obtaining consistency and
higher value in the precision of the output (recovered signal) approximations
as shown in this current work and as compared with the results obtained using
the Adaptive LMS Filter.
</summary>
    <author>
      <name>Parthasarathy Srinivasan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2024.15401</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2024.15401" rel="related"/>
    <link href="http://arxiv.org/abs/2409.01272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.01272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.02969v3</id>
    <updated>2024-10-11T16:31:46Z</updated>
    <published>2024-09-04T07:44:43Z</published>
    <title>LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch</title>
    <summary>  Multiobjective optimization problems (MOPs) are prevalent in machine
learning, with applications in multi-task learning, learning under fairness or
robustness constraints, etc. Instead of reducing multiple objective functions
into a scalar objective, MOPs aim to optimize for the so-called Pareto
optimality or Pareto set learning, which involves optimizing more than one
objective function simultaneously, over models with thousands / millions of
parameters. Existing benchmark libraries for MOPs mainly focus on evolutionary
algorithms, most of which are zeroth-order / meta-heuristic methods that do not
effectively utilize higher-order information from objectives and cannot scale
to large-scale models with thousands / millions of parameters. In light of the
above gap, this paper introduces LibMOON, the first multiobjective optimization
library that supports state-of-the-art gradient-based methods, provides a fair
benchmark, and is open-sourced for the community.
</summary>
    <author>
      <name>Xiaoyuan Zhang</name>
    </author>
    <author>
      <name>Liang Zhao</name>
    </author>
    <author>
      <name>Yingying Yu</name>
    </author>
    <author>
      <name>Xi Lin</name>
    </author>
    <author>
      <name>Yifan Chen</name>
    </author>
    <author>
      <name>Han Zhao</name>
    </author>
    <author>
      <name>Qingfu Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.02969v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.02969v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.06752v3</id>
    <updated>2024-12-10T18:34:46Z</updated>
    <published>2024-09-10T14:04:58Z</published>
    <title>A tutorial on automatic differentiation with complex numbers</title>
    <summary>  Automatic differentiation is everywhere, but there exists only minimal
documentation of how it works in complex arithmetic beyond stating "derivatives
in $\mathbb{C}^d$" $\cong$ "derivatives in $\mathbb{R}^{2d}$" and, at best,
shallow references to Wirtinger calculus. Unfortunately, the equivalence
$\mathbb{C}^d \cong \mathbb{R}^{2d}$ becomes insufficient as soon as we need to
derive custom gradient rules, e.g., to avoid differentiating "through"
expensive linear algebra functions or differential equation simulators. To
combat such a lack of documentation, this article surveys forward- and
reverse-mode automatic differentiation with complex numbers, covering topics
such as Wirtinger derivatives, a modified chain rule, and different gradient
conventions while explicitly avoiding holomorphicity and the Cauchy--Riemann
equations (which would be far too restrictive). To be precise, we will derive,
explain, and implement a complex version of Jacobian-vector and vector-Jacobian
products almost entirely with linear algebra without relying on complex
analysis or differential geometry. This tutorial is a call to action, for users
and developers alike, to take complex values seriously when implementing custom
gradient propagation rules -- the manuscript explains how.
</summary>
    <author>
      <name>Nicholas Krämer</name>
    </author>
    <link href="http://arxiv.org/abs/2409.06752v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.06752v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.07563v2</id>
    <updated>2025-03-10T19:54:56Z</updated>
    <published>2024-09-11T18:31:33Z</published>
    <title>MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization</title>
    <summary>  This paper introduces a new C++/CUDA library for GPU-accelerated stochastic
optimization called MPPI-Generic. It provides implementations of Model
Predictive Path Integral control, Tube-Model Predictive Path Integral Control,
and Robust Model Predictive Path Integral Control, and allows for these
algorithms to be used across many pre-existing dynamics models and cost
functions. Furthermore, researchers can create their own dynamics models or
cost functions following our API definitions without needing to change the
actual Model Predictive Path Integral Control code. Finally, we compare
computational performance to other popular implementations of Model Predictive
Path Integral Control over a variety of GPUs to show the real-time capabilities
our library can allow for. Library code can be found at:
https://acdslab.github.io/mppi-generic-website/ .
</summary>
    <author>
      <name>Bogdan Vlahov</name>
    </author>
    <author>
      <name>Jason Gibson</name>
    </author>
    <author>
      <name>Manan Gandhi</name>
    </author>
    <author>
      <name>Evangelos A. Theodorou</name>
    </author>
    <link href="http://arxiv.org/abs/2409.07563v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.07563v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.13090v1</id>
    <updated>2024-09-19T21:20:00Z</updated>
    <published>2024-09-19T21:20:00Z</published>
    <title>Some new techniques to use in serial sparse Cholesky factorization
  algorithms</title>
    <summary>  We present a new variant of serial right-looking supernodal sparse Cholesky
factorization (RL). Our comparison of RL with the multifrontal method confirms
that RL is simpler, slightly faster, and requires slightly less storage. The
key to the rest of the work in this paper is recent work on reordering columns
within supernodes so that the dense off-diagonal blocks in the factor matrix
joining pairs of supernodes are fewer and larger. We present a second new
variant of serial right-looking supernodal sparse Cholesky factorization (RLB),
where this one is specifically designed to exploit fewer and larger
off-diagonal blocks in the factor matrix obtained by reordering within
supernodes. A key distinction found in RLB is that it uses no floating-point
working storage and performs no assembly operations. Our key finding is that
RLB is unequivocally faster than its competitors. Indeed, RLB is consistently,
but modestly, faster than its competitors whenever Intel's MKL sequential BLAS
are used. More importantly, RLB is substantially faster than its competitors
whenever Intel's MKL multithreaded BLAS are used. Finally, RLB using the
multithreaded BLAS achieves impressive speedups over RLB using the sequential
BLAS.
</summary>
    <author>
      <name>M. Ozan Karsavuran</name>
    </author>
    <author>
      <name>Esmond G. Ng</name>
    </author>
    <author>
      <name>Barry W. Peyton</name>
    </author>
    <author>
      <name>Jonathan L. Peyton</name>
    </author>
    <link href="http://arxiv.org/abs/2409.13090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.13090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.18772v1</id>
    <updated>2024-09-27T14:16:35Z</updated>
    <published>2024-09-27T14:16:35Z</published>
    <title>A method of using RSVD in residual calculation of LowBit GEMM</title>
    <summary>  The advancements of hardware technology in recent years has brought many
possibilities for low-precision applications. However, the use of low precision
can introduce significant computational errors, posing a considerable challenge
to maintaining the computational accuracy.
  We propose low-rank residuals quantized matrix multiplication(LRQMM) method
which introduces low-rank approximation in residual compensation for dense low
precision quantization matrix multiplication. It can bring several times
accuracy improvement with only BLAS-2 level extra time overhead. Moreover,
LRQMM is a completely data-free quantization method that does not require
additional data for pre-training. And it only works with low precision GEMM
operator, which is easy to couple with other methods.
  Through experimentation, LRQMM can reduce the error of direct quantized
matrix multiplication by 1~2 orders of magnitude, when dealing with larger
matrix sizes, the computational speed is only reduced by approximately 20\%. In
deep learning networks, LRQMM-4bit achieves 61.8% ImageNet Top-1 accuracy in
Resnet-50, while the Direct Quant accuracy is only 8.3%.
</summary>
    <author>
      <name>Hongyaoxing Gu</name>
    </author>
    <link href="http://arxiv.org/abs/2409.18772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.18772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.06770v1</id>
    <updated>2024-10-09T11:03:14Z</updated>
    <published>2024-10-09T11:03:14Z</published>
    <title>BLAS-like Interface for Binary Tensor Contractions</title>
    <summary>  In the world of linear algebra computation, a well-established standard
exists called BLAS(Basic Linear Algebra Subprograms). This standard has been
crucial for the development of software using linear algebra operations. Its
benefits include portability with efficiency and mitigation of suboptimal
re-implementations of linear algebra operations. Multilinear algebra is an
extension of linear algebra in which the central objects are tensors, which are
generalizations of vectors and matrices. Though tensor operations are becoming
more common, they do not have a standard like BLAS. Such standardization would
be beneficial and decrease the now-visible replication of work, as many
libraries nowadays use their own implementations. This master thesis aims to
work towards such a standard by discovering whether or not a BLAS-like
interface is possible for the operation binary tensor contraction. To answer
this, an interface has been developed in the programming language C together
with an implementation and tested to see if it would be sufficient. The
interface developed is:
  xGETT(RANKA, EXTA, INCA, A, RANKB, EXTB, INCB, B, CONTS, CONTA, CONTB, PERM,
INCC, C)
  with the implementation and tests, it has been deemed sufficient as a
BLAS-like interface for binary tensor contractions and possible to use in a
BLAS-like standardization for tensor operations.
</summary>
    <author>
      <name>Niklas Hörnblad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">master thesis report, 21 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.06770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.06770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.22652v1</id>
    <updated>2024-10-30T02:41:42Z</updated>
    <published>2024-10-30T02:41:42Z</published>
    <title>Development of a Python-Based Software for Calculating the Jones
  Polynomial: Insights into the Behavior of Polymers and Biopolymers</title>
    <summary>  This thesis details a Python-based software designed to calculate the Jones
polynomial, a vital mathematical tool from Knot Theory used for characterizing
the topological and geometrical complexity of curves in \( \mathbb{R}^3 \),
which is essential in understanding physical systems of filaments, including
the behavior of polymers and biopolymers. The Jones polynomial serves as a
topological invariant capable of distinguishing between different knot
structures. This capability is fundamental to characterizing the architecture
of molecular chains, such as proteins and DNA. Traditional computational
methods for deriving the Jones polynomial have been limited by closure-schemes
and high execution costs, which can be impractical for complex structures like
those that appear in real life. This software implements methods that
significantly reduce calculation times, allowing for more efficient and
practical applications in the study of biological polymers. It utilizes a
divide-and-conquer approach combined with parallel computing and applies
recursive Reidemeister moves to optimize the computation, transitioning from an
exponential to a near-linear runtime for specific configurations. This thesis
provides an overview of the software's functions, detailed performance
evaluations using protein structures as test cases, and a discussion of the
implications for future research and potential algorithmic improvements.
</summary>
    <author>
      <name>Caleb Musfeldt</name>
    </author>
    <link href="http://arxiv.org/abs/2410.22652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.22652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.03501v1</id>
    <updated>2024-11-05T20:31:23Z</updated>
    <published>2024-11-05T20:31:23Z</published>
    <title>The Python LevelSet Toolbox (LevelSetPy)</title>
    <summary>  This paper describes open-source scientific contributions in python
surrounding the numerical solutions to hyperbolic Hamilton-Jacobi (HJ) partial
differential equations viz., their implicit representation on co-dimension one
surfaces; dynamics evolution with levelsets; spatial derivatives; total
variation diminishing Runge-Kutta integration schemes; and their applications
to the theory of reachable sets. They are increasingly finding applications in
multiple research domains such as reinforcement learning, robotics, control
engineering and automation. We describe the library components, illustrate
usage with an example, and provide comparisons with existing implementations.
This GPU-accelerated package allows for easy portability to many modern
libraries for the numerical analyses of the HJ equations. We also provide a CPU
implementation in python that is significantly faster than existing
alternatives.
</summary>
    <author>
      <name>Lekan Molu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 63rd IEEE Conference on Decision and Control, Milan, 2024</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2411.03501v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.03501v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.16509v1</id>
    <updated>2024-11-25T15:46:54Z</updated>
    <published>2024-11-25T15:46:54Z</published>
    <title>Jaya R Package -- A Parameter-Free Solution for Advanced Single and
  Multi-Objective Optimization</title>
    <summary>  The Jaya R package offers a robust and versatile implementation of the
parameter-free Jaya optimization algorithm, suitable for solving both
single-objective and multi-objective optimization problems. By integrating
advanced features such as constraint handling, adaptive population management,
Pareto front tracking for multi-objective trade-offs, and parallel processing
for computational efficiency, the package caters to a wide range of
optimization challenges. Its intuitive design and flexibility allow users to
solve complex, real-world problems across various domains. To demonstrate its
practical utility, a case study on energy modeling explores the optimization of
renewable energy shares, showcasing the package's ability to minimize carbon
emissions and costs while enhancing system reliability. The Jaya R package is
an invaluable tool for researchers and practitioners seeking efficient and
adaptive optimization solutions.
</summary>
    <author>
      <name>Neeraj Dhanraj Bokde</name>
    </author>
    <link href="http://arxiv.org/abs/2411.16509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.16509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.03398v1</id>
    <updated>2025-01-06T21:36:43Z</updated>
    <published>2025-01-06T21:36:43Z</published>
    <title>Rapid Experimentation with Python Considering Optional and Hierarchical
  Inputs</title>
    <summary>  Space-filling experimental design techniques are commonly used in many
computer modeling and simulation studies to explore the effects of inputs on
outputs. This research presents raxpy, a Python package that leverages
expressive annotation of Python functions and classes to simplify space-filling
experimentation. It incorporates code introspection to derive a Python
function's input space and novel algorithms to automate the design of
space-filling experiments for spaces with optional and hierarchical input
dimensions. In this paper, we review the criteria for design evaluation given
these types of dimensions and compare the proposed algorithms with numerical
experiments. The results demonstrate the ability of the proposed algorithms to
create improved space-filling experiment designs. The package includes support
for parallelism and distributed execution. raxpy is available as free and
open-source software under a MIT license.
</summary>
    <author>
      <name>Neil Ranly</name>
    </author>
    <author>
      <name>Torrey Wagner</name>
    </author>
    <link href="http://arxiv.org/abs/2501.03398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.03398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62K99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.04032v1</id>
    <updated>2025-01-01T10:52:31Z</updated>
    <published>2025-01-01T10:52:31Z</published>
    <title>Efficient Computation of Collatz Sequence Stopping Times: A Novel
  Algorithmic Approach</title>
    <summary>  The Collatz conjecture, which posits that any positive integer will
eventually reach 1 through a specific iterative process, is a classic unsolved
problem in mathematics. This research focuses on designing an efficient
algorithm to compute the stopping time of numbers in the Collatz sequence,
achieving significant computational improvements. By leveraging structural
patterns in the Collatz tree, the proposed algorithm minimizes redundant
operations and optimizes computational steps. Unlike prior methods, it
efficiently handles extremely large numbers without requiring advanced
techniques such as memoization or parallelization. Experimental evaluations
confirm computational efficiency improvements of approximately 28% over
state-of-the-art methods. These findings underscore the algorithm's scalability
and robustness, providing a foundation for future large-scale verification of
the conjecture and potential applications in computational mathematics.
</summary>
    <author>
      <name>Eyob Solomon Getachew</name>
    </author>
    <author>
      <name>Beakal Gizachew Assefa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been submitted to the IEEE for possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2501.04032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.04032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.08395v1</id>
    <updated>2025-01-14T19:25:19Z</updated>
    <published>2025-01-14T19:25:19Z</published>
    <title>A comparison of two effective methods for reordering columns within
  supernodes</title>
    <summary>  In some recent papers, researchers have found two very good methods for
reordering columns within supernodes in sparse Cholesky factors; these
reorderings can be very useful for certain factorization methods. The first of
these reordering methods is based on modeling the underlying problem as a
traveling salesman problem (TSP), and the second of these methods is based on
partition refinement (PR). In this paper, we devise a fair way to compare the
two methods. While the two methods are virtually the same in the quality of the
reorderings that they produce, PR should be the method of choice because PR
reorderings can be computed using far less time and storage than TSP
reorderings.
</summary>
    <author>
      <name>M. Ozan Karsavuran</name>
    </author>
    <author>
      <name>Esmond G. Ng</name>
    </author>
    <author>
      <name>Barry W. Peyton</name>
    </author>
    <link href="http://arxiv.org/abs/2501.08395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.08395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.15856v1</id>
    <updated>2025-01-27T08:32:41Z</updated>
    <published>2025-01-27T08:32:41Z</published>
    <title>rcpptimer: Rcpp Tic-Toc Timer with OpenMP Support</title>
    <summary>  Efficient code writing is both a critical and challenging task, especially
with the growing demand for computationally intensive algorithms in statistical
and machine-learning applications. Despite the availability of significant
computational power today, the need for optimized algorithm implementations
remains crucial. Many R users rely on Rcpp to write performant code in C++, but
writing and benchmarking C++ code presents its own difficulties. While R's
benchmarking tools are insufficient for measuring the execution times of C++
code segments, C++'s native profiling tools often come with a steep learning
curve. The rcpptimer package bridges this gap by offering a simple and
efficient solution for timing C++ code within the Rcpp ecosystem. This novel
package introduces a user-friendly tic-toc class that supports overlapping and
nested timers and OpenMP parallelism, providing nanosecond-level time
resolution. Results, including summary statistics, are seamlessly passed back
to R without requiring users to write any C++ code. This paper contextualizes
the rcpptimer package within the broader ecosystem of R and C++ profiling
tools, explains the motivation behind its development, and offers a
comprehensive overview of its implementation. Supplementary to this paper, we
provide multiple vignettes that thoroughly explain this package's usage.
</summary>
    <author>
      <name>Jonathan Berrisch</name>
    </author>
    <link href="http://arxiv.org/abs/2501.15856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.15856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.03000v3</id>
    <updated>2025-03-26T09:02:08Z</updated>
    <published>2025-02-05T08:52:37Z</published>
    <title>Armadillo: An Efficient Framework for Numerical Linear Algebra</title>
    <summary>  A major challenge in the deployment of scientific software solutions is the
adaptation of research prototypes to production-grade code. While high-level
languages like MATLAB are useful for rapid prototyping, they lack the resource
efficiency required for scalable production applications, necessitating
translation into lower level languages like C++. Further, for machine learning
and signal processing applications, the underlying linear algebra primitives,
generally provided by the standard BLAS and LAPACK libraries, are unwieldy and
difficult to use, requiring manual memory management and other tedium. To
address this challenge, the Armadillo C++ linear algebra library provides an
intuitive interface for writing linear algebra expressions that are easily
compiled into efficient production-grade implementations. We describe the
expression optimisations we have implemented in Armadillo, exploiting template
metaprogramming. We demonstrate that these optimisations result in considerable
efficiency gains on a variety of benchmark linear algebra expressions.
</summary>
    <author>
      <name>Conrad Sanderson</name>
    </author>
    <author>
      <name>Ryan Curtin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICCAE64891.2025.10980539</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICCAE64891.2025.10980539" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Computer and Automation Engineering,
  2025</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2502.03000v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.03000v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N99, 65Y04, 65Y15, 65F45" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.3; D.2.3; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.07935v1</id>
    <updated>2025-02-11T20:28:20Z</updated>
    <published>2025-02-11T20:28:20Z</published>
    <title>$\texttt{PrecisionLauricella}$: package for numerical computation of
  Lauricella functions depending on a parameter</title>
    <summary>  We introduce the $\texttt{PrecisionLauricella}$ package, a computational tool
developed in Wolfram Mathematica for high-precision numerical evaluations of
Lauricella functions with indices linearly dependent on a parameter,
$\varepsilon$. The package leverages a method based on analytical continuation
via Frobenius generalized power series, providing an efficient and accurate
alternative to conventional approaches relying on multi-dimensional series
expansions or Mellin--Barnes representations. This one-dimensional approach is
particularly advantageous for high-precision calculations and facilitates
further optimization through $\varepsilon$-dependent reconstruction from
evaluations at specific numerical values, enabling efficient parallelization.
The underlying mathematical framework for this method has been detailed in our
previous work, while the current paper focuses on the design, implementation,
and practical applications of the $\texttt{PrecisionLauricella}$ package.
</summary>
    <author>
      <name>M. A. Bezuglov</name>
    </author>
    <author>
      <name>B. A. Kniehl</name>
    </author>
    <author>
      <name>A. I. Onishchenko</name>
    </author>
    <author>
      <name>O. L. Veretin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:2502.03276</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.07935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.07935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.08677v1</id>
    <updated>2025-02-12T05:43:30Z</updated>
    <published>2025-02-12T05:43:30Z</published>
    <title>RMCDA: The comprehensive R library for applying multi-criteria decision
  analysis methods</title>
    <summary>  Multi-Criteria Decision Making (MCDM) is a branch of operations research used
in a variety of domains from health care to engineering to facilitate
decision-making among multiple options based on specific criteria. Several R
packages have been developed for the application of traditional MCDM
approaches. However, as the discipline has advanced, many new approaches have
emerged, necessitating the development of innovative and comprehensive tools to
enhance the accessibility of these methodologies. Here, we introduce RMCDA, a
comprehensive and universal R package that offers access to a variety of
established MCDM approaches (e.g., AHP, TOPSIS, PROMETHEE, and VIKOR), along
with newer techniques such as Stratified MCDM (SMCDM) and the Stratified
Best-Worst Method (SBWM). Our open source software intends to broaden the
practical use of these methods through supplementary visualization tools and
straightforward installation.
</summary>
    <author>
      <name>Annice Najafi</name>
    </author>
    <author>
      <name>Shokoufeh Mirzaei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.08677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.08677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.14256v1</id>
    <updated>2025-02-20T04:45:12Z</updated>
    <published>2025-02-20T04:45:12Z</published>
    <title>A Unified Implementation of Quasi-Monte Carlo Generators, Randomization
  Routines, and Fast Kernel Methods</title>
    <summary>  Quasi-random sequences, also called low-discrepancy sequences, have been
extensively used as efficient experimental designs across many scientific
disciplines. This article provides a unified description and software API for
methods pertaining to low-discrepancy point sets. These methods include low
discrepancy point set generators, randomization techniques, and fast kernel
methods. Specifically, we provide generators for lattices, digital nets, and
Halton point sets. Supported randomization techniques include random
permutations / shifts, linear matrix scrambling, and nested uniform scrambling.
Routines for working with higher-order digital nets and scramblings are also
detailed. For kernel methods, we provide implementations of special
shift-invariant and digitally-shift invariant kernels along with fast Gram
matrix operations facilitated by the bit-reversed FFT, the bit-reversed IFFT,
and the FWHT. A new digitally-shift-invariant kernel of higher-order smoothness
is also derived. We also describe methods to quickly update the matrix-vector
product or linear system solution after doubling the number of points in a
lattice or digital net in natural order.
</summary>
    <author>
      <name>Aleksei Sorokin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 4 figures, submitted to ACM TOMS</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.14256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.14256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.16517v1</id>
    <updated>2025-02-23T09:43:23Z</updated>
    <published>2025-02-23T09:43:23Z</published>
    <title>Annotation-guided AoS-to-SoA conversions and GPU offloading with data
  views in C++</title>
    <summary>  The C++ programming language provides classes and structs as fundamental
modeling entities. Consequently, C++ code tends to favour array-of-structs
(AoS) for encoding data sequences, even though structure-of-arrays (SoA) yields
better performance for some calculations. We propose a C++ language extension
based on attributes that allows developers to guide the compiler in selecting
memory arrangements, i.e.~to select the optimal choice between AoS and SoA
dynamically depending on both the execution context and algorithm step. The
compiler can then automatically convert data into the preferred format prior to
the calculations and convert results back afterward. The compiler handles all
the complexity of determining which data to convert and how to manage data
transformations. Our implementation realises the compiler-extension for the new
annotations in Clang and demonstrates their effectiveness through a smoothed
particle hydrodynamics (SPH) code, which we evaluate on an Intel CPU, an ARM
CPU, and a Grace-Hopper GPU. While the separation of concerns between data
structure and operators is elegant and provides performance improvements, the
new annotations do not eliminate the need for performance engineering. Instead,
they challenge conventional performance wisdom and necessitate rethinking
approaches how to write efficient implementations.
</summary>
    <author>
      <name>Pawel K. Radtke</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <link href="http://arxiv.org/abs/2502.16517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.16517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02134v1</id>
    <updated>2025-03-03T23:46:53Z</updated>
    <published>2025-03-03T23:46:53Z</published>
    <title>Enabling Mixed-Precision in Computational Fluids Dynamics Codes</title>
    <summary>  Mixed-precision computing has the potential to significantly reduce the cost
of exascale computations, but determining when and how to implement it in
programs can be challenging. In this article, we propose a methodology for
enabling mixed-precision with the help of computer arithmetic tools, roofline
model, and computer arithmetic techniques. As case studies, we consider
Nekbone, a mini-application for the Computational Fluid Dynamics (CFD) solver
Nek5000, and a modern Neko CFD application. With the help of the VerifiCarlo
tool and computer arithmetic techniques, we introduce a strategy to address
stagnation issues in the preconditioned Conjugate Gradient method in Nekbone
and apply these insights to implement a mixed-precision version of Neko. We
evaluate the derived mixed-precision versions of these codes by combining
metrics in three dimensions: accuracy, time-to-solution, and
energy-to-solution. Notably, mixed-precision in Nekbone reduces
time-to-solution by roughly 38% and energy-to-solution by 2.8x on MareNostrum
5, while in the real-world Neko application the gain is up to 29% in time and
up to 24% in energy, without sacrificing the accuracy.
</summary>
    <author>
      <name>Yanxiang Chen</name>
    </author>
    <author>
      <name>Pablo de Oliveira Castro</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <author>
      <name>Niclas Jansson</name>
    </author>
    <author>
      <name>Roman Iakymchuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2405.11065</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.02134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.17405v1</id>
    <updated>2025-03-20T16:07:14Z</updated>
    <published>2025-03-20T16:07:14Z</published>
    <title>Efficiently Vectorized MCMC on Modern Accelerators</title>
    <summary>  With the advent of automatic vectorization tools (e.g., JAX's
$\texttt{vmap}$), writing multi-chain MCMC algorithms is often now as simple as
invoking those tools on single-chain code. Whilst convenient, for various MCMC
algorithms this results in a synchronization problem -- loosely speaking, at
each iteration all chains running in parallel must wait until the last chain
has finished drawing its sample. In this work, we show how to design
single-chain MCMC algorithms in a way that avoids synchronization overheads
when vectorizing with tools like $\texttt{vmap}$ by using the framework of
finite state machines (FSMs). Using a simplified model, we derive an exact
theoretical form of the obtainable speed-ups using our approach, and use it to
make principled recommendations for optimal algorithm design. We implement
several popular MCMC algorithms as FSMs, including Elliptical Slice Sampling,
HMC-NUTS, and Delayed Rejection, demonstrating speed-ups of up to an order of
magnitude in experiments.
</summary>
    <author>
      <name>Hugh Dance</name>
    </author>
    <author>
      <name>Pierre Glaser</name>
    </author>
    <author>
      <name>Peter Orbanz</name>
    </author>
    <author>
      <name>Ryan Adams</name>
    </author>
    <link href="http://arxiv.org/abs/2503.17405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.03628v1</id>
    <updated>2025-04-04T17:45:54Z</updated>
    <published>2025-04-04T17:45:54Z</published>
    <title>Improving Interoperability in Scientific Computing via MaRDI Open
  Interfaces</title>
    <summary>  MaRDI Open Interfaces is a software project aimed at improving reuse and
interoperability in Scientific Computing by alleviating the difficulties of
crossing boundaries between different programming languages, in which numerical
packages are usually implemented, and of switching between multiple
implementations of the same mathematical problem. The software consists of a
set of formal interface specifications for common Scientific Computing tasks,
as well as a set of loosely coupled libraries that facilitate implementing
these interfaces or adapting existing implementations for multiple programming
languages and handle data marshalling automatically without sacrificing
performance, enabling users to use different implementations without
significant code efforts. The software has high reuse potential due to aim to
solve general numerical problems.
</summary>
    <author>
      <name>Dmitry I. Kabanov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics Münster, University of Münster, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Stephan Rave</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics Münster, University of Münster, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Mario Ohlberger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics Münster, University of Münster, Germany</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.03628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.03628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13821v1</id>
    <updated>2025-04-18T17:51:34Z</updated>
    <published>2025-04-18T17:51:34Z</published>
    <title>Toward Portable GPU Performance: Julia Recursive Implementation of TRMM
  and TRSM</title>
    <summary>  This paper presents a performant and portable recursive implementation of
triangular matrix-matrix multiplication (TRMM) and triangular solve (TRSM) in
Julia for GPUs, two kernels that underlie many linear-algebra algorithms. We
restructure TRMM and TRSM so that most work is executed as general
matrix-matrix multiplication (GEMM), improving use of the GPU memory hierarchy
and reducing latency. Exploiting Julia's multiple dispatch and metaprogramming
together with the GPUArrays and KernelAbstractions frameworks, we expose a
single hardware-agnostic API that runs on NVIDIA, AMD, and Apple Silicon GPUs.
For large matrices the recursive code reaches throughput comparable to vendor
libraries such as cuBLAS and rocBLAS, while providing these routines on Apple
Silicon for the first time. The entire implementation is only a few hundred
lines of code, showing that unified Julia programs can deliver near-vendor
performance across heterogeneous architectures.
</summary>
    <author>
      <name>Vicki Carrica</name>
    </author>
    <author>
      <name>Maxwell Onyango</name>
    </author>
    <author>
      <name>Rabab Alomairy</name>
    </author>
    <author>
      <name>Evelyne Ringoot</name>
    </author>
    <author>
      <name>James Schloss</name>
    </author>
    <author>
      <name>Alan Edelman</name>
    </author>
    <link href="http://arxiv.org/abs/2504.13821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.00448v1</id>
    <updated>2025-05-01T10:45:37Z</updated>
    <published>2025-05-01T10:45:37Z</published>
    <title>NApy: Efficient Statistics in Python for Large-Scale Heterogeneous Data
  with Enhanced Support for Missing Data</title>
    <summary>  Existing Python libraries and tools lack the ability to efficiently compute
statistical test results for large datasets in the presence of missing values.
This presents an issue as soon as constraints on runtime and memory
availability become essential considerations for a particular usecase. Relevant
research areas where such limitations arise include interactive tools and
databases for exploratory analysis of biomedical data. To address this problem,
we present the Python package NApy, which relies on a Numba and C++ backend
with OpenMP parallelization to enable scalable statistical testing for
mixed-type datasets in the presence of missing values. Both with respect to
runtime and memory consumption, NApy outperforms competitor tools and baseline
implementations with naive Python-based parallelization by orders of magnitude,
thereby enabling on-the-fly analyses in interactive applications. NApy is
publicly available at https://github.com/DyHealthNet/NApy.
</summary>
    <author>
      <name>Fabian Woller</name>
    </author>
    <author>
      <name>Lis Arend</name>
    </author>
    <author>
      <name>Christian Fuchsberger</name>
    </author>
    <author>
      <name>Markus List</name>
    </author>
    <author>
      <name>David B. Blumenthal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.00448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.00448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512073v12</id>
    <updated>2015-12-10T20:53:25Z</updated>
    <published>2005-12-17T15:09:11Z</published>
    <title>Schwerdtfeger-Fillmore-Springer-Cnops Construction Implemented in GiNaC</title>
    <summary>  This paper presents an implementation of the
Schwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with
illustrations of its usage. SFSCc linearises the linear-fraction action of the
Moebius group in R^n. This has clear advantages in several theoretical and
applied fields including engineering. Our implementation is based on the
Clifford algebra capacities of the GiNaC computer algebra system
(http://www.ginac.de/), which were described in cs.MS/0410044.
  The core of this realisation of SFSCc is done for an arbitrary dimension of
R^n with a metric given by an arbitrary bilinear form. We also present a
subclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),
which add some 2D specific routines including a visualisation to PostScript
files through the MetaPost (http://www.tug.org/metapost.html) or Asymptote
(http://asymptote.sourceforge.net/) packages.
  This software is the backbone of many results published in math.CV/0512416
and we use its applications their for demonstration. The library can be ported
(with various level of required changes) to other CAS with Clifford algebras
capabilities similar to GiNaC.
  There is an ISO image of a Live Debian DVD attached to this paper as an
auxiliary file, a copy is stored on Google Drive as well.
</summary>
    <author>
      <name>Vladimir V. Kisil</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00006-006-0017-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00006-006-0017-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTeX, 82 p; 11 PS graphics in two figures, the full source files and
  ISO image of Live DVD are included; v9: library update for the book on
  Moebius transformations; v10: an ISO image of a Live DVD is attached to the
  paper; v11: a bug is fixed; v12: Library is uupdated, the reference to a
  larger project is added</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Adv. Appl. Clifford Algebr. v.17 (2007), no.1, 59-70</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0512073v12" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512073v12" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="51B25, 51N25, 68U05, 11E88, 68W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105033v1</id>
    <updated>2001-05-25T15:08:13Z</updated>
    <published>2001-05-25T15:08:13Z</published>
    <title>Lectures on Reduce and Maple at UAM I - Mexico</title>
    <summary>  These lectures give a brief introduction to the Computer Algebra systems
Reduce and Maple. The aim is to provide a systematic survey of most important
commands and concepts. In particular, this includes a discussion of
simplification schemes and the handling of simplification and substitution
rules (e.g., a Lie Algebra is implemented in Reduce by means of simplification
rules).
  Another emphasis is on the different implementations of tensor calculi and
the exterior calculus by Reduce and Maple and their application in Gravitation
theory and Differential Geometry.
  I held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa,
Departamento de Fisica, Mexico, in November 1999.
</summary>
    <author>
      <name>Marc Toussaint</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">61 pages; supplementary material can be found at
  http://www.neuroinformatik.ruhr-uni-bochum.de/PEOPLE/mt/work/1999mexico/</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107036v2</id>
    <updated>2001-07-31T08:34:53Z</updated>
    <published>2001-07-29T11:00:59Z</published>
    <title>TeXmacs interfaces to Maxima, MuPAD and REDUCE</title>
    <summary>  GNU TeXmacs is a free wysiwyg word processor providing an excellent
typesetting quality of texts and formulae. It can also be used as an interface
to Computer Algebra Systems (CASs). In the present work, interfaces to three
general-purpose CASs have been implemented.
</summary>
    <author>
      <name>A. G. Grozin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Talk at 5 Int. Workshop on Computer Algebra and its Applications to
  Physics, Dubna, June 28-30; 9 pages, prepared in TeXmacs and exported as
  LaTeX, 6 PostScript figures included</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0107036v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107036v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.3;G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0303004v1</id>
    <updated>2003-03-06T09:19:42Z</updated>
    <published>2003-03-06T09:19:42Z</published>
    <title>Reliability Conditions in Quadrature Algorithms</title>
    <summary>  The detection of insufficiently resolved or ill-conditioned integrand
structures is critical for the reliability assessment of the quadrature rule
outputs. We discuss a method of analysis of the profile of the integrand at the
quadrature knots which allows inferences approaching the theoretical 100% rate
of success, under error estimate sharpening. The proposed procedure is of the
highest interest for the solution of parametric integrals arising in complex
physical models.
</summary>
    <author>
      <name>Gh. Adam</name>
    </author>
    <author>
      <name>S. Adam</name>
    </author>
    <author>
      <name>N. M. Plakida</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/S0010-4655(03)00282-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/S0010-4655(03)00282-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 8 figures, 1 table, LaTeX2e, elsart.cls macro added,
  submitted to Computer Physics Communications</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0303004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; G.1.4; G.1.0; J.2; D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0303031v1</id>
    <updated>2003-03-28T20:47:50Z</updated>
    <published>2003-03-28T20:47:50Z</published>
    <title>A Bird's eye view of Matrix Distributed Processing</title>
    <summary>  We present Matrix Distributed Processing, a C++ library for fast development
of efficient parallel algorithms. MDP is based on MPI and consists of a
collection of C++ classes and functions such as lattice, site and field. Once
an algorithm is written using these components the algorithm is automatically
parallel and no explicit call to communication functions is required. MDP is
particularly suitable for implementing parallel solvers for multi-dimensional
differential equations and mesh-like problems.
</summary>
    <author>
      <name>Massimo Di Pierro</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the ICCSA 2003 Conference</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0303031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; D.3.2;G.1;G.4;I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307061v1</id>
    <updated>2003-07-28T09:35:52Z</updated>
    <published>2003-07-28T09:35:52Z</published>
    <title>Boundary knot method for Laplace and biharmonic problems</title>
    <summary>  The boundary knot method (BKM) [1] is a meshless boundary-type radial basis
function (RBF) collocation scheme, where the nonsingular general solution is
used instead of fundamental solution to evaluate the homogeneous solution,
while the dual reciprocity method (DRM) is employed to approximation of
particular solution. Despite the fact that there are not nonsingular RBF
general solutions available for Laplace and biharmonic problems, this study
shows that the method can be successfully applied to these problems. The
high-order general and fundamental solutions of Burger and Winkler equations
are also first presented here.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3; G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310055v1</id>
    <updated>2003-10-28T16:56:44Z</updated>
    <published>2003-10-28T16:56:44Z</published>
    <title>Mace4 Reference Manual and Guide</title>
    <summary>  Mace4 is a program that searches for finite models of first-order formulas.
For a given domain size, all instances of the formulas over the domain are
constructed. The result is a set of ground clauses with equality. Then, a
decision procedure based on ground equational rewriting is applied. If
satisfiability is detected, one or more models are printed. Mace4 is a useful
complement to first-order theorem provers, with the prover searching for proofs
and Mace4 looking for countermodels, and it is useful for work on finite
algebras. Mace4 performs better on equational problems than did our previous
model-searching program Mace2.
</summary>
    <author>
      <name>William McCune</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310056v1</id>
    <updated>2003-10-28T19:17:38Z</updated>
    <published>2003-10-28T19:17:38Z</published>
    <title>OTTER 3.3 Reference Manual</title>
    <summary>  OTTER is a resolution-style theorem-proving program for first-order logic
with equality. OTTER includes the inference rules binary resolution,
hyperresolution, UR-resolution, and binary paramodulation. Some of its other
abilities and features are conversion from first-order formulas to clauses,
forward and back subsumption, factoring, weighting, answer literals, term
ordering, forward and back demodulation, evaluable functions and predicates,
Knuth-Bendix completion, and the hints strategy. OTTER is coded in ANSI C, is
free, and is portable to many different kinds of computer.
</summary>
    <author>
      <name>William McCune</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">66 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409033v4</id>
    <updated>2009-07-29T10:18:23Z</updated>
    <published>2004-09-17T10:39:45Z</published>
    <title>Mean and Variance Estimation by Kriging</title>
    <summary>  The aim of the paper is to derive the numerical least-squares estimator for
mean and variance of random variable. In order to do so the following questions
have to be answered: (i) what is the statistical model for the estimation
procedure? (ii) what are the properties of the estimator, like optimality (in
which class) or asymptotic properties? (iii) how does the estimator work in
practice, how compared to competing estimators?
</summary>
    <author>
      <name>Tomasz Suslo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, source code (combo.pas) and input file (inp.dat)
  attached</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0409033v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409033v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509070v2</id>
    <updated>2005-11-10T13:19:44Z</updated>
    <published>2005-09-22T15:45:35Z</published>
    <title>A Maple Package for Computing Groebner Bases for Linear Recurrence
  Relations</title>
    <summary>  A Maple package for computing Groebner bases of linear difference ideals is
described. The underlying algorithm is based on Janet and Janet-like monomial
divisions associated with finite difference operators. The package can be used,
for example, for automatic generation of difference schemes for linear partial
differential equations and for reduction of multiloop Feynman integrals. These
two possible applications are illustrated by simple examples of the Laplace
equation and a one-loop scalar integral of propagator type
</summary>
    <author>
      <name>Vladimir P. Gerdt</name>
    </author>
    <author>
      <name>Daniel Robertz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.nima.2005.11.171</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.nima.2005.11.171" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, presented at ACAT-2005</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nucl.Instrum.Meth. A559 (2006) 215-219</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0509070v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509070v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510034v1</id>
    <updated>2005-10-14T01:03:55Z</updated>
    <published>2005-10-14T01:03:55Z</published>
    <title>COMODI: On the Graphical User Interface</title>
    <summary>  We propose a series of features for the graphical user interface (GUI) of the
COmputational MOdule Integrator (COMODI) \cite{Synasc05a}\cite{COMODI}. In view
of the special requirements that a COMODI type of framework for scientific
computing imposes and inspiring from existing solutions that provide advanced
graphical visual programming environments, we identify those elements and
associated behaviors that will have to find their way into the first release of
COMODI.
</summary>
    <author>
      <name>Zsolt I. Lázár</name>
    </author>
    <author>
      <name>Andreea Fanea</name>
    </author>
    <author>
      <name>Dragoş Petraşcu</name>
    </author>
    <author>
      <name>Vladiela Ciobotariu-Boer</name>
    </author>
    <author>
      <name>Bazil Pârv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, to be published as proceedings of SYNASC 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0510034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.13; D.2.12; D.2.11; D.2.9; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510051v1</id>
    <updated>2005-10-18T09:55:42Z</updated>
    <published>2005-10-18T09:55:42Z</published>
    <title>Numerical resolution of some BVP using Bernstein polynomials</title>
    <summary>  In this work we present a method, based on the use of Bernstein polynomials,
for the numerical resolution of some boundary values problems. The computations
have not need of particular approximations of derivatives, such as finite
differences, or particular techniques, such as finite elements. Also, the
method doesn't require the use of matrices, as in resolution of linear
algebraic systems, nor the use of like-Newton algorithms, as in resolution of
non linear sets of equations. An initial equation is resolved only once, then
the method is based on iterated evaluations of appropriate polynomials.
</summary>
    <author>
      <name>Gianluca Argentini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Posted since 2005-11-29 at Applied Mathematics E-Notes,
  http://www.math.nthu.edu.tw/~amen/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0510051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512072v1</id>
    <updated>2005-12-18T16:58:35Z</updated>
    <published>2005-12-18T16:58:35Z</published>
    <title>Computations with one and two real algebraic numbers</title>
    <summary>  We present algorithmic and complexity results concerning computations with
one and two real algebraic numbers, as well as real solving of univariate
polynomials and bivariate polynomial systems with integer coefficients using
Sturm-Habicht sequences.
  Our main results, in the univariate case, concern the problems of real root
isolation (Th. 19) and simultaneous inequalities (Cor.26) and in the bivariate,
the problems of system real solving (Th.42), sign evaluation (Th. 37) and
simultaneous inequalities (Cor. 43).
</summary>
    <author>
      <name>Ioannis Z. Emiris</name>
    </author>
    <author>
      <name>Elias P. Tsigaridas</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0512072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608003v2</id>
    <updated>2006-08-01T22:08:19Z</updated>
    <published>2006-08-01T19:25:17Z</published>
    <title>On a solution to display non-filled-in quaternionic Julia sets</title>
    <summary>  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
</summary>
    <author>
      <name>Alessandro Rosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 28 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0608003v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608003v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610122v1</id>
    <updated>2006-10-20T11:22:52Z</updated>
    <published>2006-10-20T11:22:52Z</published>
    <title>Faithful Polynomial Evaluation with Compensated Horner Algorithm</title>
    <summary>  This paper presents two sufficient conditions to ensure a faithful evaluation
of polynomial in IEEE-754 floating point arithmetic. Faithfulness means that
the computed value is one of the two floating point neighbours of the exact
result; it can be satisfied using a more accurate algorithm than the classic
Horner scheme. One condition here provided is an apriori bound of the
polynomial condition number derived from the error analysis of the compensated
Horner algorithm. The second condition is both dynamic and validated to check
at the running time the faithfulness of a given evaluation. Numerical
experiments illustrate the behavior of these two conditions and that associated
running time over-cost is really interesting.
</summary>
    <author>
      <name>Philippe Langlois</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A-DALI</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Louvet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A-DALI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0610122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/9905155v2</id>
    <updated>1999-05-26T00:19:43Z</updated>
    <published>1999-05-25T20:13:09Z</published>
    <title>An Implementation of the Bestvina-Handel Algorithm for Surface
  Homeomorphisms</title>
    <summary>  Bestvina and Handel have found an effective algorithm that determines whether
a given homeomorphism of an orientable, possibly punctured surface is
pseudo-Anosov. We present a software package in Java that realizes this
algorithm for surfaces with one puncture. Moreover, the package allows the user
to define homeomorphisms in terms of Dehn twists, and in the pseudo-Anosov case
it generates images of train tracks in the sense of Bestvina-Handel.
</summary>
    <author>
      <name>Peter Brinkmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Experimental Mathematics 9:2, 2000, 235-240</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/math/9905155v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/9905155v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0603606v1</id>
    <updated>2006-03-26T12:30:11Z</updated>
    <published>2006-03-26T12:30:11Z</published>
    <title>Lanczos $τ$-method optimal algorithm in APS for approximating the
  mathematical functions</title>
    <summary>  A new procedure is constructed by means of APS in APLAN language. The
procedure solves the initial-value problem for linear differential equations of
order $k$ with polynomial coefficients and regular singularity in the
initialization point in the interval $[a, b]$ and computes the algebraic
polynomial $y_n$ of given order $n$. A new algorithm of Lanczos $\tau$-method
is built for this procedure, the solution existence $y_n$ of the initial-value
problem proved on this algorithm and also is proved the optimality by precision
of order $k$ derivative of the initial-value problem solution.
</summary>
    <author>
      <name>P. N. Denisenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages. Based on a talk given at the Workshop on Symbolic
  Calculations and Exact Methods in Mathematical Physics, Kiev, June 20-26,
  2005</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0603606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0603606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0608789v7</id>
    <updated>2006-11-11T16:25:24Z</updated>
    <published>2006-08-31T14:59:20Z</published>
    <title>One method for proving inequalities by computer</title>
    <summary>  In this article we consider a method for proving a class of analytical
inequalities via minimax rational approximations. All numerical calculations in
this paper are given by Maple computer program.
</summary>
    <author>
      <name>Branko J. Malesevic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in Journal of Inequalities and Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0608789v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0608789v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="26Dxx, 33F05, 41A20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.0090v1</id>
    <updated>2007-04-01T14:35:40Z</updated>
    <published>2007-04-01T14:35:40Z</published>
    <title>Real Options for Project Schedules (ROPS)</title>
    <summary>  Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <link href="http://arxiv.org/abs/0704.0090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.0090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; G.1; G.1.6; G.3; J.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.1490v1</id>
    <updated>2007-07-10T16:23:43Z</updated>
    <published>2007-07-10T16:23:43Z</published>
    <title>Fast computing of velocity field for flows in industrial burners and
  pumps</title>
    <summary>  In this work we present a technique of fast numerical computation for
solutions of Navier-Stokes equations in the case of flows of industrial
interest. At first the partial differential equations are translated into a set
of nonlinear ordinary differential equations using the geometrical shape of the
domain where the flow is developing, then these ODEs are numerically resolved
using a set of computations distributed among the available processors. We
present some results from simulations on a parallel hardware architecture using
native multithreads software and simulating a shared-memory or a
distributed-memory environment.
</summary>
    <author>
      <name>Gianluca Argentini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures; paper accepted for Special Issue "Application of
  distributed and grid computing", Future Generation Computer Systems journal,
  2007</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.1490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.1490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.4659v1</id>
    <updated>2007-07-31T16:54:33Z</updated>
    <published>2007-07-31T16:54:33Z</published>
    <title>Difference Equations in Massive Higher Order Calculations</title>
    <summary>  The calculation of massive 2--loop operator matrix elements, required for the
higher order Wilson coefficients for heavy flavor production in deeply
inelastic scattering, leads to new types of multiple infinite sums over
harmonic sums and related functions, which depend on the Mellin parameter $N$.
We report on the solution of these sums through higher order difference
equations using the summation package {\tt Sigma}.
</summary>
    <author>
      <name>I. Bierenbaum</name>
    </author>
    <author>
      <name>J. Blümlein</name>
    </author>
    <author>
      <name>S. Klein</name>
    </author>
    <author>
      <name>C. Schneider</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages latex, Proceedings ACAT 2007</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PoSACAT2007:082,2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.4659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.4659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.2371v1</id>
    <updated>2008-02-17T09:48:07Z</updated>
    <published>2008-02-17T09:48:07Z</published>
    <title>Generic and Typical Ranks of Three-Way Arrays</title>
    <summary>  The concept of tensor rank, introduced in the twenties, has been popularized
at the beginning of the seventies. This has allowed to carry out Factor
Analysis on arrays with more than two indices. The generic rank may be seen as
an upper bound to the number of factors that can be extracted from a given
tensor. We explain in this short paper how to obtain numerically the generic
rank of tensors of arbitrary dimensions, and compare it with the rare algebraic
results already known at order three. In particular, we examine the cases of
symmetric tensors, tensors with symmetric matrix slices, or tensors with free
entries.
</summary>
    <author>
      <name>P. Comon</name>
    </author>
    <author>
      <name>J. ten Berge</name>
    </author>
    <link href="http://arxiv.org/abs/0802.2371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.2371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.3; G.0; G.3; I.1; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.0554v1</id>
    <updated>2008-08-05T05:20:51Z</updated>
    <published>2008-08-05T05:20:51Z</published>
    <title>Ranking and Unranking of Hereditarily Finite Functions and Permutations</title>
    <summary>  Prolog's ability to return multiple answers on backtracking provides an
elegant mechanism to derive reversible encodings of combinatorial objects as
Natural Numbers i.e. {\em ranking} and {\em unranking} functions. Starting from
a generalization of Ackerman's encoding of Hereditarily Finite Sets with
Urelements and a novel tupling/untupling operation, we derive encodings for
Finite Functions and use them as building blocks for an executable theory of
{\em Hereditarily Finite Functions}. The more difficult problem of {\em
ranking} and {\em unranking} {\em Hereditarily Finite Permutations} is then
tackled using Lehmer codes and factoradics.
  The paper is organized as a self-contained literate Prolog program available
at \url{http://logic.csci.unt.edu/tarau/research/2008/pHFF.zip}
</summary>
    <author>
      <name>Paul Tarau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">unpublished draft</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.0554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.0554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.2665v1</id>
    <updated>2009-01-17T23:36:23Z</updated>
    <published>2009-01-17T23:36:23Z</published>
    <title>A Density Matrix-based Algorithm for Solving Eigenvalue Problems</title>
    <summary>  A new numerical algorithm for solving the symmetric eigenvalue problem is
presented. The technique deviates fundamentally from the traditional Krylov
subspace iteration based techniques (Arnoldi and Lanczos algorithms) or other
Davidson-Jacobi techniques, and takes its inspiration from the contour
integration and density matrix representation in quantum mechanics. It will be
shown that this new algorithm - named FEAST - exhibits high efficiency,
robustness, accuracy and scalability on parallel architectures. Examples from
electronic structure calculations of Carbon nanotubes (CNT) are presented, and
numerical performances and capabilities are discussed.
</summary>
    <author>
      <name>Eric Polizzi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevB.79.115112</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevB.79.115112" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0901.2665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.2665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.4323v1</id>
    <updated>2009-01-26T21:48:35Z</updated>
    <published>2009-01-26T21:48:35Z</published>
    <title>On the bit-complexity of sparse polynomial multiplication</title>
    <summary>  In this paper, we present fast algorithms for the product of two multivariate
polynomials in sparse representation. The bit complexity of our algorithms are
studied in detail for various types of coefficients, and we derive new
complexity results for the power series multiplication in many variables. Our
algorithms are implemented and freely available within the Mathemagix software.
We show that their theoretical costs are well-reflected in practice.
</summary>
    <author>
      <name>Joris van der Hoeven</name>
    </author>
    <author>
      <name>Grégoire Lecerf</name>
    </author>
    <link href="http://arxiv.org/abs/0901.4323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.4323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3065v1</id>
    <updated>2009-06-17T03:29:37Z</updated>
    <published>2009-06-17T03:29:37Z</published>
    <title>Real Solution Isolation with Multiplicity of Zero-Dimensional Triangular
  Systems</title>
    <summary>  Existing algorithms for isolating real solutions of zero-dimensional
polynomial systems do not compute the multiplicities of the solutions. In this
paper, we define in a natural way the multiplicity of solutions of
zero-dimensional triangular polynomial systems and prove that our definition is
equivalent to the classical definition of local (intersection) multiplicity.
Then we present an effective and complete algorithm for isolating real
solutions with multiplicities of zero-dimensional triangular polynomial systems
using our definition. The algorithm is based on interval arithmetic and
square-free factorization of polynomials with real algebraic coefficients. The
computational results on some examples from the literature are presented.
</summary>
    <author>
      <name>Zhihai Zhang</name>
    </author>
    <author>
      <name>Tian Fang</name>
    </author>
    <author>
      <name>Bican Xia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.3065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.4121v1</id>
    <updated>2009-06-22T20:29:09Z</updated>
    <published>2009-06-22T20:29:09Z</published>
    <title>On computing the Hermite form of a matrix of differential polynomials</title>
    <summary>  Given an n x n matrix over the ring of differential polynomials
F(t)[\D;\delta], we show how to compute the Hermite form H of A, and a
unimodular matrix U such that UA=H. The algorithm requires a polynomial number
of operations in terms of n, deg_D(A), and deg_t(A). When F is the field of
rational numbers, it also requires time polynomial in the bit-length of the
coefficients.
</summary>
    <author>
      <name>Mark Giesbrecht</name>
    </author>
    <author>
      <name>Myung Sub Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-04103-7_12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-04103-7_12" rel="related"/>
    <link href="http://arxiv.org/abs/0906.4121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.4121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5339v2</id>
    <updated>2009-11-30T03:03:56Z</updated>
    <published>2009-06-29T19:37:12Z</published>
    <title>Asymmetric Quantum Cyclic Codes</title>
    <summary>  It is recently conjectured in quantum information processing that phase-shift
errors occur with high probability than qubit-flip errors, hence the former is
more disturbing to quantum information than the later one. This leads us to
construct asymmetric quantum error controlling codes to protect quantum
information over asymmetric channels, $\Pr Z \geq \Pr X$. In this paper we
present two generic methods to derive asymmetric quantum cyclic codes using the
generator polynomials and defining sets of classical cyclic codes.
Consequently, the methods allow us to construct several families of asymmetric
quantum BCH, RS, and RM codes. Finally, the methods are used to construct
families of asymmetric subsystem codes.
</summary>
    <author>
      <name>Salah A. Aly</name>
    </author>
    <link href="http://arxiv.org/abs/0906.5339v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5339v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3248v1</id>
    <updated>2009-09-17T14:58:09Z</updated>
    <published>2009-09-17T14:58:09Z</published>
    <title>Topology of 2D and 3D Rational Curves</title>
    <summary>  In this paper we present algorithms for computing the topology of planar and
space rational curves defined by a parametrization. The algorithms given here
work directly with the parametrization of the curve, and do not require to
compute or use the implicit equation of the curve (in the case of planar
curves) or of any projection (in the case of space curves). Moreover, these
algorithms have been implemented in Maple; the examples considered and the
timings obtained show good performance skills.
</summary>
    <author>
      <name>Juan Gerardo Alcazar</name>
    </author>
    <author>
      <name>Gema Maria Diaz-Toca</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cagd.2010.07.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cagd.2010.07.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.3248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4956v1</id>
    <updated>2009-09-27T19:38:00Z</updated>
    <published>2009-09-27T19:38:00Z</published>
    <title>Local Shape of Generalized Offsets to Algebraic Curves</title>
    <summary>  In this paper we study the local behavior of an algebraic curve under a
geometric construction which is a variation of the usual offsetting
construction, namely the {\it generalized} offsetting process (\cite {SS99}).
More precisely, here we discuss when and how this geometric construction may
cause local changes in the shape of an algebraic curve, and we compare our
results with those obtained for the case of classical offsets (\cite{JGS07}).
For these purposes, we use well-known notions of Differential Geometry, and
also the notion of {\it local shape} introduced in \cite{JGS07}.
</summary>
    <author>
      <name>Juan Gerardo Alcazar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.4956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1783v2</id>
    <updated>2011-05-22T09:40:47Z</updated>
    <published>2009-11-09T21:17:43Z</published>
    <title>Numerical Algebraic Geometry for Macaulay2</title>
    <summary>  Numerical Algebraic Geometry uses numerical data to describe algebraic
varieties. It is based on the methods of numerical polynomial homotopy
continuation, an alternative to the classical symbolic approaches of
computational algebraic geometry. We present a package, the driving idea behind
which is to interlink the existing symbolic methods of Macaulay2 and the
powerful engine of numerical approximate computations. The core procedures of
the package exhibit performance competitive with the other homotopy
continuation software.
</summary>
    <author>
      <name>Anton Leykin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Numerical algebraic geometry. JSAG, 3:5-10, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.1783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="14Q99, 68N01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.5272v1</id>
    <updated>2010-01-28T21:10:41Z</updated>
    <published>2010-01-28T21:10:41Z</published>
    <title>An in-place truncated Fourier transform and applications to polynomial
  multiplication</title>
    <summary>  The truncated Fourier transform (TFT) was introduced by van der Hoeven in
2004 as a means of smoothing the "jumps" in running time of the ordinary FFT
algorithm that occur at power-of-two input sizes. However, the TFT still
introduces these jumps in memory usage. We describe in-place variants of the
forward and inverse TFT algorithms, achieving time complexity O(n log n) with
only O(1) auxiliary space. As an application, we extend the second author's
results on space-restricted FFT-based polynomial multiplication to polynomials
of arbitrary degree.
</summary>
    <author>
      <name>David Harvey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">New York University</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel S. Roche</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Waterloo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, pdflatex</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.5272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.5272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.4; I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0012v1</id>
    <updated>2010-01-29T21:23:05Z</updated>
    <published>2010-01-29T21:23:05Z</published>
    <title>The Power of Vocabulary: The Case of Cyclotomic Polynomials</title>
    <summary>  We observe that the vocabulary used to construct the "answer" to problems in
computer algebra can have a dramatic effect on the computational complexity of
solving that problem. We recall a formalization of this observation and explain
the classic example of sparse polynomial arithmetic. For this case, we show
that it is possible to extend the vocabulary so as reap the benefits of
conciseness whilst avoiding the obvious pitfall of repeating the problem
statement as the "solution".
  It is possible to extend the vocabulary either by irreducible cyclotomics or
by $x^n-1$: we look at the options and suggest that the pragmatist might opt
for both.
</summary>
    <author>
      <name>Jacques Carette</name>
    </author>
    <author>
      <name>James H. Davenport</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. Submitted to ISSAC 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.0012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2594v1</id>
    <updated>2010-02-12T16:44:18Z</updated>
    <published>2010-02-12T16:44:18Z</published>
    <title>Fast Arithmetics in Artin-Schreier Towers over Finite Fields</title>
    <summary>  An Artin-Schreier tower over the finite field F_p is a tower of field
extensions generated by polynomials of the form X^p - X - a. Following Cantor
and Couveignes, we give algorithms with quasi-linear time complexity for
arithmetic operations in such towers. As an application, we present an
implementation of Couveignes' algorithm for computing isogenies between
elliptic curves using the p-torsion.
</summary>
    <author>
      <name>Luca De Feo</name>
    </author>
    <author>
      <name>Éric Schost</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jsc.2011.12.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jsc.2011.12.008" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 4 figures, 3 tables, uses mathdots.sty, yjsco.sty Submitted
  to J. Symb. Comput</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.2594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4629v2</id>
    <updated>2010-11-07T14:01:25Z</updated>
    <published>2010-03-24T12:47:13Z</published>
    <title>A Review of Error Estimation in Adaptive Quadrature</title>
    <summary>  The most critical component of any adaptive numerical quadrature routine is
the estimation of the integration error. Since the publication of the first
algorithms in the 1960s, many error estimation schemes have been presented,
evaluated and discussed. This paper presents a review of existing error
estimation techniques and discusses their differences and their common
features. Some common shortcomings of these algorithms are discussed and a new
general error estimation technique is presented.
</summary>
    <author>
      <name>Pedro Gonnet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM Computing Surveys</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.4629v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4629v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.0; G.1.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5196v1</id>
    <updated>2010-03-26T18:17:01Z</updated>
    <published>2010-03-26T18:17:01Z</published>
    <title>SWiM -- A Semantic Wiki for Mathematical Knowledge Management</title>
    <summary>  SWiM is a semantic wiki for collaboratively building, editing and browsing
mathematical knowledge represented in the domain-specific structural semantic
markup language OMDoc. It motivates users to contribute to collections of
mathematical knowledge by instantly sharing the benefits of knowledge-powered
services with them. SWiM is currently being used for authoring content
dictionaries, i. e. collections of uniquely identified mathematical symbols,
and prepared for managing a large-scale proof formalisation effort.
</summary>
    <author>
      <name>Christoph Lange</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-540-68234-9_68</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-540-68234-9_68" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">S. Bechhofer, M. Hauswirth, J. Hoffmann, M. Koubarakis. The
  Semantic Web: Research and Applications. ESWC 2008. LNCS 5021, Springer 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.5196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T35; 68T30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.m; H.3.5; H.5.3; H.5.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.6036v3</id>
    <updated>2011-10-11T13:36:18Z</updated>
    <published>2010-03-31T12:26:10Z</published>
    <title>Computational Complexity of Iterated Maps on the Interval</title>
    <summary>  The correct computation of orbits of discrete dynamical systems on the
interval is considered. Therefore, an arbitrary-precision floating-point
approach based on automatic error analysis is chosen and a general algorithm is
presented. The correctness of the algorithm is shown and the computational
complexity is analyzed. There are two main results. First, the computational
complexity measure considered here is related to the Lyapunov exponent of the
dynamical system under consideration. Second, the presented algorithm is
optimal with regard to that complexity measure.
</summary>
    <author>
      <name>Christoph Spandl</name>
    </author>
    <link href="http://arxiv.org/abs/1003.6036v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.6036v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3719v1</id>
    <updated>2010-04-21T14:52:36Z</updated>
    <published>2010-04-21T14:52:36Z</published>
    <title>Exact Sparse Matrix-Vector Multiplication on GPU's and Multicore
  Architectures</title>
    <summary>  We propose different implementations of the sparse matrix--dense vector
multiplication (\spmv{}) for finite fields and rings $\Zb/m\Zb$. We take
advantage of graphic card processors (GPU) and multi-core architectures. Our
aim is to improve the speed of \spmv{} in the \linbox library, and henceforth
the speed of its black box algorithms. Besides, we use this and a new
parallelization of the sigma-basis algorithm in a parallel block Wiedemann rank
implementation over finite fields.
</summary>
    <author>
      <name>Brice Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Guillaume Dumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Pascal Giorgi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1837210.1837224</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1837210.1837224" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Symposium on Parallel Symbolic Computation, Grenoble
  : France (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2183v1</id>
    <updated>2010-06-11T02:10:58Z</updated>
    <published>2010-06-11T02:10:58Z</published>
    <title>Highly Parallel Sparse Matrix-Matrix Multiplication</title>
    <summary>  Generalized sparse matrix-matrix multiplication is a key primitive for many
high performance graph algorithms as well as some linear solvers such as
multigrid. We present the first parallel algorithms that achieve increasing
speedups for an unbounded number of processors. Our algorithms are based on
two-dimensional block distribution of sparse matrices where serial sections use
a novel hypersparse kernel for scalability. We give a state-of-the-art MPI
implementation of one of our algorithms. Our experiments show scaling up to
thousands of processors on a variety of test scenarios.
</summary>
    <author>
      <name>Aydın Buluç</name>
    </author>
    <author>
      <name>John R. Gilbert</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1317v1</id>
    <updated>2010-07-28T12:20:06Z</updated>
    <published>2010-07-28T12:20:06Z</published>
    <title>LinBox founding scope allocation, parallel building blocks, and separate
  compilation</title>
    <summary>  To maximize efficiency in time and space, allocations and deallocations, in
the exact linear algebra library \linbox, must always occur in the founding
scope. This provides a simple lightweight allocation model. We present this
model and its usage for the rebinding of matrices between different coefficient
domains. We also present automatic tools to speed-up the compilation of
template libraries and a software abstraction layer for the introduction of
transparent parallelism at the algorithmic level.
</summary>
    <author>
      <name>Jean-Guillaume Dumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Gautier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Clément Pernet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>B. David Saunders</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CIS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Third International Congress on Mathematical Software, Kobe :
  Japan (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.1317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.4647v2</id>
    <updated>2010-10-28T18:21:33Z</updated>
    <published>2010-09-23T15:54:20Z</published>
    <title>Parameterized Adaptive Multidimensional Integration Routines (PAMIR):
  Localization by Repeated 2^p Subdivision</title>
    <summary>  This book draft gives the theory of a new method for p dimensional adaptive
integration by repeated 2^p subdivision of simplexes and hypercubes. A new
method of constructing high order integration routines for these geometries
permits adjustable samplings of the integration region controlled by user
supplied parameters. An outline of the programs and use instructions are also
included in the draft. The fortran programs are not included, but will be
published with this draft as a book.
</summary>
    <author>
      <name>Stephen L. Adler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">84 pages Latex, figures included; minor changes to program
  descriptions and tildes added to Eqs. (63) and (65)</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.4647v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.4647v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.1091v2</id>
    <updated>2011-09-20T20:19:43Z</updated>
    <published>2010-11-04T09:57:00Z</published>
    <title>alphaCertified: certifying solutions to polynomial systems</title>
    <summary>  Smale's alpha-theory uses estimates related to the convergence of Newton's
method to give criteria implying that Newton iterations will converge
quadratically to solutions to a square polynomial system. The program
alphaCertified implements algorithms based on alpha-theory to certify solutions
to polynomial systems using both exact rational arithmetic and arbitrary
precision floating point arithmetic. It also implements an algorithm to certify
whether a given point corresponds to a real solution to a real polynomial
system, as well as algorithms to heuristically validate solutions to
overdetermined systems. Examples are presented to demonstrate the algorithms.
</summary>
    <author>
      <name>Jonathan D. Hauenstein</name>
    </author>
    <author>
      <name>Frank Sottile</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.1091v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.1091v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65G20, 65H05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.3534v1</id>
    <updated>2010-11-15T21:59:11Z</updated>
    <published>2010-11-15T21:59:11Z</published>
    <title>Fast Multiplication of Matrices with Decay</title>
    <summary>  A fast algorithm for the approximate multiplication of matrices with decay is
introduced; the Sparse Approximate Matrix Multiply (SpAMM) reduces complexity
in the product space, a different approach from current methods that economize
within the matrix space through truncation or rank reduction. Matrix truncation
(element dropping) is compared to SpAMM for quantum chemical matrices with
approximate exponential and algebraic decay. For matched errors in the
electronic total energy, SpAMM is found to require fewer to far fewer floating
point operations relative to dropping. The challenges and opportunities
afforded by this new approach are discussed, including the potential for high
performance implementations.
</summary>
    <author>
      <name>Matt Challacombe</name>
    </author>
    <author>
      <name>Nicolas Bock</name>
    </author>
    <link href="http://arxiv.org/abs/1011.3534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.3534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4598v2</id>
    <updated>2011-10-19T16:46:34Z</updated>
    <published>2011-02-22T19:57:11Z</published>
    <title>Generating and using truly random quantum states in Mathematica</title>
    <summary>  The problem of generating random quantum states is of a great interest from
the quantum information theory point of view. In this paper we present a
package for Mathematica computing system harnessing a specific piece of
hardware, namely Quantis quantum random number generator (QRNG), for
investigating statistical properties of quantum states. The described package
implements a number of functions for generating random states, which use
Quantis QRNG as a source of randomness. It also provides procedures which can
be used in simulations not related directly to quantum information processing.
</summary>
    <author>
      <name>J. A. Miszczak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2011.08.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2011.08.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, see http://www.iitis.pl/~miszczak/trqs.html for
  related software</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Commun., Vol. 183, No. 1 (2012), pp. 118-124</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.4598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0689v1</id>
    <updated>2011-04-04T20:52:03Z</updated>
    <published>2011-04-04T20:52:03Z</published>
    <title>Algorithms for Computing Triangular Decompositions of Polynomial Systems</title>
    <summary>  We propose new algorithms for computing triangular decompositions of
polynomial systems incrementally. With respect to previous works, our
improvements are based on a {\em weakened} notion of a polynomial GCD modulo a
regular chain, which permits to greatly simplify and optimize the
sub-algorithms. Extracting common work from similar expensive computations is
also a key feature of our algorithms. In our experimental results the
implementation of our new algorithms, realized with the {\RegularChains}
library in {\Maple}, outperforms solvers with similar specifications by several
orders of magnitude on sufficiently difficult problems.
</summary>
    <author>
      <name>Changbo Chen</name>
    </author>
    <author>
      <name>Marc Moreno Maza</name>
    </author>
    <link href="http://arxiv.org/abs/1104.0689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2263v1</id>
    <updated>2011-06-11T22:32:32Z</updated>
    <published>2011-06-11T22:32:32Z</published>
    <title>A Library for Implementing the Multiple Hypothesis Tracking Algorithm</title>
    <summary>  The Multiple Hypothesis Tracking (MHT) algorithm is known to produce good
results in difficult multi-target tracking situations. However, its
implementation is not trivial, and is associated with a significant programming
effort, code size and long implementation time. We propose a library which
addresses these problems by providing a domain independent implementation of
the most complex MHT operations. We also address the problem of applying
clustering in domain independent manner.
</summary>
    <author>
      <name>David Miguel Antunes</name>
    </author>
    <author>
      <name>David Martins de Matos</name>
    </author>
    <author>
      <name>José Gaspar</name>
    </author>
    <link href="http://arxiv.org/abs/1106.2263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.0385v1</id>
    <updated>2011-07-02T15:07:48Z</updated>
    <published>2011-07-02T15:07:48Z</published>
    <title>An algorithm for autonomously plotting solution sets in the presence of
  turning points</title>
    <summary>  Plotting solution sets for particular equations may be complicated by the
existence of turning points. Here we describe an algorithm which not only
overcomes such problematic points, but does so in the most general of settings.
Applications of the algorithm are highlighted through two examples: the first
provides verification, while the second demonstrates a non-trivial application.
The latter is followed by a thorough run-time analysis. While both examples
deal with bivariate equations, it is discussed how the algorithm may be
generalized for space curves in $\R^{3}$.
</summary>
    <author>
      <name>Steven Pollack</name>
    </author>
    <author>
      <name>Daniel Badali</name>
    </author>
    <author>
      <name>Jonathan Pollack</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.0385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.0385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5815v2</id>
    <updated>2011-12-10T06:15:37Z</updated>
    <published>2011-08-30T03:27:14Z</published>
    <title>Hierarchical N-body simulations with auto-tuning for heterogeneous
  systems</title>
    <summary>  With the current hybridization of treecodes and FMMs, combined with
auto-tuning capabilities on heterogeneous architectures, the flexibility of
fast N-body methods has been greatly enhanced. These features are a requirement
to developing a black-box software library for fast N-body algorithms on
heterogeneous systems, which is our immediate goal.
</summary>
    <author>
      <name>Rio Yokota</name>
    </author>
    <author>
      <name>Lorena A. Barba</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MCSE.2012.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MCSE.2012.1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computing in Science and Engineering, May/June 2012 (vol. 14 no.
  3), pp. 30-39</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.5815v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5815v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="70F10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.2; D.1.3; G.1.0; G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3233v1</id>
    <updated>2011-10-14T15:04:14Z</updated>
    <published>2011-10-14T15:04:14Z</published>
    <title>Metaprogramming Applied to Numerical Problems</title>
    <summary>  From the discovery that the template system of C++ forms a Turing complete
language in 1994, a programming technique called Template Metaprogramming has
emerged that allows for the creation of faster, more generic and better code.
Here, we apply Template Metaprogramming to implement a generic Runge-Kutta
scheme that can be used to numerically solve ordinary differential equations.
We show that using Template Metaprogramming results in a significantly improved
performance compared to a classical implementation.
</summary>
    <author>
      <name>Mario Mulansky</name>
    </author>
    <author>
      <name>Karsten Ahnert</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3637933</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3637933" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages,2 figures,3 listings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AIP Conf. Proc. 1389, pp. 1582-1585 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.3233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3606v3</id>
    <updated>2015-02-12T13:12:12Z</updated>
    <published>2011-11-15T18:32:29Z</published>
    <title>tym: Typed Matlab</title>
    <summary>  Although, many scientists and engineers use Octave or MATLAB as their
preferred programming language, dynamic nature of these languages can lead to
slower running-time of programs written in these languages compared to programs
written in languages which are not as dynamic, like C, C++ and Fortran. In this
work we developed a translator for a new programming language (tym) which tries
to address performance issues, common in scientific programs, by adding new
constructs to a subset of Octave/MATLAB language. Our translator compiles
programs written in tym, to efficient C++ code.
</summary>
    <author>
      <name>Hamid A. Toussi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at University of Sistan and Baluchestan, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3606v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3606v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1820v2</id>
    <updated>2012-02-14T20:04:49Z</updated>
    <published>2012-02-08T20:58:11Z</published>
    <title>Fatgraph Algorithms and the Homology of the Kontsevich Complex</title>
    <summary>  Fatgraphs are multigraphs enriched with a cyclic order of the edges incident
to a vertex. This paper presents algorithms to: (1) generate the set of all
fatgraphs having a given genus and number of boundary cycles; (2) compute
automorphisms of any given fatgraph; (3) compute the homology of the fatgraph
complex. The algorithms are suitable for effective computer implementation.
  In particular, this allows us to compute the rational homology of the moduli
space of Riemann surfaces with marked points. We thus compute the Betti numbers
of $M_{g,n}$ with $(2g + n) \leq 6$, corroborating known results.
</summary>
    <author>
      <name>Riccardo Murri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">61 pages, 12 figures. Corrected attributions, claims, and
  bibliography</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.1820v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1820v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="32G15, 05C30, 05C85" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2736v1</id>
    <updated>2012-02-13T14:14:00Z</updated>
    <published>2012-02-13T14:14:00Z</published>
    <title>Function call overhead benchmarks with MATLAB, Octave, Python, Cython
  and C</title>
    <summary>  We consider the overhead of function calls in the programming languages
MATLAB/Octave, Python, Cython and C. In many applications a function has to be
called very often inside a loop. One such application in numerical analysis is
the finite element method where integrals have to be computed on each element
in a loop. The called functions can often be evaluated efficiently but the
function call itself may be time-consuming. We present a benchmark whose goal
is to identify and quantify optimization potentials with respect to time
consumption caused by function calls in the mentioned programming languages.
</summary>
    <author>
      <name>André Gaul</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The benchmark's source code is available under GPL3 at
  https://bitbucket.org/andrenarchy/funcall</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.2736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3215v2</id>
    <updated>2012-08-12T18:20:23Z</updated>
    <published>2012-06-14T19:07:42Z</published>
    <title>Performance of FORTRAN and C GPU Extensions for a Benchmark Suite of
  Fourier Pseudospectral Algorithms</title>
    <summary>  A comparison of PGI OpenACC, FORTRAN CUDA, and Nvidia CUDA pseudospectral
methods on a single GPU and GCC FORTRAN on single and multiple CPU cores is
reported. The GPU implementations use CuFFT and the CPU implementations use
FFTW. Porting pre-existing FORTRAN codes to utilize a GPUs is efficient and
easy to implement with OpenACC and CUDA FORTRAN. Example programs are provided.
</summary>
    <author>
      <name>B. Cloutier</name>
    </author>
    <author>
      <name>B. K. Muite</name>
    </author>
    <author>
      <name>P. Rigge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version. New title. Forthcoming in proceedings of the
  Symposium on Application Accelerators in High-Performance computing (SAAHPC
  2012). Related programs are available for download</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3215v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3215v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1711v2</id>
    <updated>2018-01-09T15:22:10Z</updated>
    <published>2012-09-08T12:31:50Z</published>
    <title>Programming Languages for Scientific Computing</title>
    <summary>  Scientific computation is a discipline that combines numerical analysis,
physical understanding, algorithm development, and structured programming.
Several yottacycles per year on the world's largest computers are spent
simulating problems as diverse as weather prediction, the properties of
material composites, the behavior of biomolecules in solution, and the quantum
nature of chemical compounds. This article is intended to review specfic
languages features and their use in computational science. We will review the
strengths and weaknesses of different programming styles, with examples taken
from widely used scientific codes.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-540-70529-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-540-70529-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Encyclopedia of Applied and Computational Mathematics, Springer,
  2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1711v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1711v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2075v1</id>
    <updated>2012-11-09T08:55:53Z</updated>
    <published>2012-11-09T08:55:53Z</published>
    <title>A multi-scale code for flexible hybrid simulations</title>
    <summary>  Multi-scale computer simulations combine the computationally efficient
classical algorithms with more expensive but also more accurate ab-initio
quantum mechanical algorithms. This work describes one implementation of
multi-scale computations using the Atomistic Simulation Environment (ASE). This
implementation can mix classical codes like LAMMPS and the Density Functional
Theory-based GPAW. Any combination of codes linked via the ASE interface
however can be mixed. We also introduce a framework to easily add classical
force fields calculators for ASE using LAMMPS, which also allows harnessing the
full performance of classical-only molecular dynamics. Our work makes it
possible to combine different simulation codes, quantum mechanical or
classical, with great ease and minimal coding effort.
</summary>
    <author>
      <name>L. Leukkunen</name>
    </author>
    <author>
      <name>T. Verho</name>
    </author>
    <author>
      <name>O. Lopez-Acevedo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MCSE.2013.51</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MCSE.2013.51" rel="related"/>
    <link href="http://arxiv.org/abs/1211.2075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2350v1</id>
    <updated>2012-12-11T09:24:46Z</updated>
    <published>2012-12-11T09:24:46Z</published>
    <title>Automated verification of termination certificates</title>
    <summary>  In order to increase user confidence, many automated theorem provers provide
certificates that can be independently verified. In this paper, we report on
our progress in developing a standalone tool for checking the correctness of
certificates for the termination of term rewrite systems, and formally proving
its correctness in the proof assistant Coq. To this end, we use the extraction
mechanism of Coq and the library on rewriting theory and termination called
CoLoR.
</summary>
    <author>
      <name>Frédéric Blanqui</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIAMA, LCS</arxiv:affiliation>
    </author>
    <author>
      <name>Kim Quyen Ly</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIAMA, LCS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">15th National Symposium of Selected ICT Problems (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.2350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0763v1</id>
    <updated>2013-01-04T16:25:56Z</updated>
    <published>2013-01-04T16:25:56Z</published>
    <title>Improved QFT algorithm for power-of-two FFT</title>
    <summary>  This paper shows that it is possible to improve the computational cost, the
memory requirements and the accuracy of Quick Fourier Transform (QFT) algorithm
for power-of-two FFT (Fast Fourier Transform) just introducing a slight
modification in this algorithm. The new algorithm requires the same number of
additions and multiplications of split-radix 3add/3mul, one of the most
appreciated FFT algorithms appeared in the literature, but employing only half
of the trigonometric constants. These results can elevate the QFT approach to
the level of most used FFT procedures. A new quite general way to describe FFT
algorithms, based on signal types and on a particular notation, is also
proposed and used, highligting its advantages.
</summary>
    <author>
      <name>Lorenzo Pasquini</name>
    </author>
    <link href="http://arxiv.org/abs/1301.0763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1, G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1737v1</id>
    <updated>2013-02-07T13:15:45Z</updated>
    <published>2013-02-07T13:15:45Z</published>
    <title>Kleene Algebra with Tests and Coq Tools for While Programs</title>
    <summary>  We present a Coq library about Kleene algebra with tests, including a proof
of their completeness over the appropriate notion of languages, a decision
procedure for their equational theory, and tools for exploiting hypotheses of a
particular shape in such a theory. Kleene algebra with tests make it possible
to represent if-then-else statements and while loops in most imperative
programming languages. They were actually introduced by Kozen as an alternative
to propositional Hoare logic. We show how to exploit the corresponding Coq
tools in the context of program verification by proving equivalences of while
programs, correctness of some standard compiler optimisations, Hoare rules for
partial correctness, and a particularly challenging equivalence of flowchart
schemes.
</summary>
    <author>
      <name>Damien Pous</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16+3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.1737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2738v2</id>
    <updated>2015-03-15T10:03:45Z</updated>
    <published>2013-02-12T09:38:46Z</published>
    <title>RandFile package for Mathematica for accessing file-based sources of
  randomness</title>
    <summary>  We present a package for Mathematica computer algebra system which allows the
exploitation of local files as sources of random data. We provide the
description of the package and illustrate its usage by showing some examples.
We also compare the provided functionality with alternative sources of
randomness, namely a built-in pseudo-random generator and the package for
accessing hardware true random number generators.
</summary>
    <author>
      <name>J. A. Miszczak</name>
    </author>
    <author>
      <name>M. Wahl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures, 3 tables, improved version of the software
  available from http://www.iitis.pl/~miszczak/rand_file/</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.2738v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2738v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.7425v1</id>
    <updated>2013-03-29T15:47:45Z</updated>
    <published>2013-03-29T15:47:45Z</published>
    <title>Highly Scalable Multiplication for Distributed Sparse Multivariate
  Polynomials on Many-core Systems</title>
    <summary>  We present a highly scalable algorithm for multiplying sparse multivariate
polynomials represented in a distributed format. This algo- rithm targets not
only the shared memory multicore computers, but also computers clusters or
specialized hardware attached to a host computer, such as graphics processing
units or many-core coprocessors. The scal- ability on the large number of cores
is ensured by the lacks of synchro- nizations, locks and false-sharing during
the main parallel step.
</summary>
    <author>
      <name>Mickael Gastineau</name>
    </author>
    <author>
      <name>Jacques Laskar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.7425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.7425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0864v1</id>
    <updated>2013-04-03T08:01:42Z</updated>
    <published>2013-04-03T08:01:42Z</published>
    <title>Efficient Generation of Correctness Certificates for the Abstract Domain
  of Polyhedra</title>
    <summary>  Polyhedra form an established abstract domain for inferring runtime
properties of programs using abstract interpretation. Computations on them need
to be certified for the whole static analysis results to be trusted. In this
work, we look at how far we can get down the road of a posteriori verification
to lower the overhead of certification of the abstract domain of polyhedra. We
demonstrate methods for making the cost of inclusion certificate generation
negligible. From a performance point of view, our single-representation,
constraints-based implementation compares with state-of-the-art
implementations.
</summary>
    <author>
      <name>Alexis Fouilhé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VERIMAG - IMAG</arxiv:affiliation>
    </author>
    <author>
      <name>David Monniaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VERIMAG - IMAG</arxiv:affiliation>
    </author>
    <author>
      <name>Michaël Périn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VERIMAG - IMAG</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1304.0864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7123v1</id>
    <updated>2013-04-26T10:59:21Z</updated>
    <published>2013-04-26T10:59:21Z</published>
    <title>Proceedings International Workshop on the ACL2 Theorem Prover and its
  Applications</title>
    <summary>  This volume contains the proceedings of the Eleventh International Workshop
on the ACL2 Theorem Prover and its Applications, held on May 30 and 31, 2013,
in Laramie, Wyoming, USA.
  ACL2 is an industrial-strength automated reasoning system, the latest in the
Boyer-Moore family of theorem provers. The ACL2 workshop is the major technical
forum for users of the ACL2 theorem proving system to present research on the
prover and its applications.
  This year's workshop received 15 submissions covering a wide range of
applications, libraries, prover enhancements, interfaces, and experience
reports. 11 papers were selected by the program committee for presentation at
the workshop.
</summary>
    <author>
      <name>Ruben Gamboa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Wyoming, USA</arxiv:affiliation>
    </author>
    <author>
      <name>Jared Davis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Centaur Technology, USA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.114</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.114" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 114, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3122v1</id>
    <updated>2013-05-14T11:52:17Z</updated>
    <published>2013-05-14T11:52:17Z</published>
    <title>An efficient way to perform the assembly of finite element matrices in
  Matlab and Octave</title>
    <summary>  We describe different optimization techniques to perform the assembly of
finite element matrices in Matlab and Octave, from the standard approach to
recent vectorized ones, without any low level language used. We finally obtain
a simple and efficient vectorized algorithm able to compete in performance with
dedicated software such as FreeFEM++. The principle of this assembly algorithm
is general, we present it for different matrices in the P1 finite elements case
and in linear elasticity. We present numerical results which illustrate the
computational costs of the different approaches
</summary>
    <author>
      <name>François Cuvelier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAGA</arxiv:affiliation>
    </author>
    <author>
      <name>Caroline Japhet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAGA, Inria Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Scarella</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAGA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Inria: No: RR-8305 (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3625v1</id>
    <updated>2013-05-15T20:16:42Z</updated>
    <published>2013-05-15T20:16:42Z</published>
    <title>Making the case of GPUs in courses on computational physics</title>
    <summary>  Most relatively modern desktop or even laptop computers contain a graphics
card useful for more than showing colors on a screen. In this paper, we make a
case for why you should learn enough about GPU (graphics processing unit)
computing to use as an accelerator or even replacement to your CPU code. We
include an example of our own as a case study to show what can be realistically
expected.
</summary>
    <author>
      <name>Knut Skogstrand Gjerden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="82-01, 82-08, 65Z05, 97Q99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.5866v1</id>
    <updated>2013-07-22T20:15:34Z</updated>
    <published>2013-07-22T20:15:34Z</published>
    <title>RNGSSELIB: Program library for random number generation. More
  generators, parallel streams of random numbers and Fortran compatibility</title>
    <summary>  In this update, we present the new version of the random number generator
(RNG) library RNGSSELIB, which, in particular, contains fast SSE realizations
of a number of modern and most reliable generators \cite{RNGSSELIB1}. The new
features are: i) Fortran compatibility and examples of using the library in
Fortran; ii) new modern and reliable generators; iii) the abilities to jump
ahead inside RNG sequence and to initialize up to $10^{19}$ independent random
number streams with block splitting method.
</summary>
    <author>
      <name>L. Yu. Barash</name>
    </author>
    <author>
      <name>L. N. Shchur</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2013.04.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2013.04.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 184 (2013) pp. 2367-2369</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.5866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.5866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.5869v2</id>
    <updated>2014-02-17T16:01:53Z</updated>
    <published>2013-07-22T20:21:20Z</published>
    <title>PRAND: GPU accelerated parallel random number generation library: Using
  most reliable algorithms and applying parallelism of modern GPUs and CPUs</title>
    <summary>  The library PRAND for pseudorandom number generation for modern CPUs and GPUs
is presented. It contains both single-threaded and multi-threaded realizations
of a number of modern and most reliable generators recently proposed and
studied in [1,2,3,4,5] and the efficient SIMD realizations proposed in [6]. One
of the useful features for using PRAND in parallel simulations is the ability
to initialize up to $10^{19}$ independent streams. Using massive parallelism of
modern GPUs and SIMD parallelism of modern CPUs substantially improves
performance of the generators.
</summary>
    <author>
      <name>L. Yu. Barash</name>
    </author>
    <author>
      <name>L. N. Shchur</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2014.01.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2014.01.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 1 figure, 7 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 185 (2014) 1343-1353</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.5869v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.5869v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3493v1</id>
    <updated>2013-08-15T20:00:02Z</updated>
    <published>2013-08-15T20:00:02Z</published>
    <title>xTras: a field-theory inspired xAct package for Mathematica</title>
    <summary>  We present the tensor computer algebra package xTras, which provides
functions and methods frequently needed when doing (classical) field theory.
Amongst others, it can compute contractions, make Ans\"atze, and solve
tensorial equations. It is built upon the tensor computer algebra system xAct,
a collection of packages for Mathematica.
</summary>
    <author>
      <name>Teake Nutma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2014.02.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2014.02.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages. The package can be downloaded from
  http://www.xact.es/xtras/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput. Phys. Commun. 185 (2014) 1719-1738</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.3493v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3493v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4214v1</id>
    <updated>2013-08-20T02:50:43Z</updated>
    <published>2013-08-20T02:50:43Z</published>
    <title>Pylearn2: a machine learning research library</title>
    <summary>  Pylearn2 is a machine learning research library. This does not just mean that
it is a collection of machine learning algorithms that share a common API; it
means that it has been designed for flexibility and extensibility in order to
facilitate research projects that involve new or unusual use cases. In this
paper we give a brief history of the library, an overview of its basic
philosophy, a summary of the library's architecture, and a description of how
the Pylearn2 community functions socially.
</summary>
    <author>
      <name>Ian J. Goodfellow</name>
    </author>
    <author>
      <name>David Warde-Farley</name>
    </author>
    <author>
      <name>Pascal Lamblin</name>
    </author>
    <author>
      <name>Vincent Dumoulin</name>
    </author>
    <author>
      <name>Mehdi Mirza</name>
    </author>
    <author>
      <name>Razvan Pascanu</name>
    </author>
    <author>
      <name>James Bergstra</name>
    </author>
    <author>
      <name>Frédéric Bastien</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.4214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.6523v1</id>
    <updated>2013-08-29T17:06:18Z</updated>
    <published>2013-08-29T17:06:18Z</published>
    <title>Branch Cuts in Maple 17</title>
    <summary>  Accurate and comprehensible knowledge about the position of branch cuts is
essential for correctly working with multi-valued functions, such as the square
root and logarithm. We discuss the new tools in Maple 17 for calculating and
visualising the branch cuts of such functions, and others built up from them.
The cuts are described in an intuitive and accurate form, offering substantial
improvement on the descriptions previously available.
</summary>
    <author>
      <name>M. England</name>
    </author>
    <author>
      <name>E. Cheb-Terrab</name>
    </author>
    <author>
      <name>R. Bradford</name>
    </author>
    <author>
      <name>J. H. Davenport</name>
    </author>
    <author>
      <name>D. Wilson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2644288.2644293</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2644288.2644293" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Communications in Computer Algebra 48:1 pp. 24-27, ACM, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.6523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.6523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.1, G.4" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.1; I.1.2; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1781v1</id>
    <updated>2013-09-06T21:48:39Z</updated>
    <published>2013-09-06T21:48:39Z</published>
    <title>Experiences from Software Engineering of Large Scale AMR Multiphysics
  Code Frameworks</title>
    <summary>  Among the present generation of multiphysics HPC simulation codes there are
many that are built upon general infrastructural frameworks. This is especially
true of the codes that make use of structured adaptive mesh refinement (SAMR)
because of unique demands placed on the housekeeping aspects of the code. They
have varying degrees of abstractions between the infrastructure such as mesh
management and IO and the numerics of the physics solvers. In this experience
report we summarize the experiences and lessons learned from two of such major
software efforts, FLASH and Chombo.
</summary>
    <author>
      <name>A. Dubey</name>
    </author>
    <author>
      <name>B. Van Straalen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.am</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.am" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Experience Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1812v2</id>
    <updated>2013-09-16T01:33:06Z</updated>
    <published>2013-09-07T03:18:51Z</published>
    <title>Cactus: Issues for Sustainable Simulation Software</title>
    <summary>  The Cactus Framework is an open-source, modular, portable programming
environment for the collaborative development and deployment of scientific
applications using high-performance computing. Its roots reach back to 1996 at
the National Center for Supercomputer Applications and the Albert Einstein
Institute in Germany, where its development jumpstarted. Since then, the Cactus
framework has witnessed major changes in hardware infrastructure as well as its
own community. This paper describes its endurance through these past changes
and, drawing upon lessons from its past, also discusses future
</summary>
    <author>
      <name>Frank Löffler</name>
    </author>
    <author>
      <name>Steven R. Brandt</name>
    </author>
    <author>
      <name>Gabrielle Allen</name>
    </author>
    <author>
      <name>Erik Schnetter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to the Workshop on Sustainable Software for Science:
  Practice and Experiences 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1812v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1812v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3297v1</id>
    <updated>2013-10-11T21:17:59Z</updated>
    <published>2013-10-11T21:17:59Z</published>
    <title>Bertini for Macaulay2</title>
    <summary>  Numerical algebraic geometry is the field of computational mathematics
concerning the numerical solution of polynomial systems of equations. Bertini,
a popular software package for computational applications of this field,
includes implementations of a variety of algorithms based on polynomial
homotopy continuation. The Macaulay2 package Bertini.m2 provides an interface
to Bertini, making it possible to access the core run modes of Bertini in
Macaulay2. With these run modes, users can find approximate solutions to
zero-dimensional systems and positive-dimensional systems, test numerically
whether a point lies on a variety, sample numerically from a variety, and
perform parameter homotopy runs.
</summary>
    <author>
      <name>Daniel J. Bates</name>
    </author>
    <author>
      <name>Elizabeth Gross</name>
    </author>
    <author>
      <name>Anton Leykin</name>
    </author>
    <author>
      <name>Jose Israel Rodriguez</name>
    </author>
    <link href="http://arxiv.org/abs/1310.3297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65H10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.1753v1</id>
    <updated>2013-11-07T17:18:42Z</updated>
    <published>2013-11-07T17:18:42Z</published>
    <title>GooFit: A library for massively parallelising maximum-likelihood fits</title>
    <summary>  Fitting complicated models to large datasets is a bottleneck of many
analyses. We present GooFit, a library and tool for constructing
arbitrarily-complex probability density functions (PDFs) to be evaluated on
nVidia GPUs or on multicore CPUs using OpenMP. The massive parallelisation of
dividing up event calculations between hundreds of processors can achieve
speedups of factors 200-300 in real-world problems.
</summary>
    <author>
      <name>R. Andreassen</name>
    </author>
    <author>
      <name>B. T. Meadows</name>
    </author>
    <author>
      <name>M. de Silva</name>
    </author>
    <author>
      <name>M. D. Sokoloff</name>
    </author>
    <author>
      <name>K. Tomko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-6596/513/5/052003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-6596/513/5/052003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the CHEP 2013 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.1753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.1753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.2719v1</id>
    <updated>2013-11-12T09:12:54Z</updated>
    <published>2013-11-12T09:12:54Z</published>
    <title>Lattice Simulations using OpenACC compilers</title>
    <summary>  OpenACC compilers allow one to use Graphics Processing Units without having
to write explicit CUDA codes. Programs can be modified incrementally using
OpenMP like directives which causes the compiler to generate CUDA kernels to be
run on the GPUs. In this article we look at the performance gain in lattice
simulations with dynamical fermions using OpenACC compilers.
</summary>
    <author>
      <name>Pushan Majumdar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure, presented at the 31st International Symposium on
  Lattice Field Theory (Lattice 2013), 29 July - 3 August 2013, Mainz, Germany</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.2719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.2719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2266v4</id>
    <updated>2013-12-31T12:47:20Z</updated>
    <published>2013-12-08T21:31:14Z</published>
    <title>The deal.II Library, Version 8.1</title>
    <summary>  This paper provides an overview of the new features of the finite element
library deal.II version 8.1.
</summary>
    <author>
      <name>Wolfgang Bangerth</name>
    </author>
    <author>
      <name>Timo Heister</name>
    </author>
    <author>
      <name>Luca Heltai</name>
    </author>
    <author>
      <name>Guido Kanschat</name>
    </author>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <author>
      <name>Matthias Maier</name>
    </author>
    <author>
      <name>Bruno Turcksin</name>
    </author>
    <author>
      <name>Toby D. Young</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v4: for deal.II version 8.1 v3: minor fixes. v2: correct the citation
  inside the article</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.2266v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2266v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3270v2</id>
    <updated>2013-12-16T00:02:00Z</updated>
    <published>2013-12-11T18:25:46Z</published>
    <title>Misfortunes of a mathematicians' trio using Computer Algebra Systems:
  Can we trust?</title>
    <summary>  Computer algebra systems are a great help for mathematical research but
sometimes unexpected errors in the software can also badly affect it. As an
example, we show how we have detected an error of Mathematica computing
determinants of matrices of integer numbers: not only it computes the
determinants wrongly, but also it produces different results if one evaluates
the same determinant twice.
</summary>
    <author>
      <name>Antonio J. Durán</name>
    </author>
    <author>
      <name>Mario Pérez</name>
    </author>
    <author>
      <name>Juan L. Varona</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1090/noti1173</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1090/noti1173" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Notices Amer. Math. Soc. 61 (2014), 1249-1252</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.3270v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3270v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6694v2</id>
    <updated>2014-05-02T05:01:05Z</updated>
    <published>2014-01-26T21:37:51Z</published>
    <title>Multivariate sparse interpolation using randomized Kronecker
  substitutions</title>
    <summary>  We present new techniques for reducing a multivariate sparse polynomial to a
univariate polynomial. The reduction works similarly to the classical and
widely-used Kronecker substitution, except that we choose the degrees randomly
based on the number of nonzero terms in the multivariate polynomial, that is,
its sparsity. The resulting univariate polynomial often has a significantly
lower degree than the Kronecker substitution polynomial, at the expense of a
small number of term collisions. As an application, we give a new algorithm for
multivariate interpolation which uses these new techniques along with any
existing univariate interpolation algorithm.
</summary>
    <author>
      <name>Andrew Arnold</name>
    </author>
    <author>
      <name>Daniel S. Roche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 2 tables, 1 procedure. Accepted to ISSAC 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.6694v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6694v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.4; I.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6635v1</id>
    <updated>2014-02-22T15:47:58Z</updated>
    <published>2014-02-22T15:47:58Z</published>
    <title>Tensor computations in computer algebra systems</title>
    <summary>  This paper considers three types of tensor computations. On their basis, we
attempt to formulate criteria that must be satisfied by a computer algebra
system dealing with tensors. We briefly overview the current state of tensor
computations in different computer algebra systems. The tensor computations are
illustrated with appropriate examples implemented in specific systems: Cadabra
and Maxima.
</summary>
    <author>
      <name>A. V. Korolkova</name>
    </author>
    <author>
      <name>D. S. Kulyabov</name>
    </author>
    <author>
      <name>L. A. Sevastyanov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S0361768813030031</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S0361768813030031" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Russian; in English</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A. V. Korol'kova, D. S. Kulyabov, and L. A. Sevast'yanov. Tensor
  computations in computer algebra systems. Programming and Computer Software,
  39(3):135--142, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.6635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0700v1</id>
    <updated>2014-05-04T14:12:53Z</updated>
    <published>2014-05-04T14:12:53Z</published>
    <title>PLQCD library for Lattice QCD on multi-core machines</title>
    <summary>  PLQCD is a stand-alone software library developed under PRACE for lattice
QCD. It provides an implementation of the Dirac operator for Wilson type
fermions and few efficient linear solvers. The library is optimized for
multi-core machines using a hybrid parallelization with OpenMP+MPI. The main
objectives of the library is to provide a scalable implementation of the Dirac
operator for efficient computation of the quark propagator. In this
contribution, a description of the PLQCD library is given together with some
benchmark results.
</summary>
    <author>
      <name>A. Abdel-Rehim</name>
    </author>
    <author>
      <name>C. Alexandrou</name>
    </author>
    <author>
      <name>N. Anastopoulos</name>
    </author>
    <author>
      <name>G. Koutsou</name>
    </author>
    <author>
      <name>I. Liabotis</name>
    </author>
    <author>
      <name>N. Papadopoulou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, presented at the 31st International Symposium on Lattice
  Field Theory (Lattice 2013), 29 July - 3 August 2013, Mainz, Germany</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3758v1</id>
    <updated>2014-05-15T06:55:21Z</updated>
    <published>2014-05-15T06:55:21Z</published>
    <title>Search Interfaces for Mathematicians</title>
    <summary>  Access to mathematical knowledge has changed dramatically in recent years,
therefore changing mathematical search practices. Our aim with this study is to
scrutinize professional mathematicians' search behavior. With this
understanding we want to be able to reason why mathematicians use which tool
for what search problem in what phase of the search process. To gain these
insights we conducted 24 repertory grid interviews with mathematically inclined
people (ranging from senior professional mathematicians to non-mathematicians).
From the interview data we elicited patterns for the user group
"mathematicians" that can be applied when understanding design issues or
creating new designs for mathematical search interfaces.
</summary>
    <author>
      <name>Andrea Kohlhase</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">conference article "CICM'14: International Conference on Computer
  Mathematics 2014", DML-Track: Digital Math Libraries 17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4921v1</id>
    <updated>2014-05-19T23:53:58Z</updated>
    <published>2014-05-19T23:53:58Z</published>
    <title>Zgoubi: A startup guide for the complete beginner</title>
    <summary>  Zgoubi is a code which can be used to model accelerators and beam lines,
comprised of magnetic and electrostatic elements. It has been extensively
developed since the mid-1980s to include circular accelerators and related beam
physics. It has been made freely available by its author on a code development
site, including a Users' Guide, a data treatment/graphic interfacing tool, and
many examples. This startup guide give directions to install the required
elements onto a Windows or Unix system to enable running of the Zgoubi code
with examples of code written to model the EMMA accelerator based at the
Cockcroft Institute.
</summary>
    <author>
      <name>Annette Pressman</name>
    </author>
    <author>
      <name>Kai Hock</name>
    </author>
    <link href="http://arxiv.org/abs/1405.4921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.acc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.acc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2079v4</id>
    <updated>2014-11-20T08:28:13Z</updated>
    <published>2014-06-09T05:36:44Z</published>
    <title>Program Verification of Numerical Computation - Part 2</title>
    <summary>  These notes present some extensions of a formal method introduced in an
earlier paper. The formal method is designed as a tool for program verification
of numerical computation and forms the basis of the software package VPC.
Included in the extensions that are presented here are disjunctions and methods
for detecting non-computable programs. A more comprehensive list of the
construction rules as higher order constructs is also presented.
</summary>
    <author>
      <name>Garry Pantelis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1401.1290</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.2079v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2079v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03Fxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; F.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.5953v1</id>
    <updated>2014-07-22T17:42:29Z</updated>
    <published>2014-07-22T17:42:29Z</published>
    <title>Implementing cryptographic pairings at standard security levels</title>
    <summary>  This study reports on an implementation of cryptographic pairings in a
general purpose computer algebra system. For security levels equivalent to the
different AES flavours, we exhibit suitable curves in parametric families and
show that optimal ate and twisted ate pairings exist and can be efficiently
evaluated. We provide a correct description of Miller's algorithm for signed
binary expansions such as the NAF and extend a recent variant due to Boxall et
al. to addition-subtraction chains. We analyse and compare several algorithms
proposed in the literature for the final exponentiation. Finally, we ive
recommendations on which curve and pairing to choose at each security level.
</summary>
    <author>
      <name>Andreas Enge</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest, IMB</arxiv:affiliation>
    </author>
    <author>
      <name>Jérôme Milan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1407.5953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.5953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1387v1</id>
    <updated>2014-10-02T18:15:22Z</updated>
    <published>2014-10-02T18:15:22Z</published>
    <title>High-Order Finite-differences on multi-threaded architectures using OCCA</title>
    <summary>  High-order finite-difference methods are commonly used in wave propagators
for industrial subsurface imaging algorithms. Computational aspects of the
reduced linear elastic vertical transversely isotropic propagator are
considered. Thread parallel algorithms suitable for implementing this
propagator on multi-core and many-core processing devices are introduced.
Portability is addressed through the use of the \OCCA runtime programming
interface. Finally, performance results are shown for various architectures on
a representative synthetic test case.
</summary>
    <author>
      <name>David S. Medina</name>
    </author>
    <author>
      <name>Amik St-Cyr</name>
    </author>
    <author>
      <name>Timothy Warburton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICOSAHOM 2014 conference paper, 9 pages, 2 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.1387v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1387v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8507v1</id>
    <updated>2014-10-30T19:29:08Z</updated>
    <published>2014-10-30T19:29:08Z</published>
    <title>External Use of TOPCAT's Plotting Library</title>
    <summary>  The table analysis application TOPCAT uses a custom Java plotting library for
highly configurable high-performance interactive or exported visualisations in
two and three dimensions. We present here a variety of ways for end users or
application developers to make use of this library outside of the TOPCAT
application: via the command-line suite STILTS or its Jython variant JyStilts,
via a traditional Java API, or by programmatically assigning values to a set of
parameters in java code or using some form of inter-process communication. The
library has been built with large datasets in mind; interactive plots scale
well up to several million points, and static output to standard graphics
formats is possible for unlimited sized input data.
</summary>
    <author>
      <name>M. B. Taylor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.8507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2562v1</id>
    <updated>2014-12-08T13:56:17Z</updated>
    <published>2014-12-08T13:56:17Z</published>
    <title>Minkowski sum of HV-polytopes in Rn</title>
    <summary>  Minkowski sums cover a wide range of applications in many different fields
like algebra, morphing, robotics, mechanical CAD/CAM systems ... This paper
deals with sums of polytopes in a n dimensional space provided that both
H-representation and V-representation are available i.e. the polytopes are
described by both their half-spaces and vertices. The first method uses the
polytope normal fans and relies on the ability to intersect dual polyhedral
cones. Then we introduce another way of considering Minkowski sums of polytopes
based on the primal polyhedral cones attached to each vertex.
</summary>
    <author>
      <name>Vincent Delos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I2M</arxiv:affiliation>
    </author>
    <author>
      <name>Denis Teissandier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I2M</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4th Annual International Conference on Computational Mathematics,
  Computational Geometry and Statistics, Jan 2015, Singapore, Singapore</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.2562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.class-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2564v2</id>
    <updated>2015-06-16T09:39:04Z</updated>
    <published>2014-12-08T13:57:21Z</published>
    <title>Minkowski Sum of Polytopes Defined by Their Vertices</title>
    <summary>  Minkowski sums are of theoretical interest and have applications in fields
related to industrial backgrounds. In this paper we focus on the specific case
of summing polytopes as we want to solve the tolerance analysis problem
described in [1]. Our approach is based on the use of linear programming and is
solvable in polynomial time. The algorithm we developed can be implemented and
parallelized in a very easy way.
</summary>
    <author>
      <name>Vincent Delos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I2M</arxiv:affiliation>
    </author>
    <author>
      <name>Denis Teissandier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I2M</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4236/jamp.2015.31008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4236/jamp.2015.31008" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Applied Mathematics and Physics (JAMP), Scientific
  Research Publishing, 2015, 3 (1), pp.62-67</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.2564v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2564v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.class-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6367v1</id>
    <updated>2014-12-19T15:06:50Z</updated>
    <published>2014-12-19T15:06:50Z</published>
    <title>PyFAI: a Python library for high performance azimuthal integration on
  GPU</title>
    <summary>  The pyFAI package has been designed to reduce X-ray diffraction images into
powder diffraction curves to be further processed by scientists. This
contribution describes how to convert an image into a radial profile using the
Numpy package, how the process was accelerated using Cython. The algorithm was
parallelised, needing a complete re-design to benefit from massively parallel
devices like graphical processing units or accelerators like the Intel Xeon Phi
using the PyOpenCL library.
</summary>
    <author>
      <name>Jérôme Kieffer</name>
    </author>
    <author>
      <name>Giannis Ashiotis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01161v1</id>
    <updated>2015-04-05T20:58:18Z</updated>
    <published>2015-04-05T20:58:18Z</published>
    <title>Python bindings for libcloudph++</title>
    <summary>  This technical note introduces the Python bindings for libcloudph++. The
libcloudph++ is a C++ library of algorithms for representing atmospheric cloud
microphysics in numerical models. The bindings expose the complete
functionality of the library to the Python users. The bindings are implemented
using the Boost.Python C++ library and use NumPy arrays. This note includes
listings with Python scripts exemplifying the use of selected library
components. An example solution for using the Python bindings to access
libcloudph++ from Fortran is presented.
</summary>
    <author>
      <name>Dorota Jarecka</name>
    </author>
    <author>
      <name>Sylwester Arabas</name>
    </author>
    <author>
      <name>Davide Del Vento</name>
    </author>
    <link href="http://arxiv.org/abs/1504.01161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01380v2</id>
    <updated>2015-11-14T16:26:05Z</updated>
    <published>2015-04-06T16:00:32Z</published>
    <title>The swept rule for breaking the latency barrier in time advancing PDEs</title>
    <summary>  This article investigates the swept rule of space-time domain decomposition,
an idea to break the latency barrier via communicating less often when
explicitly solving time-dependent PDEs. The swept rule decomposes space and
time among computing nodes in ways that exploit the domains of influence and
the domain of dependency, making it possible to communicate once per many
timesteps without redundant computation. The article presents simple
theoretical analysis to the performance of the swept rule which then was shown
to be accurate by conducting numerical experiments.
</summary>
    <author>
      <name>Maitham Makki Alhubail</name>
    </author>
    <author>
      <name>Qiqi Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2015.11.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2015.11.026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Physics (2016), pp. 110-121</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.01380v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01380v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01629v1</id>
    <updated>2015-05-07T08:54:19Z</updated>
    <published>2015-05-07T08:54:19Z</published>
    <title>LeoPARD --- A Generic Platform for the Implementation of Higher-Order
  Reasoners</title>
    <summary>  LeoPARD supports the implementation of knowledge representation and reasoning
tools for higher-order logic(s). It combines a sophisticated data structure
layer (polymorphically typed {\lambda}-calculus with nameless spine notation,
explicit substitutions, and perfect term sharing) with an ambitious multi-agent
blackboard architecture (supporting prover parallelism at the term, clause, and
search level). Further features of LeoPARD include a parser for all TPTP
dialects, a command line interpreter, and generic means for the integration of
external reasoners.
</summary>
    <author>
      <name>Max Wisniewski</name>
    </author>
    <author>
      <name>Alexander Steen</name>
    </author>
    <author>
      <name>Christoph Benzmüller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, to appear in the proceedings of CICM'2015 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="03B35, 68T15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.3; F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05241v1</id>
    <updated>2015-05-20T04:11:49Z</updated>
    <published>2015-05-20T04:11:49Z</published>
    <title>Software for the Gale transform of fewnomial systems and a Descartes
  rule for fewnomials</title>
    <summary>  We give a Descartes'-like bound on the number of positive solutions to a
system of fewnomials that holds when its exponent vectors are not in convex
position and a sign condition is satisfied. This was discovered while
developing algorithms and software for computing the Gale transform of a
fewnomial system, which is our main goal. This software is a component of a
package we are developing for Khovanskii-Rolle continuation, which is a
numerical algorithm to compute the real solutions to a system of fewnomials.
</summary>
    <author>
      <name>Daniel J. Bates</name>
    </author>
    <author>
      <name>Jonathan D. Hauenstein</name>
    </author>
    <author>
      <name>Matthew E. Niemerg</name>
    </author>
    <author>
      <name>Frank Sottile</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.05241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="14P99, 65H10, 65H20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05605v1</id>
    <updated>2015-06-18T09:47:41Z</updated>
    <published>2015-06-18T09:47:41Z</published>
    <title>Asynchronous processing of Coq documents: from the kernel up to the user
  interface</title>
    <summary>  The work described in this paper improves the reactivity of the Coq system by
completely redesigning the way it processes a formal document. By subdividing
such work into independent tasks the system can give precedence to the ones of
immediate interest for the user and postpones the others. On the user side, a
modern interface based on the PIDE middleware aggregates and present in a
consistent way the output of the prover. Finally postponed tasks are processed
exploiting modern, parallel, hardware to offer better scalability.
</summary>
    <author>
      <name>Bruno Barras</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPECFUN</arxiv:affiliation>
    </author>
    <author>
      <name>Carst Tankink</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPECFUN</arxiv:affiliation>
    </author>
    <author>
      <name>Enrico Tassi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MARELLE</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Proceedings of ITP, Aug 2015, Nanjing, China</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.05605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07980v1</id>
    <updated>2015-06-26T07:44:38Z</updated>
    <published>2015-06-26T07:44:38Z</published>
    <title>A Java Implementation of the SGA, UMDA, ECGA, and HBOA</title>
    <summary>  The Simple Genetic Algorithm, the Univariate Marginal Distribution Algorithm,
the Extended Compact Genetic Algorithm, and the Hierarchical Bayesian
Optimization Algorithm are all well known Evolutionary Algorithms.
  In this report we present a Java implementation of these four algorithms with
detailed instructions on how to use each of them to solve a given set of
optimization problems. Additionally, it is explained how to implement and
integrate new problems within the provided set. The source and binary files of
the Java implementations are available for free download at
https://github.com/JoseCPereira/2015EvolutionaryAlgorithmsJava.
</summary>
    <author>
      <name>José C. Pereira</name>
    </author>
    <author>
      <name>Fernando G. Lobo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.07980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.01982v3</id>
    <updated>2016-08-15T04:27:52Z</updated>
    <published>2015-08-09T03:55:19Z</published>
    <title>JuMP: A Modeling Language for Mathematical Optimization</title>
    <summary>  JuMP is an open-source modeling language that allows users to express a wide
range of optimization problems (linear, mixed-integer, quadratic,
conic-quadratic, semidefinite, and nonlinear) in a high-level, algebraic
syntax. JuMP takes advantage of advanced features of the Julia programming
language to offer unique functionality while achieving performance on par with
commercial modeling tools for standard tasks. In this work we will provide
benchmarks, present the novel aspects of the implementation, and discuss how
JuMP can be extended to new problem classes and composed with state-of-the-art
tools for visualization and interactivity.
</summary>
    <author>
      <name>Iain Dunning</name>
    </author>
    <author>
      <name>Joey Huchette</name>
    </author>
    <author>
      <name>Miles Lubin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/15M1020575</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/15M1020575" rel="related"/>
    <link href="http://arxiv.org/abs/1508.01982v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.01982v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03211v1</id>
    <updated>2015-08-13T13:42:35Z</updated>
    <published>2015-08-13T13:42:35Z</published>
    <title>Computing accurate Horner form approximations to special functions in
  finite precision arithmetic</title>
    <summary>  In various applications, computers are required to compute approximations to
univariate elementary and special functions such as $\exp$ and $\arctan$ to
modest accuracy. This paper proposes a new heuristic for automating the design
of such implementations. This heuristic takes a certain restricted
specification of program structure and the desired error properties as input
and takes explicit account of roundoff error during evaluation.
</summary>
    <author>
      <name>Tor G. J. Myklebust</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="33F05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.00864v1</id>
    <updated>2015-09-02T20:23:07Z</updated>
    <published>2015-09-02T20:23:07Z</published>
    <title>Strong Pseudoprimes to Twelve Prime Bases</title>
    <summary>  Let $\psi_m$ be the smallest strong pseudoprime to the first $m$ prime bases.
This value is known for $1 \leq m \leq 11$. We extend this by finding
$\psi_{12}$ and $\psi_{13}$. We also present an algorithm to find all integers
$n\le B$ that are strong pseudoprimes to the first $m$ prime bases; with a
reasonable heuristic assumption we can show that it takes at most
$B^{2/3+o(1)}$ time.
</summary>
    <author>
      <name>Jonathan P. Sorenson</name>
    </author>
    <author>
      <name>Jonathan Webster</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1090/mcom/3134</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1090/mcom/3134" rel="related"/>
    <link href="http://arxiv.org/abs/1509.00864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.00864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 11Y16, 11Y16, Secondary 11A41, 68W40, 68W10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.08642v1</id>
    <updated>2015-10-29T10:58:55Z</updated>
    <published>2015-10-29T10:58:55Z</published>
    <title>Performance evaluation of multiple precision matrix multiplications
  using parallelized Strassen and Winograd algorithms</title>
    <summary>  It is well known that Strassen and Winograd algorithms can reduce the
computational costs associated with dense matrix multiplication. We have
already shown that they are also very effective for software-based multiple
precision floating-point arithmetic environments such as the MPFR/GMP library.
In this paper, we show that we can obtain the same effectiveness for
double-double (DD) and quadruple-double (QD) environments supported by the QD
library, and that parallelization can increase the speed of these multiple
precision matrix multiplications. Finally, we demonstrate that our implemented
parallelized Strassen and Winograd algorithms can increase the speed of
parallelized LU decomposition.
</summary>
    <author>
      <name>Tomonori Kouya</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14495/jsiaml.8.21</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14495/jsiaml.8.21" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JSIAM Letters Vol. 8 (2016) p. 21-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.08642v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.08642v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03614v1</id>
    <updated>2015-10-23T16:07:56Z</updated>
    <published>2015-10-23T16:07:56Z</published>
    <title>FIESTA 4: optimized Feynman integral calculations with GPU support</title>
    <summary>  This paper presents a new major release of the program FIESTA (Feynman
Integral Evaluation by a Sector decomposiTion Approach). The new release is
mainly aimed at optimal performance at large scales when one is increasing the
number of sampling points in order to reduce the uncertainty estimates. The
release now supports graphical processor units (GPU) for the numerical
integration, methods to optimize cluster-usage, as well as other speed, memory,
and stability improvements.
</summary>
    <author>
      <name>Alexander V. Smirnov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2016.03.013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2016.03.013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1312.3186</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comp. Phys. Comm, 204, 2016, p, 189-199</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.03614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07527v1</id>
    <updated>2016-02-24T14:35:31Z</updated>
    <published>2016-02-24T14:35:31Z</published>
    <title>Differentiation of the Cholesky decomposition</title>
    <summary>  We review strategies for differentiating matrix-based computations, and
derive symbolic and algorithmic update rules for differentiating expressions
containing the Cholesky decomposition. We recommend new `blocked' algorithms,
based on differentiating the Cholesky algorithm DPOTRF in the LAPACK library,
which uses `Level 3' matrix-matrix operations from BLAS, and so is
cache-friendly and easy to parallelize. For large matrices, the resulting
algorithms are the fastest way to compute Cholesky derivatives, and are an
order of magnitude faster than the algorithms in common usage. In some
computing environments, symbolically-derived updates are faster for small
matrices than those based on differentiating Cholesky algorithms. The symbolic
and algorithmic approaches can be combined to get the best of both worlds.
</summary>
    <author>
      <name>Iain Murray</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, including 7 pages of code listings</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00206v1</id>
    <updated>2016-07-31T10:22:40Z</updated>
    <published>2016-07-31T10:22:40Z</published>
    <title>An exact, cache-localized algorithm for the sub-quadratic convolution of
  hypercubes</title>
    <summary>  Fast multidimensional convolution can be performed naively in quadratic time
and can often be performed more efficiently via the Fourier transform; however,
when the dimensionality is large, these algorithms become more challenging. A
method is proposed for performing exact hypercube convolution in sub-quadratic
time. The method outperforms FFTPACK, called via numpy, and FFTW, called via
pyfftw) for hypercube convolution. Embeddings in hypercubes can be paired with
sub-quadratic hypercube convolution method to construct sub-quadratic
algorithms for variants of vector convolution.
</summary>
    <author>
      <name>Oliver Serang</name>
    </author>
    <link href="http://arxiv.org/abs/1608.00206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00829v1</id>
    <updated>2016-09-03T13:59:43Z</updated>
    <published>2016-09-03T13:59:43Z</published>
    <title>Efficient computation of Laguerre polynomials</title>
    <summary>  An efficient algorithm and a Fortran 90 module (LaguerrePol) for computing
Laguerre polynomials $L^{(\alpha)}_n(z)$ are presented. The standard three-term
recurrence relation satisfied by the polynomials and different types of
asymptotic expansions valid for $n$ large and $\alpha$ small, are used
depending on the parameter region.
  Based on tests of contiguous relations in the parameter $\alpha$ and the
degree $n$ satisfied by the polynomials, we claim that a relative accuracy
close or better than $10^{-12}$ can be obtained using the module LaguerrePol
for computing the functions $L^{(\alpha)}_n(z)$ in the parameter range $z \ge
0$, $-1 &lt; \alpha \le 5$, $n \ge 0$.
</summary>
    <author>
      <name>A. Gil</name>
    </author>
    <author>
      <name>J. Segura</name>
    </author>
    <author>
      <name>N. M. Temme</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2016.09.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2016.09.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Computer Physics Communications</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.00829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03034v2</id>
    <updated>2019-04-13T01:50:06Z</updated>
    <published>2016-10-10T19:14:59Z</published>
    <title>Numerical Implicitization</title>
    <summary>  We present the $\textit{NumericalImplicitization}$ package for
$\textit{Macaulay2}$, which allows for user-friendly computation of the
invariants of the image of a polynomial map, such as dimension, degree, and
Hilbert function values. This package relies on methods of numerical algebraic
geometry, including homotopy continuation and monodromy.
</summary>
    <author>
      <name>Justin Chen</name>
    </author>
    <author>
      <name>Joe Kileel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2140/jsag.2019.9.55</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2140/jsag.2019.9.55" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, various improvements, to appear in Journal of Software for
  Algebra and Geometry</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Softw. Alg. Geom. 9 (2019) 55-63</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.03034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="14-04, 14Q99, 65H10, 65H20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.07819v1</id>
    <updated>2016-11-19T00:24:12Z</updated>
    <published>2016-11-19T00:24:12Z</published>
    <title>dMath: Distributed Linear Algebra for DL</title>
    <summary>  The paper presents a parallel math library, dMath, that demonstrates leading
scaling when using intranode, internode, and hybrid-parallelism for deep
learning (DL). dMath provides easy-to-use distributed primitives and a variety
of domain-specific algorithms including matrix multiplication, convolutions,
and others allowing for rapid development of scalable applications like deep
neural networks (DNNs). Persistent data stored in GPU memory and advanced
memory management techniques avoid costly transfers between host and device.
dMath delivers performance, portability, and productivity to its specific
domain of support.
</summary>
    <author>
      <name>Steven Eliuk</name>
    </author>
    <author>
      <name>Cameron Upright</name>
    </author>
    <author>
      <name>Hars Vardhan</name>
    </author>
    <author>
      <name>Stephen Walsh</name>
    </author>
    <author>
      <name>Trevor Gale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages. arXiv admin note: text overlap with arXiv:1604.01416</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.07819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.07819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00985v1</id>
    <updated>2017-03-02T23:27:33Z</updated>
    <published>2017-03-02T23:27:33Z</published>
    <title>Small Superposition Dimension and Active Set Construction for
  Multivariate Integration Under Modest Error Demand</title>
    <summary>  Constructing active sets is a key part of the Multivariate Decomposition
Method. An algorithm for constructing optimal or quasi-optimal active sets is
proposed in the paper. By numerical experiments, it is shown that the new
method can provide sets that are significantly smaller than the sets
constructed by the already existing method. The experiments also show that the
superposition dimension could surprisingly be very small, at most 3, when the
error demand is not smaller than $10^{-3}$ and the weights decay sufficiently
fast.
</summary>
    <author>
      <name>Alexander D. Gilbert</name>
    </author>
    <author>
      <name>Greg W. Wasilkowski</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05298v2</id>
    <updated>2017-03-16T08:32:19Z</updated>
    <published>2017-03-10T18:01:20Z</published>
    <title>Neural Networks for Beginners. A fast implementation in Matlab, Torch,
  TensorFlow</title>
    <summary>  This report provides an introduction to some Machine Learning tools within
the most common development environments. It mainly focuses on practical
problems, skipping any theoretical introduction. It is oriented to both
students trying to approach Machine Learning and experts looking for new
frameworks.
</summary>
    <author>
      <name>Francesco Giannini</name>
    </author>
    <author>
      <name>Vincenzo Laveglia</name>
    </author>
    <author>
      <name>Alessandro Rossi</name>
    </author>
    <author>
      <name>Dario Zanca</name>
    </author>
    <author>
      <name>Andrea Zugarini</name>
    </author>
    <link href="http://arxiv.org/abs/1703.05298v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05298v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02808v2</id>
    <updated>2017-06-22T22:04:44Z</updated>
    <published>2017-06-09T01:44:03Z</published>
    <title>A randomized Halton algorithm in R</title>
    <summary>  Randomized quasi-Monte Carlo (RQMC) sampling can bring orders of magnitude
reduction in variance compared to plain Monte Carlo (MC) sampling. The extent
of the efficiency gain varies from problem to problem and can be hard to
predict. This article presents an R function rhalton that produces scrambled
versions of Halton sequences. On some problems it brings efficiency gains of
several thousand fold. On other problems, the efficiency gain is minor. The
code is designed to make it easy to determine whether a given integrand will
benefit from RQMC sampling. An RQMC sample of n points in $[0,1]^d$ can be
extended later to a larger n and/or d.
</summary>
    <author>
      <name>Art B. Owen</name>
    </author>
    <link href="http://arxiv.org/abs/1706.02808v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02808v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01271v1</id>
    <updated>2017-07-05T09:24:46Z</updated>
    <published>2017-07-05T09:24:46Z</published>
    <title>Compiling LATEX to computer algebra-enabled HTML5</title>
    <summary>  This document explains how to create or modify an existing LATEX document
with commands enabling computations in the HTML5 output: when the reader opens
the HTML5 output, he can run a computation in his browser, or modify the
command to be executed and run it. This is done by combining different
softwares: hevea for compilation to HTML5, giac.js for the CAS computing kernel
(itself compiled from the C++ Giac library with emscripten), and a modified
version of itex2MML for fast and nice rendering in MathML in browsers that
support MathML.
</summary>
    <author>
      <name>Bernard Parisse</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The interactive HTML5/MathML version of the document is available at
  https://www-fourier.ujf-grenoble.fr/~parisse/giac/castex.htmlThe LaTeX source
  will not compile properly to PDF without installing the software described in
  the document</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.01271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01898v1</id>
    <updated>2017-07-06T04:12:25Z</updated>
    <published>2017-07-06T04:12:25Z</published>
    <title>Adaptive Modular Exponentiation Methods v.s. Python's Power Function</title>
    <summary>  In this paper we use Python to implement two efficient modular exponentiation
methods: the adaptive m-ary method and the adaptive sliding-window method of
window size k, where both m's are adaptively chosen based on the length of
exponent. We also conduct the benchmark for both methods. Evaluation results
show that compared to the industry-standard efficient implementations of
modular power function in CPython and Pypy, our algorithms can reduce 1-5%
computing time for exponents with more than 3072 bits.
</summary>
    <author>
      <name>Shiyu Ji</name>
    </author>
    <author>
      <name>Kun Wan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.01898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08265v1</id>
    <updated>2017-07-26T01:16:29Z</updated>
    <published>2017-07-26T01:16:29Z</published>
    <title>Dragon: A Computation Graph Virtual Machine Based Deep Learning
  Framework</title>
    <summary>  Deep Learning has made a great progress for these years. However, it is still
difficult to master the implement of various models because different
researchers may release their code based on different frameworks or interfaces.
In this paper, we proposed a computation graph based framework which only aims
to introduce well-known interfaces. It will help a lot when reproducing a newly
model or transplanting models that were implemented by other frameworks.
Additionally, we implement numerous recent models covering both Computer Vision
and Nature Language Processing. We demonstrate that our framework will not
suffer from model-starving because it is much easier to make full use of the
works that are already done.
</summary>
    <author>
      <name>Ting Pan</name>
    </author>
    <link href="http://arxiv.org/abs/1707.08265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01054v2</id>
    <updated>2017-09-05T04:37:43Z</updated>
    <published>2017-08-20T06:03:31Z</published>
    <title>Distributed Triangle Counting in the Graphulo Matrix Math Library</title>
    <summary>  Triangle counting is a key algorithm for large graph analysis. The Graphulo
library provides a framework for implementing graph algorithms on the Apache
Accumulo distributed database. In this work we adapt two algorithms for
counting triangles, one that uses the adjacency matrix and another that also
uses the incidence matrix, to the Graphulo library for server-side processing
inside Accumulo. Cloud-based experiments show a similar performance profile for
these different approaches on the family of power law Graph500 graphs, for
which data skew increasingly bottlenecks. These results motivate the design of
skew-aware hybrid algorithms that we propose for future work.
</summary>
    <author>
      <name>Dylan Hutchison</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HPEC.2017.8091041</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HPEC.2017.8091041" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Honorable mention in the 2017 IEEE HPEC's Graph Challenge</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01054v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01054v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.07226v1</id>
    <updated>2017-10-18T06:24:50Z</updated>
    <published>2017-10-18T06:24:50Z</published>
    <title>Wilson and Domainwall Kernels on Oakforest-PACS</title>
    <summary>  We report the performance of Wilson and Domainwall Kernels on a new Intel
Xeon Phi Knights Landing based machine named Oakforest-PACS, which is co-hosted
by University of Tokyo and Tsukuba University and is currently fastest in
Japan. This machine uses Intel Omni-Path for the internode network. We compare
performance with several types of implementation including that makes use of
the Grid library. The code is incorporated with the code set Bridge++.
</summary>
    <author>
      <name>Issaku Kanamori</name>
    </author>
    <author>
      <name>Hideo Matsufuru</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1051/epjconf/201817509002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1051/epjconf/201817509002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures, Proceedings for the 35th International Symposium
  on Lattice Field Theory (Lattice 2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.07226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.07226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-lat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.04582v1</id>
    <updated>2018-01-14T16:47:52Z</updated>
    <published>2018-01-14T16:47:52Z</published>
    <title>Distributed dynamic load balancing for task parallel programming</title>
    <summary>  In this paper, we derive and investigate approaches to dynamically load
balance a distributed task parallel application software. The load balancing
strategy is based on task migration. Busy processes export parts of their ready
task queue to idle processes. Idle--busy pairs of processes find each other
through a random search process that succeeds within a few steps with high
probability. We evaluate the load balancing approach for a block Cholesky
factorization implementation and observe a reduction in execution time on the
order of 5\% in the selected test cases.
</summary>
    <author>
      <name>Afshin Zafari</name>
    </author>
    <author>
      <name>Elisabeth Larsson</name>
    </author>
    <link href="http://arxiv.org/abs/1801.04582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.04582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.06601v1</id>
    <updated>2018-01-19T23:39:15Z</updated>
    <published>2018-01-19T23:39:15Z</published>
    <title>CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs</title>
    <summary>  Deep Neural Networks are becoming increasingly popular in always-on IoT edge
devices performing data analytics right at the source, reducing latency as well
as energy consumption for data communication. This paper presents CMSIS-NN,
efficient kernels developed to maximize the performance and minimize the memory
footprint of neural network (NN) applications on Arm Cortex-M processors
targeted for intelligent IoT edge devices. Neural network inference based on
CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X
improvement in energy efficiency.
</summary>
    <author>
      <name>Liangzhen Lai</name>
    </author>
    <author>
      <name>Naveen Suda</name>
    </author>
    <author>
      <name>Vikas Chandra</name>
    </author>
    <link href="http://arxiv.org/abs/1801.06601v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.06601v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.07247v2</id>
    <updated>2018-06-20T03:23:18Z</updated>
    <published>2018-06-17T08:14:42Z</published>
    <title>Tensor-Tensor Product Toolbox</title>
    <summary>  The tensor-tensor product (t-product) [M. E. Kilmer and C. D. Martin, 2011]
is a natural generalization of matrix multiplication. Based on t-product, many
operations on matrix can be extended to tensor cases, including tensor SVD,
tensor spectral norm, tensor nuclear norm [C. Lu, et al., 2018] and many
others. The linear algebraic structure of tensors are similar to the matrix
cases. We develop a Matlab toolbox to implement several basic operations on
tensors based on t-product. The toolbox is available at
https://github.com/canyilu/tproduct.
</summary>
    <author>
      <name>Canyi Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1804.03728.
  Carnegie Mellon University</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.07247v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.07247v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.03916v1</id>
    <updated>2018-08-12T09:38:34Z</updated>
    <published>2018-08-12T09:38:34Z</published>
    <title>Linguistic Relativity and Programming Languages</title>
    <summary>  The use of programming languages can wax and wane across the decades. We
examine the split-apply- combine pattern that is common in statistical
computing, and consider how its invocation or implementation in languages like
MATLAB and APL differ from R/dplyr. The differences in spelling illustrate how
the concept of linguistic relativity applies to programming languages in ways
that are analogous to human languages. Finally, we discuss how Julia, by being
a high performance yet general purpose dynamic language, allows its users to
express different abstractions to suit individual preferences.
</summary>
    <author>
      <name>Jiahao Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, repo at
  https://github.com/jiahao/statistical-computing-linguistics, Published in
  Proceedings of the 2016 Joint Statistical Meetings, Chicago, IL, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.03916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.03916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.11363v1</id>
    <updated>2018-10-24T13:08:24Z</updated>
    <published>2018-10-24T13:08:24Z</published>
    <title>CatBoost: gradient boosting with categorical features support</title>
    <summary>  In this paper we present CatBoost, a new open-sourced gradient boosting
library that successfully handles categorical features and outperforms existing
publicly available implementations of gradient boosting in terms of quality on
a set of popular publicly available datasets. The library has a GPU
implementation of learning algorithm and a CPU implementation of scoring
algorithm, which are significantly faster than other gradient boosting
libraries on ensembles of similar sizes.
</summary>
    <author>
      <name>Anna Veronika Dorogush</name>
    </author>
    <author>
      <name>Vasily Ershov</name>
    </author>
    <author>
      <name>Andrey Gulin</name>
    </author>
    <link href="http://arxiv.org/abs/1810.11363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.11363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.01719v1</id>
    <updated>2018-11-01T08:20:49Z</updated>
    <published>2018-11-01T08:20:49Z</published>
    <title>Issues in the software implementation of stochastic numerical
  Runge-Kutta</title>
    <summary>  This paper discusses stochastic numerical methods of Runge-Kutta type with
weak and strong convergences for systems of stochastic differential equations
in It\^o form. At the beginning we give a brief overview of the stochastic
numerical methods and information from the theory of stochastic differential
equations. Then we motivate the approach to the implementation of these methods
using source code generation. We discuss the implementation details and the
used programming languages and libraries
</summary>
    <author>
      <name>Migran N. Gevorkyan</name>
    </author>
    <author>
      <name>Anastasia V. Demidova</name>
    </author>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-99447-5_46</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-99447-5_46" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.01719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.01719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.04243v1</id>
    <updated>2019-03-08T03:11:02Z</updated>
    <published>2019-03-08T03:11:02Z</published>
    <title>Auto-Vectorizing TensorFlow Graphs: Jacobians, Auto-Batching And Beyond</title>
    <summary>  We propose a static loop vectorization optimization on top of high level
dataflow IR used by frameworks like TensorFlow. A new statically vectorized
parallel-for abstraction is provided on top of TensorFlow, and used for
applications ranging from auto-batching and per-example gradients, to jacobian
computation, optimized map functions and input pipeline optimization. We report
huge speedups compared to both loop based implementations, as well as run-time
batching adopted by the DyNet framework.
</summary>
    <author>
      <name>Ashish Agarwal</name>
    </author>
    <author>
      <name>Igor Ganichev</name>
    </author>
    <link href="http://arxiv.org/abs/1903.04243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.04243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03317v2</id>
    <updated>2021-08-03T17:11:38Z</updated>
    <published>2019-04-05T23:05:33Z</published>
    <title>A Flexible, Parallel, Adaptive Geometric Multigrid method for FEM</title>
    <summary>  We present the design and implementation details of a geometric multigrid
method on adaptively refined meshes for massively parallel computations. The
method uses local smoothing on the refined part of the mesh. Partitioning is
achieved by using a space filling curve for the leaf mesh and distributing
ancestors in the hierarchy based on the leaves. We present a model of the
efficiency of mesh hierarchy distribution and compare its predictions to
runtime measurements. The algorithm is implemented as part of the deal.II
finite element library and as such available to the public.
</summary>
    <author>
      <name>Thomas C. Clevenger</name>
    </author>
    <author>
      <name>Timo Heister</name>
    </author>
    <author>
      <name>Guido Kanschat</name>
    </author>
    <author>
      <name>Martin Kronbichler</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3425193</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3425193" rel="related"/>
    <link href="http://arxiv.org/abs/1904.03317v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03317v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00562v3</id>
    <updated>2020-02-27T20:03:44Z</updated>
    <published>2019-05-02T03:19:49Z</published>
    <title>Disciplined Quasiconvex Programming</title>
    <summary>  We present a composition rule involving quasiconvex functions that
generalizes the classical composition rule for convex functions. This rule
complements well-known rules for the curvature of quasiconvex functions under
increasing functions and pointwise maximums. We refer to the class of
optimization problems generated by these rules, along with a base set of
quasiconvex and quasiconcave functions, as disciplined quasiconvex programs.
Disciplined quasiconvex programming generalizes disciplined convex programming,
the class of optimization problems targeted by most modern domain-specific
languages for convex optimization. We describe an implementation of disciplined
quasiconvex programming that makes it possible to specify and solve quasiconvex
programs in CVXPY 1.0.
</summary>
    <author>
      <name>Akshay Agrawal</name>
    </author>
    <author>
      <name>Stephen Boyd</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">p. 4: corrected typos</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.00562v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00562v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.09539v1</id>
    <updated>2019-05-23T08:54:45Z</updated>
    <published>2019-05-23T08:54:45Z</published>
    <title>Recursive blocked algorithms for linear systems with Kronecker product
  structure</title>
    <summary>  Recursive blocked algorithms have proven to be highly efficient at the
numerical solution of the Sylvester matrix equation and its generalizations. In
this work, we show that these algorithms extend in a seamless fashion to
higher-dimensional variants of generalized Sylvester matrix equations, as they
arise from the discretization of PDEs with separable coefficients or the
approximation of certain models in macroeconomics. By combining recursions with
a mechanism for merging dimensions, an efficient algorithm is derived that
outperforms existing approaches based on Sylvester solvers.
</summary>
    <author>
      <name>Minhong Chen</name>
    </author>
    <author>
      <name>Daniel Kressner</name>
    </author>
    <link href="http://arxiv.org/abs/1905.09539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.08611v3</id>
    <updated>2021-07-12T09:30:49Z</updated>
    <published>2019-07-19T17:59:56Z</published>
    <title>Distributions.jl: Definition and Modeling of Probability Distributions
  in the JuliaStats Ecosystem</title>
    <summary>  Random variables and their distributions are a central part in many areas of
statistical methods. The Distributions.jl package provides Julia users and
developers tools for working with probability distributions, leveraging Julia
features for their intuitive and flexible manipulation, while remaining highly
efficient through zero-cost abstractions.
</summary>
    <author>
      <name>Mathieu Besançon</name>
    </author>
    <author>
      <name>Theodore Papamarkou</name>
    </author>
    <author>
      <name>David Anthoff</name>
    </author>
    <author>
      <name>Alex Arslan</name>
    </author>
    <author>
      <name>Simon Byrne</name>
    </author>
    <author>
      <name>Dahua Lin</name>
    </author>
    <author>
      <name>John Pearson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18637/jss.v098.i16</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18637/jss.v098.i16" rel="related"/>
    <link href="http://arxiv.org/abs/1907.08611v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08611v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02558v1</id>
    <updated>2019-11-06T18:57:01Z</updated>
    <published>2019-11-06T18:57:01Z</published>
    <title>TensorTrace: an application to contract tensor networks</title>
    <summary>  Tensor network methods are a conceptually elegant framework for encoding
complicated datasets, where high-order tensors are approximated as networks of
low-order tensors. In practice, however, the numeric implementation of tensor
network algorithms is often a labor-intensive and error-prone task, even for
experienced researchers in this area. \emph{TensorTrace} is application
designed to alleviate the burden of contracting tensor networks: it provides a
graphic drawing interface specifically tailored for the construction of tensor
network diagrams, from which the code for their optimal contraction can then be
automatically generated (in the users choice of the MATLAB, Python or Julia
languages). \emph{TensorTrace} is freely available at
\url{https://www.tensortrace.com} with versions for Windows, Mac and Ubuntu.
</summary>
    <author>
      <name>Glen Evenbly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.02558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00816v1</id>
    <updated>2019-12-02T14:22:42Z</updated>
    <published>2019-12-02T14:22:42Z</published>
    <title>Recent Developments in Iterative Methods for Reducing Synchronization</title>
    <summary>  On modern parallel architectures, the cost of synchronization among
processors can often dominate the cost of floating-point computation. Several
modifications of the existing methods have been proposed in order to keep the
communication cost as low as possible. This paper aims at providing a brief
overview of recent advances in parallel iterative methods for solving
large-scale problems. We refer the reader to the related references for more
details on the derivation, implementation, performance, and analysis of these
techniques.
</summary>
    <author>
      <name>Qinmeng Zou</name>
    </author>
    <author>
      <name>Frederic Magoules</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/DCABES48411.2019.00048</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/DCABES48411.2019.00048" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">18th International Symposium on Distributed Computing and
  Applications for Business Engineering and Science (DCABES), 2019, IEEE</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.00816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.09319v1</id>
    <updated>2019-12-19T15:59:24Z</updated>
    <published>2019-12-19T15:59:24Z</published>
    <title>Assembly of multiscale linear PDE operators</title>
    <summary>  In numerous applications the mathematical model consists of different
processes coupled across a lower dimensional manifold. Due to the multiscale
coupling, finite element discretization of such models presents a challenge.
Assuming that only singlescale finite element forms can be assembled we present
here a simple algorithm for representing multiscale models as linear operators
suitable for Krylov methods. Flexibility of the approach is demonstrated by
numerical examples with coupling across dimensionality gap 1 and 2.
Preconditioners for several of the problems are discussed.
</summary>
    <author>
      <name>Miroslav Kuchta</name>
    </author>
    <link href="http://arxiv.org/abs/1912.09319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.11930v1</id>
    <updated>2019-12-26T20:41:05Z</updated>
    <published>2019-12-26T20:41:05Z</published>
    <title>Strategies for the vectorized Block Conjugate Gradients method</title>
    <summary>  Block Krylov methods have recently gained a lot of attraction. Due to their
increased arithmetic intensity they offer a promising way to improve
performance on modern hardware. Recently Frommer et al. presented a block
Krylov framework that combines the advantages of block Krylov methods and data
parallel methods. We review this framework and apply it on the Block Conjugate
Gradients method,to solve linear systems with multiple right hand sides. In
this course we consider challenges that occur on modern hardware, like a
limited memory bandwidth, the use of SIMD instructions and the communication
overhead. We present a performance model to predict the efficiency of different
Block CG variants and compare these with experimental numerical results.
</summary>
    <author>
      <name>Nils-Arne Dreier</name>
    </author>
    <author>
      <name>Christian Engwer</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03400v1</id>
    <updated>2020-02-09T17:19:44Z</updated>
    <published>2020-02-09T17:19:44Z</published>
    <title>Butterfly factorization via randomized matrix-vector multiplications</title>
    <summary>  This paper presents an adaptive randomized algorithm for computing the
butterfly factorization of a $m\times n$ matrix with $m\approx n$ provided that
both the matrix and its transpose can be rapidly applied to arbitrary vectors.
The resulting factorization is composed of $O(\log n)$ sparse factors, each
containing $O(n)$ nonzero entries. The factorization can be attained using
$O(n^{3/2}\log n)$ computation and $O(n\log n)$ memory resources. The proposed
algorithm applies to matrices with strong and weak admissibility conditions
arising from surface integral equation solvers with a rigorous error bound, and
is implemented in parallel.
</summary>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Xin Xing</name>
    </author>
    <author>
      <name>Han Guo</name>
    </author>
    <author>
      <name>Eric Michielssen</name>
    </author>
    <author>
      <name>Pieter Ghysels</name>
    </author>
    <author>
      <name>Xiaoye Sherry Li</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03400v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03400v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.03673v2</id>
    <updated>2020-05-26T11:47:21Z</updated>
    <published>2020-04-07T19:52:20Z</published>
    <title>Maintaining a Library of Formal Mathematics</title>
    <summary>  The Lean mathematical library mathlib is developed by a community of users
with very different backgrounds and levels of experience. To lower the barrier
of entry for contributors and to lessen the burden of reviewing contributions,
we have developed a number of tools for the library which check proof
developments for subtle mistakes in the code and generate documentation suited
for our varied audience.
</summary>
    <author>
      <name>Floris van Doorn</name>
    </author>
    <author>
      <name>Gabriel Ebner</name>
    </author>
    <author>
      <name>Robert Y. Lewis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-53518-6_16</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-53518-6_16" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of CICM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.03673v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.03673v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.09488v1</id>
    <updated>2020-07-18T17:49:33Z</updated>
    <published>2020-07-18T17:49:33Z</published>
    <title>Languages for modeling the RED active queue management algorithms:
  Modelica vs. Julia</title>
    <summary>  This work is devoted to the study of the capabilities of the Modelica and
Julia programming languages for the implementation of a continuously discrete
paradigm in modeling hybrid systems that contain both continuous and discrete
aspects of behavior. A system consisting of an incoming stream that is
processed according to the Transmission Control Protocol (TCP) and a router
that processes traffic using the Random Early Detection (RED) algorithm acts as
a simulated threshold system.
</summary>
    <author>
      <name>Anna Maria Yu. Apreutesey</name>
    </author>
    <author>
      <name>Anna V. Korolkova</name>
    </author>
    <author>
      <name>Dmitry S. Kulyabov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in English; in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in CEUR Workshop Proceedings, vol. 2639, 130-140 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.09488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.09488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.02746v2</id>
    <updated>2021-02-22T13:55:25Z</updated>
    <published>2020-12-04T17:55:30Z</published>
    <title>What the new RooFit can do for your analysis</title>
    <summary>  RooFit is a toolkit for statistical modelling and fitting, and together with
RooStats it is used for measurements and statistical tests by most experiments
in particle physics. Since one year, RooFit is being modernised. In this talk,
improvements already released with ROOT will be discussed, such as faster data
loading, vectorised computations and more standard-like interfaces. These allow
for speeding up unbinned fits by several factors, and make RooFit easier to use
from both C++ and Python.
</summary>
    <author>
      <name>Stephan Hageboeck</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.22323/1.390.0910</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.22323/1.390.0910" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, submitted to Proceedings of Science (ICHEP 2020)
  v2: Minor rephrasing to address comments by reviewers</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.02746v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.02746v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.03771v1</id>
    <updated>2020-11-30T10:25:20Z</updated>
    <published>2020-11-30T10:25:20Z</published>
    <title>Combined Sieve Algorithm for Prime Gaps</title>
    <summary>  A new Combined Sieve algorithm is presented with cost proportional to the
number of enumerated factors over a series of intervals. This algorithm
achieves a significant speedup, over a traditional sieve, when handling many
([10^4, 10^7]) intervals concurrently. The speedup comes from a space-time
tradeoff and a novel solution to a modular equation. In real world tests, this
new algorithm regularly runs 10,000x faster. This faster sieve paired with
higher sieving limits eliminates more composites and accelerates the search for
large prime gaps by 30-70%. During the development and testing of this new
algorithm, two top-10 record merit prime gaps were discovered.
</summary>
    <author>
      <name>Seth Troisi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, Open source code (GitHub), active development</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.03771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.03771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11N05 (Primary) 11N35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.02164v1</id>
    <updated>2021-01-06T17:57:44Z</updated>
    <published>2021-01-06T17:57:44Z</published>
    <title>A Julia implementation of Algorithm NCL for constrained optimization</title>
    <summary>  Algorithm NCL is designed for general smooth optimization problems where
first and second derivatives are available, including problems whose
constraints may not be linearly independent at a solution (i.e., do not satisfy
the LICQ). It is equivalent to the LANCELOT augmented Lagrangian method,
reformulated as a short sequence of nonlinearly constrained subproblems that
can be solved efficiently by IPOPT and KNITRO, with warm starts on each
subproblem. We give numerical results from a Julia implementation of Algorithm
NCL on tax policy models that do not satisfy the LICQ, and on nonlinear
least-squares problems and general problems from the CUTEst test set.
</summary>
    <author>
      <name>Ding Ma</name>
    </author>
    <author>
      <name>Dominique Orban</name>
    </author>
    <author>
      <name>Michael A. Saunders</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.29888.35841</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.29888.35841" rel="related"/>
    <link href="http://arxiv.org/abs/2101.02164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.02164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.00915v1</id>
    <updated>2021-03-01T11:09:40Z</updated>
    <published>2021-03-01T11:09:40Z</published>
    <title>TSSOS: a Julia library to exploit sparsity for large-scale polynomial
  optimization</title>
    <summary>  The Julia library TSSOS aims at helping polynomial optimizers to solve
large-scale problems with sparse input data. The underlying algorithmic
framework is based on exploiting correlative and term sparsity to obtain a new
moment-SOS hierarchy involving potentially much smaller positive semidefinite
matrices. TSSOS can be applied to numerous problems ranging from power networks
to eigenvalue and trace optimization of noncommutative polynomials, involving
up to tens of thousands of variables and constraints.
</summary>
    <author>
      <name>Victor Magron</name>
    </author>
    <author>
      <name>Jie Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.00915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.00915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.00917v2</id>
    <updated>2021-03-11T22:30:50Z</updated>
    <published>2021-03-01T11:14:01Z</published>
    <title>An open-source framework for ExpFinder integrating $N$-gram Vector Space
  Model and $μ$CO-HITS</title>
    <summary>  Finding experts drives successful collaborations and high-quality product
development in academic and research domains. To contribute to the expert
finding research community, we have developed ExpFinder which is a novel
ensemble model for expert finding by integrating an $N$-gram vector space model
($n$VSM) and a graph-based model ($\mu$CO-HITS). This paper provides
descriptions of ExpFinder's architecture, key components, functionalities, and
illustrative examples. ExpFinder is an effective and competitive model for
expert finding, significantly outperforming a number of expert finding models.
</summary>
    <author>
      <name>Hung Du</name>
    </author>
    <author>
      <name>Yong-Bin Kang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, "Submitted to Software Impacts"</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.00917v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.00917v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.12739v2</id>
    <updated>2021-07-12T12:40:58Z</updated>
    <published>2021-05-26T18:00:01Z</published>
    <title>Task inefficiency patterns for a wave equation solver</title>
    <summary>  The orchestration of complex algorithms demands high levels of automation to
use modern hardware efficiently. Task-based programming with OpenMP 5.0 is a
prominent candidate to accomplish this goal. We study OpenMP 5.0's tasking in
the context of a wave equation solver (ExaHyPE) using three different
architectures and runtimes. We describe several task-scheduling flaws present
in currently available runtimes, demonstrate how they impact performance and
show how to work around them. Finally, we propose extensions to the OpenMP
standard.
</summary>
    <author>
      <name>Holger Schulz</name>
    </author>
    <author>
      <name>Gonzalo Brito Gadeschi</name>
    </author>
    <author>
      <name>Oleksandr Rudyy</name>
    </author>
    <author>
      <name>Tobias Weinzierl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-85262-7_8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-85262-7_8" rel="related"/>
    <link href="http://arxiv.org/abs/2105.12739v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.12739v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.07126v1</id>
    <updated>2021-08-16T14:49:04Z</updated>
    <published>2021-08-16T14:49:04Z</published>
    <title>Parallel time integration using Batched BLAS (Basic Linear Algebra
  Subprograms) routines</title>
    <summary>  We present an approach for integrating the time evolution of quantum systems.
We leverage the computation power of graphics processing units (GPUs) to
perform the integration of all time steps in parallel. The performance boost is
especially prominent for small to medium-sized quantum systems. The devised
algorithm can largely be implemented using the recently-specified batched
versions of the BLAS routines, and can therefore be easily ported to a variety
of platforms. Our PARAllelized Matrix Exponentiation for Numerical Time
evolution (PARAMENT) implementation runs on CUDA-enabled graphics processing
units.
</summary>
    <author>
      <name>Konstantin Herb</name>
    </author>
    <author>
      <name>Pol Welter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2021.108181</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2021.108181" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages including source of the integration core in pseudo C code</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 270, 108181 (2022)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2108.07126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.07126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.10390v2</id>
    <updated>2021-11-01T15:00:58Z</updated>
    <published>2021-08-23T20:19:43Z</published>
    <title>Reachability of weakly nonlinear systems using Carleman linearization</title>
    <summary>  In this article we introduce a solution method for a special class of
nonlinear initial-value problems using set-based propagation techniques. The
novelty of the approach is that we employ a particular embedding (Carleman
linearization) to leverage recent advances of high-dimensional reachability
solvers for linear ordinary differential equations based on the support
function. Using a global error bound for the Carleman linearization
abstraction, we are able to describe the full set of behaviors of the system
for sets of initial conditions and in dense time.
</summary>
    <author>
      <name>Marcelo Forets</name>
    </author>
    <author>
      <name>Christian Schilling</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-89716-1_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-89716-1_6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Reachability Problems (pp. 85-99),
  2021. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2108.10390v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.10390v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.13061v2</id>
    <updated>2022-03-28T14:55:32Z</updated>
    <published>2021-08-30T08:43:23Z</published>
    <title>A New Test for Hamming-Weight Dependencies</title>
    <summary>  We describe a new statistical test for pseudorandom number generators
(PRNGs). Our test can find bias induced by dependencies among the Hamming
weights of the outputs of a PRNG, even for PRNGs that pass state-of-the-art
tests of the same kind from the literature, and in particular for generators
based on $\mathbf F_2$-linear transformations such as the dSFMT,
xoroshiro1024+, and WELL512.
</summary>
    <author>
      <name>David Blackman</name>
    </author>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1805.01407</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.13061v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.13061v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.14929v1</id>
    <updated>2021-09-30T08:56:39Z</updated>
    <published>2021-09-30T08:56:39Z</published>
    <title>Learning the Markov Decision Process in the Sparse Gaussian Elimination</title>
    <summary>  We propose a learning-based approach for the sparse Gaussian Elimination.
There are many hard combinatorial optimization problems in modern sparse
solver. These NP-hard problems could be handled in the framework of Markov
Decision Process, especially the Q-Learning technique. We proposed some
Q-Learning algorithms for the main modules of sparse solver: minimum degree
ordering, task scheduling and adaptive pivoting. Finally, we recast the sparse
solver into the framework of Q-Learning.
  Our study is the first step to connect these two classical mathematical
models: Gaussian Elimination and Markov Decision Process. Our learning-based
algorithm could help improve the performance of sparse solver, which has been
verified in some numerical experiments.
</summary>
    <author>
      <name>Yingshi Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages,2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.14929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.14929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.06209v2</id>
    <updated>2021-10-14T19:18:07Z</updated>
    <published>2021-10-12T00:10:28Z</published>
    <title>A Brief Introduction to Automatic Differentiation for Machine Learning</title>
    <summary>  Machine learning and neural network models in particular have been improving
the state of the art performance on many artificial intelligence related tasks.
Neural network models are typically implemented using frameworks that perform
gradient based optimization methods to fit a model to a dataset. These
frameworks use a technique of calculating derivatives called automatic
differentiation (AD) which removes the burden of performing derivative
calculations from the model designer. In this report we describe AD, its
motivations, and different implementation approaches. We briefly describe
dataflow programming as it relates to AD. Lastly, we present example programs
that are implemented with Tensorflow and PyTorch, which are two commonly used
AD frameworks.
</summary>
    <author>
      <name>Davan Harrison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2110.06209v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.06209v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.09244v1</id>
    <updated>2021-10-18T12:45:02Z</updated>
    <published>2021-10-18T12:45:02Z</published>
    <title>The search of Type I codes</title>
    <summary>  A self-dual binary linear code is called Type I code if it has singly-even
codewords, i.e.~it has codewords with weight divisible by $2.$ The purpose of
this paper is to investigate interesting properties of Type I codes of
different lengths. Further, we build up a computer-based code-searching program
based on our knowledge about Type I codes. Some computation results achieved by
this program are given.
</summary>
    <author>
      <name>Carolin Hannusch</name>
    </author>
    <author>
      <name>Roland S. Major</name>
    </author>
    <link href="http://arxiv.org/abs/2110.09244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.09244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.06718v1</id>
    <updated>2021-11-12T13:37:49Z</updated>
    <published>2021-11-12T13:37:49Z</published>
    <title>SimpleTensor -- a user-friendly Mathematica package for elementary
  tensor and differential-geometric calculations</title>
    <summary>  In this paper we present a short overview of the new Wolfram Mathematica
package intended for elementary "in-basis" tensor and differential-geometric
calculations. In contrast to alternatives our package is designed to be
easy-to-use, short, all-purpose, and hackable. It supports tensor contractions
using Einstein notation, transformations between different bases, tensor
derivative operator, expansion in basis vectors and forms, exterior derivative,
and interior product.
</summary>
    <author>
      <name>D. O. Rybalka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.06718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.06718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.09841v1</id>
    <updated>2021-11-18T18:07:32Z</updated>
    <published>2021-11-18T18:07:32Z</published>
    <title>Method for representing an exponent in a fifth-dimensional hypercomplex
  number systems using a hypercomplex computing software</title>
    <summary>  The structure of method for constructing a representation of an exponential
function in hypercomplex number systems(HNS) by the method of solving an
associated system of linear differential equations is considered. Brief
information about the hypercomplex computing software (HCS) is given. With the
use of HCS, the necessary cumbersome operations on symbolic expressions were
performed when constructing the representation of the exponent in the
fifth-dimensional HNS. Fragments of programs in the environment of HCS and
results of symbolic calculations are resulted
</summary>
    <author>
      <name>Y. Boiarinova</name>
    </author>
    <author>
      <name>Y. Kalinovskiy</name>
    </author>
    <link href="http://arxiv.org/abs/2111.09841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.09841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.11680v2</id>
    <updated>2022-11-15T11:45:27Z</updated>
    <published>2021-11-23T06:55:29Z</published>
    <title>Computing with B-series</title>
    <summary>  We present BSeries.jl, a Julia package for the computation and manipulation
of B-series, which are a versatile theoretical tool for understanding and
designing discretizations of differential equations. We give a short
introduction to the theory of B-series and associated concepts and provide
examples of their use, including method composition and backward error
analysis. The associated software is highly performant and makes it possible to
work with B-series of high order.
</summary>
    <author>
      <name>David I. Ketcheson</name>
    </author>
    <author>
      <name>Hendrik Ranocha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3573384</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3573384" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Mathematical Software, 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2111.11680v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.11680v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.02934v1</id>
    <updated>2021-12-06T11:13:47Z</updated>
    <published>2021-12-06T11:13:47Z</published>
    <title>AIMpy: A Python code to solve Schrödinger-like equations with the
  asymptotic iteration method</title>
    <summary>  This paper is dedicated to present an open-source program so-called
\emph{AIMpy} built on Python language. \emph{AIMpy} is a solver for
Schr\"{o}dinger-like differential equations using Asymptotic Iteration Method
(AIM). To confirm the code works seamlessly, it has been shown through the
paper with recalculation of some previously studied eigenvalue examples that
the code can reproduce their results very well.
</summary>
    <author>
      <name>Mesut Karakoç</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0129183121500170</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0129183121500170" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Modern Physics C Vol. 32, No. 02, 2150017
  (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2112.02934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.02934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.06617v1</id>
    <updated>2021-12-10T14:24:28Z</updated>
    <published>2021-12-10T14:24:28Z</published>
    <title>(R)SE challenges in HPC</title>
    <summary>  We discuss some specific software engineering challenges in the field of
high-performance computing, and argue that the slow adoption of SE tools and
techniques is at least in part caused by the fact that these do not address the
HPC challenges `out-of-the-box'. By giving some examples of solutions for
designing, testing and benchmarking HPC software, we intend to bring software
engineering and HPC closer together.
</summary>
    <author>
      <name>Jonas Thies</name>
    </author>
    <author>
      <name>Melven Röhrig-Zöllner</name>
    </author>
    <author>
      <name>Achim Basermann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, whitepaper for the RSE-HPC-2021 workshop on the SC'21,
  https://us-rse.org/rse-hpc-2021/</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.06617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.06617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.11880v1</id>
    <updated>2021-12-22T14:04:53Z</updated>
    <published>2021-12-22T14:04:53Z</published>
    <title>Iterative Krylov Methods for Acoustic Problems on Graphics Processing
  Unit</title>
    <summary>  This paper deals with linear algebra operations on Graphics Processing Unit
(GPU) with complex number arithmetic using double precision. An analysis of
their uses within iterative Krylov methods is presented to solve acoustic
problems. Numerical experiments performed on a set of acoustic matrices arising
from the modelisation of acoustic phenomena inside a car compartment are
collected, and outline the performance, robustness and effectiveness of our
algorithms, with a speed-up up to 28x for dot product, 9.8x for sparse
matrix-vector product and solvers.
</summary>
    <author>
      <name>Abal-Kassim Cheik Ahamed</name>
    </author>
    <author>
      <name>Frederic Magoules</name>
    </author>
    <link href="http://arxiv.org/abs/2112.11880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.11880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.01339v1</id>
    <updated>2022-04-04T09:22:42Z</updated>
    <published>2022-04-04T09:22:42Z</published>
    <title>mVEM: A MATLAB Software Package for the Virtual Element Methods</title>
    <summary>  This paper summarizes the development of mVEM, a MATLAB software package
containing efficient and easy-following codes for various virtual element
methods (VEMs) published in the literature. We explain in detail the numerical
implementation of the mixed VEMs for the Darcy problem and the
three-dimensional linear VEMs for the Poisson equation. For other model
problems, we present the construction of the discrete methods and only provide
the implementation of the elliptic projection matrices. Some mesh related
functions are also given in the package, including the mesh generation and
refinement in two or three dimensions. mVEM is free and open source software.
</summary>
    <author>
      <name>Yue Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">mVEM</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.01339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.01339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.01488v1</id>
    <updated>2022-03-17T19:42:52Z</updated>
    <published>2022-03-17T19:42:52Z</published>
    <title>Training the next generation of computational scientists through a new
  undergraduate course</title>
    <summary>  We introduce a newly designed undergraduate-level interdisciplinary course in
scientific computing that aims to prepare students as the next generation of
research-oriented computational scientists and engineers. The course offers
students opportunities to explore a diverse set of projects and develop the
necessary programming skills to implement ideas and algorithms within high
performance computing environments. The training includes how to think about,
formulate, organize, and implement programs in scientific computing. The
emphasis of the course is on problem solving within a wide range of
applications in science and engineering.
</summary>
    <author>
      <name>Tulin Kaman</name>
    </author>
    <author>
      <name>Rouben Rostamian</name>
    </author>
    <author>
      <name>Shannon W. Dingman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.01488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.01488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97C90" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.4369v1</id>
    <updated>2007-05-30T11:34:39Z</updated>
    <published>2007-05-30T11:34:39Z</published>
    <title>Computing Integer Powers in Floating-Point Arithmetic</title>
    <summary>  We introduce two algorithms for accurately evaluating powers to a positive
integer in floating-point arithmetic, assuming a fused multiply-add (fma)
instruction is available. We show that our log-time algorithm always produce
faithfully-rounded results, discuss the possibility of getting correctly
rounded results, and show that results correctly rounded in double precision
can be obtained if extended-precision is available with the possibility to
round into double precision (with a single rounding).
</summary>
    <author>
      <name>Peter Kornerup</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMADA</arxiv:affiliation>
    </author>
    <author>
      <name>Vincent Lefèvre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Michel Muller</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Laboratoire LIP : CNRS/ENS Lyon/INRIA/Universit\'e Lyon 1</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.4369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.4369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4324v1</id>
    <updated>2011-05-22T09:57:05Z</updated>
    <published>2011-05-22T09:57:05Z</published>
    <title>A search for an optimal start system for numerical homotopy continuation</title>
    <summary>  We use our recent implementation of a certified homotopy tracking algorithm
to search for start systems that minimize the average complexity of finding all
roots of a regular system of polynomial equations. While finding optimal start
systems is a hard problem, our experiments show that it is possible to find
start systems that deliver better average complexity than the ones that are
commonly used in the existing homotopy continuation software.
</summary>
    <author>
      <name>Anton Leykin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y20, 14Q99, 68N01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4881v2</id>
    <updated>2012-10-10T18:53:24Z</updated>
    <published>2011-05-24T20:15:08Z</published>
    <title>PHCpack in Macaulay2</title>
    <summary>  The Macaulay2 package PHCpack.m2 provides an interface to PHCpack, a
general-purpose polynomial system solver that uses homotopy continuation. The
main method is a numerical blackbox solver which is implemented for all Laurent
systems. The package also provides a fast mixed volume computation, the ability
to filter solutions, homotopy path tracking, and a numerical irreducible
decomposition method. As the size of many problems in applied algebraic
geometry often surpasses the capabilities of symbolic software, this package
will be of interest to those working on problems involving large polynomial
systems.
</summary>
    <author>
      <name>Elizabeth Gross</name>
    </author>
    <author>
      <name>Sonja Petrović</name>
    </author>
    <author>
      <name>Jan Verschelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, exposition and examples improved</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4881v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4881v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65H10 (Primary) 14Q99 (Secondary) 68W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.6314v1</id>
    <updated>2011-05-31T15:25:33Z</updated>
    <published>2011-05-31T15:25:33Z</published>
    <title>Activity-Based Search for Black-Box Contraint-Programming Solvers</title>
    <summary>  Robust search procedures are a central component in the design of black-box
constraint-programming solvers. This paper proposes activity-based search, the
idea of using the activity of variables during propagation to guide the search.
Activity-based search was compared experimentally to impact-based search and
the WDEG heuristics. Experimental results on a variety of benchmarks show that
activity-based search is more robust than other heuristics and may produce
significant improvements in performance.
</summary>
    <author>
      <name>L. Michel</name>
    </author>
    <author>
      <name>P. Van Hentenryck</name>
    </author>
    <link href="http://arxiv.org/abs/1105.6314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.6314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4523v1</id>
    <updated>2011-12-19T22:51:21Z</updated>
    <published>2011-12-19T22:51:21Z</published>
    <title>Complexity and Algorithms for Euler Characteristic of Simplicial
  Complexes</title>
    <summary>  We consider the problem of computing the Euler characteristic of an abstract
simplicial complex given by its vertices and facets. We show that this problem
is #P-complete and present two new practical algorithms for computing Euler
characteristic. The two new algorithms are derived using combinatorial
commutative algebra and we also give a second description of them that requires
no algebra. We present experiments showing that the two new algorithms can be
implemented to be faster than previous Euler characteristic implementations by
a large margin.
</summary>
    <author>
      <name>Bjarke Hammersholt Roune</name>
    </author>
    <author>
      <name>Eduardo Sáenz de Cabezón</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.4523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2951v1</id>
    <updated>2012-10-10T15:13:55Z</updated>
    <published>2012-10-10T15:13:55Z</published>
    <title>Regular and Singular Boundary Problems in Maple</title>
    <summary>  We describe a new Maple package for treating boundary problems for linear
ordinary differential equations, allowing two-/multipoint as well as Stieltjes
boundary conditions. For expressing differential operators, boundary
conditions, and Green's operators, we employ the algebra of
integro-differential operators. The operations implemented for regular boundary
problems include computing Green's operators as well as composing and factoring
boundary problems. Our symbolic approach to singular boundary problems is new;
it provides algorithms for computing compatibility conditions and generalized
Green's operators.
</summary>
    <author>
      <name>Anja Korporal</name>
    </author>
    <author>
      <name>Georg Regensburger</name>
    </author>
    <author>
      <name>Markus Rosenkranz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-23568-9_22</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-23568-9_22" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages; Berlin/Heidelberg, Springer</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Algebra in Scientific Computing (CASC 2011), LNCS 6885,
  pp. 280-293, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.2951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5771v1</id>
    <updated>2013-06-24T20:22:29Z</updated>
    <published>2013-06-24T20:22:29Z</published>
    <title>Panphasia: a user guide</title>
    <summary>  We make a very large realisation of a Gaussian white noise field, called
PANPHASIA, public by releasing software that computes this field. Panphasia is
designed specifically for setting up Gaussian initial conditions for
cosmological simulations and resimulations of structure formation. We make
available both software to compute the field itself and codes to illustrate
applications including a modified version of a public serial initial conditions
generator. We document the software and present the results of a few basic
tests of the field. The properties and method of construction of Panphasia are
described in full in a companion paper Jenkins 2013.
</summary>
    <author>
      <name>Adrian Jenkins</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICC, Durham</arxiv:affiliation>
    </author>
    <author>
      <name>Stephen Booth</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EPCC, Edinburgh</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures. Software to calculate Panphasia is available
  from: http://icc.dur.ac.uk/Panphasia.php</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6291v4</id>
    <updated>2015-02-16T19:20:56Z</updated>
    <published>2013-06-26T16:57:40Z</published>
    <title>A Method for Fast Diagonalization of a 2x2 or 3x3 Real Symmetric Matrix</title>
    <summary>  A method is presented for fast diagonalization of a 2x2 or 3x3 real symmetric
matrix, that is determination of its eigenvalues and eigenvectors. The Euler
angles of the eigenvectors are computed. A small computer algebra program is
used to compute some of the identities, and a C++ program for testing the
formulas has been uploaded to arXiv.
</summary>
    <author>
      <name>M. J. Kronenburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected formula 4.12</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.6291v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6291v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.05814v1</id>
    <updated>2017-11-15T21:26:09Z</updated>
    <published>2017-11-15T21:26:09Z</published>
    <title>Python Implementation and Construction of Finite Abelian Groups</title>
    <summary>  Here we present a working framework to establish finite abelian groups in
python. The primary aim is to allow new A-level students to work with examples
of finite abelian groups using open source software. We include the code used
in the implementation of the framework. We also prove some useful results
regarding finite abelian groups which are used to establish the functions and
help show how number theoretic results can blend with computational power when
studying algebra. The groups established are based modular multiplication and
addition. We include direct products of cyclic groups meaning the user has
access to all finite abelian groups.
</summary>
    <author>
      <name>Paul Bradley</name>
    </author>
    <author>
      <name>John Smethurst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.05814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.05814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60-04, 20-04" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.07790v1</id>
    <updated>2017-11-17T13:44:33Z</updated>
    <published>2017-11-17T13:44:33Z</published>
    <title>Solving Poisson's Equation on the Microsoft HoloLens</title>
    <summary>  We present a mixed reality application (HoloFEM) for the Microsoft HoloLens.
The application lets a user define and solve a physical problem governed by
Poisson's equation with the surrounding real world geometry as input data.
Holograms are used to visualise both the problem and the solution. The finite
element method is used to solve Poisson's equation. Solving and visualising
partial differential equations in mixed reality could have potential usage in
areas such as building planning and safety engineering.
</summary>
    <author>
      <name>Anders Logg</name>
    </author>
    <author>
      <name>Carl Lundholm</name>
    </author>
    <author>
      <name>Magne Nordaas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3139131.3141777</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3139131.3141777" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 23rd ACM Symposium on Virtual Reality
  Software and Technology (VRST 2017). ACM, New York, NY, USA, Article 87</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1711.07790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.07790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.02201v1</id>
    <updated>2018-05-06T12:31:55Z</updated>
    <published>2018-05-06T12:31:55Z</published>
    <title>RealCertify: a Maple package for certifying non-negativity</title>
    <summary>  Let $\mathbb{Q}$ (resp. $\mathbb{R}$) be the field of rational (resp. real)
numbers and $X = (X_1, \ldots, X_n)$ be variables. Deciding the non-negativity
of polynomials in $\mathbb{Q}[X]$ over $\mathbb{R}^n$ or over semi-algebraic
domains defined by polynomial constraints in $\mathbb{Q}[X]$ is a classical
algorithmic problem for symbolic computation.
  The Maple package \textsc{RealCertify} tackles this decision problem by
computing sum of squares certificates of non-negativity for inputs where such
certificates hold over the rational numbers. It can be applied to numerous
problems coming from engineering sciences, program verification and
cyber-physical systems. It is based on hybrid symbolic-numeric algorithms based
on semi-definite programming.
</summary>
    <author>
      <name>Victor Magron</name>
    </author>
    <author>
      <name>Mohab Safey El Din</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.02201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.02201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.03467v3</id>
    <updated>2019-04-12T18:49:20Z</updated>
    <published>2018-12-09T12:16:33Z</published>
    <title>A note on solving nonlinear optimization problems in variable precision</title>
    <summary>  This short note considers an efficient variant of the trust-region algorithm
with dynamic accuracy proposed Carter (1993) and Conn, Gould and Toint (2000)
as a tool for very high-performance computing, an area where it is critical to
allow multi-precision computations for keeping the energy dissipation under
control. Numerical experiments are presented indicating that the use of the
considered method can bring substantial savings in objective function's and
gradient's evaluation "energy costs" by efficiently exploiting multi-precision
computations.
</summary>
    <author>
      <name>S. Gratton</name>
    </author>
    <author>
      <name>Ph. L. Toint</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.03467v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.03467v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C26, 90C30, 65K05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; F.2.1; B.2.3; B.2.4; I.2.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.04175v1</id>
    <updated>2020-08-10T14:57:41Z</updated>
    <published>2020-08-10T14:57:41Z</published>
    <title>EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,
  and NumPy</title>
    <summary>  EagerPy is a Python framework that lets you write code that automatically
works natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no
longer need to choose between supporting just one of these frameworks or
reimplementing the library for each framework and dealing with code
duplication. Users of such libraries can more easily switch frameworks without
being locked in by a specific 3rd party library. Beyond multi-framework
support, EagerPy also brings comprehensive type annotations and consistent
support for method chaining to any framework. The latest documentation is
available online at https://eagerpy.jonasrauber.de and the code can be found on
GitHub at https://github.com/jonasrauber/eagerpy.
</summary>
    <author>
      <name>Jonas Rauber</name>
    </author>
    <author>
      <name>Matthias Bethge</name>
    </author>
    <author>
      <name>Wieland Brendel</name>
    </author>
    <link href="http://arxiv.org/abs/2008.04175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.04175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.06992v2</id>
    <updated>2020-12-29T03:46:58Z</updated>
    <published>2020-08-16T20:37:28Z</published>
    <title>Elmer FEM-Dakota: A unified open-source computational framework for
  electromagnetics and data analytics</title>
    <summary>  Open-source electromagnetic design software, Elmer FEM, was interfaced with
data analytics toolkit, Dakota. Furthermore, the coupled software was validated
against a benchmark test. The interface developed provides a unified
open-source computational framework for electromagnetics and data analytics.
Its key features include uncertainty quantification, surrogate modelling and
parameter studies. This framework enables a richer understanding of model
predictions to better design electric machines in a time sensitive manner.
</summary>
    <author>
      <name>Anjali Sandip</name>
    </author>
    <link href="http://arxiv.org/abs/2008.06992v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.06992v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.07919v2</id>
    <updated>2021-02-01T13:59:46Z</updated>
    <published>2020-11-16T13:12:33Z</published>
    <title>A simple technique for unstructured mesh generation via adaptive finite
  elements</title>
    <summary>  This work describes a concise algorithm for the generation of triangular
meshes with the help of standard adaptive finite element methods. We
demonstrate that a generic adaptive finite element solver can be repurposed
into a triangular mesh generator if a robust mesh smoothing algorithm is
applied between the mesh refinement steps. We present an implementation of the
mesh generator and demonstrate the resulting meshes via examples.
</summary>
    <author>
      <name>Tom Gustafsson</name>
    </author>
    <link href="http://arxiv.org/abs/2011.07919v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.07919v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.08126v2</id>
    <updated>2021-01-13T20:54:38Z</updated>
    <published>2020-11-16T17:46:50Z</published>
    <title>Threaded Gröbner Bases: a Macaulay2 package</title>
    <summary>  The complexity of Gr\"{o}bner computations has inspired many improvements to
Buchberger's algorithm over the years. Looking for further insights into the
algorithm's performance, we offer a threaded implementation of classical
Buchberger's algorithm in {\it Macaulay2}. The output of the main function of
the package includes information about {\it lineages} of non-zero remainders
that are added to the basis during the computation. This information can be
used for further algorithm improvements and optimization.
</summary>
    <author>
      <name>Sonja Petrović</name>
    </author>
    <author>
      <name>Shahrzad Jamshidi Zelenberg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2140/jsag.2021.11.123</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2140/jsag.2021.11.123" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, package in revision</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Softw. Alg. Geom. 11 (2021) 123-127</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2011.08126v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.08126v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="13P10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.11430v2</id>
    <updated>2020-11-24T10:53:43Z</updated>
    <published>2020-11-23T14:33:31Z</published>
    <title>Automatic differentiation of Sylvester, Lyapunov, and algebraic Riccati
  equations</title>
    <summary>  Sylvester, Lyapunov, and algebraic Riccati equations are the bread and butter
of control theorists. They are used to compute infinite-horizon Gramians, solve
optimal control problems in continuous or discrete time, and design observers.
While popular numerical computing frameworks (e.g., scipy) provide efficient
solvers for these equations, these solvers are still largely missing from most
automatic differentiation libraries. Here, we derive the forward and
reverse-mode derivatives of the solutions to all three types of equations, and
showcase their application on an inverse control problem.
</summary>
    <author>
      <name>Ta-Chu Kao</name>
    </author>
    <author>
      <name>Guillaume Hennequin</name>
    </author>
    <link href="http://arxiv.org/abs/2011.11430v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.11430v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.11762v1</id>
    <updated>2020-11-23T22:04:50Z</updated>
    <published>2020-11-23T22:04:50Z</published>
    <title>The Chunks and Tasks Matrix Library 2.0</title>
    <summary>  We present a C++ header-only parallel sparse matrix library, based on sparse
quadtree representation of matrices using the Chunks and Tasks programming
model. The library implements a number of sparse matrix algorithms for
distributed memory parallelization that are able to dynamically exploit data
locality to avoid movement of data. This is demonstrated for the example of
block-sparse matrix-matrix multiplication applied to three sequences of
matrices with different nonzero structure, using the CHT-MPI 2.0 runtime
library implementation of the Chunks and Tasks model. The runtime library
succeeds to dynamically load balance the calculation regardless of the sparsity
structure.
</summary>
    <author>
      <name>Emanuel H. Rubensson</name>
    </author>
    <author>
      <name>Elias Rudberg</name>
    </author>
    <author>
      <name>Anastasia Kruchinina</name>
    </author>
    <author>
      <name>Anton G. Artemov</name>
    </author>
    <link href="http://arxiv.org/abs/2011.11762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.11762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; G.1.3; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.07670v1</id>
    <updated>2021-02-15T16:58:19Z</updated>
    <published>2021-02-15T16:58:19Z</published>
    <title>A computer algebra system for the study of commutativity up-to-coherent
  homotopies</title>
    <summary>  The Python package ComCH is a lightweight specialized computer algebra system
that provides models for well known objects, the surjection and Barratt-Eccles
operads, parameterizing the product structure of algebras that are commutative
in a derived sense. The primary examples of such algebras treated by ComCH are
the cochain complexes of spaces, for which it provides effective constructions
of Steenrod cohomology operations at all prime.
</summary>
    <author>
      <name>Anibal M. Medina-Mardones</name>
    </author>
    <link href="http://arxiv.org/abs/2102.07670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.07670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 55-04, 18M60, Secondary 55S05, 18M70, 55N31" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.04097v1</id>
    <updated>2021-07-08T20:31:05Z</updated>
    <published>2021-07-08T20:31:05Z</published>
    <title>Decomposition algorithms for tensors and polynomials</title>
    <summary>  We give algorithms to compute decompositions of a given polynomial, or more
generally mixed tensor, as sum of rank one tensors, and to establish whether
such a decomposition is unique. In particular, we present methods to compute
the decomposition of a general plane quintic in seven powers, and of a general
space cubic in five powers; the two decompositions of a general plane sextic of
rank nine, and the five decompositions of a general plane septic. Furthermore,
we give Magma implementations of all our algorithms.
</summary>
    <author>
      <name>Antonio Laface</name>
    </author>
    <author>
      <name>Alex Massarenti</name>
    </author>
    <author>
      <name>Rick Rischter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.04097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.04097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 14N07, Secondary 14N05, 51N35, 14Q15, 14N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.12322v1</id>
    <updated>2021-07-26T16:51:44Z</updated>
    <published>2021-07-26T16:51:44Z</published>
    <title>MLDev: Data Science Experiment Automation and Reproducibility Software</title>
    <summary>  In this paper we explore the challenges of automating experiments in data
science. We propose an extensible experiment model as a foundation for
integration of different open source tools for running research experiments. We
implement our approach in a prototype open source MLDev software package and
evaluate it in a series of experiments yielding promising results. Comparison
with other state-of-the-art tools signifies novelty of our approach.
</summary>
    <author>
      <name>Anton Khritankov</name>
    </author>
    <author>
      <name>Nikita Pershin</name>
    </author>
    <author>
      <name>Nikita Ukhov</name>
    </author>
    <author>
      <name>Artem Ukhov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-12285-9_1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-12285-9_1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">DAMDID/RCDL-2021, CCIS vol. 1620 (2022), Springer Cham, 3-18</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2107.12322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.12322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00534v1</id>
    <updated>2022-01-03T09:24:34Z</updated>
    <published>2022-01-03T09:24:34Z</published>
    <title>On Automating Triangle Constructions in Absolute and Hyperbolic Geometry</title>
    <summary>  We describe first steps towards a system for automated triangle constructions
in absolute and hyperbolic geometry. We discuss key differences between
constructions in Euclidean, absolute and hyperbolic geometry, compile a list of
primitive constructions and lemmas used for constructions in absolute and
hyperbolic geometry, build an automated system for solving construction
problems and test it on a corpus of triangle-construction problems. We also
provide an online compendium containing construction descriptions and
illustrations.
</summary>
    <author>
      <name>Vesna Marinković</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Faculty of Mathematics, University of Belgrade, Serbia</arxiv:affiliation>
    </author>
    <author>
      <name>Tijana Šukilović</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Faculty of Mathematics, University of Belgrade, Serbia</arxiv:affiliation>
    </author>
    <author>
      <name>Filip Marić</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Faculty of Mathematics, University of Belgrade, Serbia</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.352.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.352.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ADG 2021, arXiv:2112.14770</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 352, 2021, pp. 14-26</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2201.00534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00539v1</id>
    <updated>2022-01-03T09:26:01Z</updated>
    <published>2022-01-03T09:26:01Z</published>
    <title>Mechanization of Incidence Projective Geometry in Higher Dimensions, a
  Combinatorial Approach</title>
    <summary>  Several tools have been developed to enhance automation of theorem proving in
the 2D plane. However, in 3D, only a few approaches have been studied, and to
our knowledge, nothing has been done in higher dimensions. In this paper, we
present a few examples of incidence geometry theorems in dimensions 3, 4, and
5. We then prove them with the help of a combinatorial prover based on matroid
theory applied to geometry.
</summary>
    <author>
      <name>Pascal Schreck</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICube, UMR 7357 CNRS Université de Strasbourg, France</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Magaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICube, UMR 7357 CNRS Université de Strasbourg, France</arxiv:affiliation>
    </author>
    <author>
      <name>David Braun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICube, UMR 7357 CNRS Université de Strasbourg, France</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.352.8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.352.8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ADG 2021, arXiv:2112.14770</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 352, 2021, pp. 77-90</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2201.00539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.04820v2</id>
    <updated>2023-06-09T16:20:37Z</updated>
    <published>2022-02-10T03:51:25Z</published>
    <title>L0Learn: A Scalable Package for Sparse Learning using L0 Regularization</title>
    <summary>  We present L0Learn: an open-source package for sparse linear regression and
classification using $\ell_0$ regularization. L0Learn implements scalable,
approximate algorithms, based on coordinate descent and local combinatorial
optimization. The package is built using C++ and has user-friendly R and Python
interfaces. L0Learn can address problems with millions of features, achieving
competitive run times and statistical performance with state-of-the-art sparse
learning packages. L0Learn is available on both CRAN and GitHub
(https://cran.r-project.org/package=L0Learn and
https://github.com/hazimehh/L0Learn).
</summary>
    <author>
      <name>Hussein Hazimeh</name>
    </author>
    <author>
      <name>Rahul Mazumder</name>
    </author>
    <author>
      <name>Tim Nonet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to JMLR (MLOSS)</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.04820v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.04820v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.07382v1</id>
    <updated>2022-02-15T13:20:14Z</updated>
    <published>2022-02-15T13:20:14Z</published>
    <title>Phase Vocoder Done Right</title>
    <summary>  The phase vocoder (PV) is a widely spread technique for processing audio
signals. It employs a short-time Fourier transform (STFT)
analysis-modify-synthesis loop and is typically used for time-scaling of
signals by means of using different time steps for STFT analysis and synthesis.
The main challenge of PV used for that purpose is the correction of the STFT
phase. In this paper, we introduce a novel method for phase correction based on
phase gradient estimation and its integration. The method does not require
explicit peak picking and tracking nor does it require detection of transients
and their separate treatment. Yet, the method does not suffer from the typical
phase vocoder artifacts even for extreme time stretching factors.
</summary>
    <author>
      <name>Zdenek Prusa</name>
    </author>
    <author>
      <name>Nicki Holighaus</name>
    </author>
    <link href="http://arxiv.org/abs/2202.07382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.07382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.07498v1</id>
    <updated>2022-02-15T15:11:54Z</updated>
    <published>2022-02-15T15:11:54Z</published>
    <title>Non-iterative Filter Bank Phase (Re)Construction</title>
    <summary>  Signal reconstruction from magnitude-only measurements presents a
long-standing problem in signal processing. In this contribution, we propose a
phase (re)construction method for filter banks with uniform decimation and
controlled frequency variation. The suggested procedure extends the recently
introduced phase-gradient heap integration and relies on a phase-magnitude
relationship for filter bank coefficients obtained from Gaussian filters.
Admissible filter banks are modeled as the discretization of certain
generalized translation-invariant systems, for which we derive the
phase-magnitude relationship explicitly. The implementation for discrete
signals is described and the performance of the algorithm is evaluated on a
range of real and synthetic signals.
</summary>
    <author>
      <name>Zdeněk Průša</name>
    </author>
    <author>
      <name>Nicki Holighaus</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.23919/EUSIPCO.2017.8081342</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.23919/EUSIPCO.2017.8081342" rel="related"/>
    <link href="http://arxiv.org/abs/2202.07498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.07498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.15447v1</id>
    <updated>2022-05-30T22:08:47Z</updated>
    <published>2022-05-30T22:08:47Z</published>
    <title>Holistic Generalized Linear Models</title>
    <summary>  Holistic linear regression extends the classical best subset selection
problem by adding additional constraints designed to improve the model quality.
These constraints include sparsity-inducing constraints, sign-coherence
constraints and linear constraints. The $\textsf{R}$ package $\texttt{holiglm}$
provides functionality to model and fit holistic generalized linear models. By
making use of state-of-the-art conic mixed-integer solvers, the package can
reliably solve GLMs for Gaussian, binomial and Poisson responses with a
multitude of holistic constraints. The high-level interface simplifies the
constraint specification and can be used as a drop-in replacement for the
$\texttt{stats::glm()}$ function.
</summary>
    <author>
      <name>Benjamin Schwendinger</name>
    </author>
    <author>
      <name>Florian Schwendinger</name>
    </author>
    <author>
      <name>Laura Vana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 2 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.15447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.15447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.03166v2</id>
    <updated>2023-06-28T09:41:29Z</updated>
    <published>2022-06-07T10:27:23Z</published>
    <title>A novel statistical approach for two-sample testing based on the overlap
  coefficient</title>
    <summary>  Here we propose a new nonparametric framework for two-sample testing, named
as the OVL-$q$ ($q = 1, 2, \ldots$). This can be regarded as a natural
extension of the Smirnov test, which is equivalent to the OVL-1. We
specifically focus on the OVL-2, implement its fast algorithm, and show its
superiority over other statistical tests in some experiments.
</summary>
    <author>
      <name>Atsushi Komaba</name>
    </author>
    <author>
      <name>Hisashi Johno</name>
    </author>
    <author>
      <name>Kazunori Nakamoto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 5 figures. Accepted for publication in Journal of
  Mathematical Sciences, the University of Tokyo</arxiv:comment>
    <link href="http://arxiv.org/abs/2206.03166v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.03166v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G10 (Primary), 62-04 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.11128v2</id>
    <updated>2022-09-21T07:06:51Z</updated>
    <published>2022-06-22T14:19:15Z</published>
    <title>tntorch: Tensor Network Learning with PyTorch</title>
    <summary>  We present tntorch, a tensor learning framework that supports multiple
decompositions (including Candecomp/Parafac, Tucker, and Tensor Train) under a
unified interface. With our library, the user can learn and handle low-rank
tensors with automatic differentiation, seamless GPU support, and the
convenience of PyTorch's API. Besides decomposition algorithms, tntorch
implements differentiable tensor algebra, rank truncation, cross-approximation,
batch processing, comprehensive tensor arithmetics, and more.
</summary>
    <author>
      <name>Mikhail Usvyatsov</name>
    </author>
    <author>
      <name>Rafael Ballester-Ripoll</name>
    </author>
    <author>
      <name>Konrad Schindler</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JMLR (2022) 23-208</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2206.11128v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.11128v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.03921v1</id>
    <updated>2022-07-08T14:22:20Z</updated>
    <published>2022-07-08T14:22:20Z</published>
    <title>nlfem: A flexible 2d Fem Code for Nonlocal Convection-Diffusion and
  Mechanics</title>
    <summary>  In this work we present the mathematical foundation of an assembly code for
finite element approximations of nonlocal models with compactly supported,
weakly singular kernels. We demonstrate the code on a nonlocal diffusion model
in various configurations and on a two-dimensional bond-based peridynamics
model. The code nlfem is published under the MIT License and can be freely
downloaded.
</summary>
    <author>
      <name>Manuel Klar</name>
    </author>
    <author>
      <name>Christian Vollmann</name>
    </author>
    <author>
      <name>Volker Schulz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2207.03921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.03921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.13802v1</id>
    <updated>2022-07-27T21:33:18Z</updated>
    <published>2022-07-27T21:33:18Z</published>
    <title>Digital Nets and Sequences for Quasi-Monte Carlo Methods</title>
    <summary>  Quasi-Monte Carlo methods are a way of improving the efficiency of Monte
Carlo methods. Digital nets and sequences are one of the low discrepancy point
sets used in quasi-Monte Carlo methods. This thesis presents the three new
results pertaining to digital nets and sequences: implementing randomized
digital nets, finding the distribution of the discrepancy of scrambled digital
nets, and obtaining better quality of digital nets through evolutionary
computation. Finally, applications of scrambled and non-scrambled digital nets
are provided.
</summary>
    <author>
      <name>Hee Sun Hong</name>
    </author>
    <link href="http://arxiv.org/abs/2207.13802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.13802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.05250v1</id>
    <updated>2022-09-08T20:16:41Z</updated>
    <published>2022-09-08T20:16:41Z</published>
    <title>Looplets: A Language For Structured Coiteration</title>
    <summary>  Real world arrays often contain underlying structure, such as sparsity, runs
of repeated values, or symmetry. Specializing for structure yields significant
speedups. But automatically generating efficient code for structured data is
challenging, especially when arrays with different structure interact. We show
how to abstract over array structures so that the compiler can generate code to
coiterate over any combination of them. Our technique enables new array formats
(such as 1DVBL for irregular clustered sparsity), new iteration strategies
(such as galloping intersections), and new operations over structured data
(such as concatenation or convolution).
</summary>
    <author>
      <name>Willow Ahrens</name>
    </author>
    <author>
      <name>Daniel Donenfeld</name>
    </author>
    <author>
      <name>Fredrik Kjolstad</name>
    </author>
    <author>
      <name>Saman Amarasinghe</name>
    </author>
    <link href="http://arxiv.org/abs/2209.05250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.05250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.09145v1</id>
    <updated>2022-09-19T16:04:57Z</updated>
    <published>2022-09-19T16:04:57Z</published>
    <title>IGraph/M: graph theory and network analysis for Mathematica</title>
    <summary>  IGraph/M is an efficient general purpose graph theory and network analysis
package for Mathematica. IGraph/M serves as the Wolfram Language interfaces to
the igraph C library, and also provides several unique pieces of functionality
not yet present in igraph, but made possible by combining its capabilities with
Mathematica's. The package is designed to support both graph theoretical
research as well as the analysis of large-scale empirical networks.
</summary>
    <author>
      <name>Szabolcs Horvát</name>
    </author>
    <author>
      <name>Jakub Podkalicki</name>
    </author>
    <author>
      <name>Gábor Csárdi</name>
    </author>
    <author>
      <name>Tamás Nepusz</name>
    </author>
    <author>
      <name>Vincent Traag</name>
    </author>
    <author>
      <name>Fabio Zanini</name>
    </author>
    <author>
      <name>Daniel Noom</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/joss.04899</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/joss.04899" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Journal of Open Source Software on August 30, 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.09145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.09145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.03813v1</id>
    <updated>2022-10-07T20:50:53Z</updated>
    <published>2022-10-07T20:50:53Z</published>
    <title>MOS: A Mathematical Optimization Service</title>
    <summary>  We introduce MOS, a software application designed to facilitate the
deployment, integration, management, and analysis of mathematical optimization
models. MOS approaches mathematical optimization at a higher level of
abstraction than existing optimization modeling systems, enabling its use with
all of them. The sole requirement to harness MOS is a simple annotation of the
code specifying the formulation of an optimization model. With this, the model
becomes accessible to humans through the automatic generation of a user
interface, and to machines through an associated API and client libraries. All
this is achieved while avoiding the ad hoc code typically required to obtain
such features.
</summary>
    <author>
      <name>James Hubert Merrick</name>
    </author>
    <author>
      <name>Tomás Tinoco De Rubira</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.03813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.03813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.04840v1</id>
    <updated>2022-10-10T16:55:32Z</updated>
    <published>2022-10-10T16:55:32Z</published>
    <title>Rieoptax: Riemannian Optimization in JAX</title>
    <summary>  We present Rieoptax, an open source Python library for Riemannian
optimization in JAX. We show that many differential geometric primitives, such
as Riemannian exponential and logarithm maps, are usually faster in Rieoptax
than existing frameworks in Python, both on CPU and GPU. We support various
range of basic and advanced stochastic optimization solvers like Riemannian
stochastic gradient, stochastic variance reduction, and adaptive gradient
methods. A distinguishing feature of the proposed toolbox is that we also
support differentially private optimization on Riemannian manifolds.
</summary>
    <author>
      <name>Saiteja Utpala</name>
    </author>
    <author>
      <name>Andi Han</name>
    </author>
    <author>
      <name>Pratik Jawanpuria</name>
    </author>
    <author>
      <name>Bamdev Mishra</name>
    </author>
    <link href="http://arxiv.org/abs/2210.04840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.04840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.07964v1</id>
    <updated>2023-01-19T09:40:15Z</updated>
    <published>2023-01-19T09:40:15Z</published>
    <title>Parallel two-stage reduction to Hessenberg-triangular form</title>
    <summary>  We present a two-stage algorithm for the parallel reduction of a pencil to
Hessenberg-triangular form. Traditionally, two-stage Hessenberg-triangular
reduction algorithms achieve high performance in the first stage, but struggle
to achieve high performance in the second stage. Our algorithm extends
techniques described by Karlsson et al. to also achieve high performance in the
second stage. Experiments in a shared memory environment demonstrate that the
algorithm can outperform state-of-the-art implementations.
</summary>
    <author>
      <name>Thijs Steel</name>
    </author>
    <author>
      <name>Raf Vandebril</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2301.07964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.07964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F15, 65Y05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.12473v2</id>
    <updated>2024-01-16T14:47:36Z</updated>
    <published>2023-02-24T06:16:21Z</published>
    <title>SubalgebraBases in Macaulay2</title>
    <summary>  We describe a recently revived version of the software package
SubalgberaBases, which is distributed in the Macaulay2 computer algebra system.
The package allows the user to compute and manipulate subagebra bases -- which
are also known as SAGBI bases or canonical bases and form a special class of
Khovanskii bases -- for polynomial rings and their quotients. We provide an
overview of the design and functionality of SubalgberaBases and demonstrate how
the package works on several motivating examples.
</summary>
    <author>
      <name>Michael Burr</name>
    </author>
    <author>
      <name>Oliver Clarke</name>
    </author>
    <author>
      <name>Timothy Duff</name>
    </author>
    <author>
      <name>Jackson Leaman</name>
    </author>
    <author>
      <name>Nathan Nichols</name>
    </author>
    <author>
      <name>Elise Walker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2140/jsag.2024.14.97</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2140/jsag.2024.14.97" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version. 11 pages w/ refs. Ancillary file
  "accompanyingCode.m2" available on arXiv</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Softw. Alg. Geom. 14 (2024) 97-109</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2302.12473v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.12473v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.10492v1</id>
    <updated>2023-03-08T05:30:40Z</updated>
    <published>2023-03-08T05:30:40Z</published>
    <title>DisjunctiveProgramming.jl: Generalized Disjunctive Programming Models
  and Algorithms for JuMP</title>
    <summary>  We present a Julia package, DisjunctiveProgramming.jl, that extends the
functionality in JuMP.jl to allow modeling problems via logical propositions
and disjunctive constraints. Such models can then be reformulated into
Mixed-Integer Programs (MIPs) that can be solved with the various MIP solvers
supported by JuMP. To do so, logical propositions are converted to Conjunctive
Normal Form (CNF) and reformulated into equivalent algebraic constraints.
Disjunctions are reformulated into mixed-integer constraints via the
reformulation technique specified by the user (Big-M or Hull reformulations).
The package supports reformulations for disjunctions containing linear,
quadratic, and nonlinear constraints.
</summary>
    <author>
      <name>Hector D. Perez</name>
    </author>
    <author>
      <name>Shivank Joshi</name>
    </author>
    <author>
      <name>Ignacio E. Grossmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.10492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.10492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.14536v1</id>
    <updated>2023-04-27T21:08:17Z</updated>
    <published>2023-04-27T21:08:17Z</published>
    <title>A framework for rigorous computational methods using Haar wavelets for
  differential equations</title>
    <summary>  This work presents a framework for a-posteriori error-estimating algorithms
for differential equations which combines the radii polynomial approach with
Haar wavelets. By using Haar wavelets, we obtain recursive structures for the
matrix representations of the differential operators and quadratic
nonlinearities, which can be exploited for the radii polynomial method in order
to get error estimates in the $L^2$ sense. This allows the method to be
applicable when the system or solution is not continuous, which is a limitation
of other radii-polynomial-based methods. Numerical examples show how the method
is implemented in practice.
</summary>
    <author>
      <name>Guilherme Nakassima</name>
    </author>
    <author>
      <name>Marcio Gameiro</name>
    </author>
    <link href="http://arxiv.org/abs/2304.14536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.14536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34A34, 34L30, 65G20, 65H10, 65T60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.07030v1</id>
    <updated>2023-05-05T05:42:03Z</updated>
    <published>2023-05-05T05:42:03Z</published>
    <title>Using Hierarchical Parallelism to Accelerate the Solution of Many Small
  Partial Differential Equations</title>
    <summary>  This paper presents efforts to improve the hierarchical parallelism of a two
scale simulation code. Two methods to improve the GPU parallel performance were
developed and compared. The first used the NVIDIA Multi-Process Service and the
second moved the entire sub-problem loop into a single kernel using Kokkos
hierarchical parallelism and a PackedView data structure. Both approaches
improved parallel performance with the second method providing the greatest
improvements.
</summary>
    <author>
      <name>Jacob Merson</name>
    </author>
    <author>
      <name>Mark S. Shephard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Originally presented at the HiPar workshop at The International
  Conference for High Performance Computing, Networking, Storage, and Analysis
  (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.07030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.07030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.09122v1</id>
    <updated>2023-05-16T03:08:45Z</updated>
    <published>2023-05-16T03:08:45Z</published>
    <title>Power Grid Transient Analysis via Open-Source Circuit Simulator: A Case
  Study of HVDC</title>
    <summary>  This paper proposes an electronic circuit simulator-based method to
accelerate the power system transient simulation, where the modeling of a
generic HVDC (High Voltage Direct Current) system is focused. The electronic
circuit simulation equations and the backward differentiation formula for
numerical solving are described. Then, the circuit modeling process for power
system components such as slack bus, constant power load, and HVDC are
respectively illustrated. Finally, a case study is conducted on a four-bus
power system to demonstrate the effectiveness of the proposed modeling and
simulation method.
</summary>
    <author>
      <name>Yongli Zhu</name>
    </author>
    <author>
      <name>Xiang Zhang</name>
    </author>
    <author>
      <name>Renchang Dai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted by the IEEE KPEC 2023 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.09122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.09122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.03466v2</id>
    <updated>2023-07-26T10:51:25Z</updated>
    <published>2023-07-07T09:00:14Z</published>
    <title>Scylla: a matrix-free fix-propagate-and-project heuristic for
  mixed-integer optimization</title>
    <summary>  We introduce Scylla, a primal heuristic for mixed-integer optimization
problems. It exploits approximate solves of the Linear Programming relaxations
through the matrix-free Primal-Dual Hybrid Gradient algorithm with specialized
termination criteria, and derives integer-feasible solutions via
fix-and-propagate procedures and feasibility-pump-like updates to the objective
function. Computational experiments show that the method is particularly suited
to instances with hard linear relaxations.
</summary>
    <author>
      <name>Gioni Mexi</name>
    </author>
    <author>
      <name>Mathieu Besançon</name>
    </author>
    <author>
      <name>Suresh Bolusani</name>
    </author>
    <author>
      <name>Antonia Chmiela</name>
    </author>
    <author>
      <name>Alexander Hoen</name>
    </author>
    <author>
      <name>Ambros Gleixner</name>
    </author>
    <link href="http://arxiv.org/abs/2307.03466v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.03466v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.08049v1</id>
    <updated>2023-08-15T21:29:22Z</updated>
    <published>2023-08-15T21:29:22Z</published>
    <title>Computation of GIT quotients of semisimple groups</title>
    <summary>  We describe three algorithms to determine the stable, semistable, and
torus-polystable loci of the GIT quotient of a projective variety by a
reductive group. The algorithms are efficient when the group is semisimple. By
using an implementation of our algorithms for simple groups, we provide several
applications to the moduli theory of algebraic varieties, including the
K-moduli of algebraic varieties, the moduli of algebraic curves and the Mukai
models of the moduli space of curves for low genus. We also discuss a number of
potential improvements and some natural open problems arising from this work.
</summary>
    <author>
      <name>Patricio Gallardo</name>
    </author>
    <author>
      <name>Jesus Martinez-Garcia</name>
    </author>
    <author>
      <name>Han-Bom Moon</name>
    </author>
    <author>
      <name>David Swinarski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 3 figures. 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.08049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.08049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="14L24, 14Q20, 14-04, 13A50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.08778v2</id>
    <updated>2023-12-16T01:55:49Z</updated>
    <published>2023-09-15T21:44:49Z</published>
    <title>Satisfiability.jl: Satisfiability Modulo Theories in Julia</title>
    <summary>  Satisfiability modulo theories (SMT) is a core tool in formal verification.
While the SMT-LIB specification language can be used to interact with theorem
proving software, a high-level interface allows for faster and easier
specifications of complex SMT formulae. In this paper we present a novel
open-source package for interacting with SMT-LIB compliant solvers in the Julia
programming language.
</summary>
    <author>
      <name>Emiko Soroka</name>
    </author>
    <author>
      <name>Mykel J. Kochenderfer</name>
    </author>
    <author>
      <name>Sanjay Lall</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21105/joss.06757</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21105/joss.06757" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, revised from a previous longer version to comply with a
  conference length requirement. Submitted to NASA Formal Methods 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.08778v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.08778v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.00084v1</id>
    <updated>2023-10-31T18:52:05Z</updated>
    <published>2023-10-31T18:52:05Z</published>
    <title>NoMoPy: Noise Modeling in Python</title>
    <summary>  NoMoPy is a code for fitting, analyzing, and generating noise modeled as a
hidden Markov model (HMM) or, more generally, factorial hidden Markov model
(FHMM). This code, written in Python, implements approximate and exact
expectation maximization (EM) algorithms for performing the parameter
estimation process, model selection procedures via cross-validation, and
parameter confidence region estimation. Here, we describe in detail the
functionality implemented in NoMoPy and provide examples of its use and
performance on example problems.
</summary>
    <author>
      <name>Dylan Albrecht</name>
    </author>
    <author>
      <name>N. Tobias Jacobson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 68 figures, citation paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2311.00084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.00084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.02037v2</id>
    <updated>2024-09-04T17:25:51Z</updated>
    <published>2023-11-03T17:10:26Z</published>
    <title>An Efficient Framework for Global Non-Convex Polynomial Optimization
  with Algebraic Constraints</title>
    <summary>  We present an efficient framework for solving algebraically-constrained
global non-convex polynomial optimization problems over subsets of the
hypercube. We prove the existence of an equivalent nonlinear reformulation of
such problems that possesses essentially no spurious local minima. Through
numerical experiments on previously intractable global constrained polynomial
optimization problems in high dimension, we show that polynomial scaling in
dimension and degree is achievable when computing the optimal value and
location.
</summary>
    <author>
      <name>Mitchell Tong Harris</name>
    </author>
    <author>
      <name>Pierre-David Letourneau</name>
    </author>
    <author>
      <name>Dalton Jones</name>
    </author>
    <author>
      <name>M. Harper Langston</name>
    </author>
    <link href="http://arxiv.org/abs/2311.02037v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.02037v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.12685v1</id>
    <updated>2023-12-20T01:05:00Z</updated>
    <published>2023-12-20T01:05:00Z</published>
    <title>Using monodromy to recover symmetries of polynomial systems</title>
    <summary>  Galois/monodromy groups attached to parametric systems of polynomial
equations provide a method for detecting the existence of symmetries in
solution sets. Beyond the question of existence, one would like to compute
formulas for these symmetries, towards the eventual goal of solving the systems
more efficiently. We describe and implement one possible approach to this task
using numerical homotopy continuation and multivariate rational function
interpolation. We describe additional methods that detect and exploit a priori
unknown quasi-homogeneous structure in symmetries. These methods extend the
range of interpolation to larger examples, including applications with
nonlinear symmetries drawn from vision and robotics.
</summary>
    <author>
      <name>Timothy Duff</name>
    </author>
    <author>
      <name>Viktor Korotynskiy</name>
    </author>
    <author>
      <name>Tomas Pajdla</name>
    </author>
    <author>
      <name>Margaret Regan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended journal version of conference paper published at ISSAC 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.12685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.12685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.09983v1</id>
    <updated>2024-02-15T14:49:18Z</updated>
    <published>2024-02-15T14:49:18Z</published>
    <title>Optimistix: modular optimisation in JAX and Equinox</title>
    <summary>  We introduce Optimistix: a nonlinear optimisation library built in JAX and
Equinox. Optimistix introduces a novel, modular approach for its minimisers and
least-squares solvers. This modularity relies on new practical abstractions for
optimisation which we call search and descent, and which generalise classical
notions of line search, trust-region, and learning-rate algorithms. It provides
high-level APIs and solvers for minimisation, nonlinear least-squares,
root-finding, and fixed-point iteration. Optimistix is available at
https://github.com/patrick-kidger/optimistix.
</summary>
    <author>
      <name>Jason Rader</name>
    </author>
    <author>
      <name>Terry Lyons</name>
    </author>
    <author>
      <name>Patrick Kidger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.09983v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.09983v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.11868v1</id>
    <updated>2024-02-19T06:24:25Z</updated>
    <published>2024-02-19T06:24:25Z</published>
    <title>Recent Extensions of the ZKCM Library for Parallel and Accurate MPS
  Simulation of Quantum Circuits</title>
    <summary>  A C++ library ZKCM and its extension library ZKCM_QC have been developed
since 2011 for multiple-precision matrix computation and accurate
matrix-product-state (MPS) quantum circuit simulation, respectively. In this
report, a recent progress in the extensions of these libraries is described,
which are mainly for parallel processing with the OpenMP and CUDA frameworks.
</summary>
    <author>
      <name>Akira SaiToh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, under review in the post-conference Proc. CCP2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.11868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.11868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N80, 81-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
