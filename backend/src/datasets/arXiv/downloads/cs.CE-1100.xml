<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.CE%26id_list%3D%26start%3D0%26max_results%3D1100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.CE&amp;id_list=&amp;start=0&amp;max_results=1100</title>
  <id>http://arxiv.org/api/le6kkAzjQyfvM+BunkEH+mP7pwQ</id>
  <updated>2025-05-27T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">8621</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/0110067v1</id>
    <updated>2001-10-31T20:18:35Z</updated>
    <published>2001-10-31T20:18:35Z</published>
    <title>Analysis of Investment Policy in Belarus</title>
    <summary>  The optimal planning trajectory is analyzed on the basis of the growth model
with effectiveness. The saving per capital value has to be rather high
initially with smooth decrement in the future years.
</summary>
    <author>
      <name>Fedor S. Kilin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 2 figures, 1 table. email: fedia@dragon.bas-net.by</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0110067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1;J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306016v1</id>
    <updated>2003-06-03T08:48:54Z</updated>
    <published>2003-06-03T08:48:54Z</published>
    <title>Modelling Biochemical Operations on RNA Secondary Structures</title>
    <summary>  In this paper we model several simple biochemical operations on RNA molecules
that modify their secondary structure by means of a suitable variation of
Gro\ss e-Rhode's Algebra Transformation Systems.
</summary>
    <author>
      <name>Merce Llabres</name>
    </author>
    <author>
      <name>Francesc Rossello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3;F.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509012v5</id>
    <updated>2009-08-01T11:05:51Z</updated>
    <published>2005-09-05T08:04:06Z</published>
    <title>Kriging Scenario For Capital Markets</title>
    <summary>  An introduction to numerical statistics.
</summary>
    <author>
      <name>T. Suslo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, attachments: source code and input files</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0509012v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509012v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510084v1</id>
    <updated>2005-10-26T14:49:47Z</updated>
    <published>2005-10-26T14:49:47Z</published>
    <title>Réflexions sur la question fréquentielle en traitement du signal</title>
    <summary>  New definitions are suggested for frequencies which may be instantaneous or
not. The Heisenberg-Gabor inequality and the Shannon sampling theorem are
briefly discussed.
</summary>
    <author>
      <name>Michel Fliess</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0510084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0833v1</id>
    <updated>2009-08-06T12:21:22Z</updated>
    <published>2009-08-06T12:21:22Z</published>
    <title>Top-down Paradigm in Engineering Software Integration</title>
    <summary>  The top-down approach of engineering software integration is considered in
this parer. A set of advantages of this approach are presented, by examples.
All examples are supplied by open source code.
</summary>
    <author>
      <name>Petr R. Ivankov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 44 figures, 5 references</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.0833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4391v3</id>
    <updated>2016-04-07T06:14:03Z</updated>
    <published>2013-02-18T19:14:38Z</published>
    <title>Constructing a genome assembly that has the maximum likelihood</title>
    <summary>  We formulate genome assembly problem as an optimization problem in which the
objective function is the likelihood of the assembly given the reads.
</summary>
    <author>
      <name>Mohammadreza Ghodsi</name>
    </author>
    <link href="http://arxiv.org/abs/1302.4391v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4391v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2223v1</id>
    <updated>2013-03-09T15:34:25Z</updated>
    <published>2013-03-09T15:34:25Z</published>
    <title>khmer: Working with Big Data in Bioinformatics</title>
    <summary>  We introduce design and optimization considerations for the 'khmer' package.
</summary>
    <author>
      <name>Eric McDonald</name>
    </author>
    <author>
      <name>C. Titus Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Invited chapter for forthcoming book on Performance of Open Source
  Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.2223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6181v1</id>
    <updated>2014-05-06T06:05:04Z</updated>
    <published>2014-05-06T06:05:04Z</published>
    <title>Py-oopsi: the python implementation of the fast-oopsi algorithm</title>
    <summary>  Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widely
used to extract neuron spike activities from calcium fluorescence signals.
Here, we propose detailed implementation of the fast-oopsi algorithm in python
programming language. Some corrections are also made to the original fast-oopsi
paper.
</summary>
    <author>
      <name>Benyuan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1405.6181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7030v1</id>
    <updated>2014-12-22T15:47:51Z</updated>
    <published>2014-12-22T15:47:51Z</published>
    <title>Proceedings of the 7th European Conference on Python in Science
  (EuroSciPy 2014)</title>
    <summary>  These are the proceedings of the 7th European Conference on Python in
Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).
</summary>
    <author>
      <name>Pierre de Buyl</name>
    </author>
    <author>
      <name>Nelle Varoquaux</name>
    </author>
    <link href="http://arxiv.org/abs/1412.7030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01119v1</id>
    <updated>2015-02-04T08:24:04Z</updated>
    <published>2015-02-04T08:24:04Z</published>
    <title>A discontinuous Galerkin method for cohesive zone modelling</title>
    <summary>  We propose a discontinuous finite element method for small strain elasticity
allowing for cohesive zone modeling. The method yields a seamless transition
between the discontinuous Galerkin method and classical cohesive zone modeling.
Some relevant numerical examples are presented.
</summary>
    <author>
      <name>Peter Hansbo</name>
    </author>
    <author>
      <name>Kent Salomonsson</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00594v1</id>
    <updated>2016-04-03T05:21:19Z</updated>
    <published>2016-04-03T05:21:19Z</published>
    <title>Two Dimensional Angle of Arrival Estimation</title>
    <summary>  We present a new method for the estimation of two dimensional (2D) angles of
arrival (AOAs), namely, azimuth and incidence angles of multiple narrowband
signals of same frequency in the far field of antenna array.
</summary>
    <author>
      <name>Santhosh Kumar</name>
    </author>
    <author>
      <name>Pradip Sircar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09842v1</id>
    <updated>2020-01-24T09:29:12Z</updated>
    <published>2020-01-24T09:29:12Z</published>
    <title>Electric Field Propagation Through Singular Value Decomposition</title>
    <summary>  We demonstrate that the singular value decomposition algorithm in conjunction
with the fast Fourier transform or finite difference procedures provides a
straightforward and accurate method for rapidly propagating electric fields in
the one-way Helmholtz formalism.
</summary>
    <author>
      <name>David Yevick</name>
    </author>
    <link href="http://arxiv.org/abs/2001.09842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.06960v1</id>
    <updated>2023-07-13T04:30:59Z</updated>
    <published>2023-07-13T04:30:59Z</published>
    <title>On stepwise advancement of fractures and pressure oscillations in
  saturated porous media</title>
    <summary>  Comments to K.M. Pervaiz Fathima, Ren\'e de Borst, Implications of single or
multiple pressure degrees of freedom at fracture in fluid saturated porous
media, Engineering Fracture Mechanics, 213 (2019), 1-20.
</summary>
    <author>
      <name>Carlo Peruzzo</name>
    </author>
    <author>
      <name>Luciano Simoni</name>
    </author>
    <author>
      <name>Bernhard Schrefler</name>
    </author>
    <link href="http://arxiv.org/abs/2307.06960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.06960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906011v1</id>
    <updated>1999-06-09T12:27:03Z</updated>
    <published>1999-06-09T12:27:03Z</published>
    <title>A Newton method without evaluation of nonlinear function values</title>
    <summary>  The present author recently proposed and proved a relationship theorem
between nonlinear polynomial equations and the corresponding Jacobian matrix.
By using this theorem, this paper derives a Newton iterative formula without
requiring the evaluation of nonlinear function values in the solution of
nonlinear polynomial-only problems.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to chenw@homer.shinshu-u.ac.jp or
  chenwwhy@hotmail.com</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.1.5; G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204056v1</id>
    <updated>2002-04-29T12:20:11Z</updated>
    <published>2002-04-29T12:20:11Z</published>
    <title>Trading Agents for Roaming Users</title>
    <summary>  Some roaming users need services to manipulate autonomous processes. Trading
agents running on agent trade servers are used as a case in point. We present a
solution that provides the agent owners with means to upkeeping their desktop
environment, and maintaining their agent trade server processes, via a
briefcase service.
</summary>
    <author>
      <name>Magnus Boman</name>
    </author>
    <author>
      <name>Markus Bylund</name>
    </author>
    <author>
      <name>Fredrik Espinoza</name>
    </author>
    <author>
      <name>Mats Danielson</name>
    </author>
    <author>
      <name>David Lyback</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0204056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.11; K.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208016v1</id>
    <updated>2002-08-08T07:29:10Z</updated>
    <published>2002-08-08T07:29:10Z</published>
    <title>A note on fractional derivative modeling of broadband
  frequency-dependent absorption: Model III</title>
    <summary>  By far, the fractional derivative model is mainly related to the modelling of
complicated solid viscoelastic material. In this study, we try to build the
fractional derivative PDE model for broadband ultrasound propagation through
human tissues.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0208016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.2, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307064v1</id>
    <updated>2003-07-29T12:58:45Z</updated>
    <published>2003-07-29T12:58:45Z</published>
    <title>Implementing an Agent Trade Server</title>
    <summary>  An experimental server for stock trading autonomous agents is presented and
made available, together with an agent shell for swift development. The server,
written in Java, was implemented as proof-of-concept for an agent trade server
for a real financial exchange.
</summary>
    <author>
      <name>Magnus Boman</name>
    </author>
    <author>
      <name>Anna Sandin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures, intended for B/W printing</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="{I.2.11}{Artificial Intelligence}{Distributed Artificial&#10;  Intelligence}[Intelligent Agents];{K.4.4}{Computers and Society}{Electronic&#10;  Commerce}[Distributed Commercial Transactions]" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405041v1</id>
    <updated>2004-05-12T07:55:34Z</updated>
    <published>2004-05-12T07:55:34Z</published>
    <title>The modulus in the CAD system drawings as a base of developing of the
  problem-oriented extensions</title>
    <summary>  The concept of the "modulus" in the CAD system drawings is characterized,
being a base of developing of the problem-oriented extensions. The modulus
consists of visible geometric elements of the drawing and invisible parametric
representation of the modelling object. The technological advantages of
moduluss in a complex CAD system developing are described.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, no figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503084v1</id>
    <updated>2005-03-30T07:00:29Z</updated>
    <published>2005-03-30T07:00:29Z</published>
    <title>The Peculiarities of Nonstationary Formation of Inhomogeneous Structures
  of Charged Particles in the Electrodiffusion Processes</title>
    <summary>  In this paper the distribution of charged particles is constructed under the
approximation of ambipolar diffusion. The results of mathematical modelling in
two-dimensional case taking into account the velocities of the system are
presented.
</summary>
    <author>
      <name>P. Nefyodov</name>
    </author>
    <author>
      <name>V. Reztsov</name>
    </author>
    <author>
      <name>O. Riabinina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures The example of our scientific work</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0503084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506051v2</id>
    <updated>2005-11-11T10:25:53Z</updated>
    <published>2005-06-13T15:26:16Z</published>
    <title>Comparison of two different implementations of a
  finite-difference-method for first-order pde in mathematica and matlab</title>
    <summary>  In this article two implementations of a symmetric finite difference
algorithm for a first-order partial differential equation are discussed. The
considered partial differential equation discribes the time evolution of the
crack length distribution of microcracks in brittle materia.
</summary>
    <author>
      <name>Heiko Herrmann</name>
    </author>
    <author>
      <name>Gunnar Rueckner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTeX, 6 pages, 9 eps-figures, v2: minor additions/corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506051v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506051v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0507055v2</id>
    <updated>2005-08-02T07:14:59Z</updated>
    <published>2005-07-21T14:17:47Z</published>
    <title>ReacProc: A Tool to Process Reactions Describing Particle Interactions</title>
    <summary>  ReacProc is a program written in C/C++ programming language which can be used
(1) to check out of reactions describing particles interactions against
conservation laws and (2) to reduce input reaction into some canonical form. A
table with particles properties is available within ReacProc package.
</summary>
    <author>
      <name>A. S. Siver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0507055v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0507055v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603003v1</id>
    <updated>2006-03-01T11:26:22Z</updated>
    <published>2006-03-01T11:26:22Z</published>
    <title>Analyse non standard du bruit</title>
    <summary>  Thanks to the nonstandard formalization of fast oscillating functions, due to
P. Cartier and Y. Perrin, an appropriate mathematical framework is derived for
new non-asymptotic estimation techniques, which do not necessitate any
statistical analysis of the noises corrupting any sensor. Various applications
are deduced for multiplicative noises, for the length of the parametric
estimation windows, and for burst errors.
</summary>
    <author>
      <name>Michel Fliess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIX, INRIA Futurs</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0603003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611049v2</id>
    <updated>2007-02-28T02:06:40Z</updated>
    <published>2006-11-13T20:37:42Z</published>
    <title>On numerical stability of recursive present value computation method</title>
    <summary>  We analyze numerical stability of a recursive computation scheme of present
value (PV) amd show that the absolute error increases exponentially for
positive discount rates. We show that reversing the direction of calculations
in the recurrence equation yields a robust PV computation routine.
</summary>
    <author>
      <name>Argyn Kuketayev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611049v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611049v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0; J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611132v1</id>
    <updated>2006-11-27T04:31:09Z</updated>
    <published>2006-11-27T04:31:09Z</published>
    <title>The specifications making in complex CAD-system of renovation of the
  enterprises on the basis of modules in the drawing and electronic catalogues</title>
    <summary>  The experience of automation of the specifications making of the projects of
renovation of the industrial enterprises is described, being based on the
special modules in the drawing containing the visible image and additional
parameters, and electronic catalogues
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611133v1</id>
    <updated>2006-11-27T04:39:09Z</updated>
    <published>2006-11-27T04:39:09Z</published>
    <title>The modelling of the automation schemes of technological processes in
  CAD-system of renovation of the enterprises</title>
    <summary>  According to the requirements of the Russian standards, the automation
schemes are necessary practically in each project of renovation of industrial
buildings and facilities, in which any technological processes are realized.
The model representations of the automation schemes in CAD-system TechnoCAD
GlassX are described. The models follow a principle "to exclude a repeated
input operations"
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612126v1</id>
    <updated>2006-12-22T19:19:41Z</updated>
    <published>2006-12-22T19:19:41Z</published>
    <title>The virtual reality framework for engineering objects</title>
    <summary>  A framework for virtual reality of engineering objects has been developed.
This framework may simulate different equipment related to virtual reality.
Framework supports 6D dynamics, ordinary differential equations, finite
formulas, vector and matrix operations. The framework also supports embedding
of external software.
</summary>
    <author>
      <name>Petr R. Ivankov</name>
    </author>
    <author>
      <name>Nikolay P. Ivankov</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0612126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701119v1</id>
    <updated>2007-01-19T12:18:14Z</updated>
    <published>2007-01-19T12:18:14Z</published>
    <title>The framework for simulation of dynamics of mechanical aggregates</title>
    <summary>  A framework for simulation of dynamics of mechanical aggregates has been
developed. This framework enables us to build model of aggregate from models of
its parts. Framework is a part of universal framework for science and
engineering.
</summary>
    <author>
      <name>Petr R. Ivankov</name>
    </author>
    <author>
      <name>Nikolay P. Ivankov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3048v2</id>
    <updated>2008-02-26T16:29:01Z</updated>
    <published>2007-08-22T16:25:17Z</published>
    <title>Identifying Small Mean Reverting Portfolios</title>
    <summary>  Given multivariate time series, we study the problem of forming portfolios
with maximum mean reversion while constraining the number of assets in these
portfolios. We show that it can be formulated as a sparse canonical correlation
analysis and study various algorithms to solve the corresponding sparse
generalized eigenvalue problems. After discussing penalized parameter
estimation procedures, we study the sparsity versus predictability tradeoff and
the impact of predictability in various markets.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <link href="http://arxiv.org/abs/0708.3048v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3048v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.4324v1</id>
    <updated>2007-11-27T18:34:40Z</updated>
    <published>2007-11-27T18:34:40Z</published>
    <title>Report on "American Option Pricing and Hedging Strategies"</title>
    <summary>  This paper mainly discusses the American option's hedging strategies via
binomialmodel and the basic idea of pricing and hedging American option.
Although the essential scheme of hedging is almost the same as European option,
small differences may arise when simulating the process for American option
holder has more rights, spelling that the option can be exercised at anytime
before its maturity. Our method is dynamic-hedging method.
</summary>
    <author>
      <name>Jinshan Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.4324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.4324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.0840v2</id>
    <updated>2009-02-09T19:17:26Z</updated>
    <published>2008-09-04T15:33:23Z</published>
    <title>HEP data analysis using jHepWork and Java</title>
    <summary>  A role of Java in high-energy physics and recent progress in development of a
platform-independent data-analysis framework, jHepWork, is discussed. The
framework produces professional graphics and has many libraries for data
manipulation.
</summary>
    <author>
      <name>S. Chekanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Proceedings of the HERA-LHC workshops (2007-2008), DESY-CERN</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.0840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.0840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1672v1</id>
    <updated>2009-11-09T13:16:01Z</updated>
    <published>2009-11-09T13:16:01Z</published>
    <title>Biological Computing Fundamentals and Futures</title>
    <summary>  The fields of computing and biology have begun to cross paths in new ways. In
this paper a review of the current research in biological computing is
presented. Fundamental concepts are introduced and these foundational elements
are explored to discuss the possibilities of a new computing paradigm. We
assume the reader to possess a basic knowledge of Biology and Computer Science
</summary>
    <author>
      <name>Balaji Akula</name>
    </author>
    <author>
      <name>James Cusick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Introduction to Biological computing, 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.1672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.3125v2</id>
    <updated>2009-11-22T08:20:17Z</updated>
    <published>2009-11-16T19:24:59Z</published>
    <title>A computational model of the bottlenose dolphin sonar:
  Feature-extracting method</title>
    <summary>  The data describing a process of echo-image formation in bottlenose dolphin
sonar perception were accumulated in our experimental explorations. These data
were formalized mathematically and used in the computational model, comparative
testing of which in echo-discrimination tasks revealed no less capabilities
then those of bottlenose dolphins.
</summary>
    <author>
      <name>T. Zorikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.3125v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.3125v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4230v1</id>
    <updated>2009-11-22T04:07:08Z</updated>
    <published>2009-11-22T04:07:08Z</published>
    <title>Introduction to Bioinformatics</title>
    <summary>  Bioinformatics is a new discipline that addresses the need to manage and
interpret the data that in the past decade was massively generated by genomic
research. This discipline represents the convergence of genomics, biotechnology
and information technology, and encompasses analysis and interpretation of
data, modeling of biological phenomena, and development of algorithms and
statistics. This article presents an introduction to bioinformatics
</summary>
    <author>
      <name>Sabu M. Thampi</name>
    </author>
    <link href="http://arxiv.org/abs/0911.4230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.2410v1</id>
    <updated>2010-08-14T03:03:44Z</updated>
    <published>2010-08-14T03:03:44Z</published>
    <title>Removing the Barrier to Scalability in Parallel FMM</title>
    <summary>  The Fast Multipole Method (FMM) is well known to possess a bottleneck arising
from decreasing workload on higher levels of the FMM tree [Greengard and Gropp,
Comp. Math. Appl., 20(7), 1990]. We show that this potential bottleneck can be
eliminated by overlapping multipole and local expansion computations with
direct kernel evaluations on the finest level grid.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.2410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.2410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3479v1</id>
    <updated>2012-01-17T10:57:29Z</updated>
    <published>2012-01-17T10:57:29Z</published>
    <title>Simple Numerical Model of Laminated Glass Beams</title>
    <summary>  This contribution presents a simple Finite Element model aimed at efficient
simulation of layered glass units. The adopted approach is based on considering
independent kinematics of each layer, tied together via Lagrange multipliers.
Validation and verification of the resulting model against independent data
demonstrate its accuracy, showing its potential for generalization towards more
complex problems.
</summary>
    <author>
      <name>Alena Zemanová</name>
    </author>
    <author>
      <name>Jan Zeman</name>
    </author>
    <author>
      <name>Michal Šejnoha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Polytechnica, 48(6), 22-26 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.3479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2528v1</id>
    <updated>2012-03-12T16:02:46Z</updated>
    <published>2012-03-12T16:02:46Z</published>
    <title>Knowledge-based antenna pattern extrapolation</title>
    <summary>  We describe a theoretically-motivated algorithm for extrapolation of antenna
radiation patterns from a small number of measurements. This algorithm exploits
constraints on the antenna's underlying design to avoid ambiguities, but is
sufficiently general to address many different antenna types. A theoretical
basis for the robustness of this algorithm is developed, and its performance is
verified in simulation using a number of popular antenna designs.
</summary>
    <author>
      <name>Michael Robinson</name>
    </author>
    <link href="http://arxiv.org/abs/1203.2528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1125v1</id>
    <updated>2012-05-05T12:19:33Z</updated>
    <published>2012-05-05T12:19:33Z</published>
    <title>Application Of Data Mining In Bioinformatics</title>
    <summary>  This article highlights some of the basic concepts of bioinformatics and data
mining. The major research areas of bioinformatics are highlighted. The
application of data mining in the domain of bioinformatics is explained. It
also highlights some of the current challenges and opportunities of data mining
in bioinformatics.
</summary>
    <author>
      <name>Khalid Raza</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Indian Journal of Computer Science and Engineering 1(2):114-118
  2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.1125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0638v2</id>
    <updated>2012-07-09T16:53:30Z</updated>
    <published>2012-06-04T14:51:18Z</published>
    <title>WM Program manual</title>
    <summary>  This user manual has been written to describe the open source code WM to be
distributed associated with a research article submitted to the information
technology journal 45001-ITJ-ANSI, entitled: "Maintenance and Reengineering of
software: Creating a Visual C++ Graphical User Interface to Perform Specific
Tasks Related to Soil Structure Interaction in Poroelastic Soil".
</summary>
    <author>
      <name>Amani Tahat</name>
    </author>
    <author>
      <name>Jordi Marti</name>
    </author>
    <author>
      <name>Mohammad Tahat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">63 pages,19 figures,one appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0638v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0638v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5099v1</id>
    <updated>2013-04-18T12:16:44Z</updated>
    <published>2013-04-18T12:16:44Z</published>
    <title>Expressando Atributos Não-Funcionais em Workflows Científicos</title>
    <summary>  In this paper we present OSC, a scientific workflow specification language
based on software architecture principles. In contrast with other approaches,
OSC employs connectors as first-class constructs. In this way, we leverage
reusability and compositionality in the workflow modeling process, specially in
the configuration of mechanisms that manage non-functional attributes.
</summary>
    <author>
      <name>Vivian Medeiros</name>
    </author>
    <author>
      <name>Antonio Tadeu Azevedo Gomes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In portuguese</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.5099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1112v1</id>
    <updated>2013-05-06T08:31:48Z</updated>
    <published>2013-05-06T08:31:48Z</published>
    <title>json2run: a tool for experiment design &amp; analysis</title>
    <summary>  json2run is a tool to automate the running, storage and analysis of
experiments. The main advantage of json2run is that it allows to describe a set
of experiments concisely as a JSON-formatted parameter tree. It also supports
parallel execution of experiments, automatic parameter tuning through the
F-Race framework and storage and analysis of experiments with MongoDB and R.
</summary>
    <author>
      <name>Tommaso Urli</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0871v1</id>
    <updated>2013-09-03T23:41:36Z</updated>
    <published>2013-09-03T23:41:36Z</published>
    <title>Exploring the Dynamics of Mass Action Systems</title>
    <summary>  We present the Populus toolkit for exploring the dynamics of mass action
systems under different assumptions.
</summary>
    <author>
      <name>Oded Maler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CNRS-VERIMAG, University of Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Ádám M. Halász</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Methematics, West Virginia University</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Lebeltel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CNRS-VERIMAG, University of Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Ouri Maler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Grenoble</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.125.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.125.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2013, arXiv:1308.5724</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 125, 2013, pp. 84-91</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.0871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1467v1</id>
    <updated>2014-02-06T19:54:39Z</updated>
    <published>2014-02-06T19:54:39Z</published>
    <title>Reconstruction Models for Attractors in the Technical and Economic
  Processes</title>
    <summary>  The article discusses building models based on the reconstructed attractors
of the time series. Discusses the use of the properties of dynamical chaos,
namely to identify the strange attractors structure models. Here is used the
group properties of differential equations, which consist in the symmetry of
particular solutions. Examples of modeling engineering systems are given.
</summary>
    <author>
      <name>Evgeny Nikulchev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V6N3P128</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V6N3P128" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology. 2013. V.6
  N.3. P.171-175</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.1467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94-02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.7351v1</id>
    <updated>2014-02-28T19:12:50Z</updated>
    <published>2014-02-28T19:12:50Z</published>
    <title>A Machine Learning Model for Stock Market Prediction</title>
    <summary>  Stock market prediction is the act of trying to determine the future value of
a company stock or other financial instrument traded on a financial exchange.
</summary>
    <author>
      <name>Osman Hegazy</name>
    </author>
    <author>
      <name>Omar S. Soliman</name>
    </author>
    <author>
      <name>Mustafa Abdul Salam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages. arXiv admin note: substantial text overlap with
  arXiv:1402.6366</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Telecommunications
  [Volume 4, Issue 12, December 2013]</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.7351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.7351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4508v1</id>
    <updated>2014-01-29T13:06:20Z</updated>
    <published>2014-01-29T13:06:20Z</published>
    <title>Research on Study Mechanical Vibrations with Data Acquisition Systems</title>
    <summary>  The paper presents a new study method of mechanic vibrations with the help of
the data acquisition systems. The study of vibrations with the help of data
acquisition systems allows the solving of some engineering problems connected
to the measurement of some parameters which are difficult to measure having in
view the improvement of the technical performances of the industrial equipment
or devices
</summary>
    <author>
      <name>Lenuta Suciu</name>
    </author>
    <author>
      <name>Florentina Cziple</name>
    </author>
    <author>
      <name>Cornelia Anghel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AGIR Bucuresti Press, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.4508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7550v1</id>
    <updated>2014-04-29T22:31:21Z</updated>
    <published>2014-04-29T22:31:21Z</published>
    <title>The Synchrosqueezing transform for instantaneous spectral analysis</title>
    <summary>  The Synchrosqueezing transform is a time-frequency analysis method that can
decompose complex signals into time-varying oscillatory components. It is a
form of time-frequency reassignment that is both sparse and invertible,
allowing for the recovery of the signal. This article presents an overview of
the theory and stability properties of Synchrosqueezing, as well as
applications of the technique to topics in cardiology, climate science and
economics.
</summary>
    <author>
      <name>Gaurav Thakur</name>
    </author>
    <link href="http://arxiv.org/abs/1404.7550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3373v1</id>
    <updated>2014-07-12T11:21:05Z</updated>
    <published>2014-07-12T11:21:05Z</published>
    <title>Car-following model on two lanes and stability analysis</title>
    <summary>  Considering lateral influence from adjacent lane, an improved car-following
model is developed in this paper. Then linear and non-linear stability analyses
are carried out. The modified Korteweg-de Vries (MKdV) equation is derived with
the kink-antikink soliton solution. Numerical simulations are implemented and
the result shows good consistency with theoretical study.
</summary>
    <author>
      <name>Yuhan Jia</name>
    </author>
    <author>
      <name>Jianping Wu</name>
    </author>
    <author>
      <name>Yiman Du</name>
    </author>
    <author>
      <name>Geqi Qi</name>
    </author>
    <link href="http://arxiv.org/abs/1407.3373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4388v1</id>
    <updated>2014-12-14T18:11:18Z</updated>
    <published>2014-12-14T18:11:18Z</published>
    <title>A New System For Recording The Radiological Effective Doses For Patients
  Investigated by Imaging Methods</title>
    <summary>  In this paper the project of an integrated system for radiation safety and
security of the patients investigated by radiological imaging methods is
presented. The new system is based on smart cards and Public Key
Infrastructure. The new system allows radiation effective dose data storage and
a more accurate reporting system.
</summary>
    <author>
      <name>Silviu Stanciu</name>
    </author>
    <author>
      <name>Lidia Dobrescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Congress Of Radiology ICR 2014, Dubai, United Arab
  Emirates</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.4388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.8093v1</id>
    <updated>2014-12-28T00:52:53Z</updated>
    <published>2014-12-28T00:52:53Z</published>
    <title>Multiple alignment of structures using center of proteins</title>
    <summary>  In this paper we report on an algorithm for aligning multiple protein
structures. The algorithm has been tested on a variety of inputs and it
performs well in comparison to well-known algorithms for this problem.
</summary>
    <author>
      <name>Kaushik Roy</name>
    </author>
    <author>
      <name>Satish Ch. Panigrahi</name>
    </author>
    <author>
      <name>Asish Mukhopadhyay</name>
    </author>
    <link href="http://arxiv.org/abs/1412.8093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.8093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00349v1</id>
    <updated>2015-01-02T06:31:25Z</updated>
    <published>2015-01-02T06:31:25Z</published>
    <title>Static Analysis for Biological Systems (BioAmbients)</title>
    <summary>  In this paper, I present a summary on some works that utilized static
analysis techniques for understanding biological systems. Control flow
analysis, context dependent analysis, and other techniques were employed to
investigate the properties of BioAmbients. In this summary report, I tried to
introduce the ideas and explain the techniques used in the subject papers. This
summary will highlight the biological concepts of BioAmbients.
</summary>
    <author>
      <name>A. Aziz Altowayan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00062v2</id>
    <updated>2015-04-08T22:38:46Z</updated>
    <published>2015-03-31T23:02:11Z</published>
    <title>Top Tips to Make Your Research Irreproducible</title>
    <summary>  It is an unfortunate convention of science that research should pretend to be
reproducible; our top tips will help you mitigate this fussy conventionality,
enabling you to enthusiastically showcase your irreproducible work.
</summary>
    <author>
      <name>Neil P. Chue Hong</name>
    </author>
    <author>
      <name>Tom Crick</name>
    </author>
    <author>
      <name>Ian P. Gent</name>
    </author>
    <author>
      <name>Lars Kotthoff</name>
    </author>
    <author>
      <name>Kenji Takeda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, LaTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.00062v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00062v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00851v1</id>
    <updated>2015-05-05T01:05:12Z</updated>
    <published>2015-05-05T01:05:12Z</published>
    <title>Space-Time Galerkin Projection of Electro-Magnetic Fields</title>
    <summary>  Spatial Galerkin projection transfers fields between different meshes. In the
area of finite element analysis of electromagnetic fields, it provides great
convenience for remeshing, multi-physics, domain decomposition methods, etc. In
this paper, a space-time Galerkin projection is developed in order to transfer
fields between different spatial and temporal discretization bases.
</summary>
    <author>
      <name>Zifu Wang</name>
    </author>
    <author>
      <name>Thomas Henneron</name>
    </author>
    <author>
      <name>Heath Hofmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at Compumag 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.00851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01118v1</id>
    <updated>2015-05-05T18:29:28Z</updated>
    <published>2015-05-05T18:29:28Z</published>
    <title>Energetic Galerkin Projection of Electromagnetic Fields between
  Different Meshes</title>
    <summary>  In order to project electromagnetic fields between different meshes with
respect to the conservation of energetic values, Galerkin projection
formulations based on the energetic norm are developed in this communication.
The proposed formulations are applied to an academic example.
</summary>
    <author>
      <name>Zifu Wang</name>
    </author>
    <author>
      <name>Zuqi Tang</name>
    </author>
    <author>
      <name>Thomas Henneron</name>
    </author>
    <author>
      <name>Francis Piriou</name>
    </author>
    <author>
      <name>Jean-Claude Mipo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published at Compumag 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01033v1</id>
    <updated>2016-06-29T12:44:14Z</updated>
    <published>2016-06-29T12:44:14Z</published>
    <title>An Application of the EM-algorithm to Approximate Empirical
  Distributions of Financial Indices with the Gaussian Mixtures</title>
    <summary>  In this study I briefly illustrate application of the Gaussian mixtures to
approximate empirical distributions of financial indices (DAX, Dow Jones,
Nikkei, RTSI, S&amp;P 500). The resulting distributions illustrate very high
quality of approximation as evaluated by Kolmogorov-Smirnov test. This implies
further study of application of the Gaussian mixtures to approximate empirical
distributions of financial indices.
</summary>
    <author>
      <name>Sergey Tarasenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00531v1</id>
    <updated>2016-11-02T10:18:13Z</updated>
    <published>2016-11-02T10:18:13Z</published>
    <title>Modal Analysis of Masonry Structures</title>
    <summary>  This paper presents a new numerical procedure for evaluating the vibration
frequencies and mode shapes of masonry buildings in the presence of cracks. The
algorithm has been implemented within the NOSA-ITACA code, which models masonry
as a nonlinear elastic material with zero tensile strength. Some case studies
are reported, and the differences between linear and nonlinear behavior
highlighted.
</summary>
    <author>
      <name>Maria Girardi</name>
    </author>
    <author>
      <name>Cristina Padovani</name>
    </author>
    <author>
      <name>Daniele Pellegrini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, 23 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.00531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.09876v1</id>
    <updated>2017-03-29T03:48:14Z</updated>
    <published>2017-03-29T03:48:14Z</published>
    <title>Efficient Spatial Variation Characterization via Matrix Completion</title>
    <summary>  In this paper, we propose a novel method to estimate and characterize spatial
variations on dies or wafers. This new technique exploits recent developments
in matrix completion, enabling estimation of spatial variation across wafers or
dies with a small number of randomly picked sampling points while still
achieving fairly high accuracy. This new approach can be easily generalized,
including for estimation of mixed spatial and structure or device type
information.
</summary>
    <author>
      <name>Hongge Chen</name>
    </author>
    <author>
      <name>Duane Boning</name>
    </author>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1703.09876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.09876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.10434v1</id>
    <updated>2019-04-23T17:29:21Z</updated>
    <published>2019-04-23T17:29:21Z</published>
    <title>Data-driven Computing in Elasticity via Chebyshev Approximation</title>
    <summary>  This paper proposes a data-driven approach for computing elasticity by means
of a non-parametric regression approach rather than an optimization approach.
The Chebyshev approximation is utilized for tackling the material data-sets
non-linearity of the elasticity. Also, additional efforts have been taken to
compare the results with several other state-of-the-art methodologies.
</summary>
    <author>
      <name>Rahul-Vigneswaran K</name>
    </author>
    <author>
      <name>Neethu Mohan</name>
    </author>
    <author>
      <name>Soman KP</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, Accepted for ICCS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.10434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.10434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.10151v1</id>
    <updated>2019-07-22T13:01:54Z</updated>
    <published>2019-07-22T13:01:54Z</published>
    <title>Calculating phase diagrams with ATAT</title>
    <summary>  This document is a short and informal tutorial on some aspects of calculating
phase diagrams with the ATAT-tools emc2 and phb and on creating cluster
expansions with maps. It is neither complete, nor in any way an official
document, but mainly a set of collected notes I took during experimentation
with ATAT.
</summary>
    <author>
      <name>Martin Bäker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.10151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.08097v1</id>
    <updated>2020-05-16T20:47:07Z</updated>
    <published>2020-05-16T20:47:07Z</published>
    <title>Kaemika app, Integrating protocols and chemical simulation</title>
    <summary>  Kaemika is an app available on the four major app stores. It provides
deterministic and stochastic simulation, supporting natural chemical notation
enhanced with recursive and conditional generation of chemical reaction
networks. It has a liquid-handling protocol sublanguage compiled to a virtual
digital microfluidic device. Chemical and microfluidic simulations can be
interleaved for full experimental-cycle modeling. A novel and unambiguous
representation of directed multigraphs is used to lay out chemical reaction
networks in graphical form.
</summary>
    <author>
      <name>Luca Cardelli</name>
    </author>
    <link href="http://arxiv.org/abs/2005.08097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.08097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.07799v1</id>
    <updated>2021-05-17T13:14:49Z</updated>
    <published>2021-05-17T13:14:49Z</published>
    <title>Efficient yield optimization with limited gradient information</title>
    <summary>  In this work an efficient strategy for yield optimization with uncertain and
deterministic optimization variables is presented. The gradient based adaptive
Newton-Monte Carlo method is modified, such that it can handle variables with
(uncertain parameters) and without (deterministic parameters) analytical
gradient information. This mixed strategy is numerically compared to derivative
free approaches.
</summary>
    <author>
      <name>Mona Fuhrländer</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/2105.07799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.07799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G15, 60H35, 65K99, 78M31," scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.1; G.1.2; G.1.6; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.05348v1</id>
    <updated>2021-08-04T14:07:13Z</updated>
    <published>2021-08-04T14:07:13Z</published>
    <title>Notes on Perfectly Matched Layers (PMLs)</title>
    <summary>  This note is intended as a brief introduction to the theory and practice of
perfectly matched layer (PML) absorbing boundaries for wave equations,
originally developed for MIT courses 18.369 and 18.336. It focuses on the
complex stretched-coordinate viewpoint, and also discusses the limitations of
PML.
</summary>
    <author>
      <name>Steven G. Johnson</name>
    </author>
    <link href="http://arxiv.org/abs/2108.05348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.05348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.01370v1</id>
    <updated>2021-09-21T14:53:00Z</updated>
    <published>2021-09-21T14:53:00Z</published>
    <title>The influence of deflections on the static and dynamic behaviour of
  masonry columns</title>
    <summary>  This paper studies the influence of bending deflections on the structural
behaviour of masonry columns. Some explicit solutions are presented, and the
combined effects of the constitutive and geometric nonlinearities are
investigated through an iterative numerical procedure. The results show that
considering second-order effects affects both the collapse load and the
dynamical properties of masonry beams significantly.
</summary>
    <author>
      <name>M. Girardi</name>
    </author>
    <author>
      <name>C. Padovani</name>
    </author>
    <author>
      <name>D. Pellegrini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.euromechsol.2022.104570</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.euromechsol.2022.104570" rel="related"/>
    <link href="http://arxiv.org/abs/2110.01370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.01370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.2843v3</id>
    <updated>2013-06-23T16:40:20Z</updated>
    <published>2013-06-11T05:45:57Z</published>
    <title>On Some Recent Insights in Integral Biomathics</title>
    <summary>  This paper summarizes the results in Integral Biomathics obtained to this
moment and provides an outlook for future research in the field.
</summary>
    <author>
      <name>Plamen L. Simeonov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.pbiomolbio.2013.06.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.pbiomolbio.2013.06.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 0 figures. In Journal Progress in Biophysics and Molecular
  Biology, 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Progress in Biophysics and Molecular Biology, Vol. 113, Issues 1,
  2013, pp. 216-228</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.2843v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.2843v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.09686v2</id>
    <updated>2020-06-08T10:24:27Z</updated>
    <published>2020-01-27T10:54:08Z</published>
    <title>Solving Maxwell's Eigenvalue Problem via Isogeometric Boundary Elements
  and a Contour Integral Method</title>
    <summary>  We solve Maxwell's eigenvalue problem via isogeometric boundary elements and
a contour integral method. We discuss the analytic properties of the
discretisation, outline the implementation, and showcase numerical examples.
</summary>
    <author>
      <name>Stefan Kurz</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Gerhard Unger</name>
    </author>
    <author>
      <name>Felix Wolf</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/mma.7447</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/mma.7447" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Methods in the Applied Sciences, May 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.09686v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.09686v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34L16, 35P30, 65N38, 65D07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.01227v2</id>
    <updated>2022-01-06T13:29:47Z</updated>
    <published>2022-01-04T16:14:23Z</published>
    <title>Sparse Non-Convex Optimization For Higher Moment Portfolio Management</title>
    <summary>  One of the reasons that higher order moment portfolio optimization methods
are not fully used by practitioners in investment decisions is the complexity
that these higher moments create by making the optimization problem nonconvex.
Many few methods and theoretical results exists in the literature, but the
present paper uses the method of successive convex approximation for the
mean-variance-skewness problem.
</summary>
    <author>
      <name>Farshad Noravesh</name>
    </author>
    <link href="http://arxiv.org/abs/2201.01227v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.01227v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.08966v1</id>
    <updated>2022-05-09T06:04:58Z</updated>
    <published>2022-05-09T06:04:58Z</published>
    <title>A Tutorial on Structural Optimization</title>
    <summary>  Structural optimization is a useful and interesting tool. Unfortunately, it
can be hard for new researchers to get started on the topic because existing
tutorials assume the reader has substantial domain knowledge. They obscure the
fact that structural optimization is really quite simple, elegant, and easy to
implement. With that in mind, let's write our own structural optimization code,
from scratch, in 180 lines.
</summary>
    <author>
      <name>Sam Greydanus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.08966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.08966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.00422v1</id>
    <updated>2022-09-01T13:01:09Z</updated>
    <published>2022-09-01T13:01:09Z</published>
    <title>An energetically consistent surface correction method for bond-based
  peridynamics</title>
    <summary>  A novel surface correction method is proposed for bond based peridynamics
which ensures energy consistency with a classical reference body for general
affine deformations. This method is validated for simple geometries and then
applied to a typical surface-dominated problem, namely the indentation of a
surface in the shallow to moderate-depth regime.
</summary>
    <author>
      <name>Jonas Ritter</name>
    </author>
    <author>
      <name>Shucheta Shegufta</name>
    </author>
    <author>
      <name>Paul Steinmann</name>
    </author>
    <author>
      <name>Michael Zaiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures, submitted to Forces in Mechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.00422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.00422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.13028v1</id>
    <updated>2023-09-22T17:43:09Z</updated>
    <published>2023-09-22T17:43:09Z</published>
    <title>Minimization of energy functionals via FEM: implementation of hp-FEM</title>
    <summary>  Many problems in science and engineering can be rigorously recast into
minimizing a suitable energy functional. We have been developing efficient and
flexible solution strategies to tackle various minimization problems by
employing finite element discretization with P1 triangular elements [1,2]. An
extension to rectangular hp-finite elements in 2D is introduced in this
contribution.
</summary>
    <author>
      <name>Miroslav Frost</name>
    </author>
    <author>
      <name>Alexej Moskovka</name>
    </author>
    <author>
      <name>Jan Valdman</name>
    </author>
    <link href="http://arxiv.org/abs/2309.13028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.13028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.13380v1</id>
    <updated>2024-03-20T08:22:24Z</updated>
    <published>2024-03-20T08:22:24Z</published>
    <title>A characteristics-based method for shock-ramp data analysis</title>
    <summary>  For the data analysis problem of shock-ramp compression, i.e., ramp
compression after a relatively strong initial shock, a characteristics-based
method that strictly deals with the initial hydrodynamic shock is described in
detail. Validation of this analysis method using simulated shock-ramp data
generated by molecular dynamics and one-dimensional radiation hydrodynamic code
is also presented.
</summary>
    <author>
      <name>Jingxiang Shen</name>
    </author>
    <author>
      <name>Wei Kang</name>
    </author>
    <link href="http://arxiv.org/abs/2403.13380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.13380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.09673v1</id>
    <updated>2025-04-13T17:54:25Z</updated>
    <published>2025-04-13T17:54:25Z</published>
    <title>Earthquake Simulation</title>
    <summary>  This paper presents a seismic activity simulator that models the effects of
fault lines on surface pressure. This project uses C programming to create a
fully interactive learning resource intended to educate users on the mechanics
of earthquakes. The motivation behind this project is to make studying seismic
activity more accessible, engaging and cost effective.
</summary>
    <author>
      <name>Palak Chawla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.09673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.09673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904003v1</id>
    <updated>1999-04-11T08:21:13Z</updated>
    <published>1999-04-11T08:21:13Z</published>
    <title>The Structure of Weighting Coefficient Matrices of Harmonic Differential
  Quadrature and Its Applications</title>
    <summary>  The structure of weighting coefficient matrices of Harmonic Differential
Quadrature (HDQ) is found to be either centrosymmetric or skew centrosymmetric
depending on the order of the corresponding derivatives. The properties of both
matrices are briefly discussed in this paper. It is noted that the
computational effort of the harmonic quadrature for some problems can be
further reduced up to 75 per cent by using the properties of the
above-mentioned matrices.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>W. Wang</name>
    </author>
    <author>
      <name>T. Zhong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 table, Original MS. Word format, published in Common.
  Numer. Methods. Engrg</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Commnuications in Numerical Methods in Engineering, 12 (1996), pp.
  455-459</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9904003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3, G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904021v1</id>
    <updated>1999-04-28T13:12:47Z</updated>
    <published>1999-04-28T13:12:47Z</published>
    <title>Hadamard product nonlinear formulation of Galerkin and finite element
  methods</title>
    <summary>  A novel nonlinear formulation of the finite element and Galerkin methods is
presented here, which leads to the Hadamard product expression of the resultant
nonlinear algebraic analogue. The presented formulation attains the advantages
of weak formulation in the standard finite element and Galerkin schemes and
avoids the costly repeated numerical integration of the Jacobian matrix via the
recently developed SJT product approach. This also provides possibility of the
nonlinear decoupling computations.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, welcome any comments to author: chenw@homer.shinshu-u.ac.jp
  or chenwwhy@hotmail.com</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9904021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2; G.1.5; G.1.8, G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905016v1</id>
    <updated>1999-05-27T23:58:05Z</updated>
    <published>1999-05-27T23:58:05Z</published>
    <title>Programs with Stringent Performance Objectives Will Often Exhibit
  Chaotic Behavior</title>
    <summary>  Software for the resolution of certain kind of problems, those that rate high
in the Stringent Performance Objectives adjustment factor (IFPUG scheme), can
be described using a combination of game theory and autonomous systems. From
this description it can be shown that some of those problems exhibit chaotic
behavior, an important fact in understanding the functioning of the related
software. As a relatively simple example, it is shown that chess exhibits
chaotic behavior in its configuration space. This implies that static
evaluators in chess programs have intrinsic limitations.
</summary>
    <author>
      <name>M. Chaves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9905016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N05,68Q20,90D05,90D80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907020v2</id>
    <updated>1999-07-14T11:52:11Z</updated>
    <published>1999-07-12T11:34:56Z</published>
    <title>Generalized linearization in nonlinear modeling of data</title>
    <summary>  The principal innovative idea in this paper is to transform the original
complex nonlinear modeling problem into a combination of linear problem and
very simple nonlinear problems. The key step is the generalized linearization
of nonlinear terms. This paper only presents the introductory strategy of this
methodology. The practical numerical experiments will be provided subsequently.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This modified version of the original paper corrected two crucial
  errors in Eqs. (1) and (3). The interested readers may contact the author in
  chenw@homer.shinshu-u.ac.jp or chenwwhy@hotmail.com</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9907020v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907020v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102010v1</id>
    <updated>2001-02-10T14:13:07Z</updated>
    <published>2001-02-10T14:13:07Z</published>
    <title>The Enhanced Double Digest Problem for DNA Physical Mapping</title>
    <summary>  The double digest problem is a common NP-hard approach to constructing
physical maps of DNA sequences. This paper presents a new approach called the
enhanced double digest problem. Although this new problem is also NP-hard, it
can be solved in linear time in certain theoretically interesting cases.
</summary>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Jared Samet</name>
    </author>
    <author>
      <name>Wing-Kin Sung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A preliminary version appeared in M. Halldorsson, editor, Lecture
  Notes in Computer Science 1851: Proceedings of the 7th Scandinavian Workshop
  on Algorithm Theory, pages 383--392. Springer-Verlag, New York, NY, 2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0102010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.2.3; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104014v1</id>
    <updated>2001-04-09T08:49:57Z</updated>
    <published>2001-04-09T08:49:57Z</published>
    <title>Tracing a Faint Fingerprint of the Invisible Hand?</title>
    <summary>  Any economic agent constituting the monetary economy maintains the activity
of monetary flow equilibration for fulfilling the condition of monetary flow
continuity in the record, except at the central bank. At the same time,
monetary flow equilibration at one economic agent constantly induces at other
agents in the economy further flow disequilibrium to be eliminated
subsequently. We propose the rate of monetary flow disequilibration as a figure
measuring the progressive movement of the economy. The rate of disequilibration
was read out of both the Japanese and the United States monetary economy
recorded over the last fifty years.
</summary>
    <author>
      <name>Koichiro Matsuno</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0104014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0203023v1</id>
    <updated>2002-03-19T10:05:58Z</updated>
    <published>2002-03-19T10:05:58Z</published>
    <title>Agent trade servers in financial exchange systems</title>
    <summary>  New services based on the best-effort paradigm could complement the current
deterministic services of an electronic financial exchange. Four crucial
aspects of such systems would benefit from a hybrid stance: proper use of
processing resources, bandwidth management, fault tolerance, and exception
handling. We argue that a more refined view on Quality-of-Service control for
exchange systems, in which the principal ambition of upholding a fair and
orderly marketplace is left uncompromised, would benefit all interested
parties.
</summary>
    <author>
      <name>David Lyback</name>
    </author>
    <author>
      <name>Magnus Boman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0203023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0203023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.11; J.4; K.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204051v1</id>
    <updated>2002-04-26T12:20:08Z</updated>
    <published>2002-04-26T12:20:08Z</published>
    <title>Parrondo Strategies for Artificial Traders</title>
    <summary>  On markets with receding prices, artificial noise traders may consider
alternatives to buy-and-hold. By simulating variations of the Parrondo
strategy, using real data from the Swedish stock market, we produce first
indications of a buy-low-sell-random Parrondo variation outperforming
buy-and-hold. Subject to our assumptions, buy-low-sell-random also outperforms
the traditional value and trend investor strategies. We measure the success of
the Parrondo variations not only through their performance compared to other
kinds of strategies, but also relative to varying levels of perfect
information, received through messages within a multi-agent system of
artificial traders.
</summary>
    <author>
      <name>Magnus Boman</name>
    </author>
    <author>
      <name>Stefan Johansson</name>
    </author>
    <author>
      <name>David Lyback</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Intelligent Agent Technology; Zhong, Liu, Ohsuga, Bradshaw (eds);
  150-159; World Scientific, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.11; J.4; K.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206013v1</id>
    <updated>2002-06-08T10:46:56Z</updated>
    <published>2002-06-08T10:46:56Z</published>
    <title>High-order fundamental and general solutions of convection-diffusion
  equation and their applications with boundary particle method</title>
    <summary>  In this study, we presented the high-order fundamental solutions and general
solutions of convection-diffusion equation. To demonstrate their efficacy, we
applied the high-order general solutions to the boundary particle method (BPM)
for the solution of some inhomogeneous convection-diffusion problems, where the
BPM is a new truly boundary-only meshfree collocation method based on multiple
reciprocity principle. For the sake of completeness, the BPM is also briefly
described here.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Int. J. of Engng. Anal. Bound Elem very soon. The
  present version has a little difference from the journal version. Welcome to
  contact wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0206013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206039v1</id>
    <updated>2002-06-25T09:12:16Z</updated>
    <published>2002-06-25T09:12:16Z</published>
    <title>Hidden Markov model segmentation of hydrological and enviromental time
  series</title>
    <summary>  Motivated by Hubert's segmentation procedure we discuss the application of
hidden Markov models (HMM) to the segmentation of hydrological and enviromental
time series. We use a HMM algorithm which segments time series of several
hundred terms in a few seconds and is computationally feasible for even longer
time series. The segmentation algorithm computes the Maximum Likelihood
segmentation by use of an expectation / maximization iteration. We rigorously
prove algorithm convergence and use numerical experiments, involving
temperature and river discharge time series, to show that the algorithm usually
converges to the globally optimal segmentation. The relation of the proposed
algorithm to Hubert's segmentation procedure is also discussed.
</summary>
    <author>
      <name>Ath. Kehagias</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0206039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207018v1</id>
    <updated>2002-07-04T12:20:24Z</updated>
    <published>2002-07-04T12:20:24Z</published>
    <title>Definitions of distance function in radial basis function approach</title>
    <summary>  Very few studies involve how to construct the efficient RBFs by means of
problem features. Recently the present author presented general solution RBF
(GS-RBF) methodology to create operator-dependent RBFs successfully [1]. On the
other hand, the normal radial basis function (RBF) is defined via Euclidean
space distance function or the geodesic distance [2]. This purpose of this note
is to redefine distance function in conjunction with problem features, which
include problem-dependent and time-space distance function.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0207018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207033v1</id>
    <updated>2002-07-09T19:53:42Z</updated>
    <published>2002-07-09T19:53:42Z</published>
    <title>Reducing the Computational Requirements of the Differential Quadrature
  Method</title>
    <summary>  This paper shows that the weighting coefficient matrices of the differential
quadrature method (DQM) are centrosymmetric or skew-centrosymmetric if the grid
spacings are symmetric irrespective of whether they are equal or unequal. A new
skew centrosymmetric matrix is also discussed. The application of the
properties of centrosymmetric and skew centrosymmetric matrix can reduce the
computational effort of the DQM for calculations of the inverse, determinant,
eigenvectors and eigenvalues by 75%. This computational advantage are also
demonstrated via several numerical examples.
</summary>
    <author>
      <name>W Chen</name>
    </author>
    <author>
      <name>Xinwei Wang</name>
    </author>
    <author>
      <name>Yongxi Yu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Numerical Methods for Partial Differential Equations, 12, 565-577,
  1996</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0207033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208022v1</id>
    <updated>2002-08-15T03:45:36Z</updated>
    <published>2002-08-15T03:45:36Z</published>
    <title>Symbolic Methodology in Numeric Data Mining: Relational Techniques for
  Financial Applications</title>
    <summary>  Currently statistical and artificial neural network methods dominate in
financial data mining. Alternative relational (symbolic) data mining methods
have shown their effectiveness in robotics, drug design and other applications.
Traditionally symbolic methods prevail in the areas with significant
non-numeric (symbolic) knowledge, such as relative location in robot
navigation. At first glance, stock market forecast looks as a pure numeric area
irrelevant to symbolic methods. One of our major goals is to show that
financial time series can benefit significantly from relational data mining
based on symbolic methods. The paper overviews relational data mining
methodology and develops this techniques for financial data mining.
</summary>
    <author>
      <name>B. Kovalerchuk</name>
    </author>
    <author>
      <name>E. Vityaev</name>
    </author>
    <author>
      <name>H. Yusupov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 1 figure, 16 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0208022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208030v1</id>
    <updated>2002-08-20T12:36:06Z</updated>
    <published>2002-08-20T12:36:06Z</published>
    <title>A direct time-domain FEM modeling of broadband frequency-dependent
  absorption with the presence of matrix fractional power: Model I</title>
    <summary>  The frequency-dependent attenuation of broadband acoustics is often
confronted in many different areas. However, the related time domain simulation
is rarely found in literature due to enormous technical difficulty. The
currently popular relaxation models with the presence of convolution operation
require some material parameters which are not readily available. In this
study, three reports are contributed to address broadband ultrasound
frequency-dependent absorptions using the readily available empirical
parameters. This report is the first in series concerned with developing a
direct time domain FEM formulation. The next two reports are about the
frequency decomposition model and the fractional derivative model.
</summary>
    <author>
      <name>W Chen</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0208030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.8, G1.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0209001v1</id>
    <updated>2002-09-02T03:52:48Z</updated>
    <published>2002-09-02T03:52:48Z</published>
    <title>A Novel Statistical Diagnosis of Clinical Data</title>
    <summary>  In this paper, we present a diagnosis method of diseases from clinical data.
The data are routine test such as urine test, hematology, chemistries etc.
Though those tests have been done for people who check in medical institutes,
how each item of the data interacts each other and which combination of them
cause a disease are neither understood nor studied well. Here we attack the
practically important problem by putting the data into mathematical setup and
applying support vector machine. Finally we present simulation results for
fatty liver, gastritis etc and discuss about their implications.
</summary>
    <author>
      <name>Gene Kim</name>
    </author>
    <author>
      <name>MyungHo Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0209001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0209001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.1.2; H.1.1; I.5.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0210005v1</id>
    <updated>2002-10-07T19:28:50Z</updated>
    <published>2002-10-07T19:28:50Z</published>
    <title>Positive time fractional derivative</title>
    <summary>  In mathematical modeling of the non-squared frequency-dependent diffusions,
also known as the anomalous diffusions, it is desirable to have a positive real
Fourier transform for the time derivative of arbitrary fractional or odd
integer order. The Fourier transform of the fractional time derivative in the
Riemann-Liouville and Caputo senses, however, involves a complex power function
of the fractional order. In this study, a positive time derivative of
fractional or odd integer order is introduced to respect the positivity in
modeling the anomalous diffusions.
</summary>
    <author>
      <name>W Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0210005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0210005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.1.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302034v2</id>
    <updated>2005-10-05T21:07:53Z</updated>
    <published>2003-02-25T02:48:42Z</published>
    <title>Interest Rate Model Calibration Using Semidefinite Programming</title>
    <summary>  We show that, for the purpose of pricing Swaptions, the Swap rate and the
corresponding Forward rates can be considered lognormal under a single
martingale measure. Swaptions can then be priced as options on a basket of
lognormal assets and an approximation formula is derived for such options. This
formula is centered around a Black-Scholes price with an appropriate
volatility, plus a correction term that can be interpreted as the expected
tracking error. The calibration problem can then be solved very efficiently
using semidefinite programming.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematical Finance 10(3), pp. 183-213, September 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0302034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302035v2</id>
    <updated>2005-10-05T21:28:13Z</updated>
    <published>2003-02-25T03:09:11Z</published>
    <title>Risk-Management Methods for the Libor Market Model Using Semidefinite
  Programming</title>
    <summary>  When interest rate dynamics are described by the Libor Market Model as in
BGM97, we show how some essential risk-management results can be obtained from
the dual of the calibration program. In particular, if the objetive is to
maximize another swaption's price, we show that the optimal dual variables
describe a hedging portfolio in the sense of \cite{Avel96}. In the general
case, the local sensitivity of the covariance matrix to all market movement
scenarios can be directly computed from the optimal dual solution. We also show
how semidefinite programming can be used to manage the Gamma exposure of a
portfolio.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Finance 8(4), pp. 77-99, Summer 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0302035v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302035v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306105v1</id>
    <updated>2003-06-17T07:01:43Z</updated>
    <published>2003-06-17T07:01:43Z</published>
    <title>Design, implementation and deployment of the Saclay muon reconstruction
  algorithms (Muonbox/y) in the Athena software framework of the ATLAS
  experiment</title>
    <summary>  This paper gives an overview of a reconstruction algorithm for muon events in
ATLAS experiment at CERN. After a short introduction on ATLAS Muon
Spectrometer, we will describe the procedure performed by the algorithms
Muonbox and Muonboy (last version) in order to achieve correctly the
reconstruction task. These algorithms have been developed in Fortran language
and are working in the official C++ framework Athena, as well as in stand alone
mode. A description of the interaction between Muonboy and Athena will be
given, together with the reconstruction performances (efficiency and momentum
resolution) obtained with MonteCarlo data.
</summary>
    <author>
      <name>Andrea Formica</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 8 figures, CHEP2003 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307039v1</id>
    <updated>2003-07-17T15:41:13Z</updated>
    <published>2003-07-17T15:41:13Z</published>
    <title>Modeling Business</title>
    <summary>  Business concepts are studied using a metamodel-based approach, using UML
2.0. The Notation Independent Business concepts metamodel is introduced. The
approach offers a mapping between different business modeling notations which
could be used for bridging BM tools and boosting the MDA approach.
</summary>
    <author>
      <name>Valdis Vitolins</name>
    </author>
    <author>
      <name>Audris Kalnins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 figures, Proceedings of Internation Conference 'Modeling
  and Simulation of Business Systems", Vilnius, Lithuania (May 13-14, 2003)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vitolins Valdis, Audris Kalnins. Modeling Business. Modeling and
  Simulation of Business Systems, Kaunas University of Technology Press,
  Vilnius, May 13-14, 2003, pp. 215.-220.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0307039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5; J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307054v1</id>
    <updated>2003-07-24T14:01:16Z</updated>
    <published>2003-07-24T14:01:16Z</published>
    <title>Contributions to the Development and Improvement of a Regulatory and
  Pre-Regulatory Digitally System for the Tools within Flexible Fabrication
  Systems</title>
    <summary>  The paper reports the obtained results for the projection and realization of
a digitally system aiming to assist the equipment for a regulatory and
pre-regulatory tools and holding tools within the flexible fabrication systems
(FFS). Moreover, based on the present results, the same methodology can be
applied for assisting tools from the point of view of their integrity and to
wear compensation in the FFS framework.
</summary>
    <author>
      <name>Viorel Putz</name>
    </author>
    <author>
      <name>Mihai V. Putz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307061v1</id>
    <updated>2003-07-28T09:35:52Z</updated>
    <published>2003-07-28T09:35:52Z</published>
    <title>Boundary knot method for Laplace and biharmonic problems</title>
    <summary>  The boundary knot method (BKM) [1] is a meshless boundary-type radial basis
function (RBF) collocation scheme, where the nonsingular general solution is
used instead of fundamental solution to evaluate the homogeneous solution,
while the dual reciprocity method (DRM) is employed to approximation of
particular solution. Despite the fact that there are not nonsingular RBF
general solutions available for Laplace and biharmonic problems, this study
shows that the method can be successfully applied to these problems. The
high-order general and fundamental solutions of Burger and Winkler equations
are also first presented here.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3; G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405054v1</id>
    <updated>2004-05-17T09:39:03Z</updated>
    <published>2004-05-17T09:39:03Z</published>
    <title>The model of the tables in design documentation for operating with the
  electronic catalogs and for specifications making in a CAD system</title>
    <summary>  The hierarchic block model of the tables in design documentation as a part of
a CAD system is described, intended for automatic specifications making of
elements of the drawings, with usage of the electronic catalogs. The model is
created for needs of a CAD system of reconstruction of the industrial plants,
where the result of designing are the drawings, which include the
specifications of different types. The adequate simulation of the specification
tables is ensured with technology of storing in the drawing of the visible
geometric elements and invisible parametric representation, sufficient for
generation of this elements.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2, I.2.1, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405056v1</id>
    <updated>2004-05-17T10:14:12Z</updated>
    <published>2004-05-17T10:14:12Z</published>
    <title>Modular technology of developing of the extensions of a CAD system. The
  axonometric piping diagrams. Common and special operations</title>
    <summary>  Applying the modular technology of developing of the problem-oriented
extensions of a CAD system to a problem of automation of creating of the
axonometric piping diagrams on an example of the program system TechnoCAD
GlassX is described. The features of realization of common operations,
composition and realization of special operations of a designing of the schemas
of the special technological pipe lines, systems of a water line and water
drain, heating, heat supply, ventilating, air conditioning are reviewed.
</summary>
    <author>
      <name>Ilsur T. Safin</name>
    </author>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <author>
      <name>Rustem R. Kafiatullov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405057v1</id>
    <updated>2004-05-17T10:34:16Z</updated>
    <published>2004-05-17T10:34:16Z</published>
    <title>Mathematical and programming toolkit of the computer aided design of the
  axonometric piping diagrams</title>
    <summary>  The problem of the automation of the designing of the axonometric piping
diagrams include, as the minimum, manipulations with the flat schemas of
three-dimensional wireframe objects (with dimension of 2,5). The specialized
model, methodical and mathematical approaches are required because of large
bulk of calculuss. Coordinate systems, data types, common principles of
realization of operation with data and composition of the basic operations are
described which are realised in the complex CAD system of the reconstruction of
the plants TechnoCAD GlassX.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, no figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0407029v1</id>
    <updated>2004-07-10T16:17:26Z</updated>
    <published>2004-07-10T16:17:26Z</published>
    <title>Static versus Dynamic Arbitrage Bounds on Multivariate Option Prices</title>
    <summary>  We compare static arbitrage price bounds on basket calls, i.e. bounds that
only involve buy-and-hold trading strategies, with the price range obtained
within a multi-variate generalization of the Black-Scholes model. While there
is no gap between these two sets of prices in the univariate case, we observe
here that contrary to our intuition about model risk for at-the-money calls,
there is a somewhat large gap between model prices and static arbitrage prices,
hence a similarly large set of prices on which a multivariate Black-Scholes
model cannot be calibrated but where no conclusion can be drawn on the presence
or not of a static arbitrage opportunity.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IMA series</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0407029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0407029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412029v1</id>
    <updated>2004-12-08T08:42:53Z</updated>
    <published>2004-12-08T08:42:53Z</published>
    <title>The modular technology of development of the CAD expansions: profiles of
  outside networks of water supply and water drain</title>
    <summary>  The modular technology of development of the problem-oriented CAD expansions
is applied to a task of designing of profiles of outside networks of water
supply and water drain with realization in program system TechnoCAD GlassX. The
unity of structure of this profiles is revealed, the system model of the
drawings of profiles of networks is developed including the structured
parametric representation (properties of objects and their interdependence,
general settings and default settings) and operations with it, which
efficiently automate designing
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <author>
      <name>Rustem R. Kafiyatullov</name>
    </author>
    <author>
      <name>Ilsur T. Safin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412030v1</id>
    <updated>2004-12-08T08:49:08Z</updated>
    <published>2004-12-08T08:49:08Z</published>
    <title>The modular technology of development of the CAD expansions: protection
  of the buildings from the lightning</title>
    <summary>  The modular technology of development of the problem-oriented CAD expansions
is applied to a task of designing of protection of the buildings from the
lightning with realization in program system TechnoCAD GlassX. The system model
of the drawings of lightning protection is developed including the structured
parametric representation (properties of objects and their interdependence,
general settings and default settings) and operations with it, which
efficiently automate designing
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <author>
      <name>Rustem R. Kafiyatullov</name>
    </author>
    <author>
      <name>Ilsur T. Safin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412031v1</id>
    <updated>2004-12-08T08:52:28Z</updated>
    <published>2004-12-08T08:52:28Z</published>
    <title>The Features of the Complex CAD system of Reconstruction of the
  Industrial Plants</title>
    <summary>  The features of designing of reconstruction of the acting plant by its design
department are considered: the results of work are drawings corresponding with
the national standards; large number of the small projects for different acting
objects; variety of the types of the drawings in one project; large paper
archive. The models and methods of developing of the complex CAD system with
friend uniform environment of designing, with setting a profile of operations,
with usage of the general parts of the project, with a series of
problem-oriented subsystems are described on an example of a CAD system
TechnoCAD GlassX
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, no figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412032v1</id>
    <updated>2004-12-08T08:57:49Z</updated>
    <published>2004-12-08T08:57:49Z</published>
    <title>The methods of support of the requirements of the Russian standards at
  development of a CAD of industrial objects</title>
    <summary>  The methods of support of the requirements of the Russian standards in a CAD
of industrial objects are explained, which were implemented in the CAD system
TechnoCAD GlassX with an own graphics core and own structures of data storage.
It is rotined, that the binding of storage structures and program code of a CAD
to the requirements of standards enable not only to fulfil these requirements
in project documentation, but also to increase a degree of compactness of
storage of drawings both on the disk and in the RAM
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412033v1</id>
    <updated>2004-12-08T09:01:20Z</updated>
    <published>2004-12-08T09:01:20Z</published>
    <title>The modelling of the build constructions in a CAD of the renovation of
  the enterprises by means of units in the drawings</title>
    <summary>  The parametric model of build constructions and features of design operations
are described for making drawings, which are the common component of the
different parts of the projects of renovation of enterprises. The key moment of
the deep design automation is the using of so-called units in the drawings,
which are joining a visible graphic part and invisible parameters. The model
has passed check during designing of several hundreds of drawings
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412034v1</id>
    <updated>2004-12-08T11:08:48Z</updated>
    <published>2004-12-08T11:08:48Z</published>
    <title>The informatization of design works at industry firm during its
  renovation</title>
    <summary>  The characteristic of design works on firm at its renovation and of the
common directions of their informatization is given. The implantation of a CAD
is selected as the key direction, and the requirements to a complex CAD-system
are stated. The methods of such a CAD-system development are featured, and the
connectedness of this development with the process of integration of
information space of design department of the firm is characterized. The
experience of development and implantation of a complex CAD of renovation of
firms TechnoCAD GlassX lies in a basis of this reviewing
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502007v1</id>
    <updated>2005-02-02T00:12:45Z</updated>
    <published>2005-02-02T00:12:45Z</published>
    <title>Identification of complex systems in the basis of wavelets</title>
    <summary>  In this paper is proposed the method of the identification of complex dynamic
systems. Method can be used for the identification of linear and nonlinear
complex dynamic systems for the determined or stochastic signals at the inputs
and the outputs. It is proposed to use a basis of wavelets for obtaining the
impulse transient function (ITF) of system. ITF is considered in the form of
surface in the 3D space. Are given the results of experiments on the
identification of systems in the basis of wavelets.
</summary>
    <author>
      <name>Alexander Shaydurov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0502007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0507025v1</id>
    <updated>2005-07-08T15:14:51Z</updated>
    <published>2005-07-08T15:14:51Z</published>
    <title>Comparison of Resampling Schemes for Particle Filtering</title>
    <summary>  This contribution is devoted to the comparison of various resampling
approaches that have been proposed in the literature on particle filtering. It
is first shown using simple arguments that the so-called residual and
stratified methods do yield an improvement over the basic multinomial
resampling approach. A simple counter-example showing that this property does
not hold true for systematic resampling is given. Finally, some results on the
large-sample behavior of the simple bootstrap filter algorithm are given. In
particular, a central limit theorem is established for the case where
resampling is performed using the residual approach.
</summary>
    <author>
      <name>Randal Douc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMAP</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Cappé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Moulines</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Image and Signal Processing and Analysis, 2005. ISPA 2005.
  Proceedings of the 4th International Symposium on (2005) 64-69</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0507025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0507025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509002v1</id>
    <updated>2005-08-31T21:57:04Z</updated>
    <published>2005-08-31T21:57:04Z</published>
    <title>Component Based Programming in Scientific Computing: The Viable Approach</title>
    <summary>  Computational scientists are facing a new era where the old ways of
developing and reusing code have to be left behind and a few daring steps are
to be made towards new horizons. The present work analyzes the needs that drive
this change, the factors that contribute to the inertia of the community and
slow the transition, the status and perspective of present attempts, the
principle, practical and technical problems that are to be addressed in the
short and long run.
</summary>
    <author>
      <name>Zsolt I. Lázár</name>
    </author>
    <author>
      <name>Jouke R. Heringa</name>
    </author>
    <author>
      <name>Bazil Pârv</name>
    </author>
    <author>
      <name>Simon W. de Leeuw</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0509002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.13; D.2.12; D.2.11; D.2.9; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509003v1</id>
    <updated>2005-08-31T22:48:40Z</updated>
    <published>2005-08-31T22:48:40Z</published>
    <title>COMODI: Architecture for a Component-Based Scientific Computing System</title>
    <summary>  The COmputational MODule Integrator (COMODI) is an initiative aiming at a
component based framework, component developer tool and component repository
for scientific computing. We identify the main ingredients to a solution that
would be sufficiently appealing to scientists and engineers to consider
alternatives to their deeply rooted programming traditions. The overall
structure of the complete solution is sketched with special emphasis on the
Component Developer Tool standing at the basis of COMODI.
</summary>
    <author>
      <name>Zsolt I. Lázár</name>
    </author>
    <author>
      <name>Lehel István Kovács</name>
    </author>
    <author>
      <name>Bazil Pârv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0509003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.13; D.2.12; D.2.11; D.2.9; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510027v2</id>
    <updated>2006-06-15T17:05:08Z</updated>
    <published>2005-10-11T13:40:17Z</published>
    <title>A Market Test for the Positivity of Arrow-Debreu Prices</title>
    <summary>  We derive tractable necessary and sufficient conditions for the absence of
buy-and-hold arbitrage opportunities in a perfectly liquid, one period market.
We formulate the positivity of Arrow-Debreu prices as a generalized moment
problem to show that this no arbitrage condition is equivalent to the positive
semidefiniteness of matrices formed by the market price of tradeable securities
and their products. We apply this result to a market with multiple assets and
basket call options.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">New version, fixes a few minor errors and typos</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0510027v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510027v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0511024v1</id>
    <updated>2005-11-04T18:31:49Z</updated>
    <published>2005-11-04T18:31:49Z</published>
    <title>Heat kernel expansion for a family of stochastic volatility models :
  delta-geometry</title>
    <summary>  In this paper, we study a family of stochastic volatility processes; this
family features a mean reversion term for the volatility and a double CEV-like
exponent that generalizes SABR and Heston's models. We derive approximated
closed form formulas for the digital prices, the local and implied
volatilities. Our formulas are efficient for small maturities.
  Our method is based on differential geometry, especially small time
diffusions on riemanian spaces. This geometrical point of view can be extended
to other processes, and is very accurate to produce variate smiles for small
maturities and small moneyness.
</summary>
    <author>
      <name>Bourgade Paul</name>
    </author>
    <author>
      <name>Croissant Olivier</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0511024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0511024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606010v1</id>
    <updated>2006-06-02T03:06:07Z</updated>
    <published>2006-06-02T03:06:07Z</published>
    <title>A Decision-Making Support System Based on Know-How</title>
    <summary>  The research results described are concerned with: - developing a domain
modeling method and tools to provide the design and implementation of
decision-making support systems for computer integrated manufacturing; -
building a decision-making support system based on know-how and its software
environment. The research is funded by NEDO, Japan.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>V. A. Abramov</name>
    </author>
    <author>
      <name>Y. Fukuda</name>
    </author>
    <author>
      <name>K. Konishi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures. Preprint completed in 1997</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CIRP Journal of Manufacturing Systems. 1998, Vol. 27, No.4,
  427-432</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607018v2</id>
    <updated>2006-08-12T19:10:24Z</updated>
    <published>2006-07-06T16:35:38Z</published>
    <title>Feynman Checkerboard as a Model of Discrete Space-Time</title>
    <summary>  In 1965, Feynman wrote of using a lattice containing one dimension of space
and one dimension of time to derive aspects of quantum mechanics. Instead of
summing the behavior of all possible paths as he did, this paper will consider
the motion of single particles within this discrete Space-Time lattice,
sometimes called Feynman's Checkerboard. This empirical approach yielded
several predicted emergent properties for a discrete Space-Time lattice, one of
which is novel and testable.
</summary>
    <author>
      <name>Edward Hanna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 14 figures - changed section 6 title</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607018v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607018v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607091v1</id>
    <updated>2006-07-19T06:58:37Z</updated>
    <published>2006-07-19T06:58:37Z</published>
    <title>Finite element method for thermal analysis of concentrating solar
  receivers</title>
    <summary>  Application of finite element method and heat conductivity transfer model for
calculation of temperature distribution in receiver for dish-Stirling
concentrating solar system is described. The method yields discretized
equations that are entirely local to the elements and provides complete
geometric flexibility. A computer program solving the finite element method
problem is created and great number of numerical experiments is carried out.
Illustrative numerical results are given for an array of triangular elements in
receiver for dish-Stirling system.
</summary>
    <author>
      <name>Stanko Shtrakov</name>
    </author>
    <author>
      <name>Anton Stoilov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609145v1</id>
    <updated>2006-09-26T15:34:40Z</updated>
    <published>2006-09-26T15:34:40Z</published>
    <title>A Semidefinite Relaxation for Air Traffic Flow Scheduling</title>
    <summary>  We first formulate the problem of optimally scheduling air traffic low with
sector capacity constraints as a mixed integer linear program. We then use
semidefinite relaxation techniques to form a convex relaxation of that problem.
Finally, we present a randomization algorithm to further improve the quality of
the solution. Because of the specific structure of the air traffic flow
problem, the relaxation has a single semidefinite constraint of size dn where d
is the maximum delay and n the number of flights.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <author>
      <name>Laurent El Ghaoui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to RIVF 2007</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611044v1</id>
    <updated>2006-11-10T07:43:33Z</updated>
    <published>2006-11-10T07:43:33Z</published>
    <title>Protection of the information in a complex CAD system of renovation of
  industrial firms</title>
    <summary>  The threats to security of the information originating owing to involuntary
operations of the users of a CAD, and methods of its protection implemented in
a complex CAD system of renovation of firms are considered: rollback, autosave,
automatic backup copying and electronic subscript. The specificity of a complex
CAD is reflected in necessity of rollback and autosave both of the draw and the
parametric representations of its parts, which are the information models of
the problem-oriented extensions of the CAD
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <author>
      <name>Rustem R. Kafiyatullov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611045v1</id>
    <updated>2006-11-10T07:56:19Z</updated>
    <published>2006-11-10T07:56:19Z</published>
    <title>The evolution of the parametric models of drawings (modules) in the
  enterprises reconstruction CAD system</title>
    <summary>  Progressing methods of drawings creating automation is discussed on the basis
of so-called modules containing parametric representation of a part of the
drawing and the geometrical elements. The stages of evolution of modular
technology of automation of engineering are describing alternatives of applying
of moduluss for simple association of elements of the drawing without
parametric representation with an opportunity of its commenting, for graphic
symbols creating in the schemas of automation and drawings of pipelines, for
storage of the specific properties of elements, for development of the
specialized parts of the project: the axonometric schemas, profiles of outboard
pipe networks etc.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, no figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611061v1</id>
    <updated>2006-11-14T16:58:58Z</updated>
    <published>2006-11-14T16:58:58Z</published>
    <title>Multivariate Integral Perturbation Techniques - I (Theory)</title>
    <summary>  We present a quasi-analytic perturbation expansion for multivariate
N-dimensional Gaussian integrals. The perturbation expansion is an infinite
series of lower-dimensional integrals (one-dimensional in the simplest
approximation). This perturbative idea can also be applied to multivariate
Student-t integrals. We evaluate the perturbation expansion explicitly through
2nd order, and discuss the convergence, including enhancement using Pade
approximants. Brief comments on potential applications in finance are given,
including options, models for credit risk and derivatives, and correlation
sensitivities.
</summary>
    <author>
      <name>Jan W. Dash</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.2.4; G.1.4; G.3; J.1; J.2; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611083v1</id>
    <updated>2006-11-17T08:27:45Z</updated>
    <published>2006-11-17T08:27:45Z</published>
    <title>Environment of development of the programs of parametric creating of the
  drawings in CAD-system of renovation of the enterprises</title>
    <summary>  The main ideas, data structures, structure and realization of operations with
them in environment of development of the programs of parametric creating of
the drawings are considered for the needs of the automated design engineering
system of renovation of the enterprises. The example of such program and
example of application of this environment for creating the drawing of the base
for equipment in CAD-system TechnoCAD GlassX are presented
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702131v1</id>
    <updated>2007-02-22T17:27:05Z</updated>
    <published>2007-02-22T17:27:05Z</published>
    <title>AICA: a New Pair Force Evaluation Method for Parallel Molecular Dynamics
  in Arbitrary Geometries</title>
    <summary>  A new algorithm for calculating intermolecular pair forces in Molecular
Dynamics (MD) simulations on a distributed parallel computer is presented. The
Arbitrary Interacting Cells Algorithm (AICA) is designed to operate on
geometrical domains defined by an unstructured, arbitrary polyhedral mesh,
which has been spatially decomposed into irregular portions for
parallelisation. It is intended for nano scale fluid mechanics simulation by MD
in complex geometries, and to provide the MD component of a hybrid MD/continuum
simulation. AICA has been implemented in the open-source computational toolbox
OpenFOAM, and verified against a published MD code.
</summary>
    <author>
      <name>Graham B. Macpherson</name>
    </author>
    <author>
      <name>Jason M. Reese</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0702131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.0090v1</id>
    <updated>2007-04-01T14:35:40Z</updated>
    <published>2007-04-01T14:35:40Z</published>
    <title>Real Options for Project Schedules (ROPS)</title>
    <summary>  Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <link href="http://arxiv.org/abs/0704.0090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.0090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; G.1; G.1.6; G.3; J.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.1119v2</id>
    <updated>2011-01-24T11:53:45Z</updated>
    <published>2007-06-08T07:04:24Z</published>
    <title>Cointegration of the Daily Electric Power System Load and the Weather</title>
    <summary>  The paper makes a thermal predictive analysis of the electric power system
security for a day ahead. This predictive analysis is set as a thermal
computation of the expected security. This computation is obtained by
cointegrating the daily electric power systen load and the weather, by finding
the daily electric power system thermodynamics and by introducing tests for
this thermodynamics. The predictive analysis made shows the electricity
consumers' wisdom.
</summary>
    <author>
      <name>Stefan Z. Stefanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, extended version</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.1119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.1119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.2331v5</id>
    <updated>2008-12-03T16:56:17Z</updated>
    <published>2007-06-15T16:43:14Z</published>
    <title>Pricing American Options for Jump Diffusions by Iterating Optimal
  Stopping Problems for Diffusions</title>
    <summary>  We approximate the price of the American put for jump diffusions by a
sequence of functions, which are computed iteratively. This sequence converges
to the price function uniformly and exponentially fast. Each element of the
approximating sequence solves an optimal stopping problem for geometric
Brownian motion, and can be numerically computed using the classical finite
difference methods. We prove the convergence of this numerical scheme and
present examples to illustrate its performance.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Hao Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Pricing derivatives, American options, jump diffusions,
  barrier options, finite difference methods</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.2331v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.2331v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3463v1</id>
    <updated>2007-08-26T05:10:29Z</updated>
    <published>2007-08-26T05:10:29Z</published>
    <title>A Neural Networks Model of the Venezuelan Economy</title>
    <summary>  Besides an indicator of the GDP, the Central Bank of Venezuela generates the
so called Monthly Economic Activity General Indicator. The a priori knowledge
of this indicator, which represents and sometimes even anticipates the
economy's fluctuations, could be helpful in developing public policies and in
investment decision making. The purpose of this study is forecasting the IGAEM
through non parametric methods, an approach that has proven effective in a wide
variety of problems in economics and finance.
</summary>
    <author>
      <name>Sabatino Costanzo</name>
    </author>
    <author>
      <name>Loren Trigo</name>
    </author>
    <author>
      <name>Luis Jimenez</name>
    </author>
    <author>
      <name>Juan Gonzalez</name>
    </author>
    <link href="http://arxiv.org/abs/0708.3463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3464v1</id>
    <updated>2007-08-26T05:30:18Z</updated>
    <published>2007-08-26T05:30:18Z</published>
    <title>A Non Parametric Study of the Volatility of the Economy as a Country
  Risk Predictor</title>
    <summary>  This paper intends to explain Venezuela's country spread behavior through the
Neural Networks analysis of a monthly economic activity general index of
economic indicators constructed by the Central Bank of Venezuela, a measure of
the shocks affecting country risk of emerging markets and the U.S. short term
interest rate. The use of non parametric methods allowed the finding of non
linear relationship between these inputs and the country risk. The networks
performance was evaluated using the method of excess predictability.
</summary>
    <author>
      <name>Sabatino Costanzo</name>
    </author>
    <author>
      <name>Loren Trigo</name>
    </author>
    <author>
      <name>Ramses Dominguez</name>
    </author>
    <author>
      <name>William Moreno</name>
    </author>
    <link href="http://arxiv.org/abs/0708.3464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3465v1</id>
    <updated>2007-08-26T05:33:41Z</updated>
    <published>2007-08-26T05:33:41Z</published>
    <title>An Early Warning System for Bankruptcy Prediction: lessons from the
  Venezuelan Bank Crisis</title>
    <summary>  During 1993-94 Venezuela experienced a severe banking crisis which ended up
with 18 commercial banks intervened by the government. Here we develop an early
warning system for detecting credit related bankruptcy through discriminant
functions developed on financial and macroeconomic data predating the crisis. A
robustness test performed on these functions shows high precision in error
estimation. The model calibrated on pre-crisis data could detect abnormal
financial tension in the late Banco Capital many months before it was
intervened and liquidated.
</summary>
    <author>
      <name>Loren Trigo</name>
    </author>
    <author>
      <name>Sabatino Costanzo</name>
    </author>
    <author>
      <name>Felix Gonzalez</name>
    </author>
    <author>
      <name>Jose Llamozas</name>
    </author>
    <link href="http://arxiv.org/abs/0708.3465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4486v1</id>
    <updated>2007-10-24T14:48:39Z</updated>
    <published>2007-10-24T14:48:39Z</published>
    <title>Non-linear estimation is easy</title>
    <summary>  Non-linear state estimation and some related topics, like parametric
estimation, fault diagnosis, and perturbation attenuation, are tackled here via
a new methodology in numerical differentiation. The corresponding basic system
theoretic definitions and properties are presented within the framework of
differential algebra, which permits to handle system variables and their
derivatives of any order. Several academic examples and their computer
simulations, with on-line estimations, are illustrating our viewpoint.
</summary>
    <author>
      <name>Michel Fliess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <author>
      <name>Cédric Join</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs, CRAN</arxiv:affiliation>
    </author>
    <author>
      <name>Hebertt Sira-Ramirez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1504/IJMIC.2008.020996</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1504/IJMIC.2008.020996" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Modelling Identification and Control 4, 1 (2008) 12-27</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4486v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4486v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.1806v1</id>
    <updated>2008-05-13T09:05:41Z</updated>
    <published>2008-05-13T09:05:41Z</published>
    <title>Tuplix Calculus Specifications of Financial Transfer Networks</title>
    <summary>  We study the application of Tuplix Calculus in modular financial budget
design. We formalize organizational structure using financial transfer
networks. We consider the notion of flux of money over a network, and a way to
enforce the matching of influx and outflux for parts of a network. We exploit
so-called signed attribute notation to make internal streams visible through
encapsulations. Finally, we propose a Tuplix Calculus construct for the
definition of data functions.
</summary>
    <author>
      <name>J. A. Bergstra</name>
    </author>
    <author>
      <name>S. Nolst Trenite</name>
    </author>
    <author>
      <name>M. B. van der Zwaag</name>
    </author>
    <link href="http://arxiv.org/abs/0805.1806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.1806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.5120v2</id>
    <updated>2008-09-30T10:24:51Z</updated>
    <published>2008-07-31T17:40:55Z</published>
    <title>Accelerated Option Pricing in Multiple Scenarios</title>
    <summary>  This paper covers a massive acceleration of Monte-Carlo based pricing method
for financial products and financial derivatives. The method is applicable in
risk management settings, where a financial product has to be priced under a
number of potential future scenarios. Instead of starting a separate nested
Monte Carlo simulation for each scenario under consideration, the new method
covers the utilization of very few representative nested simulations and
estimating the product prices at each scenario by a smoothing method based on
the state-space. This smoothing technique can be e.g. non-parametric regression
or kernel smoothing.
</summary>
    <author>
      <name>Stefan Dirnstorfer</name>
    </author>
    <author>
      <name>Andreas J. Grau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages: Page 17, References corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.5120v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.5120v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3688v1</id>
    <updated>2008-09-22T12:03:52Z</updated>
    <published>2008-09-22T12:03:52Z</published>
    <title>Mathematical and computer tools of discrete dynamic modeling and
  analysis of complex systems in control loop</title>
    <summary>  We present a method of discrete modeling and analysis of multilevel dynamics
of complex large-scale hierarchical dynamic systems subject to external dynamic
control mechanism. Architectural model of information system supporting
simulation and analysis of dynamic processes and development scenarios
(strategies) of complex large-scale hierarchical systems is also proposed.
</summary>
    <author>
      <name>Armen Bagdasaryan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 15 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int J Mathematical Models and Methods in Applied Sciences, vol. 2,
  issue 1, 2008, pp. 82-95</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.4523v1</id>
    <updated>2008-12-24T12:07:48Z</updated>
    <published>2008-12-24T12:07:48Z</published>
    <title>System Theoretic Viewpoint on Modeling of Complex Systems: Design,
  Synthesis, Simulation, and Control</title>
    <summary>  We consider the basic features of complex dynamic and control systems,
including systems having hierarchical structure. Special attention is paid to
the problems of design and synthesis of complex systems and control models, and
to the development of simulation techniques and systems. A model of complex
system is proposed and briefly analyzed.
</summary>
    <author>
      <name>Armen Bagdasaryan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; Contribution to the Proceedings of the 7th WSEAS
  International Conference on Computational Intelligence, Man-Machine Systems,
  and Cybernetics, Cairo, Egypt, December 29-31, 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.4523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.4523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.2665v1</id>
    <updated>2009-01-17T23:36:23Z</updated>
    <published>2009-01-17T23:36:23Z</published>
    <title>A Density Matrix-based Algorithm for Solving Eigenvalue Problems</title>
    <summary>  A new numerical algorithm for solving the symmetric eigenvalue problem is
presented. The technique deviates fundamentally from the traditional Krylov
subspace iteration based techniques (Arnoldi and Lanczos algorithms) or other
Davidson-Jacobi techniques, and takes its inspiration from the contour
integration and density matrix representation in quantum mechanics. It will be
shown that this new algorithm - named FEAST - exhibits high efficiency,
robustness, accuracy and scalability on parallel architectures. Examples from
electronic structure calculations of Carbon nanotubes (CNT) are presented, and
numerical performances and capabilities are discussed.
</summary>
    <author>
      <name>Eric Polizzi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevB.79.115112</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevB.79.115112" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0901.2665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.2665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1990v1</id>
    <updated>2009-07-13T18:40:38Z</updated>
    <published>2009-07-13T18:40:38Z</published>
    <title>Automated Protein Structure Classification: A Survey</title>
    <summary>  Classification of proteins based on their structure provides a valuable
resource for studying protein structure, function and evolutionary
relationships. With the rapidly increasing number of known protein structures,
manual and semi-automatic classification is becoming ever more difficult and
prohibitively slow. Therefore, there is a growing need for automated, accurate
and efficient classification methods to generate classification databases or
increase the speed and accuracy of semi-automatic techniques. Recognizing this
need, several automated classification methods have been developed. In this
survey, we overview recent developments in this area. We classify different
methods based on their characteristics and compare their methodology, accuracy
and efficiency. We then present a few open problems and explain future
directions.
</summary>
    <author>
      <name>Oktie Hassanzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, Technical Report CSRG-589, University of Toronto</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.1990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2336v2</id>
    <updated>2010-05-19T13:37:06Z</updated>
    <published>2009-09-12T13:51:59Z</published>
    <title>Two-Phase Flow in Heterogeneous Media</title>
    <summary>  In this study, we investigate the appeared complexity of two-phase flow
(air-water) in a heterogeneous soil where the supposed porous media is
non-deformable media which is under the time-dependent gas pressure. After
obtaining of governing equations and considering the capillary
pressure-saturation and permeability functions, the evolution of the models
unknown parameters were obtained. In this way, using COMSOL (FEMLAB) and fluid
flow-script Module, the role of heterogeneity in intrinsic permeability was
analysed. Also, the evolution of relative permeability of wetting and
non-wetting fluid, capillary pressure and other parameters were elicited.
</summary>
    <author>
      <name>Hamed . O. Ghaffari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to repetition of some
  parts in other publications</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.2336v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2336v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1605v2</id>
    <updated>2009-10-22T02:29:16Z</updated>
    <published>2009-10-08T20:15:51Z</published>
    <title>Proceedings Second International Workshop on Computational Models for
  Cell Processes</title>
    <summary>  The second international workshop on Computational Models for Cell Processes
(ComProc 2009) took place on November 3, 2009 at the Eindhoven University of
Technology, in conjunction with Formal Methods 2009. The workshop was jointly
organized with the EC-MOAN project. This volume contains the final versions of
all contributions accepted for presentation at the workshop.
</summary>
    <author>
      <name>Ralph-Johan Back</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Åbo Akademi University, Finland</arxiv:affiliation>
    </author>
    <author>
      <name>Ion Petre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Åbo Akademi University, Finland</arxiv:affiliation>
    </author>
    <author>
      <name>Erik de Vink</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Eindhoven University of Technology, the Netherlands</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 6, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.1605v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1605v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.2276v1</id>
    <updated>2009-10-13T15:53:45Z</updated>
    <published>2009-10-13T15:53:45Z</published>
    <title>State of the Art Review for Applying Computational Intelligence and
  Machine Learning Techniques to Portfolio Optimisation</title>
    <summary>  Computational techniques have shown much promise in the field of Finance,
owing to their ability to extract sense out of dauntingly complex systems. This
paper reviews the most promising of these techniques, from traditional
computational intelligence methods to their machine learning siblings, with
particular view to their application in optimising the management of a
portfolio of financial instruments. The current state of the art is assessed,
and prospective further work is assessed and recommended
</summary>
    <author>
      <name>Evan Hurwitz</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.2276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.2276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.3848v1</id>
    <updated>2009-10-20T15:18:27Z</updated>
    <published>2009-10-20T15:18:27Z</published>
    <title>Equivalence Classes of Optimal Structures in HP Protein Models Including
  Side Chains</title>
    <summary>  Lattice protein models, as the Hydrophobic-Polar (HP) model, are a common
abstraction to enable exhaustive studies on structure, function, or evolution
of proteins. A main issue is the high number of optimal structures, resulting
from the hydrophobicity-based energy function applied. We introduce an
equivalence relation on protein structures that correlates to the energy
function. We discuss the efficient enumeration of optimal representatives of
the corresponding equivalence classes and the application of the results.
</summary>
    <author>
      <name>Martin Mann</name>
    </author>
    <author>
      <name>Rolf Backofen</name>
    </author>
    <author>
      <name>Sebastian Will</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Proceedings of the Fifth Workshop on Constraint Based
  Methods for Bioinformatics (WCB09), 2009, 9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fifth Workshop on Constraint Based Methods
  for Bioinformatics (WCB09), 2009, Lisbon</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.3848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.3848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.6; G.2.1; J.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4987v1</id>
    <updated>2009-11-26T00:33:04Z</updated>
    <published>2009-11-26T00:33:04Z</published>
    <title>Drip and Mate Operations Acting in Test Tube Systems and Tissue-like P
  systems</title>
    <summary>  The operations drip and mate considered in (mem)brane computing resemble the
operations cut and recombination well known from DNA computing. We here
consider sets of vesicles with multisets of objects on their outside membrane
interacting by drip and mate in two different setups: in test tube systems, the
vesicles may pass from one tube to another one provided they fulfill specific
constraints; in tissue-like P systems, the vesicles are immediately passed to
specified cells after having undergone a drip or mate operation. In both
variants, computational completeness can be obtained, yet with different
constraints for the drip and mate operations.
</summary>
    <author>
      <name>Rudolf Freund</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Vienna University of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Marian Kogler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Vienna University of Technology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.11.8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.11.8" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 11, 2009, pp. 123-135</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0887v1</id>
    <updated>2010-01-06T13:11:35Z</updated>
    <published>2010-01-06T13:11:35Z</published>
    <title>Stable Feature Selection for Biomarker Discovery</title>
    <summary>  Feature selection techniques have been used as the workhorse in biomarker
discovery applications for a long time. Surprisingly, the stability of feature
selection with respect to sampling variations has long been under-considered.
It is only until recently that this issue has received more and more attention.
In this article, we review existing stable feature selection methods for
biomarker discovery using a generic hierarchal framework. We have two
objectives: (1) providing an overview on this new yet fast growing topic for a
convenient reference; (2) categorizing existing methods under an expandable
framework for future research and development.
</summary>
    <author>
      <name>Zengyou He</name>
    </author>
    <author>
      <name>Weichuan Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1001.0887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3495v1</id>
    <updated>2010-01-20T08:03:53Z</updated>
    <published>2010-01-20T08:03:53Z</published>
    <title>Expert System Models in the Companies' Financial and Accounting Domain</title>
    <summary>  The present paper is based on studying, analyzing and implementing the expert
systems in the financial and accounting domain of the companies, describing the
use method of the informational systems that can be used in the multi-national
companies, public interest institutions, and medium and small dimension
economical entities, in order to optimize the managerial decisions and render
efficient the financial-accounting functionality. The purpose of this paper is
aimed to identifying the economical exigencies of the entities, based on the
already used accounting instruments and the management software that could
consent the control of the economical processes and patrimonial assets.
</summary>
    <author>
      <name>D. Mates</name>
    </author>
    <author>
      <name>E. Iancu</name>
    </author>
    <author>
      <name>I. Bostan</name>
    </author>
    <author>
      <name>V. Grosu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Vol. 2, Issue 1, January 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3500v3</id>
    <updated>2010-04-26T11:20:11Z</updated>
    <published>2010-01-20T08:15:18Z</published>
    <title>Mathematical Modeling to Study the Dynamics of A Diatomic Molecule N2 in
  Water</title>
    <summary>  In the present work an attempt has been made to study the dynamics of a
diatomic molecule N2 in water. The proposed model consists of Langevin
stochastic differential equation whose solution is obtained through Euler's
method. The proposed work has been concluded by studying the behavior of
statistical parameters like variance in position, variance in velocity and
covariance between position and velocity. This model incorporates the important
parameters like acceleration, intermolecular force, frictional force and random
force.
</summary>
    <author>
      <name>Nitin Sharma</name>
    </author>
    <author>
      <name>Madhvi Shakya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://sites.google.com/site/journalofcomputing</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Vol. 2, Issue 1, January 2010, 115-120</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3500v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3500v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4919v1</id>
    <updated>2010-02-26T03:54:16Z</updated>
    <published>2010-02-26T03:54:16Z</published>
    <title>Proceedings Third Workshop From Biology To Concurrency and back</title>
    <summary>  This volume contains the papers presented at the 3rd Workshop "From Biology
To Concurrency and back", FBTC 2010, held in Paphos, Cyprus, on March 27, 2010,
as satellite event of the Joint European Conference on Theory and Practice of
Software, ETAPS 2010.
  The Workshop aimed at gathering together researchers with special interest at
the convergence of life and computer science, with particular focus on the
application of techniques and methods from concurrency. The papers contained in
this volume present works on modelling, analysis, and validation of biological
behaviours using concurrency-inspired methods and platforms, and bio-inspired
models and tools for describing distributed interactions.
</summary>
    <author>
      <name>Emanuela Merelli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Camerino, IT</arxiv:affiliation>
    </author>
    <author>
      <name>Paola Quaglia</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CoSBi and University of Trento, IT</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4005v1</id>
    <updated>2010-05-21T17:05:23Z</updated>
    <published>2010-05-21T17:05:23Z</published>
    <title>Optical phase extraction algorithm based on the continuous wavelet and
  the Hilbert transforms</title>
    <summary>  In this paper we present an algorithm for optical phase evaluation based on
the wavelet transform technique. The main advantage of this method is that it
requires only one fringe pattern. This algorithm is based on the use of a
second {\pi}/2 phase shifted fringe pattern where it is calculated via the
Hilbert transform. To test its validity, the algorithm was used to demodulate a
simulated fringe pattern giving the phase distribution with a good accuracy.
</summary>
    <author>
      <name>Mustapha Bahich</name>
    </author>
    <author>
      <name>Mohamed Afifi</name>
    </author>
    <author>
      <name>Elmostafa Barj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">www.journalofcomputing.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 5, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.4683v1</id>
    <updated>2010-09-23T19:18:23Z</updated>
    <published>2010-09-23T19:18:23Z</published>
    <title>Efficient Computation of Optimal Trading Strategies</title>
    <summary>  Given the return series for a set of instruments, a \emph{trading strategy}
is a switching function that transfers wealth from one instrument to another at
specified times. We present efficient algorithms for constructing (ex-post)
trading strategies that are optimal with respect to the total return, the
Sterling ratio and the Sharpe ratio. Such ex-post optimal strategies are useful
analysis tools. They can be used to analyze the "profitability of a market" in
terms of optimal trading; to develop benchmarks against which real trading can
be compared; and, within an inductive framework, the optimal trades can be used
to to teach learning systems (predictors) which are then used to identify
future trading opportunities.
</summary>
    <author>
      <name>Victor Boyarshinov</name>
    </author>
    <author>
      <name>Malik Magdon-Ismail</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">45 pages; working paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.4683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.4683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0250v1</id>
    <updated>2010-11-01T04:54:50Z</updated>
    <published>2010-11-01T04:54:50Z</published>
    <title>Delineation of Raw Plethysmograph using Wavelets for Mobile based Pulse
  Oximeters</title>
    <summary>  The non-invasive pulse-oximeter is a crucial parameter in continuous
monitoring systems. It plays a vital role from admission of the patient to
surgeries with general anaesthesia. The paper proposes the application of
wavelet transform to delineate the raw plethysmograph signals obtained from
basic portable and mobile-powered electronic hardware. The paper primarily
focuses on finding peaks and baseline from noisy infrared and red waveforms
which are responsible for calculating heart-rate and oxygen saturation
percentages.
</summary>
    <author>
      <name>Sangeeta Soni</name>
    </author>
    <author>
      <name>Yogendra Namjoshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 5th Innovative Conference on Embedded Systems, Mobile
  Communication and Computing, Pg. 74-84, ISBN 023-033-045-2</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.0250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0488v1</id>
    <updated>2010-11-02T01:29:09Z</updated>
    <published>2010-11-02T01:29:09Z</published>
    <title>Measurable Stochastics for Brane Calculus</title>
    <summary>  We give a stochastic extension of the Brane Calculus, along the lines of
recent work by Cardelli and Mardare. In this presentation, the semantics of a
Brane process is a measure of the stochastic distribution of possible
derivations. To this end, we first introduce a labelled transition system for
Brane Calculus, proving its adequacy w.r.t. the usual reduction semantics.
Then, brane systems are presented as Markov processes over the measurable space
generated by terms up-to syntactic congruence, and where the measures are
indexed by the actions of this new LTS. Finally, we provide a SOS presentation
of this stochastic semantics, which is compositional and syntax-driven.
</summary>
    <author>
      <name>Giorgio Bacci</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DiMI, University of Udine</arxiv:affiliation>
    </author>
    <author>
      <name>Marino Miculan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DiMI, University of Udine</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 6-22</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.1; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.1508v1</id>
    <updated>2010-11-05T20:49:13Z</updated>
    <published>2010-11-05T20:49:13Z</published>
    <title>Forecast Bias Correction: A Second Order Method</title>
    <summary>  The difference between a model forecast and actual observations is called
forecast bias. This bias is due to either incomplete model assumptions and/or
poorly known parameter values and initial/boundary conditions. In this paper we
discuss a method for estimating corrections to parameters and initial
conditions that would account for the forecast bias. A set of simple
experiments with the logistic ordinary differential equation is performed using
an iterative version of a first order version of our method to compare with the
second order version of the method.
</summary>
    <author>
      <name>Sean Crowell</name>
    </author>
    <author>
      <name>S. Lakshmivarahan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 Pages, 3 figures, 8 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.1508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.1508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3953v1</id>
    <updated>2010-12-17T18:32:10Z</updated>
    <published>2010-12-17T18:32:10Z</published>
    <title>PhyloGrid: a development for a workflow in Phylogeny</title>
    <summary>  In this work we present the development of a workflow based on Taverna which
is going to be implemented for calculations in Phylogeny by means of the
MrBayes tool. It has a friendly interface developed with the Gridsphere
framework. The user is able to define the parameters for doing the Bayesian
calculation, determine the model of evolution, check the accuracy of the
results in the intermediate stages as well as do a multiple alignment of the
sequences previously to the final result. To do this, no knowledge from his/her
side about the computational procedure is required.
</summary>
    <author>
      <name>Esther Montes</name>
    </author>
    <author>
      <name>Raul Isea</name>
    </author>
    <author>
      <name>Rafael Mayo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, ISBN: 978-84-9745-288-5</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Iberian Grid Infrastructure Conf. Proceeding (2008) Vol. 2, pp.
  378-387</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1012.3953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4086v2</id>
    <updated>2012-09-26T16:48:26Z</updated>
    <published>2011-02-20T17:08:52Z</published>
    <title>Schroedinger Eigenmaps for the Analysis of Bio-Medical Data</title>
    <summary>  We introduce Schroedinger Eigenmaps, a new semi-supervised manifold learning
and recovery technique. This method is based on an implementation of graph
Schroedinger operators with appropriately constructed barrier potentials as
carriers of labeled information. We use our approach for the analysis of
standard bio-medical datasets and new multispectral retinal images.
</summary>
    <author>
      <name>Wojciech Czaja</name>
    </author>
    <author>
      <name>Martin Ehler</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPAMI.2012.270</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPAMI.2012.270" rel="related"/>
    <link href="http://arxiv.org/abs/1102.4086v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4086v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2351v1</id>
    <updated>2011-03-11T19:27:20Z</updated>
    <published>2011-03-11T19:27:20Z</published>
    <title>Engineering Relative Compression of Genomes</title>
    <summary>  Technology progress in DNA sequencing boosts the genomic database growth at
faster and faster rate. Compression, accompanied with random access
capabilities, is the key to maintain those huge amounts of data. In this paper
we present an LZ77-style compression scheme for relative compression of
multiple genomes of the same species. While the solution bears similarity to
known algorithms, it offers significantly higher compression ratios at
compression speed over a order of magnitude greater. One of the new successful
ideas is augmenting the reference sequence with phrases from the other
sequences, making more LZ-matches available.
</summary>
    <author>
      <name>Szymon Grabowski</name>
    </author>
    <author>
      <name>Sebastian Deorowicz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W32" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2447v1</id>
    <updated>2011-03-12T14:30:48Z</updated>
    <published>2011-03-12T14:30:48Z</published>
    <title>Mini-step Strategy for Transient Analysis</title>
    <summary>  Domain decomposition methods are widely used to solve sparse linear systems
from scientific problems, but they are not suited to solve sparse linear
systems extracted from integrated circuits. The reason is that the sparse
linear system of integrated circuits may be non-diagonal-dominant, and domain
decomposition method might be unconvergent for these non-diagonal-dominant
matrices. In this paper, we propose a mini-step strategy to do the circuit
transient analysis. Different from the traditional large-step approach, this
strategy is able to generate diagonal-dominant sparse linear systems. As a
result, preconditioned domain decomposition methods can be used to simulate the
large integrated circuits on the supercomputers and clouds.
</summary>
    <author>
      <name>Fei Wei</name>
    </author>
    <author>
      <name>Huazhong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">a preprint version, full version is submitted to an international
  journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.2447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3391v1</id>
    <updated>2011-03-17T12:27:10Z</updated>
    <published>2011-03-17T12:27:10Z</published>
    <title>An Integer Linear Programming Model for the Radiotherapy Treatment
  Scheduling Problem</title>
    <summary>  Radiotherapy represents an important phase of treatment for a large number of
cancer patients. It is essential that resources used to deliver this treatment
are employed effectively. This paper presents a new integer linear programming
model for real-world radiotherapy treatment scheduling and analyses the
effectiveness of using this model on a daily basis in a hospital. Experiments
are conducted varying the days on which schedules can be created. Results
obtained using real-world data from the Nottingham University Hospitals NHS
Trust, UK, are presented and show how the proposed model can be used with
different policies in order to achieve good quality schedules.
</summary>
    <author>
      <name>Edmund K. Burke</name>
    </author>
    <author>
      <name>Pedro Leite-Rocha</name>
    </author>
    <author>
      <name>Sanja Petrovic</name>
    </author>
    <link href="http://arxiv.org/abs/1103.3391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4720v2</id>
    <updated>2011-03-25T07:00:16Z</updated>
    <published>2011-03-24T10:31:44Z</published>
    <title>Computer Modelling of 3D Geological Surface</title>
    <summary>  The geological surveying presently uses methods and tools for the computer
modeling of 3D-structures of the geographical subsurface and geotechnical
characterization as well as the application of geoinformation systems for
management and analysis of spatial data, and their cartographic presentation.
The objectives of this paper are to present a 3D geological surface model of
Latur district in Maharashtra state of India. This study is undertaken through
the several processes which are discussed in this paper to generate and
visualize the automated 3D geological surface model of a projected area.
</summary>
    <author>
      <name>B. G. Kodge</name>
    </author>
    <author>
      <name>P. S. Hiremath</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">05 Pages, and 05 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, Vol. 9, No. 2, February 2011, pp: 175-179</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.4720v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4720v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.8; I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1717v1</id>
    <updated>2011-04-09T16:05:32Z</updated>
    <published>2011-04-09T16:05:32Z</published>
    <title>Continuous and Discrete Adjoints to the Euler Equations for Fluids</title>
    <summary>  Adjoints are used in optimization to speed-up computations, simplify
optimality conditions or compute sensitivities. Because time is reversed in
adjoint equations with first order time derivatives, boundary conditions and
transmission conditions through shocks can be difficult to understand. In this
article we analyze the adjoint equations that arise in the context of
compressible flows governed by the Euler equations of fluid dynamics. We show
that the continuous adjoints and the discrete adjoints computed by automatic
differentiation agree numerically; in particular the adjoint is found to be
continuous at the shocks and usually discontinuous at contact discontinuities
by both.
</summary>
    <author>
      <name>Frederic Alauzet</name>
    </author>
    <author>
      <name>Olivier Pironneau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1366v1</id>
    <updated>2011-09-07T06:27:29Z</updated>
    <published>2011-09-07T06:27:29Z</published>
    <title>A Minimal OO Calculus for Modelling Biological Systems</title>
    <summary>  In this paper we present a minimal object oriented core calculus for
modelling the biological notion of type that arises from biological ontologies
in formalisms based on term rewriting. This calculus implements encapsulation,
method invocation, subtyping and a simple formof overriding inheritance, and it
is applicable to models designed in the most popular term-rewriting formalisms.
The classes implemented in a formalism can be used in several models, like
programming libraries.
</summary>
    <author>
      <name>Livio Bioglio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.67.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.67.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings CompMod 2011, arXiv:1109.1044</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 67, 2011, pp. 50-64</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1367v1</id>
    <updated>2011-09-07T06:27:36Z</updated>
    <published>2011-09-07T06:27:36Z</published>
    <title>A Study of the PDGF Signaling Pathway with PRISM</title>
    <summary>  In this paper, we apply the probabilistic model checker PRISM to the analysis
of a biological system -- the Platelet-Derived Growth Factor (PDGF) signaling
pathway, demonstrating in detail how this pathway can be analyzed in PRISM. We
show that quantitative verification can yield a better understanding of the
PDGF signaling pathway.
</summary>
    <author>
      <name>Qixia Yuan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <author>
      <name>Jun Pang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <author>
      <name>Sjouke Mauw</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <author>
      <name>Panuwat Trairatphisan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <author>
      <name>Monique Wiesinger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <author>
      <name>Thomas Sauter</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Luxembourg</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.67.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.67.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings CompMod 2011, arXiv:1109.1044</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 67, 2011, pp. 65-81</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3524v2</id>
    <updated>2016-04-09T00:39:08Z</updated>
    <published>2011-09-16T04:02:15Z</published>
    <title>cuIBM -- A GPU-accelerated Immersed Boundary Method</title>
    <summary>  A projection-based immersed boundary method is dominated by sparse linear
algebra routines. Using the open-source Cusp library, we observe a speedup
(with respect to a single CPU core) which reflects the constraints of a
bandwidth-dominated problem on the GPU. Nevertheless, GPUs offer the capacity
to solve large problems on commodity hardware. This work includes validation
and a convergence study of the GPU-accelerated IBM, and various optimizations.
</summary>
    <author>
      <name>Simon K Layton</name>
    </author>
    <author>
      <name>Anush Krishnan</name>
    </author>
    <author>
      <name>Lorena A. Barba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended paper post-conference, presented at the 23rd International
  Conference on Parallel Computational Fluid Dynamics (http://www.parcfd.org),
  ParCFD 2011, Barcelona (unpublished)</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3524v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3524v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3127v1</id>
    <updated>2011-11-14T08:04:16Z</updated>
    <published>2011-11-14T08:04:16Z</published>
    <title>Tracing the temporal evolution of clusters in a financial stock market</title>
    <summary>  We propose a methodology for clustering financial time series of stocks'
returns, and a graphical set-up to quantify and visualise the evolution of
these clusters through time. The proposed graphical representation allows for
the application of well known algorithms for solving classical combinatorial
graph problems, which can be interpreted as problems relevant to portfolio
design and investment strategies. We illustrate this graph representation of
the evolution of clusters in time and its use on real data from the Madrid
Stock Exchange market.
</summary>
    <author>
      <name>Argimiro Arratia</name>
    </author>
    <author>
      <name>Alejandra Cabaña</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10614-012-9327-x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10614-012-9327-x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 3 figures (submitted for publication)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05, 68R10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3545v1</id>
    <updated>2012-01-16T11:27:52Z</updated>
    <published>2012-01-16T11:27:52Z</published>
    <title>On Natural Genetic Engineering: Structural Dynamism in Random Boolean
  Networks</title>
    <summary>  This short paper presents an abstract, tunable model of genomic structural
change within the cell lifecycle and explores its use with simulated evolution.
A well-known Boolean model of genetic regulatory networks is extended to
include changes in node connectivity based upon the current cell state, e.g.,
via transposable elements. The underlying behaviour of the resulting dynamical
networks is investigated before their evolvability is explored using a version
of the NK model of fitness landscapes. Structural dynamism is found to be
selected for in non-stationary environments and subsequently shown capable of
providing a mechanism for evolutionary innovation when such reorganizations are
inherited.
</summary>
    <author>
      <name>Larry Bull</name>
    </author>
    <link href="http://arxiv.org/abs/1201.3545v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3545v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0096v1</id>
    <updated>2012-03-01T05:41:48Z</updated>
    <published>2012-03-01T05:41:48Z</published>
    <title>Joint Estimation of Angle and Delay of Radio Wave Arrival under
  Multiplicative Noise Environment</title>
    <summary>  We propose a novel technique for joint estimation of angle and delay of radio
wave arrival in a multipath mobile communication channel using knowledge of the
transmitted pulse shape function. Employing an array of sensors to sample the
radio received signal, and subsequent array signal processing can provide the
characterization of a high-rank channel in terms of the multipath angles of
arrival and time delays. Although several works have been reported in the
literature for estimation of the high-rank channel parameters, we are not aware
of any work that deals with the problem of estimation in a fading channel,
which essentially leads to a multiplicative noise environment.
</summary>
    <author>
      <name>Pradip Sircar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 table, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.0096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4366v1</id>
    <updated>2012-04-19T15:02:30Z</updated>
    <published>2012-04-19T15:02:30Z</published>
    <title>Multipath-dominant, pulsed doppler analysis of rotating blades</title>
    <summary>  We present a novel angular fingerprinting algorithm for detecting changes in
the direction of rotation of a target with a monostatic, stationary sonar
platform. Unlike other approaches, we assume that the target's centroid is
stationary, and exploit doppler multipath signals to resolve the otherwise
unavoidable ambiguities that arise. Since the algorithm is based on an
underlying differential topological theory, it is highly robust to distortions
in the collected data. We demonstrate performance of this algorithm
experimentally, by exhibiting a pulsed doppler sonar collection system that
runs on a smartphone. The performance of this system is sufficiently good to
both detect changes in target rotation direction using angular fingerprints,
and also to form high-resolution inverse synthetic aperature images of the
target.
</summary>
    <author>
      <name>Michael Robinson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.4366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5174v2</id>
    <updated>2012-05-04T16:11:28Z</updated>
    <published>2012-04-23T17:15:17Z</published>
    <title>Christhin: Quantitative Analysis of Thin Layer Chromatography</title>
    <summary>  Manual for Christhin 0.1.36 Christhin (Chromatography Riser Thin) is software
developed for the quantitative analysis of data obtained from thin-layer
chromatographic techniques (TLC). Once installed on your computer, the program
is very easy to use, and provides data quickly and accurately. This manual
describes the program, and reading should be enough to use it properly.
</summary>
    <author>
      <name>Maximiliano Barchiesi</name>
    </author>
    <author>
      <name>Mercedes Sangroni</name>
    </author>
    <author>
      <name>Carlos Renaudo</name>
    </author>
    <author>
      <name>Pablo Rossi</name>
    </author>
    <author>
      <name>María de Carmen Pramparo</name>
    </author>
    <author>
      <name>Valeria Nepote</name>
    </author>
    <author>
      <name>Nelson Ruben Grosso</name>
    </author>
    <author>
      <name>María Fernanda Gayol</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5174v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5174v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1986v1</id>
    <updated>2012-05-09T14:04:35Z</updated>
    <published>2012-05-09T14:04:35Z</published>
    <title>Evolutionary algorithms in genetic regulatory networks model</title>
    <summary>  Genetic Regulatory Networks (GRNs) plays a vital role in the understanding of
complex biological processes. Modeling GRNs is significantly important in order
to reveal fundamental cellular processes, examine gene functions and
understanding their complex relationships. Understanding the interactions
between genes gives rise to develop better method for drug discovery and
diagnosis of the disease since many diseases are characterized by abnormal
behaviour of the genes. In this paper we have reviewed various evolutionary
algorithms-based approach for modeling GRNs and discussed various opportunities
and challenges.
</summary>
    <author>
      <name>Khalid Raza</name>
    </author>
    <author>
      <name>Rafat Parveen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures and 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Advanced Bioinformatics Applications and Research
  3(1):271-280, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.1986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="http://bipublication.com/files/JABAR-V3I1-2012-06.pdf" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4438v1</id>
    <updated>2012-06-20T10:07:31Z</updated>
    <published>2012-06-20T10:07:31Z</published>
    <title>Inverse Modeling of Climate Responses of Monumental Buildings</title>
    <summary>  The indoor climate conditions of monumental buildings are very important for
the conservation of these objects. Simplified models with physical meaning are
desired that are capable of simulating temperature and relative humidity. In
this paper we research state-space models as methodology for the inverse
modeling of climate responses of unheated monumental buildings. It is concluded
that this approach is very promising for obtaining physical models and
parameters of indoor climate responses. Furthermore state space models can be
simulated very efficiently: the simulation duration time of a 100 year hourly
based period take less than a second on an ordinary computer.
</summary>
    <author>
      <name>R. P. Kramer</name>
    </author>
    <author>
      <name>A. W. M. van Schijndel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preliminary conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1933v1</id>
    <updated>2012-07-09T02:08:26Z</updated>
    <published>2012-07-09T02:08:26Z</published>
    <title>A Hybrid Forecast of Exchange Rate based on ARFIMA,Discrete Grey-Markov,
  and Fractal Kalman Model</title>
    <summary>  We propose a hybrid forecast based on extended discrete grey Markov and
variable dimension Kalman model and show that our hybrid model can improve much
more the performance of forecast than traditional grey Markov and Kalman
models. Our simulation results are given to demonstrate that our hybrid
forecast method combined with degree of grey incidence are better than grey
Markov and ARFIMA model or Kalman methods.
</summary>
    <author>
      <name>Gol Kim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Center of Natural Science, University of Sciences, Pyongyang, DPR Korea</arxiv:affiliation>
    </author>
    <author>
      <name>Ri Suk Yun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Foreign Economic General Bureau, Pyongyang, DPR Korea</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1207.1933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2254v1</id>
    <updated>2012-07-10T07:46:04Z</updated>
    <published>2012-07-10T07:46:04Z</published>
    <title>A Hybrid Forecast of Exchange Rate based on Discrete Grey-Markov and
  Grey Neural Network Model</title>
    <summary>  We propose a hybrid forecast model based on discrete grey-fuzzy Markov and
grey neural network model and show that our hybrid model can improve much more
the performance of forecast than traditional grey-Markov model and neural
network models. Our simulation results are shown that our hybrid forecast
method with the combinational weight based on optimal grey relation degree
method is better than the hybrid model with combinational weight based
minimization of error-squared criterion.
</summary>
    <author>
      <name>Gol Kim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Center of Natural Science, University of Sciences, Pyongyang, DPR Korea</arxiv:affiliation>
    </author>
    <author>
      <name>Ri Suk Yun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Foreign Economic General Bureau, Pyongyang, DPR Korea</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1207.2254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3151v1</id>
    <updated>2012-08-15T16:06:59Z</updated>
    <published>2012-08-15T16:06:59Z</published>
    <title>Proceedings First International Workshop on Hybrid Systems and Biology</title>
    <summary>  This volume contains the proceedings of the First International Workshop on
Hybrid Systems and Biology (HSB 2012), that will be held in Newcastle upon
Tyne, UK, on the 3rd September, 2012. HSB 2012 is a satellite event of the 23rd
International Conference on Concurrency Theory (CONCUR 2012).
  This workshop aims at collecting scientists working in the area of hybrid
modeling applied to systems biology, in order to discuss about current achieved
goals, current challenges and future possible developments.
</summary>
    <author>
      <name>Ezio Bartocci</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Vienna University of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Luca Bortolussi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Trieste</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.3151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.0; I.6.1; I.6.3; I.6.4; I.6.7; I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3849v1</id>
    <updated>2012-08-19T16:01:06Z</updated>
    <published>2012-08-19T16:01:06Z</published>
    <title>Analysis of parametric biological models with non-linear dynamics</title>
    <summary>  In this paper we present recent results on parametric analysis of biological
models. The underlying method is based on the algorithms for computing
trajectory sets of hybrid systems with polynomial dynamics. The method is then
applied to two case studies of biological systems: one is a cardiac cell model
for studying the conditions for cardiac abnormalities, and the second is a
model of insect nest-site choice.
</summary>
    <author>
      <name>Romain Testylier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VERIMAG, Joseph Fourier University</arxiv:affiliation>
    </author>
    <author>
      <name>Thao Dang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CNRS/VERIMAG</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 16-29</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3850v1</id>
    <updated>2012-08-19T16:01:13Z</updated>
    <published>2012-08-19T16:01:13Z</published>
    <title>A subsystems approach for parameter estimation of ODE models of hybrid
  systems</title>
    <summary>  We present a new method for parameter identification of ODE system
descriptions based on data measurements. Our method works by splitting the
system into a number of subsystems and working on each of them separately,
thereby being easily parallelisable, and can also deal with noise in the
observations.
</summary>
    <author>
      <name>Anastasis Georgoulas</name>
    </author>
    <author>
      <name>Allan Clark</name>
    </author>
    <author>
      <name>Andrea Ocone</name>
    </author>
    <author>
      <name>Stephen Gilmore</name>
    </author>
    <author>
      <name>Guido Sanguinetti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 30-41</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3852v1</id>
    <updated>2012-08-19T16:01:27Z</updated>
    <published>2012-08-19T16:01:27Z</published>
    <title>Hybrid Automata and ε-Analysis on a Neural Oscillator</title>
    <summary>  In this paper we propose a hybrid model of a neural oscillator, obtained by
partially discretizing a well-known continuous model. Our construction points
out that in this case the standard techniques, based on replacing sigmoids with
step functions, is not satisfactory. Then, we study the hybrid model through
both symbolic methods and approximation techniques. This last analysis, in
particular, allows us to show the differences between the considered
approximation approaches. Finally, we focus on approximations via
epsilon-semantics, proving how these can be computed in practice.
</summary>
    <author>
      <name>Alberto Casagrande</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Trieste</arxiv:affiliation>
    </author>
    <author>
      <name>Tommaso Dreossi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Udine</arxiv:affiliation>
    </author>
    <author>
      <name>Carla Piazza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Udine</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 58-72</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6489v1</id>
    <updated>2012-09-28T11:46:28Z</updated>
    <published>2012-09-28T11:46:28Z</published>
    <title>Online Financial Algorithms Competitive Analysis</title>
    <summary>  Analysis of algorithms with complete knowledge of its inputs is sometimes not
up to our expectations. Many times we are surrounded with such scenarios where
inputs are generated without any prior knowledge. Online Algorithms have found
their applicability in broad areas of computer engineering. Among these, an
online financial algorithm is one of the most important areas where lots of
efforts have been used to produce an efficient algorithm. In this paper various
Online Algorithms have been reviewed for their efficiency and various
alternative measures have been explored for analysis purposes.
</summary>
    <author>
      <name>Sandeep Kumar</name>
    </author>
    <author>
      <name>Deepak Garg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/4974-7228</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/4974-7228" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 40(7):8-14, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.6489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3922v1</id>
    <updated>2012-12-17T08:17:14Z</updated>
    <published>2012-12-17T08:17:14Z</published>
    <title>Interroom radiative couplings through windows and large openings in
  buildings: Proposal of a simplified model</title>
    <summary>  A simplified model of indoor short wave radiation couplings adapted to
multi-zone simulations is proposed, thanks to a simplifying hypothesis and to
the introduction of an indoor short wave exchange matrix. The specific
properties of this matrix appear useful to quantify the thermal radiation
exchanges between the zones separated by windows or large openings. Integrated
in CODYRUN software, this module is detailed and compared to experimental
measurements carried out on a real scale tropical building.
</summary>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>M. Bojic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>H. Ennamiri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>D. Calogine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>S. Guichard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JP Journal of Heat and Mass Transfer 6, 2 (2012) 191-211</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5217v1</id>
    <updated>2012-12-20T20:11:30Z</updated>
    <published>2012-12-20T20:11:30Z</published>
    <title>A Neural Network Approach to ECG Denoising</title>
    <summary>  We propose an ECG denoising method based on a feed forward neural network
with three hidden layers. Particulary useful for very noisy signals, this
approach uses the available ECG channels to reconstruct a noisy channel. We
tested the method, on all the records from Physionet MIT-BIH Arrhythmia
Database, adding electrode motion artifact noise. This denoising method
improved the perfomance of publicly available ECG analysis programs on noisy
ECG signals. This is an offline method that can be used to remove noise from
very corrupted Holter records.
</summary>
    <author>
      <name>Rui Rodrigues</name>
    </author>
    <author>
      <name>Paula Couto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5265v1</id>
    <updated>2012-12-20T15:51:13Z</updated>
    <published>2012-12-20T15:51:13Z</published>
    <title>An Effective Machine-Part Grouping Algorithm to Construct Manufacturing
  Cells</title>
    <summary>  The machine-part cell formation problem consists of creating machine cells
and their corresponding part families with the objective of minimizing the
inter-cell and intra-cell movement while maximizing the machine utilization.
This article demonstrates a hybrid clustering approach for the cell formation
problem in cellular manufacturing that conjoins Sorenson s similarity
coefficient based method to form the production cells. Computational results
are shown over the test datasets obtained from the past literature. The hybrid
technique is shown to outperform the other methods proposed in literature and
including powerful soft computing approaches such as genetic algorithms,
genetic programming by exceeding the solution quality on the test problems.
</summary>
    <author>
      <name>Tamal Ghosh</name>
    </author>
    <author>
      <name>Pranab K Dan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Conference on Industrial Engineering (NCIE 2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5589v1</id>
    <updated>2012-12-20T21:21:41Z</updated>
    <published>2012-12-20T21:21:41Z</published>
    <title>CODYRUN, outil de simulation et d'aide à la conception
  thermo-aéraulique de bâtiments</title>
    <summary>  This article presents the CODYRUN software developped by University of La
R\'eunion. It is a multizone thermal software, with detailled airflow and
humidity transfer calculations. One of its specific aspects is that it
constitutes a research tool, a design tool used by the lab and professionnals
and also a teaching tool. After a presentation of the multiple model aspect,
some details of the tree modules associated to physical phenomenons are given.
Elements of validation are exposed in next paraghaph, and then a few details of
the front end.
</summary>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Bastide</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Alfred Jean Philippe Lauret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journ\'ee th\'ematique SFT-IBPSA 2005, La Rochelle : France (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5589v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5589v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5593v1</id>
    <updated>2012-12-21T13:52:10Z</updated>
    <published>2012-12-21T13:52:10Z</published>
    <title>Time-variant Linear reduction model approximation : application to
  thermal and airflow building simulation</title>
    <summary>  Considering the natural ventilation, the thermal behavior of buildings can be
described by a linear time varying model. In this paper, we describe an
implementation of model reduction of linear time varying systems. We show the
consequences of the model reduction on computing time and accuracy. Finally, we
compare experimental measures and simulation results using the initial model or
the reduced model. The reduced model shows negligible difference in accuracy,
and the computing time shortens.
</summary>
    <author>
      <name>Thierry Berthomieu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Eighth International IBPSA Conference, Eindhoven : Netherlands
  (2003); Proceedings available at http://www.ibpsa.org/m_bs2003.asp</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1714v1</id>
    <updated>2013-01-08T23:09:49Z</updated>
    <published>2013-01-08T23:09:49Z</published>
    <title>Parallel Computing of Discrete Element Method on GPU</title>
    <summary>  We investigate applicability of GPU to DEM. NVIDIA's code obtained superior
performance than CPU in computational time. A model of contact forces in
NVIDIA's code is too simple for practical use. We modify this model by
replacing it with the practical model. The simulation shows that the practical
model obtains the computing speed 6 times faster than the practical one on CPU
while 7 times slower than the simple one on GPU. The result are analyzed.
</summary>
    <author>
      <name>Teruyoshi Washizawa</name>
    </author>
    <author>
      <name>Yasuhiro Nakahara</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4236/am.2013.41A037</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4236/am.2013.41A037" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematics, vol.4, no.1A, pp.242-247, (January 2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.1714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2354v1</id>
    <updated>2013-01-10T23:11:16Z</updated>
    <published>2013-01-10T23:11:16Z</published>
    <title>A New Approach for Solving Singular Systems in Topology Optimization
  Using Krylov Subspace Methods</title>
    <summary>  In topology optimization, the design parameter with no contribution to the
objective function vanishes. This causes the stiffness matrix to become
singular. We show that a local optimal solution is obtained by Conjugate
Residual Method and Conjugate Gradient Method even if the stiffness matrix
becomes singular. We prove that CGMconverges to a local optimal solution in
that case. Computer simulation shows that CGM gives the same solutions obtained
by CRM in case of a cantilever beam problem.
</summary>
    <author>
      <name>Teruyoshi Washizawa</name>
    </author>
    <author>
      <name>Akira Asai</name>
    </author>
    <author>
      <name>Nobuhiro Yoshikawa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00158-004-0439-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00158-004-0439-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Structural and Multidisciplinary Optimization, vol.28, pp.330-339,
  2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.2354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3449v1</id>
    <updated>2013-03-27T19:58:34Z</updated>
    <published>2013-03-27T19:58:34Z</published>
    <title>Statistical Mechanics Algorithm for Response to Targets (SMART)</title>
    <summary>  It is proposed to apply modern methods of nonlinear nonequilibrium
statistical mechanics to develop software algorithms that will optimally
respond to targets within short response times with minimal computer resources.
This Statistical Mechanics Algorithm for Response to Targets (SMART) can be
developed with a view towards its future implementation into a hardwired
Statistical Algorithm Multiprocessor (SAM) to enhance the efficiency and speed
of response to targets (SMART_SAM).
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the First Conference on Uncertainty in
  Artificial Intelligence (UAI1985)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.4865v1</id>
    <updated>2013-04-17T15:46:05Z</updated>
    <published>2013-04-17T15:46:05Z</published>
    <title>On the Generalized Hermite-Based Lattice Boltzmann Construction, Lattice
  Sets, Weights, Moments, Distribution Functions and High-Order Models</title>
    <summary>  The influence of the use of the generalized Hermite polynomial on the
Hermite-based lattice Boltzmann (LB) construction approach, lattice sets, the
thermal weights, moments and the equilibrium distribution function (EDF) are
addressed. A new moment system is proposed. The theoretical possibility to
obtain a high-order Hermite-based LB model capable to exactly match some first
hydrodynamic moments thermally 1) on-Cartesian lattice, 2) with thermal weights
in the EDF, 3) whilst the highest possible hydrodynamic moments that are
exactly matched are obtained with the shortest on-Cartesian lattice sets with
some fixed real-valued temperatures, is also analyzed.
  Keywords: Lattice Boltzmann, fluid dynamics, kinetic theory, distribution
function
</summary>
    <author>
      <name>Raúl Machado</name>
    </author>
    <link href="http://arxiv.org/abs/1304.4865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.4865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7226v1</id>
    <updated>2013-04-26T16:48:48Z</updated>
    <published>2013-04-26T16:48:48Z</published>
    <title>Lay-up Optimization of Laminated Composites: Mixed Approach with Exact
  Feasibility Bounds on Lamination Parameters</title>
    <summary>  We suggest modified bi-level approach for finding the best stacking sequence
of laminated composite structures subject to mechanical, blending and
manufacturing constraints. We propose to use both the number of plies laid up
at predefined angles and lamination parameters as independent variables at
outer (global) stage of bi-level scheme aimed to satisfy buckling, strain and
percentage constraints. Our formulation allows precise definition of the
feasible region of lamination parameters and greatly facilitates the solution
of inner level problem of finding the optimal stacking sequence.
</summary>
    <author>
      <name>F. Gubarev</name>
    </author>
    <author>
      <name>V. Kunin</name>
    </author>
    <author>
      <name>A. Pospelov</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7397v1</id>
    <updated>2013-04-27T18:34:22Z</updated>
    <published>2013-04-27T18:34:22Z</published>
    <title>Uniform generation of RNA pseudoknot structures with genus filtration</title>
    <summary>  In this paper we present a sampling framework for RNA structures of fixed
topological genus. We introduce a novel, linear time, uniform sampling
algorithm for RNA structures of fixed topological genus $g$, for arbitrary
$g&gt;0$. Furthermore we develop a linear time sampling algorithm for RNA
structures of fixed topological genus $g$ that are weighted by a simplified,
loop-based energy functional. For this process the partition function of the
energy functional has to be computed once, which has $O(n^2)$ time complexity.
</summary>
    <author>
      <name>Fenix W. D. Huang</name>
    </author>
    <author>
      <name>Markus E. Nebel</name>
    </author>
    <author>
      <name>Christian M. Reidys</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 figures, 25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.7397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C85" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3758v1</id>
    <updated>2013-05-16T11:07:42Z</updated>
    <published>2013-05-16T11:07:42Z</published>
    <title>The Karyotype Ontology: a computational representation for human
  cytogenetic patterns</title>
    <summary>  The karyotype ontology describes the human chromosome complement as
determined cytogenetically, and is designed as an initial step toward the goal
of replacing the current system which is based on semantically meaningful
strings. This ontology uses a novel, semi-programmatic methodology based around
the tawny library to construct many classes rapidly. Here, we describe our use
case, methodology and the event-based approach that we use to represent
karyotypes.
  The ontology is available at http://www.purl.org/ontolink/karyotype/. The
clojure code is available at http://code.google.com/p/karyotype-clj/.
</summary>
    <author>
      <name>Jennifer D. Warrender</name>
    </author>
    <author>
      <name>Phillip Lord</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, to be submitted to Bio-Ontologies 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5524v1</id>
    <updated>2013-05-23T19:24:25Z</updated>
    <published>2013-05-23T19:24:25Z</published>
    <title>Denoising the 3-Base Periodicity Walks of DNA Sequences in Gene Finding</title>
    <summary>  A nonlinear Tracking-Differentiator is one-input-two-output system that can
generate smooth approximation of measured signals and get the derivatives of
the signals. The nonlinear tracking-Differentiator is explored to denoise and
generate the derivatives of the walks of the 3-periodicity of DNA sequences. An
improved algorithm for gene finding is presented using the nonlinear
Tracking-Differentiator. The gene finding algorithm employs the 3-base
periodicity of coding region. The 3-base periodicity DNA walks are denoised and
tracked using the nonlinear Tracking-Differentiator. Case studies demonstrate
that the nonlinear Tracking-Differentiator is an effective method to improve
the accuracy of the gene finding algorithm.
</summary>
    <author>
      <name>Changchuan Yin</name>
    </author>
    <author>
      <name>Dongchul Yoo</name>
    </author>
    <author>
      <name>Stephen S. -T. Yau</name>
    </author>
    <link href="http://arxiv.org/abs/1305.5524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Uxx" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.7437v1</id>
    <updated>2013-05-31T15:01:01Z</updated>
    <published>2013-05-31T15:01:01Z</published>
    <title>Modelling Electricity Consumption in Office Buildings: An Agent Based
  Approach</title>
    <summary>  In this paper, we develop an agent-based model which integrates four
important elements, i.e. organisational energy management policies/regulations,
energy management technologies, electric appliances and equipment, and human
behaviour, to simulate the electricity consumption in office buildings. Based
on a case study, we use this model to test the effectiveness of different
electricity management strategies, and solve practical office electricity
consumption problems. This paper theoretically contributes to an integration of
the four elements involved in the complex organisational issue of office
electricity consumption, and practically contributes to an application of an
agent-based approach for office building electricity consumption study.
</summary>
    <author>
      <name>Tao Zhang</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Energy and Buildings 43(10), 2882-2892, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.7437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.7437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1394v1</id>
    <updated>2013-07-04T16:24:17Z</updated>
    <published>2013-07-04T16:24:17Z</published>
    <title>Detect adverse drug reactions for drug Alendronate</title>
    <summary>  Adverse drug reaction (ADR) is widely concerned for public health issue. In
this study we propose an original approach to detect the ADRs using feature
matrix and feature selection. The experiments are carried out on the drug
Simvastatin. Major side effects for the drug are detected and better
performance is achieved compared to other computerized methods. The detected
ADRs are based on the computerized method, further investigation is needed.
</summary>
    <author>
      <name>Yihui Liu</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Second International Conference on Business Computing and Global
  Informatization (BCGIN), pp 820-823, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1394v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1394v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1598v1</id>
    <updated>2013-07-05T12:46:33Z</updated>
    <published>2013-07-05T12:46:33Z</published>
    <title>Extending a Microsimulation of the Port of Dover</title>
    <summary>  Modelling and simulating the traffic of heavily used but secure environments
such as seaports and airports is of increasing importance. This paper discusses
issues and problems that may arise when extending an existing microsimulation
strategy. We also discuss how extensions of these simulations can aid planners
with optimal physical and operational feedback. Conclusions are drawn about how
microsimulations can be moved forward as a robust planning tool for the 21st
century.
</summary>
    <author>
      <name>Christopher M. Roadknight</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ORS SW12 Simulation Conference, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1625v2</id>
    <updated>2014-08-13T15:39:04Z</updated>
    <published>2013-07-05T14:45:00Z</published>
    <title>Robust Causality Check for Sampled Scattering Parameters via a Filtered
  Fourier Transform</title>
    <summary>  We introduce a robust numerical technique to verify the causality of sampled
scattering parameters given on a finite bandwidth. The method is based on a
filtered Fourier transform and includes a rigorous estimation of the errors
caused by missing out-of-band samples. Compared to existing techniques, the
method is simpler to implement and provides a useful insight on the time-domain
characteristics of the detected violation. Through an applicative example, we
shows its usefulness to improve the accuracy and reliability of macromodeling
techniques used to convert sampled scattering parameters into models for
transient analysis.
</summary>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LMWC.2013.2290218</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LMWC.2013.2290218" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Microwave and Wireless Components Letters, vol.24, no.2,
  pp.72,74, Feb. 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1625v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1625v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.5076v1</id>
    <updated>2013-07-18T20:34:20Z</updated>
    <published>2013-07-18T20:34:20Z</published>
    <title>Low-rank Approximations for Computing Observation Impact in 4D-Var Data
  Assimilation</title>
    <summary>  We present an efficient computational framework to quantify the impact of
individual observations in four dimensional variational data assimilation. The
proposed methodology uses first and second order adjoint sensitivity analysis,
together with matrix-free algorithms to obtain low-rank approximations of ob-
servation impact matrix. We illustrate the application of this methodology to
important applications such as data pruning and the identification of faulty
sensors for a two dimensional shallow water test system.
</summary>
    <author>
      <name>Alexandru Cioaca</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <link href="http://arxiv.org/abs/1307.5076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.5076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1860v2</id>
    <updated>2013-11-09T12:26:13Z</updated>
    <published>2013-08-08T14:16:28Z</published>
    <title>An Optimization Framework to Improve 4D-Var Data Assimilation System
  Performance</title>
    <summary>  This paper develops a computational framework for optimizing the parameters
of data assimilation systems in order to improve their performance. The
approach formulates a continuous meta-optimization problem for parameters; the
meta-optimization is constrained by the original data assimilation problem. The
numerical solution process employs adjoint models and iterative solvers. The
proposed framework is applied to optimize observation values, data weighting
coefficients, and the location of sensors for a test problem. The ability to
optimize a distributed measurement network is crucial for cutting down
operating costs and detecting malfunctions.
</summary>
    <author>
      <name>Alexandru Cioaca</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2014.07.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2014.07.005" rel="related"/>
    <link href="http://arxiv.org/abs/1308.1860v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1860v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2773v3</id>
    <updated>2016-12-05T18:07:35Z</updated>
    <published>2013-08-13T07:16:03Z</published>
    <title>Wind Speed Data Analysis for Various Seasons during a Decade by Wavelet
  and S transform</title>
    <summary>  The appropriate weather prediction is a challenging task and it can be
feasible with proper wind speed fluctuation analysis. In this current paper
daubechies-4 wavelet is used to analyze the winter wind speed fluctuations due
to lesser agitated wind data samples of winter. In summer abrupt changes in
wind speed occurs which creates difficulty for wavelets to keep proper track of
wind speed fluctuations. So, in that case the concept of the S-transform is
introduced.
</summary>
    <author>
      <name>Sabyasachi Mukhopadhyay</name>
    </author>
    <author>
      <name>Prasanta K Panigrahi</name>
    </author>
    <link href="http://arxiv.org/abs/1308.2773v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2773v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4801v1</id>
    <updated>2013-08-22T09:20:15Z</updated>
    <published>2013-08-22T09:20:15Z</published>
    <title>The Mapping of Simulated Climate-Dependent Building Innovations</title>
    <summary>  Performances of building energy innovations are most of the time dependent on
the external climate conditions. This means a high performance of a specific
innovation in a certain part of Europe, does not imply the same performances in
other regions. The mapping of simulated building performances at the EU scale
could prevent the waste of potential good ideas by identifying the best region
for a specific innovation. This paper presents a methodology for obtaining maps
of performances of building innovations that are virtually spread over whole
Europe. It is concluded that these maps are useful for finding regions at the
EU where innovations have the highest expected performances.
</summary>
    <author>
      <name>A. W. M. van Schijndel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preliminary conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.4801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5144v1</id>
    <updated>2013-08-23T14:44:29Z</updated>
    <published>2013-08-23T14:44:29Z</published>
    <title>Detect adverse drug reactions for drug Pioglitazone</title>
    <summary>  In this study we propose a novel method to successfully detect the ADRs using
feature matrix and feature selection. A feature matrix, which characterizes the
medical events before patients take drugs or after patients take drugs, is
created from THIN database. The feature selection method of Student's t-test is
used to detect the significant features from thousands of medical events. The
significant ADRs, which are corresponding to significant features, are
detected. Experiments are performed on the drug Pioglitazone. Compared to other
computerized methods, our proposed method achieves good performance.
</summary>
    <author>
      <name>Yihui Liu</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICoSP.2012.6491898</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICoSP.2012.6491898" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE 11th International Conference on Signal Processing (ICSP),
  1654-1658, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.5144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1781v1</id>
    <updated>2013-09-06T21:48:39Z</updated>
    <published>2013-09-06T21:48:39Z</published>
    <title>Experiences from Software Engineering of Large Scale AMR Multiphysics
  Code Frameworks</title>
    <summary>  Among the present generation of multiphysics HPC simulation codes there are
many that are built upon general infrastructural frameworks. This is especially
true of the codes that make use of structured adaptive mesh refinement (SAMR)
because of unique demands placed on the housekeeping aspects of the code. They
have varying degrees of abstractions between the infrastructure such as mesh
management and IO and the numerics of the physics solvers. In this experience
report we summarize the experiences and lessons learned from two of such major
software efforts, FLASH and Chombo.
</summary>
    <author>
      <name>A. Dubey</name>
    </author>
    <author>
      <name>B. Van Straalen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5334/jors.am</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5334/jors.am" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Experience Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1812v2</id>
    <updated>2013-09-16T01:33:06Z</updated>
    <published>2013-09-07T03:18:51Z</published>
    <title>Cactus: Issues for Sustainable Simulation Software</title>
    <summary>  The Cactus Framework is an open-source, modular, portable programming
environment for the collaborative development and deployment of scientific
applications using high-performance computing. Its roots reach back to 1996 at
the National Center for Supercomputer Applications and the Albert Einstein
Institute in Germany, where its development jumpstarted. Since then, the Cactus
framework has witnessed major changes in hardware infrastructure as well as its
own community. This paper describes its endurance through these past changes
and, drawing upon lessons from its past, also discusses future
</summary>
    <author>
      <name>Frank Löffler</name>
    </author>
    <author>
      <name>Steven R. Brandt</name>
    </author>
    <author>
      <name>Gabrielle Allen</name>
    </author>
    <author>
      <name>Erik Schnetter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to the Workshop on Sustainable Software for Science:
  Practice and Experiences 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1812v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1812v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5145v1</id>
    <updated>2013-09-20T01:45:29Z</updated>
    <published>2013-09-20T01:45:29Z</published>
    <title>The Immune System: the ultimate fractionated cyber-physical system</title>
    <summary>  In this little vision paper we analyze the human immune system from a
computer science point of view with the aim of understanding the architecture
and features that allow robust, effective behavior to emerge from local sensing
and actions. We then recall the notion of fractionated cyber-physical systems,
and compare and contrast this to the immune system. We conclude with some
challenges.
</summary>
    <author>
      <name>Carolyn Talcott</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.129.18</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.129.18" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 129, 2013, pp. 309-324</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.5145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7122v1</id>
    <updated>2013-09-27T06:27:53Z</updated>
    <published>2013-09-27T06:27:53Z</published>
    <title>Proceedings Wivace 2013 - Italian Workshop on Artificial Life and
  Evolutionary Computation</title>
    <summary>  The Wivace 2013 Electronic Proceedings in Theoretical Computer Science
(EPTCS) contain some selected long and short articles accepted for the
presentation at Wivace 2013 - Italian Workshop on Artificial Life and
Evolutionary Computation, which was held at the University of Milan-Bicocca,
Milan, on the 1st and 2nd of July, 2013.
</summary>
    <author>
      <name>Alex Graudenzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Informatics, Systems and Communication, University of Milan Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Giulio Caravagna</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Informatics, Systems and Communication, University of Milan Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Giancarlo Mauri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Informatics, Systems and Communication, University of Milan Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Marco Antoniotti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Informatics, Systems and Communication, University of Milan Bicocca</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7689v1</id>
    <updated>2013-09-30T01:05:43Z</updated>
    <published>2013-09-30T01:05:43Z</published>
    <title>Application of a Semi-automatic Algorithm for Identification of
  Molecular Components in SBML Models</title>
    <summary>  Reactions forming a pathway can be rewritten by making explicit the different
molecular components involved in them. A molecular component represents a
biological entity (e.g. a protein) in all its states (free, bound, degraded,
etc.). In this paper we show the application of a component identification
algorithm to a number of real-world models to experimentally validate the
approach. Components identification allows subpathways to be computed to better
understand the pathway functioning.
</summary>
    <author>
      <name>Andrea Maggiolo-Schettini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Milazzo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Giovanni Pardini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 43-52</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7692v1</id>
    <updated>2013-09-30T01:06:09Z</updated>
    <published>2013-09-30T01:06:09Z</published>
    <title>A Model of Colonic Crypts using SBML Spatial</title>
    <summary>  The Spatial Processes package enables an explicit definition of a spatial
environment on top of the normal dynamic modeling SBML capabilities. The
possibility of an explicit representation of spatial dynamics increases the
representation power of SBML. In this work we used those new SBML features to
define an extensive model of colonic crypts composed of the main cellular types
(from stem cells to fully differentiated cells), alongside their spatial
dynamics.
</summary>
    <author>
      <name>Daniele Ramazzotti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Carlo Maj</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Marco Antoniotti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.11</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.11" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 74-78</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.2361v1</id>
    <updated>2013-10-09T05:58:26Z</updated>
    <published>2013-10-09T05:58:26Z</published>
    <title>Survey on Modelling Methods Applicable to Gene Regulatory Network</title>
    <summary>  Gene Regulatory Network (GRN) plays an important role in knowing insight of
cellular life cycle. It gives information about at which different
environmental conditions genes of particular interest get over expressed or
under expressed. Modelling of GRN is nothing but finding interactive
relationships between genes. Interaction can be positive or negative. For
inference of GRN, time series data provided by Microarray technology is used.
Key factors to be considered while constructing GRN are scalability,
robustness, reliability and maximum detection of true positive interactions
between genes. This paper gives detailed technical review of existing methods
applied for building of GRN along with scope for future work.
</summary>
    <author>
      <name>Chanda Panse</name>
    </author>
    <author>
      <name>Dr. Manali Kshirsagar</name>
    </author>
    <link href="http://arxiv.org/abs/1310.2361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.2361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5568v1</id>
    <updated>2013-10-21T14:31:20Z</updated>
    <published>2013-10-21T14:31:20Z</published>
    <title>Towards Application of the RBNK Model</title>
    <summary>  The computational modeling of genetic regulatory networks is now common
place, either by fitting a system to experimental data or by exploring the
behaviour of abstract systems with the aim of identifying underlying
principles. This paper presents an approach to the latter, considering the
response to environmental changes of a well-known model placed upon tunable
fitness landscapes. The effects on genome size and gene connectivity are
explored.
</summary>
    <author>
      <name>Larry Bull</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1306.4793,
  arXiv:1303.7220</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0438v2</id>
    <updated>2014-04-29T08:42:24Z</updated>
    <published>2013-11-03T08:26:38Z</published>
    <title>Modeling Vanilla Option prices: A simulation study by an implicit method</title>
    <summary>  Option contracts can be valued by using the Black-Scholes equation, a partial
differential equation with initial conditions. An exact solution for European
style options is known. The computation time and the error need to be minimized
simultaneously. In this paper, the authors have solved the Black-Scholes
equation by employing a reasonably accurate implicit method. Options with known
analytic solutions have been evaluated. Furthermore, an overall second order
accurate space and time discretization is proposed in this paper Keywords:
Computational finance, implicit methods, finite differences, call/put options.
</summary>
    <author>
      <name>Snehanshu Saha</name>
    </author>
    <author>
      <name>Swati Routh</name>
    </author>
    <author>
      <name>Bidisha Goswami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An expository report</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0438v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0438v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2203v1</id>
    <updated>2013-12-08T12:36:36Z</updated>
    <published>2013-12-08T12:36:36Z</published>
    <title>Research on fresh agriculture product based on overconfidence of the
  retailer under options and spot markets dominated</title>
    <summary>  In this article, we analyze the application of options contract in special
commodity supply chain such as fresh agricultural products. This problem is
discussed in the point of the retailer. When spot market and future market are
both available, we discuss how the retailer chooses the optimal production.
Furthermore, overconfidence is introduced to the supply chain of the fresh
agricultural products, which has not happened before. Then,based on the
overconfidence of the retailer, we explore how overconfidence affects the
supply chain system under different circumstances. At last, we get the
conclusion that different overconfidence level has different affection on
retailer's optimal ordering quantity and profit.
</summary>
    <author>
      <name>Kai Nie</name>
    </author>
    <author>
      <name>Man Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1312.2203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3858v1</id>
    <updated>2013-12-13T16:19:35Z</updated>
    <published>2013-12-13T16:19:35Z</published>
    <title>Computational impact of hydrophobicity in protein stability</title>
    <summary>  Among the various features of amino acids, the hydrophobic property has most
visible impact on stability of a sequence folding. This is mentioned in many
protein folding related work, in this paper we more elaborately discuss the
computational impact of the well defined hydrophobic aspect in determining
stability, approach with the help of a developed free energy computing
algorithm covering various aspects preprocessing of an amino acid sequence,
generating the folding and calculating free energy. Later discussing its use in
protein structure related research work.
</summary>
    <author>
      <name>Geetika Silakari Pandey</name>
    </author>
    <author>
      <name>R. C. Jain</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(ijcsis)international journal of computer science and information
  security, vol.11, no. 10, october 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.3858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4587v1</id>
    <updated>2013-12-16T23:01:46Z</updated>
    <published>2013-12-16T23:01:46Z</published>
    <title>FFTPL: An Analytic Placement Algorithm Using Fast Fourier Transform for
  Density Equalization</title>
    <summary>  We propose a flat nonlinear placement algorithm FFTPL using fast Fourier
transform for density equalization. The placement instance is modeled as an
electrostatic system with the analogy of density cost to the potential energy.
A well-defined Poisson's equation is proposed for gradient and cost
computation. Our placer outperforms state-of-the-art placers with better
solution quality and efficiency.
</summary>
    <author>
      <name>Jingwei Lu</name>
    </author>
    <author>
      <name>Pengwen Chen</name>
    </author>
    <author>
      <name>Chin-Chih Chang</name>
    </author>
    <author>
      <name>Lu Sha</name>
    </author>
    <author>
      <name>Dennis Jen-Hsin Huang</name>
    </author>
    <author>
      <name>Chin-Chi Teng</name>
    </author>
    <author>
      <name>Chung-Kuan Cheng</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4587v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4587v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3446v1</id>
    <updated>2014-01-15T04:59:08Z</updated>
    <published>2014-01-15T04:59:08Z</published>
    <title>Amino Acid Interaction Network Prediction using Multi-objective
  Optimization</title>
    <summary>  Protein can be represented by amino acid interaction network. This network is
a graph whose vertices are the proteins amino acids and whose edges are the
interactions between them. This interaction network is the first step of
proteins three-dimensional structure prediction. In this paper we present a
multi-objective evolutionary algorithm for interaction prediction and ant
colony probabilistic optimization algorithm is used to confirm the interaction.
</summary>
    <author>
      <name>Md. Shiplu Hawlader</name>
    </author>
    <author>
      <name>Saifuddin Md. Tareeq</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/csit.2014.4113</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/csit.2014.4113" rel="related"/>
    <link href="http://arxiv.org/abs/1401.3446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5791v1</id>
    <updated>2014-01-22T11:22:19Z</updated>
    <published>2014-01-22T11:22:19Z</published>
    <title>Advanced Signal Processing Techniqes to Study Normal and Epileptic EEG</title>
    <summary>  EEG monitoring has an important milestone provide valuable information of
those candidates who suffer from epilepsy.In this paper human normal and
epileptic Electroencephalogram signals are analyzed with popular and efficient
signal processing techniques like Fourier and Wavelet transform. The delta,
theta, alpha, beta and gamma sub bands of EEG are obtained and studied for
detection of seizure and epilepsy. The extracted feature is then applied to ANN
for classification of the EEG signals.
</summary>
    <author>
      <name>Debadatta Dash</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">41 st annual conference of OMS and International Conference on
  Industrial Mathematics and Scientific Computing, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.5791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1523v1</id>
    <updated>2014-02-06T23:14:58Z</updated>
    <published>2014-02-06T23:14:58Z</published>
    <title>Programming plantation lines on driverless tractors</title>
    <summary>  Recent advances in Agricultural Engineering include image processing,
robotics and geographic information systems (GIS). Some tasks are still
accomplished manually, like drawing plantation lines that optimize
productivity. Herewith we present an algorithm to find the optimal plantation
lines in linear time. The algorithm is based upon classical results of Geometry
which enabled a source code with only 573 lines. We have implemented it in
Matlab for sugar cane, and it can be easily adapted to other crops like coffee,
maize and soy.
</summary>
    <author>
      <name>Antonio Elias Fabris</name>
    </author>
    <author>
      <name>Marcelo Zanchetta do Nascimento</name>
    </author>
    <author>
      <name>Valério Ramos Batista</name>
    </author>
    <link href="http://arxiv.org/abs/1402.1523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2453v1</id>
    <updated>2014-02-11T11:24:11Z</updated>
    <published>2014-02-11T11:24:11Z</published>
    <title>Sliding window and compressive sensing for low-field dynamic magnetic
  resonance imaging</title>
    <summary>  We describe an acquisition/processing procedure for image reconstruction in
dynamic Magnetic Resonance Imaging (MRI). The approach requires sliding window
to record a set of trajectories in the k-space, standard regularization to
reconstruct an estimate of the object and compressed sensing to recover image
residuals. We validated this approach in the case of specific simulated
experiments and, in the case of real measurements, we showed that the procedure
is reliable even in the case of data acquired by means of a low-field scanner.
</summary>
    <author>
      <name>Cristian Toraci</name>
    </author>
    <author>
      <name>Gabriele Zaccaria</name>
    </author>
    <author>
      <name>Stefano Ceriani</name>
    </author>
    <author>
      <name>David Wilson</name>
    </author>
    <author>
      <name>Marco Fato</name>
    </author>
    <author>
      <name>Michele Piana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Medical Imaging</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.2453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 65R32" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2551v1</id>
    <updated>2014-02-11T16:31:46Z</updated>
    <published>2014-02-11T16:31:46Z</published>
    <title>Modeling European Options</title>
    <summary>  Option contracts can be valued by using the Black-Scholes equation, a partial
differential equation with initial conditions. An exact solution for European
style options is known. The computation time and the error need to be minimized
simultaneously. In this paper, the authors have solved the Black-Scholes
equation by employing a reasonably accurate implicit method. Options with known
analytic solutions have been evaluated. Furthermore, an overall second order
accurate space and time discretization has been accomplished in this paper.
</summary>
    <author>
      <name>Aishwarya B U</name>
    </author>
    <author>
      <name>Mohammed Saaqib A</name>
    </author>
    <author>
      <name>Rajashree H R</name>
    </author>
    <author>
      <name>Vigasini B</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1311.0438 by
  other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.2551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3174v1</id>
    <updated>2014-02-13T15:10:39Z</updated>
    <published>2014-02-13T15:10:39Z</published>
    <title>Modeling of Degradation Processes in Historical Mortars</title>
    <summary>  The aim of presented paper is modeling of degradation processes in historical
mortars exposed to moisture impact during freezing. Internal damage caused by
ice crystallization in pores is one of the most important factors limiting the
service life of historical structures. Coupling the transport processes with
the mechanical part will allow us to address the impact of moisture on the
durability, strength and stiffness of mortars. This should be accomplished with
the help of a complex thermo-hygro-mechanical model representing one of the
prime objectives of this work. The proposed formulation is based on the
extension of the classical poroelasticity models with the damage mechanics. An
example of two-dimensional moisture transport in the environment with
temperature below freezing point is presented to support the theoretical
derivations.
</summary>
    <author>
      <name>J. Sýkora</name>
    </author>
    <link href="http://arxiv.org/abs/1402.3174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6775v1</id>
    <updated>2014-02-27T02:59:52Z</updated>
    <published>2014-02-27T02:59:52Z</published>
    <title>Analysis of Barcode sequence features to find anomalies due to
  amplification Bias</title>
    <summary>  In this paper we aim at investigating whether barcode sequence features can
predict the read count ambiguities caused during PCR based next generation
sequencing techniques. The methodologies we used are mutual information based
motif discovery and Lasso regression technique using features generated from
the barcode sequence. The results indicate that there is a certain degree of
correlation between motifs discovered in the sequences and the read counts. Our
main contribution in this paper is a thorough investigation of the barcode
features that gave us useful information regarding the significance of the
sequence features and the sequence containing the discovered motifs in
prediction of read counts.
</summary>
    <author>
      <name>Chandrima Sarkar</name>
    </author>
    <author>
      <name>Raamesh Deshpande</name>
    </author>
    <author>
      <name>Chad Myers</name>
    </author>
    <link href="http://arxiv.org/abs/1402.6775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.7324v1</id>
    <updated>2014-02-28T17:22:50Z</updated>
    <published>2014-02-28T17:22:50Z</published>
    <title>Geometrical approach to modeling of nonlinear systems from experimental
  data</title>
    <summary>  This monograph presents a geometric modeling method nonlinear dynamical
systems from experimental data . basis method is a qualitative approach to the
analysis of linear models and construction of the symmetry groups of attractors
of dynamical systems with controls . A theoretical study including the central
theorem manifold defining conditions of existence of the class in question
models in the local area , taking into account the group properties ,
estimation algorithms invariant characteristics , methods of constructing
models and identifiable description of the results obtained using the method
for simulation -driven engineering processes . included two application is the
development of the proposed approach : identification of groups symmetries on
the phase portraits of dynamical systems and the method of constructing neural
network predictive models
</summary>
    <author>
      <name>Evgeny Nikulchev</name>
    </author>
    <link href="http://arxiv.org/abs/1402.7324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.7324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2343v1</id>
    <updated>2014-04-09T01:19:29Z</updated>
    <published>2014-04-09T01:19:29Z</published>
    <title>Wireless Transmission of Video for Biomechanical Analysis</title>
    <summary>  When there is a possibility to wirelessly stream video over a network, a
sophisticated computer analysis of the transmitted video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it using specific software such as Arial Performance Analysis Systems
or Dartfish. This manuscript presents some approaches and challenges in
streaming video as well as some applications of Information Technology in
biomechanics. An example of how scientists from Indiana State University
approached the wireless transmission of video is also introduced.
</summary>
    <author>
      <name>Dr. Timur Mirzoev</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information systems. Problems, perspectives, innovation approaches
  Volume 2. 2007. Saint Petersburg State University of Aerospace
  Instrumentation. ISBN 978-5-80888-0244-5</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.2343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3286v1</id>
    <updated>2014-04-12T12:30:06Z</updated>
    <published>2014-04-12T12:30:06Z</published>
    <title>A Continuous Optimization Approach for the Financial Portfolio Selection
  under Discrete Asset Choice Constraints</title>
    <summary>  In this paper we consider a generalization of the Markowitz's Mean-Variance
model under linear transaction costs and cardinality constraints. The
cardinality constraints are used to limit the number of assets in the optimal
portfolio. The generalized model is formulated as a mixed integer quadratic
programming (MIP) problem. The purpose of this paper is to investigate a
continuous approach based on difference of convex functions (DC) programming
for solving the MIP model. The preliminary comparative results of the proposed
approach versus CPLEX are presented.
</summary>
    <author>
      <name>Mahdi Moeini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th International Symposium on Operational
  Research (SOR'2013), Slovenia, September 2013, pp. 89-95, (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3330v1</id>
    <updated>2014-04-12T23:58:20Z</updated>
    <published>2014-04-12T23:58:20Z</published>
    <title>A DC programming approach for constrained two-dimensional non-guillotine
  cutting problem</title>
    <summary>  We investigate a new application of Difference of Convex functions
programming and DCA in solving the constrained two-dimensional non-guillotine
cutting problem. This problem consists of cutting a number of rectangular
pieces from a large rectangular object. The cuts are done under some
constraints and the objective is to maximize the total value of the pieces cut.
We reformulate this problem as a DC program and solve it by DCA. The
performance of the approach is compared with the standard solver CPLEX.
</summary>
    <author>
      <name>Mahdi Moeini</name>
    </author>
    <author>
      <name>Hoai An Le Thi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Industrial Engineering
  and Systems Management (IESM 2011), Metz, May 2011, pp. 212-221, (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4820v1</id>
    <updated>2014-04-17T14:19:19Z</updated>
    <published>2014-04-17T14:19:19Z</published>
    <title>Topology optimization based on moving deformable components: A new
  computational framework</title>
    <summary>  In the present work, a new computational framework for structural topology
optimization based on the concept of moving deformable components is proposed.
Compared with the traditional pixel or node point-based solution framework, the
proposed solution paradigm can incorporate more geometry and mechanical
information into topology optimization directly and therefore render the
solution process more flexible. It also has the great potential to reduce the
computational burden associated with topology optimization substantially. Some
representative examples are presented to illustrate the effectiveness of the
proposed approach.
</summary>
    <author>
      <name>Xu Guo</name>
    </author>
    <author>
      <name>Weisheng Zhang</name>
    </author>
    <author>
      <name>Wenliang Zhong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1115/1.4027609</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1115/1.4027609" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 22 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Applied Mechanics Vol.81 (2014) 081009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.4820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5254v1</id>
    <updated>2014-04-21T17:55:34Z</updated>
    <published>2014-04-21T17:55:34Z</published>
    <title>Simultaneous Source for non-uniform data variance and missing data</title>
    <summary>  The use of simultaneous sources in geophysical inverse problems has
revolutionized the ability to deal with large scale data sets that are obtained
from multiple source experiments. However, the technique breaks when the data
has non-uniform standard deviation or when some data are missing. In this paper
we develop, study, and compare a number of techniques that enable to utilize
advantages of the simultaneous source framework for these cases. We show that
the inverse problem can still be solved efficiently by using these new
techniques. We demonstrate our new approaches on the Direct Current Resistivity
inverse problem.
</summary>
    <author>
      <name>Eldad Haber</name>
    </author>
    <author>
      <name>Mathias Chung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.5254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6385v2</id>
    <updated>2014-04-29T14:19:35Z</updated>
    <published>2014-04-25T10:54:26Z</published>
    <title>High-Content Digital Microscopy with Python</title>
    <summary>  High-Content Digital Microscopy enhances user comfort, data storage and
analysis throughput, paving the way to new researches and medical diagnostics.
A digital microscopy platform aims at capturing an image of a cover slip, at
storing information on a file server and a database, at visualising the image
and analysing its content. We will discuss how the Python ecosystem can provide
such software framework efficiently. Moreover this paper will give an
illustration of the data chunking approach to manage the huge amount of data.
</summary>
    <author>
      <name>Fabrice Salvaire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6385v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6385v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6391v2</id>
    <updated>2014-04-29T14:28:34Z</updated>
    <published>2014-04-25T10:56:35Z</published>
    <title>SfePy - Write Your Own FE Application</title>
    <summary>  SfePy (Simple Finite Elements in Python) is a framework for solving various
kinds of problems (mechanics, physics, biology, ...) described by partial
differential equations in two or three space dimensions by the finite element
method. The paper illustrates its use in an interactive environment or as a
framework for building custom finite-element based solvers.
</summary>
    <author>
      <name>Robert Cimrman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6391v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6391v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0878v1</id>
    <updated>2014-05-05T12:51:21Z</updated>
    <published>2014-05-05T12:51:21Z</published>
    <title>Market Coupling as the Universal Algorithm to Assess Zonal Divisions</title>
    <summary>  Adopting a zonal structure of electricity market requires specification of
zones' borders. In this paper we use social welfare as the measure to assess
quality of various zonal divisions. The social welfare is calculated by Market
Coupling algorithm. The analyzed divisions are found by the usage of extended
Locational Marginal Prices (LMP) methodology presented in paper [1], which
takes into account variable weather conditions. The offered method of
assessment of a proposed division of market into zones is however not limited
to LMP approach but can evaluate the social welfare of divisions obtained by
any methodology.
</summary>
    <author>
      <name>Grzegorz Orynczak</name>
    </author>
    <author>
      <name>Marcin Jakubek</name>
    </author>
    <author>
      <name>Karol Wawrzyniak</name>
    </author>
    <author>
      <name>Michal Klos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1300v2</id>
    <updated>2024-05-11T22:05:59Z</updated>
    <published>2014-03-20T16:00:45Z</published>
    <title>The calculation of air filtration efficiency through the visual basic
  programming language</title>
    <summary>  The present article describes the development of a software which was written
in visual basic programming language. The software calculates the particle
collection efficiency and penetration of a fibrous filter medium for given
values of particle diameter, fiber diameter filter thickness, volume fraction
etc, during the process of air filtration. The progress of the development of
software is divided into two steps, the design of graphical user interface
(GUI) and the code writing. The code is mainly based on the mathematical model
of particle collection efficiency of fibrous filters media.
</summary>
    <author>
      <name>Giorgos Kouropoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 tables, 5 figures, 13 equations</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.1300v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1300v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1304v1</id>
    <updated>2014-05-03T14:26:42Z</updated>
    <published>2014-05-03T14:26:42Z</published>
    <title>Application of Machine Learning Techniques in Aquaculture</title>
    <summary>  In this paper we present applications of different machine learning
algorithms in aquaculture. Machine learning algorithms learn models from
historical data. In aquaculture historical data are obtained from farm
practices, yields, and environmental data sources. Associations between these
different variables can be obtained by applying machine learning algorithms to
historical data. In this paper we present applications of different machine
learning algorithms in aquaculture applications.
</summary>
    <author>
      <name>Akhlaqur Rahman</name>
    </author>
    <author>
      <name>Sumaira Tasnim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V10P137</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V10P137" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology (IJCTT)
  V10(3):214-215 Apr 2014. ISSN:2231-2803</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.1304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5151v1</id>
    <updated>2014-06-19T18:57:03Z</updated>
    <published>2014-06-19T18:57:03Z</published>
    <title>Tollan-Xicocotitlan: A reconstructed City by augmented reality</title>
    <summary>  This project presents the analysis, design, implementation and results of
Reconstruction Xicocotitlan Tollan-through augmented reality, which will
release information about the Toltec culture supplemented by presenting an
overview of the main premises of the Xicocotitlan Tollan city supported
dimensional models based on the augmented reality technique showing the user a
virtual representation of buildings in Tollan.
</summary>
    <author>
      <name>Martha Rosa Cordero Lopez</name>
    </author>
    <author>
      <name>Marco Antonio Dorantes Gonzalez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 12 figures, Fourth International Conference on Advances in
  Computing and Information technology (ACITY 2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.5151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7459v1</id>
    <updated>2014-06-29T04:27:06Z</updated>
    <published>2014-06-29T04:27:06Z</published>
    <title>Speedup of Micromagnetic Simulations with C++ AMP On Graphics Processing
  Units</title>
    <summary>  A finite-difference Micromagnetic solver is presented utilizing the C++
Accelerated Massive Parallelism (C++ AMP). The high speed performance of a
single Graphics Processing Unit (GPU) is demonstrated compared to a typical
CPU-based solver. The speed-up of GPU to CPU is shown to be greater than 100
for problems with larger sizes. This solver is based on C++ AMP and can run on
GPUs from various hardware vendors, such as NVIDIA, AMD and Intel, regardless
of whether it is dedicated or integrated graphics processor.
</summary>
    <author>
      <name>Ru Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.7459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1291v2</id>
    <updated>2014-09-17T12:59:13Z</updated>
    <published>2014-07-04T18:37:33Z</published>
    <title>Reinforcement Learning Based Algorithm for the Maximization of EV
  Charging Station Revenue</title>
    <summary>  This paper presents an online reinforcement learning based application which
increases the revenue of one particular electric vehicles (EV) station,
connected to a renewable source of energy. Moreover, the proposed application
adapts to changes in the trends of the station's average number of customers
and their types. Most of the parameters in the model are simulated
stochastically and the algorithm used is a Q-learning algorithm. A computer
simulation was implemented which demonstrates and confirms the utility of the
model.
</summary>
    <author>
      <name>Stoyan Dimitrov</name>
    </author>
    <author>
      <name>Redouane Lguensat</name>
    </author>
    <link href="http://arxiv.org/abs/1407.1291v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1291v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2237v1</id>
    <updated>2014-07-06T17:00:53Z</updated>
    <published>2014-07-06T17:00:53Z</published>
    <title>An Algorithm for Alignment-free Sequence Comparison using Logical Match</title>
    <summary>  This paper proposes an algorithm for alignment-free sequence comparison using
Logical Match. Here, we compute the score using fuzzy membership values which
generate automatically from the number of matches and mismatches. We
demonstrate the method with both the artificial and real datum. The results
show the uniqueness of the proposed method by analyzing DNA sequences taken
from NCBI databank with a novel computational time.
</summary>
    <author>
      <name>Sanil Shanker KP</name>
    </author>
    <author>
      <name>Elizabeth Sherly</name>
    </author>
    <author>
      <name>Jim Austin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICCAE.2010.5452072</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICCAE.2010.5452072" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computer and Automation Engineering (ICCAE), 2010 The 2nd
  International Conference on</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7924v1</id>
    <updated>2014-07-30T02:33:57Z</updated>
    <published>2014-07-30T02:33:57Z</published>
    <title>Chance Constrained Optimization for Targeted Internet Advertising</title>
    <summary>  We introduce a chance constrained optimization model for the fulfillment of
guaranteed display Internet advertising campaigns. The proposed formulation for
the allocation of display inventory takes into account the uncertainty of the
supply of Internet viewers. We discuss and present theoretical and
computational features of the model via Monte Carlo sampling and convex
approximations. Theoretical upper and lower bounds are presented along with a
numerical substantiation.
</summary>
    <author>
      <name>Antoine Deza</name>
    </author>
    <author>
      <name>Kai Huang</name>
    </author>
    <author>
      <name>Michael R. Metel</name>
    </author>
    <link href="http://arxiv.org/abs/1407.7924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5634v1</id>
    <updated>2014-08-24T20:41:51Z</updated>
    <published>2014-08-24T20:41:51Z</published>
    <title>An application of topological graph clustering to protein function
  prediction</title>
    <summary>  We use a semisupervised learning algorithm based on a topological data
analysis approach to assign functional categories to yeast proteins using
similarity graphs. This new approach to analyzing biological networks yields
results that are as good as or better than state of the art existing
approaches.
</summary>
    <author>
      <name>R. Sean Bowman</name>
    </author>
    <author>
      <name>Douglas Heisterkamp</name>
    </author>
    <author>
      <name>Jesse Johnson</name>
    </author>
    <author>
      <name>Danielle O'Donnol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0658v1</id>
    <updated>2014-09-02T10:43:25Z</updated>
    <published>2014-09-02T10:43:25Z</published>
    <title>Detect Adverse Drug Reactions for Drug Aspirin</title>
    <summary>  Adverse drug reaction (ADR) is widely concerned for public health issue. In
this study we propose an original approach to detect the ADRs using feature
matrix and feature selection. The experiments are carried out on the drug
Aspirin. Major side effects for the drug are detected and better performance is
achieved compared to other computerized methods. The detected ADRs are based on
the computerized method, further investigation is needed.
</summary>
    <author>
      <name>Yihui liu</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE fifth International Conference on Advanced Computational
  Intelligence (ICACI), pp. 234-237, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.0658v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0658v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1059v1</id>
    <updated>2014-09-03T12:30:05Z</updated>
    <published>2014-09-03T12:30:05Z</published>
    <title>Detecting adverse drug reactions for the drug Simvastatin</title>
    <summary>  Adverse drug reactions (ADR) are widely concerning for public health issue.
In this study we propose an original approach to detect ADRs using a feature
matrix and feature selection. The experiments are carried out on the drug
Simvastatin. Major side effects for the drug are detected and better
performance is achieved compared to other computerized methods. Because
currently the detected ADRs are based solely on computerized methods, further
expert investigation is needed.
</summary>
    <author>
      <name>Yihui Liu</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fourth International Conference on Multimedia Information Networking
  and Security (MINES), pp. 246-249, 2012. arXiv admin note: substantial text
  overlap with arXiv:1409.0658</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.1059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1233v11</id>
    <updated>2024-11-22T00:25:16Z</updated>
    <published>2014-10-06T01:29:42Z</published>
    <title>EnKF-C user guide</title>
    <summary>  EnKF-C provides a compact generic framework for off-line data assimilation
into large-scale layered geophysical models with the ensemble Kalman filter
(EnKF). It is coded in C for GNU/Linux platform and can work either in EnKF,
ensemble optimal interpolation (EnOI), or hybrid (EnKF/EnOI) modes.
</summary>
    <author>
      <name>Pavel Sakov</name>
    </author>
    <link href="http://arxiv.org/abs/1410.1233v11" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1233v11" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6609v1</id>
    <updated>2014-10-24T08:10:13Z</updated>
    <published>2014-10-24T08:10:13Z</published>
    <title>Parallel Multiphysics Simulations of Charged Particles in Microfluidic
  Flows</title>
    <summary>  The article describes parallel multiphysics simulations of charged particles
in microfluidic flows with the waLBerla framework. To this end, three physical
effects are coupled: rigid body dynamics, fluid flow modelled by a lattice
Boltzmann algorithm, and electric potentials represented by a finite volume
discretisation. For solving the finite volume discretisation for the
electrostatic forces, a cell-centered multigrid algorithm is developed that
conforms to the lattice Boltzmann meshes and the parallel communication
structure of waLBerla. The new functionality is validated with suitable
benchmark scenarios. Additionally, the parallel scaling and the numerical
efficiency of the algorithms are analysed on an advanced supercomputer.
</summary>
    <author>
      <name>Dominik Bartuschat</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Computational Science (Elsevier)</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.6609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2565v1</id>
    <updated>2014-11-10T20:12:46Z</updated>
    <published>2014-11-10T20:12:46Z</published>
    <title>Grace: a Cross-platform Micromagnetic Simulator On Graphics Processing
  Units</title>
    <summary>  A micromagnetic simulator running on graphics processing unit (GPU) is
presented. It achieves significant performance boost as compared to previous
central processing unit (CPU) simulators, up to two orders of magnitude for
large input problems. Different from GPU implementations of other research
groups, this simulator is developed with C++ Accelerated Massive Parallelism
(C++ AMP) and is hardware platform compatible. It runs on GPU from venders
include NVidia, AMD and Intel, which paved the way for fast micromagnetic
simulation on both high-end workstations with dedicated graphics cards and
low-end personal computers with integrated graphics card. A copy of the
simulator software is publicly available.
</summary>
    <author>
      <name>Ru Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4726v1</id>
    <updated>2014-12-15T19:09:48Z</updated>
    <published>2014-12-15T19:09:48Z</published>
    <title>Experimental economics for web mining</title>
    <summary>  This paper offers a step towards research infrastructure, which makes data
from experimental economics efficiently usable for analysis of web data. We
believe that regularities of human behavior found in experimental data also
emerge in real world web data. A format for data from experiments is suggested,
which enables its publication as open data. Once standardized datasets of
experiments are available on-line, web mining can take advantages from this
data. Further, the questions about the order of causalities arisen from web
data analysis can inspire new experiment setups.
</summary>
    <author>
      <name>Rustam Tagiew</name>
    </author>
    <author>
      <name>Dmitry I. Ignatov</name>
    </author>
    <author>
      <name>Fadi Amroush</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.4726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.8574v1</id>
    <updated>2014-12-30T07:37:52Z</updated>
    <published>2014-12-30T07:37:52Z</published>
    <title>Fast and Scalable Inference of Multi-Sample Cancer Lineages</title>
    <summary>  Somatic variants can be used as lineage markers for the phylogenetic
reconstruction of cancer evolution. Since somatic phylogenetics is complicated
by sample heterogeneity, novel specialized tree-building methods are required
for cancer phylogeny reconstruction. We present LICHeE (Lineage Inference for
Cancer Heterogeneity and Evolution), a novel method that automates the
phylogenetic inference of cancer progression from multiple somatic samples.
LICHeE uses variant allele frequencies of SSNVs obtained by deep sequencing to
reconstruct multi-sample cell lineage trees and infer the subclonal composition
of the samples. LICHeE is open-sourced and available at
http://viq854.github.io/lichee.
</summary>
    <author>
      <name>Victoria Popic</name>
    </author>
    <author>
      <name>Raheleh Salari</name>
    </author>
    <author>
      <name>Iman Hajirasouliha</name>
    </author>
    <author>
      <name>Dorna Kashef-Haghighi</name>
    </author>
    <author>
      <name>Robert B. West</name>
    </author>
    <author>
      <name>Serafim Batzoglou</name>
    </author>
    <link href="http://arxiv.org/abs/1412.8574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.8574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07293v1</id>
    <updated>2015-01-25T18:21:58Z</updated>
    <published>2015-01-25T18:21:58Z</published>
    <title>Accelerate micromagnetic simulations with GPU programming in MATLAB</title>
    <summary>  A finite-difference Micromagnetic simulation code written in MATLAB is
presented with Graphics Processing Unit (GPU) acceleration. The high
performance of Graphics Processing Unit (GPU) is demonstrated compared to a
typical Central Processing Unit (CPU) based code. The speed-up of GPU to CPU is
shown to be greater than 30 for problems with larger sizes on a mid-end GPU in
single precision. The code is less than 200 lines and suitable for new
algorithm developing.
</summary>
    <author>
      <name>Ru Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.07293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07671v1</id>
    <updated>2015-01-30T06:06:37Z</updated>
    <published>2015-01-30T06:06:37Z</published>
    <title>Prioritizing the Components of Vulnerability in a Genetic Algorithms
  Minimization of Flood Risk</title>
    <summary>  We compare two prioritization schemes for the components of flooding
vulnerability: urbanized area ration, literacy rate, mortality rate, poverty,
radio/tv penetration, non-structural measures and structural measure. We
prioritize the components, giving each a weight. We then express the
vulnerability function as a weighted sum of its components. This weighted sum
serves as the fitness function in a genetic algorithm, which comes up with the
optimal design for a flood-resistant city.
</summary>
    <author>
      <name>Vena Pearl Boñgolan</name>
    </author>
    <author>
      <name>Karessa Alexandra O. Baritua</name>
    </author>
    <author>
      <name>Marie Junne Santos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">eight pages in pdf, with figures included</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.07671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01733v1</id>
    <updated>2015-02-05T21:31:25Z</updated>
    <published>2015-02-05T21:31:25Z</published>
    <title>Arrhythmia Detection using Mutual Information-Based Integration Method</title>
    <summary>  The aim of this paper is to propose an application of mutual
information-based ensemble methods to the analysis and classification of heart
beats associated with different types of Arrhythmia. Models of multilayer
perceptrons, support vector machines, and radial basis function neural networks
were trained and tested using the MIT-BIH arrhythmia database. This research
brings a focus to an ensemble method that, to our knowledge, is a novel
application in the area of ECG Arrhythmia detection. The proposed classifier
ensemble method showed improved performance, relative to either majority voting
classifier integration or to individual classifier performance. The overall
ensemble accuracy was 98.25%.
</summary>
    <author>
      <name>Othman Soufan</name>
    </author>
    <author>
      <name>Samer Arafat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, 7 tables, WConSC 2011 conference
  http://www.ece.ualberta.ca/~reform/WConSC/ (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.01733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02824v1</id>
    <updated>2015-02-10T09:37:17Z</updated>
    <published>2015-02-10T09:37:17Z</published>
    <title>Fuzzy finite element solution of uncertain neutron diffusion equation
  for imprecisely defined homogeneous triangular bare reactor</title>
    <summary>  Scattering of neutron collision inside a reactor depends upon geometry of the
reactor, diffusion coefficient and absorption coefficient etc. In general these
parameters are not crisp and hence we may get uncertain neutron diffusion
equation. In this paper we have investigated the above problem for a bare
triangular homogeneous reactor. Here the uncertain governing differential
equation is modelled by a modified fuzzy finite element method using newly
proposed interval arithmetic. Obtained eigenvalues by the proposed method are
studied in detail. Further the eigenvalues are compared with the classical
finite element method in special cases and various uncertain results have been
discussed.
</summary>
    <author>
      <name>Sukanta Nayak</name>
    </author>
    <author>
      <name>Snehashish Chakraverty</name>
    </author>
    <link href="http://arxiv.org/abs/1502.02824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01380v2</id>
    <updated>2015-11-14T16:26:05Z</updated>
    <published>2015-04-06T16:00:32Z</published>
    <title>The swept rule for breaking the latency barrier in time advancing PDEs</title>
    <summary>  This article investigates the swept rule of space-time domain decomposition,
an idea to break the latency barrier via communicating less often when
explicitly solving time-dependent PDEs. The swept rule decomposes space and
time among computing nodes in ways that exploit the domains of influence and
the domain of dependency, making it possible to communicate once per many
timesteps without redundant computation. The article presents simple
theoretical analysis to the performance of the swept rule which then was shown
to be accurate by conducting numerical experiments.
</summary>
    <author>
      <name>Maitham Makki Alhubail</name>
    </author>
    <author>
      <name>Qiqi Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2015.11.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2015.11.026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Physics (2016), pp. 110-121</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.01380v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01380v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02008v1</id>
    <updated>2015-05-08T11:59:43Z</updated>
    <published>2015-05-08T11:59:43Z</published>
    <title>Decomposition of Power Flow Used for Optimizing Zonal Configurations of
  Energy Market</title>
    <summary>  Zonal configuration of energy market is often a consequence of political
borders. However there are a few methods developed to help with zonal
delimitation in respect to some measures. This paper presents the approach
aiming at reduction of the loop flow effect - an element of unscheduled flows
which introduces a loss of market efficiency. In order to undertake zonal
partitioning, a detailed decomposition of power flow is performed. Next, we
identify the zone which is a source of the problem and enhance delimitation by
dividing it into two zones. The procedure is illustrated by a study of simple
case.
</summary>
    <author>
      <name>Michal Klos</name>
    </author>
    <author>
      <name>Karol Wawrzyniak</name>
    </author>
    <author>
      <name>Marcin Jakubek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, IEEE European Energy Markets 2015 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.02008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04114v1</id>
    <updated>2015-05-15T16:35:43Z</updated>
    <published>2015-05-15T16:35:43Z</published>
    <title>Scaffolding the Mitochondrial Disease Ontology from extant knowledge
  sources</title>
    <summary>  Bio-medical ontologies can contain a large number of concepts. Often many of
these concepts are very similar to each other, and similar or identical to
concepts found in other bio-medical databases. This presents both a challenge
and opportunity: maintaining many similar concepts is tedious and fastidious
work, which could be substantially reduced if the data could be derived from
pre-existing knowledge sources. In this paper, we describe how we have achieved
this for an ontology of the mitochondria using our novel ontology development
environment, the Tawny-OWL library.
</summary>
    <author>
      <name>Jennifer D. Warrender</name>
    </author>
    <author>
      <name>Phillip Lord</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, accepted at ICBO 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04785v1</id>
    <updated>2015-05-18T10:18:20Z</updated>
    <published>2015-05-18T10:18:20Z</published>
    <title>Advances in Bioinformatics and Computational Biology: Don't take them
  too seriously anyway</title>
    <summary>  In the last few decades or so, we witness a paradigm shift in our nature
studies - from a data-processing based computational approach to an
information-processing based cognitive approach. The process is restricted and
often misguided by the lack of a clear understanding about what information is
and how it should be treated in research applications (in general) and in
biological studies (in particular). The paper intend to provide some remedies
for this bizarre situation.
</summary>
    <author>
      <name>Emanuel Diamant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper was submitted to the BIOCOMP'15 conference (Las Vegas,
  Nevada, USA, July 27-30, 2015) and was accepted as a poster presentation.
  arXiv admin note: text overlap with arXiv:1505.04578</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02808v1</id>
    <updated>2015-06-09T07:41:26Z</updated>
    <published>2015-06-09T07:41:26Z</published>
    <title>Simulations using meshfree methods</title>
    <summary>  In this paper, attempt is made to solve a few problems using the Polynomial
Point Collocation Method (PPCM), the Radial Point Collocation Method (RPCM),
Smoothed Particle Hydrodynamics (SPH), and the Finite Point Method (FPM). A few
observations on the accuracy of these methods are recorded. All the simulations
in this paper are three dimensional linear elastostatic simulations, without
accounting for body forces.
</summary>
    <author>
      <name>Kirana Kumara P</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint (draft) + 3 figures, 1 table, 2 appendices, 2 images, 1
  MATLAB code</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03610v2</id>
    <updated>2015-06-22T19:36:56Z</updated>
    <published>2015-06-11T10:11:19Z</published>
    <title>Yang-Baxter Equations, Computational Methods and Applications</title>
    <summary>  Computational methods are an important tool for solving the Yang-Baxter
equations(in small dimensions), for classifying (unifying) structures, and for
solving related problems. This paper is an account of some of the latest
developments on the Yang-Baxter equation, its set-theoretical version, and its
applications. We construct new set-theoretical solutions for the Yang-Baxter
equation. Unification theories and other results are proposed or proved.
</summary>
    <author>
      <name>Florin F. Nichita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.03610v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03610v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="16T10, 16T25, 17B01, 17B60, 17C05, 17C50, 17D99, 65D20, 65L09,&#10;  68R99, 97M10, 97M80, 97N50, 97N80, 97P20, 97R20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05996v1</id>
    <updated>2015-06-19T13:27:05Z</updated>
    <published>2015-06-19T13:27:05Z</published>
    <title>GPU accelerated spectral finite elements on all-hex meshes</title>
    <summary>  This paper presents a spectral element finite element scheme that efficiently
solves elliptic problems on unstructured hexahedral meshes. The discrete
equations are solved using a matrix-free preconditioned conjugate gradient
algorithm. An additive Schwartz two-scale preconditioner is employed that
allows h-independence convergence. An extensible multi-threading programming
API is used as a common kernel language that allows runtime selection of
different computing devices (GPU and CPU) and different threading interfaces
(CUDA, OpenCL and OpenMP). Performance tests demonstrate that problems with
over 50 million degrees of freedom can be solved in a few seconds on an
off-the-shelf GPU.
</summary>
    <author>
      <name>J. -F. Remacle</name>
    </author>
    <author>
      <name>R. Gandham</name>
    </author>
    <author>
      <name>T. Warburton</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2016.08.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2016.08.005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.05996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05, 65Y10, 65Y20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07220v1</id>
    <updated>2015-06-24T01:43:11Z</updated>
    <published>2015-06-24T01:43:11Z</published>
    <title>Leverage Financial News to Predict Stock Price Movements Using Word
  Embeddings and Deep Neural Networks</title>
    <summary>  Financial news contains useful information on public companies and the
market. In this paper we apply the popular word embedding methods and deep
neural networks to leverage financial news to predict stock price movements in
the market. Experimental results have shown that our proposed methods are
simple but very effective, which can significantly improve the stock prediction
accuracy on a standard financial database over the baseline system using only
the historical price information.
</summary>
    <author>
      <name>Yangtuo Peng</name>
    </author>
    <author>
      <name>Hui Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.07220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05391v1</id>
    <updated>2015-07-20T06:00:47Z</updated>
    <published>2015-07-20T06:00:47Z</published>
    <title>Data Acquisition and Control System for High-Performance Large-Area CCD
  Systems</title>
    <summary>  Astronomical CCD systems based on second-generation DINACON controllers were
developed at the SAO RAS Advanced Design Laboratory more than seven years ago
and since then have been in constant operation at the 6-meter and Zeiss-1000
telescopes. Such systems use monolithic large-area CCDs. We describe the
software developed for the control of a family of large-area CCD systems
equipped with a DINACON-II controller. The software suite serves for
acquisition, primary reduction, visualization, and storage of video data, and
also for the control, setup, and diagnostics of the CCD system.
</summary>
    <author>
      <name>I. V. Afanasieva</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S1990341315020017</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S1990341315020017" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Astrophysical Bulletin, April 2015, Volume 70, Issue 2, pp 232-237</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.05391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.04105v1</id>
    <updated>2015-08-17T18:37:58Z</updated>
    <published>2015-08-17T18:37:58Z</published>
    <title>PTILE: A framework for the Evaluation of Power Transformer Insulation
  Life in Electric Power System</title>
    <summary>  In this paper, a framework is developed for power transformer (Generator Step
up Unit) insulation life evaluation (PTILE) study on power system Network.
Parameters used for studies include real time sample data obtained from power
transformer field studies in the South-South Niger Delta region of Nigeria. It
is used for performing simulations over varying number of years. Simulation
reports shows a polynomial running time complexity and validates the stochastic
Hot Spot theory indicating that the transformers in such region should be
replaced sooner due to higher hot spots and transformer loading in such regions
</summary>
    <author>
      <name>Nelson O. Ogbogu</name>
    </author>
    <author>
      <name>Theophilus C. Madueme</name>
    </author>
    <author>
      <name>Emmanuel N. Osegi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.04105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.04105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.04252v1</id>
    <updated>2015-09-14T19:29:41Z</updated>
    <published>2015-09-14T19:29:41Z</published>
    <title>Parareal convergence for 2D unsteady flow around a cylinder</title>
    <summary>  In this technical report we study the convergence of Parareal for 2D
incompressible flow around a cylinder for different viscosities. Two methods
are used as fine integrator: backward Euler and a fractional step method. It is
found that Parareal converges better for the implicit Euler, likely because it
under-resolves the fine-scale dynamics as a result of numerical diffusion.
</summary>
    <author>
      <name>Andreas Kreienbuehl</name>
    </author>
    <author>
      <name>Arne Naegel</name>
    </author>
    <author>
      <name>Daniel Ruprecht</name>
    </author>
    <author>
      <name>Andreas Vogel</name>
    </author>
    <author>
      <name>Gabriel Wittum</name>
    </author>
    <author>
      <name>Rolf Krause</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.04252v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.04252v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08410v1</id>
    <updated>2015-11-26T15:09:59Z</updated>
    <published>2015-11-26T15:09:59Z</published>
    <title>Modeling of anechoich chambers with equivalent materials and equivalent
  sources</title>
    <summary>  Numerical simulation of anechoic chambers is a hot topic since it can provide
useful data about the performance of the EMC site. However, the mathematical
nature of the problem, the physical dimensions of the simulated sites and the
frequency ranges pose nontrivial challenges to the simulation. Computational
requirements in particular will quickly become unmanageable if adequate
techniques are not employed. In this work we describe a novel approach, based
on equivalent elements, that enables the simulation of large chambers with
modest computational resources. The method is then validated against real
measurement results.
</summary>
    <author>
      <name>Silvano Chialina</name>
    </author>
    <author>
      <name>Matteo Cicuttin</name>
    </author>
    <author>
      <name>Lorenzo Codecasa</name>
    </author>
    <author>
      <name>Giovanni Solari</name>
    </author>
    <author>
      <name>Ruben Specogna</name>
    </author>
    <author>
      <name>Francesco Trevisan</name>
    </author>
    <link href="http://arxiv.org/abs/1511.08410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08920v1</id>
    <updated>2015-11-28T19:08:03Z</updated>
    <published>2015-11-28T19:08:03Z</published>
    <title>Computational Homogenization of Fresh Concrete Flow Around Reinforcing
  Bars</title>
    <summary>  Motivated by casting of fresh concrete in reinforced concrete structures, we
introduce a numerical model of a steady-state non-Newtonian fluid flow through
a porous domain. Our approach combines homogenization techniques to represent
the reinforced domain by the Darcy law with an interface coupling of the Stokes
and Darcy flows through the Beavers-Joseph-Saffman conditions. The ensuing
two-scale problem is solved by the Finite Element Method with consistent
linearization and the results obtained from the homogenization approach are
verified against fully resolved direct numerical simulations.
</summary>
    <author>
      <name>Filip Kolařík</name>
    </author>
    <author>
      <name>Bořek Patzák</name>
    </author>
    <author>
      <name>Jan Zeman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.08920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06076v1</id>
    <updated>2016-01-22T17:14:13Z</updated>
    <published>2016-01-22T17:14:13Z</published>
    <title>Liquid Humans - Pedestrian Simulator based on the LWR-model</title>
    <summary>  Dense human flow has been a concern for the safety of public events for a
long time. Macroscopic pedestrian models, which are mainly based on fluid
dynamics, are often used to simulate huge crowds due to their low computational
costs. Similar approaches are used in the field of traffic simulations. A
combined macroscopic simulation of vehicles and pedestrians is extremely
helpful for all-encompassing traffic control. Therefore, we developed a hybrid
model that contains networks for vehicular traffic and human flow. This
comprehensive model supports concurrent multi-modal simulations of traffic and
pedestrians.
</summary>
    <author>
      <name>Quirin Aumann</name>
    </author>
    <author>
      <name>Carlos M. Osorio</name>
    </author>
    <author>
      <name>Celeste Lai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages. Journal version of conference article arXiv:1511.00053</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.06076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02675v2</id>
    <updated>2016-09-09T06:20:21Z</updated>
    <published>2016-02-08T18:14:57Z</published>
    <title>Performance of 1-D and 2-D Lattice Boltzmann (LB) in Solution of the
  Shock Tube Problem</title>
    <summary>  In this paper we presented a lattice Boltzmann with square grid for
compressible flow problems. Triple level velocity is considered for each cell.
Migration step use discrete velocity but continuous parameters are utilized to
calculate density, velocity, and energy. So, we called this semi-discrete
method. To evaluate the performance of the method the well-known shock tube
problem is solved, using 1-D and 2-D version of the lattice Boltzmann method.
The results of these versions are compared with each other and with the results
of the analytical solution.
</summary>
    <author>
      <name>M. Komeili</name>
    </author>
    <author>
      <name>M. Mirzaei</name>
    </author>
    <author>
      <name>M. Shabouei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in International Conference on Fascinating Advancement in Mechanical
  Engineering (FAME2008), India, 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.02675v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02675v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02680v3</id>
    <updated>2016-09-12T07:08:25Z</updated>
    <published>2016-02-08T18:26:36Z</published>
    <title>Numerical Solution of Cylindrically Converging Shock Waves</title>
    <summary>  The cylindrically converging shock wave was numerically simulated by solving
the Euler equations in cylindrical coordinates with TVD scheme and MUSCL
approach, using Roe's approximate Riemann solver and super-bee nonlinear
limiter. The present study used the in house code developed for this purpose.
The behavior of the solution in the vicinity of axis is investigated and the
results of the numerical solution are compared with the computed data given by
Payne, Lapidus, Abarbanel, and Goldberg, Sod, and Leutioff et al.
</summary>
    <author>
      <name>M. Shabouei</name>
    </author>
    <author>
      <name>R. Ebrahimi</name>
    </author>
    <author>
      <name>K. Mazaheri Body</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Fascinating Advancement in Mechanical
  Engineering (FAME08), India, 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.02680v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02680v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05122v1</id>
    <updated>2016-04-18T12:44:39Z</updated>
    <published>2016-04-18T12:44:39Z</published>
    <title>Numerical solution of a parabolic system in air pollution</title>
    <summary>  An air pollution model is generally described by a system of PDEs on
unbounded domain. Transformation of the independent variable is used to convert
the problem for nonlinear air pollution on finite computational domain. We
investigate the new, degenerated parabolic problem in Sobolev spaces with
weights for well-posedness and positivity of the solution. Then we construct a
fitted finite volume difference scheme. Some results from computations are
presented.
</summary>
    <author>
      <name>Tatiana P. Chernogorova</name>
    </author>
    <author>
      <name>Lubin G. Vulkov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.05122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00548v1</id>
    <updated>2016-06-02T06:06:28Z</updated>
    <published>2016-06-02T06:06:28Z</published>
    <title>Large-scale Reservoir Simulations on IBM Blue Gene/Q</title>
    <summary>  This paper presents our work on simulation of large-scale reservoir models on
IBM Blue Gene/Q and studying the scalability of our parallel reservoir
simulators. An in-house black oil simulator has been implemented. It uses MPI
for communication and is capable of simulating reservoir models with hundreds
of millions of grid cells. Benchmarks show that our parallel simulator are
thousands of times faster than sequential simulators that designed for
workstations and personal computers, and the simulator has excellent
scalability.
</summary>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Kun Wang</name>
    </author>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00548v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00548v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05502v3</id>
    <updated>2018-12-03T02:40:19Z</updated>
    <published>2016-09-18T15:44:04Z</published>
    <title>Inverse Problems with Invariant Multiscale Statistics</title>
    <summary>  We propose a new approach to linear ill-posed inverse problems. Our algorithm
alternates between enforcing two constraints: the measurements and the
statistical correlation structure in some transformed space. We use a
non-linear multiscale scattering transform which discards the phase and thus
exposes strong spectral correlations otherwise hidden beneath the phase
fluctuations. As a result, both constraints may be put into effect by linear
projections in their respective spaces. We apply the algorithm to
super-resolution and tomography and show that it outperforms ad hoc convex
regularizers and stably recovers the missing spectrum.
</summary>
    <author>
      <name>Ivan Dokmanić</name>
    </author>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <author>
      <name>Maarten de Hoop</name>
    </author>
    <link href="http://arxiv.org/abs/1609.05502v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05502v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02796v1</id>
    <updated>2016-10-10T08:15:26Z</updated>
    <published>2016-10-10T08:15:26Z</published>
    <title>Modeling of Spatial Uncertainties in the Magnetic Reluctivity</title>
    <summary>  In this paper a computationally efficient approach is suggested for the
stochastic modeling of an inhomogeneous reluctivity of magnetic materials.
These materials can be part of electrical machines, such as a single phase
transformer (a benchmark example that is considered in this paper). The
approach is based on the Karhunen-Lo\`{e}ve expansion. The stochastic model is
further used to study the statistics of the self inductance of the primary coil
as a quantity of interest.
</summary>
    <author>
      <name>Radoslav Jankoski</name>
    </author>
    <author>
      <name>Ulrich Römer</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1108/COMPEL-10-2016-0438</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1108/COMPEL-10-2016-0438" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to COMPEL</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">COMPEL, Vol. 36, Issue: 4, pp.1151-1167, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.02796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H15, 65C30, 65N30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; J.2; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.10057v1</id>
    <updated>2016-10-31T18:34:36Z</updated>
    <published>2016-10-31T18:34:36Z</published>
    <title>Hydropower optimization: an industrial approach</title>
    <summary>  Nowadays hydroelectric energy is one of the best energy sources: it is
cleaner, safer and more programmable than other sources. For this reason, its
manage could not be done in an approssimative way, but advance mathematical
models must be use. In this article we consider an overview of the problem: we
introduce the problem, then we show its simplest but quite exaustive
mathematical formulation and in the end we produce numerical results under the
ipothesis that all input are deterministic.
</summary>
    <author>
      <name>Matteo Gardini</name>
    </author>
    <author>
      <name>Aurora Manicardi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.10057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.10057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.00402v1</id>
    <updated>2016-12-01T19:58:34Z</updated>
    <published>2016-12-01T19:58:34Z</published>
    <title>Reduced Order Models for Pricing European and American Options under
  Stochastic Volatility and Jump-Diffusion Models</title>
    <summary>  European options can be priced by solving parabolic partial(-integro)
differential equations under stochastic volatility and jump-diffusion models
like Heston, Merton, and Bates models. American option prices can be obtained
by solving linear complementary problems (LCPs) with the same operators. A
finite difference discretization leads to a so-called full order model (FOM).
Reduced order models (ROMs) are derived employing proper orthogonal
decomposition (POD). The early exercise constraint of American options is
enforced by a penalty on subset of grid points. The presented numerical
experiments demonstrate that pricing with ROMs can be orders of magnitude
faster within a given model parameter variation range.
</summary>
    <author>
      <name>Maciej Balajewicz</name>
    </author>
    <author>
      <name>Jari Toivanen</name>
    </author>
    <link href="http://arxiv.org/abs/1612.00402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.00402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03350v1</id>
    <updated>2016-12-10T22:26:30Z</updated>
    <published>2016-12-10T22:26:30Z</published>
    <title>Non-negative Factorization of the Occurrence Tensor from Financial
  Contracts</title>
    <summary>  We propose an algorithm for the non-negative factorization of an occurrence
tensor built from heterogeneous networks. We use l0 norm to model sparse errors
over discrete values (occurrences), and use decomposed factors to model the
embedded groups of nodes. An efficient splitting method is developed to
optimize the nonconvex and nonsmooth objective. We study both synthetic
problems and a new dataset built from financial documents, resMBS.
</summary>
    <author>
      <name>Zheng Xu</name>
    </author>
    <author>
      <name>Furong Huang</name>
    </author>
    <author>
      <name>Louiqa Raschid</name>
    </author>
    <author>
      <name>Tom Goldstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS tensor workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.03350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.00394v2</id>
    <updated>2017-09-27T13:07:06Z</updated>
    <published>2017-02-01T18:57:38Z</published>
    <title>The exponentiated Hencky energy: Anisotropic extension and case studies</title>
    <summary>  In this paper we propose an anisotropic extension of the isotropic
exponentiated Hencky energy, based on logarithmic strain invariants. Unlike
other elastic formulations, the isotropic exponentiated Hencky elastic energy
has been derived solely on differential geometric grounds, involving the
geodesic distance of the deformation gradient F to the group of rotations. We
formally extend this approach towards anisotropy by defining additional
anisotropic logarithmic strain invariants with the help of suitable structural
tensors and consider our findings for selected case studies.
</summary>
    <author>
      <name>Jörg Schröder</name>
    </author>
    <author>
      <name>Markus von Hoegen</name>
    </author>
    <author>
      <name>Patrizio Neff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-017-1466-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-017-1466-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Computational Mechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.00394v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.00394v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.06708v2</id>
    <updated>2017-09-19T03:38:05Z</updated>
    <published>2017-03-20T12:30:31Z</published>
    <title>Complex Number Formulation and Convex Relaxations for Aircraft Conflict
  Resolution</title>
    <summary>  We present a novel complex number formulation along with tight convex
relaxations for the aircraft conflict resolution problem. Our approach combines
both speed and heading control and provides global optimality guarantees
despite non-convexities in the feasible region. As a side result, we present a
new characterization of the conflict separation condition in the form of
disjunctive linear constraints. Our formulation features one binary variable
per pair of aircraft, is free of trigonometric functions, and captures the
non-convexity in a set of quadratic concave constraints. Using our approach, we
are able to close a number of open instances and reduce computational time by
up to two orders of magnitude on standard instances.
</summary>
    <author>
      <name>David Rey</name>
    </author>
    <author>
      <name>Hassan Hijazi</name>
    </author>
    <link href="http://arxiv.org/abs/1703.06708v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.06708v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.06679v1</id>
    <updated>2017-04-21T18:44:55Z</updated>
    <published>2017-04-21T18:44:55Z</published>
    <title>A cost-effective isogeometric approach for composite plates based on a
  stress recovery procedure</title>
    <summary>  This paper introduces a cost-effective strategy to simulate the behavior of
laminated plates by means of isogeometric 3D solid elements. Exploiting the
high continuity of spline functions and their properties, a proper out-of-plane
stress state is recovered from a coarse displacement solution using a
post-processing step based on the enforcement of equilibrium in strong form.
Appealing results are obtained and the method is shown to be particularly
Peffective on slender composite stacks with a large number of layers.
</summary>
    <author>
      <name>John-Eric Dufour</name>
    </author>
    <author>
      <name>Pablo Antolin</name>
    </author>
    <author>
      <name>Giancarlo Sangalli</name>
    </author>
    <author>
      <name>Ferdinando Auricchio</name>
    </author>
    <author>
      <name>Alessandro Reali</name>
    </author>
    <link href="http://arxiv.org/abs/1704.06679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.06679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00819v1</id>
    <updated>2017-05-02T06:47:35Z</updated>
    <published>2017-05-02T06:47:35Z</published>
    <title>Towards an Automated Optimization of Laminated Composite Structures:
  Hierarchical Zoning Approach with Exact Blending Rules</title>
    <summary>  We present an automated methodology to optimize laminated composite
structures. Our approach, inspired by bi-level optimization scheme, avoids its
prime deficiencies and is based on developed computationally inexpensive
stacking sequences reconstruction algorithm, which identically satisfies
conventional set of blending rules. We combine it with proposed tight
approximation to feasible domain of composite integral parameters and
hierarchical zoning procedure to get highly efficient optimization methodology,
which we test in two example applications. In both cases it is shown that
blending rules compliant optimal solution remains within 10% gap from one with
no rules applied.
</summary>
    <author>
      <name>D. T. Shvarts</name>
    </author>
    <author>
      <name>F. V. Gubarev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.00819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07024v1</id>
    <updated>2017-05-19T14:41:56Z</updated>
    <published>2017-05-19T14:41:56Z</published>
    <title>Optimal prevention with possibilistic and mixed background risk</title>
    <summary>  In this paper the effect of posibilistic or mixed background risk on the
level of optimal prevention is studied. In the framework of five purely
possibilistic or mixed models, necessary and sufficient conditions are found
such that the level of optimal saving decreases or increases as a result of the
actions of various types of background risk. This way our results complete
those obtained by Courbage and Rey for some prevention models with
probabilistic background risk.
</summary>
    <author>
      <name>Irina Georgescu</name>
    </author>
    <author>
      <name>Ana Maria Lucia Casademunt</name>
    </author>
    <link href="http://arxiv.org/abs/1705.07024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08173v1</id>
    <updated>2017-05-23T10:46:25Z</updated>
    <published>2017-05-23T10:46:25Z</published>
    <title>Multilevel Monte Carlo Simulation of the Eddy Current Problem With
  Random Parameters</title>
    <summary>  The multilevel Monte Carlo method is applied to an academic example in the
field of electromagnetism. The method exhibits a reduced variance by assigning
the samples to multiple models with a varying spatial resolution. For the given
example it is found that the main costs of the method are spent on the coarsest
level.
</summary>
    <author>
      <name>Armin Galetzka</name>
    </author>
    <author>
      <name>Zeger Bontinck</name>
    </author>
    <author>
      <name>Ulrich Römer</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.23919/ROPACES.2017.7916062</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.23919/ROPACES.2017.7916062" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Computational Electromagnetics Society Symposium - Italy
  (ACES), 2017 International, http://ieeexplore.ieee.org/document/7916062/</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.08173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04449v2</id>
    <updated>2018-04-24T07:29:53Z</updated>
    <published>2017-06-09T13:03:41Z</published>
    <title>Damage detection in a unidimensional truss using the firefly
  optimization algorithm and finite elements</title>
    <summary>  In this paper, we investigate the damage detection of structures seen as an
optimization problem, using modal characterization to evaluate the dynamic
response of the structure given a damage model. We implemented the firefly
optimization algorithm with a simple numerical damage model to assess the
performance of the method and its advantages for structural health monitoring
(SHM). We show some implementation details and discuss the obtained results.
</summary>
    <author>
      <name>Camilo Manrique Escobar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIEMA</arxiv:affiliation>
    </author>
    <author>
      <name>Octavio Andrés González-Estrada</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIEMA</arxiv:affiliation>
    </author>
    <author>
      <name>Heller Guillermo Sánchez Acevedo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIEMA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PREPRINT PAPER, submitted for publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.04449v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04449v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.class-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04524v1</id>
    <updated>2017-08-08T15:29:46Z</updated>
    <published>2017-08-08T15:29:46Z</published>
    <title>ThermalSim: A Thermal Simulator for Error Analysis</title>
    <summary>  Researchers have extensively explored predictive control strategies for
controlling heating, ventilation, and air conditioning (HVAC) units in
commercial buildings. Predictive control strategies, however, critically rely
on weather and occupancy forecasts. Existing state-of-the-art building
simulators are incapable of analysing the influence of prediction errors (in
weather and occupancy) on HVAC energy consumption and occupant comfort. In this
paper, we introduce ThermalSim, a building simulator that can quantify the
effect of prediction errors on the HVAC operations. ThermalSim has been
implemented in C/C++ and MATLAB. We describe its design, use, and input format.
</summary>
    <author>
      <name>Milan Jain</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06912v1</id>
    <updated>2017-08-23T08:08:47Z</updated>
    <published>2017-08-23T08:08:47Z</published>
    <title>Tomographic Reconstruction Methods for Decomposing Directional
  Components</title>
    <summary>  Decomposition of tomographic reconstructions has many different practical
application. We propose two new reconstruction methods that combines the task
of tomographic reconstruction with object decomposition. We demonstrate these
reconstruction methods in the context of decomposing directional objects into
various directional components. Furthermore we propose a method for estimating
the main direction in a directional object, directly from the measured computed
tomography data. We demonstrate all the proposed methods on simulated and real
samples to show their practical applicability. The numerical tests show that
decomposition and reconstruction can combined to achieve a highly useful
fibre-crack decomposition.
</summary>
    <author>
      <name>Rasmus Dalgas Kongskov</name>
    </author>
    <author>
      <name>Yiqiu Dong</name>
    </author>
    <link href="http://arxiv.org/abs/1708.06912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.02513v1</id>
    <updated>2017-09-08T02:54:59Z</updated>
    <published>2017-09-08T02:54:59Z</published>
    <title>Intelligent Subset Selection of Power Generators for Economic Dispatch</title>
    <summary>  Sustainable and economical generation of electrical power is an essential and
mandatory component of infrastructure in today's world. Optimal generation
(generator subset selection) of power requires a careful evaluation of various
factors like type of source, generation, transmission &amp; storage capacities,
congestion among others which makes this a difficult task. We created a grid to
simulate various conditions including stimuli like generator supply, weather
and load demand using Siemens PSS/E software and this data is trained using
deep learning methods and subsequently tested. The results are highly
encouraging. As per our knowledge, this is the first paper to propose a working
and scalable deep learning model for this problem.
</summary>
    <author>
      <name>Biswarup Bhattacharya</name>
    </author>
    <author>
      <name>Abhishek Sinha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.02513v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.02513v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07068v1</id>
    <updated>2017-09-20T20:12:41Z</updated>
    <published>2017-09-20T20:12:41Z</published>
    <title>Survey on Semi-Explicit Time Integration of Eddy Current Problems</title>
    <summary>  The spatial discretization of the magnetic vector potential formulation of
magnetoquasistatic field problems results in an infinitely stiff
differential-algebraic equation system. It is transformed into a finitely stiff
ordinary differential equation system by applying a generalized Schur
complement. Applying the explicit Euler time integration scheme to this system
results in a small maximum stable time step size. Fast computations are
required in every time step to yield an acceptable overall simulation time.
Several acceleration methods are presented.
</summary>
    <author>
      <name>Jennifer Dutiné</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by the SCEE 2016 proceedings to be published in the Springer
  Series "Mathematics in Industry"</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.07068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L80, 65N30, 78M10, 78A30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10069v1</id>
    <updated>2017-09-28T17:19:50Z</updated>
    <published>2017-09-28T17:19:50Z</published>
    <title>An Extended Analytic Model for the Heating of Bondwires</title>
    <summary>  We present an extended analytic formula for the calculation of the
temperature profile along a bondwire embedded in a package. The resulting
closed formula is built by coupling the heat transfer equations of the bondwire
and the surrounding moulding compound by means of auxiliary variables that stem
from an \emph{ad-hoc} linearisation and mediate the wire-mould thermal
interaction. The model, which corrects typical simplifications in previously
introduced analytic models, is also optimised against carefully taken
experimental samples representing fusing events of bondwires within real
packages.
</summary>
    <author>
      <name>David Duque</name>
    </author>
    <author>
      <name>Tomas Gotthans</name>
    </author>
    <author>
      <name>Renaud Gillon</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/1709.10069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="78A30, 94C12, 80A20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.03803v1</id>
    <updated>2017-10-10T20:10:05Z</updated>
    <published>2017-10-10T20:10:05Z</published>
    <title>Day-Ahead Solar Forecasting Based on Multi-level Solar Measurements</title>
    <summary>  The growing proliferation in solar deployment, especially at distribution
level, has made the case for power system operators to develop more accurate
solar forecasting models. This paper proposes a solar photovoltaic (PV)
generation forecasting model based on multi-level solar measurements and
utilizing a nonlinear autoregressive with exogenous input (NARX) model to
improve the training and achieve better forecasts. The proposed model consists
of four stages of data preparation, establishment of fitting model, model
training, and forecasting. The model is tested under different weather
conditions. Numerical simulations exhibit the acceptable performance of the
model when compared to forecasting results obtained from two-level and
single-level studies.
</summary>
    <author>
      <name>Mohana Alanazi</name>
    </author>
    <author>
      <name>Mohsen Mahoor</name>
    </author>
    <author>
      <name>Amin Khodaei</name>
    </author>
    <link href="http://arxiv.org/abs/1710.03803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.03803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.04859v1</id>
    <updated>2017-10-13T10:05:06Z</updated>
    <published>2017-10-13T10:05:06Z</published>
    <title>Reduced Order Modelling for the Simulation of Quenches in
  Superconducting Magnets</title>
    <summary>  This contributions discusses the simulation of magnetothermal effects in
superconducting magnets as used in particle accelerators. An iterative coupling
scheme using reduced order models between a magnetothermal partial differential
model and an electrical lumped-element circuit is demonstrated. The
multiphysics, multirate and multiscale problem requires a consistent
formulation and framework to tackle the challenging transient effects occurring
at both system and device level.
</summary>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Idoia Cortes Garcia</name>
    </author>
    <author>
      <name>Michał Maciejewski</name>
    </author>
    <author>
      <name>Bernhard Auchmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18419/opus-9334</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18419/opus-9334" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 7th GACM Colloquium on Computational Mechanics,
  11 - 13 October 2017, Stuttgart, Germany</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1710.04859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.04859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N30, 78M12, 80M10, 94C12" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.05781v1</id>
    <updated>2017-10-16T15:24:12Z</updated>
    <published>2017-10-16T15:24:12Z</published>
    <title>A Fast Tree Algorithm for Electric Field Calculation in Electrical
  Discharge Simulations</title>
    <summary>  The simulation of electrical discharges has been attracting a great deal of
attention. In such simulations, the electric field computation dominates the
computational time. In this paper, we propose a fast tree algorithm that helps
to reduce the time complexity from $O(N^2)$ (from using direct summation) to
$O(N\log N)$. The implementation details are discussed and the time complexity
is analyzed. A rigorous error estimation shows the error of the tree algorithm
decays exponentially with the number of truncation terms and can be controlled
adaptively. Numerical examples are presented to validate the accuracy and
efficiency of the algorithm.
</summary>
    <author>
      <name>Chijie Zhuang</name>
    </author>
    <author>
      <name>Yong Zhang</name>
    </author>
    <author>
      <name>Xin Zhou</name>
    </author>
    <author>
      <name>Rong Zeng</name>
    </author>
    <author>
      <name>Jinliang He</name>
    </author>
    <author>
      <name>Lei Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2017.2756991</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2017.2756991" rel="related"/>
    <link href="http://arxiv.org/abs/1710.05781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.05781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.08337v1</id>
    <updated>2017-10-15T21:27:18Z</updated>
    <published>2017-10-15T21:27:18Z</published>
    <title>A Unified Spectral Method for FPDEs with Two-sided Derivatives;
  Stability, and Error Analysis</title>
    <summary>  We present the stability and error analysis of the unified Petrov-Galerkin
spectral method, developed in \cite{samiee2017Unified}, for linear fractional
partial differential equations with two-sided derivatives and constant
coefficients in any ($1+d$)-dimensional space-time hypercube, $d = 1, 2, 3,
\cdots$, subject to homogeneous Dirichlet initial/boundary conditions.
Specifically, we prove the existence and uniqueness of the weak form and
perform the corresponding stability and error analysis of the proposed method.
Finally, we perform several numerical simulations to compare the theoretical
and computational rates of convergence.
</summary>
    <author>
      <name>Mehdi Samiee</name>
    </author>
    <author>
      <name>Mohsen Zayernouri</name>
    </author>
    <author>
      <name>Mark M. Meerschaert</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2018.07.041</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2018.07.041" rel="related"/>
    <link href="http://arxiv.org/abs/1710.08337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.08337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.03599v1</id>
    <updated>2017-12-10T22:24:02Z</updated>
    <published>2017-12-10T22:24:02Z</published>
    <title>Shape optimization in laminar flow with a label-guided variational
  autoencoder</title>
    <summary>  Computational design optimization in fluid dynamics usually requires to solve
non-linear partial differential equations numerically. In this work, we explore
a Bayesian optimization approach to minimize an object's drag coefficient in
laminar flow based on predicting drag directly from the object shape. Jointly
training an architecture combining a variational autoencoder mapping shapes to
latent representations and Gaussian process regression allows us to generate
improved shapes in the two dimensional case we consider.
</summary>
    <author>
      <name>Stephan Eismann</name>
    </author>
    <author>
      <name>Stefan Bartzsch</name>
    </author>
    <author>
      <name>Stefano Ermon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contribution to workshop "Bayesian optimization for science and
  engineering" at NIPS 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.03599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.03599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.00500v1</id>
    <updated>2018-01-01T19:56:33Z</updated>
    <published>2018-01-01T19:56:33Z</published>
    <title>Chance-Constrained Outage Scheduling using a Machine Learning Proxy</title>
    <summary>  Outage scheduling aims at defining, over a horizon of several months to
years, when different components needing maintenance should be taken out of
operation. Its objective is to minimize operation-cost expectation while
satisfying reliability-related constraints. We propose a distributed
scenario-based chance-constrained optimization formulation for this problem. To
tackle tractability issues arising in large networks, we use machine learning
to build a proxy for predicting outcomes of power system operation processes in
this context. On the IEEE-RTS79 and IEEE-RTS96 networks, our solution obtains
cheaper and more reliable plans than other candidates.
</summary>
    <author>
      <name>Gal Dalal</name>
    </author>
    <author>
      <name>Elad Gilboa</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <author>
      <name>Louis Wehenkel</name>
    </author>
    <link href="http://arxiv.org/abs/1801.00500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.00500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.00718v3</id>
    <updated>2020-03-26T08:54:35Z</updated>
    <published>2018-01-02T16:44:08Z</published>
    <title>Selective review of offline change point detection methods</title>
    <summary>  This article presents a selective survey of algorithms for the offline
detection of multiple change points in multivariate time series. A general yet
structuring methodological strategy is adopted to organize this vast body of
work. More precisely, detection algorithms considered in this review are
characterized by three elements: a cost function, a search method and a
constraint on the number of changes. Each of those elements is described,
reviewed and discussed separately. Implementations of the main algorithms
described in this article are provided within a Python package called ruptures.
</summary>
    <author>
      <name>Charles Truong</name>
    </author>
    <author>
      <name>Laurent Oudre</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.sigpro.2019.107299</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.sigpro.2019.107299" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal Processing, 167:107299, 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1801.00718v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.00718v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.04828v1</id>
    <updated>2018-01-15T14:48:52Z</updated>
    <published>2018-01-15T14:48:52Z</published>
    <title>Uncertainty Quantification For A Permanent Magnet Synchronous Machine
  With Dynamic Rotor Eccentricity</title>
    <summary>  The influence of dynamic eccentricity on the harmonic spectrum of the torque
of a permanent magnet synchronous machine is studied. The spectrum is
calculated by an energy balance method. Uncertainty quantification is applied
by using generalized Polynomial Chaos and Monte Carlo. It is found that the
displacement of the rotor impacts the spectrum of the torque the most.
</summary>
    <author>
      <name>Zeger Bontinck</name>
    </author>
    <author>
      <name>Oliver Lass</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-63082-3_77</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-63082-3_77" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Progress in Industrial Mathematics at ECMI 2016. Mathematics in
  Industry, vol 26. Springer</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1801.04828v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.04828v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08040v2</id>
    <updated>2018-08-03T22:02:25Z</updated>
    <published>2018-02-22T13:47:46Z</published>
    <title>Inverse analysis of traction-separation relationship based on
  sequentially linear approach</title>
    <summary>  Traction-separation relationship is an important material characteristic
describing the fracture behaviour of quasi-brittle solids. A new numerical
scheme for identification of the traction-separation relation by inverse
analysis of data obtained from various types of fracture tests is proposed. Due
to employing the concept of sequentially linear analysis, the method exhibits a
superior numerical stability and versatility. The applicability and
effectiveness of the proposed method is demonstrated on examples involving
identification of the traction-separation relationship using experimental data
from various test configurations.
</summary>
    <author>
      <name>Jan Vorel</name>
    </author>
    <author>
      <name>Petr Kabele</name>
    </author>
    <link href="http://arxiv.org/abs/1802.08040v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08040v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.05665v1</id>
    <updated>2018-04-06T22:06:25Z</updated>
    <published>2018-04-06T22:06:25Z</published>
    <title>Optimisation of Least Squares Algorithm: A Study of Frame Based
  Programming Techniques in Horizontal Networks</title>
    <summary>  Least squares estimation, a regression technique based on minimisation of
residuals, has been invaluable in bringing the best fit solutions to parameters
in science and engineering. However, in dynamic environments such as in
Geomatics Engineering, formation of these equations can be very challenging.
And these constraints are ported and apparent in most program models, requiring
users at ease with the subject matter. This paper reviews the methods of least
squares approximation and examines a one-step automated approach, with error
analysis, through the instrumentality of frames, object oriented programming.
</summary>
    <author>
      <name>C. P. E. Agbachi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22315373/IJMTT-V37P526</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22315373/IJMTT-V37P526" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJMTT. V37(3):190-198 September 2016. ISSN:2231-5373</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1804.05665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.05665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.01072v1</id>
    <updated>2018-06-04T12:33:13Z</updated>
    <published>2018-06-04T12:33:13Z</published>
    <title>A rational decentralized generalized Nash equilibrium seeking for energy
  markets</title>
    <summary>  We propose a method to design a decentralized energy market which guarantees
individual rationality (IR) in expectation, in the presence of system-level
grid constraints. We formulate the market as a welfare maximization problem
subject to IR constraints, and we make use of Lagrangian duality to model the
problem as a n-person non-cooperative game with a unique generalized Nash
equilibrium (GNE). We provide a distributed algorithm which converges to the
GNE. The convergence and properties of the algorithm are investigated by means
of numerical simulations.
</summary>
    <author>
      <name>Lorenzo Nespoli</name>
    </author>
    <author>
      <name>Matteo Salani</name>
    </author>
    <author>
      <name>Vasco Medici</name>
    </author>
    <link href="http://arxiv.org/abs/1806.01072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.01072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.04351v2</id>
    <updated>2019-12-14T01:25:05Z</updated>
    <published>2018-06-12T06:22:44Z</published>
    <title>Network Subgraphs of the heterogeneous Chinese credit system</title>
    <summary>  In this study, we investigate the evolution of Chinese guarantee networks
from the angle of sub-patterns. First, we find that the mutual, 2-out-stars and
triangle sub-patterns are motifs in 2- and 3-node subgraphs. Considering the
heterogeneous financial characteristics of nodes, we find that small firms tend
to form a mutual guarantee relationship and large firms are likely to be the
guarantors in 2-out-stars sub-patterns.
</summary>
    <author>
      <name>Yingli Wang</name>
    </author>
    <author>
      <name>Qingpeng Zhang</name>
    </author>
    <author>
      <name>Xiaoguang Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1806.04351v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.04351v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.03628v1</id>
    <updated>2018-07-10T13:35:19Z</updated>
    <published>2018-07-10T13:35:19Z</published>
    <title>A Numerical Comparison of an Isogeometric and a Classical Higher-Order
  Approach to the Electric Field Integral Equation</title>
    <summary>  In this paper, we advocate a novel spline-based isogeometric approach for
boundary elements and its efficient implementation. We compare solutions
obtained by both an isogeometric approach, and a classical parametric
higher-order approach via Raviart-Thomas elements to the solution of the
electric field integral equation; i.e., the solution to an electromagnetic
scattering problem, promising high convergence orders w.r.t. pointwise error.
We discuss both, the obtained accuracy per DOF, as well as the effort required
to solve the corresponding system iteratively, on three numerical examples of
varying complexity.
</summary>
    <author>
      <name>Jürgen Dölz</name>
    </author>
    <author>
      <name>Stefan Kurz</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Felix Wolf</name>
    </author>
    <link href="http://arxiv.org/abs/1807.03628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.03628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.09688v1</id>
    <updated>2018-07-25T16:05:52Z</updated>
    <published>2018-07-25T16:05:52Z</published>
    <title>Turbulucid: A Python Package for Post-Processing of Fluid Flow
  Simulations</title>
    <summary>  A Python package for post-processing of plane two-dimensional data from
computational fluid dynamics simulations is presented. The package, called
turbulucid, provides means for scripted, reproducible analysis of large
simulation campaigns and includes routines for both data extraction and
visualization. For the former, the Visualization Toolkit (VTK) is used,
allowing for post-processing of simulations performed on unstructured meshes.
For visualization, several matplotlib-based functions for creating highly
customizable, publication-quality plots are provided. To demonstrate
turbulucid's functionality it is here applied to post-processing a simulation
of a flow over a backward-facing step. The implementation and architecture of
the package are also discussed, as well as its reuse potential.
</summary>
    <author>
      <name>Timofey Mukha</name>
    </author>
    <link href="http://arxiv.org/abs/1807.09688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.09688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10352v1</id>
    <updated>2019-01-25T22:47:52Z</updated>
    <published>2019-01-25T22:47:52Z</published>
    <title>Using adjoint CFD to quantify the impact of manufacturing variations on
  a heavy duty turbine vane</title>
    <summary>  We consider the evaluation of manufacturing variations to the aerodynamic
performace of turbine vanes using the adjoint method. The empirical data is
based on 102 white light scans from casted parts. We compare expensive
calculations by the finite disfference method with cheap adjoint calculations
and we find high correlations.
</summary>
    <author>
      <name>Alexander Liefke</name>
    </author>
    <author>
      <name>Vincent Marciniak</name>
    </author>
    <author>
      <name>Uwe Janoske</name>
    </author>
    <author>
      <name>Hanno Gottschalk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 p., 10 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">6th European Conference on Computational Mechanics (ECCM 6) 7th
  European Conference on Computational Fluid Dynamics (ECFD 7) June 2018,
  Glasgow, UK</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.10352v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10352v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.01993v1</id>
    <updated>2019-02-06T01:22:31Z</updated>
    <published>2019-02-06T01:22:31Z</published>
    <title>A Predictor-Corrector Method for Power System Variable Step Numerical
  Simulation</title>
    <summary>  This letter proposes a predictor-corrector method to strike a balance between
simulation accuracy and efficiency by appropriately tuning the numerical
integration step length of a power system time-domain simulation. Numerical
tests indicate that, by estimating the truncation error for step length tuning
based on the 2-Step Adams-Moulton method and the implicit Trapezoidal method,
the proposed method can provide much more precise results at little cost of
efficiency compared to a conventional variable step method based on Newton's
method.
</summary>
    <author>
      <name>Yiming Cai</name>
    </author>
    <author>
      <name>Junbo Zhang</name>
    </author>
    <author>
      <name>Weizhou Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1902.01993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.03949v1</id>
    <updated>2019-02-11T15:47:22Z</updated>
    <published>2019-02-11T15:47:22Z</published>
    <title>A model updating procedure to enhance structural analysis in the FE code
  NOSA-ITACA</title>
    <summary>  This paper describes the model updating procedure implemented in NOSA-ITACA,
a finite-element code for the structural analysis of masonry constructions of
historical interest. The procedure, aimed at matching experimental frequencies
and mode shapes, allows fine-tuning calculation of the free parameters in the
model. The numerical method is briefly described, and some issues related to
its robustness are addressed. The procedure is then applied to a simple case
study and two historical structures in Tuscany, the Clock Tower in Lucca and
the Maddalena bridge in Borgo a Mozzano.
</summary>
    <author>
      <name>M. Girardi</name>
    </author>
    <author>
      <name>C. Padovani</name>
    </author>
    <author>
      <name>D. Pellegrini</name>
    </author>
    <author>
      <name>L. Robol</name>
    </author>
    <link href="http://arxiv.org/abs/1902.03949v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.03949v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.13076v1</id>
    <updated>2019-05-30T14:37:33Z</updated>
    <published>2019-05-30T14:37:33Z</published>
    <title>An efficient steady-state analysis of the eddy current problem using a
  parallel-in-time algorithm</title>
    <summary>  This paper introduces a parallel-in-time algorithm for efficient steady-state
solution of the eddy current problem. Its main idea is based on the application
of the well-known multi-harmonic (or harmonic balance) approach as the coarse
solver within the periodic parallel-in-time framework. A frequency domain
representation allows for the separate calculation of each harmonic component
in parallel and therefore accelerates the solution of the time-periodic system.
The presented approach is verified for a nonlinear coaxial cable model.
</summary>
    <author>
      <name>Iryna Kulchytska-Ruchka</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/cp.2019.0113</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/cp.2019.0113" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Tenth International Conference on Computational
  Electromagnetics (CEM 2019), Edinburgh, UK</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.13076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01106v1</id>
    <updated>2019-06-28T10:10:11Z</updated>
    <published>2019-06-28T10:10:11Z</published>
    <title>An efficient method to solve the mathematical model of HIV infection for
  CD8+ T-cells</title>
    <summary>  In this paper, the mathematical model of HIV infection for CD8+ T-cells is
illustrated. The homotopy analysis method and the Laplace transformations are
combined for solving this model. Also, the convergence theorem is proved to
demonstrate the abilities of presented method for solving non-linear
mathematical models. The numerical results for N = 5, 10 are presented. Several
h-curves are plotted to show the convergence regions of solutions. The plots of
residual error functions indicate the precision of presented method.
</summary>
    <author>
      <name>Samad Noeiaghdam</name>
    </author>
    <author>
      <name>Emran Khoshrouye Ghiasi</name>
    </author>
    <link href="http://arxiv.org/abs/1907.01106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.12980v1</id>
    <updated>2019-07-30T14:26:26Z</updated>
    <published>2019-07-30T14:26:26Z</published>
    <title>Forecasting Short-term Dynamics of Fair-Weather Cumuli using Dynamic
  Mode Decomposition</title>
    <summary>  Application of Dynamic Mode Decomposition to clear-sky index forecasting of
shadowing effects of convective fair-weather cumulus clouds is presented. Cloud
dynamics are captured by sequences of visible-light photographic video frames.
This method can be more easily applied to the modeling of cloud evolution than
traditional fluid-based methods, and can enhance existing frozen-cloud
advection methods. Its use is demonstrated for an actual fair-weather cumulus
cloud image sequence and compared to an advection-only forecast. It is
concluded that the method shows promise for very short-term clear-sky index
forecasting for up to seven minute horizons.
</summary>
    <author>
      <name>Jeff Manning</name>
    </author>
    <author>
      <name>Ross Baldick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Z05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06009v2</id>
    <updated>2020-03-17T20:19:02Z</updated>
    <published>2019-08-15T15:35:07Z</published>
    <title>Shape Optimization of Rotating Electric Machines using Isogeometric
  Analysis and Harmonic Stator-Rotor Coupling</title>
    <summary>  This work deals with shape optimization of electric machines using
isogeometric analysis. Isogeometric analysis is particularly well suited for
shape optimization as it allows to easily modify the geometry without remeshing
the domain. A 6-pole permanent magnet synchronous machine is modeled using a
multipatch isogeometric approach and rotation of the machine is realized by
modeling the stator and rotor domain separately and coupling them at the
interface using harmonic basis functions. Shape optimization is applied to the
model minimizing the total harmonic distortion of the electromotive force as a
goal functional.
</summary>
    <author>
      <name>Melina Merkel</name>
    </author>
    <author>
      <name>Peter Gangl</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TEC.2021.3061271</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TEC.2021.3061271" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Energy Conversion, February 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.06009v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06009v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11852v1</id>
    <updated>2019-08-24T08:08:22Z</updated>
    <published>2019-08-24T08:08:22Z</published>
    <title>New stable method to solve heat conduction problems in extremely large
  systems</title>
    <summary>  We present a new explicit and stable numerical algorithm to solve the
homogeneous heat equation. We illustrate the performance of the new method in
the cases of two 2D systems with highly inhomogeneous random parameters.
Spatial discretization of these problems results in huge and stiff ordinary
differential equation systems, which can be solved by our novel method faster
than by explicit or the commonly used implicit methods.
</summary>
    <author>
      <name>Endre Kovács</name>
    </author>
    <author>
      <name>András Gilicz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Design of Machines and Structures, Vol. 8, No. 2, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.11852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.04875v1</id>
    <updated>2019-11-12T14:15:56Z</updated>
    <published>2019-11-12T14:15:56Z</published>
    <title>Spectrally accurate Ewald summation for the Yukawa potential in two
  dimensions</title>
    <summary>  An Ewald decomposition of the two-dimensional Yukawa potential and its
derivative is presented for both the periodic and the free-space case. These
modified Bessel functions of the second kind of zeroth and first degrees are
used e.g. when solving the modified Helmholtz equation using a boundary
integral method. The spectral Ewald method is used to compute arising sums at
O(N log N) cost for N source and target points. To facilitate parameter
selection, truncation-error estimates are developed for both the real-space sum
and the Fourier-space sum, and are shown to estimate the errors well.
</summary>
    <author>
      <name>Sara Pålsson</name>
    </author>
    <author>
      <name>Anna-Karin Tornberg</name>
    </author>
    <link href="http://arxiv.org/abs/1911.04875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.09548v1</id>
    <updated>2019-11-21T15:43:40Z</updated>
    <published>2019-11-21T15:43:40Z</published>
    <title>A parallel space-time multigrid method for the eddy-current equation</title>
    <summary>  We expand the applicabilities and capabilities of an already existing
space-time parallel method based on a block Jacobi smoother. First we formulate
a more detailed criterion for spatial coarsening, which enables the method to
deal with unstructured meshes and varying material parameters. Further we
investigate the application to the eddy-current equation, where the non-trivial
kernel of the curl operator causes severe problems. This is remedied with a new
nodal auxiliary space correction. We proceed to identify convergence rates by
local Fourier analysis and numerical experiments. Finally, we present a
numerical experiment which demonstrates its excellent scaling properties.
</summary>
    <author>
      <name>Martin Neumüller</name>
    </author>
    <author>
      <name>Martin Schwalsberger</name>
    </author>
    <link href="http://arxiv.org/abs/1911.09548v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09548v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.10725v2</id>
    <updated>2019-12-11T08:17:07Z</updated>
    <published>2019-11-25T06:50:09Z</published>
    <title>Analyzing Insect-Plant Predation Data By Bayesian Nonparametrics</title>
    <summary>  In the prospect of ecology and biology, studying insect-plant predation will
considerably contribute to pest control, benefit agriculture and afforestation,
and also help people to better understand insect-plant co-evolution. Therefore,
we are motivated to do two work in this study. The first part is to cluster the
insect-plant predation, in such manner, unobserved predation could be
estimated. The second part is to explore the connection between predation and
bio-taxonomy, and we find insects get more divergence than plants during the
insect-plant co-evolution.
</summary>
    <author>
      <name>Fan Yang</name>
    </author>
    <author>
      <name>Takatomi Kubo</name>
    </author>
    <author>
      <name>Kazushi Ikeda</name>
    </author>
    <link href="http://arxiv.org/abs/1911.10725v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.10725v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.10835v2</id>
    <updated>2021-07-27T21:55:25Z</updated>
    <published>2019-12-19T09:22:13Z</published>
    <title>A simple framework for arriving at bounds on effective moduli in
  heterogeneous anisotropic poroelastic solids</title>
    <summary>  The concepts of representative volume element (RVE), statistical homogeneity
and homogeneous boundary conditions are invoked to arrive at bounds on
effective moduli for heterogeneous anisotropic poroelastic solids. The
homogeneous displacement boundary condition applicable to linear elasticity is
replaced by a homogeneous displacement-pressure boundary condition to arrive at
an upper bound within the RVE while the homogeneous traction boundary condition
applicable to linear elasticity is replaced by a homogeneous traction-fluid
content boundary condition to arrive at a lower bound within the RVE.
Statistical homogeneity is then invoked to argue that the bounds obtained over
the RVE are representative of the bounds obtained over the whole heterogeneous
poroelastic solid.
</summary>
    <author>
      <name>Saumik Dana</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10835v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10835v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05018v1</id>
    <updated>2020-02-11T18:01:56Z</updated>
    <published>2020-02-11T18:01:56Z</published>
    <title>Direct Domain Decomposition Method (D3M) for Finite Element
  Electromagnetic Computations</title>
    <summary>  An exact arithmetic, memory efficient direct solution method for finite
element method (FEM) computations is outlined. Unlike conventional black-box or
low-rank direct solvers that are opaque to the underlying physical problem, the
proposed method leverages physical insights at every stage of the development
through a new symmetric domain decomposition method (DDM) with one set of
Lagrange multipliers. Comparisons with state-of-the-art exact direct solvers on
electrically large problems suggest up to 10 times less memory and better
run-time complexity while maintaining the same accuracy.
</summary>
    <author>
      <name>Javad Moshfegh</name>
    </author>
    <author>
      <name>Marinos N. Vouvakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 3 figures, 2016 IEEE APS/URSI</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In 2016 IEEE International Symposium on Antennas and Propagation
  (APSURSI) (pp. 1127-1128). IEEE</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.05018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.13201v1</id>
    <updated>2020-04-27T22:44:33Z</updated>
    <published>2020-04-27T22:44:33Z</published>
    <title>A linearised consistent mixed displacement-pressure formulation for
  hyperelasticity</title>
    <summary>  We propose a novel mixed displacement-pressure formulation based on an energy
functional that takes into account the relation between the pressure and the
volumetric energy function. We demonstrate that the proposed two-field mixed
displacement-pressure formulation is not only applicable for nearly and truly
incompressible cases but also is consistent in the compressible regime.
Furthermore, we prove with analytical derivation and numerical results that the
proposed two-field formulation is a simplified and efficient alternative for
the three-field displacement-pressure-Jacobian formulation for hyperelastic
materials whose strain energy density functions are decomposed into deviatoric
and volumetric parts.
</summary>
    <author>
      <name>Chennakesava Kadapa</name>
    </author>
    <author>
      <name>Mokarram Hossain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Mechanics of Advanced Materials and
  Structures</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.13201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.13201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.15911v1</id>
    <updated>2020-06-29T10:02:15Z</updated>
    <published>2020-06-29T10:02:15Z</published>
    <title>Parametric Modeling of EEG by Mono-Component Non-Stationary Signal</title>
    <summary>  In this paper, we propose a novel approach for parametric modeling of
electroencephalographic (EEG) signals. It is demonstrated that the EEG signal
is a mono-component non-stationary signal whose amplitude and phase (frequency)
can be expressed as functions of time. We present detailed strategy for
estimation of the parameters of the proposed model with high accuracy.
Simulation study illustrates the procedure of model fitting. Some
interpretation of the characteristic features of the model is described.
</summary>
    <author>
      <name>Pradip Sircar</name>
    </author>
    <author>
      <name>Rakesh Kumar Sharma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 1 table, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.15911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.15911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94-10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1; H.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.16919v1</id>
    <updated>2020-06-26T22:13:17Z</updated>
    <published>2020-06-26T22:13:17Z</published>
    <title>Spiral capacitor calculation using FEniCS</title>
    <summary>  The paper shows how to optimize a water level sensor consisting of a cylinder
with spiraling metal stripes on the side, using a powerful Python library
FEniCS. It is shown how to reduce a 3D Laplace equation to a 2D, using a
spiraling coordinate system; how to specify the correct boundary conditions for
an open region; how to convert the partial differential equation to a
variational form for FEniCS; and how to calculate the capacitance. Then the
FEniCS code is shown that solves the Laplace equation and calculates the
capacitance. The further numeric experiments show that there is an optimal
combination of the spiral frequency and the width of the stripes that maximizes
the sensitivity of the sensor. The Python code is given to calculate the
optimum.
</summary>
    <author>
      <name>Slava Andrejev</name>
    </author>
    <link href="http://arxiv.org/abs/2006.16919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.16919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.05066v1</id>
    <updated>2020-07-08T06:42:21Z</updated>
    <published>2020-07-08T06:42:21Z</published>
    <title>Non-local modeling with asymptotic expansion homogenization of random
  materials</title>
    <summary>  The aim of this study is to build a non-local homogenized model for
three-dimensional composites with inclusions randomly embedded within a matrix
according to a stochastic point process w in a bounded open set associated with
a suitable probability space). Both phases were linear elastic. Asymptotic
expansion homogenization (AEH) was revisited by taking into account the
stochastic parameter representing the inclusion centers distribution. The
macroscopic behavior was then studied by combining the variational approach
with the mean-ergodicity.
</summary>
    <author>
      <name>Sami Ben Elhaj Salah</name>
    </author>
    <author>
      <name>Azdine Nait-Ali</name>
    </author>
    <author>
      <name>Mikael Gueguen</name>
    </author>
    <author>
      <name>Carole Nadot-Martin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.mechmat.2020.103459</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.mechmat.2020.103459" rel="related"/>
    <link href="http://arxiv.org/abs/2007.05066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.05066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.11566v1</id>
    <updated>2020-07-22T17:44:11Z</updated>
    <published>2020-07-22T17:44:11Z</published>
    <title>Towards a Better Modelling of the Cell Formation Problem: An Overview of
  Decisions and a Critical analysis of Constraints and Objectives</title>
    <summary>  Cell formation problem is among the first obstacles the designer of cellular
production systems must overcome. This paper presents a critical analysis of
the various criteria and constraints considered in the literature. The
objective is to help any researcher who wants to model the problem by adopting
a multi-criteria approach.
</summary>
    <author>
      <name>Menouar Boulif</name>
    </author>
    <author>
      <name>Karim Atif</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures, 1 table, almost integral translation of the
  paper: Boulif, Menouar, and Karim Atif., Pour une meilleure modelisation du
  probleme de composition de cellules: expose des decisions et analyse critique
  des contraintes et des criteres. First International Conference on Industrial
  Engineering \&amp; Manufacturing (ICIEM) Batna, Algeria (2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.11566v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.11566v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C26" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; J.6.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.13881v1</id>
    <updated>2020-07-14T17:12:01Z</updated>
    <published>2020-07-14T17:12:01Z</published>
    <title>iESC: iterative Equivalent Surface Current Approximation</title>
    <summary>  A novel iterative Equivalent Surface Current (iESC) algorithm has been
developed to simulate the electromagnetic scattering of electrically large
dielectric objects with relatively smooth surfaces. The iESC algorithm corrects
the surface currents to compensate for the electromagnetic field deviation
across the dielectric surface. Numerically validation has been performed with a
dielectric sphere to show the performance of the iESC algorithm. The
experimental result shows that it takes only a few iterations for the algorithm
to increase the surface current accuracy by more than three orders of
magnitude.
</summary>
    <author>
      <name>Shaolin Liao</name>
    </author>
    <author>
      <name>Lu Ou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.13881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.13881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.01095v2</id>
    <updated>2021-08-18T13:18:21Z</updated>
    <published>2020-12-02T11:29:47Z</published>
    <title>Quantitative supply security related significance measures for gas
  reservoires</title>
    <summary>  Computational models corresponding to supply security in natural gas networks
aim to describe flows and consumption values in the case of component failures
or unforseen pipeline shutdowns. The role of natural gas reservoires in this
process has only been marginally analyzed in such models, and typically only on
the level of countries. In this paper we define a computational framework,
which is capable of interpreting real flow and reservoir data to assign a
quantitative supply security related measure to reservoires, depending on how
much the given reservoir is critical in the process of restoring consumption
outages in the network.
</summary>
    <author>
      <name>Dávid Csercsik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.01095v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.01095v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.05704v2</id>
    <updated>2021-02-10T15:02:48Z</updated>
    <published>2020-12-10T14:35:24Z</published>
    <title>The natural frequencies of masonry beams</title>
    <summary>  The present paper aims at analytically evaluating the natural frequencies of
cracked slender masonry elements. The problem is dealt with in the framework of
linear perturbation, and the small oscillations of the structure are studied
under loaded conditions, after the equilibrium for permanent loads has been
achieved. A masonry beam element made of masonry-like material is considered,
and some explicit expressions of the beam's fundamental frequency as a function
of the external loads and the amplitude of imposed deformations are derived.
The analytical results are validated via finite-element analysis.
</summary>
    <author>
      <name>Maria Girardi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00419-021-01887-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00419-021-01887-4" rel="related"/>
    <link href="http://arxiv.org/abs/2012.05704v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.05704v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.12751v1</id>
    <updated>2020-12-23T15:44:03Z</updated>
    <published>2020-12-23T15:44:03Z</published>
    <title>Optimal approximation spaces for discontinuous Petrov-Galerkin finite
  element methods</title>
    <summary>  Certain Petrov-Galerkin schemes are inherently stable formulations of
variational problems on a given mesh. This stability is primarily obtained by
computing an optimal test basis for a given approximation space. Furthermore,
these Petrov-Galerkin schemes are equipped with a robust a posteriori error
estimate which makes them an ideal candidate for mesh adaptation. One could
extend these Petrov-Galerkin schemes not only to have optimal test spaces but
also optimal approximation spaces with respect to current estimates of the
solution. These extensions are the main focus of this article. In this article,
we provide a methodology to drive mesh adaptation to produce optimal meshes for
resolving solution features and output functionals which we demonstrate through
numerical experiments.
</summary>
    <author>
      <name>Ankit Chakraborty</name>
    </author>
    <author>
      <name>Ajay Rangarajan</name>
    </author>
    <author>
      <name>Georg May</name>
    </author>
    <link href="http://arxiv.org/abs/2012.12751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.12751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.14458v1</id>
    <updated>2020-12-28T19:33:12Z</updated>
    <published>2020-12-28T19:33:12Z</published>
    <title>An efficient method for approximating resonance curves of weakly-damped
  nonlinear mechanical systems</title>
    <summary>  A method is presented for tracing the locus of a specific peak in the
frequency response under variation of a parameter. It is applicable to
periodic, steady-state vibrations of harmonically forced nonlinear mechanical
systems. It operates in the frequency domain and its central idea is to assume
a constant phase lag between forcing and response. The method is validated for
a two-degree-of-freedom oscillator with cubic spring and a bladed disk with
shroud contact. The method provides superior computational efficiency, but is
limited to weakly-damped systems. Finally, the capability to reveal isolated
solution branches is highlighted.
</summary>
    <author>
      <name>Alwin Förster</name>
    </author>
    <author>
      <name>Malte Krack</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2016.03.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2016.03.003" rel="related"/>
    <link href="http://arxiv.org/abs/2012.14458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.14458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.06298v1</id>
    <updated>2020-12-26T12:44:37Z</updated>
    <published>2020-12-26T12:44:37Z</published>
    <title>A second-order self-adjusting steepness based remapping method for
  arbitrary quadrilateral meshes</title>
    <summary>  In this paper, based on the idea of self-adjusting steepness based
schemes[5], a two-dimensional calculation method of steepness parameter is
proposed, and thus a two-dimensional self-adjusting steepness based limiter is
constructed. With the application of such limiter to the over-intersection
based remapping framework, a low dissipation remapping method has been proposed
that can be applied to the existing ALE method.
</summary>
    <author>
      <name>Zhiwei He</name>
    </author>
    <link href="http://arxiv.org/abs/2101.06298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.06298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.07548v1</id>
    <updated>2021-01-19T10:18:47Z</updated>
    <published>2021-01-19T10:18:47Z</published>
    <title>Multiobjective Multitasking Optimization Based on Decomposition with
  Dual Neighborhoods</title>
    <summary>  This paper proposes a multiobjective multitasking optimization evolutionary
algorithm based on decomposition with dual neighborhood. In our proposed
algorithm, each subproblem not only maintains a neighborhood based on the
Euclidean distance among weight vectors within its own task, but also keeps a
neighborhood with subproblems of other tasks. Gray relation analysis is used to
define neighborhood among subproblems of different tasks. In such a way,
relationship among different subproblems can be effectively exploited to guide
the search. Experimental results show that our proposed algorithm outperforms
four state-of-the-art multiobjective multitasking evolutionary algorithms and a
traditional decomposition-based multiobjective evolutionary algorithm on a set
of test problems.
</summary>
    <author>
      <name>Xianpeng Wang</name>
    </author>
    <author>
      <name>Zhiming Dong</name>
    </author>
    <author>
      <name>Lixin Tang</name>
    </author>
    <author>
      <name>Qingfu Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2101.07548v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.07548v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.06621v1</id>
    <updated>2021-04-14T04:51:38Z</updated>
    <published>2021-04-14T04:51:38Z</published>
    <title>GSEIM: A General-purpose Simulator with Explicit and Implicit Methods</title>
    <summary>  A new simulation package, GSEIM, for solving a set of ordinary differential
equations is presented. The organisation of the program is illustrated with the
help of a block diagram. Various features of GSEIM are discussed. Two ways of
incorporating new elements in GSEIM, viz., as a template and as a subcircuit,
are explained by taking a specific example. Simulation examples are described
to bring out the capabilities of GSEIM.
</summary>
    <author>
      <name>Mahesh B. Patil</name>
    </author>
    <author>
      <name>Ruchita D. Korgaonkar</name>
    </author>
    <author>
      <name>Kumar Appaiah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 25 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.06621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.06621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.09749v1</id>
    <updated>2021-04-20T04:01:58Z</updated>
    <published>2021-04-20T04:01:58Z</published>
    <title>Interpolation of Microscale Stress and Strain Fields Based on Mechanical
  Models</title>
    <summary>  In this short contribution we introduce a new procedure to recover the stress
and strain fields for particle systems by mechanical models. Numerical tests
for simple loading conditions have shown an excellent match between the
estimated values and the reference values. The estimated stress field is also
consistent with the so called Quasicontinuum stress field, which suggests its
potential application for scale bridging techniques. The estimated stress
fields for complicated loading conditions such as defect and indentation are
also demonstrated
</summary>
    <author>
      <name>Wenzhe Shan</name>
    </author>
    <author>
      <name>Udo Nackenhorst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.09749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.09749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.11156v1</id>
    <updated>2021-04-19T09:29:57Z</updated>
    <published>2021-04-19T09:29:57Z</published>
    <title>Uncertainty Quantification in Friction Model for Earthquakes using
  Bayesian inference</title>
    <summary>  This work presents a framework to inversely quantify uncertainty in the model
parameters of the friction model using earthquake data via the Bayesian
inference. The forward model is the popular rate- and state- friction (RSF)
model along with the spring slider damper idealization. The inverse model is to
determine the model parameters using the earthquake data as the response of the
RSF model. The conventional solution to the inverse problem is the
deterministic parameter values, which may not represent the true value, and
quantifying uncertainty in the model parameters increases confidence in the
estimation. The uncertainty in the model parameters is estimated by the
posterior distribution obtained through the Bayesian inversion.
</summary>
    <author>
      <name>Saumik Dana</name>
    </author>
    <author>
      <name>Karthik Reddy Lyathakula</name>
    </author>
    <link href="http://arxiv.org/abs/2104.11156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.11156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.13554v1</id>
    <updated>2021-04-28T03:30:26Z</updated>
    <published>2021-04-28T03:30:26Z</published>
    <title>Mesoscale simulation of woven composite design decisions</title>
    <summary>  Characterizing the connection between material design decisions/parameters
and their effective properties allows for accelerated materials development and
optimization. We present a global sensitivity analysis of woven composite
thermophysical properties, including density, volume fraction, thermal
conductivity, specific heat, moduli, permeability, and tortuosity, predicted
using mesoscale finite element simulations. The mesoscale simulations use
microscale approximations for the tow and matrix phases. We performed Latin
hypercube sampling of viable input parameter ranges, and the resulting
effective property distributions are analyzed using a surrogate model to
determine the correlations between material parameters and responses,
interactions between properties, and finally Sobol' indices and sensitivities.
We demonstrate that both constituent physical properties and the mesoscale
geometry strongly influence the composite material properties.
</summary>
    <author>
      <name>Lincoln N. Collins</name>
    </author>
    <author>
      <name>Scott A. Roberts</name>
    </author>
    <link href="http://arxiv.org/abs/2104.13554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.13554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.02651v1</id>
    <updated>2021-05-06T13:31:58Z</updated>
    <published>2021-05-06T13:31:58Z</published>
    <title>Technical Report: Virtual X-ray imaging for higher-order finite element
  results</title>
    <summary>  This work describes and demonstrates the operation of a virtual X-ray
algorithm operating on finite-element post-processing results which allows for
higher polynomial orders in geometry representation as well as density
distribution. A nested hierarchy of oriented bounding boxes is used for
preselecting candidate elements undergoing a ray-casting procedure. The exact
intersection points of the ray with the finite element are not computed,
instead the ray is discretized by a sequence of points. The element-local
coordinates of each discretized point are determined using a local
Newton-iteration and the resulting densities are accumulated. This procedure
results in highly accurate virtual X-ray images of finite element models.
</summary>
    <author>
      <name>Maximilian Bittens</name>
    </author>
    <link href="http://arxiv.org/abs/2105.02651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.02651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.08627v2</id>
    <updated>2021-08-19T00:20:43Z</updated>
    <published>2021-04-27T02:34:48Z</published>
    <title>SuperVoxHenry Tucker-Enhanced and FFT-Accelerated Inductance Extraction
  for Voxelized Superconducting Structures</title>
    <summary>  This paper introduces SuperVoxHenry, an inductance extraction simulator for
analyzing voxelized superconducting structures. SuperVoxHenry extends the
capabilities of the inductance extractor VoxHenry for analyzing the
superconducting structures by incorporating the following enhancements. 1.
SuperVoxHenry utilizes a two-fluid model to account for normal currents and
supercurrents. 2. SuperVoxHenry introduces the Tucker decompositions to reduce
the memory requirement of circulant tensors as well as the setup time of the
simulator. 3. SuperVoxHenry incorporates an aggregation-based algebraic
multigrid technique to obtain the sparse preconditioner.
</summary>
    <author>
      <name>Mingyu Wang</name>
    </author>
    <author>
      <name>Cheng Qian</name>
    </author>
    <author>
      <name>Enrico Di Lorenzo</name>
    </author>
    <author>
      <name>Luis J. Gomez</name>
    </author>
    <author>
      <name>Vladimir Okhmatovski</name>
    </author>
    <author>
      <name>Abdulkadir C. Yucel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TASC.2021.3105715</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TASC.2021.3105715" rel="related"/>
    <link href="http://arxiv.org/abs/2105.08627v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.08627v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.10854v1</id>
    <updated>2021-05-23T04:15:38Z</updated>
    <published>2021-05-23T04:15:38Z</published>
    <title>Projection-Based Reduced Order Model and Machine Learning Closure for
  Transient Simulations of High-Re Flows</title>
    <summary>  The paper presents a Projection-Based Reduced-Order Model for simulations of
high Reynolds turbulent flows. The PBROM are enhanced by incorporating various
models of turbulent viscosity and residual closures to model the effects of
interactions among the modes and energy dissipations. Remarkable improvements
in prediction accuracies are achieved with a suitable turbulent viscosity model
and a residual closure. The enhanced PBROM models are demonstrated for high-Re
flows past a cylinder in two- and three- dimensions. These enhancements have
shown capable of capturing complex flow features and removing unnecessary ones,
while not affecting the efficiency of the overall model.
</summary>
    <author>
      <name>My Ha Dao</name>
    </author>
    <author>
      <name>Hoang Huy Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/2105.10854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.10854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.13126v1</id>
    <updated>2021-05-26T15:38:29Z</updated>
    <published>2021-05-26T15:38:29Z</published>
    <title>An Introduction To Regret Minimization In Algorithmic Trading: A Survey
  of Universal Portfolio Techniques</title>
    <summary>  In financial investing, universal portfolios are a means of constructing
portfolios which guarantee a certain level of performance relative to a
baseline, while making no statistical assumptions about the future market data.
They fall under the broad category of regret minimization algorithms. This
document covers an introduction and survey to universal portfolio techniques,
covering some of the basic concepts and proofs in the area. Topics include:
Constant Rebalanced Portfolios, Cover's Algorithm, Incorporating Transaction
Costs, Efficient Computation of Portfolios, Including Side Information, and
Follow The Leader Algorithm.
</summary>
    <author>
      <name>Thomas Orton</name>
    </author>
    <link href="http://arxiv.org/abs/2105.13126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.13126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.14831v1</id>
    <updated>2021-05-31T09:45:02Z</updated>
    <published>2021-05-31T09:45:02Z</published>
    <title>Insights into the performance of loosely-coupled FSI schemes based on
  Robin boundary conditions</title>
    <summary>  Robin boundary conditions are a natural consequence of employing Nitsche's
method for imposing the kinematic velocity constraint at the fluid-solid
interface. Loosely-coupled FSI schemes based on Dirichlet-Robin or Robin-Robin
coupling have been demonstrated to improve the stability of such schemes with
respect to added-mass. This paper aims to offer some numerical insights into
the performance characteristics of such loosely-coupled FSI schemes based on
Robin boundary conditions. Using numerical examples, we demonstrate that the
improved stability due to the added damping term is actually at the expense of
important dynamic characteristics of the structural sub-problem.
</summary>
    <author>
      <name>Chennakesava Kadapa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2105.14831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.14831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.06343v1</id>
    <updated>2021-06-11T12:30:00Z</updated>
    <published>2021-06-11T12:30:00Z</published>
    <title>Multiscale modeling of cancellous bone considering full coupling of
  mechanical, electrical and magnetic effects</title>
    <summary>  Modeling of cancellous bone has important applications in the detection and
treatment of fatigue fractures and diseases like osteoporosis. In this paper,
we present a fully coupled multiscale approach considering mechanical,
electrical and magnetic effects by using the multiscale finite element method
and a two-phase material model on the microscale. We show numerical results for
both scales, including calculations for a femur bone, comparing a healthy bone
to ones affected by different stages of osteoporosis. Here, the magnetic field
strength resulting from a small mechanical impact decreases drastically for
later stages of the disease, confirming experimental research.
</summary>
    <author>
      <name>Mischa Blaszczyk</name>
    </author>
    <author>
      <name>Klaus Hackl</name>
    </author>
    <link href="http://arxiv.org/abs/2106.06343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.06343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.15351v1</id>
    <updated>2021-06-25T10:00:55Z</updated>
    <published>2021-06-25T10:00:55Z</published>
    <title>Spectral concepts in genome informational analysis</title>
    <summary>  The concept of k-spectrum for genomes is here investigated as a basic tool to
analyze genomes. Related spectral notions based on k-mers are introduced with
some related mathematical properties which are relevant for informational
analysis of genomes. Procedures to generate spectral segmentations of genomes
are provided and are tested (under several values of length k for k-mers) on
cases of real genomes, such as some human chromosomes and Saccharomyces
cerevisiae.
</summary>
    <author>
      <name>Vincenzo Bonnici</name>
    </author>
    <author>
      <name>Giuditta Franco</name>
    </author>
    <author>
      <name>Vincenzo Manca</name>
    </author>
    <link href="http://arxiv.org/abs/2106.15351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.15351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.03335v1</id>
    <updated>2021-09-07T21:04:51Z</updated>
    <published>2021-09-07T21:04:51Z</published>
    <title>Aerodynamic Risk Assessment using Parametric, Three-Dimensional
  Unstructured, High-Fidelity CFD and Adaptive Sampling</title>
    <summary>  We demonstrate an adaptive sampling approach for computing the probability of
a rare event for a set of three-dimensional airplane geometries under various
flight conditions. We develop a fully automated method to generate
parameterized airplanes geometries and create volumetric mesh for viscous CFD
solution. With the automatic geometry and meshing, we perform the adaptive
sampling procedure to compute the probability of the rare event. We show that
the computational cost of our adaptive sampling approach is hundreds of times
lower than a brute-force Monte Carlo method.
</summary>
    <author>
      <name>Runda Ji</name>
    </author>
    <author>
      <name>Qiqi Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2514/6.2021-2461</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2514/6.2021-2461" rel="related"/>
    <link href="http://arxiv.org/abs/2109.03335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.03335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.08419v1</id>
    <updated>2021-09-17T09:11:44Z</updated>
    <published>2021-09-17T09:11:44Z</published>
    <title>What machine learning can do for computational solid mechanics</title>
    <summary>  Machine learning has found its way into almost every area of science and
engineering, and we are only at the beginning of its exploration across fields.
Being a popular, versatile and powerful framework, machine learning has proven
most useful where classical techniques are computationally inefficient, which
applies particularly to computational solid mechanics. Here, we dare to give a
non-exhaustive overview of potential avenues for machine learning in the
numerical modeling of solids and structures and offer our (subjective)
perspective on what is yet to come.
</summary>
    <author>
      <name>Siddhant Kumar</name>
    </author>
    <author>
      <name>Dennis M. Kochmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-87312-7_27</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-87312-7_27" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.08419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.08419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.14447v1</id>
    <updated>2021-08-30T11:54:47Z</updated>
    <published>2021-08-30T11:54:47Z</published>
    <title>A phase field model for hydrogen-assisted fatigue</title>
    <summary>  We present a new theoretical and numerical phase field-based formulation for
predicting hydrogen-assisted fatigue. The coupled deformation-diffusion-damage
model presented enables predicting fatigue crack nucleation and growth for
arbitrary loading patterns and specimen geometries. The role of hydrogen in
increasing fatigue crack growth rates and decreasing the number of cycles to
failure is investigated. Our numerical experiments enable mapping the three
loading frequency regimes and naturally recover Paris law behaviour for various
hydrogen concentrations. In addition, Virtual S-N curves are obtained for both
notched and smooth samples, exhibiting a good agreement with experiments.
</summary>
    <author>
      <name>Alireza Golahmar</name>
    </author>
    <author>
      <name>Philip K. Kristensen</name>
    </author>
    <author>
      <name>Christian F. Niordson</name>
    </author>
    <author>
      <name>Emilio Martínez-Pañeda</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Fatigue (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2109.14447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.14447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.00682v1</id>
    <updated>2021-11-29T07:50:26Z</updated>
    <published>2021-11-29T07:50:26Z</published>
    <title>Quasi-3D Magneto-Thermal Quench Simulation Scheme for Superconducting
  Accelerator Magnets</title>
    <summary>  To tackle the strong multi-scale problem in the quench simulation of
superconducting accelerator magnets, this work proposes a hybrid numerical
method which uses two-dimensional first-order finite-elements in the magnet
cross-section and one-dimensional higher-order orthogonal polynomials in
longitudinal direction.
</summary>
    <author>
      <name>Laura A. M. D'Angelo</name>
    </author>
    <author>
      <name>Yvonne Späck-Leigsnering</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TASC.2022.3159302</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TASC.2022.3159302" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 8 figures, MT27 conference special issue paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.00682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.00682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.04221v1</id>
    <updated>2021-12-08T10:46:53Z</updated>
    <published>2021-12-08T10:46:53Z</published>
    <title>Survey of charging scheduling, fleet management, and location planning
  of charging stations for electrified demand-responsive transport systems:
  methodologies and recent developments</title>
    <summary>  The accelerated electrification of transport systems with EVs has brought new
challenges for charging scheduling, fleet management, and charging
infrastructure location and configuration planning. In this review, we have
provided a systematic review of the recent development in strategic, tactical,
and operational decisions for demand responsive transport system planning using
electric vehicles (EV-DRT). We have summarized recent developments in
mathematical modeling approaches and identified future research directions. A
list of existing open-access datasets, numerical test instances, and software
are provided for future research in EV-DRT and related problems.
</summary>
    <author>
      <name>Tai-Yu Ma</name>
    </author>
    <author>
      <name>Yumeng Fang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/s12544-022-00560-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/s12544-022-00560-3" rel="related"/>
    <link href="http://arxiv.org/abs/2112.04221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.04221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.14942v2</id>
    <updated>2022-03-30T17:08:49Z</updated>
    <published>2022-03-28T17:51:07Z</published>
    <title>Topology optimization under thermo-elastic buckling</title>
    <summary>  The focus of this paper is on topology optimization of continuum structures
subject to thermally induced buckling. Popular strategies for solving such
problems include Solid Isotropic Material with Penalization (SIMP) and Rational
Approximation of Material Properties (RAMP). Both methods rely on material
parameterization, and can sometimes exhibit pseudo buckling modes in regions
with low pseudo-densities. Here we consider a level-set approach that relies on
the concept of topological sensitivity. Topological sensitivity analysis for
thermo-elastic buckling is carried out via direct and adjoint formulations.
Then, an augmented Lagrangian formulation is presented that exploits these
sensitivities to solve a buckling constrained problem. Numerical experiments in
3D illustrate the robustness and efficiency of the proposed method.
</summary>
    <author>
      <name>Shiguang Deng</name>
    </author>
    <author>
      <name>Suresh Krishnan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00158-016-1611-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00158-016-1611-2" rel="related"/>
    <link href="http://arxiv.org/abs/2203.14942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.14942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.15111v2</id>
    <updated>2022-03-30T17:07:52Z</updated>
    <published>2022-03-28T21:40:21Z</published>
    <title>Multi-constrained topology optimization via the topological sensitivity</title>
    <summary>  The objective of this paper is to introduce and demonstrate a robust method
for multi-constrained topology optimization. The method is derived by combining
the topological sensitivity with the classic augmented Lagrangian formulation.
The primary advantages of the proposed method are: (1) it rests on
well-established augmented Lagrangian formulation for constrained optimization,
(2) the augmented topological level-set can be derived systematically for an
arbitrary set of loads and constraints, and (3) the level-set can be updated
efficiently. The method is illustrated through numerical experiments.
</summary>
    <author>
      <name>Shiguang Deng</name>
    </author>
    <author>
      <name>Krishnan Suresh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00158-014-1188-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00158-014-1188-6" rel="related"/>
    <link href="http://arxiv.org/abs/2203.15111v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.15111v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.15115v2</id>
    <updated>2022-03-30T17:06:52Z</updated>
    <published>2022-03-28T21:43:16Z</published>
    <title>Multi-constrained 3D topology optimization via augmented topological
  level-set</title>
    <summary>  The objective of this paper is to introduce and demonstrate a robust
methodology for solving multi-constrained 3D topology optimization problems.
The proposed methodology is a combination of the topological level-set
formulation, augmented Lagrangian algorithm, and assembly-free deflated finite
element analysis (FEA). The salient features of the proposed method include:
(1) it exploits the topological sensitivity fields that can be derived for a
variety of constraints, (2) it rests on well-established augmented Lagrangian
formulation to solve constrained problems, and (3) it overcomes the
computational challenges by employing assembly-free deflated FEA. The proposed
method is illustrated through several 3D numerical experiments.
</summary>
    <author>
      <name>Shiguang Deng</name>
    </author>
    <author>
      <name>Suresh Krishnan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2016.02.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2016.02.009" rel="related"/>
    <link href="http://arxiv.org/abs/2203.15115v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.15115v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.01503v1</id>
    <updated>2022-03-09T02:14:58Z</updated>
    <published>2022-03-09T02:14:58Z</published>
    <title>A Method for Random Packing of Spheres with Application to Bonding
  Modeling in Powder Bed 3D Printing Process</title>
    <summary>  A Matlab-based computational procedure is proposed to fill a given volume
with spheres whose radii are randomly picked from any specified probability
distribution supported by \verb|Matlab|. The general program sequence and
examples of filling a unit cube, a parallelepiped, and a concave domain between
two hemispherical surfaces, with spheres whose radii are drawn from the Weibull
and Gamma distributions, are presented. A sample application to the numerical
modeling of bond formation between particles heated by a laser beam in powder
bed 3D printing process is considered.
</summary>
    <author>
      <name>Travis J. Black</name>
    </author>
    <author>
      <name>Alexei F. Cheviakov</name>
    </author>
    <link href="http://arxiv.org/abs/2204.01503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.01503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.05117v1</id>
    <updated>2022-04-08T13:33:09Z</updated>
    <published>2022-04-08T13:33:09Z</published>
    <title>ReservoirComputing.jl: An Efficient and Modular Library for Reservoir
  Computing Models</title>
    <summary>  We introduce ReservoirComputing.jl, an open source Julia library for
reservoir computing models. The software offers a great number of algorithms
presented in the literature, and allows to expand on them with both internal
and external tools in a simple way. The implementation is highly modular, fast
and comes with a comprehensive documentation, which includes reproduced
experiments from literature. The code and documentation are hosted on Github
under an MIT license https://github.com/SciML/ReservoirComputing.jl.
</summary>
    <author>
      <name>Francesco Martinuzzi</name>
    </author>
    <author>
      <name>Chris Rackauckas</name>
    </author>
    <author>
      <name>Anas Abdelrehim</name>
    </author>
    <author>
      <name>Miguel D. Mahecha</name>
    </author>
    <author>
      <name>Karin Mora</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research 23 (2022) 1-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2204.05117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.05117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0150v2</id>
    <updated>2007-08-24T17:53:30Z</updated>
    <published>2007-05-01T18:24:52Z</published>
    <title>Comparison of Discrete and Continuous Wavelet Transforms</title>
    <summary>  In this paper we outline several points of view on the interplay between
discrete and continuous wavelet transforms; stressing both pure and applied
aspects of both. We outline some new links between the two transform
technologies based on the theory of representations of generators and
relations. By this we mean a finite system of generators which are represented
by operators in Hilbert space. We further outline how these representations
yield sub-band filter banks for signal and image processing algorithms.
</summary>
    <author>
      <name>Palle E. T. Jorgensen</name>
    </author>
    <author>
      <name>Myung-Sin Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, Springer Encyclopedia of Complexity and Systems Science,
  the full version with figures is available at
  http://www.siue.edu/~msong/Research/ency.pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.0150v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0150v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.1214v1</id>
    <updated>2007-05-09T07:08:58Z</updated>
    <published>2007-05-09T07:08:58Z</published>
    <title>Control of Complex Systems Using Bayesian Networks and Genetic Algorithm</title>
    <summary>  A method based on Bayesian neural networks and genetic algorithm is proposed
to control the fermentation process. The relationship between input and output
variables is modelled using Bayesian neural network that is trained using
hybrid Monte Carlo method. A feedback loop based on genetic algorithm is used
to change input variables so that the output variables are as close to the
desired target as possible without the loss of confidence level on the
prediction that the neural network gives. The proposed procedure is found to
reduce the distance between the desired target and measured outputs
significantly.
</summary>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.1214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.1214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.1673v1</id>
    <updated>2007-05-11T15:49:40Z</updated>
    <published>2007-05-11T15:49:40Z</published>
    <title>Using artificial intelligence for data reduction in mechanical
  engineering</title>
    <summary>  In this paper artificial neural networks and support vector machines are used
to reduce the amount of vibration data that is required to estimate the Time
Domain Average of a gear vibration signal. Two models for estimating the time
domain average of a gear vibration signal are proposed. The models are tested
on data from an accelerated gear life test rig. Experimental results indicate
that the required data for calculating the Time Domain Average of a gear
vibration signal can be reduced by up to 75% when the proposed models are
implemented.
</summary>
    <author>
      <name>L. Mdlazi</name>
    </author>
    <author>
      <name>C. J. Stander</name>
    </author>
    <author>
      <name>P. S. Heyns</name>
    </author>
    <author>
      <name>T. Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.1673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.1673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.2604v1</id>
    <updated>2007-05-17T21:20:58Z</updated>
    <published>2007-05-17T21:20:58Z</published>
    <title>Computational Intelligence for Condition Monitoring</title>
    <summary>  Condition monitoring techniques are described in this chapter. Two aspects of
condition monitoring process are considered: (1) feature extraction; and (2)
condition classification. Feature extraction methods described and implemented
are fractals, Kurtosis and Mel-frequency Cepstral Coefficients. Classification
methods described and implemented are support vector machines (SVM), hidden
Markov models (HMM), Gaussian mixture models (GMM) and extension neural
networks (ENN). The effectiveness of these features were tested using SVM, HMM,
GMM and ENN on condition monitoring of bearings and are found to give good
results.
</summary>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <author>
      <name>Christina Busisiwe Vilakazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.2604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.2604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5160v1</id>
    <updated>2013-06-21T14:49:29Z</updated>
    <published>2013-06-21T14:49:29Z</published>
    <title>Towards modelling cost and risks of infrequent events in the cargo
  screening process</title>
    <summary>  We introduce a simulation model of the port of Calais with a focus on the
operation of immigration controls. Our aim is to compare the cost and benefits
of different screening policies. Methodologically, we are trying to understand
the limits of discrete event simulation of rare events. When will they become
'too rare' for simulation to give meaningful results?
</summary>
    <author>
      <name>Galina Sherman</name>
    </author>
    <author>
      <name>David Menachof</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UK OR Society Simulation Workshop 2010 (SW10), 23-24 March,
  Worcestershire, UK, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5533v1</id>
    <updated>2013-06-24T07:53:25Z</updated>
    <published>2013-06-24T07:53:25Z</published>
    <title>Evolving Gene Regulatory Networks with Mobile DNA Mechanisms</title>
    <summary>  This paper uses a recently presented abstract, tuneable Boolean regulatory
network model extended to consider aspects of mobile DNA, such as transposons.
The significant role of mobile DNA in the evolution of natural systems is
becoming increasingly clear. This paper shows how dynamically controlling
network node connectivity and function via transposon-inspired mechanisms can
be selected for in computational intelligence tasks to give improved
performance. The designs of dynamical networks intended for implementation
within the slime mould Physarum polycephalum and for the distributed control of
a smart surface are considered.
</summary>
    <author>
      <name>Larry Bull</name>
    </author>
    <author>
      <name>Andrew Adamatzky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures. arXiv admin note: substantial text overlap with
  arXiv:1303.7220</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02328v1</id>
    <updated>2015-03-08T21:45:07Z</updated>
    <published>2015-03-08T21:45:07Z</published>
    <title>Financial Market Prediction</title>
    <summary>  Given financial data from popular sites like Yahoo and the London Exchange,
the presented paper attempts to model and predict stocks that can be considered
"good investments". Stocks are characterized by 125 features ranging from gross
domestic product to EDIBTA, and are labeled by discrepancies between stock and
market price returns. An artificial neural network (Self-Organizing Map) is
fitted to train on more than a million data points to predict "good
investments" given testing stocks from 2013 and after.
</summary>
    <author>
      <name>Mike Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.02328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06331v1</id>
    <updated>2015-03-21T17:43:28Z</updated>
    <published>2015-03-21T17:43:28Z</published>
    <title>Exploratory Data Analysis of The KelvinHelmholtz instability in Jets</title>
    <summary>  The KelvinHelmholtz (KH) instability is a fundamental wave instability that
is frequently observed in all kinds of shear layer (jets, wakes, atmospheric
air currents etc). The study of KH-instability, coherent flow structures has a
major impact in understanding the fundamentals of fluid dynamics. Therefore
there is a need for methods that can identify and analyse these structures. In
this Final assignment, we use machine-learning methods such as Proper
Orthogonal Decomposition (POD) and Dynamic Mode Decomposition (DMD) to analyse
the coherent flow structures. We used a 2D co-axial jet as our data, with
Reynolds number corresponding to Re: 10,000. Results for POD modes and DMD
modes are discussed and compared.
</summary>
    <author>
      <name>Santosh Tirunagari</name>
    </author>
    <link href="http://arxiv.org/abs/1503.06331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07122v1</id>
    <updated>2015-03-21T19:34:49Z</updated>
    <published>2015-03-21T19:34:49Z</published>
    <title>On damping created by heterogeneous yielding in the numerical analysis
  of nonlinear reinforced concrete frame elements</title>
    <summary>  In the dynamic analysis of structural engineering systems, it is common
practice to introduce damping models to reproduce experimentally observed
features. These models, for instance Rayleigh damping, account for the damping
sources in the system altogether and often lack physical basis. We report on an
alternative path for reproducing damping coming from material nonlinear
response through the consideration of the heterogeneous character of material
mechanical properties. The parameterization of that heterogeneity is performed
through a stochastic model. It is shown that such a variability creates the
patterns in the concrete cyclic response that are classically regarded as
source of damping.
</summary>
    <author>
      <name>Pierre Jehel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CEEM, MSSMat</arxiv:affiliation>
    </author>
    <author>
      <name>Régis Cottereau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MSSMat</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2015.03.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2015.03.001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers &amp; Structures, Elsevier, 2015, pp.2015.03.001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.07122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07809v1</id>
    <updated>2015-03-14T12:31:02Z</updated>
    <published>2015-03-14T12:31:02Z</published>
    <title>Numerical solution of moving plate problem with uncertain parameters</title>
    <summary>  This paper deals with uncertain parabolic fluid flow problem where the
uncertainty occurs due to the initial conditions and parameters involved in the
system. Uncertain values are considered as fuzzy and these are handled through
a recently developed method. Here the concepts of fuzzy numbers are combined
with Finite Difference Method (FDM) and then Fuzzy Finite Difference Method
(FFDM) has been proposed. The proposed FFDM has been used to solve the fluid
flow problem bounded by two parallel plates. Finally sensitivity of the fuzzy
parameters has also been analysed.
</summary>
    <author>
      <name>S. Nayak</name>
    </author>
    <author>
      <name>S. Chakraverty</name>
    </author>
    <link href="http://arxiv.org/abs/1503.07809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.06236v1</id>
    <updated>2018-05-16T10:33:33Z</updated>
    <published>2018-05-16T10:33:33Z</published>
    <title>An Analysis Scheme for Investigation of Effects of Various Parameters on
  Signals in Acoustic-Resolution Photoacoustic Microscopy of Mice Brain: a
  Simulation Study</title>
    <summary>  Photoacoustic spectral analysis is a novel tool for studying various
parameters affecting signals in Photoacoustic microscopy. But only observing
frequency components of photoacoustic signals doesn't make enough data for a
desirable analysis. Thus a hybrid time-domain and frequency-domain analysis
scheme has been proposed to investigate effects of various parameters like
depth of microscopy, laser focal spot size and contrast agent concentration on
Photoacoustic signals.
</summary>
    <author>
      <name>Hossein Ghadiri</name>
    </author>
    <author>
      <name>Mohammad Reza Fouladi</name>
    </author>
    <author>
      <name>Arman Rahmim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 12 figure, 36 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers in Biomedical Technologies 4, no. 3-4 (2018): 59-69</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1805.06236v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.06236v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.08463v1</id>
    <updated>2018-09-22T18:09:32Z</updated>
    <published>2018-09-22T18:09:32Z</published>
    <title>Co-simulation of Continuous Systems: A Tutorial</title>
    <summary>  Co-simulation consists of the theory and techniques to enable global
simulation of a coupled system via the composition of simulators. Despite the
large number of applications and growing interest in the challenges, the field
remains fragmented into multiple application domains, with limited sharing of
knowledge.
  This tutorial aims at introducing co-simulation of continuous systems,
targeted at researchers new to the field.
</summary>
    <author>
      <name>Cláudio Gomes</name>
    </author>
    <author>
      <name>Casper Thule</name>
    </author>
    <author>
      <name>Peter Gorm Larsen</name>
    </author>
    <author>
      <name>Joachim Denil</name>
    </author>
    <author>
      <name>Hans Vangheluwe</name>
    </author>
    <link href="http://arxiv.org/abs/1809.08463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.08463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.1; I.6.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.06867v2</id>
    <updated>2019-03-21T20:15:05Z</updated>
    <published>2018-12-17T16:08:59Z</published>
    <title>Proper Generalized Decomposition of Parameterized Electrothermal
  Problems Discretized by the Finite Integration Technique</title>
    <summary>  The proper generalized decomposition is applied to a static electrothermal
model subject to uncertainties. A reduced model that circumvents the curse of
dimensionality is obtained. The quadratic electrothermal coupling term is
non-standard and requires the introduction of a trilinear form. An existing
finite integration technique based solver is used to demonstrate the
opportunities and difficulties in integrating the proper generalized
decomposition in existing codes.
</summary>
    <author>
      <name>Alexander Krimm</name>
    </author>
    <author>
      <name>Thorben Casper</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Ludovic Chamoin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2019.2907223</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2019.2907223" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to IEEE Transactions on Magnetics - Conferences, to appear</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.06867v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.06867v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.12166v1</id>
    <updated>2019-06-27T00:02:09Z</updated>
    <published>2019-06-27T00:02:09Z</published>
    <title>A study on Stokes-Brinkman dimensionless model for flow in porous media</title>
    <summary>  In this work we propose a non-dimensionalization approach for the
Stokes-Brinkman model for flow in porous media. We study the effect of the
dimensionless number found, which will be denoted by A and named as Anna's
number, has on the outflow and transition between the Darcy and Stokes regime.
</summary>
    <author>
      <name>Anna Caroline Felix Santos de Jesus</name>
    </author>
    <link href="http://arxiv.org/abs/1906.12166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.12166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01776v1</id>
    <updated>2019-08-30T20:59:25Z</updated>
    <published>2019-08-30T20:59:25Z</published>
    <title>Technical Report -- Comparison of Direct Finite Element Simulation with
  Actuator Line Models and Vortex Models for Simulation of Turbulent Flow Past
  a Vertical Axis wind Turbine</title>
    <summary>  We compare three different methodologies for simulation of turbulent flow
past a vertical axis wind turbine: (i) full resolution of the turbine blades in
a Direct Finite Element Simulation (DFS), (ii) implicit representation of the
turbine blades in a 3D Actuator Line Method (ALM), and (iii) implicit
representation of the turbine blades as sources in a Vortex Model (VM). The
integrated normal force on one blade is computed for a range of azimuthal
angles, and is compared to experimental data for the different tip speed
ratios, 2.55, 3.44 and 4.09.
</summary>
    <author>
      <name>Van-Dang Nguyen</name>
    </author>
    <author>
      <name>Johan Jansson</name>
    </author>
    <author>
      <name>Anders Goude</name>
    </author>
    <author>
      <name>Johan Hoffman</name>
    </author>
    <link href="http://arxiv.org/abs/1909.01776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.10321v2</id>
    <updated>2019-11-17T07:15:46Z</updated>
    <published>2019-09-19T23:15:19Z</published>
    <title>Modeling Fluid Mixing in Microfluidic Grids</title>
    <summary>  We describe an approach for modeling fluid concentration profiles in
grid-based microfluidic chips for fluid mixing. This approach provides an
algorithm that predicts fluid concentrations at the chip outlets. Our algorithm
significantly outperforms COMSOL finite element simulations in term of runtime
while still producing results that closely approximate those of COMSOL.
</summary>
    <author>
      <name>Huong Luu</name>
    </author>
    <author>
      <name>Marek Chrobak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">- Details to the correctness argument, description of the algorithm,
  are added - Experiment results are updated</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.10321v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.10321v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03237v1</id>
    <updated>2019-12-29T19:19:57Z</updated>
    <published>2019-12-29T19:19:57Z</published>
    <title>Multi-Objective Optimisation of Damper Placement for Improved Seismic
  Response in Dynamically Similar Adjacent Buildings</title>
    <summary>  Multi-objective optimisation of damper placement in dynamically symmetric
adjacent buildings is considered with identical viscoelastic dampers used for
vibration control. First, exhaustive search is used to describe the solution
space in terms of various quantities of interest such as maximum top floor
displacement, maximum floor acceleration, base shear, and interstorey drift.
With the help of examples, it is pointed out that the Pareto fronts in these
problems contain a very small number of solutions. The effectiveness of two
commonly used multi-objective evolutionary algorithms, viz., NSGA-II and MOPSO,
is evaluated for a specific example.
</summary>
    <author>
      <name>Mahesh B. Patil</name>
    </author>
    <author>
      <name>Ramakrishna U.</name>
    </author>
    <author>
      <name>Mohan S. C</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10639v1</id>
    <updated>2020-01-28T23:38:22Z</updated>
    <published>2020-01-28T23:38:22Z</published>
    <title>Automatic weak imposition of free slip boundary conditions via Nitsche's
  method: application to nonlinear problems in geodynamics</title>
    <summary>  Imposition of free slip boundary conditions in science and engineering
simulations presents a challenge when the simulation domain is non-trivial.
Inspired by recent progress in symbolic computation of discontinuous Galerkin
finite element methods, we present a symmetric interior penalty form of
Nitsche's method to weakly impose these slip boundary conditions and present
examples of its use in the Stokes subsystem motivated by problems in
geodynamics. We compare numerical results with well established benchmark
problems. We also examine performance of the method with iterative solvers.
</summary>
    <author>
      <name>Nathan Sime</name>
    </author>
    <author>
      <name>Cian R. Wilson</name>
    </author>
    <link href="http://arxiv.org/abs/2001.10639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.04079v1</id>
    <updated>2020-07-03T18:22:23Z</updated>
    <published>2020-07-03T18:22:23Z</published>
    <title>Complexity matters: highly-accurate numerical models of coupled
  radiative-conductive heat transfer in a laser flash experiment</title>
    <summary>  Thermal diffusivity measurements of samples transmitting thermal radiation
require adjustments to the data treatment procedures in laser flash analysis.
Conventionally, an unconstrained diathermic model is used. Current results show
that the alternative coupled radiative-conductive models produce substantially
different results -- for instance, at high temperatures in oxide ceramics.
However, care must be taken to ensure accurate implementations of each
constituent computational technique. The latter are presented in this work.
</summary>
    <author>
      <name>Artem Lunev</name>
    </author>
    <author>
      <name>Vadim Zborovskii</name>
    </author>
    <author>
      <name>Teymur Aliev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijthermalsci.2020.106695</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijthermalsci.2020.106695" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 13 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2008.04079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.04079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.01347v1</id>
    <updated>2020-08-31T21:09:28Z</updated>
    <published>2020-08-31T21:09:28Z</published>
    <title>An Expedient Approach to FDTD-based Modeling of Finite Periodic
  Structures</title>
    <summary>  This paper proposes an efficient FDTD technique for determining
electromagnetic fields interacting with a finite-sized 2D and 3D periodic
structures. The technique combines periodic boundary conditions---modelling
fields away from the edges of the structure---with independent simulations of
fields near the edges of the structure. It is shown that this algorithm
efficiently determines the size of a periodic structure necessary for fields to
converge to the infinitely-periodic case. Numerical validations of the
technique illustrate the savings concomitant with the algorithm.
</summary>
    <author>
      <name>Aaron J. Kogon</name>
    </author>
    <author>
      <name>Costas D. Sarris</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMTT.2020.3045729</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMTT.2020.3045729" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 16 figures, 6 tables. This work has been submitted to the
  IEEE for possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.01347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.01347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.06627v1</id>
    <updated>2020-09-13T17:33:33Z</updated>
    <published>2020-09-13T17:33:33Z</published>
    <title>User Manual for the SU2 EQUiPS Module: Enabling Quantification of
  Uncertainty in Physics Simulations</title>
    <summary>  This document serves as the manual for using the EQUiPS (Enabling
Quantification of Uncertainty in Physics Simulations) module in SU2. The EQUiPS
module uses the Eigenspace Perturbation methodology to provide interval bounds
on Quantities of Interest (QoIs) that capture epistemic uncertainties arising
from assumptions made in RANS turbulence models. This has been implemented and
tested in SU2 for a variety of benchmark turbulence cases as well as flows of
aerodynamic interest.
</summary>
    <author>
      <name>Jayant Mukhopadhaya</name>
    </author>
    <link href="http://arxiv.org/abs/2009.06627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.06627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.10689v1</id>
    <updated>2020-09-22T17:03:38Z</updated>
    <published>2020-09-22T17:03:38Z</published>
    <title>Simulation model of spacetime with the Minkowski metric</title>
    <summary>  In this paper, we propose a simulation model of spacetime as a discrete model
of physical space. The model is based on the ideas of Stephen Wolfram and uses
non-numerical modelling. The simulation model is described as an ontology. We
use object-oriented simulation (OOS), but the model is also suitable for
agent-based simulation (ABS). We use UML2 SP (UML Scientific Profile), an
object-oriented simulation language used in scientific fields. This paper
describes several experiments that demonstrate time dilation and dynamic
relativistic effects. The reproducibility of experimental results can be
verified. We provide a link to the repository in this paper. The model is
implemented in Python.
</summary>
    <author>
      <name>Vasyliy I. Gurianov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.10689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.10689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.12879v1</id>
    <updated>2020-10-24T11:32:30Z</updated>
    <published>2020-10-24T11:32:30Z</published>
    <title>Towards Real-Time Magnetic Dosimetry Simulations for Inductive Charging
  Systems</title>
    <summary>  The exposure of a human by magneto-quasistatic fields from wireless charging
systems is to be determined from magnetic field measurements in near real-time.
This requires a fast linear equations solver for the discrete Poisson system of
the Co-Simulation Scalar Potential Finite Difference (Co-Sim. SPFD) scheme.
Here, the use of the AmgX library on NVIDIA GPUs is presented for this task. It
enables solving the equation system resulting from an ICNIRP recommended human
voxel model resolution of 2 mm in less than 0.5 seconds on a single NVIDIA
Tesla V100 GPU.
</summary>
    <author>
      <name>Norman Haussmann</name>
    </author>
    <author>
      <name>Martin Zang</name>
    </author>
    <author>
      <name>Robin Mease</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <author>
      <name>Benedikt Schmuelling</name>
    </author>
    <author>
      <name>Matthias Bolten</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1108/COMPEL-03-2021-0084</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1108/COMPEL-03-2021-0084" rel="related"/>
    <link href="http://arxiv.org/abs/2010.12879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.12879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.03075v1</id>
    <updated>2020-11-05T19:50:07Z</updated>
    <published>2020-11-05T19:50:07Z</published>
    <title>Magnetic Field Simulations Using Explicit Time Integration With Higher
  Order Schemes</title>
    <summary>  A transient magneto-quasistatic vector potential formulation involving
nonlinear material is spatially discretized using the finite element method of
first and second polynomial order. By applying a generalized Schur complement
the resulting system of differential algebraic equations is reformulated into a
system of ordinary differential equations (ODE). The ODE system is integrated
in time using the explicit Euler scheme, which is conditionally stable by a
maximum time step size. To overcome this limit, an explicit multistage
Runge-Kutta-Chebyshev time integration method of higher order is employed to
enlarge the maximum stable time step size. Both time integration methods are
compared regarding the overall computational effort.
</summary>
    <author>
      <name>Bernhard Kähne</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/2011.03075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.03075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.11593v2</id>
    <updated>2020-12-02T18:09:13Z</updated>
    <published>2020-11-23T18:11:26Z</published>
    <title>Simulating an Object-Oriented Financial System in a Functional Language</title>
    <summary>  This paper summarises a successful application of functional programming
within a commercial environment. We report on experience at Accenture's
Financial Services Solution Centre in London with simulating an object-oriented
financial system in order to assist analysis and design. The work was part of a
large IT project for an international investment bank and provides a pragmatic
case study.
</summary>
    <author>
      <name>Lee Braine</name>
    </author>
    <author>
      <name>Keith Haviland</name>
    </author>
    <author>
      <name>Owen Smith-Jaynes</name>
    </author>
    <author>
      <name>Andy Vautier</name>
    </author>
    <author>
      <name>Chris Clack</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: author list corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/2011.11593v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.11593v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.12390v1</id>
    <updated>2020-11-24T21:15:37Z</updated>
    <published>2020-11-24T21:15:37Z</published>
    <title>Anomaly Detection Model for Imbalanced Datasets</title>
    <summary>  This paper proposes a method to detect bank frauds using a mixed approach
combining a stochastic intensity model with the probability of fraud observed
on transactions. It is a dynamic unsupervised approach which is able to predict
financial frauds. The fraud prediction probability on the financial transaction
is derived as a function of the dynamic intensities. In this context, the
Kalman filter method is proposed to estimate the dynamic intensities. The
application of our methodology to financial datasets shows a better predictive
power in higher imbalanced data compared to other intensity-based models.
</summary>
    <author>
      <name>Régis Houssou</name>
    </author>
    <author>
      <name>Stephan Robert-Nicoud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2011.12390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.12390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.08819v1</id>
    <updated>2021-02-17T15:27:36Z</updated>
    <published>2021-02-17T15:27:36Z</published>
    <title>Efficient and robust numerical treatment of a gradient-enhanced damage
  model at large deformations</title>
    <summary>  The modeling of damage processes in materials constitutes an ill-posed
mathematical problem which manifests in mesh-dependent finite element results.
The loss of ellipticity of the discrete system of equations is counteracted by
regularization schemes of which the gradient enhancement of the strain energy
density is often used. In this contribution, we present an extension of the
efficient numerical treatment, which has been proposed in [1], to materials
that are subjected to large deformations. Along with the model derivation, we
present a technique for element erosion in the case of severely damaged
materials. Efficiency and robustness of our approach is demonstrated by two
numerical examples.
</summary>
    <author>
      <name>Philipp Junker</name>
    </author>
    <author>
      <name>Johannes Riesselmann</name>
    </author>
    <author>
      <name>Daniel Balzani</name>
    </author>
    <link href="http://arxiv.org/abs/2102.08819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.08819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.12999v1</id>
    <updated>2021-02-25T17:03:34Z</updated>
    <published>2021-02-25T17:03:34Z</published>
    <title>An Advection-Diffusion based Filter for Machinable Designs in Topology
  Optimization</title>
    <summary>  This paper introduces a simple formulation for topology optimization problems
ensuring manufacturability by machining. The method distinguishes itself from
existing methods by using the advection-diffusion equation with Robin boundary
conditions to perform a filtering of the design variables. The proposed
approach is less computationally expensive than the traditional methods used.
Furthermore, the approach is easy to implement on unstructured meshes and in a
distributed memory setting. Finally, the proposed approach can be performed
with few to no continuation steps in any system parameters. Applications are
demonstrated with topology optimization on unstructured meshes with up to 64
million elements and up to 29 milling tool directions.
</summary>
    <author>
      <name>Lukas Christian Høghøj</name>
    </author>
    <author>
      <name>Erik Albert Träff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2021.114488</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2021.114488" rel="related"/>
    <link href="http://arxiv.org/abs/2102.12999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.12999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.04123v2</id>
    <updated>2022-06-17T12:43:33Z</updated>
    <published>2021-07-07T09:08:25Z</published>
    <title>Efficient topology optimization using compatibility projection in
  micromechanical homogenization</title>
    <summary>  The adjoint method allows efficient calculation of the gradient with respect
to the design variables of a topology optimization problem. This method is
almost exclusively used in combination with traditional
Finite-Element-Analysis, whereas Fourier-based solvers have recently shown
large efficiency gains for homogenization problems. In this paper, we derive
the discrete adjoint method for Fourier-based solvers that employ compatibility
projection. We demonstrate the method on the optimization of composite
materials and auxetic metamaterials, where void regions are modelled with zero
stiffness.
</summary>
    <author>
      <name>Indre Jödicke</name>
    </author>
    <author>
      <name>Richard J. Leute</name>
    </author>
    <author>
      <name>Till Junge</name>
    </author>
    <author>
      <name>Lars Pastewka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.04123v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.04123v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.11737v1</id>
    <updated>2021-07-25T06:20:16Z</updated>
    <published>2021-07-25T06:20:16Z</published>
    <title>Mathematical Modeling of Heat Conduction</title>
    <summary>  This report describes a mathematical model of heat conduction. The
differential equation for heat conduction in one dimensional rod has been
derived. The explicit finite difference numerical method is used to solve this
differential equation. Then for simulation, a code was written in using python
libraries via Jupyter notebook. The simulation carried out for Aluminum, Copper
and Mild Steel rods and results were discussed.
</summary>
    <author>
      <name>Abdul Aziz Momin</name>
    </author>
    <author>
      <name>Nikhil Shende</name>
    </author>
    <author>
      <name>Abhijna Anamtatmakula</name>
    </author>
    <author>
      <name>Emily Ganguly</name>
    </author>
    <author>
      <name>Ashwin Gurbani</name>
    </author>
    <author>
      <name>Chaitanya A Joshi</name>
    </author>
    <author>
      <name>Yogesh Y Mahajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures, 3 tables, IMRSE-2021(https://www.imrse2021.com/)</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.11737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.11737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.14615v2</id>
    <updated>2021-09-29T21:59:33Z</updated>
    <published>2021-07-30T13:27:57Z</published>
    <title>Simulation-Based Optimization of High-Performance Wheel Loading</title>
    <summary>  Having smart and autonomous earthmoving in mind, we explore high-performance
wheel loading in a simulated environment. This paper introduces a wheel loader
simulator that combines contacting 3D multibody dynamics with a hybrid
continuum-particle terrain model, supporting realistic digging forces and soil
displacements at real-time performance. A total of 270,000 simulations are run
with different loading actions, pile slopes, and soil to analyze how they
affect the loading performance. The results suggest that the preferred digging
actions should preserve and exploit a steep pile slope. High digging speed
favors high productivity, while energy-efficient loading requires a lower dig
speed.
</summary>
    <author>
      <name>Koji Aoshima</name>
    </author>
    <author>
      <name>Martin Servin</name>
    </author>
    <author>
      <name>Eddie Wadbro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.14615v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.14615v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00205v1</id>
    <updated>2022-01-01T15:14:27Z</updated>
    <published>2022-01-01T15:14:27Z</published>
    <title>Some connections between higher moments portfolio optimization methods</title>
    <summary>  In this paper, different approaches to portfolio optimization having higher
moments such as skewness and kurtosis are classified so that the reader can
observe different paradigms and approaches in this field of research which is
essential for practitioners in Hedge Funds in particular. Several methods based
on different paradigms such as utility approach and multi-objective
optimization are reviewed and the advantage and disadvantageous of these ideas
are explained. Keywords: multi-objective optimization, portfolio optimization,
scalarization, utility
</summary>
    <author>
      <name>Farshad Noravesh</name>
    </author>
    <author>
      <name>Kristiaan Kerstens</name>
    </author>
    <link href="http://arxiv.org/abs/2201.00205v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00205v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.01451v1</id>
    <updated>2022-02-03T08:03:46Z</updated>
    <published>2022-02-03T08:03:46Z</published>
    <title>Topology Optimization with Tetra-kai-decahedra and Spheroidal Masks</title>
    <summary>  A novel meshing scheme, based on regular tetra-kai-decahedron, also referred
to as truncated octahedron, cells is presented for use in spatial topology
optimization. A tetra-kai-decahedron mesh ensures face connectivity between
elements thereby eliminating singular solutions from the solution space.
Various other benefits of implementing the said mesh are also highlighted, and
the corresponding finite element is introduced. Material mask overlay strategy
or MMOS, a feature based method for topology optimization is extended for use
in 3-dimensions (MMOS-3D) via the aforementioned finite element and spheroidal
negative masks. Formulation for density computation and sensitivity analysis
for gradient based optimization is developed. Examples on traditional
structural topology optimization problems are presented with detailed
discussion on efficacy of the proposed approach.
</summary>
    <author>
      <name>Nikhil Singh</name>
    </author>
    <author>
      <name>Anupam Saxena</name>
    </author>
    <link href="http://arxiv.org/abs/2202.01451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.01451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.01560v2</id>
    <updated>2022-02-04T11:47:51Z</updated>
    <published>2022-02-03T12:36:32Z</published>
    <title>Extending turbulence model uncertainty quantification using machine
  learning</title>
    <summary>  In order to achieve a more virtual design and certification process of jet
engines in aviation industry, the uncertainty bounds for computational fluid
dynamics have to be known. This work shows the application of a machine
learning methodology to quantify the epistemic uncertainties of turbulence
models. The underlying method in order to estimate the uncertainty bounds is
based on an eigenspace perturbation of the Reynolds stress tensor in
combination with random forests.
</summary>
    <author>
      <name>Marcel Matha</name>
    </author>
    <author>
      <name>Christian Morsbach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS2021 - Thirty-fifth Conference on Neural Information
  Processing Systems, Fourth Workshop on Machine Learning and the Physical
  Sciences, 5 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.01560v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.01560v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.01681v1</id>
    <updated>2021-12-22T08:10:18Z</updated>
    <published>2021-12-22T08:10:18Z</published>
    <title>Domain Decomposition in space-time of 4D-VAR Data Assimilation problem:
  a case study on the ROMS software</title>
    <summary>  Domain Decomposition of 4D-VAR Data Assimilation (DD-4DVAR) is made up of
decomposition of the spate-time domain, solution of reduced forecast model and
minimization of local 4D-VAR functionals. Relying on the existing software
implementation of ROMS software, we describe main components of DD-4D VAR DA
method, highlighting the topics that we will should address both on the
mathematical problem underlying ROMS and the MPI-based code implementation of
the ROMS-IS4DVAR formulation.
</summary>
    <author>
      <name>L. D'Amore</name>
    </author>
    <author>
      <name>R. Cacciapuoti</name>
    </author>
    <author>
      <name>A. Moore</name>
    </author>
    <link href="http://arxiv.org/abs/2202.01681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.01681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.06794v2</id>
    <updated>2024-08-23T00:51:01Z</updated>
    <published>2022-02-14T15:18:11Z</published>
    <title>Disentangle VAE for Molecular Generation</title>
    <summary>  Automatic molecule generation plays an important role on drug discovery and
has received a great deal of attention in recent years thanks to deep learning
successful use. Graph-based neural network represents state of the art methods
on automatic molecule generation. However, it is still challenging to generate
molecule with desired properties, which is a core task in drug discovery. In
this paper, we focus on this task and propose a Controllable Junction Tree
Variational Autoencoder (C JTVAE), adding an extractor module into VAE
framework to describe some properties of molecule. Our method is able to
generate similar molecular with desired property given an input molecule.
Experimental results is encouraging.
</summary>
    <author>
      <name>Yanbo Wang</name>
    </author>
    <author>
      <name>Qianqian Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The experimental setup is wrong</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.06794v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.06794v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.08596v1</id>
    <updated>2022-02-17T11:24:58Z</updated>
    <published>2022-02-17T11:24:58Z</published>
    <title>Augmented Lagrangian approach to deriving discontinuous Galerkin methods
  for nonlinear elasticity problems</title>
    <summary>  We use the augmented Lagrangian formalism to derive discontinuous Galerkin
formulations for problems in nonlinear elasticity. In elasticity stress is
typically a symmetric function of strain, leading to symmetric tangent
stiffness matrices in Newtons method when conforming finite elements are used
for discretization. By use of the augmented Lagrangian framework, we can also
obtain symmetric tangent stiffness matrices in discontinuous Galerkin methods.
We suggest two different approaches and give examples from plasticity and from
large deformation hyperelasticity.
</summary>
    <author>
      <name>Peter Hansbo</name>
    </author>
    <author>
      <name>Mats G. Larson</name>
    </author>
    <link href="http://arxiv.org/abs/2202.08596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.08596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.12186v3</id>
    <updated>2022-10-28T07:24:39Z</updated>
    <published>2022-02-24T16:39:30Z</published>
    <title>Sequential asset ranking in nonstationary time series</title>
    <summary>  We create a ranking algorithm, the naive Bayes asset ranker. Our algorithm
computes the posterior probability that individual assets will be ranked higher
than other portfolio constituents. Unlike earlier algorithms, such as the
weighted majority, our algorithm allows poor-performing experts to have
increased weight when they start performing well. We outperform the long-only
holding of the S&amp;P 500 index and a regress-then-rank baseline.
</summary>
    <author>
      <name>Gabriel Borrageiro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3533271.3561666</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3533271.3561666" rel="related"/>
    <link href="http://arxiv.org/abs/2202.12186v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.12186v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.11038v1</id>
    <updated>2022-05-23T05:03:28Z</updated>
    <published>2022-05-23T05:03:28Z</published>
    <title>Computational Approach of Designing Magnetfree Nonreciprocal
  Metamaterial</title>
    <summary>  This article aims at discussing computational approach to design magnet-free
nonreciprocal metamaterial. Detailed mathematical derivation on floquet mode
analysis is presented for Faraday and Kerr rotation. Non-reciprocity in the
designed metasurface is achieved in the presence of biased transistor loaded in
the gap of circular ring resonator. Based on the synthesized mathematical
model, We extract co-cross polarized components as well as Faraday and Kerr
rotation from the developed synthesized model and compare/contrast reciprocal
and nonreciprocal system.
</summary>
    <author>
      <name>Swadesh Poddar</name>
    </author>
    <author>
      <name>Md. Tanvir Hasan</name>
    </author>
    <author>
      <name>Md. Ragib Shakil Rafi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 figures, 10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.11038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.11038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.00994v1</id>
    <updated>2022-06-02T11:30:18Z</updated>
    <published>2022-06-02T11:30:18Z</published>
    <title>A new fluid-based strategy for the connection of non-matching lattice
  materials</title>
    <summary>  We present a new algorithm for the design of the connection region between
different lattice materials. We solve a Stokes-type topology optimization
problem on a narrow morphing region to smoothly connect two different unit
cells. The proposed procedure turns out to be effective and provides a local
re-design of the materials, leading to a very mild modification of the
mechanical behaviour characterizing the original lattices. The robustness of
the algorithm is assessed in terms of sensitivity of the final layout to
different parameters. Both the cases of Cartesian and non-Cartesian morphing
regions are successfully investigated.
</summary>
    <author>
      <name>Nicola Ferro</name>
    </author>
    <author>
      <name>Simona Perotto</name>
    </author>
    <author>
      <name>Matteo Gavazzoni</name>
    </author>
    <link href="http://arxiv.org/abs/2206.00994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.00994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.04795v1</id>
    <updated>2022-06-04T05:00:52Z</updated>
    <published>2022-06-04T05:00:52Z</published>
    <title>Precise Calculation of Electrical Capacitance by means of Quadruple
  Integrals in Method of Moments Technique</title>
    <summary>  In this paper, the capacitance of a parallel plate air-gap rectangular
capacitor, and a unit cube capacitor have been calculated. Because of its
generality and simplicity, the method of moments (MOM) Technique is utilized.
In order to improve the accuracy of the calculations, the use of quadratic
integrals instead of binary integrals has been proposed. A neat form is
provided for the analytical solution of the integrals required for the method
of moment. The results show that there is a very small error in calculating the
capacity even with coarse boundary division. The described formulas and codes
can easily be used for similar purposes.
</summary>
    <author>
      <name>Saeed Sarkarati</name>
    </author>
    <author>
      <name>Mohammad Mehdi Tehranchi</name>
    </author>
    <author>
      <name>Esfandiar Mehrshahi</name>
    </author>
    <link href="http://arxiv.org/abs/2206.04795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.04795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.06783v2</id>
    <updated>2022-09-29T08:12:27Z</updated>
    <published>2022-06-10T11:04:07Z</published>
    <title>Characteristic Mode Decomposition Using the Scattering Dyadic in
  Arbitrary Full-Wave Solvers</title>
    <summary>  Characteristic modes are formulated using the scattering dyadic, which maps
incident plane waves to scattered far fields generated by an object of
arbitrary material composition. Numerical construction of the scattering dyadic
using arbitrary full-wave electromagnetic solvers is demonstrated in examples
involving a variety of dielectric and magnetic materials. Wrapper functions for
computing characteristic modes in method-of-moments, finite-difference time
domain, and finite element solvers are provided as supplementary material.
</summary>
    <author>
      <name>Miloslav Capek</name>
    </author>
    <author>
      <name>Johan Lundgren</name>
    </author>
    <author>
      <name>Mats Gustafsson</name>
    </author>
    <author>
      <name>Kurt Schab</name>
    </author>
    <author>
      <name>Lukas Jelinek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAP.2022.3213945</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAP.2022.3213945" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 10 figures, with supplementary material (github)</arxiv:comment>
    <link href="http://arxiv.org/abs/2206.06783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.06783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.class-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.01245v1</id>
    <updated>2022-07-04T08:06:20Z</updated>
    <published>2022-07-04T08:06:20Z</published>
    <title>A Permutation-Based Heuristic for Buy Low, Sell High</title>
    <summary>  Buy low, sell high is one of the basic rules of thumb used in investment,
although it is not considered to be a beneficial strategy. In this paper, we
show how the appropriate permutation-based representation (i.e., the epistemic
form) of a minute-by-minute trading time-series, alongside the use of a simple
decision heuristic (i.e., the epistemic game), may surprisingly result in
significant benefits. Using our heuristic for selecting seven stocks, we ran
two experiments on the data. The results provide empirical support for the
possible benefit of using simple decision models in investment, even in the
context of minute-by-minute trading.
</summary>
    <author>
      <name>Yair Neuman</name>
    </author>
    <author>
      <name>Yochai Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2207.01245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.01245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91-02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.03087v1</id>
    <updated>2022-09-07T11:53:22Z</updated>
    <published>2022-09-07T11:53:22Z</published>
    <title>Autonomous Cooking with Digital Twin Methodology</title>
    <summary>  This work introduces the concept of an autonomous cooking process based on
Digital Twin method- ology. It proposes a hybrid approach of physics-based full
order simulations followed by a data-driven system identification process with
low errors. It makes faster-than-real-time simulations of Digital Twins
feasible on a device level, without the need for cloud or high-performance
computing. The concept is universally applicable to various physical processes.
</summary>
    <author>
      <name>Maximilian Kannapinn</name>
    </author>
    <author>
      <name>Michael Schäfer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.23967/wccm-eccomas.2020.074</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.23967/wccm-eccomas.2020.074" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted version of manuscript published in Proceedings of
  WCCM-ECCOMAS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.03087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.03087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.13724v1</id>
    <updated>2022-09-25T15:17:53Z</updated>
    <published>2022-09-25T15:17:53Z</published>
    <title>Stochastic projection based approach for gradient free physics informed
  learning</title>
    <summary>  We propose a stochastic projection-based gradient free physics-informed
neural network. The proposed approach, referred to as the stochastic projection
based physics informed neural network (SP-PINN), blends upscaled stochastic
projection theory with the recently proposed physics-informed neural network.
This results in a framework that is robust and can solve problems involving
complex solution domain and discontinuities. SP-PINN is a gradient-free
approach which addresses the computational bottleneck associated with automatic
differentiation in conventional PINN. Efficacy of the proposed approach is
illustrated by a number of examples involving regular domain, complex domain,
complex response and phase field based fracture mechanics problems. Case
studies by varying network architecture (activation function) and number of
collocation points have also been presented.
</summary>
    <author>
      <name>Navaneeth N</name>
    </author>
    <author>
      <name>Souvik Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/2209.13724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.13724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.00969v1</id>
    <updated>2022-10-03T14:37:10Z</updated>
    <published>2022-10-03T14:37:10Z</published>
    <title>Almost Exact Risk Budgeting with Return Forecasts for Portfolio
  Allocation</title>
    <summary>  In this paper, we revisit the portfolio allocation problem with designated
risk-budget [Qian, 2005]. We generalize the problem of arbitrary risk budgets
with unequal correlations to one that includes return forecasts and transaction
costs while keeping the no-shorting (long-only positions) constraint. We offer
a convex second order cone formulation that scales well with the number of
assets and explore solutions to the problem in different settings. In
particular, the problem is solved on a few practical cases - on equity and bond
asset allocation problems as well as formulating index constituents for the
NASDAQ100 index, illustrating the benefits of this approach.
</summary>
    <author>
      <name>Avinash Bhardwaj</name>
    </author>
    <author>
      <name>Manjesh K Hanawal</name>
    </author>
    <author>
      <name>Purushottam Parthasarathy</name>
    </author>
    <link href="http://arxiv.org/abs/2210.00969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.00969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.11983v2</id>
    <updated>2023-09-29T15:06:31Z</updated>
    <published>2022-10-21T14:18:22Z</published>
    <title>Pyrit: A Finite Element Based Field Simulation Software Written in
  Python</title>
    <summary>  Pyrit is a field simulation software based on the finite element method
written in Python to solve coupled systems of partial differential equations.
It is designed as a modular software that is easily modifiable and extendable.
The framework can, therefore, be adapted to various activities, i.e. research,
education and industry collaboration.
</summary>
    <author>
      <name>Jonas Bundschuh</name>
    </author>
    <author>
      <name>M. Greta Ruppert</name>
    </author>
    <author>
      <name>Yvonne Späck-Leigsnering</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1108/COMPEL-01-2023-0013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1108/COMPEL-01-2023-0013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures, Published in COMPEL - The international journal
  for computation and mathematics in electrical and electronic engineering.
  This preprint offers a more precise formatting and includes software parts</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.11983v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.11983v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.06905v2</id>
    <updated>2024-02-07T22:34:30Z</updated>
    <published>2022-12-13T21:15:41Z</published>
    <title>Query Time Optimized Deep Learning Based Video Inference System</title>
    <summary>  This is a project report about how we tune Focus[1], a video inference system
that provides low cost and low latency, through two phases. In this report, we
will decrease the query time by saving the middle layer output of the neural
network. This is a trade-off strategy that involves using more space to save
time. We show how this scheme works using prototype systems, and it saves 20%
of the time. The code repository URL is here, https://github.com/iphyer/CS744
FocousIngestOpt.
</summary>
    <author>
      <name>Mingren Shen</name>
    </author>
    <author>
      <name>Shuoxuan Dong</name>
    </author>
    <author>
      <name>Xiuyuan He</name>
    </author>
    <link href="http://arxiv.org/abs/2212.06905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.06905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.04595v1</id>
    <updated>2023-01-11T17:43:23Z</updated>
    <published>2023-01-11T17:43:23Z</published>
    <title>Circuit simulation using explicit methods</title>
    <summary>  Use of explicit methods for simulating electrical circuits, especially for
power electronics applications, is described. Application of the forward Euler
method to a half-wave rectifier is discussed, and the limitations of a
fixed-step method are pointed out. Implementation of the Runge-Kutta-Fehlberg
(RKF) method, which allows variable time steps, for the half-wave rectifier
circuit is discussed, and its advantages pointed out. Formulation of circuit
equations for the purpose of simulation using the RKF method is described for
some more examples. Stability and accuracy issues related to power electronic
circuits are brought out, and mechanisms to address them are presented. Future
plans related to this work are described.
</summary>
    <author>
      <name>Mahesh B. Patil</name>
    </author>
    <author>
      <name>V. V. S. Pavan Kumar Hari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 22 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2301.04595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.04595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.00313v1</id>
    <updated>2023-02-01T08:43:01Z</updated>
    <published>2023-02-01T08:43:01Z</published>
    <title>Low-Frequency Stabilization of Dielectric Simulation Problems with
  Conductors and Insulators</title>
    <summary>  When simulating resistive-capacitive circuits or electroquasistatic problems
where conductors and insulators coexist, one observes that large time steps or
low frequencies lead to numerical instabilities, which are related to the
condition number of the system matrix. Here, we propose several stable
formulations by scaling the equation systems. This enables a reliable
calculation of solutions for very low frequencies (even for the static case),
or large time steps. Numerical experiments underline the findings.
</summary>
    <author>
      <name>Devin Balian</name>
    </author>
    <author>
      <name>Melina Merkel</name>
    </author>
    <author>
      <name>Jörg Ostrowski</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/2302.00313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.00313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="78-10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.01930v1</id>
    <updated>2023-02-01T14:56:57Z</updated>
    <published>2023-02-01T14:56:57Z</published>
    <title>A phase field model for high-cycle fatigue: total-life analysis</title>
    <summary>  We present a generalised phase field formulation for predicting high-cycle
fatigue in metals. Different fatigue degradation functions are presented,
together with new damage accumulation strategies, to account for (i) a typical
S-N curve slope, (ii) the fatigue endurance limit, and (iii) the mean stress
effect. The numerical implementation exploits an efficient quasi-Newton
monolithic solution strategy and Virtual S-N curves are computed for both
smooth and notched samples. The comparison with experiments reveals that the
model can accurately predict fatigue lives and endurance limits, as well as
naturally capture the influence of the stress concentration factor and the load
ratio.
</summary>
    <author>
      <name>A. Golahmar</name>
    </author>
    <author>
      <name>C. F. Niordson</name>
    </author>
    <author>
      <name>E. Martínez-Pañeda</name>
    </author>
    <link href="http://arxiv.org/abs/2302.01930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.01930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.06445v2</id>
    <updated>2023-02-15T23:51:07Z</updated>
    <published>2023-02-13T15:22:00Z</published>
    <title>Technical Note: PDE-constrained Optimization Formulation for Tumor
  Growth Model Calibration</title>
    <summary>  We discuss solution algorithms for calibrating a tumor growth model using
imaging data posed as a deterministic inverse problem. The forward model
consists of a nonlinear and time-dependent reaction-diffusion partial
differential equation (PDE) with unknown parameters (diffusivity and
proliferation rate) being spatial fields. We use a dimension-independent
globalized, inexact Newton Conjugate Gradient algorithm to solve the
PDE-constrained optimization. The required gradient and Hessian actions are
also presented using the adjoint method and Lagrangian formalism.
</summary>
    <author>
      <name>Baoshan Liang</name>
    </author>
    <author>
      <name>Luke Lozenski</name>
    </author>
    <author>
      <name>Umberto Villa</name>
    </author>
    <author>
      <name>Danial Faghihi</name>
    </author>
    <link href="http://arxiv.org/abs/2302.06445v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.06445v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.08656v2</id>
    <updated>2023-05-06T02:24:02Z</updated>
    <published>2023-02-17T02:29:01Z</published>
    <title>Towards Efficient Alternating Current Optimal Power Flow Analysis on
  Graphical Processing Units</title>
    <summary>  We present a solution of sparse alternating current optimal power flow
(ACOPF) analysis on graphical processing unit (GPU). In particular, we discuss
the performance bottlenecks and detail our efforts to accelerate the linear
solver, a core component of ACOPF that dominates the computational time. ACOPF
analyses of two large-scale systems, synthetic Northeast (25,000 buses) and
Eastern (70,000 buses) U.S. grids [1], on GPU show promising speed-up compared
to analyses on central processing unit (CPU) using a state-of-the-art solver.
To our knowledge, this is the first result demonstrating a significant
acceleration of sparse ACOPF on GPUs.
</summary>
    <author>
      <name>Kasia Swirydowicz</name>
    </author>
    <author>
      <name>Nicholson Koukpaizan</name>
    </author>
    <author>
      <name>Shrirang Abhyankar</name>
    </author>
    <author>
      <name>Slaven Peles</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICAT57854.2023.10171317</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICAT57854.2023.10171317" rel="related"/>
    <link href="http://arxiv.org/abs/2302.08656v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.08656v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.03120v1</id>
    <updated>2023-02-22T10:42:35Z</updated>
    <published>2023-02-22T10:42:35Z</published>
    <title>High-Order Elasticity Interpolants for Microstructure Simulation</title>
    <summary>  We propose a novel formulation of elastic materials based on high-order
interpolants, which fits accurately complex elastic behaviors, but remains
conservative. The proposed high-order interpolants can be regarded as a
high-dimensional extension of radial basis functions, and they allow the
interpolation of derivatives of elastic energy, in particular stress and
stiffness. Given the proposed parameterization of elasticity models, we devise
an algorithm to find optimal model parameters based on training data. We have
tested our methodology for the homogenization of 2D microstructures, and we
show that it succeeds to match complex behaviors with high accuracy.
</summary>
    <author>
      <name>Antoine Chan-Lock</name>
    </author>
    <author>
      <name>Jesus Perez</name>
    </author>
    <author>
      <name>Miguel Otaduy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at Computer Graphics Forum (Proc. of ACM/SIGGRAPH SCA),
  2022. Project website http://mslab.es/projects/HiOInterp/</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.03120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.03120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.03401v1</id>
    <updated>2023-03-06T12:21:38Z</updated>
    <published>2023-03-06T12:21:38Z</published>
    <title>Data-driven Modified Nodal Analysis Circuit Solver</title>
    <summary>  This work introduces a novel data-driven modified nodal analysis (MNA)
circuit solver. The solver is capable of handling circuit problems featuring
elements for which solely measurement data are available. Rather than utilizing
hard-coded phenomenological model representations, the data-driven MNA solver
reformulates the circuit problem such that the solution is found by minimizing
the distance between circuit states that fulfill Kirchhoff's laws, to states
belonging to the measurement data. In this way, the previously inevitable
demand for model representations is abolished, thus avoiding the introduction
of related modeling errors and uncertainties. The proposed solver is applied to
linear and nonlinear RC-circuits and to a half-wave rectifier.
</summary>
    <author>
      <name>Armin Galetzka</name>
    </author>
    <author>
      <name>Dimitrios Loukrezis</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.03401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.03401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.07309v1</id>
    <updated>2023-03-13T17:30:52Z</updated>
    <published>2023-03-13T17:30:52Z</published>
    <title>An efficient phase-field model of shear fractures using deviatoric
  stress split</title>
    <summary>  We propose a phase-field model of shear fractures using the deviatoric stress
decomposition (DSD). This choice allows us to use general three-dimensional
Mohr-Coulomb's (MC) failure function for formulating the relations and
evaluating peak and residual stresses. We apply the model to a few benchmark
problems of shear fracture and strain localization and report remarkable
performance. Our model is able to capture conjugate failure modes under biaxial
compression test and for the slope stability problem, a challenging task for
most models of geomechanics.
</summary>
    <author>
      <name>Ehsan Haghighat</name>
    </author>
    <author>
      <name>David Santillán</name>
    </author>
    <link href="http://arxiv.org/abs/2303.07309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.07309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.00017v1</id>
    <updated>2023-03-30T14:41:39Z</updated>
    <published>2023-03-30T14:41:39Z</published>
    <title>A novel class of electro-mechanical metamaterials for stress reduction
  through electric fields</title>
    <summary>  While most previous developed metamaterials only consider a single physical
effect, we introduce a novel class of electro-mechanical metamaterials, which
allows a direct controllable reduction of the total stress by applying an
electric field counteracting the mechanical stress. The solution of the
resulting minimization problem yields a relation involving the eigenvalues of
the mechanical stress tensor. Additionally, we evaluate the constrained cases
allowing only tensile or compressive stresses, respectively, and consider the
plane stress problem. We show numerical results for all cases and discuss, to
what extent a stress reduction is possible.
</summary>
    <author>
      <name>Mischa Blaszczyk</name>
    </author>
    <author>
      <name>Klaus Hackl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages + 6 pages supplemental material</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.00017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.00017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.00497v1</id>
    <updated>2023-04-02T10:04:26Z</updated>
    <published>2023-04-02T10:04:26Z</published>
    <title>Level set-based shape optimization of deformable structures for
  manipulating sound propagation</title>
    <summary>  In this paper, we propose a level set-based shape optimization method for
acoustic wave propagation problems with a deformable structure. First, we
propose a mathematical model for acoustic wave propagation with a deformed
structure based on coordinate transformation and the Eulerian approach. Next,
we formulate the shape optimization problem and perform sensitivity analysis
based on the shape derivative concept. We then construct an optimization
algorithm based on the framework of a level set-based shape and topology
optimization method. Finally, we provide two-dimensional optimization examples
that demonstrate the effectiveness of our proposed method in providing
optimized designs with desired functionality, while considering the structural
deformation.
</summary>
    <author>
      <name>Yuki Noguchi</name>
    </author>
    <author>
      <name>Takayuki Yamada</name>
    </author>
    <link href="http://arxiv.org/abs/2304.00497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.00497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.04867v1</id>
    <updated>2023-04-11T15:05:20Z</updated>
    <published>2023-04-11T15:05:20Z</published>
    <title>A New Algorithm to determine Adomian Polynomials for nonlinear
  polynomial functions</title>
    <summary>  We present a new algorithm by which the Adomian polynomials can be determined
for scalar-valued nonlinear polynomial functional in a Hilbert space. This
algorithm calculates the Adomian polynomials without the complicated operations
such as parametrization, expansion, regrouping, differentiation, etc. The
algorithm involves only some matrix operations. Because of the simplicity in
the mathematical operations, the new algorithm is faster and more efficient
than the other algorithms previously reported in the literature. We also
implement the algorithm in the MATHEMATICA code. The computing speed and
efficiency of the new algorithm are compared with some other algorithms in the
one-dimensional case.
</summary>
    <author>
      <name>Mithun Bairagi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.9734/arjom/2023/v19i7670</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.9734/arjom/2023/v19i7670" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Asian Research Journal of Mathematics, Volume 19, Issue 7, Page
  1-12, 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2305.04867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.04867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.08732v1</id>
    <updated>2023-06-14T20:33:59Z</updated>
    <published>2023-06-14T20:33:59Z</published>
    <title>A Fluid-Solid-Growth Solver for Cardiovascular Modeling</title>
    <summary>  We implement full, three-dimensional constrained mixture theory for vascular
growth and remodeling into a finite element fluid-structure interaction (FSI)
solver. The resulting "fluid-solid-growth" (FSG) solver allows long term,
patient-specific predictions of changing hemodynamics, vessel wall morphology,
tissue composition, and material properties. This extension from short term
(FSI) to long term (FSG) simulations increases clinical relevance by enabling
mechanobioloigcally-dependent studies of disease progression in complex
domains.
</summary>
    <author>
      <name>Erica L. Schwarz</name>
    </author>
    <author>
      <name>Martin R. Pfaller</name>
    </author>
    <author>
      <name>Jason M. Szafron</name>
    </author>
    <author>
      <name>Marcos Latorre</name>
    </author>
    <author>
      <name>Stephanie E. Lindsey</name>
    </author>
    <author>
      <name>Christopher K. Breuer</name>
    </author>
    <author>
      <name>Jay D. Humphrey</name>
    </author>
    <author>
      <name>Alison L. Marsden</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2023.116312</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2023.116312" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.08732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.08732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.10272v1</id>
    <updated>2023-06-17T06:34:56Z</updated>
    <published>2023-06-17T06:34:56Z</published>
    <title>Orientation Optimization Based on Topological Derivatives in Cooperation
  with Multi-Material Topology Optimization Based on Extended Level Set Method</title>
    <summary>  This paper provides an orientation angle optimization method for the design
of fiber-reinforced composite materials using topology optimization. The
orientation angle optimization is based on a topological derivative, which
measures the sensitivity of an objective function with respect to a topological
change of anisotropic materials. The sensitivity is incorporated into a new
gradient-based optimization algorithm. This method allows us to avoid local
optima and seek a global optimal solution. We provide some numerical examples
and verify the effectiveness of the proposed method.
</summary>
    <author>
      <name>Masaki Noda</name>
    </author>
    <author>
      <name>Kei Matsushima</name>
    </author>
    <author>
      <name>Takayuki Yamada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.10272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.10272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.13489v1</id>
    <updated>2023-06-23T13:12:55Z</updated>
    <published>2023-06-23T13:12:55Z</published>
    <title>Circuit simulation using explicit methods: singular matrix issues</title>
    <summary>  Some aspects of the ELectrical EXplicit (ELEX) scheme for using explicit
integration schemes in circuit simulation are discussed. It is pointed out that
the parallel resistor approach, presented earlier to address singular matrix
issues arising in the ELEX scheme, is not adequately robust for incorporation
in a general-purpose simulator for power electronic circuits. New
topology-aware approaches, which are more robust and efficient compared to the
parallel resistor approach, are presented. Several circuit examples are
considered to illustrate the new approaches.
</summary>
    <author>
      <name>Mahesh B. Patil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.13489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.13489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.02494v1</id>
    <updated>2023-07-04T06:16:43Z</updated>
    <published>2023-07-04T06:16:43Z</published>
    <title>Comparison of Neural FEM and Neural Operator Methods for applications in
  Solid Mechanics</title>
    <summary>  Machine Learning methods belong to the group of most up-to-date approaches
for solving partial differential equations. The current work investigates two
classes, Neural FEM and Neural Operator Methods, for the use in elastostatics
by means of numerical experiments. The Neural Operator methods require
expensive training but then allow for solving multiple boundary value problems
with the same Machine Learning model. Main differences between the two classes
are the computational effort and accuracy. Especially the accuracy requires
more research for practical applications.
</summary>
    <author>
      <name>Stefan Hildebrand</name>
    </author>
    <author>
      <name>Sandra Klinge</name>
    </author>
    <link href="http://arxiv.org/abs/2307.02494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.02494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.01457v1</id>
    <updated>2023-08-02T22:16:11Z</updated>
    <published>2023-08-02T22:16:11Z</published>
    <title>Shape Uncertainty Quantification for Electromagnetic Wave Scattering via
  First-Order Sparse Boundary Element Approximation</title>
    <summary>  Quantifying the effects on electromagnetic waves scattered by objects of
uncertain shape is key for robust design, particularly in high precision
applications. Assuming small random perturbations departing from a nominal
domain, the first-order sparse boundary element method (FOSB) has been proven
to directly compute statistical moments with poly-logarithmic complexity for a
prescribed accuracy, without resorting to computationally intense Monte Carlo
simulations. However, implementing the FOSB is not straightforward. To this
end, we introduce an easy-to-use with open-source framework to directly apply
the technique when dealing with complex objects. Exhaustive computational
experiments confirm our claims and demonstrate the technique's applicability as
well as provide pathways for further improvement.
</summary>
    <author>
      <name>Paul Escapil-Inchauspé</name>
    </author>
    <author>
      <name>Carlos Jerez-Hanckes</name>
    </author>
    <link href="http://arxiv.org/abs/2308.01457v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.01457v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.02259v1</id>
    <updated>2023-08-04T11:35:10Z</updated>
    <published>2023-08-04T11:35:10Z</published>
    <title>Reduced Basis Approximation for Maxwell's Eigenvalue Problem and
  Parameter-Dependent Domains</title>
    <summary>  In many high-frequency simulation workflows, eigenvalue tracking along a
parameter variation is necessary. This can become computationally prohibitive
when repeated time-consuming eigenvalue problems must be solved. Therefore, we
employ a reduced basis approximation to bring down the computational costs. It
is based on the greedy strategy from Horger et al. 2017 which considers
multiple eigenvalues for elliptic eigenvalue problems. We extend this algorithm
to deal with parameter-dependent domains and the Maxwell eigenvalue problem. In
this setting, the reduced basis may contain spurious eigenmodes, which require
special treatment. We demonstrate our algorithm in an eigenvalue tracking
application for an eigenmode classification.
</summary>
    <author>
      <name>Max Kappesser</name>
    </author>
    <author>
      <name>Anna Ziegler</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/2308.02259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.02259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.02957v1</id>
    <updated>2023-08-05T21:58:34Z</updated>
    <published>2023-08-05T21:58:34Z</published>
    <title>Improved convergence of forward and inverse finite element models</title>
    <summary>  Forward and inverse models are used throughout different engineering fields
to predict and understand the behaviour of systems and to find parameters from
a set of observations. These models use root-finding and minimisation
techniques respectively to achieve their goals. This paper introduces
improvements to these mathematical methods to then improve the convergence
behaviour of the overarching models when used in highly non-linear systems. The
performance of the new techniques is examined in detail and compared to that of
the standard methods. The improved techniques are also tested with FEM models
to show their practical application. Depending on the specific configuration of
the problem, the improved models yielded larger convergence basins and/or took
fewer steps to converge.
</summary>
    <author>
      <name>Preslav Aleksandrov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.02957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.02957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.05503v1</id>
    <updated>2023-08-10T11:28:31Z</updated>
    <published>2023-08-10T11:28:31Z</published>
    <title>EFX Allocations Exist for Binary Valuations</title>
    <summary>  We study the fair division problem and the existence of allocations
satisfying the fairness criterion envy-freeness up to any item (EFX). The
existence of EFX allocations is a major open problem in the fair division
literature. We consider binary valuations where the marginal gain of the value
by receiving an extra item is either $0$ or $1$. Babaioff et al. [2021] proved
that EFX allocations always exist for binary and submodular valuations. In this
paper, by using completely different techniques, we extend this existence
result to general binary valuations that are not necessarily submodular, and we
present a polynomial time algorithm for computing an EFX allocation.
</summary>
    <author>
      <name>Xiaolin Bu</name>
    </author>
    <author>
      <name>Jiaxin Song</name>
    </author>
    <author>
      <name>Ziqi Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2308.05503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.05503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.09102v1</id>
    <updated>2023-08-17T17:02:53Z</updated>
    <published>2023-08-17T17:02:53Z</published>
    <title>Universal and Automatic Elbow Detection for Learning the Effective
  Number of Components in Model Selection Problems</title>
    <summary>  We design a Universal Automatic Elbow Detector (UAED) for deciding the
effective number of components in model selection problems. The relationship
with the information criteria widely employed in the literature is also
discussed. The proposed UAED does not require the knowledge of a likelihood
function and can be easily applied in diverse applications, such as regression
and classification, feature and/or order selection, clustering, and dimension
reduction. Several experiments involving synthetic and real data show the
advantages of the proposed scheme with benchmark techniques in the literature.
</summary>
    <author>
      <name>E. Morgado</name>
    </author>
    <author>
      <name>L. Martino</name>
    </author>
    <author>
      <name>R. San Millan-Castillo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.dsp.2023.104103</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.dsp.2023.104103" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Digital Signal Processing, Volume 140, 2023, 104103</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2308.09102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.09102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.05555v1</id>
    <updated>2023-09-11T15:44:02Z</updated>
    <published>2023-09-11T15:44:02Z</published>
    <title>Unraveling Managerial Tangents in Firm Disclosure: Concealing Issues or
  Being Exposed?</title>
    <summary>  Earnings calls influence stock prices and are traditionally analyzed using
sentiment and linguistic traces. Our research introduces a "Topic-Switching
Index," a novel metric quantified through the transformer model FinBERT, to
measure managerial evasion during Q$\&amp;$A sessions in earnings calls. We find a
negative correlation between this index and subsequent stock prices, indicating
that investors penalize managerial evasiveness. This study is the first to
quantify such evasive tactics, adding a new dimension to how earnings calls are
understood and suggesting that topic shifting is an overlooked but significant
factor. We also show the predictability of the index under three different
classifier models and it stands out in all circumstances.
</summary>
    <author>
      <name>Xuan Zhou</name>
    </author>
    <author>
      <name>Yushen Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2309.05555v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.05555v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.04421v1</id>
    <updated>2023-08-30T12:28:09Z</updated>
    <published>2023-08-30T12:28:09Z</published>
    <title>Kinetic equations and level-set approach for simulating solid-state
  microstructure evolutions at the mesoscopic scale: state of the art,
  limitations, and prospects</title>
    <summary>  For over three decades, the front-capturing level-set method has demonstrated
its prowess for the simulation, at the mesoscopic scale, of numerous mechanisms
in the context of microstructure evolution occurring during complex
thermomechanical paths. This review delves into the foundations of this
numerical framework, charting its evolution concerning polycrystalline
materials, examining its recent advancements, scrutinizing its current
shortcomings, and exploring future possibilities. Special attention will be
given to the context of hot metal forming processes. In this context, this
article also aims to reintroduce, as simply as possible, the kinetic equations
related to the grain boundary migration.
</summary>
    <author>
      <name>Marc Bernacki</name>
    </author>
    <link href="http://arxiv.org/abs/2310.04421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.04421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.08931v1</id>
    <updated>2023-10-13T07:52:41Z</updated>
    <published>2023-10-13T07:52:41Z</published>
    <title>Data-driven aerodynamic shape design with distributionally robust
  optimization approaches</title>
    <summary>  We formulate and solve data-driven aerodynamic shape design problems with
distributionally robust optimization (DRO) approaches. Building on the findings
of the work \cite{gotoh2018robust}, we study the connections between a class of
DRO and the Taguchi method in the context of robust design optimization. Our
preliminary computational experiments on aerodynamic shape optimization in
transonic turbulent flow show promising design results.
</summary>
    <author>
      <name>Long Chen</name>
    </author>
    <author>
      <name>Jan Rottmayer</name>
    </author>
    <author>
      <name>Lisa Kusch</name>
    </author>
    <author>
      <name>Nicolas R. Gauger</name>
    </author>
    <author>
      <name>Yinyu Ye</name>
    </author>
    <link href="http://arxiv.org/abs/2310.08931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.08931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.12006v1</id>
    <updated>2023-10-18T14:40:45Z</updated>
    <published>2023-10-18T14:40:45Z</published>
    <title>Guaranteed, Predictable, Polynomial AGV Time-Pathing</title>
    <summary>  In this paper we present a framework of key algorithms and data-structures
for efficiently generating timetables for any number of AGVs from any given
positioning on any given graph to accomplish any given demands as long as a few
easily satisfiable assumptions are met. Our proposed algorithms provide
guaranteed solutions in predictable polynomial running-times, which is
fundamental to any real-time application. We also develop an improved
geographic reservation algorithm that provides a substantial run-time
improvement of the previously best-known algorithm from $O(nm)$ to $O(n)$.
</summary>
    <author>
      <name>James Forster</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2310.12006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.12006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.14427v1</id>
    <updated>2023-10-22T22:14:13Z</updated>
    <published>2023-10-22T22:14:13Z</published>
    <title>CMDA: a tool for Continuous Monitoring Data Analysis</title>
    <summary>  Over the last few years, with the growth of time-series collecting and
storing, there has been a great demand for tools and software for temporal data
engineering and modeling. This paper presents a generic workflow for time
series data research, including temporal data importing, preprocessing, and
feature extraction. This framework is developed and built as a robust and
easy-to-use Python package, called CMDA, with a modular structure that offers
tools to prepare raw data, allowing both scientists and non-experts to analyze
various temporal data structures.
</summary>
    <author>
      <name>Pejman Farhadi Ghalati</name>
    </author>
    <author>
      <name>Andreas Schuppert</name>
    </author>
    <link href="http://arxiv.org/abs/2310.14427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.14427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.15506v1</id>
    <updated>2023-10-24T04:23:48Z</updated>
    <published>2023-10-24T04:23:48Z</published>
    <title>Topology Optimization with Text-Guided Stylization</title>
    <summary>  We propose an approach for the generation of topology-optimized structures
with text-guided appearance stylization. This methodology aims to enrich the
concurrent design of a structure's physical functionality and aesthetic
appearance. Users can effortlessly input descriptive text to govern the style
of the structure. Our system employs a hash-encoded neural network as the
implicit structure representation backbone, which serves as the foundation for
the co-optimization of structural mechanical performance, style, and
connectivity, to ensure full-color, high-quality 3D-printable solutions. We
substantiate the effectiveness of our system through extensive comparisons,
demonstrations, and a 3D printing test.
</summary>
    <author>
      <name>Shengze Zhong</name>
    </author>
    <author>
      <name>Parinya Punpongsanon</name>
    </author>
    <author>
      <name>Daisuke Iwai</name>
    </author>
    <author>
      <name>Kosuke Sato</name>
    </author>
    <link href="http://arxiv.org/abs/2310.15506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.15506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.16249v1</id>
    <updated>2023-10-24T23:49:27Z</updated>
    <published>2023-10-24T23:49:27Z</published>
    <title>A clustering tool for interrogating finite element models based on
  eigenvectors of graph adjacency</title>
    <summary>  This note introduces an unsupervised learning algorithm to debug errors in
finite element (FE) simulation models and details how it was productionised.
The algorithm clusters degrees of freedom in the FE model using numerical
properties of the adjacency of its stiffness matrix. The algorithm has been
deployed as a tool called `Model Stability Analysis' tool within the commercial
structural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used
successfully by end-users for debugging real world FE models and we present
examples of the tool in action.
</summary>
    <author>
      <name>Ramaseshan Kannan</name>
    </author>
    <link href="http://arxiv.org/abs/2310.16249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.16249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.20308v1</id>
    <updated>2023-10-31T09:33:03Z</updated>
    <published>2023-10-31T09:33:03Z</published>
    <title>A physics-informed GAN Framework based on Model-free Data-Driven
  Computational Mechanics</title>
    <summary>  Model-free data-driven computational mechanics, first proposed by
Kirchdoerfer and Ortiz, replace phenomenological models with numerical
simulations based on sample data sets in strain-stress space. In this study, we
integrate this paradigm within physics-informed generative adversarial networks
(GANs). We enhance the conventional physics-informed neural network framework
by implementing the principles of data-driven computational mechanics into
GANs. Specifically, the generator is informed by physical constraints, while
the discriminator utilizes the closest strain-stress data to discern the
authenticity of the generator's output. This combined approach presents a new
formalism to harness data-driven mechanics and deep learning to simulate and
predict mechanical behaviors.
</summary>
    <author>
      <name>Kerem Ciftci</name>
    </author>
    <author>
      <name>Klaus Hackl</name>
    </author>
    <link href="http://arxiv.org/abs/2310.20308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.20308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.02209v1</id>
    <updated>2023-11-03T19:40:32Z</updated>
    <published>2023-11-03T19:40:32Z</published>
    <title>A Model-Based Synthetic Stock Price Time Series Generation Framework</title>
    <summary>  The Ornstein-Uhlenbeck (OU) process, a mean-reverting stochastic process, has
been widely applied as a time series model in various domains. This paper
describes the design and implementation of a model-based synthetic time series
model based on a multivariate OU process and the Arbitrage Pricing Theory (APT)
for generating synthetic pricing data for a complex market of interacting
stocks. The objective is to create a group of synthetic stock price time series
that reflects the correlation between individual stocks and clusters of stocks
in how a real market behaves. We demonstrate the method using the Standard and
Poor's (S&amp;P) 500 universe of stocks as an example.
</summary>
    <author>
      <name>Haibei Zhu</name>
    </author>
    <author>
      <name>Svitlana Vyetrenko</name>
    </author>
    <author>
      <name>Tucker Balch</name>
    </author>
    <link href="http://arxiv.org/abs/2311.02209v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.02209v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.05470v1</id>
    <updated>2023-11-09T15:58:55Z</updated>
    <published>2023-11-09T15:58:55Z</published>
    <title>Designing ship hull forms using generative adversarial networks</title>
    <summary>  We proposed a GAN-based method to generate a ship hull form. Unlike
mathematical hull forms that require geometrical parameters to generate ship
hull forms, the proposed method requires desirable ship performance parameters,
i.e., the drag coefficient and tonnage. The requirements of ship owners are
generally focused on the ship performance and not the geometry itself. Hence,
the proposed model is useful for obtaining the ship hull form based on an
owner's requirements. The GAN model was trained using a ship hull form dataset
generated using the generalized Wigley hull form. The proposed method was
evaluated through numerical experiments and successfully generated ship data
with small errors.
</summary>
    <author>
      <name>Kazuo Yonekura</name>
    </author>
    <author>
      <name>Kotaro Omori</name>
    </author>
    <author>
      <name>Xinran Qi</name>
    </author>
    <author>
      <name>Katsuyuki Suzuki</name>
    </author>
    <link href="http://arxiv.org/abs/2311.05470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.05470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.08821v1</id>
    <updated>2023-11-15T09:51:20Z</updated>
    <published>2023-11-15T09:51:20Z</published>
    <title>Thermal Finite Element Modeling and Simulation of a Squirrel-Cage
  Induction Machine</title>
    <summary>  Finite element models of electrical machines allow insights in electrothermal
stresses which endanger the insulation system of the machine. This paper
presents a thermal finite element model of a 3.7 kW squirrel-cage induction
machine. The model resolves the conductors and the surrounding insulation
materials in the stator slots. A set of transient thermal scenarios is defined
and measured in the machine laboratory. These data are used to assess the
finite element model.
</summary>
    <author>
      <name>Christian Bergfried</name>
    </author>
    <author>
      <name>Yvonne Späck-Leigsnering</name>
    </author>
    <author>
      <name>Roland Seebacher</name>
    </author>
    <author>
      <name>Heinrich Eickhoff</name>
    </author>
    <author>
      <name>Annette Muetze</name>
    </author>
    <link href="http://arxiv.org/abs/2311.08821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.08821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.01021v1</id>
    <updated>2023-12-02T04:03:32Z</updated>
    <published>2023-12-02T04:03:32Z</published>
    <title>Data-Driven Autoencoder Numerical Solver with Uncertainty Quantification
  for Fast Physical Simulations</title>
    <summary>  Traditional partial differential equation (PDE) solvers can be
computationally expensive, which motivates the development of faster methods,
such as reduced-order-models (ROMs). We present GPLaSDI, a hybrid deep-learning
and Bayesian ROM. GPLaSDI trains an autoencoder on full-order-model (FOM) data
and simultaneously learns simpler equations governing the latent space. These
equations are interpolated with Gaussian Processes, allowing for uncertainty
quantification and active learning, even with limited access to the FOM solver.
Our framework is able to achieve up to 100,000 times speed-up and less than 7%
relative error on fluid mechanics problems.
</summary>
    <author>
      <name>Christophe Bonneville</name>
    </author>
    <author>
      <name>Youngsoo Choi</name>
    </author>
    <author>
      <name>Debojyoti Ghosh</name>
    </author>
    <author>
      <name>Jonathan L. Belof</name>
    </author>
    <link href="http://arxiv.org/abs/2312.01021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.01021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.07681v1</id>
    <updated>2023-12-12T19:23:11Z</updated>
    <published>2023-12-12T19:23:11Z</published>
    <title>A Note on Local Convergence of Iterative Processes for Pipe Network
  Analysis</title>
    <summary>  Analysis of pipe networks involves computing flow rates and pressure
differences on pipe segments in the network, given the external inflow/outflow
values. This analysis can be conducted using iterative methods, among which the
algorithms of Hardy Cross and Newton-Raphson have historically been applied in
practice. In this note, we address the mathematical analysis of the local
convergence of these algorithms. The loop-based Newton-Raphson algorithm
converges quadratically fast, and we provide estimates for its convergence
radius to correct some estimates in the previous literature. In contrast, we
show that the convergence of the Hardy Cross algorithm is only linear. This
provides theoretical confirmation of experimental observations reported earlier
in the literature.
</summary>
    <author>
      <name>Huong Luu</name>
    </author>
    <author>
      <name>Marek Chrobak</name>
    </author>
    <link href="http://arxiv.org/abs/2312.07681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.07681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.16984v1</id>
    <updated>2023-12-28T11:58:28Z</updated>
    <published>2023-12-28T11:58:28Z</published>
    <title>Reformulation and generalisation of the air-gap element</title>
    <summary>  The air-gap macro element is reformulated such that rotation, rotor or stator
skewing and rotor eccentricity can be incorporated easily. The air-gap element
is evaluated using Fast Fourier Transforms which in combination with the
Conjugate Gradient algorithm leads to highly efficient and memory inexpensive
iterative solution scheme. The improved air-gap element features beneficial
approximation properties and is competitive to moving-band and sliding-surface
technique.
</summary>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Thomas Weiland</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in ICS Newsletter (International Compumag Society)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICS Newsletter, Vol. 12, No. 1, ISSN 1026-0854, 1 March 2005, pp.
  2-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2312.16984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.16984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.17043v4</id>
    <updated>2024-12-02T09:30:35Z</updated>
    <published>2023-12-28T14:41:39Z</published>
    <title>Collatz-Weyl Generators: High Quality and High Throughput Parameterized
  Pseudorandom Number Generators</title>
    <summary>  We introduce the Collatz-Weyl Generators, a family of uniform pseudorandom
number generators (PRNGs) which are based on generalized Collatz mappings,
derived from the Collatz conjecture and Weyl sequences. The high-quality
statistical properties of our generators is demonstrated by the fact that they
pass stringent randomness tests used by the research and standardization
community. The proposed Collatz-Weyl Generators have a number of important
properties, including solid mathematical foundations, enablement of high
throughput and low latency implementation, small code and/or ASIC size,
enablement of producing multiple independent streams and potential of support
of cryptographic applications.
</summary>
    <author>
      <name>Tomasz R. Działa</name>
    </author>
    <link href="http://arxiv.org/abs/2312.17043v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.17043v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.07179v1</id>
    <updated>2024-01-14T00:33:30Z</updated>
    <published>2024-01-14T00:33:30Z</published>
    <title>Forecasting GDP in Europe with Textual Data</title>
    <summary>  We evaluate the informational content of news-based sentiment indicators for
forecasting Gross Domestic Product (GDP) and other macroeconomic variables of
the five major European economies. Our data set includes over 27 million
articles for 26 major newspapers in 5 different languages. The evidence
indicates that these sentiment indicators are significant predictors to
forecast macroeconomic variables and their predictive content is robust to
controlling for other indicators available to forecasters in real-time.
</summary>
    <author>
      <name>Luca Barbaglia</name>
    </author>
    <author>
      <name>Sergio Consoli</name>
    </author>
    <author>
      <name>Sebastiano Manzan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/jae.3027</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/jae.3027" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 6 figures, published in Journal of Applied Econometrics
  (Early view)</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.07179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.07179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B62, 91B84, 91B86" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.07762v1</id>
    <updated>2024-01-15T15:16:23Z</updated>
    <published>2024-01-15T15:16:23Z</published>
    <title>Auto-Regressive Model with Exogenous Input--ARX--based traffic-flow
  prediction</title>
    <summary>  Traffic flow prediction is widely used in travel decision making, traffic
control, roadway system planning, business sectors, and government agencies.
ARX models have proved to be highly effective and versatile. In this research,
we investigated the applications of ARX models in prediction for real traffic
flow in New York City. The ARX models were constructed by linear/polynomial or
neural networks. Comparative studies were carried out based on the results by
the efficiency, accuracy, and training computational demand of the algorithms.
</summary>
    <author>
      <name>Jun Ying</name>
    </author>
    <author>
      <name>Xin Dong</name>
    </author>
    <author>
      <name>Bowei Li</name>
    </author>
    <author>
      <name>Zihan Tian</name>
    </author>
    <link href="http://arxiv.org/abs/2401.07762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.07762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.13355v1</id>
    <updated>2024-01-24T10:31:30Z</updated>
    <published>2024-01-24T10:31:30Z</published>
    <title>Considering Capacitive Effects in Foil Winding Homogenization</title>
    <summary>  In conventional finite element simulations, foil windings with a thin foil
and many turns require many mesh elements. This renders models quickly
computationally infeasible. With the use of homogenization approaches, the
finite element mesh does not need to resolve the small-scale structure of the
foil winding domain. Present homogenization approaches take resistive and
inductive effects into account. With an increase of the operation frequency of
foil windings, however, capacitive effects between adjacent turns in the foil
winding become relevant. This paper presents an extension to the standard foil
winding model that covers the capacitive behavior of foil windings.
</summary>
    <author>
      <name>Jonas Bundschuh</name>
    </author>
    <author>
      <name>Yvonne Späck-Leigsnering</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.13355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.13355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35Q61" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; J.2; G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.15715v1</id>
    <updated>2024-01-28T17:38:56Z</updated>
    <published>2024-01-28T17:38:56Z</published>
    <title>Exploring the Impact of Blockchain, AI, and ML on Financial Accounting
  Efficiency and Transformation</title>
    <summary>  Continuous innovations profoundly impact the financial and commercial
domains, reshaping conventional business practices. Among the disruptive
forces, Artificial Intelligence (AI), Machine Learning (ML), and blockchain
technology stand out prominently. This study aims to evaluate the integration
of blockchain, AI, and ML within financial accounting practices. It suggests a
potential revolutionary impact on financial accounting through the adoption of
blockchain technology and ML, promising reduced accounting expenses, heightened
precision, real-time financial reporting capabilities, and expeditious auditing
processes. AI's role in automating repetitive financial accounting tasks
assists organizations in circumventing the need for additional staff, thereby
minimizing associated costs. Consequently, to bolster efficiency, businesses
are increasingly embracing blockchain technology and AI applications in their
financial accounting operations.
</summary>
    <author>
      <name>Vijaya Kanaparthi</name>
    </author>
    <link href="http://arxiv.org/abs/2401.15715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.15715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.02483v1</id>
    <updated>2024-02-04T13:21:29Z</updated>
    <published>2024-02-04T13:21:29Z</published>
    <title>A Survey on Blockchain in E-Government Services: Status and Challenges</title>
    <summary>  Blockchain technology is referred to as a very secure decentralized,
distributed ledger that records the history of any digital asset. It is being
used in numerous governmental and private sector organizations across numerous
nations. Surveying the current state of blockchain applications and
difficulties in e-government services is the goal of this review. Held to the
account are use cases for current facilities that use blockchain. Finally, it
examines the research gap in blockchain deployment and makes suggestions for
future work for additional research.
</summary>
    <author>
      <name>Manal Mansour</name>
    </author>
    <author>
      <name>May Salama</name>
    </author>
    <author>
      <name>Hala Helmi</name>
    </author>
    <author>
      <name>Mona Mursi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.17577/IJERTV12IS040157</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.17577/IJERTV12IS040157" rel="related"/>
    <link href="http://arxiv.org/abs/2402.02483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.02483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.09409v1</id>
    <updated>2023-12-13T10:47:13Z</updated>
    <published>2023-12-13T10:47:13Z</published>
    <title>Seasons's Greetings by AD</title>
    <summary>  We use Algorithmic Differentiation (AD) to implement type-generic tangent and
adjoint versions of $$ y=\sum_{i=0}^{n-1} x_{2 i} \cdot x_{2 i+1} $$ in C++. We
run an instantiation for char-arithmetic and we print the gradient at
$(101~77~114~114~32~121~109~88~115~97)^T$ to std::cout, yielding the output
``Merry Xmas''.
  Similar instantiations of type-generic second-order tangent and second-order
adjoint versions of $$
  y=\frac{1}{6} \cdot \sum_{i=0}^{n-1} x^3_{i} $$ yield ``Happy 2024'' at
$(72~97~112~112~121~32~50~48~50~52)^T.$ Prepend a sufficiently large number of
zeros to the input vector to explore the varying run times of the different
derivative codes. The entire source code can be found on
https://github.com/un110076/SeasonsGreetings.
</summary>
    <author>
      <name>Uwe Naumann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code available on github</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.09409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.09409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00-02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.13925v1</id>
    <updated>2024-02-21T16:45:02Z</updated>
    <published>2024-02-21T16:45:02Z</published>
    <title>UMAT4COMSOL: An Abaqus user material (UMAT) subroutine wrapper for
  COMSOL</title>
    <summary>  We present a wrapper that allows Abaqus user material subroutines (UMATs) to
be used as an External Material library in the software COMSOL Multiphysics.
The wrapper, written in C language, transforms COMSOL's external material
subroutine inputs and outputs into Fortran-coded Abaqus UMAT inputs and
outputs, by means of a consistent variable transformation. This significantly
facilitates conducting coupled, multi-physics studies employing the advanced
material models that the solid mechanics community has developed over the past
decades. We exemplify the potential of our new framework, UMAT4COMSOL, by
conducting numerical experiments in the areas of elastoplasticity,
hyperelasticity and crystal plasticity. The source code, detailed documentation
and example tutorials are made freely available to download at
www.empaneda.com/codes.
</summary>
    <author>
      <name>S. Lucarini</name>
    </author>
    <author>
      <name>E. Martínez-Pañeda</name>
    </author>
    <link href="http://arxiv.org/abs/2402.13925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.13925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.04914v1</id>
    <updated>2024-03-07T22:00:17Z</updated>
    <published>2024-03-07T22:00:17Z</published>
    <title>Improving the Equation of Exchange for Cryptoasset Valuation Using
  Empirical Data</title>
    <summary>  In the evolving domain of cryptocurrency markets, accurate token valuation
remains a critical aspect influencing investment decisions and policy
development. Whilst the prevailing equation of exchange pricing model offers a
quantitative valuation approach based on the interplay between token price,
transaction volume, supply, and either velocity or holding time, it exhibits
intrinsic shortcomings. Specifically, the model may not consistently delineate
the relationship between average token velocity and holding time. This paper
aims to refine this equation, enhancing the depth of insight into token
valuation methodologies.
</summary>
    <author>
      <name>Stylianos Kampakis</name>
    </author>
    <author>
      <name>Melody Yuan</name>
    </author>
    <author>
      <name>Oritsebawo Paul Ikpobe</name>
    </author>
    <author>
      <name>Linas Stankevicius</name>
    </author>
    <link href="http://arxiv.org/abs/2403.04914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.04914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.11648v1</id>
    <updated>2024-03-18T10:44:27Z</updated>
    <published>2024-03-18T10:44:27Z</published>
    <title>Vehicle single track modeling using physics guided neural differential
  equations</title>
    <summary>  In this paper, we follow the physics guided modeling approach and integrate a
neural differential equation network into the physical structure of a vehicle
single track model. By relying on the kinematic relations of the single track
ordinary differential equations (ODE), a small neural network and few training
samples are sufficient to substantially improve the model accuracy compared
with a pure physics based vehicle single track model. To be more precise, the
sum of squared error is reduced by 68% in the considered scenario. In addition,
it is demonstrated that the prediction capabilities of the physics guided
neural ODE model are superior compared with a pure black box neural
differential equation approach.
</summary>
    <author>
      <name>Stephan Rhode</name>
    </author>
    <author>
      <name>Fabian Jarmolowitz</name>
    </author>
    <author>
      <name>Felix Berkel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint, 11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.11648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.11648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.16507v1</id>
    <updated>2024-03-25T07:44:17Z</updated>
    <published>2024-03-25T07:44:17Z</published>
    <title>An experimental evaluation of choices of SSA forecasting parameters</title>
    <summary>  Six time series related to atmospheric phenomena are used as inputs for
experiments offorecasting with singular spectrum analysis (SSA). Existing
methods for SSA parametersselection are compared throughout their forecasting
accuracy relatively to an optimal aposteriori selection and to a naive
forecasting methods. The comparison shows that awidespread practice of
selecting longer windows leads often to poorer predictions. It alsoconfirms
that the choices of the window length and of the grouping are essential.
Withthe mean error of rainfall forecasting below 1.5%, SSA appears as a viable
alternative forhorizons beyond two weeks.
</summary>
    <author>
      <name>Teodor Knapik</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISEA</arxiv:affiliation>
    </author>
    <author>
      <name>Adolphe Ratiarison</name>
    </author>
    <author>
      <name>Hasina Razafindralambo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.46298/arima.9641</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.46298/arima.9641" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revue Africaine de Recherche en Informatique et Math{\'e}matiques
  Appliqu{\'e}es, In press, 40</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.16507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.16507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.19109v1</id>
    <updated>2024-03-28T03:03:19Z</updated>
    <published>2024-03-28T03:03:19Z</published>
    <title>Enhancing Evolutionary Solver Efficiency for NP Hard Single Machine
  Scheduling Problems</title>
    <summary>  The study explores the optimization of evolutionary solver parameters for
minimizing total tardiness in single machine scheduling, an NP-hard problem
with zero ready times included. It investigates various parameter combinations,
including population sizes, mutation rates, and a constant convergence rate,
both above and below default values. The aim is to enhance the solver's
effectiveness in addressing this complex challenge. The findings contribute to
improving scheduling efficiency in manufacturing and operations management
contexts.
</summary>
    <author>
      <name>Mohammed Alromema</name>
    </author>
    <author>
      <name>Mohammed A. Makarem</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21275/SR231128074407</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21275/SR231128074407" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 13 figures, International Journal of Science and Research
  (IJSR), ISSN: 2319-7064, Volume 13 Issue 28, November 2023</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Science and Research (IJSR), ISSN:
  2319-7064, Volume 13 Issue 28, November 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2403.19109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.19109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.03523v1</id>
    <updated>2024-04-04T15:26:26Z</updated>
    <published>2024-04-04T15:26:26Z</published>
    <title>Integrating Generative AI into Financial Market Prediction for Improved
  Decision Making</title>
    <summary>  This study provides an in-depth analysis of the model architecture and key
technologies of generative artificial intelligence, combined with specific
application cases, and uses conditional generative adversarial networks ( cGAN
) and time series analysis methods to simulate and predict dynamic changes in
financial markets. The research results show that the cGAN model can
effectively capture the complexity of financial market data, and the deviation
between the prediction results and the actual market performance is minimal,
showing a high degree of accuracy.
</summary>
    <author>
      <name>Chang Che</name>
    </author>
    <author>
      <name>Zengyi Huang</name>
    </author>
    <author>
      <name>Chen Li</name>
    </author>
    <author>
      <name>Haotian Zheng</name>
    </author>
    <author>
      <name>Xinyu Tian</name>
    </author>
    <link href="http://arxiv.org/abs/2404.03523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.03523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.13028v1</id>
    <updated>2024-04-19T17:43:26Z</updated>
    <published>2024-04-19T17:43:26Z</published>
    <title>When Life gives you LLMs, make LLM-ADE: Large Language Models with
  Adaptive Data Engineering</title>
    <summary>  This paper presents the LLM-ADE framework, a novel methodology for continued
pre-training of large language models (LLMs) that addresses the challenges of
catastrophic forgetting and double descent. LLM-ADE employs dynamic
architectural adjustments, including selective block freezing and expansion,
tailored to specific datasets. This strategy enhances model adaptability to new
data while preserving previously acquired knowledge. We demonstrate LLM-ADE's
effectiveness on the TinyLlama model across various general knowledge
benchmarks, showing significant performance improvements without the drawbacks
of traditional continuous training methods. This approach promises a more
versatile and robust way to keep LLMs current and efficient in real-world
applications.
</summary>
    <author>
      <name>Stephen Choi</name>
    </author>
    <author>
      <name>William Gazeley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 tables and 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.13028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.13028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.17645v1</id>
    <updated>2024-03-08T09:58:13Z</updated>
    <published>2024-03-08T09:58:13Z</published>
    <title>Técnicas Quantum-Inspired en Tensor Networks para Contextos
  Industriales</title>
    <summary>  In this paper we present a study of the applicability and feasibility of
quantum-inspired algorithms and techniques in tensor networks for industrial
environments and contexts, with a compilation of the available literature and
an analysis of the use cases that may be affected by such methods. In addition,
we explore the limitations of such techniques in order to determine their
potential scalability.
</summary>
    <author>
      <name>Alejandro Mata Ali</name>
    </author>
    <author>
      <name>Iñigo Perez Delgado</name>
    </author>
    <author>
      <name>Aitor Moreno Fdez. de Leceta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, in Spanish language, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.17645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.17645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1; G.1.3; G.2.1; G.0; I.0; J.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.03437v1</id>
    <updated>2024-05-06T13:02:47Z</updated>
    <published>2024-05-06T13:02:47Z</published>
    <title>pyCFS-data: Data Processing Framework in Python for openCFS</title>
    <summary>  Many numerical simulation tools have been developed and are on the market,
but there is still a strong need for appropriate tools capable of simulating
multi-field problems, especially in aeroacoustics. Therefore, openCFS provides
an open-source framework for implementing partial differential equations using
the finite element method. Since 2000, the software has been developed
continuously. The result is openCFS (before 2020, known as CFS++ Coupled Field
Simulations written in C++). In this paper, we present pyCFS-data, a data
processing framework written in Python to provide a flexible and easy-to-use
toolbox to access and manipulate, pre- and postprocess data generated by or for
usage with openCFS.
</summary>
    <author>
      <name>Andreas Wurzinger</name>
    </author>
    <author>
      <name>Stefan Schoder</name>
    </author>
    <link href="http://arxiv.org/abs/2405.03437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.03437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.18430v1</id>
    <updated>2024-05-28T17:59:42Z</updated>
    <published>2024-05-28T17:59:42Z</published>
    <title>Feasibility of Privacy-Preserving Entity Resolution on Confidential
  Healthcare Datasets Using Homomorphic Encryption</title>
    <summary>  Patient datasets contain confidential information which is protected by laws
and regulations such as HIPAA and GDPR. Ensuring comprehensive patient
information necessitates privacy-preserving entity resolution (PPER), which
identifies identical patient entities across multiple databases from different
healthcare organizations while maintaining data privacy. Existing methods often
lack cryptographic security or are computationally impractical for real-world
datasets. We introduce a PPER pipeline based on AMPPERE, a secure abstract
computation model utilizing cryptographic tools like homomorphic encryption.
Our tailored approach incorporates extensive parallelization techniques and
optimal parameters specifically for patient datasets. Experimental results
demonstrate the proposed method's effectiveness in terms of accuracy and
efficiency compared to various baselines.
</summary>
    <author>
      <name>Yixiang Yao</name>
    </author>
    <author>
      <name>Joseph Cecil</name>
    </author>
    <author>
      <name>Praveen Angyan</name>
    </author>
    <author>
      <name>Neil Bahroos</name>
    </author>
    <author>
      <name>Srivatsan Ravi</name>
    </author>
    <link href="http://arxiv.org/abs/2405.18430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.18430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.00865v1</id>
    <updated>2024-06-02T20:46:02Z</updated>
    <published>2024-06-02T20:46:02Z</published>
    <title>Topology optimization of contact-aided thermo-mechanical regulators</title>
    <summary>  Topology optimization is used to systematically design contact-aided
thermo-mechanical regulators, i.e. components whose effective thermal
conductivity is tunable by mechanical deformation and contact. The
thermo-mechanical interactions are modeled using a fully coupled non-linear
thermo-mechanical finite element framework. To obtain the intricate heat
transfer response, the components leverage self-contact, which is modeled using
a third medium contact method. The effective heat transfer properties of the
regulators are tuned by solving a topology optimization problem using a
traditional gradient based algorithm. Several designs of thermo-mechanical
regulators in the form of switches, diodes and triodes are presented.
</summary>
    <author>
      <name>Anna Dalklint</name>
    </author>
    <author>
      <name>Joe Alexandersen</name>
    </author>
    <author>
      <name>Andreas Henrik Frederiksen</name>
    </author>
    <author>
      <name>Konstantinos Poulios</name>
    </author>
    <author>
      <name>Ole Sigmund</name>
    </author>
    <link href="http://arxiv.org/abs/2406.00865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.00865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.09692v1</id>
    <updated>2024-06-14T03:32:36Z</updated>
    <published>2024-06-14T03:32:36Z</published>
    <title>SplineGen: a generative model for B-spline approximation of unorganized
  points</title>
    <summary>  This paper presents a learning-based method to solve the traditional
parameterization and knot placement problems in B-spline approximation.
Different from conventional heuristic methods or recent AI-based methods, the
proposed method does not assume ordered or fixed-size data points as input.
There is also no need for manually setting the number of knots. It casts the
parameterization and knot placement problems as a sequence-to-sequence
translation problem, a generative process automatically determining the number
of knots, their placement, parameter values, and their ordering. Once trained,
SplineGen demonstrates a notable improvement over existing methods, with a one
to two orders of magnitude increase in approximation accuracy on test data.
</summary>
    <author>
      <name>Qiang Zou</name>
    </author>
    <author>
      <name>Lizhen Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/2406.09692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.09692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.11276v2</id>
    <updated>2024-10-18T14:36:55Z</updated>
    <published>2024-06-17T07:28:47Z</published>
    <title>A Mixed Tree-Cotree Gauge for the Reduced Basis Approximation of
  Maxwell's Eigenvalue Problem</title>
    <summary>  Model order reduction methods are a powerful tool to drastically reduce the
computational effort of problems which need to be evaluated repeatedly, i.e.,
when computing the same system for various parameter values. When applying a
reduced basis approximation algorithm to the Maxwell eigenvalue problem, we
encounter spurious solutions in the reduced system which hence need to be
removed during the basis construction. In this paper, we discuss two
tree-cotree gauge-based methods for the removal of the spurious eigenmodes.
</summary>
    <author>
      <name>Anna Ziegler</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <link href="http://arxiv.org/abs/2406.11276v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.11276v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.12676v1</id>
    <updated>2024-06-18T14:49:48Z</updated>
    <published>2024-06-18T14:49:48Z</published>
    <title>Systematic equation formulation for simulation of power electronic
  circuits using explicit methods</title>
    <summary>  Use of explicit integration methods for power electronic circuits with ideal
switch models significantly improves simulation speed. The PLECS package [1]
has effectively used this idea; however, the implementation details involved in
PLECS are not available in the public domain. Recently, a basic framework,
called the ``ELEX" scheme, for implementing explicit methods has been described
[2]. A few modifications of the ELEX scheme for efficient handling of inductors
and switches have been presented in [3]. In this paper, the approach presented
in [3] is further augmented with robust schemes that enable systematic equation
formulation for circuits involving switches, inductors, and transformers.
Several examples are presented to illustrate the proposed schemes.
</summary>
    <author>
      <name>Mahesh B. Patil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 35 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.12676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.12676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.19025v1</id>
    <updated>2024-06-27T09:20:42Z</updated>
    <published>2024-06-27T09:20:42Z</published>
    <title>Isogeometric Shape Optimization of Multi-Tapered Coaxial Baluns
  Simulated by an Integral Equation Method</title>
    <summary>  We discuss the advantages of a spline-based freeform shape optimization
approach using the example of a multi-tapered coaxial balun connected to a
spiral antenna. The underlying simulation model is given in terms of a recently
proposed isogeometric integral equation formulation, which can be interpreted
as a high-order generalization of the partial element equivalent circuit
method. We demonstrate a significant improvement in the optimized design, i.e.,
a reduction in the magnitude of the scattering parameter over a wide frequency
range.
</summary>
    <author>
      <name>Boian Balouchev</name>
    </author>
    <author>
      <name>Jürgen Dölz</name>
    </author>
    <author>
      <name>Maximilian Nolte</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Riccardo Torchio</name>
    </author>
    <link href="http://arxiv.org/abs/2406.19025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.19025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.09116v1</id>
    <updated>2024-07-12T09:30:50Z</updated>
    <published>2024-07-12T09:30:50Z</published>
    <title>On a High-Frequency Analysis of Some Relevant Integral Equations in
  Electromagnetics</title>
    <summary>  In this contribution we analyze the spectral properties of some commonly used
boundary integral operators in computational electromagnetics and of their
discrete counterparts, highlighting peculiar features of their spectra. In
particular, a comparison with the eigenvalues of the continuous operators will
be presented that highlights deviations in the high frequency regime and
impacts, in a peculiar way, the accuracy of the numerical solutions of each
formulation. A study and a proactive analysis of numerical results from
standard boundary element solvers and the predictions from the theoretical
analysis will corroborate the analytical framework employed and the validity of
our observations.
</summary>
    <author>
      <name>V. Giunzioni</name>
    </author>
    <author>
      <name>A. Merlini</name>
    </author>
    <author>
      <name>F. P. Andriulli</name>
    </author>
    <link href="http://arxiv.org/abs/2407.09116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.09116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.10206v1</id>
    <updated>2024-07-14T14:00:02Z</updated>
    <published>2024-07-14T14:00:02Z</published>
    <title>Dominant Design Prediction with Phylogenetic Networks</title>
    <summary>  This study proposes an effective method to predict technology development
from an evolutionary perspective. Product evolution is the result of
technological evolution and market selection. A phylogenetic network is the
main method to study product evolution. The formation of the dominant design
determines the trajectory of technology development. How to predict future
dominant design has become a key issue in technology forecasting and new
product development. We define the dominant product and use machine learning
methods, combined with product evolutionary theory, to construct a Fully
Connected Phylogenetic Network dataset to effectively predict the future
dominant design.
</summary>
    <author>
      <name>Youwei He</name>
    </author>
    <author>
      <name>Jeong-Dong Lee</name>
    </author>
    <author>
      <name>Dawoon Jeong</name>
    </author>
    <author>
      <name>Sungjun Choi</name>
    </author>
    <author>
      <name>Jiyong Kim</name>
    </author>
    <link href="http://arxiv.org/abs/2407.10206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.10206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.14275v1</id>
    <updated>2024-05-14T00:56:17Z</updated>
    <published>2024-05-14T00:56:17Z</published>
    <title>Empirical Voronoi Wavelets</title>
    <summary>  Recently, the construction of 2D empirical wavelets based on partitioning the
Fourier domain with the watershed transform has been proposed. If such approach
can build partitions of completely arbitrary shapes, for some applications, it
is desirable to keep a certain level of regularity in the geometry of the
obtained partitions. In this paper, we propose to build such partition using
Voronoi diagrams. This solution allows us to keep a high level of adaptability
while guaranteeing a minimum level of geometric regularity in the detected
partition.
</summary>
    <author>
      <name>Jerome Gilles</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.33205/cma.1181174</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.33205/cma.1181174" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, 1 algorithm</arxiv:comment>
    <link href="http://arxiv.org/abs/2407.14275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.14275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="42C40, 68U10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.01609v1</id>
    <updated>2024-08-03T00:07:10Z</updated>
    <published>2024-08-03T00:07:10Z</published>
    <title>Fed-RD: Privacy-Preserving Federated Learning for Financial Crime
  Detection</title>
    <summary>  We introduce Federated Learning for Relational Data (Fed-RD), a novel
privacy-preserving federated learning algorithm specifically developed for
financial transaction datasets partitioned vertically and horizontally across
parties. Fed-RD strategically employs differential privacy and secure
multiparty computation to guarantee the privacy of training data. We provide
theoretical analysis of the end-to-end privacy of the training algorithm and
present experimental results on realistic synthetic datasets. Our results
demonstrate that Fed-RD achieves high model accuracy with minimal degradation
as privacy increases, while consistently surpassing benchmark results.
</summary>
    <author>
      <name>Md. Saikat Islam Khan</name>
    </author>
    <author>
      <name>Aparna Gupta</name>
    </author>
    <author>
      <name>Oshani Seneviratne</name>
    </author>
    <author>
      <name>Stacy Patterson</name>
    </author>
    <link href="http://arxiv.org/abs/2408.01609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.01609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.06585v1</id>
    <updated>2024-08-13T02:50:10Z</updated>
    <published>2024-08-13T02:50:10Z</published>
    <title>SSAAM: Sentiment Signal-based Asset Allocation Method with Causality
  Information</title>
    <summary>  This study demonstrates whether financial text is useful for tactical asset
allocation using stocks by using natural language processing to create polarity
indexes in financial news. In this study, we performed clustering of the
created polarity indexes using the change-point detection algorithm. In
addition, we constructed a stock portfolio and rebalanced it at each change
point utilizing an optimization algorithm. Consequently, the asset allocation
method proposed in this study outperforms the comparative approach. This result
suggests that the polarity index helps construct the equity asset allocation
method.
</summary>
    <author>
      <name>Rei Taguchi</name>
    </author>
    <author>
      <name>Hiroki Sakaji</name>
    </author>
    <author>
      <name>Kiyoshi Izumi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/BigData55660.2022.10021064</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/BigData55660.2022.10021064" rel="related"/>
    <link href="http://arxiv.org/abs/2408.06585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.06585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.08285v2</id>
    <updated>2025-03-17T10:55:42Z</updated>
    <published>2024-08-28T15:49:38Z</published>
    <title>DIC2Abaqus: Calculating mixed-mode stress intensity factors from 2D and
  3D-stereo displacement fields</title>
    <summary>  Integrating experimental data into simulations is crucial for predicting
material behaviour, especially in fracture mechanics. Digital Image Correlation
(DIC) provides precise displacement measurements, essential for evaluating
strain energy release rates and stress intensity factors (SIF) around cracks.
Translating DIC data into CAE software like ABAQUS has been challenging.
DIC2CAE, a MATLAB-based tool, automates this conversion, enabling accurate
simulations. It uses the J-integral method to calculate SIFs and handles
complex scenarios without needing specimen geometry or applied loads. DIC2CAE
enhances fracture mechanics simulations' reliability, accelerating materials
research and development.
</summary>
    <author>
      <name>Abdalrhaman Koko</name>
    </author>
    <author>
      <name>T. James Marrow</name>
    </author>
    <link href="http://arxiv.org/abs/2409.08285v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.08285v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.15282v1</id>
    <updated>2024-08-16T23:19:56Z</updated>
    <published>2024-08-16T23:19:56Z</published>
    <title>Modelling Fire Incidents Response Times in Ålesund</title>
    <summary>  In the ESGI-156 project together with {\AA}lesund Brannvesen we develop a
model for response times to fire incidents on publicly available data for
{\AA}lesund. We investigate different scenarios and a first step towards an
interactive software for illustrating the response times.
</summary>
    <author>
      <name>J. Christmas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Exeter, UK</arxiv:affiliation>
    </author>
    <author>
      <name>R. Bergmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTNU Trondheim, Norway</arxiv:affiliation>
    </author>
    <author>
      <name>A. Zhakatayev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Agder, Norway</arxiv:affiliation>
    </author>
    <author>
      <name>J. Rebenda</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Agder, Norway</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brno University of Technology, Czech Republic</arxiv:affiliation>
    </author>
    <author>
      <name>S. Singh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTNU Trondheim, Norway</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 26 figures, extended ESGI 156 {\AA}lesund Brannvesen Report
  (see https://ecmiindmath.org/wp-content/uploads/2023/11/ecmiannrep2022.pdf ,
  page 40-49)</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.15282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.15282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C90, 68R10, 90C35 (Primary) 94C15 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.15447v1</id>
    <updated>2024-09-23T18:18:49Z</updated>
    <published>2024-09-23T18:18:49Z</published>
    <title>Topological and geometric characterization of synthetic aperture sonar
  collections</title>
    <summary>  This article explores the theoretical underpinnings of -- and practical
results for -- topological and geometric features of data collected by
synthetic aperture sonar systems. We prove a strong theoretical guarantee about
the structure of the space of echos (the signature space) that is relevant for
classification, and that this structure is measurable in laboratory conditions.
The guarantee makes minimal assumptions about the sonar platform's trajectory,
and establishes that the signature space divides neatly into topological
features based upon the number of prominent echos and their placement, and
geometric features that capture their corresponding sonar cross section.
</summary>
    <author>
      <name>Michael Robinson</name>
    </author>
    <author>
      <name>Zander Memon</name>
    </author>
    <author>
      <name>Maxwell Gualtieri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.15447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.15447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.00202v1</id>
    <updated>2024-09-30T19:57:30Z</updated>
    <published>2024-09-30T19:57:30Z</published>
    <title>Spectral Element Simulation of Liquid Metal Magnetohydrodynamics</title>
    <summary>  A spectral-element-based formulation of incompressible MHD is presented in
the context of the open-source fluid-thermal code, Nek5000/RS. The formulation
supports magnetic fields in a solid domain that surrounds the fluid domain.
Several steady-state and time-transient model problems are presented as part of
the code verification process. Nek5000/RS is designed for large-scale
turbulence simulations, which will be the next step with this new MHD
capability.
</summary>
    <author>
      <name>Yichen Guo</name>
    </author>
    <author>
      <name>Paul Fischer</name>
    </author>
    <author>
      <name>Misun Min</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 2 tables, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.00202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.00202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35-04" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.12348v1</id>
    <updated>2024-10-16T08:12:00Z</updated>
    <published>2024-10-16T08:12:00Z</published>
    <title>SELF-BART : A Transformer-based Molecular Representation Model using
  SELFIES</title>
    <summary>  Large-scale molecular representation methods have revolutionized applications
in material science, such as drug discovery, chemical modeling, and material
design. With the rise of transformers, models now learn representations
directly from molecular structures. In this study, we develop an
encoder-decoder model based on BART that is capable of leaning molecular
representations and generate new molecules. Trained on SELFIES, a robust
molecular string representation, our model outperforms existing baselines in
downstream tasks, demonstrating its potential in efficient and effective
molecular data analysis and manipulation.
</summary>
    <author>
      <name>Indra Priyadarsini</name>
    </author>
    <author>
      <name>Seiji Takeda</name>
    </author>
    <author>
      <name>Lisa Hamada</name>
    </author>
    <author>
      <name>Emilio Vital Brazil</name>
    </author>
    <author>
      <name>Eduardo Soares</name>
    </author>
    <author>
      <name>Hajime Shinohara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS AI4Mat 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.12348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.12348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.14645v1</id>
    <updated>2024-10-04T09:07:11Z</updated>
    <published>2024-10-04T09:07:11Z</published>
    <title>On the feasibility of foundational models for the simulation of physical
  phenomena</title>
    <summary>  We explore the feasibility of foundation models for the simulation of
physical phenomena, with emphasis on continuum (solid and fluid) mechanics.
Although so-called learned simulators have shown some success when applied to
specific tasks, it remains to be studied to what extent they are able to
undergo severe changes in domain shape, boundary conditions and/or constitutive
laws and still provide robust (i.e., hallucination-free) and accurate results.
In this paper we perform an exhaustive study of these features, put ourselves
in the worst-case scenario and study their resistance to such strong changes in
their domain of application.
</summary>
    <author>
      <name>Alicia Tierz</name>
    </author>
    <author>
      <name>Mikel M. Iparraguirre</name>
    </author>
    <author>
      <name>Iciar Alfaro</name>
    </author>
    <author>
      <name>David Gonzalez</name>
    </author>
    <author>
      <name>Francisco Chinesta</name>
    </author>
    <author>
      <name>Elias Cueto</name>
    </author>
    <link href="http://arxiv.org/abs/2410.14645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.14645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.14786v1</id>
    <updated>2024-10-01T08:21:10Z</updated>
    <published>2024-10-01T08:21:10Z</published>
    <title>BDDC Preconditioning on GPUs for Cardiac Simulations</title>
    <summary>  In order to understand cardiac arrhythmia, computer models for
electrophysiology are essential. In the EuroHPC MicroCARD project, we adapt the
current models and leverage modern computing resources to model diseased hearts
and their microstructure accurately. Towards this objective, we develop a
portable, highly efficient, and performing BDDC preconditioner and solver
implementation, demonstrating scalability with over 90% efficiency on up to 100
GPUs.
</summary>
    <author>
      <name>Fritz Goebel</name>
    </author>
    <author>
      <name>Terry Cojean</name>
    </author>
    <author>
      <name>Hartwig Anzt</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-48803-0_30</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-48803-0_30" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNCS, volume 14352 (2023), 265-268</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2410.14786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.14786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.16304v1</id>
    <updated>2024-10-07T09:36:47Z</updated>
    <published>2024-10-07T09:36:47Z</published>
    <title>Training an AI hyperelastic constitutive model with experimental data</title>
    <summary>  A Physics-Augmented Neural network is trained to model a hyperelastic
behavior. The dataset used for the training, validation, and test are
displacement-force couples obtained from two experiments on a rubber-like
material. One experiment was dedicated for the test, to assess the capacity of
the model to generalize on unseen loadings and geometries. The trained AI model
outperforms a standard Neo Hookean model identified on the same data.
Particular attention is paid to the mechanical data information contained in
the different datasets.
</summary>
    <author>
      <name>Clément Jailin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMPS</arxiv:affiliation>
    </author>
    <author>
      <name>Antoine Benady</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMPS</arxiv:affiliation>
    </author>
    <author>
      <name>Emmanuel Baranger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMPS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Photomechanics - IDICs, Oct 2024, Clermont - Ferrand, France</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.16304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.16304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.02324v1</id>
    <updated>2024-11-04T17:48:19Z</updated>
    <published>2024-11-04T17:48:19Z</published>
    <title>Non-parametric Inference for Diffusion Processes: A Computational
  Approach via Bayesian Inversion for PDEs</title>
    <summary>  In this paper, we present a theoretical and computational workflow for the
non-parametric Bayesian inference of drift and diffusion functions of
autonomous diffusion processes. We base the inference on the partial
differential equations arising from the infinitesimal generator of the
underlying process. Following a problem formulation in the infinite-dimensional
setting, we discuss optimization- and sampling-based solution methods. As
preliminary results, we showcase the inference of a single-scale, as well as a
multiscale process from trajectory data.
</summary>
    <author>
      <name>Maximilian Kruse</name>
    </author>
    <author>
      <name>Sebastian Krumscheid</name>
    </author>
    <link href="http://arxiv.org/abs/2411.02324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.02324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.05689v2</id>
    <updated>2025-03-25T19:59:46Z</updated>
    <published>2024-11-08T16:39:26Z</published>
    <title>optipoly: A Python package for boxed-constrained multi-variable
  polynomial cost functions optimization</title>
    <summary>  In this paper, a new python package (optipoly) is described that solves
box-constrained optimization problem over multivariate polynomial cost
functions. The principle of the algorithm is described before its performance
is compared to three general purpose NLP solvers implemented in the
state-of-the-art Gekko and scipy packages. The comparison show statistically
better best solution provided by the algorithm with significantly less
computation times. The package will be shortly made freely and easily available
through the simple (pip install) process.
</summary>
    <author>
      <name>Mazen Alamir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2411.05689v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.05689v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.12347v1</id>
    <updated>2024-11-19T08:55:49Z</updated>
    <published>2024-11-19T08:55:49Z</published>
    <title>Leveraging NFTs for Spectrum Securitization in 6G Networks</title>
    <summary>  Dynamic Spectrum Sharing can enhance spectrum resource utilization by
promoting the dynamic distribution of spectrum resources. However, to
effectively implement dynamic spectrum resource allocation, certain mechanisms
are needed to incentivize primary users to proactively share their spectrum
resources. This paper, based on the ERC404 standard and integrating
Non-Fungible Token and Fungible Token technologies, proposes a spectrum
securitization model to incentivize spectrum resource sharing and implements it
on the Ethereum test net.
</summary>
    <author>
      <name>Zhixian Zhou</name>
    </author>
    <author>
      <name>Bin Chen</name>
    </author>
    <author>
      <name>Chen Sun</name>
    </author>
    <author>
      <name>Peichang Zhang</name>
    </author>
    <author>
      <name>Shuo Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2411.12347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.12347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.15155v1</id>
    <updated>2024-11-08T06:11:15Z</updated>
    <published>2024-11-08T06:11:15Z</published>
    <title>Ultra-broadband acoustic absorber based on periodic acoustic
  rigid-metaporous composite array</title>
    <summary>  To address the increasingly serious issue of noise pollution, we propose an
ultra-broadband and wide-angle acoustic absorber based on a periodic acoustic
rigid-metaporous composite array. Numerical simulation results verify the
broadband good acoustic absorption performance of the proposed absorber, which
can achieve an average absorption coefficient of approximately 90.9% within the
frequency band from 500 to 4000 Hz with incident angles ranging from -75 to +75
degrees, thus compensating for the shortcomings of traditional acoustic
absorbers that are not as effective at low frequencies. This work will provide
a new approach for ultra-broadband and wide-angle acoustic wave absorption and
noise suppression.
</summary>
    <author>
      <name>Dongguo Zhang</name>
    </author>
    <author>
      <name>Fei Sun</name>
    </author>
    <author>
      <name>Yichao Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s42452-025-06505-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s42452-025-06505-4" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Discover Applied Sciences 7, 94 (2025)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2411.15155v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.15155v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.15483v1</id>
    <updated>2024-11-23T07:48:59Z</updated>
    <published>2024-11-23T07:48:59Z</published>
    <title>Prob-cGAN: A Probabilistic Conditional Generative Adversarial Network
  for LSD1 Inhibitor Activity Prediction</title>
    <summary>  The inhibition of Lysine-Specific Histone Demethylase 1 (LSD1) is a promising
strategy for cancer treatment and targeting epigenetic mechanisms. This paper
introduces a Probabilistic Conditional Generative Adversarial Network
(Prob-cGAN), designed to predict the activity of LSD1 inhibitors. The Prob-cGAN
was evaluated against state-of-the-art models using the ChEMBL database,
demonstrating superior performance. Specifically, it achieved a top-1 $R^2$ of
0.739, significantly outperforming the Smiles-Transformer model at 0.591 and
the baseline cGAN at 0.488. Furthermore, it recorded a lower $RMSE$ of 0.562,
compared to 0.708 and 0.791 for the Smiles-Transformer and cGAN models
respectively. These results highlight the potential of Prob-cGAN to enhance
drug design and advance our understanding of complex biological systems through
machine learning and bioinformatics.
</summary>
    <author>
      <name>Hanyang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2411.15483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.15483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.01224v1</id>
    <updated>2024-12-02T07:41:16Z</updated>
    <published>2024-12-02T07:41:16Z</published>
    <title>Option Pricing with Convolutional Kolmogorov-Arnold Networks</title>
    <summary>  With the rapid advancement of neural networks, methods for option pricing
have evolved significantly. This study employs the Black-Scholes-Merton (B-S-M)
model, incorporating an additional variable to improve the accuracy of
predictions compared to the traditional Black-Scholes (B-S) model. Furthermore,
Convolutional Kolmogorov-Arnold Networks (Conv-KANs) and Kolmogorov-Arnold
Networks (KANs) are introduced to demonstrate that networks with enhanced
non-linear capabilities yield superior fitting performance. For comparative
analysis, Conv-LSTM and LSTM models, which are widely used in time series
forecasting, are also applied. Additionally, a novel data selection strategy is
proposed to simulate a real trading environment, thereby enhancing the
robustness of the model.
</summary>
    <author>
      <name>Zeyuan Li</name>
    </author>
    <author>
      <name>Qingdao Huang</name>
    </author>
    <link href="http://arxiv.org/abs/2412.01224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.01224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.04041v1</id>
    <updated>2024-12-05T10:30:35Z</updated>
    <published>2024-12-05T10:30:35Z</published>
    <title>GenChaR: A Dataset for Stock Chart Captioning</title>
    <summary>  In this work, we introduce a new dataset GenChaR for an image captioning task
around stock charts. The task aims to read market sentiment directly from
depicted charts and generate descriptions, hopefully to provide comprehensible
and useful insights for stock trading. Impressed by the success of large
language models (LLMs), the study decides to pioneer itself by exploring the
capabilities of large vision-language models (LVLMs) on the proposed task. This
paper outlines the objectives of the stock captioning task, the dataset we
built, and automatic evaluation with some representative general-purpose LVLMs.
</summary>
    <author>
      <name>Le Qiu</name>
    </author>
    <author>
      <name>Emmanuele Chersoni</name>
    </author>
    <link href="http://arxiv.org/abs/2412.04041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.04041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.05168v1</id>
    <updated>2024-12-06T16:35:09Z</updated>
    <published>2024-12-06T16:35:09Z</published>
    <title>GRFsaw: A lightweight stochastic microstructure generator</title>
    <summary>  This article presents GRFsaw, an open-source software for generating
two-phase (binary) microstructures with user-defined structural properties.
Unlike most standard software for microstructure generation, GRFsaw is based on
the concept of thresholding Gaussian random fields (GRF). It is designed to be
used by researchers or engineers in need of a lightweight tool to generate
microstructures of various geometries, for example as input to simulations or
to other models where such geometries are needed. This could be simulations of
fluid flow through porous media, in predictive models of electromagnetic
scattering by materials, or in mechanical loading simulations in order to
assess, e.g., the material's elasticity or strength.
</summary>
    <author>
      <name>Lars Blatny</name>
    </author>
    <author>
      <name>Henning Löwe</name>
    </author>
    <author>
      <name>Johan Gaume</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures, code available on
  https://github.com/larsblatny/GRFsaw/</arxiv:comment>
    <link href="http://arxiv.org/abs/2412.05168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.05168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.05318v1</id>
    <updated>2024-12-03T03:52:05Z</updated>
    <published>2024-12-03T03:52:05Z</published>
    <title>X-RIS: A Study of the Principles and Applications of X-Shaped RIS</title>
    <summary>  This paper analyzes the working principle of X-Shaped reconfigurable
intelligent surface (RIS) in detail and reveals the different types of RIS that
can be designed based on this structure. Combined with the design examples
using this structure in the currently published articles, this paper summarizes
and organizes them, and finally, based on this X-Shaped structure, this paper
explores some other possible designs, which reflects the potential of the
design versatility of the X-RIS structure.
</summary>
    <author>
      <name>Xiaocun Zong</name>
    </author>
    <author>
      <name>Binchao Zhang</name>
    </author>
    <author>
      <name>Fan Yang</name>
    </author>
    <author>
      <name>Shenheng Xu</name>
    </author>
    <author>
      <name> Member</name>
    </author>
    <author>
      <name>Maokun Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:2410.14261</arxiv:comment>
    <link href="http://arxiv.org/abs/2412.05318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.05318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.09136v1</id>
    <updated>2024-12-12T10:15:41Z</updated>
    <published>2024-12-12T10:15:41Z</published>
    <title>Reducing Meshing Requirements for Electrostatic Problems using a
  Galerkin Boundary Element Method</title>
    <summary>  This work focuses on model preparation for electrostatic simulations of CAD
designs to realize a rapid virtual prototyping concept. We present a boundary
element method (BEM) allowing discontinuous fields between surfaces. The
corresponding edges of the CAD model are enhanced with the data required to
integrate over non-conforming elements. Finally, we generate a mesh for each
CAD surface. The approach is verified via numerical experiments and shows
excellent agreement with conforming BEM results.
</summary>
    <author>
      <name>Benjamin Marussig</name>
    </author>
    <author>
      <name>Thomas Rüberg</name>
    </author>
    <author>
      <name>Jürgen Zechner</name>
    </author>
    <author>
      <name>Lars Kielhorn</name>
    </author>
    <author>
      <name>Thomas-Peter Fries</name>
    </author>
    <link href="http://arxiv.org/abs/2412.09136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.09136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.12555v1</id>
    <updated>2024-12-17T05:30:29Z</updated>
    <published>2024-12-17T05:30:29Z</published>
    <title>Parameters Optimization of Pair Trading Algorithm</title>
    <summary>  Pair trading is a market-neutral quantitative trading strategy that exploits
price anomalies between two correlated assets. By taking simultaneous long and
short positions, it generates profits based on relative price movements,
independent of overall market trends. This study explores the mathematical
foundations of pair trading, focusing on identifying cointegrated pairs,
constructing trading signals, and optimizing model parameters to maximize
returns. The results highlight the strategy's potential for consistent
profitability even in volatile market conditions.
</summary>
    <author>
      <name>Charles Barthelemy</name>
    </author>
    <author>
      <name>Ruoyu Chen</name>
    </author>
    <author>
      <name>Edward Lucyszyn</name>
    </author>
    <link href="http://arxiv.org/abs/2412.12555v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.12555v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.04340v1</id>
    <updated>2025-01-08T08:25:51Z</updated>
    <published>2025-01-08T08:25:51Z</published>
    <title>On Domain Decomposition for Magnetostatic Problems in 3D</title>
    <summary>  The simulation of three dimensional magnetostatic problems plays an important
role, for example when simulating synchronous electric machines. Building on
prior work that developed a domain decomposition algorithm using isogeometric
analysis, this paper extends the method to support subdomains composed of
multiple patches. This extension enables load-balancing across available CPUs,
facilitated by graph partitioning tools such as METIS. The proposed approach
enhances scalability and flexibility, making it suitable for large-scale
simulations in diverse industrial contexts.
</summary>
    <author>
      <name>Mario Mally</name>
    </author>
    <author>
      <name>Melina Merkel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of proceedings-paper of ICCE2024 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2501.04340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.04340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.05848v1</id>
    <updated>2025-01-10T10:38:57Z</updated>
    <published>2025-01-10T10:38:57Z</published>
    <title>Isogeometric Analysis for 2D Magnetostatic Computations with Multi-level
  Bézier Extraction for Local Refinement</title>
    <summary>  Local refinement is vital for efficient numerical simulations. In the context
of Isogeometric Analysis (IGA), hierarchical B-splines have gained prominence.
The work applies the methodology of truncated hierarchical B-splines
(THB-splines) as they keep additional properties. The framework is further
enriched with B\'{e}zier extraction, resulting in the multi-level B\'{e}zier
extraction method. We apply this discretization method to 2D magnetostatic
problems. The implementation is based on an open-source Octave/MATLAB IGA code
called GeoPDEs, which allows us to compare our routines with globally refined
spline models as well as locally refined ones where the solver does not rely on
B\'{e}zier extraction.
</summary>
    <author>
      <name>Andreas Grendas</name>
    </author>
    <author>
      <name>Michael Wiesheu</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Benjamin Marussig</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.23967/eccomas.2024.097</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.23967/eccomas.2024.097" rel="related"/>
    <link href="http://arxiv.org/abs/2501.05848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.05848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.07701v1</id>
    <updated>2025-01-13T21:26:47Z</updated>
    <published>2025-01-13T21:26:47Z</published>
    <title>Active Learning Enhanced Surrogate Modeling of Jet Engines in JuliaSim</title>
    <summary>  Surrogate models are effective tools for accelerated design of complex
systems. The result of a design optimization procedure using surrogate models
can be used to initialize an optimization routine using the full order system.
High accuracy of the surrogate model can be advantageous for fast convergence.
In this work, we present an active learning approach to produce a very high
accuracy surrogate model of a turbofan jet engine, that demonstrates 0.1\%
relative error for all quantities of interest. We contrast this with a
surrogate model produced using a more traditional brute-force data generation
approach.
</summary>
    <author>
      <name>Anas Abdelrehim</name>
    </author>
    <author>
      <name>Dhairya Gandhi</name>
    </author>
    <author>
      <name>Sharan Yalburgi</name>
    </author>
    <author>
      <name>Ashutosh Bharambe</name>
    </author>
    <author>
      <name>Ranjan Anantharaman</name>
    </author>
    <author>
      <name>Chris Rackauckas</name>
    </author>
    <link href="http://arxiv.org/abs/2501.07701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.07701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.12583v1</id>
    <updated>2025-01-22T02:13:55Z</updated>
    <published>2025-01-22T02:13:55Z</published>
    <title>Chasing price drains liquidity</title>
    <summary>  Assuming that the price in a Uniswap v3 style Automated Market Maker (AMM)
follows a Geometric Brownian Motion (GBM), we prove that the strategy that
adjusts the position of liquidity to track the current price leads to a
deterministic and exponentially fast decay of liquidity. Next, assuming that
there is a Centralized Exchange (CEX), in which the price follows a GBM and the
AMM price mean reverts to the CEX price, we show numerically that the same
strategy still leads to decay. Last, we propose a strategy that increases the
liquidity even without compounding fees earned through liquidity provision.
</summary>
    <author>
      <name>Yizhou Cao</name>
    </author>
    <author>
      <name>Yepeng Ding</name>
    </author>
    <author>
      <name>Ruichao Jiang</name>
    </author>
    <author>
      <name>Long Wen</name>
    </author>
    <link href="http://arxiv.org/abs/2501.12583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.12583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.06238v1</id>
    <updated>2025-02-10T08:18:04Z</updated>
    <published>2025-02-10T08:18:04Z</published>
    <title>XNet-Enhanced Deep BSDE Method and Numerical Analysis</title>
    <summary>  Solving high-dimensional semilinear parabolic partial differential equations
(PDEs) challenges traditional numerical methods due to the "curse of
dimensionality." Deep learning, particularly through the Deep BSDE method,
offers a promising alternative by leveraging neural networks' capability to
approximate high-dimensional functions. This paper introduces a novel network
architecture, XNet, which significantly enhances the computational efficiency
and accuracy of the Deep BSDE method. XNet demonstrates superior approximation
capabilities with fewer parameters, addressing the trade-off between
approximation and optimization errors found in existing methods. We detail the
implementation of XNet within the Deep BSDE framework and present results that
show marked improvements in solving high-dimensional PDEs, potentially setting
a new standard for such computations.
</summary>
    <author>
      <name>Xiaotao Zheng</name>
    </author>
    <author>
      <name>Zhihong Xia</name>
    </author>
    <author>
      <name>Xin Li</name>
    </author>
    <author>
      <name>Xingye Yue</name>
    </author>
    <link href="http://arxiv.org/abs/2502.06238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.06238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.07791v1</id>
    <updated>2025-01-21T10:32:50Z</updated>
    <published>2025-01-21T10:32:50Z</published>
    <title>Simple demonstration of different types of coupling in multiphysics
  numerical problems</title>
    <summary>  Numerical modelling of coupled multiphysics phenomena is becoming an
increasingly important subject in applied mathematics. The main challenge in
teaching this subject is the complexity of both the mathematical models and
their numerical implementation. In this note, a simple demonstrator is proposed
that enables demonstration of and some hands-on experience with three types of
coupling commonly used in computational science: one-way coupling, explicit
sequential coupling, and full coupling. It makes use of a familiar nonlinear
heat equation in 1D, with the solution being a propagating heat wave.
</summary>
    <author>
      <name>Alexandre Lavrov</name>
    </author>
    <link href="http://arxiv.org/abs/2502.07791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.07791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.16518v1</id>
    <updated>2025-02-23T09:47:42Z</updated>
    <published>2025-02-23T09:47:42Z</published>
    <title>A data-constrained sharp Immersed Boundary Method for aerospace
  applications</title>
    <summary>  A numerical tool relying on sharp Immersed Boundary Method (IBM) is developed
for the analysis of aerospace applications. The method, which is conceived for
application using segregated solvers relying on implicit time discretization,
uses a Luenberger observer to dynamically update the free coefficients
governing the numerical algorithm. This technique improves the accuracy of the
method and permits to target the representation of complex flow features at the
wall, taking into account the velocity field and heat transfer. The method is
used to investigate several test cases of increasing complexity, including a
space vehicle during atmospheric reentry. The tool exhibits interesting
efficacy in terms of accuracy versus computational costs required.
</summary>
    <author>
      <name>M. A. Chemak</name>
    </author>
    <author>
      <name>E. Constant</name>
    </author>
    <author>
      <name>M. Meldi</name>
    </author>
    <link href="http://arxiv.org/abs/2502.16518v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.16518v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.00201v1</id>
    <updated>2025-02-28T21:39:15Z</updated>
    <published>2025-02-28T21:39:15Z</published>
    <title>Path Dependence in AMM-Based Markets: Mathematical Proof and
  Implications for Truth Discovery</title>
    <summary>  This paper demonstrates that Automated Market Maker (AMM) based markets, such
as those using constant product formulas (e.g., Uniswap), are inherently
path-dependent. We prove mathematically that the sequence of operations in AMMs
determines the final state, challenging the notion that market prices solely
reflect information. This property has profound implications for decentralized
prediction markets that rely on AMMs for price discovery, as it demonstrates
they cannot function as pure "truth machines." Using both mathematical proofs
and empirical evidence from ETH/USDC pools, we show that AMM-based markets
incorporate historical path information beyond the current market beliefs. Our
findings contribute to the understanding of market efficiency, mechanism
design, and the interpretation of prices in decentralized finance systems.
</summary>
    <author>
      <name>Keroshan Pillay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Adjusted Finance</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.00201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.00201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.04061v1</id>
    <updated>2025-03-06T03:36:31Z</updated>
    <published>2025-03-06T03:36:31Z</published>
    <title>High order hybridizable discontinuous Galerkin method for three-phase
  flow in porous media</title>
    <summary>  We present a high-order hybridizable discontinuous Galerkin method for the
numerical solution of time-dependent three-phase flow in heterogeneous porous
media. The underlying algorithm is a semi-implicit operator splitting approach
that relaxes the nonlinearity present in the governing equations. By treating
the subsequent equations implicitly, we obtain solution that remain stable for
large time steps. The hybridizable discontinuous Galerkin method allows for
static condensation, which significantly reduces the total number of degrees of
freedom, especially when compared to classical discontinuous Galerkin methods.
Several numerical tests are given, for example, we verify analytic convergence
rates for the method, as well as examine its robustness in both homogeneous and
heterogeneous porous media.
</summary>
    <author>
      <name>Maurice S. Fabien</name>
    </author>
    <link href="http://arxiv.org/abs/2503.04061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.04061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.05726v1</id>
    <updated>2025-02-18T01:11:10Z</updated>
    <published>2025-02-18T01:11:10Z</published>
    <title>The computation of average kernel with Gauss-Laguerre quadrature for
  double integrals</title>
    <summary>  The use of average kernel method based on the Laplace transformation can
significantly simplify the procedure for obtaining approximate analytical
solution of Smoluchowski equation. However, this method also has its own
shortcomings, one of which is the higher computational complexity of the binary
Laplace transformation for a nonlinear collision kernel. In this study, a
universal algorithm based on the Gauss-Laguerre quadrature for treating the
double integral is developed to obtain easily and quickly pre-exponential
factor of the average kernel. Furthermore, the corresponding truncation error
estimate also provided.
</summary>
    <author>
      <name>Kejun Pan</name>
    </author>
    <author>
      <name>Mingliang Xie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:2502.13377,
  arXiv:2502.13378</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.05726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.05726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.16407v1</id>
    <updated>2025-03-20T17:58:12Z</updated>
    <published>2025-03-20T17:58:12Z</published>
    <title>Deep Feynman-Kac Methods for High-dimensional Semilinear Parabolic
  Equations: Revisit</title>
    <summary>  Deep Feynman-Kac method was first introduced to solve parabolic partial
differential equations(PDE) by Beck et al. (SISC, V.43, 2021), named Deep
Splitting method since they trained the Neural Networks step by step in the
time direction. In this paper, we propose a new training approach with two
different features. Firstly, neural networks are trained at all time steps
globally, instead of step by step. Secondly, the training data are generated in
a new way, in which the method is consistent with a direct Monte Carlo scheme
when dealing with a linear parabolic PDE. Numerical examples show that our
method has significant improvement both in efficiency and accuracy.
</summary>
    <author>
      <name>Xiaotao Zheng</name>
    </author>
    <author>
      <name>Xingye Yue</name>
    </author>
    <author>
      <name>Jiyang Shi</name>
    </author>
    <link href="http://arxiv.org/abs/2503.16407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.16407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.02748v1</id>
    <updated>2025-04-03T16:35:49Z</updated>
    <published>2025-04-03T16:35:49Z</published>
    <title>Atrial constitutive neural networks</title>
    <summary>  This work presents a novel approach for characterizing the mechanical
behavior of atrial tissue using constitutive neural networks. Based on
experimental biaxial tensile test data of healthy human atria, we automatically
discover the most appropriate constitutive material model, thereby overcoming
the limitations of traditional, pre-defined models. This approach offers a new
perspective on modeling atrial mechanics and is a significant step towards
improved simulation and prediction of cardiac health.
</summary>
    <author>
      <name>Mathias Peirlinck</name>
    </author>
    <author>
      <name>Kevin Linka</name>
    </author>
    <author>
      <name>Ellen Kuhl</name>
    </author>
    <link href="http://arxiv.org/abs/2504.02748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.02748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.03070v1</id>
    <updated>2025-04-03T22:48:57Z</updated>
    <published>2025-04-03T22:48:57Z</published>
    <title>Adaptive Finite State Projection with Quantile-Based Pruning for Solving
  the Chemical Master Equation</title>
    <summary>  We present an adaptive Finite State Projection (FSP) method for efficiently
solving the Chemical Master Equation (CME) with rigorous error control. Our
approach integrates time-stepping with dynamic state-space truncation,
balancing accuracy and computational cost. Krylov subspace methods approximate
the matrix exponential, while quantile-based pruning controls state-space
growth by removing low-probability states. Theoretical error bounds ensure that
the truncation error remains bounded by the pruned mass at each step, which is
user-controlled, and does not propagate forward in time. Numerical experiments
on biochemical systems, including the Lotka-Volterra and Michaelis-Menten and
bi-stable toggle switch models.
</summary>
    <author>
      <name>Aditya Dendukuri</name>
    </author>
    <author>
      <name>Linda Petzold</name>
    </author>
    <link href="http://arxiv.org/abs/2504.03070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.03070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.04541v1</id>
    <updated>2025-04-06T16:41:29Z</updated>
    <published>2025-04-06T16:41:29Z</published>
    <title>A model agnostic eXplainable AI based fuzzy framework for sensor
  constrained Aerospace maintenance applications</title>
    <summary>  Machine Learning methods have extensively evolved to support industrial big
data methods and their corresponding need in gas turbine maintenance and
prognostics. However, most unsupervised methods need extensively labeled data
to perform predictions across many dimensions. The cutting edge of small and
medium applications do not necessarily maintain operational sensors and data
acquisition with rising costs and diminishing profits. We propose a framework
to make sensor maintenance priority decisions using a combination of SHAP,
UMAP, Fuzzy C-means clustering. An aerospace jet engine dataset is used as a
case study.
</summary>
    <author>
      <name>Bharadwaj Dogga</name>
    </author>
    <author>
      <name>Anoop Sathyan</name>
    </author>
    <author>
      <name>Kelly Cohen</name>
    </author>
    <link href="http://arxiv.org/abs/2504.04541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.04541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.07111v1</id>
    <updated>2025-03-18T23:24:37Z</updated>
    <published>2025-03-18T23:24:37Z</published>
    <title>High-Performance Gradient Evaluation for Complex Soft Materials Using
  MPI-based DFS Algorithm</title>
    <summary>  This article presents a depth-first search (DFS)-based algorithm for
evaluating sensitivity gradients in the topology optimization of soft materials
exhibiting complex deformation behavior. The algorithm is formulated using a
time-dependent adjoint sensitivity approach and is implemented within a
PETSc-based C++ MPI framework for efficient parallel computing. It has been
found that on a single processor, the sensitivity analysis for these complex
materials can take approximately 45 minutes. This necessitates the use of
high-performance computing (HPC) to achieve feasible optimization times. This
work provides insights into the algorithmic framework and its application to
large-scale generative design for physics integrated simulation of soft
materials under complex loading conditions.
</summary>
    <author>
      <name>Anurag Bhattacharyya</name>
    </author>
    <link href="http://arxiv.org/abs/2504.07111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.07111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.18024v1</id>
    <updated>2025-04-25T02:29:56Z</updated>
    <published>2025-04-25T02:29:56Z</published>
    <title>SMARTFinRAG: Interactive Modularized Financial RAG Benchmark</title>
    <summary>  Financial sectors are rapidly adopting language model technologies, yet
evaluating specialized RAG systems in this domain remains challenging. This
paper introduces SMARTFinRAG, addressing three critical gaps in financial RAG
assessment: (1) a fully modular architecture where components can be
dynamically interchanged during runtime; (2) a document-centric evaluation
paradigm generating domain-specific QA pairs from newly ingested financial
documents; and (3) an intuitive interface bridging research-implementation
divides. Our evaluation quantifies both retrieval efficacy and response
quality, revealing significant performance variations across configurations.
The platform's open-source architecture supports transparent, reproducible
research while addressing practical deployment challenges faced by financial
institutions implementing RAG systems.
</summary>
    <author>
      <name>Yiwei Zha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For open source github repo, see
  https://github.com/JonathanZha47/SMARTFinRAG</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.18024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.0673v1</id>
    <updated>2009-02-04T09:07:16Z</updated>
    <published>2009-02-04T09:07:16Z</published>
    <title>Optimal profiles in variable speed flows</title>
    <summary>  Where a 2D problem of optimal profile in variable speed flow is resolved in a
class of convex Bezier curves, using symbolic and numerical computations.
</summary>
    <author>
      <name>Gianluca Argentini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.0673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.0673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5273v2</id>
    <updated>2013-02-05T18:25:26Z</updated>
    <published>2013-01-20T02:02:30Z</published>
    <title>Using Periodicity of Nucleotide Sequences</title>
    <summary>  Withdrawn by arXiv administrators due to content entirely plagiarized from
other authors (not in arXiv).
</summary>
    <author>
      <name>Rick B. Jenison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: entirely plagiarized from
  http://www.ncbi.nlm.nih.gov/pubmed/19261626</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.5273v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5273v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6341v1</id>
    <updated>2014-12-19T13:45:26Z</updated>
    <published>2014-12-19T13:45:26Z</published>
    <title>Connectome graphs and maximum flow problems</title>
    <summary>  We propose to study maximum flow problems for connectome graphs. We suggest a
few computational problems: finding vertex pairs with maximal flow, finding new
edges which would increase the maximal flow. Initial computation results for
some publicly available connectome graphs are described.
</summary>
    <author>
      <name>Peteris Daugulis</name>
    </author>
    <link href="http://arxiv.org/abs/1412.6341v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6341v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07760v1</id>
    <updated>2017-06-05T15:27:16Z</updated>
    <published>2017-06-05T15:27:16Z</published>
    <title>A Possibilistic and Probabilistic Approach to Precautionary Saving</title>
    <summary>  This paper proposes two mixed models to study a consumer's optimal saving in
the presence of two types of risk.
</summary>
    <author>
      <name>Irina Georgescu</name>
    </author>
    <author>
      <name>Adolfo Cristóbal Campoamor</name>
    </author>
    <author>
      <name>Ana Maria Lucia Casademunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Panoeconomicus, 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0203591v1</id>
    <updated>2002-03-28T12:29:24Z</updated>
    <published>2002-03-28T12:29:24Z</published>
    <title>Anticorrelations and subdiffusion in financial systems</title>
    <summary>  Statistical dynamics of financial systems is investigated, based on a model
of a randomly coupled equation system driven by a stochastic Langevin force.
Anticorrelations of price returns, and subdiffusion of prices is found from the
model, and and compared with those calculated from historical $/EURO exchange
rates.
</summary>
    <author>
      <name>Kestutis Staliunas</name>
    </author>
    <link href="http://arxiv.org/abs/cond-mat/0203591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0203591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0209020v1</id>
    <updated>2002-09-18T12:45:43Z</updated>
    <published>2002-09-18T12:45:43Z</published>
    <title>A new definition of the fractional Laplacian</title>
    <summary>  It is noted that the standard definition of the fractional Laplacian leads to
a hyper-singular convolution integral and is also obscure about how to
implement the boundary conditions. This purpose of this note is to introduce a
new definition of the fractional Laplacian to overcome these major drawbacks.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This study is carred out with the ongoing project of "mathematical
  and numerical modelling of medical ultasound wave propagation" sponsored by
  the Simula Research Laboratory</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0209020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0209020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; G.1.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502015v1</id>
    <updated>2005-02-03T17:28:01Z</updated>
    <published>2005-02-03T17:28:01Z</published>
    <title>Can Computer Algebra be Liberated from its Algebraic Yoke ?</title>
    <summary>  So far, the scope of computer algebra has been needlessly restricted to exact
algebraic methods. Its possible extension to approximate analytical methods is
discussed. The entangled roles of functional analysis and symbolic programming,
especially the functional and transformational paradigms, are put forward. In
the future, algebraic algorithms could constitute the core of extended symbolic
manipulation systems including primitives for symbolic approximations.
</summary>
    <author>
      <name>R. Barrere</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2-column presentation, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0502015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; I.1; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609079v4</id>
    <updated>2009-07-29T10:03:56Z</updated>
    <published>2006-09-14T12:34:59Z</published>
    <title>Modern Statistics by Kriging</title>
    <summary>  We present statistics (S-statistics) based only on random variable (not
random value) with a mean squared error of mean estimation as a concept of
error.
</summary>
    <author>
      <name>Tomasz Suslo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609079v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609079v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/quant-ph/0308158v1</id>
    <updated>2003-08-28T16:02:25Z</updated>
    <published>2003-08-28T16:02:25Z</published>
    <title>New Approachs to Quantum Computer Simulaton in a Classical Supercomputer</title>
    <summary>  Classical simulation is important because it sets a benchmark for quantum
computer performance. Classical simulation is currently the only way to
exercise larger numbers of qubits. To achieve larger simulations, sparse matrix
processing is emphasized below while trading memory for processing. It
performed well within NCSA supercomputers, giving a state vector in convenient
continuous portions ready for post processing.
</summary>
    <author>
      <name>John Robert Burger</name>
    </author>
    <link href="http://arxiv.org/abs/quant-ph/0308158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/quant-ph/0308158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.0952v1</id>
    <updated>2009-03-05T10:45:51Z</updated>
    <published>2009-03-05T10:45:51Z</published>
    <title>Definition of Strange Attractor in Benard problem for Generalized
  Couette Cell</title>
    <summary>  For movements of the viscous continuous flow in generalized Couette cell the
dynamic system describing the central limiting variety is received.
</summary>
    <author>
      <name>V. V. Gotsulenko</name>
    </author>
    <author>
      <name>L. A. Gaponova</name>
    </author>
    <author>
      <name>P. I. Kogut</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, exposed on 2nd "European Conference on Computer Science and
  Applications" - XA2008, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 95-100</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.0952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.0952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.2448v1</id>
    <updated>2009-04-16T09:12:06Z</updated>
    <published>2009-04-16T09:12:06Z</published>
    <title>All that Glisters is not Galled</title>
    <summary>  Galled trees, evolutionary networks with isolated reticulation cycles, have
appeared under several slightly different definitions in the literature. In
this paper we establish the actual relationships between the main four such
alternative definitions: namely, the original galled trees, level-1 networks,
nested networks with nesting depth 1, and evolutionary networks with
arc-disjoint reticulation cycles.
</summary>
    <author>
      <name>Francesc Rossello</name>
    </author>
    <author>
      <name>Gabriel Valiente</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.2448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.2448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.3558v2</id>
    <updated>2011-08-18T08:29:07Z</updated>
    <published>2011-08-17T19:41:29Z</published>
    <title>Proceedings of the 5th Workshop on Membrane Computing and Biologically
  Inspired Process Calculi (MeCBIC 2011)</title>
    <summary>  This volume represents the proceedings of the 5th Workshop on Membrane
Computing and Biologically Inspired Process Calculi (MeCBIC 2011), held
together with the 12th International Conference on Membrane Computing on 23rd
August 2011 in Fontainebleau, France.
</summary>
    <author>
      <name>Gabriel Ciobanu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Papers presented at MeCBIC 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.3558v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.3558v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1608v1</id>
    <updated>2013-04-05T03:35:40Z</updated>
    <published>2013-04-05T03:35:40Z</published>
    <title>Simulating DNLS models</title>
    <summary>  We present different techniques to numerically solve the equations of motion
for the widely studied Discrete Nonlinear Schroedinger equation (DNLS). Being a
Hamiltonian system, the DNLS requires symplectic routines for an efficient
numerical treatment. Here, we introduce different such schemes in detail and
compare their performance and accuracy by extensive numerical simulations.
</summary>
    <author>
      <name>Mario Mulansky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1204v2</id>
    <updated>2013-09-06T19:35:43Z</updated>
    <published>2013-09-04T23:03:33Z</published>
    <title>Achieving High Performance with Unified Residual Evaluation</title>
    <summary>  We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code.
</summary>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Jed Brown</name>
    </author>
    <author>
      <name>Karl Rupp</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1204v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1204v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5271v1</id>
    <updated>2013-12-18T19:21:24Z</updated>
    <published>2013-12-18T19:21:24Z</published>
    <title>Systematic and multifactor risk models revisited</title>
    <summary>  Systematic and multifactor risk models are revisited via methods which were
already successfully developed in signal processing and in automatic control.
The results, which bypass the usual criticisms on those risk modeling, are
illustrated by several successful computer experiments.
</summary>
    <author>
      <name>Michel Fliess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIX, AL.I.E.N.</arxiv:affiliation>
    </author>
    <author>
      <name>Cédric Join</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AL.I.E.N., CRAN, INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First Paris Financial Management Conference, Paris : France (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0968v1</id>
    <updated>2014-06-04T08:25:56Z</updated>
    <published>2014-06-04T08:25:56Z</published>
    <title>Integration of a Predictive, Continuous Time Neural Network into
  Securities Market Trading Operations</title>
    <summary>  This paper describes recent development and test implementation of a
continuous time recurrent neural network that has been configured to predict
rates of change in securities. It presents outcomes in the context of popular
technical analysis indicators and highlights the potential impact of continuous
predictive capability on securities market trading operations.
</summary>
    <author>
      <name>Christopher S Kirk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2905v1</id>
    <updated>2014-07-10T19:08:32Z</updated>
    <published>2014-07-10T19:08:32Z</published>
    <title>Run-time extensibility and librarization of simulation software</title>
    <summary>  Build-time configuration and environment assumptions are hampering progress
and usability in scientific software. That which would be utterly unacceptable
in non-scientific software somehow passes for the norm in scientific packages.
The community needs reusable software packages that are easy use and flexible
enough to accommodate next-generation simulation and analysis demands.
</summary>
    <author>
      <name>Jed Brown</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <author>
      <name>Barry F. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06102v1</id>
    <updated>2015-01-25T01:42:09Z</updated>
    <published>2015-01-25T01:42:09Z</published>
    <title>Development of a Big Data Framework for Connectomic Research</title>
    <summary>  This paper outlines research and development of a new Hadoop-based
architecture for distributed processing and analysis of electron microscopy of
brains. We show development of a new C++ library for implementation of 3D image
analysis techniques, and deployment in a distributed map/reduce framework. We
demonstrate our new framework on a subset of the Kasthuri11 dataset from the
Open Connectome Project.
</summary>
    <author>
      <name>Terrence Adams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4; F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01263v1</id>
    <updated>2015-12-03T22:01:11Z</updated>
    <published>2015-12-03T22:01:11Z</published>
    <title>A Monte Carlo method for the spread of mobile malware</title>
    <summary>  A new model for the spread of mobile malware based on proximity (i.e.
Bluetooth, ad-hoc WiFi or NFC) is introduced. The spread of malware is analyzed
using a Monte Carlo method and the results of the simulation are compared with
those from mean field theory.
</summary>
    <author>
      <name>Alberto Berretti</name>
    </author>
    <author>
      <name>Simone Ciccarone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.02788v1</id>
    <updated>2018-01-09T04:13:11Z</updated>
    <published>2018-01-09T04:13:11Z</published>
    <title>Sequential Preference-Based Optimization</title>
    <summary>  Many real-world engineering problems rely on human preferences to guide their
design and optimization. We present PrefOpt, an open source package to simplify
sequential optimization tasks that incorporate human preference feedback. Our
approach extends an existing latent variable model for binary preferences to
allow for observations of equivalent preference from users.
</summary>
    <author>
      <name>Ian Dewancker</name>
    </author>
    <author>
      <name>Jakob Bauer</name>
    </author>
    <author>
      <name>Michael McCourt</name>
    </author>
    <link href="http://arxiv.org/abs/1801.02788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.02788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.01361v2</id>
    <updated>2018-10-03T09:40:53Z</updated>
    <published>2018-10-02T16:38:07Z</published>
    <title>Validation of a PETSc based software implementing a 4DVAR Data
  Assimilation algorithm: a case study related with an Oceanic Model based on
  Shallow Water equation</title>
    <summary>  In this work are presented and discussed some results related to the
validation process of a software module based on PETSc which implements a Data
Assimilation algorithm.
</summary>
    <author>
      <name>Luisa Carracciuolo</name>
    </author>
    <author>
      <name>Emil M. Constantinescu</name>
    </author>
    <author>
      <name>Luisa D'Amore</name>
    </author>
    <link href="http://arxiv.org/abs/1810.01361v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.01361v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.05753v1</id>
    <updated>2018-11-14T12:52:26Z</updated>
    <published>2018-11-14T12:52:26Z</published>
    <title>How to get meaningful and correct results from your finite element model</title>
    <summary>  This document gives guidelines to set up, run, and postprocess correct
simulations with the finite element method. It is not an introduction to the
method itself, but rather a list of things to check and possible mistakes to
watch out for when doing a finite element simulation.
</summary>
    <author>
      <name>Martin Bäker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.05753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.05753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06879v1</id>
    <updated>2019-05-16T16:05:52Z</updated>
    <published>2019-05-16T16:05:52Z</published>
    <title>Multigrid-reduction-in-time for Eddy Current problems</title>
    <summary>  Parallel-in-time methods have shown success for reducing the simulation time
of many time-dependent problems. Here, we consider applying the
multigrid-reduction-in-time (MGRIT) algorithm to a voltage-driven eddy current
model problem.
</summary>
    <author>
      <name>Stephanie Friedhoff</name>
    </author>
    <author>
      <name>Jens Hahne</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/pamm.201900262</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/pamm.201900262" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contribution from GAMM 2019 conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. Appl. Math. Mech., 19: e201900262, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.06879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L05, 65L20, 65L80, 65M12, 78M10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.8; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.11098v1</id>
    <updated>2020-07-14T12:41:22Z</updated>
    <published>2020-07-14T12:41:22Z</published>
    <title>Generating Trading Signals by ML algorithms or time series ones?</title>
    <summary>  This research investigates efficiency on-line learning Algorithms to generate
trading signals.I employed technical indicators based on high frequency stock
prices and generated trading signals through ensemble of Random Forests.
Similarly, Kalman Filter was used for signaling trading positions. Comparing
Time Series methods with Machine Learning methods, results spurious of Kalman
Filter to Random Forests in case of on-line learning predictions of stock
prices
</summary>
    <author>
      <name>Omid Safarzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 Pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.11098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.11098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.11677v1</id>
    <updated>2022-01-27T17:24:06Z</updated>
    <published>2022-01-27T17:24:06Z</published>
    <title>Parallel black-box optimization of expensive high-dimensional multimodal
  functions via magnitude</title>
    <summary>  Building on the recently developed theory of magnitude, we introduce the
optimization algorithm EXPLO2 and carefully benchmark it. EXPLO2 advances the
state of the art for optimizing high-dimensional ($D \gtrapprox 40$) multimodal
functions that are expensive to compute and for which derivatives are not
available, such as arise in hyperparameter optimization or via simulations.
</summary>
    <author>
      <name>Steve Huntsman</name>
    </author>
    <link href="http://arxiv.org/abs/2201.11677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.11677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90-08" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.09311v1</id>
    <updated>2023-07-18T14:56:12Z</updated>
    <published>2023-07-18T14:56:12Z</published>
    <title>Automatic Differentiation for Inverse Problems with Applications in
  Quantum Transport</title>
    <summary>  A neural solver and differentiable simulation of the quantum transmitting
boundary model is presented for the inverse quantum transport problem. The
neural solver is used to engineer continuous transmission properties and the
differentiable simulation is used to engineer current-voltage characteristics.
</summary>
    <author>
      <name>Ivan Williams</name>
    </author>
    <author>
      <name>Eric Polizzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.09311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.09311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.13900v1</id>
    <updated>2023-10-21T03:34:48Z</updated>
    <published>2023-10-21T03:34:48Z</published>
    <title>Private Proof of Solvency</title>
    <summary>  The Private Proof of Solvency is a groundbreaking solution in the realm of
Proof of Solvency, offering a secure, efficient, and privacy-preserving method
for crypto custody providers such as centralized cryptocurrency exchanges or
enterprise custody providers. By leveraging the inherent state concept of every
blockchain and pioneering cryptographic techniques like zkp, our approach
ensures businesses can prove their reserves without revealing their
transactions, addresses, or the total amount of liabilities.
</summary>
    <author>
      <name>Hamid Bateni</name>
    </author>
    <author>
      <name>Keyvan Kambakhsh</name>
    </author>
    <link href="http://arxiv.org/abs/2310.13900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.13900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.10039v1</id>
    <updated>2023-11-16T17:36:28Z</updated>
    <published>2023-11-16T17:36:28Z</published>
    <title>Software Dependability Measurement at the Age Of 36</title>
    <summary>  Thirty-six years after the first edition of IEEE standard 982.1, Measures of
the Software Aspects of Dependability, the third edition focuses on the
measurement of in-service software dependability. This article explains how
this new point of view evolved and shaped the third edition's guidance for
software dependability measurement.
</summary>
    <author>
      <name>Robert V. Binder</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MC.2023.3327668</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MC.2023.3327668" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures. Accepted for publication in IEEE Computer, April
  2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2311.10039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.10039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9902024v1</id>
    <updated>1999-02-11T13:13:04Z</updated>
    <published>1999-02-11T13:13:04Z</published>
    <title>Algorithms of Two-Level Parallelization for DSMC of Unsteady Flows in
  Molecular Gasdynamics</title>
    <summary>  The general scheme of two-level parallelization (TLP) for direct simulation
Monte Carlo of unsteady gas flows on shared memory multiprocessor computers has
been described. The high efficient algorithm of parallel independent runs is
used on the first level. The data parallelization is employed for the second
one. Two versions of TLP algorithm are elaborated with static and dynamic load
balancing. The method of dynamic processor reallocation is used for dynamic
load balancing. Two gasdynamic unsteady problems were used to study speedup and
efficiency of the algorithms. The conditions of efficient application field for
the algorithms have been determined.
</summary>
    <author>
      <name>Alexander V. Bogdanov</name>
    </author>
    <author>
      <name>Nick Yu. Bykov</name>
    </author>
    <author>
      <name>Igor A. Grishin</name>
    </author>
    <author>
      <name>Gregory O. Khanlarov</name>
    </author>
    <author>
      <name>German A. Lukianov</name>
    </author>
    <author>
      <name>Vladimir V. Zakharov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 17 postscript figures Submitted to the conference HPCN
  Europe 99</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9902024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9902024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0;G.3;I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906012v1</id>
    <updated>1999-06-09T12:47:13Z</updated>
    <published>1999-06-09T12:47:13Z</published>
    <title>The application of special matrix product to differential quadrature
  solution of geometrically nonlinear bending of orthotropic rectangular plates</title>
    <summary>  The Hadamard and SJT product of matrices are two types of special matrix
product. The latter was first defined by Chen. In this study, they are applied
to the differential quadrature (DQ) solution of geometrically nonlinear bending
of isotropic and orthotropic rectangular plates. By using the Hadamard product,
the nonlinear formulations are greatly simplified, while the SJT product
approach minimizes the effort to evaluate the Jacobian derivative matrix in the
Newton-Raphson method for solving the resultant nonlinear formulations. In
addition, the coupled nonlinear formulations for the present problems can
easily be decoupled by means of the Hadamard and SJT product. Therefore, the
size of the simultaneous nonlinear algebraic equations is reduced by two-thirds
and the computing effort and storage requirements are alleviated greatly. Two
recent approaches applying the multiple boundary conditions are employed in the
present DQ nonlinear computations. The solution accuracies are improved
obviously in comparison to the previously given by Bert et al. The numerical
results and detailed solution procedures are provided to demonstrate the superb
efficiency, accuracy and simplicity of the new approaches in applying DQ method
for nonlinear computations.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>C. Shu</name>
    </author>
    <author>
      <name>W. He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to chenw@homer.shinshu-u.ac.jp or
  chenwwhy@hotmail.com</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.1.5; G.1.2; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907043v1</id>
    <updated>1999-07-30T08:35:55Z</updated>
    <published>1999-07-30T08:35:55Z</published>
    <title>A simple C++ library for manipulating scientific data sets as structured
  data</title>
    <summary>  Representing scientific data sets efficiently on external storage usually
involves converting them to a byte string representation using specialized
reader/writer routines. The resulting storage files are frequently difficult to
interpret without these specialized routines as they do not contain information
about the logical structure of the data. Avoiding such problems usually
involves heavy-weight data format libraries or data base systems. We present a
simple C++ library that allows to create and access data files that store
structured data. The structure of the data is described by a data type that can
be built from elementary data types (integer and floating-point numbers, byte
strings) and composite data types (arrays, structures, unions). An abstract
data access class presents the data to the application. Different actual data
file structures can be implemented under this layer. This method is
particularly suited to applications that require complex data structures, e.g.
molecular dynamics simulations. Extensions such as late type binding and object
persistence are discussed.
</summary>
    <author>
      <name>Christoph Best</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ZIB, Berlin, and J. v. Neumann Institute, Juelich</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, LaTeX. Also available at
  http://www.zib.de/PaperWeb/abstracts/TR-98-06/</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9907043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0010010v1</id>
    <updated>2000-10-03T17:54:38Z</updated>
    <published>2000-10-03T17:54:38Z</published>
    <title>Fault Detection using Immune-Based Systems and Formal Language
  Algorithms</title>
    <summary>  This paper describes two approaches for fault detection: an immune-based
mechanism and a formal language algorithm. The first one is based on the
feature of immune systems in distinguish any foreign cell from the body own
cell. The formal language approach assumes the system as a linguistic source
capable of generating a certain language, characterised by a grammar. Each
algorithm has particular characteristics, which are analysed in the paper,
namely in what cases they can be used with advantage. To test their
practicality, both approaches were applied on the problem of fault detection in
an induction motor.
</summary>
    <author>
      <name>J. F. Martins</name>
    </author>
    <author>
      <name>P. J. Costa Branco</name>
    </author>
    <author>
      <name>A. J. Pires</name>
    </author>
    <author>
      <name>J. A. Dente</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CDC.2000.914202</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CDC.2000.914202" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear as an Invited paper in IEEE Conference on Decision and
  Control (CDC2000), 6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0010010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0010010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0010031v1</id>
    <updated>2000-10-24T17:14:01Z</updated>
    <published>2000-10-24T17:14:01Z</published>
    <title>Opportunity Cost Algorithms for Combinatorial Auctions</title>
    <summary>  Two general algorithms based on opportunity costs are given for approximating
a revenue-maximizing set of bids an auctioneer should accept, in a
combinatorial auction in which each bidder offers a price for some subset of
the available goods and the auctioneer can only accept non-intersecting bids.
Since this problem is difficult even to approximate in general, the algorithms
are most useful when the bids are restricted to be connected node subsets of an
underlying object graph that represents which objects are relevant to each
other. The approximation ratios of the algorithms depend on structural
properties of this graph and are small constants for many interesting families
of object graphs. The running times of the algorithms are linear in the size of
the bid graph, which describes the conflicts between bids. Extensions of the
algorithms allow for efficient processing of additional constraints, such as
budget constraints that associate bids with particular bidders and limit how
many bids from a particular bidder can be accepted.
</summary>
    <author>
      <name>Karhan Akcoglu</name>
    </author>
    <author>
      <name>James Aspnes</name>
    </author>
    <author>
      <name>Bhaskar DasGupta</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0010031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0010031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.0; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011014v1</id>
    <updated>2000-11-09T20:39:25Z</updated>
    <published>2000-11-09T20:39:25Z</published>
    <title>Chip-level CMP Modeling and Smart Dummy for HDP and Conformal CVD Films</title>
    <summary>  Chip-level CMP modeling is investigated to obtain the post-CMP film profile
thickness across a die from its design layout file and a few film deposition
and CMP parameters. The work covers both HDP and conformal CVD film. The
experimental CMP results agree well with the modeled results. Different
algorithms for filling of dummy structure are compared. A smart algorithm for
dummy filling is presented, which achieves maximal pattern-density uniformity
and CMP planarity.
</summary>
    <author>
      <name>George Yong Liu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMP Technology, Inc</arxiv:affiliation>
    </author>
    <author>
      <name>Ray F. Zhang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMP Technology, Inc</arxiv:affiliation>
    </author>
    <author>
      <name>Kelvin Hsu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMP Technology, Inc</arxiv:affiliation>
    </author>
    <author>
      <name>Lawrence Camilletti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Conexant Systems Inc</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures; for used software, see
  http://www.cmptechnology.com/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of CMPMIC 99, pp120-127</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011016v1</id>
    <updated>2000-11-13T02:51:49Z</updated>
    <published>2000-11-13T02:51:49Z</published>
    <title>Designing Proxies for Stock Market Indices is Computationally Hard</title>
    <summary>  In this paper, we study the problem of designing proxies (or portfolios) for
various stock market indices based on historical data. We use four different
methods for computing market indices, all of which are formulas used in actual
stock market analysis. For each index, we consider three criteria for designing
the proxy: the proxy must either track the market index, outperform the market
index, or perform within a margin of error of the index while maintaining a low
volatility. In eleven of the twelve cases (all combinations of four indices
with three criteria except the problem of sacrificing return for less
volatility using the price-relative index) we show that the problem is NP-hard,
and hence most likely intractable.
</summary>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Stephen R. Tate</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An abstract appeared in the Proceedings of the 10th Annual ACM-SIAM
  Symposium on Discrete Algorithms, 1999</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0011016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2;G.2.3;J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011018v1</id>
    <updated>2000-11-14T16:04:27Z</updated>
    <published>2000-11-14T16:04:27Z</published>
    <title>Optimal Buy-and-Hold Strategies for Financial Markets with Bounded Daily
  Returns</title>
    <summary>  In the context of investment analysis, we formulate an abstract online
computing problem called a planning game and develop general tools for solving
such a game. We then use the tools to investigate a practical buy-and-hold
trading problem faced by long-term investors in stocks. We obtain the unique
optimal static online algorithm for the problem and determine its exact
competitive ratio. We also compare this algorithm with the popular dollar
averaging strategy using actual market data.
</summary>
    <author>
      <name>Gen-Huey Chen</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Yuh-Dauh Lyuu</name>
    </author>
    <author>
      <name>Hsing-Kuo Wong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The journal version will appear in SIAM Journal on Computing. A
  preliminary version appeared in Proceedings of the 31st Annual ACM Symposium
  on Theory of Computing, 1999, pages 119--128</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0011018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.1.2; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011023v1</id>
    <updated>2000-11-17T01:55:22Z</updated>
    <published>2000-11-17T01:55:22Z</published>
    <title>Optimal Bidding Algorithms Against Cheating in Multiple-Object Auctions</title>
    <summary>  This paper studies some basic problems in a multiple-object auction model
using methodologies from theoretical computer science. We are especially
concerned with situations where an adversary bidder knows the bidding
algorithms of all the other bidders. In the two-bidder case, we derive an
optimal randomized bidding algorithm, by which the disadvantaged bidder can
procure at least half of the auction objects despite the adversary's a priori
knowledge of his algorithm. In the general $k$-bidder case, if the number of
objects is a multiple of $k$, an optimal randomized bidding algorithm is found.
If the $k-1$ disadvantaged bidders employ that same algorithm, each of them can
obtain at least $1/k$ of the objects regardless of the bidding algorithm the
adversary uses. These two algorithms are based on closed-form solutions to
certain multivariate probability distributions. In situations where a
closed-form solution cannot be obtained, we study a restricted class of bidding
algorithms as an approximation to desired optimal algorithms.
</summary>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Junfeng Qi</name>
    </author>
    <author>
      <name>Lei Tan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Computing, 28(3):955--969, 1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.2.1; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101016v1</id>
    <updated>2001-01-18T03:10:58Z</updated>
    <published>2001-01-18T03:10:58Z</published>
    <title>A Dynamic Programming Approach to De Novo Peptide Sequencing via Tandem
  Mass Spectrometry</title>
    <summary>  The tandem mass spectrometry fragments a large number of molecules of the
same peptide sequence into charged prefix and suffix subsequences, and then
measures mass/charge ratios of these ions. The de novo peptide sequencing
problem is to reconstruct the peptide sequence from a given tandem mass
spectral data of k ions. By implicitly transforming the spectral data into an
NC-spectrum graph G=(V,E) where |V|=2k+2, we can solve this problem in
O(|V|+|E|) time and O(|V|) space using dynamic programming. Our approach can be
further used to discover a modified amino acid in O(|V||E|) time and to analyze
data with other types of noise in O(|V||E|) time. Our algorithms have been
implemented and tested on actual experimental data.
</summary>
    <author>
      <name>Ting Chen</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Matthew Tepel</name>
    </author>
    <author>
      <name>John Rush</name>
    </author>
    <author>
      <name>George M. Church</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A preliminary version appeared in Proceedings of the 11th Annual
  ACM-SIAM Symposium on Discrete Algorithms, pages 389--398, 2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0101016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101030v1</id>
    <updated>2001-01-26T21:36:30Z</updated>
    <published>2001-01-26T21:36:30Z</published>
    <title>Tree Contractions and Evolutionary Trees</title>
    <summary>  An evolutionary tree is a rooted tree where each internal vertex has at least
two children and where the leaves are labeled with distinct symbols
representing species. Evolutionary trees are useful for modeling the
evolutionary history of species. An agreement subtree of two evolutionary trees
is an evolutionary tree which is also a topological subtree of the two given
trees. We give an algorithm to determine the largest possible number of leaves
in any agreement subtree of two trees T_1 and T_2 with n leaves each. If the
maximum degree d of these trees is bounded by a constant, the time complexity
is O(n log^2(n)) and is within a log(n) factor of optimal. For general d, this
algorithm runs in O(n d^2 log(d) log^2(n)) time or alternatively in O(n d
sqrt(d) log^3(n)) time.
</summary>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Computing, 27(6):1592--1616, December 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0101030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101031v2</id>
    <updated>2001-01-27T01:06:00Z</updated>
    <published>2001-01-26T23:59:55Z</published>
    <title>Cavity Matchings, Label Compressions, and Unrooted Evolutionary Trees</title>
    <summary>  We present an algorithm for computing a maximum agreement subtree of two
unrooted evolutionary trees. It takes O(n^{1.5} log n) time for trees with
unbounded degrees, matching the best known time complexity for the rooted case.
Our algorithm allows the input trees to be mixed trees, i.e., trees that may
contain directed and undirected edges at the same time. Our algorithm adopts a
recursive strategy exploiting a technique called label compression. The
backbone of this technique is an algorithm that computes the maximum weight
matchings over many subgraphs of a bipartite graph as fast as it takes to
compute a single matching.
</summary>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Tak-Wah Lam</name>
    </author>
    <author>
      <name>Wing-Kin Sung</name>
    </author>
    <author>
      <name>Hing-Fung Ting</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Computing, 30(2):602--624, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0101031v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101031v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102003v1</id>
    <updated>2001-02-02T20:52:36Z</updated>
    <published>2001-02-02T20:52:36Z</published>
    <title>Fast Pricing of European Asian Options with Provable Accuracy:
  Single-stock and Basket Options</title>
    <summary>  This paper develops three polynomial-time pricing techniques for European
Asian options with provably small errors, where the stock prices follow
binomial trees or trees of higher-degree. The first technique is the first
known Monte Carlo algorithm with analytical error bounds suitable for pricing
single-stock options with meaningful confidence and speed. The second technique
is a general recursive bucketing-based scheme that can use the
Aingworth-Motwani-Oldham aggregation algorithm, Monte-Carlo simulation and
possibly others as the base-case subroutine. This scheme enables robust
trade-offs between accuracy and time over subtrees of different sizes. For
long-term options or high frequency price averaging, it can price single-stock
options with smaller errors in less time than the base-case algorithms
themselves. The third technique combines Fast Fourier Transform with
bucketing-based schemes for pricing basket options. This technique takes
polynomial time in the number of days and the number of stocks, and does not
add any errors to those already incurred in the companion bucketing scheme.
This technique assumes that the price of each underlying stock moves
independently.
</summary>
    <author>
      <name>Karhan Akcoglu</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Shuba Raghavan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0102003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2; G.2.3; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102008v1</id>
    <updated>2001-02-10T03:58:04Z</updated>
    <published>2001-02-10T03:58:04Z</published>
    <title>Optimal Bid Sequences for Multiple-Object Auctions with Unequal Budgets</title>
    <summary>  In a multiple-object auction, every bidder tries to win as many objects as
possible with a bidding algorithm. This paper studies position-randomized
auctions, which form a special class of multiple-object auctions where a
bidding algorithm consists of an initial bid sequence and an algorithm for
randomly permuting the sequence. We are especially concerned with situations
where some bidders know the bidding algorithms of others. For the case of only
two bidders, we give an optimal bidding algorithm for the disadvantaged bidder.
Our result generalizes previous work by allowing the bidders to have unequal
budgets. One might naturally anticipate that the optimal expected numbers of
objects won by the bidders would be proportional to their budgets.
Surprisingly, this is not true. Our new algorithm runs in optimal O(n) time in
a straightforward manner. The case with more than two bidders is open.
</summary>
    <author>
      <name>Yuyu Chen</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <author>
      <name>Hsueh-I Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A preliminary version appeared in In D. T. Lee and S. H. Teng,
  editors, Lecture Notes in Computer Science 1969: Proceedings of the 11th
  Annual International Symposium on Algorithms and Computation, pages 84--95,
  New York, NY, 2000. Springer-Verlag</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0102008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; G.2.1; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104013v1</id>
    <updated>2001-04-09T06:43:12Z</updated>
    <published>2001-04-09T06:43:12Z</published>
    <title>Shooting Over or Under the Mark: Towards a Reliable and Flexible
  Anticipation in the Economy</title>
    <summary>  The real monetary economy is grounded upon monetary flow equilibration or the
activity of actualizing monetary flow continuity at each economic agent except
for the central bank. Every update of monetary flow continuity at each agent
constantly causes monetary flow equilibration at the neighborhood agents. Every
monetary flow equilibration as the activity of shooting the mark identified as
monetary flow continuity turns out to be off the mark, and constantly generate
the similar activities in sequence. Monetary flow equilibration ceaselessly
reverberating in the economy performs two functions. One is to seek an
organization on its own, and the other is to perturb the ongoing organization.
Monetary flow equilibration as the agency of seeking and perturbing its
organization also serves as a means of predicting its behavior. The likely
organizational behavior could be the one that remains most robust against
monetary flow equilibration as an agency of applying perturbations.
</summary>
    <author>
      <name>Koichiro Matsuno</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Comp. Anticipatory Syst. 5 (2000), 305-314</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0104013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104017v1</id>
    <updated>2001-04-18T13:42:49Z</updated>
    <published>2001-04-18T13:42:49Z</published>
    <title>Local Search Techniques for Constrained Portfolio Selection Problems</title>
    <summary>  We consider the problem of selecting a portfolio of assets that provides the
investor a suitable balance of expected return and risk. With respect to the
seminal mean-variance model of Markowitz, we consider additional constraints on
the cardinality of the portfolio and on the quantity of individual shares. Such
constraints better capture the real-world trading system, but make the problem
more difficult to be solved with exact methods. We explore the use of local
search techniques, mainly tabu search, for the portfolio selection problem. We
compare and combine previous work on portfolio selection that makes use of the
local search approach and we propose new algorithms that combine different
neighborhood relations. In addition, we show how the use of randomization and
of a simple form of adaptiveness simplifies the setting of a large number of
critical parameters. Finally, we show how our techniques perform on public
benchmarks.
</summary>
    <author>
      <name>Andrea Schaerf</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Udine, Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0104017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105004v1</id>
    <updated>2001-05-02T12:43:39Z</updated>
    <published>2001-05-02T12:43:39Z</published>
    <title>Parallel implementation of the TRANSIMS micro-simulation</title>
    <summary>  This paper describes the parallel implementation of the TRANSIMS traffic
micro-simulation. The parallelization method is domain decomposition, which
means that each CPU of the parallel computer is responsible for a different
geographical area of the simulated region. We describe how information between
domains is exchanged, and how the transportation network graph is partitioned.
An adaptive scheme is used to optimize load balancing. We then demonstrate how
computing speeds of our parallel micro-simulations can be systematically
predicted once the scenario and the computer architecture are known. This makes
it possible, for example, to decide if a certain study is feasible with a
certain computing budget, and how to invest that budget. The main ingredients
of the prediction are knowledge about the parallel implementation of the
micro-simulation, knowledge about the characteristics of the partitioning of
the transportation network graph, and knowledge about the interaction of these
quantities with the computer system. In particular, we investigate the
differences between switched and non-switched topologies, and the effects of 10
Mbit, 100 Mbit, and Gbit Ethernet. keywords: Traffic simulation, parallel
computing, transportation planning, TRANSIMS
</summary>
    <author>
      <name>Kai Nagel</name>
    </author>
    <author>
      <name>Marcus Rickert</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0105004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6;J.2;J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106003v1</id>
    <updated>2001-06-03T11:41:56Z</updated>
    <published>2001-06-03T11:41:56Z</published>
    <title>A note on radial basis function computing</title>
    <summary>  This note carries three purposes involving our latest advances on the radial
basis function (RBF) approach. First, we will introduce a new scheme employing
the boundary knot method (BKM) to nonlinear convection-diffusion problem. It is
stressed that the new scheme directly results in a linear BKM formulation of
nonlinear problems by using response point-dependent RBFs, which can be solved
by any linear solver. Then we only need to solve a single nonlinear algebraic
equation for desirable unknown at some inner node of interest. The numerical
results demonstrate high accuracy and efficiency of this nonlinear BKM
strategy. Second, we extend the concepts of distance function, which include
time-space and variable transformation distance functions. Finally, we
demonstrate that if the nodes are symmetrically placed, the RBF coefficient
matrices have either centrosymmetric or skew centrosymmetric structures. The
factorization features of such matrices lead to a considerable reduction in the
RBF computing effort. A simple approach is also presented to reduce the
ill-conditioning of RBF interpolation matrices in general cases.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>W. He</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Nonlinear Modelling in Sci. &amp; Engng., 1(1), 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0106003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0202027v1</id>
    <updated>2002-02-18T16:01:03Z</updated>
    <published>2002-02-18T16:01:03Z</published>
    <title>BSML: A Binding Schema Markup Language for Data Interchange in Problem
  Solving Environments (PSEs)</title>
    <summary>  We describe a binding schema markup language (BSML) for describing data
interchange between scientific codes. Such a facility is an important
constituent of scientific problem solving environments (PSEs). BSML is designed
to integrate with a PSE or application composition system that views model
specification and execution as a problem of managing semistructured data. The
data interchange problem is addressed by three techniques for processing
semistructured data: validation, binding, and conversion. We present BSML and
describe its application to a PSE for wireless communications system design.
</summary>
    <author>
      <name>Alex Verstak</name>
    </author>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Layne T. Watson</name>
    </author>
    <author>
      <name>Jian He</name>
    </author>
    <author>
      <name>Clifford A. Shaffer</name>
    </author>
    <author>
      <name>Kyung Kyoon Bae</name>
    </author>
    <author>
      <name>Jing Jiang</name>
    </author>
    <author>
      <name>William H. Tranter</name>
    </author>
    <author>
      <name>Theodore S. Rappaport</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0202027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0202027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.6; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204019v1</id>
    <updated>2002-04-10T03:13:03Z</updated>
    <published>2002-04-10T03:13:03Z</published>
    <title>Fast Universalization of Investment Strategies with Provably Good
  Relative Returns</title>
    <summary>  A universalization of a parameterized investment strategy is an online
algorithm whose average daily performance approaches that of the strategy
operating with the optimal parameters determined offline in hindsight. We
present a general framework for universalizing investment strategies and
discuss conditions under which investment strategies are universalizable. We
present examples of common investment strategies that fit into our framework.
The examples include both trading strategies that decide positions in
individual stocks, and portfolio strategies that allocate wealth among multiple
stocks. This work extends Cover's universal portfolio work. We also discuss the
runtime efficiency of universalization algorithms. While a straightforward
implementation of our algorithms runs in time exponential in the number of
parameters, we show that the efficient universal portfolio computation
technique of Kalai and Vempala involving the sampling of log-concave functions
can be generalized to other classes of investment strategies.
</summary>
    <author>
      <name>Karhan Akcoglu</name>
    </author>
    <author>
      <name>Petros Drineas</name>
    </author>
    <author>
      <name>Ming-Yang Kao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 Pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0204019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2; G.3; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204047v2</id>
    <updated>2002-04-22T21:56:55Z</updated>
    <published>2002-04-22T19:41:24Z</published>
    <title>Sampling Strategies for Mining in Data-Scarce Domains</title>
    <summary>  Data mining has traditionally focused on the task of drawing inferences from
large datasets. However, many scientific and engineering domains, such as fluid
dynamics and aircraft design, are characterized by scarce data, due to the
expense and complexity of associated experiments and simulations. In such
data-scarce domains, it is advantageous to focus the data collection effort on
only those regions deemed most important to support a particular data mining
objective. This paper describes a mechanism that interleaves bottom-up data
mining, to uncover multi-level structures in spatial data, with top-down
sampling, to clarify difficult decisions in the mining process. The mechanism
exploits relevant physical properties, such as continuity, correspondence, and
locality, in a unified framework. This leads to effective mining and sampling
decisions that are explainable in terms of domain knowledge and data
characteristics. This approach is demonstrated in two diverse applications --
mining pockets in spatial data, and qualitative determination of Jordan forms
of matrices.
</summary>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Chris Bailey-Kellogg</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0204047v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204047v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.6; G.1.2; G.1.3; G.3; I.2.10; I.5; H.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205019v1</id>
    <updated>2002-05-14T13:43:47Z</updated>
    <published>2002-05-14T13:43:47Z</published>
    <title>Distance function wavelets - Part I: Helmholtz and convection-diffusion
  transforms and series</title>
    <summary>  This report aims to present my research updates on distance function wavelets
(DFW) based on the fundamental solutions and the general solutions of the
Helmholtz, modified Helmholtz, and convection-diffusion equations, which
include the isotropic Helmholtz-Fourier (HF) transform and series, the
Helmholtz-Laplace (HL) transform, and the anisotropic convection-diffusion
wavelets and ridgelets. The latter is set to handle discontinuous and track
data problems. The edge effect of the HF series is addressed. Alternative
existence conditions for the DFW transforms are proposed and discussed. To
simplify and streamline the expression of the HF and HL transforms, a new
dimension-dependent function notation is introduced. The HF series is also used
to evaluate the analytical solutions of linear diffusion problems of arbitrary
dimensionality and geometry. The weakness of this report is lacking of rigorous
mathematical analysis due to the author's limited mathematical knowledge.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205020v1</id>
    <updated>2002-05-14T13:58:48Z</updated>
    <published>2002-05-14T13:58:48Z</published>
    <title>A quasi-RBF technique for numerical discretization of PDE's</title>
    <summary>  Atkinson developed a strategy which splits solution of a PDE system into
homogeneous and particular solutions, where the former have to satisfy the
boundary and governing equation, while the latter only need to satisfy the
governing equation without concerning geometry. Since the particular solution
can be solved irrespective of boundary shape, we can use a readily available
fast Fourier or orthogonal polynomial technique O(NlogN) to evaluate it in a
regular box or sphere surrounding physical domain. The distinction of this
study is that we approximate homogeneous solution with nonsingular general
solution RBF as in the boundary knot method. The collocation method using
general solution RBF has very high accuracy and spectral convergent speed and
is a simple, truly meshfree approach for any complicated geometry. More
importantly, the use of nonsingular general solution avoids the controversial
artificial boundary in the method of fundamental solution due to the
singularity of fundamental solution.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205063v1</id>
    <updated>2002-05-24T12:07:28Z</updated>
    <published>2002-05-24T12:07:28Z</published>
    <title>Distance function wavelets - Part II: Extended results and conjectures</title>
    <summary>  Report II is concerned with the extended results of distance function
wavelets (DFW). The fractional DFW transforms are first addressed relating to
the fractal geometry and fractional derivative, and then, the discrete
Helmholtz-Fourier transform is briefly presented. The Green second identity may
be an alternative devise in developing the theoretical framework of the DFW
transform and series. The kernel solutions of the Winkler plate equation and
the Burger's equation are used to create the DFW transforms and series. Most
interestingly, it is found that the translation invariant monomial solutions of
the high-order Laplace equations can be used to make very simple harmonic
polynomial DFW series. In most cases of this study, solid mathematical analysis
is missing and results are obtained intuitively in the conjecture status.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Welcome any comments to wenc@simula.no</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.8, G1.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207010v1</id>
    <updated>2002-07-03T20:17:31Z</updated>
    <published>2002-07-03T20:17:31Z</published>
    <title>Symmetric boundary knot method</title>
    <summary>  The boundary knot method (BKM) is a recent boundary-type radial basis
function (RBF) collocation scheme for general PDEs. Like the method of
fundamental solution (MFS), the RBF is employed to approximate the
inhomogeneous terms via the dual reciprocity principle. Unlike the MFS, the
method uses a nonsingular general solution instead of a singular fundamental
solution to evaluate the homogeneous solution so as to circumvent the
controversial artificial boundary outside the physical domain. The BKM is
meshfree, superconvergent, integration free, very easy to learn and program.
The original BKM, however, loses symmetricity in the presense of mixed
boundary. In this study, by analogy with Hermite RBF interpolation, we
developed a symmetric BKM scheme. The accuracy and efficiency of the symmetric
BKM are also numerically validated in some 2D and 3D Helmholtz and diffusion
reaction problems under complicated geometries.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Engng. Anal. Bound. Elem., 26(6), 489-494, 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0207010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.8, G1.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207015v1</id>
    <updated>2002-07-04T12:10:06Z</updated>
    <published>2002-07-04T12:10:06Z</published>
    <title>New advances in dual reciprocity and boundary-only RBF methods</title>
    <summary>  This paper made some significant advances in the dual reciprocity and
boundary-only RBF techniques. The proposed boundary knot method (BKM) is
different from the standard boundary element method in a number of important
aspects. Namely, it is truly meshless, exponential convergence,
integration-free (of course, no singular integration), boundary-only for
general problems, and leads to symmetric matrix under certain conditions (able
to be extended to general cases after further modified). The BKM also avoids
the artificial boundary in the method of fundamental solution. An amazing
finding is that the BKM can formulate linear modeling equations for nonlinear
partial differential systems with linear boundary conditions. This merit makes
it circumvent all perplexing issues in the iteration solution of nonlinear
equations. On the other hand, by analogy with Green's second identity, this
paper also presents a general solution RBF (GSR) methodology to construct
efficient RBFs in the dual reciprocity and domain-type RBF collocation methods.
The GSR approach first establishes an explicit relationship between the BEM and
RBF itself on the ground of the weighted residual principle. This paper also
discusses the RBF convergence and stability problems within the framework of
integral equation theory.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>M. Tanaka</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0207015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207035v1</id>
    <updated>2002-07-09T20:26:18Z</updated>
    <published>2002-07-09T20:26:18Z</published>
    <title>A Lyapunov Formulation for Efficient Solution of the Poisson and
  Convection-Diffusion Equations by the Differential Quadrature Method</title>
    <summary>  Civan and Sliepcevich [1, 2] suggested that special matrix solver should be
developed to further reduce the computing effort in applying the differential
quadrature (DQ) method for the Poisson and convection-diffusion equations.
Therefore, the purpose of the present communication is to introduce and apply
the Lyapunov formulation which can be solved much more efficiently than the
Gaussian elimination method. Civan and Sliepcevich [2] first presented DQ
approximate formulas in polynomial form for partial derivatives in
tow-dimensional variable domain. For simplifying formulation effort, Chen et
al. [3] proposed the compact matrix form of these DQ approximate formulas. In
this study, by using these matrix approximate formulas, the DQ formulations for
the Poisson and convection-diffusion equations can be expressed as the Lyapunov
algebraic matrix equation. The formulation effort is simplified, and a simple
and explicit matrix formulation is obtained. A variety of fast algorithms in
the solution of the Lyapunov equation [4-6] can be successfully applied in the
DQ analysis of these two-dimensional problems, and, thus, the computing effort
can be greatly reduced. Finally, we also point out that the present reduction
technique can be easily extended to the three-dimensional cases.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>Tingxiu Zhong</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. of Computational Physics, 139, 1-7, 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0207035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.8, G1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207041v1</id>
    <updated>2002-07-10T20:31:29Z</updated>
    <published>2002-07-10T20:31:29Z</published>
    <title>RBF-based meshless boundary knot method and boundary particle method</title>
    <summary>  This paper is concerned with the two new boundary-type radial basis function
collocation schemes, boundary knot method (BKM) and boundary particle method
(BPM). The BKM is developed based on the dual reciprocity theorem, while the
BPM employs the multiple reciprocity technique. Unlike the method of
fundamental solution, the wto methods use the nonsingular general solutions
instead of singular fundamental solution to circumvent the controversial
artificial boundary outside physical domain. Compared with the boundary element
method, both the BKM and BPM are meshfree, superconvergent, meshfree,
integration free, symmetric, and mathematically simple collocation techniques
for general PDEs. In particular, the BPM does not require any inner nodes for
inhomogeneous problems. In this study, the accuracy and efficiency of the two
methods are numerically demonstrated to some 2D, 3D Helmholtz and
convection-diffusion problems under complicated geometries.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0207041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207043v1</id>
    <updated>2002-07-11T12:19:49Z</updated>
    <published>2002-07-11T12:19:49Z</published>
    <title>A meshless, integration-free, and boundary-only RBF technique</title>
    <summary>  Based on the radial basis function (RBF), non-singular general solution and
dual reciprocity method (DRM), this paper presents an inherently meshless,
integration-free, boundary-only RBF collocation techniques for numerical
solution of various partial differential equation systems. The basic ideas
behind this methodology are very mathematically simple. In this study, the RBFs
are employed to approximate the inhomogeneous terms via the DRM, while
non-singular general solution leads to a boundary-only RBF formulation for
homogenous solution. The present scheme is named as the boundary knot method
(BKM) to differentiate it from the other numerical techniques. In particular,
due to the use of nonsingular general solutions rather than singular
fundamental solutions, the BKM is different from the method of fundamental
solution in that the former does no require the artificial boundary and results
in the symmetric system equations under certain conditions. The efficiency and
utility of this new technique are validated through a number of typical
numerical examples. Completeness concern of the BKM due to the only use of
non-singular part of complete fundamental solution is also discussed.
</summary>
    <author>
      <name>W. Chen</name>
    </author>
    <author>
      <name>M. Tanaka</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers and Mathematics with Applications, 43, 379-391, 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0207043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G1.3, G1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208040v1</id>
    <updated>2002-08-25T16:28:33Z</updated>
    <published>2002-08-25T16:28:33Z</published>
    <title>Using Hierarchical Data Mining to Characterize Performance of Wireless
  System Configurations</title>
    <summary>  This paper presents a statistical framework for assessing wireless systems
performance using hierarchical data mining techniques. We consider WCDMA
(wideband code division multiple access) systems with two-branch STTD (space
time transmit diversity) and 1/2 rate convolutional coding (forward error
correction codes). Monte Carlo simulation estimates the bit error probability
(BEP) of the system across a wide range of signal-to-noise ratios (SNRs). A
performance database of simulation runs is collected over a targeted space of
system configurations. This database is then mined to obtain regions of the
configuration space that exhibit acceptable average performance. The shape of
the mined regions illustrates the joint influence of configuration parameters
on system performance. The role of data mining in this application is to
provide explainable and statistically valid design conclusions. The research
issue is to define statistically meaningful aggregation of data in a manner
that permits efficient and effective data mining algorithms. We achieve a good
compromise between these goals and help establish the applicability of data
mining for characterizing wireless systems performance.
</summary>
    <author>
      <name>Alex Verstak</name>
    </author>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Kyung Kyoon Bae</name>
    </author>
    <author>
      <name>William H. Tranter</name>
    </author>
    <author>
      <name>Layne T. Watson</name>
    </author>
    <author>
      <name>Jian He</name>
    </author>
    <author>
      <name>Clifford A. Shaffer</name>
    </author>
    <author>
      <name>Theodore S. Rappaport</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0208040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0301018v1</id>
    <updated>2003-01-21T02:26:47Z</updated>
    <published>2003-01-21T02:26:47Z</published>
    <title>Novel Runtime Systems Support for Adaptive Compositional Modeling on the
  Grid</title>
    <summary>  Grid infrastructures and computing environments have progressed significantly
in the past few years. The vision of truly seamless Grid usage relies on
runtime systems support that is cognizant of the operational issues underlying
grid computations and, at the same time, is flexible enough to accommodate
diverse application scenarios. This paper addresses the twin aspects of Grid
infrastructure and application support through a novel combination of two
computational technologies: Weaves - a source-language independent parallel
runtime compositional framework that operates through reverse-analysis of
compiled object files, and runtime recommender systems that aid in dynamic
knowledge-based application composition. Domain-specific adaptivity is
exploited through a novel compositional system that supports runtime
recommendation of code modules and a sophisticated checkpointing and runtime
migration solution that can be transparently deployed over Grid
infrastructures. A core set of "adaptivity schemas" are provided as templates
for adaptive composition of large-scale scientific computations. Implementation
issues, motivating application contexts, and preliminary results are described.
</summary>
    <author>
      <name>Srinidhi Varadarajan</name>
    </author>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0301018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0301018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0305055v1</id>
    <updated>2003-05-29T18:13:08Z</updated>
    <published>2003-05-29T18:13:08Z</published>
    <title>Goodness-of-fit of the Heston model</title>
    <summary>  An analytical formula for the probability distribution of stock-market
returns, derived from the Heston model assuming a mean-reverting stochastic
volatility, was recently proposed by Dragulescu and Yakovenko in Quantitative
Finance 2002. While replicating their results, we found two significant
weaknesses in their method to pre-process the data, which cast a shadow over
the effective goodness-of-fit of the model. We propose a new method, more truly
capturing the market, and perform a Kolmogorov-Smirnov test and a Chi Square
test on the resulting probability distribution. The results raise some
significant questions for large time lags -- 40 to 250 days -- where the
smoothness of the data does not require such a complex model; nevertheless, we
also provide some statistical evidence in favour of the Heston model for small
time lags -- 1 and 5 days -- compared with the traditional Gaussian model
assuming constant volatility.
</summary>
    <author>
      <name>Gilles Daniel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures, The 9th International Conference of Computing in
  Economics and Finance, Seattle (July 2003)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0305055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0305055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307053v1</id>
    <updated>2003-07-23T19:30:25Z</updated>
    <published>2003-07-23T19:30:25Z</published>
    <title>Hamevol1.0: a C++ code for differential equations based on Runge-Kutta
  algorithm. An application to matter enhanced neutrino oscillation</title>
    <summary>  We present a C++ implementation of a fifth order semi-implicit Runge-Kutta
algorithm for solving Ordinary Differential Equations. This algorithm can be
used for studying many different problems and in particular it can be applied
for computing the evolution of any system whose Hamiltonian is known. We
consider in particular the problem of calculating the neutrino oscillation
probabilities in presence of matter interactions. The time performance and the
accuracy of this implementation is competitive with respect to the other
analytical and numerical techniques used in literature. The algorithm design
and the salient features of the code are presented and discussed and some
explicit examples of code application are given.
</summary>
    <author>
      <name>P. Aliani</name>
    </author>
    <author>
      <name>V. Antonelli</name>
    </author>
    <author>
      <name>M. Picariello</name>
    </author>
    <author>
      <name>Emilio Torrente-Lujan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, Latex</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0308009v3</id>
    <updated>2008-05-17T23:06:04Z</updated>
    <published>2003-08-05T09:31:38Z</published>
    <title>The Generalized Riemann or Henstock Integral Underpinning Multivariate
  Data Analysis: Application to Faint Structure Finding in Price Processes</title>
    <summary>  Practical data analysis involves many implicit or explicit assumptions about
the good behavior of the data, and excludes consideration of various
potentially pathological or limit cases. In this work, we present a new general
theory of data, and of data processing, to bypass some of these assumptions.
The new framework presented is focused on integration, and has direct
applicability to expectation, distance, correlation, and aggregation. In a case
study, we seek to reveal faint structure in financial data. Our new foundation
for data encoding and handling offers increased justification for our
conclusions.
</summary>
    <author>
      <name>Pat Muldowney</name>
    </author>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 4 figures. Various changes made relative to previous
  versions, in particular in introductory section</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0308009v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0308009v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310021v1</id>
    <updated>2003-10-11T14:39:00Z</updated>
    <published>2003-10-11T14:39:00Z</published>
    <title>Fuzzy Relational Modeling of Cost and Affordability for Advanced
  Technology Manufacturing Environment</title>
    <summary>  Relational representation of knowledge makes it possible to perform all the
computations and decision making in a uniform relational way by means of
special relational compositions called triangle and square products. In this
paper some applications in manufacturing related to cost analysis are
described. Testing fuzzy relational structures for various relational
properties allows us to discover dependencies, hierarchies, similarities, and
equivalences of the attributes characterizing technological processes and
manufactured artifacts in their relationship to costs and performance.
  A brief overview of mathematical aspects of BK-relational products is given
in Appendix 1 together with further references in the literature.
</summary>
    <author>
      <name>Ladislav J. Kohout</name>
    </author>
    <author>
      <name>Eunjin Kim</name>
    </author>
    <author>
      <name>Gary Zenz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, Design &amp; Manufacturing Grantees Conference Proceedings.
  Table of contents added</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J2; J1; I.2.3; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310043v3</id>
    <updated>2003-10-29T19:09:15Z</updated>
    <published>2003-10-22T18:04:24Z</published>
    <title>Value-at-Risk and Expected Shortfall for Quadratic portfolio of
  securities with mixture of elliptic Distributed Risk Factors</title>
    <summary>  Generally, in the financial literature, the notion of quadratic VaR is
implicitly confused with the Delta-Gamma VaR, because more authors dealt with
portfolios that contains derivatives instruments.
  In this paper, we postpone to estimate the Value-at-Risk of a quadratic
portfolio of securities (i.e equities) without the Delta and Gamma greeks, when
the joint log-returns changes with multivariate elliptic distribution. We have
reduced the estimation of the quadratic VaR of such portfolio to a resolution
of one dimensional integral equation. To illustrate our method, we give special
attention to the mixture of normal and mixture of t-student distribution. For
given VaR, when joint Risk Factors changes with elliptic distribution, we show
how to estimate an Expected Shortfall .
</summary>
    <author>
      <name>Jules Sadefo Kamdem</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0310043v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310043v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.9; G.1.10; G.1.2; G.1.1; J.1; J.2; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311048v1</id>
    <updated>2003-11-27T18:13:38Z</updated>
    <published>2003-11-27T18:13:38Z</published>
    <title>Turning CARTwheels: An Alternating Algorithm for Mining Redescriptions</title>
    <summary>  We present an unusual algorithm involving classification trees where two
trees are grown in opposite directions so that they are matched at their
leaves. This approach finds application in a new data mining task we formulate,
called "redescription mining". A redescription is a shift-of-vocabulary, or a
different way of communicating information about a given subset of data; the
goal of redescription mining is to find subsets of data that afford multiple
descriptions. We highlight the importance of this problem in domains such as
bioinformatics, which exhibit an underlying richness and diversity of data
descriptors (e.g., genes can be studied in a variety of ways). Our approach
helps integrate multiple forms of characterizing datasets, situates the
knowledge gained from one dataset in the context of others, and harnesses
high-level abstractions for uncovering cryptic and subtle features of data.
Algorithm design decisions, implementation details, and experimental results
are presented.
</summary>
    <author>
      <name>Deept Kumar</name>
    </author>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Malcolm Potts</name>
    </author>
    <author>
      <name>Richard F. Helm</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0311048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405047v1</id>
    <updated>2004-05-14T17:43:33Z</updated>
    <published>2004-05-14T17:43:33Z</published>
    <title>Modular technology of developing of the problem-oriented extensions of a
  CAD system of reconstruction of the plant</title>
    <summary>  The modular technology of creation of the problem-oriented extensions of a
CAD system is described, which was realised in a system TechnoCAD GlassX for
designing of reconstruction of the plants. The modularity of the technology is
expressed in storage of all parameters of the design in one element of the
drawing - modulus, with automatic generation of a geometrical part of the
modulus from these parameters. The common principles of the system organization
of extensions developing are described: separation of the part of the design to
automize in this extension, architecture of parameters in the form of the lists
of objects with their properties and links to another objects, separation of
common and special operations, stages of the developing, boundaries of
applicability of technology.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, no figures, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405055v1</id>
    <updated>2004-05-17T09:46:02Z</updated>
    <published>2004-05-17T09:46:02Z</published>
    <title>Modular technology of developing of the extensions of a CAD system.
  Axonometric piping diagrams. Parametric representation</title>
    <summary>  Applying the modular technology of developing of the problem-oriented
extensions of a CAD system to a problem of automation of creating of the
axonometric piping diagrams on an example of the program system TechnoCAD
GlassX is described. The proximity of composition of the schemas is detected
for special technological pipe lines, systems of a water line and water drain,
heating, heat supply, ventilating, air conditioning. The structured parametric
representation of the schemas, including properties of objects, their link,
common settings, settings by default and the special links of compatibility is
reviewed.
</summary>
    <author>
      <name>Vladimir V. Migunov</name>
    </author>
    <author>
      <name>Rustem R. Kafiatullov</name>
    </author>
    <author>
      <name>Ilsur T. Safin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2, I.2.1, J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406021v3</id>
    <updated>2006-05-20T14:25:21Z</updated>
    <published>2004-06-16T01:23:03Z</published>
    <title>A direct formulation for sparse PCA using semidefinite programming</title>
    <summary>  We examine the problem of approximating, in the Frobenius-norm sense, a
positive, semidefinite symmetric matrix by a rank-one matrix, with an upper
bound on the cardinality of its eigenvector. The problem arises in the
decomposition of a covariance matrix into sparse factors, and has wide
applications ranging from biology to finance. We use a modification of the
classical variational representation of the largest eigenvalue of a symmetric
matrix, where cardinality is constrained, and derive a semidefinite programming
based relaxation for our problem. We also discuss Nesterov's smooth
minimization technique applied to the SDP arising in the direct sparse PCA
method.
</summary>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <author>
      <name>Laurent El Ghaoui</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <author>
      <name>Gert R. G. Lanckriet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final version, to appear in SIAM review</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0406021v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406021v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406042v1</id>
    <updated>2004-06-22T12:19:54Z</updated>
    <published>2004-06-22T12:19:54Z</published>
    <title>Business Process Measures</title>
    <summary>  The paper proposes a new methodology for defining business process measures
and their computation. The approach is based on metamodeling according to MOF.
Especially, a metamodel providing precise definitions of typical process
measures for UML activity diagram-like notation is proposed, including precise
definitions how measures should be aggregated for composite process elements.
The proposed approach allows defining values in a natural way, and measurement
of data, which are of interest to business, without deep investigation into
specific technical solutions. This provides new possibilities for business
process measurement, decreasing the gap between technical solutions and asset
management methodologies.
</summary>
    <author>
      <name>Valdis Vitolins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures, 2 tables, Proceedings of International
  Conference "Baltic DB&amp;IS 2004", Riga, Latvia (June 6-9, 2004)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vitolins Valdis, Business Process Measures. Computer Science and
  Information Technologies, Databases and Information Systems Doctoral
  Consortium, Scientific Papers University of Latvia Vol. 673, University of
  Latvia, 2004, pp. 186.-197</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0406042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; J.7; C.4; I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408047v2</id>
    <updated>2009-10-05T02:38:16Z</updated>
    <published>2004-08-20T16:23:19Z</published>
    <title>Pervasive Service Architecture for a Digital Business Ecosystem</title>
    <summary>  In this paper we present ideas and architectural principles upon which we are
basing the development of a distributed, open-source infrastructure that, in
turn, will support the expression of business models, the dynamic composition
of software services, and the optimisation of service chains through automatic
self-organising and evolutionary algorithms derived from biology. The target
users are small and medium-sized enterprises (SMEs). We call the collection of
the infrastructure, the software services, and the SMEs a Digital Business
Ecosystem (DBE).
</summary>
    <author>
      <name>Thomas Heistracher</name>
    </author>
    <author>
      <name>Thomas Kurz</name>
    </author>
    <author>
      <name>Claudius Masuch</name>
    </author>
    <author>
      <name>Pierfranco Ferronato</name>
    </author>
    <author>
      <name>Miguel Vidal</name>
    </author>
    <author>
      <name>Angelo Corallo</name>
    </author>
    <author>
      <name>Gerard Briscoe</name>
    </author>
    <author>
      <name>Paolo Dini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages 2 Figures Presented at WCAT04 Workshop (ECOOP 2004
  Conference), Olso, Norway, 14 June 2004</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0408047v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408047v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410064v1</id>
    <updated>2004-10-25T15:55:43Z</updated>
    <published>2004-10-25T15:55:43Z</published>
    <title>Intelligent Computer Numerical Control unit for machine tools</title>
    <summary>  The paper describes a new CNC control unit for machining centres with
learning ability and automatic intelligent generating of NC programs on the
bases of a neural network, which is built-in into a CNC unit as special device.
The device performs intelligent and completely automatically the NC part
programs only on the bases of 2D, 2,5D or 3D computer model of prismatic part.
Intervention of the operator is not needed. The neural network for milling,
drilling, reaming, threading and operations alike has learned to generate NC
programs in the learning module, which is a part of intelligent CAD/CAM system.
</summary>
    <author>
      <name>J. Balic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures, 17 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural-Network-Based Numerical Control for Milling Machine,
  Journal of Intelligent and Robotic System, Volume 40, Issue 4, Aug 2004;
  Pages: 343-358 (extended version)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.6.2; J.7.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503087v4</id>
    <updated>2011-08-28T19:34:52Z</updated>
    <published>2005-03-30T20:52:11Z</published>
    <title>Dynamic Simulation of Construction Machinery: Towards an Operator Model</title>
    <summary>  In dynamic simulation of complete wheel loaders, one interesting aspect,
specific for the working task, is the momentary power distribution between
drive train and hydraulics, which is balanced by the operator.
  This paper presents the initial results to a simulation model of a human
operator. Rather than letting the operator model follow a predefined path with
control inputs at given points, it follows a collection of general rules that
together describe the machine's working cycle in a generic way. The advantage
of this is that the working task description and the operator model itself are
independent of the machine's technical parameters. Complete sub-system
characteristics can thus be changed without compromising the relevance and
validity of the simulation. Ultimately, this can be used to assess a machine's
total performance, fuel efficiency and operability already in the concept phase
of the product development process.
</summary>
    <author>
      <name>Reno Filla</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Volvo Wheel Loaders AB</arxiv:affiliation>
    </author>
    <author>
      <name>Allan Ericsson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Volvo Wheel Loaders AB</arxiv:affiliation>
    </author>
    <author>
      <name>Jan-Ove Palmberg</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Linkoping University</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Fluid Power Exhibition 2005 Technical Conference,
  pp. 429-438</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0503087v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503087v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.3; I.6.5; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505001v1</id>
    <updated>2005-04-29T20:38:42Z</updated>
    <published>2005-04-29T20:38:42Z</published>
    <title>Modelling investment in artificial stock markets: Analytical and
  Numerical Results</title>
    <summary>  In this article we study the behavior of a group of economic agents in the
context of cooperative game theory, interacting according to rules based on the
Potts Model with suitable modifications. Each agent can be thought of as
belonging to a chain, where agents can only interact with their nearest
neighbors (periodic boundary conditions are imposed). Each agent can invest an
amount &amp;#963;_{i}=0,...,q-1. Using the transfer matrix method we study
analytically, among other things, the behavior of the investment as a function
of a control parameter (denoted &amp;#946;) for the cases q=2 and 3. For q&gt;3
numerical evaluation of eigenvalues and high precision numerical derivatives
are used in order to assess this information.
</summary>
    <author>
      <name>Roberto da Silva</name>
    </author>
    <author>
      <name>Alexandre Tavares Baraviera</name>
    </author>
    <author>
      <name>Silvio R. Dahmen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0505001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506023v1</id>
    <updated>2005-06-08T21:08:38Z</updated>
    <published>2005-06-08T21:08:38Z</published>
    <title>Sparse Covariance Selection via Robust Maximum Likelihood Estimation</title>
    <summary>  We address a problem of covariance selection, where we seek a trade-off
between a high likelihood against the number of non-zero elements in the
inverse covariance matrix. We solve a maximum likelihood problem with a penalty
term given by the sum of absolute values of the elements of the inverse
covariance matrix, and allow for imposing bounds on the condition number of the
solution. The problem is directly amenable to now standard interior-point
algorithms for convex optimization, but remains challenging due to its size. We
first give some results on the theoretical computational complexity of the
problem, by showing that a recent methodology for non-smooth convex
optimization due to Nesterov can be applied to this problem, to greatly improve
on the complexity estimate given by interior-point algorithms. We then examine
two practical algorithms aimed at solving large-scale, noisy (hence dense)
instances: one is based on a block-coordinate descent approach, where columns
and rows are updated sequentially, another applies a dual version of Nesterov's
method.
</summary>
    <author>
      <name>Onureena Banerjee</name>
    </author>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <author>
      <name>Laurent El Ghaoui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to NIPS 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.3; G.1.6; G.3; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506033v4</id>
    <updated>2011-08-28T19:37:32Z</updated>
    <published>2005-06-10T10:35:14Z</published>
    <title>An Event-driven Operator Model for Dynamic Simulation of Construction
  Machinery</title>
    <summary>  Prediction and optimisation of a wheel loader's dynamic behaviour is a
challenge due to tightly coupled, non-linear subsystems of different technical
domains. Furthermore, a simulation regarding performance, efficiency, and
operability cannot be limited to the machine itself, but has to include
operator, environment, and work task. This paper presents some results of our
approach to an event-driven simulation model of a human operator. Describing
the task and the operator model independently of the machine's technical
parameters, gives the possibility to change whole sub-system characteristics
without compromising the relevance and validity of the simulation.
</summary>
    <author>
      <name>Reno Filla</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Volvo Wheel Loaders AB</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 18 figures, SICFP'05 conference; Proceedings of SICFP 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506033v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506033v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.3; I.6.5; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508102v1</id>
    <updated>2005-08-23T19:52:38Z</updated>
    <published>2005-08-23T19:52:38Z</published>
    <title>Investigations of Process Damping Forces in Metal Cutting</title>
    <summary>  Using finite element software developed for metal cutting by Third Wave
Systems we investigate the forces involved in chatter, a self-sustained
oscillation of the cutting tool. The phenomena is decomposed into a vibrating
tool cutting a flat surface work piece, and motionless tool cutting a work
piece with a wavy surface. While cutting the wavy surface, the shearplane was
seen to oscillate in advance of the oscillation of the depth of cut, as were
the cutting, thrust, and shear plane forces. The vibrating tool was used to
investigate process damping through the interaction of the relief face of the
tool and the workpiece. Crushing forces are isolated and compared to the
contact length between the tool and workpiece. We found that the wavelength
dependence of the forces depended on the relative size of the wavelength to the
length of the relief face of the tool. The results indicate that the damping
force from crushing will be proportional to the cutting speed for short tools,
and inversely proportional for long tools.
</summary>
    <author>
      <name>Emily Stone</name>
    </author>
    <author>
      <name>Suhail Ahmed</name>
    </author>
    <author>
      <name>Abe Askari</name>
    </author>
    <author>
      <name>Hong Tat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 27 figures, submitted to Journal of Computational Methods
  in Science and Engineering, Feb. 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0508102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.3; I.6.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509028v1</id>
    <updated>2005-09-10T14:01:02Z</updated>
    <published>2005-09-10T14:01:02Z</published>
    <title>Projecting the Forward Rate Flow onto a Finite Dimensional Manifold</title>
    <summary>  Given a Heath-Jarrow-Morton (HJM) interest rate model $\mathcal{M}$ and a
parametrized family of finite dimensional forward rate curves $\mathcal{G}$,
this paper provides a technique for projecting the infinite dimensional forward
rate curve $r_{t}$ given by $\mathcal{M}$ onto the finite dimensional manifold
$\mathcal{G}$.The Stratonovich dynamics of the projected finite dimensional
forward curve are derived and it is shown that, under the regularity
conditions, the given Stratonovich differential equation has a unique strong
solution. Moreover, this projection leads to an efficient algorithm for
implicit parametric estimation of the infinite dimensional HJM model. The
feasibility of this method is demonstrated by applying the generalized method
of moments.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Li Chen</name>
    </author>
    <author>
      <name>H. Vincent Poor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the International Journal of Theoretical and Applied
  Finance</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0509028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605119v1</id>
    <updated>2006-05-25T04:39:11Z</updated>
    <published>2006-05-25T04:39:11Z</published>
    <title>An Internet-enabled technology to support Evolutionary Design</title>
    <summary>  This paper discusses the systematic use of product feedback information to
support life-cycle design approaches and provides guidelines for developing a
design at both the product and the system levels. Design activities are
surveyed in the light of the product life cycle, and the design information
flow is interpreted from a semiotic perspective. The natural evolution of a
design is considered, the notion of design expectations is introduced, and the
importance of evaluation of these expectations in dynamic environments is
argued. Possible strategies for reconciliation of the expectations and
environmental factors are described. An Internet-enabled technology is proposed
to monitor product functionality, usage, and operational environment and supply
the designer with relevant information. A pilot study of assessing design
expectations of a refrigerator is outlined, and conclusions are drawn.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>H. Tamaki</name>
    </author>
    <author>
      <name>K. Ueda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 3 figures. Preprint completed in 2000</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Engineering Manufacture. 2001, Vol.215, No.B5, 647-655</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0605119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606004v1</id>
    <updated>2006-06-01T02:36:12Z</updated>
    <published>2006-06-01T02:36:12Z</published>
    <title>A Framework for the Development of Manufacturing Simulators: Towards New
  Generation of Simulation Systems</title>
    <summary>  In this paper, an attempt is made to systematically discuss the development
of simulation systems for manufacturing system design. General requirements on
manufacturing simulators are formulated and a framework to address the
requirements is suggested. Problems of information representation as an
activity underlying simulation are considered. This is to form the necessary
mathematical foundation for manufacturing simulations. The theoretical findings
are explored through a pilot study. A conclusion about the suitability of the
suggested approach to the development of simulation systems for manufacturing
system design is made, and implications for future research are described.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>V. A. Abramov</name>
    </author>
    <author>
      <name>H. Hibino</name>
    </author>
    <author>
      <name>Y. Fukuda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures. Preprint completed in 1998</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: H. Fujimoto and R.E. DeVor (eds), Proceedings of the 1998
  Japan-U.S.A. Symposium on Flexible Automation. 1998, Vol. III, pp. 1307-1314</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606021v1</id>
    <updated>2006-06-06T09:30:58Z</updated>
    <published>2006-06-06T09:30:58Z</published>
    <title>A simulation engine to support production scheduling using
  genetics-based machine learning</title>
    <summary>  The ever higher complexity of manufacturing systems, continually shortening
life cycles of products and their increasing variety, as well as the unstable
market situation of the recent years require introducing grater flexibility and
responsiveness to manufacturing processes. From this perspective, one of the
critical manufacturing tasks, which traditionally attract significant attention
in both academia and the industry, but which have no satisfactory universal
solution, is production scheduling. This paper proposes an approach based on
genetics-based machine learning (GBML) to treat the problem of flow shop
scheduling. By the approach, a set of scheduling rules is represented as an
individual of genetic algorithms, and the fitness of the individual is
estimated based on the makespan of the schedule generated by using the
rule-set. A concept of the interactive software environment consisting of a
simulator and a GBML simulation engine is introduced to support human
decision-making during scheduling. A pilot study is underway to evaluate the
performance of the GBML technique in comparison with other methods (such as
Johnson's algorithm and simulated annealing) while completing test examples.
</summary>
    <author>
      <name>H. Tamaki</name>
    </author>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>S. Kitamura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, 1 table. Preprint completed in 1998</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: K. Mertins, O. Krause, and B. Schallock (eds), Global
  Production Management, pp. 482-489. 1999, Kluwer Academic Publishers</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606039v1</id>
    <updated>2006-06-09T08:00:37Z</updated>
    <published>2006-06-09T08:00:37Z</published>
    <title>Evolutionary Design: Philosophy, Theory, and Application Tactics</title>
    <summary>  Although it has contributed to remarkable improvements in some specific
areas, attempts to develop a universal design theory are generally
characterized by failure. This paper sketches arguments for a new approach to
engineering design based on Semiotics - the science about signs. The approach
is to combine different design theories over all the product life cycle stages
into one coherent and traceable framework. Besides, it is to bring together the
designer's and user's understandings of the notion of 'good product'. Building
on the insight from natural sciences that complex systems always exhibit a
self-organizing meaning-influential hierarchical dynamics, objective laws
controlling product development are found through an examination of design as a
semiosis process. These laws are then applied to support evolutionary design of
products. An experiment validating some of the theoretical findings is
outlined, and concluding remarks are given.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>H. Tamaki</name>
    </author>
    <author>
      <name>S. Kitamura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures. Preprint completed in 1999</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CIRP Journal of Manufacturing Systems, 2005, Vol. 34/2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607083v1</id>
    <updated>2006-07-18T08:07:48Z</updated>
    <published>2006-07-18T08:07:48Z</published>
    <title>Mathematical Modelling of the Thermal Accumulation in Hot Water Solar
  Systems</title>
    <summary>  Mathematical modelling and defining useful recommendations for construction
and regimes of exploitation for hot water solar installation with thermal
stratification is the main purpose of this work. A special experimental solar
module for hot water was build and equipped with sufficient measure apparatus.
The main concept of investigation is to optimise the stratified regime of
thermal accumulation and constructive parameters of heat exchange equipment
(heat serpentine in tank). Accumulation and heat exchange processes were
investigated by theoretical end experimental means. Special mathematical model
was composed to simulate the energy transfer in stratified tank. Computer
program was developed to solve mathematical equations for thermal accumulation
and energy exchange. Extensive numerical and experimental tests were carried
out. A good correspondence between theoretical and experimental data was
arrived. Keywords: Mathematical modelling, accumulation
</summary>
    <author>
      <name>Stanko Vl. Shtrakov</name>
    </author>
    <author>
      <name>Anton Stoilov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609081v1</id>
    <updated>2006-09-14T17:51:11Z</updated>
    <published>2006-09-14T17:51:11Z</published>
    <title>Recurrence relations and fast algorithms</title>
    <summary>  We construct fast algorithms for evaluating transforms associated with
families of functions which satisfy recurrence relations. These include
algorithms both for computing the coefficients in linear combinations of the
functions, given the values of these linear combinations at certain points,
and, vice versa, for evaluating such linear combinations at those points, given
the coefficients in the linear combinations; such procedures are also known as
analysis and synthesis of series of certain special functions. The algorithms
of the present paper are efficient in the sense that their computational costs
are proportional to n (ln n) (ln(1/epsilon))^3, where n is the amount of input
and output data, and epsilon is the precision of computations. Stated somewhat
more precisely, we find a positive real number C such that, for any positive
integer n &gt; 10, the algorithms require at most C n (ln n) (ln(1/epsilon))^3
floating-point operations and words of memory to evaluate at n appropriately
chosen points any linear combination of n special functions, given the
coefficients in the linear combination, where epsilon is the precision of
computations.
</summary>
    <author>
      <name>Mark Tygert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Recurrence relations and fast algorithms, Applied and
  Computational Harmonic Analysis, 28 (1): 121-128, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0609081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609087v1</id>
    <updated>2006-09-15T14:05:43Z</updated>
    <published>2006-09-15T14:05:43Z</published>
    <title>A comparative analysis of the geometrical surface texture of a real and
  virtual model of a tooth flank of a cylindrical gear</title>
    <summary>  The paper presents the methodology of modelling tooth flanks of cylindrical
gears in the Cad environment. The modelling consists in a computer simulation
of gear generation. A model of tooth flanks is an envelope curve of a family of
envelopes that originate from the rolling motion of a solid tool model in
relation to a solid model of the cylindrical gear. The surface stereometry and
topography of the tooth flanks, hobbed and chiselled by Fellows method, are
compared to their numerical models. Metrological measurements of the real gears
were carried out using a coordinated measuring machine and a two - and a
three-dimensional profilometer. A computer simulation of the gear generation
was performed in the Mechanical Desktop environment.
</summary>
    <author>
      <name>Jacek Michalski</name>
    </author>
    <author>
      <name>Leszek Skoczylas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.4; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610053v1</id>
    <updated>2006-10-10T19:37:37Z</updated>
    <published>2006-10-10T19:37:37Z</published>
    <title>Towards a Bayesian framework for option pricing</title>
    <summary>  In this paper, we describe a general method for constructing the posterior
distribution of an option price. Our framework takes as inputs the prior
distributions of the parameters of the stochastic process followed by the
underlying, as well as the likelihood function implied by the observed price
history for the underlying. Our work extends that of Karolyi (1993) and
Darsinos and Satchell (2001), but with the crucial difference that the
likelihood function we use for inference is that which is directly implied by
the underlying, rather than imposed in an ad hoc manner via the introduction of
a function representing "measurement error." As such, an important problem
still relevant for our method is that of model risk, and we address this issue
by describing how to perform a Bayesian averaging of parameter inferences based
on the different models considered using our framework.
</summary>
    <author>
      <name>Henryk Gzyl</name>
    </author>
    <author>
      <name>Enrique ter Horst</name>
    </author>
    <author>
      <name>Samuel Malone</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0610053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612087v1</id>
    <updated>2006-12-18T21:02:03Z</updated>
    <published>2006-12-18T21:02:03Z</published>
    <title>Statistical mechanics of neocortical interactions: Portfolio of
  Physiological Indicators</title>
    <summary>  There are several kinds of non-invasive imaging methods that are used to
collect data from the brain, e.g., EEG, MEG, PET, SPECT, fMRI, etc. It is
difficult to get resolution of information processing using any one of these
methods. Approaches to integrate data sources may help to get better resolution
of data and better correlations to behavioral phenomena ranging from attention
to diagnoses of disease. The approach taken here is to use algorithms developed
for the author's Trading in Risk Dimensions (TRD) code using modern methods of
copula portfolio risk management, with joint probability distributions derived
from the author's model of statistical mechanics of neocortical interactions
(SMNI). The author's Adaptive Simulated Annealing (ASA) code is for
optimizations of training sets, as well as for importance-sampling. Marginal
distributions will be evolved to determine their expected duration and
stability using algorithms developed by the author, i.e., PATHTREE and PATHINT
codes.
</summary>
    <author>
      <name>Lester Ingber</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0612087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702148v1</id>
    <updated>2007-02-25T11:19:25Z</updated>
    <published>2007-02-25T11:19:25Z</published>
    <title>Linking Microscopic and Macroscopic Models for Evolution: Markov Chain
  Network Training and Conservation Law Approximations</title>
    <summary>  In this paper, a general framework for the analysis of a connection between
the training of artificial neural networks via the dynamics of Markov chains
and the approximation of conservation law equations is proposed. This framework
allows us to demonstrate an intrinsic link between microscopic and macroscopic
models for evolution via the concept of perturbed generalized dynamic systems.
The main result is exemplified with a number of illustrative examples where
efficient numerical approximations follow directly from network-based
computational models, viewed here as Markov chain approximations. Finally,
stability and consistency conditions of such computational models are
discussed.
</summary>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Markov Chain network training and conservation law approximations:
  Linking microscopic and macroscopic models for evolution, Melnik, R.V.N.,
  Applied Mathematics and Computation, 199 (1), 315--333, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702149v1</id>
    <updated>2007-02-25T11:09:12Z</updated>
    <published>2007-02-25T11:09:12Z</published>
    <title>Coupling Control and Human-Centered Automation in Mathematical Models of
  Complex Systems</title>
    <summary>  In this paper we analyze mathematically how human factors can be effectively
incorporated into the analysis and control of complex systems. As an example,
we focus our discussion around one of the key problems in the Intelligent
Transportation Systems (ITS) theory and practice, the problem of speed control,
considered here as a decision making process with limited information
available. The problem is cast mathematically in the general framework of
control problems and is treated in the context of dynamically changing
environments where control is coupled to human-centered automation. Since in
this case control might not be limited to a small number of control settings,
as it is often assumed in the control literature, serious difficulties arise in
the solution of this problem. We demonstrate that the problem can be reduced to
a set of Hamilton-Jacobi-Bellman equations where human factors are incorporated
via estimations of the system Hamiltonian. In the ITS context, these
estimations can be obtained with the use of on-board equipment like
sensors/receivers/actuators, in-vehicle communication devices, etc. The
proposed methodology provides a way to integrate human factor into the solving
process of the models for other complex dynamic systems.
</summary>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702163v1</id>
    <updated>2007-02-28T10:39:15Z</updated>
    <published>2007-02-28T10:39:15Z</published>
    <title>First Passage Time for Multivariate Jump-diffusion Stochastic Models
  With Applications in Finance</title>
    <summary>  The ``first passage-time'' (FPT) problem is an important problem with a wide
range of applications in mathematics, physics, biology and finance.
Mathematically, such a problem can be reduced to estimating the probability of
a (stochastic) process first to reach a critical level or threshold. While in
other areas of applications the FPT problem can often be solved analytically,
in finance we usually have to resort to the application of numerical
procedures, in particular when we deal with jump-diffusion stochastic processes
(JDP). In this paper, we develop a Monte-Carlo-based methodology for the
solution of the FPT problem in the context of a multivariate jump-diffusion
stochastic process. The developed methodology is tested by using different
parameters, the simulation results indicate that the developed methodology is
much more efficient than the conventional Monte Carlo method. It is an
efficient tool for further practical applications, such as the analysis of
default correlation and predicting barrier options in finance.
</summary>
    <author>
      <name>Di Zhang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Monte-Carlo simulations, first passage time, multivariate
  jump-diffusion process; 10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702164v1</id>
    <updated>2007-02-28T10:51:16Z</updated>
    <published>2007-02-28T10:51:16Z</published>
    <title>Monte-Carlo Simulations of the First Passage Time for Multivariate
  Jump-Diffusion Processes in Financial Applications</title>
    <summary>  Many problems in finance require the information on the first passage time
(FPT) of a stochastic process. Mathematically, such problems are often reduced
to the evaluation of the probability density of the time for such a process to
cross a certain level, a boundary, or to enter a certain region. While in other
areas of applications the FPT problem can often be solved analytically, in
finance we usually have to resort to the application of numerical procedures,
in particular when we deal with jump-diffusion stochastic processes (JDP). In
this paper, we propose a Monte-Carlo-based methodology for the solution of the
first passage time problem in the context of multivariate (and correlated)
jump-diffusion processes. The developed technique provide an efficient tool for
a number of applications, including credit risk and option pricing. We
demonstrate its applicability to the analysis of the default rates and default
correlations of several different, but correlated firms via a set of empirical
data.
</summary>
    <author>
      <name>Di Zhang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: First passage time; Monte Carlo simulation; Multivariate
  jump-diffusion processes; Credit risk</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702165v1</id>
    <updated>2007-02-28T11:22:18Z</updated>
    <published>2007-02-28T11:22:18Z</published>
    <title>Efficient estimation of default correlation for multivariate
  jump-diffusion processes</title>
    <summary>  Evaluation of default correlation is an important task in credit risk
analysis. In many practical situations, it concerns the joint defaults of
several correlated firms, the task that is reducible to a first passage time
(FPT) problem. This task represents a great challenge for jump-diffusion
processes (JDP), where except for very basic cases, there are no analytical
solutions for such problems. In this contribution, we generalize our previous
fast Monte-Carlo method (non-correlated jump-diffusion cases) for multivariate
(and correlated) jump-diffusion processes. This generalization allows us, among
other things, to evaluate the default events of several correlated assets based
on a set of empirical data. The developed technique is an efficient tool for a
number of other applications, including credit risk and option pricing.
</summary>
    <author>
      <name>Di Zhang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Default correlation, First passage time problem, Monte
  Carlo simulation</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702166v1</id>
    <updated>2007-02-28T11:48:12Z</updated>
    <published>2007-02-28T11:48:12Z</published>
    <title>Solving Stochastic Differential Equations with Jump-Diffusion
  Efficiently: Applications to FPT Problems in Credit Risk</title>
    <summary>  The first passage time (FPT) problem is ubiquitous in many applications. In
finance, we often have to deal with stochastic processes with jump-diffusion,
so that the FTP problem is reducible to a stochastic differential equation with
jump-diffusion. While the application of the conventional Monte-Carlo procedure
is possible for the solution of the resulting model, it becomes computationally
inefficient which severely restricts its applicability in many practically
interesting cases. In this contribution, we focus on the development of
efficient Monte-Carlo-based computational procedures for solving the FPT
problem under the multivariate (and correlated) jump-diffusion processes. We
also discuss the implementation of the developed Monte-Carlo-based technique
for multivariate jump-diffusion processes driving by several compound Poisson
shocks. Finally, we demonstrate the application of the developed methodologies
for analyzing the default rates and default correlations of differently rated
firms via historical data.
</summary>
    <author>
      <name>Di Zhang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Default Correlation, First Passage Time, Multivariate
  Jump-Diffusion Processes, Monte-Carlo Simulation, Multivariate Uniform
  Sampling Method</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702167v1</id>
    <updated>2007-02-28T13:00:33Z</updated>
    <published>2007-02-28T13:00:33Z</published>
    <title>Finite Volume Analysis of Nonlinear Thermo-mechanical Dynamics of Shape
  Memory Alloys</title>
    <summary>  In this paper, the finite volume method is developed to analyze coupled
dynamic problems of nonlinear thermoelasticity. The major focus is given to the
description of martensitic phase transformations essential in the modelling of
shape memory alloys. Computational experiments are carried out to study the
thermo-mechanical wave interactions in a shape memory alloy rod, and a patch.
Both mechanically and thermally induced phase transformations, as well as
hysteresis effects, in a one-dimensional structure are successfully simulated
with the developed methodology. In the two-dimensional case, the main focus is
given to square-to-rectangular transformations and examples of martensitic
combinations under different mechanical loadings are provided.
</summary>
    <author>
      <name>Linxiang X. Wang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: shape memory alloys, phase transformations, nonlinear
  thermo-elasticity, finite volume method</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702168v1</id>
    <updated>2007-02-28T14:09:42Z</updated>
    <published>2007-02-28T14:09:42Z</published>
    <title>Simulation of Phase Combinations in Shape Memory Alloys Patches by
  Hybrid Optimization Methods</title>
    <summary>  In this paper, phase combinations among martensitic variants in shape memory
alloys patches and bars are simulated by a hybrid optimization methodology. The
mathematical model is based on the Landau theory of phase transformations. Each
stable phase is associated with a local minimum of the free energy function,
and the phase combinations are simulated by minimizing the bulk energy. At low
temperature, the free energy function has double potential wells leading to
non-convexity of the optimization problem. The methodology proposed in the
present paper is based on an initial estimate of the global solution by a
genetic algorithm, followed by a refined quasi-Newton procedure to locally
refine the optimum. By combining the local and global search algorithms, the
phase combinations are successfully simulated. Numerical experiments are
presented for the phase combinations in a SMA patch under several typical
mechanical loadings.
</summary>
    <author>
      <name>Linxiang X. Wang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: phase combinations, shape memory alloys, variational
  problem, genetic algorithm, quasi-Newton methods</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702172v1</id>
    <updated>2007-02-28T18:31:19Z</updated>
    <published>2007-02-28T18:31:19Z</published>
    <title>Numerical Model For Vibration Damping Resulting From the First Order
  Phase Transformations</title>
    <summary>  A numerical model is constructed for modelling macroscale damping effects
induced by the first order martensite phase transformations in a shape memory
alloy rod. The model is constructed on the basis of the modified
Landau-Ginzburg theory that couples nonlinear mechanical and thermal fields.
The free energy function for the model is constructed as a double well function
at low temperature, such that the external energy can be absorbed during the
phase transformation and converted into thermal form. The Chebyshev spectral
methods are employed together with backward differentiation for the numerical
analysis of the problem. Computational experiments performed for different
vibration energies demonstrate the importance of taking into account damping
effects induced by phase transformations.
</summary>
    <author>
      <name>Linxiang X. Wang</name>
    </author>
    <author>
      <name>Roderick V. N. Melnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: martensite transformation, thermo-mechanical coupling,
  vibration damping, Ginzburg-Landau theory</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703068v2</id>
    <updated>2007-03-14T20:49:26Z</updated>
    <published>2007-03-14T19:48:42Z</published>
    <title>Option Valuation using Fourier Space Time Stepping</title>
    <summary>  It is well known that the Black-Scholes-Merton model suffers from several
deficiencies. Jump-diffusion and Levy models have been widely used to partially
alleviate some of the biases inherent in this classical model. Unfortunately,
the resulting pricing problem requires solving a more difficult partial-integro
differential equation (PIDE) and although several approaches for solving the
PIDE have been suggested in the literature, none are entirely satisfactory. All
treat the integral and diffusive terms asymmetrically and are difficult to
extend to higher dimensions. We present a new, efficient algorithm, based on
transform methods, which symmetrically treats the diffusive and integrals
terms, is applicable to a wide class of path-dependent options (such as
Bermudan, barrier, and shout options) and options on multiple assets, and
naturally extends to regime-switching Levy models. We present a concise study
of the precision and convergence properties of our algorithm for several
classes of options and Levy models and demonstrate that the algorithm is
second-order in space and first-order in time for path-dependent options.
</summary>
    <author>
      <name>Kenneth R. Jackson</name>
    </author>
    <author>
      <name>Sebastian Jaimungal</name>
    </author>
    <author>
      <name>Vladimir Surkov</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0703068v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703068v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.1768v1</id>
    <updated>2007-04-13T14:48:41Z</updated>
    <published>2007-04-13T14:48:41Z</published>
    <title>Assessment and Propagation of Input Uncertainty in Tree-based Option
  Pricing Models</title>
    <summary>  This paper aims to provide a practical example on the assessment and
propagation of input uncertainty for option pricing when using tree-based
methods. Input uncertainty is propagated into output uncertainty, reflecting
that option prices are as unknown as the inputs they are based on. Option
pricing formulas are tools whose validity is conditional not only on how close
the model represents reality, but also on the quality of the inputs they use,
and those inputs are usually not observable. We provide three alternative
frameworks to calibrate option pricing tree models, propagating parameter
uncertainty into the resulting option prices. We finally compare our methods
with classical calibration-based results assuming that there is no options
market established. These methods can be applied to pricing of instruments for
which there is not an options market, as well as a methodological tool to
account for parameter and model uncertainty in theoretical option pricing.
</summary>
    <author>
      <name>Henryk Gzyl</name>
    </author>
    <author>
      <name>German Molina</name>
    </author>
    <author>
      <name>Enrique ter Horst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.0870v1</id>
    <updated>2007-06-06T17:29:42Z</updated>
    <published>2007-06-06T17:29:42Z</published>
    <title>Inferring the Composition of a Trader Population in a Financial Market</title>
    <summary>  We discuss a method for predicting financial movements and finding pockets of
predictability in the price-series, which is built around inferring the
heterogeneity of trading strategies in a multi-agent trader population. This
work explores extensions to our previous framework (arXiv:physics/0506134).
Here we allow for more intelligent agents possessing a richer strategy set, and
we no longer constrain the estimate for the heterogeneity of the agents to a
probability space. We also introduce a scheme which allows the incorporation of
models with a wide variety of agent types, and discuss a mechanism for the
removal of bias from relevant parameters.
</summary>
    <author>
      <name>Nachi Gupta</name>
    </author>
    <author>
      <name>Raphael Hauser</name>
    </author>
    <author>
      <name>Neil F. Johnson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-88-470-0665-2_7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-88-470-0665-2_7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, to appear as a chapter in "Econophysics and
  Sociophysics of Markets and Networks", Springer-Verlag</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.0870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.0870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3060v1</id>
    <updated>2007-06-20T21:02:14Z</updated>
    <published>2007-06-20T21:02:14Z</published>
    <title>N-Body Simulations on GPUs</title>
    <summary>  Commercial graphics processors (GPUs) have high compute capacity at very low
cost, which makes them attractive for general purpose scientific computing. In
this paper we show how graphics processors can be used for N-body simulations
to obtain improvements in performance over current generation CPUs. We have
developed a highly optimized algorithm for performing the O(N^2) force
calculations that constitute the major part of stellar and molecular dynamics
simulations. In some of the calculations, we achieve sustained performance of
nearly 100 GFlops on an ATI X1900XTX. The performance on GPUs is comparable to
specialized processors such as GRAPE-6A and MDGRAPE-3, but at a fraction of the
cost. Furthermore, the wide availability of GPUs has significant implications
for cluster computing and distributed computing efforts like Folding@Home.
</summary>
    <author>
      <name>Erich Elsen</name>
    </author>
    <author>
      <name>V. Vishal</name>
    </author>
    <author>
      <name>Mike Houston</name>
    </author>
    <author>
      <name>Vijay Pande</name>
    </author>
    <author>
      <name>Pat Hanrahan</name>
    </author>
    <author>
      <name>Eric Darve</name>
    </author>
    <link href="http://arxiv.org/abs/0706.3060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.0181v1</id>
    <updated>2007-07-02T09:47:33Z</updated>
    <published>2007-07-02T09:47:33Z</published>
    <title>Location and Spectral Estimation of Weak Wave Packets on Noise
  Background</title>
    <summary>  The method of location and spectral estimation of weak signals on a noise
background is being considered. The method is based on the optimized on order
and noise dispersion autoregressive model of a sought signal. A new approach of
model order determination is being offered. Available estimation of the noise
dispersion is close to the real one. The optimized model allows to define
function of empirical data spectral and dynamic features changes. The analysis
of the signal as dynamic invariant in respect of the linear shift
transformation yields the function of model consistency. Use of these both
functions enables to detect short-time and nonstationary wave packets at signal
to noise ratio as from -20 dB and above.
</summary>
    <author>
      <name>Yu. Bunyak</name>
    </author>
    <author>
      <name>O. Bunyak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures. Extended version of presentation in the
  conferences IMTC-2007</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.0181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.0181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.0336v2</id>
    <updated>2007-12-21T01:08:18Z</updated>
    <published>2007-07-03T03:28:35Z</published>
    <title>Pricing Options on Defaultable Stocks</title>
    <summary>  In this note, we develop stock option price approximations for a model which
takes both the risk o default and the stochastic volatility into account. We
also let the intensity of defaults be influenced by the volatility. We show
that it might be possible to infer the risk neutral default intensity from the
stock option prices. Our option price approximation has a rich implied
volatility surface structure and fits the data implied volatility well. Our
calibration exercise shows that an effective hazard rate from bonds issued by a
company can be used to explain the implied volatility skew of the implied
volatility of the option prices issued by the same company.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Option pricing, multiscale perturbation methods,
  defaultable stocks, stochastic intensity of default, implied volatility skew</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.0336v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.0336v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.2432v7</id>
    <updated>2008-10-29T13:49:51Z</updated>
    <published>2007-07-17T04:55:18Z</published>
    <title>Pricing Asian Options for Jump Diffusions</title>
    <summary>  We construct a sequence of functions that uniformly converge (on compact
sets) to the price of Asian option, which is written on a stock whose dynamics
follows a jump diffusion, exponentially fast. Each of the element in this
sequence solves a parabolic partial differen- tial equation (not an
integro-differential equation). As a result we obtain a fast numerical
approximation scheme whose accuracy versus speed characteristics can be
controlled. We analyze the performance of our numerical algorithm on several
examples.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Hao Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Pricing Asian Options, Jump diffusions, an Iterative
  Numerical Scheme, Classical Solutions of Integro-PDEs</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.2432v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.2432v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3531v1</id>
    <updated>2007-07-24T12:00:43Z</updated>
    <published>2007-07-24T12:00:43Z</published>
    <title>e-Science initiatives in Venezuela</title>
    <summary>  Within the context of the nascent e-Science infrastructure in Venezuela, we
describe several web-based scientific applications developed at the Centro
Nacional de Calculo Cientifico Universidad de Los Andes (CeCalCULA), Merida,
and at the Instituto Venezolano de Investigaciones Cientificas (IVIC), Caracas.
The different strategies that have been followed for implementing quantum
chemistry and atomic physics applications are presented. We also briefly
discuss a damage portal based on dynamic, nonlinear, finite elements of lumped
damage mechanics and a biomedical portal developed within the framework of the
\textit{E-Infrastructure shared between Europe and Latin America} (EELA)
initiative for searching common sequences and inferring their functions in
parasitic diseases such as leishmaniasis, chagas and malaria.
</summary>
    <author>
      <name>J. L. Chaves</name>
    </author>
    <author>
      <name>G. Diaz</name>
    </author>
    <author>
      <name>V. Hamar</name>
    </author>
    <author>
      <name>R. Isea</name>
    </author>
    <author>
      <name>F. Rojas</name>
    </author>
    <author>
      <name>N. Ruiz</name>
    </author>
    <author>
      <name>R. Torrens</name>
    </author>
    <author>
      <name>M. Uzcategui</name>
    </author>
    <author>
      <name>J. Florez-Lopez</name>
    </author>
    <author>
      <name>H. Hoeger</name>
    </author>
    <author>
      <name>C. Mendoza</name>
    </author>
    <author>
      <name>L. A. Nunez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Procceedings Spanish Conference on e-Science Grid Computing, J.
  Casado, R. Mayo y R. Munoz (Editors) CIEMAT, Madrid Spain (2007), pp 45 - 52</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1116v3</id>
    <updated>2009-07-02T12:31:15Z</updated>
    <published>2007-08-08T15:07:53Z</published>
    <title>A variant of the Recoil Growth algorithm to generate multi-polymer
  systems</title>
    <summary>  The Recoil Growth algorithm, proposed in 1999 by Consta et al., is one of the
most efficient algorithm available in the literature to sample from a
multi-polymer system. Such problems are closely related to the generation of
self-avoiding paths. In this paper, we study a variant of the original Recoil
Growth algorithm, where we constrain the generation of a new polymer to take
place on a specific class of graphs. This makes it possible to make a fine
trade-off between computational cost and success rate. We moreover give a
simple proof for a lower bound on the irreducibility of this new algorithm,
which applies to the original algorithm as well.
</summary>
    <author>
      <name>Florian Simatos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Title changed</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.1116v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1116v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1818v1</id>
    <updated>2007-08-14T08:17:45Z</updated>
    <published>2007-08-14T08:17:45Z</published>
    <title>Computational Simulation and 3D Virtual Reality Engineering Tools for
  Dynamical Modeling and Imaging of Composite Nanomaterials</title>
    <summary>  An adventure at engineering design and modeling is possible with a Virtual
Reality Environment (VRE) that uses multiple computer-generated media to let a
user experience situations that are temporally and spatially prohibiting. In
this paper, an approach to developing some advanced architecture and modeling
tools is presented to allow multiple frameworks work together while being
shielded from the application program. This architecture is being developed in
a framework of workbench interactive tools for next generation
nanoparticle-reinforced damping/dynamic systems. Through the use of system, an
engineer/programmer can respectively concentrate on tailoring an engineering
design concept of novel system and the application software design while using
existing databases/software outputs.
</summary>
    <author>
      <name>L. -V. Bochkareva</name>
    </author>
    <author>
      <name>M. -V. Kireitseu</name>
    </author>
    <author>
      <name>G. R. Tomlinson</name>
    </author>
    <author>
      <name>H. Altenbach</name>
    </author>
    <author>
      <name>V. Kompis</name>
    </author>
    <author>
      <name>D. Hui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of TIMA Editions
  (http://irevues.inist.fr/tima-editions)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans European Nano Systems Worshop - ENS 2005, Paris : France
  (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.1818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3829v1</id>
    <updated>2007-08-28T18:29:55Z</updated>
    <published>2007-08-28T18:29:55Z</published>
    <title>A Non Parametric Model for the Forecasting of the Venezuelan Oil Prices</title>
    <summary>  A neural net model for forecasting the prices of Venezuelan crude oil is
proposed. The inputs of the neural net are selected by reference to a dynamic
system model of oil prices by Mashayekhi (1995, 2001) and its performance is
evaluated using two criteria: the Excess Profitability test by Anatoliev and
Gerko (2005) and the characteristics of the equity curve generated by a trading
strategy based on the neural net predictions.
  -----
  Se introduce aqui un modelo no parametrico para pronosticar los precios del
petroleo Venezolano cuyos insumos son seleccionados en base a un sistema
dinamico que explica los precios en terminos de dichos insumos. Se describe el
proceso de recoleccion y pre-procesamiento de datos y la corrida de la red y se
evaluan sus pronosticos a traves de un test estadistico de predictibilidad y de
las caracteristicas del Equity Curve inducido por la estrategia de compraventa
bursatil generada por dichos pronosticos.
</summary>
    <author>
      <name>Sabatino Costanzo</name>
    </author>
    <author>
      <name>Loren Trigo</name>
    </author>
    <author>
      <name>Wafaa Dehne</name>
    </author>
    <author>
      <name>Hender Prato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, in Spanish</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.3829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0355v1</id>
    <updated>2007-09-04T14:51:56Z</updated>
    <published>2007-09-04T14:51:56Z</published>
    <title>Solution of moving-boundary problems by the spectral element method</title>
    <summary>  This paper describes a novel numerical model aiming at solving
moving-boundary problems such as free-surface flows or fluid-structure
interaction. This model uses a moving-grid technique to solve the
Navier--Stokes equations expressed in the arbitrary Lagrangian--Eulerian
kinematics. The discretization in space is based on the spectral element
method. The coupling of the fluid equations and the moving-grid equations is
essentially done through the conditions on the moving boundaries. Two- and
three-dimensional simulations are presented: translation and rotation of a
cylinder in a fluid, and large-amplitude sloshing in a rectangular tank. The
accuracy and robustness of the present numerical model is studied and
discussed.
</summary>
    <author>
      <name>Nicolas Bodard</name>
    </author>
    <author>
      <name>Roland Bouffanais</name>
    </author>
    <author>
      <name>Michel O. Deville</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.apnum.2007.04.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.apnum.2007.04.009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Numerical Mathematics, In Press, 2008</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Numerial Mathematics 58 (2008) 968-984</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0709.0355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.3621v1</id>
    <updated>2007-10-19T02:17:35Z</updated>
    <published>2007-10-19T02:17:35Z</published>
    <title>Numerical removal of water-vapor effects from THz-TDS measurements</title>
    <summary>  One source of disturbance in a pulsed T-ray signal is attributed to ambient
water vapor. Water molecules in the gas phase selectively absorb T-rays at
discrete frequencies corresponding to their molecular rotational transitions.
This results in prominent resonances spread over the T-ray spectrum, and in the
time domain the T-ray signal is observed as fluctuations after the main pulse.
These effects are generally undesired, since they may mask critical
spectroscopic data. So, ambient water vapor is commonly removed from the T-ray
path by using a closed chamber during the measurement. Yet, in some
applications a closed chamber is not applicable. This situation, therefore,
motivates the need for another method to reduce these unwanted artifacts. This
paper presents a study on a computational means to address the problem.
Initially, a complex frequency response of water vapor is modeled from a
spectroscopic catalog. Using a deconvolution technique, together with fine
tuning of the strength of each resonance, parts of the water-vapor response are
removed from a measured T-ray signal, with minimal signal distortion.
</summary>
    <author>
      <name>Withawat Withayachumnankul</name>
    </author>
    <author>
      <name>Bernd M. Fischer</name>
    </author>
    <author>
      <name>Samuel P. Mickan</name>
    </author>
    <author>
      <name>Derek Abbott</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rspa.2007.0294</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rspa.2007.0294" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Royal Society A: Mathematical, Physical &amp;
  Engineering Sciences, vol. 464, no. 2097, pp 2435-2456, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.3621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.3621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.5512v1</id>
    <updated>2007-10-29T20:00:15Z</updated>
    <published>2007-10-29T20:00:15Z</published>
    <title>Risk Minimization and Optimal Derivative Design in a Principal Agent
  Game</title>
    <summary>  We consider the problem of Adverse Selection and optimal derivative design
within a Principal-Agent framework. The principal's income is exposed to
non-hedgeable risk factors arising, for instance, from weather or climate
phenomena. She evaluates her risk using a coherent and law invariant risk
measure and tries minimize her exposure by selling derivative securities on her
income to individual agents. The agents have mean-variance preferences with
heterogeneous risk aversion coefficients. An agent's degree of risk aversion is
private information and hidden to the principal who only knows the overall
distribution. We show that the principal's risk minimization problem has a
solution and illustrate the effects of risk transfer on her income by means of
two specific examples. Our model extends earlier work of Barrieu and El Karoui
(2005) and Carlier, Ekeland and Touzi (2007).
</summary>
    <author>
      <name>U. Horst</name>
    </author>
    <author>
      <name>S. Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.5512v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.5512v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2116v1</id>
    <updated>2007-11-14T06:21:17Z</updated>
    <published>2007-11-14T06:21:17Z</published>
    <title>A numerical approach for 3D manufacturing tolerances synthesis</title>
    <summary>  Making a product conform to the functional requirements indicated by the
customer suppose to be able to manage the manufacturing process chosen to
realise the parts. A simulation step is generally performed to verify that the
expected generated deviations fit with these requirements. It is then necessary
to assess the actual deviations of the process in progress. This is usually
done by the verification of the conformity of the workpiece to manufacturing
tolerances at the end of each set-up. It is thus necessary to determine these
manufacturing tolerances. This step is called "manufacturing tolerance
synthesis". In this paper, a numerical method is proposed to perform 3D
manufacturing tolerances synthesis. This method uses the result of the
numerical analysis of tolerances to determine influent mall displacement of
surfaces. These displacements are described by small displacements torsors. An
algorithm is then proposed to determine suitable ISO manufacturing tolerances.
</summary>
    <author>
      <name>Frédéric Vignat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGS</arxiv:affiliation>
    </author>
    <author>
      <name>François Villeneuve</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of the 10th CIRP International Seminar on
  Computer Aided Tolerancing - 10th CIRP International Seminar on Computer
  Aided Tolerancing, Erlangen : Allemagne (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.2116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.2398v2</id>
    <updated>2008-01-18T21:38:37Z</updated>
    <published>2008-01-15T22:22:25Z</published>
    <title>Removing the Stiffness of Elastic Force from the Immersed Boundary
  Method for the 2D Stokes Equations</title>
    <summary>  The Immersed Boundary method has evolved into one of the most useful
computational methods in studying fluid structure interaction. On the other
hand, the Immersed Boundary method is also known to suffer from a severe
timestep stability restriction when using an explicit time discretization. In
this paper, we propose several efficient semi-implicit schemes to remove this
stiffness from the Immersed Boundary method for the two-dimensional Stokes
flow. First, we obtain a novel unconditionally stable semi-implicit
discretization for the immersed boundary problem. Using this unconditionally
stable discretization as a building block, we derive several efficient
semi-implicit schemes for the immersed boundary problem by applying the Small
Scale Decomposition to this unconditionally stable discretization. Our
stability analysis and extensive numerical experiments show that our
semi-implicit schemes offer much better stability property than the explicit
scheme. Unlike other implicit or semi-implicit schemes proposed in the
literature, our semi-implicit schemes can be solved explicitly in the spectral
space. Thus the computational cost of our semi-implicit schemes is comparable
to that of an explicit scheme, but with a much better stability property.
</summary>
    <author>
      <name>Thomas Y. Hou</name>
    </author>
    <author>
      <name>Zuoqiang Shi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2008.03.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2008.03.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages with 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.2398v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.2398v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3046v3</id>
    <updated>2009-01-02T04:15:45Z</updated>
    <published>2008-01-19T18:54:01Z</published>
    <title>A model for reactive porous transport during re-wetting of hardened
  concrete</title>
    <summary>  A mathematical model is developed that captures the transport of liquid water
in hardened concrete, as well as the chemical reactions that occur between the
imbibed water and the residual calcium silicate compounds residing in the
porous concrete matrix. The main hypothesis in this model is that the reaction
product -- calcium silicate hydrate gel -- clogs the pores within the concrete
thereby hindering water transport. Numerical simulations are employed to
determine the sensitivity of the model solution to changes in various physical
parameters, and compare to experimental results available in the literature.
</summary>
    <author>
      <name>Michael Chapwanya</name>
    </author>
    <author>
      <name>Wentao Liu</name>
    </author>
    <author>
      <name>John M. Stockie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10665-009-9268-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10665-009-9268-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Engineering Mathematics, 65(1):53-73, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0801.3046v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3046v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.4126v1</id>
    <updated>2008-02-28T04:56:48Z</updated>
    <published>2008-02-28T04:56:48Z</published>
    <title>Hospital Case Cost Estimates Modelling - Algorithm Comparison</title>
    <summary>  Ontario (Canada) Health System stakeholders support the idea and necessity of
the integrated source of data that would include both clinical (e.g. diagnosis,
intervention, length of stay, case mix group) and financial (e.g. cost per
weighted case, cost per diem) characteristics of the Ontario healthcare system
activities at the patient-specific level. At present, the actual patient-level
case costs in the explicit form are not available in the financial databases
for all hospitals. The goal of this research effort is to develop financial
models that will assign each clinical case in the patient-specific data
warehouse a dollar value, representing the cost incurred by the Ontario health
care facility which treated the patient. Five mathematical models have been
developed and verified using real dataset. All models can be classified into
two groups based on their underlying method: 1. Models based on using relative
intensity weights of the cases, and 2. Models based on using cost per diem.
</summary>
    <author>
      <name>Peter Andru</name>
    </author>
    <author>
      <name>Alexei Botchkarev</name>
    </author>
    <link href="http://arxiv.org/abs/0802.4126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.4126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1187v1</id>
    <updated>2008-04-08T06:24:49Z</updated>
    <published>2008-04-08T06:24:49Z</published>
    <title>Méthode de calcul du rayonnement acoustique de structures complexes</title>
    <summary>  In the automotive industry, predicting noise during design cycle is a
necessary step. Well-known methods exist to answer this issue in low frequency
domain. Among these, Finite Element Methods, adapted to closed domains, are
quite easy to implement whereas Boundary Element Methods are more adapted to
infinite domains, but may induce singularity problems. In this article, the
described method, the SDM, allows to use both methods in their best application
domain. A new method is also presented to solve the SDM exterior problem.
Instead of using Boundary Element Methods, an original use of Finite Elements
is made. Efficiency of this new version of the Substructure Deletion Method is
discussed.
</summary>
    <author>
      <name>Marianne Viallet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTDS</arxiv:affiliation>
    </author>
    <author>
      <name>Gérald Poumérol</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTDS</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Dessombz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTDS</arxiv:affiliation>
    </author>
    <author>
      <name>Louis Jezequel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTDS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Actes du huiti\`eme colloque national en Calcul des
  structures - GIENS 2007 - Huiti\`eme colloque national en Calcul des
  structures, Giens : France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.1187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.0360v1</id>
    <updated>2008-05-03T13:00:42Z</updated>
    <published>2008-05-03T13:00:42Z</published>
    <title>Prediction and Mitigation of Crush Conditions in Emergency Evacuations</title>
    <summary>  Several simulation environments exist for the simulation of large-scale
evacuations of buildings, ships, or other enclosed spaces. These offer
sophisticated tools for the study of human behaviour, the recreation of
environmental factors such as fire or smoke, and the inclusion of architectural
or structural features, such as elevators, pillars and exits. Although such
simulation environments can provide insights into crowd behaviour, they lack
the ability to examine potentially dangerous forces building up within a crowd.
These are commonly referred to as crush conditions, and are a common cause of
death in emergency evacuations.
  In this paper, we describe a methodology for the prediction and mitigation of
crush conditions. The paper is organised as follows. We first establish the
need for such a model, defining the main factors that lead to crush conditions,
and describing several exemplar case studies. We then examine current methods
for studying crush, and describe their limitations. From this, we develop a
three-stage hybrid approach, using a combination of techniques. We conclude
with a brief discussion of the potential benefits of our approach.
</summary>
    <author>
      <name>Peter J. Harding</name>
    </author>
    <author>
      <name>Martyn Amos</name>
    </author>
    <author>
      <name>Steve Gwynne</name>
    </author>
    <link href="http://arxiv.org/abs/0805.0360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.0360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.1475v1</id>
    <updated>2008-07-09T16:04:37Z</updated>
    <published>2008-07-09T16:04:37Z</published>
    <title>Simulations of Large-scale WiFi-based Wireless Networks:
  Interdisciplinary Challenges and Applications</title>
    <summary>  Wireless Fidelity (WiFi) is the fastest growing wireless technology to date.
In addition to providing wire-free connectivity to the Internet WiFi technology
also enables mobile devices to connect directly to each other and form highly
dynamic wireless adhoc networks. Such distributed networks can be used to
perform cooperative communication tasks such ad data routing and information
dissemination in the absence of a fixed infrastructure. Furthermore, adhoc
grids composed of wirelessly networked portable devices are emerging as a new
paradigm in grid computing. In this paper we review computational and
algorithmic challenges of high-fidelity simulations of such WiFi-based wireless
communication and computing networks, including scalable topology maintenance,
mobility modelling, parallelisation and synchronisation. We explore
similarities and differences between the simulations of these networks and
simulations of interacting many-particle systems, such as molecular dynamics
(MD) simulations. We show how the cell linked-list algorithm which we have
adapted from our MD simulations can be used to greatly improve the
computational performance of wireless network simulators in the presence of
mobility, and illustrate with an example from our simulation studies of worm
attacks on mobile wireless adhoc networks.
</summary>
    <author>
      <name>Maziar Nekovee</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.future.2008.05.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.future.2008.05.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Future Generation Computer Systems, Article in Press</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.1475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.1475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3187v1</id>
    <updated>2008-09-18T15:29:40Z</updated>
    <published>2008-09-18T15:29:40Z</published>
    <title>A Control Variate Approach for Improving Efficiency of Ensemble Monte
  Carlo</title>
    <summary>  In this paper we present a new approach to control variates for improving
computational efficiency of Ensemble Monte Carlo. We present the approach using
simulation of paths of a time-dependent nonlinear stochastic equation. The core
idea is to extract information at one or more nominal model parameters and use
this information to gain estimation efficiency at neighboring parameters. This
idea is the basis of a general strategy, called DataBase Monte Carlo (DBMC),
for improving efficiency of Monte Carlo. In this paper we describe how this
strategy can be implemented using the variance reduction technique of Control
Variates (CV). We show that, once an initial setup cost for extracting
information is incurred, this approach can lead to significant gains in
computational efficiency. The initial setup cost is justified in projects that
require a large number of estimations or in those that are to be performed
under real-time constraints.
</summary>
    <author>
      <name>T. Borogovac</name>
    </author>
    <author>
      <name>F. J. Alexander</name>
    </author>
    <author>
      <name>P. Vakili</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 ps figures, elsart.cls</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.3187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; J.2; I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.2637v1</id>
    <updated>2008-11-17T08:33:49Z</updated>
    <published>2008-11-17T08:33:49Z</published>
    <title>The Design of Compressive Sensing Filter</title>
    <summary>  In this paper, the design of universal compressive sensing filter based on
normal filters including the lowpass, highpass, bandpass, and bandstop filters
with different cutoff frequencies (or bandwidth) has been developed to enable
signal acquisition with sub-Nyquist sampling. Moreover, to control flexibly the
size and the coherence of the compressive sensing filter, as an example, the
microstrip filter based on defected ground structure (DGS) has been employed to
realize the compressive sensing filter. Of course, the compressive sensing
filter also can be constructed along the identical idea by many other
structures, for example, the man-made electromagnetic materials, the plasma
with different electron density, and so on. By the proposed architecture, the
n-dimensional signals of S-sparse in arbitrary orthogonal frame can be exactly
reconstructed with measurements on the order of Slog(n) with overwhelming
probability, which is consistent with the bonds estimated by theoretical
analysis.
</summary>
    <author>
      <name>Lianlin Li</name>
    </author>
    <author>
      <name>Wenji Zhang</name>
    </author>
    <author>
      <name>Yin Xiang</name>
    </author>
    <author>
      <name>Fang Li</name>
    </author>
    <link href="http://arxiv.org/abs/0811.2637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.2637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.0763v1</id>
    <updated>2009-02-04T18:29:21Z</updated>
    <published>2009-02-04T18:29:21Z</published>
    <title>Genetic algorithm based optimization and post optimality analysis of
  multi-pass face milling</title>
    <summary>  This paper presents an optimization technique for the multi-pass face milling
process. Genetic algorithm (GA) is used to obtain the optimum cutting
parameters by minimizing the unit production cost for a given amount of
material removal. Cutting speed, feed and depth of cut for the finish and rough
passes are the cutting parameters. An equal depth of cut for roughing passes
has been considered. A lookup table containing the feasible combinations of
depth of cut in finish and rough passes is generated so as to reduce the number
of variables by one. The resulting mixed integer nonlinear optimization problem
is solved in a single step using GA. The entire technique is demonstrated in a
case study. Post optimality analysis of the example problem is done to develop
a strategy for optimizing without running GA again for different values of
total depth of cut.
</summary>
    <author>
      <name>Sourabh Saha</name>
    </author>
    <link href="http://arxiv.org/abs/0902.0763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.0763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3541v1</id>
    <updated>2009-02-20T10:28:14Z</updated>
    <published>2009-02-20T10:28:14Z</published>
    <title>System approach to synthesis, modeling and control of complex dynamical
  systems</title>
    <summary>  We consider the basic features of complex dynamical and control systems.
Special attention is paid to the problems of synthesis of dynamical models of
complex systems, construction of efficient control models, and to the
development of simulation techniques. We propose an approach to the synthesis
of dynamic models of complex systems that integrates expert knowledge with the
process of modeling. A set-theoretic model of complex system is defined and
briefly analyzed. A mathematical model of complex dynamical system with
control, based on aggregate description, is also proposed. The structure of the
model is described, and architecture of computer simulation system is
presented, requirements to and components of computer simulation systems are
analyzed.
</summary>
    <author>
      <name>Armen Bagdasaryan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 fig.; submitted for journal publication</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WSEAS Trans. Systems and Control, vol. 4, no. 2, 2009, pp. 77-87</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.3541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2641v1</id>
    <updated>2009-03-15T16:27:55Z</updated>
    <published>2009-03-15T16:27:55Z</published>
    <title>Multiscale Computations on Neural Networks: From the Individual Neuron
  Interactions to the Macroscopic-Level Analysis</title>
    <summary>  We show how the Equation-Free approach for multi-scale computations can be
exploited to systematically study the dynamics of neural interactions on a
random regular connected graph under a pairwise representation perspective.
Using an individual-based microscopic simulator as a black box coarse-grained
timestepper and with the aid of simulated annealing we compute the
coarse-grained equilibrium bifurcation diagram and analyze the stability of the
stationary states sidestepping the necessity of obtaining explicit closures at
the macroscopic level. We also exploit the scheme to perform a rare-events
analysis by estimating an effective Fokker-Planck describing the evolving
probability density function of the corresponding coarse-grained observables.
</summary>
    <author>
      <name>Konstantinos G. Spiliotis</name>
    </author>
    <author>
      <name>Constantinos I. Siettos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0218127410025442</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0218127410025442" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Bifurcation and Chaos 20 (1) 121-134 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.2641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.4771v3</id>
    <updated>2010-12-15T02:23:48Z</updated>
    <published>2009-05-29T01:49:38Z</published>
    <title>Variational structure of the optimal artificial diffusion method for the
  advection-diffusion equation</title>
    <summary>  In this research note we provide a variational basis for the optimal
artificial diffusion method, which has been a cornerstone in developing many
stabilized methods. The optimal artificial diffusion method produces exact
nodal solutions when applied to one-dimensional problems with constant
coefficients and forcing function. We first present a variational principle for
a multi-dimensional advective-diffusive system, and then derive a new stable
weak formulation. When applied to one-dimensional problems with constant
coefficients and forcing function, this resulting weak formulation will be
equivalent to the optimal artificial diffusion method. We present
representative numerical results to corroborate our theoretical findings.
</summary>
    <author>
      <name>K. B. Nakshatrala</name>
    </author>
    <author>
      <name>A. J. Valocchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.4771v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.4771v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.4580v1</id>
    <updated>2009-08-31T16:57:35Z</updated>
    <published>2009-08-31T16:57:35Z</published>
    <title>A Computational View of Market Efficiency</title>
    <summary>  We propose to study market efficiency from a computational viewpoint.
Borrowing from theoretical computer science, we define a market to be
\emph{efficient with respect to resources $S$} (e.g., time, memory) if no
strategy using resources $S$ can make a profit. As a first step, we consider
memory-$m$ strategies whose action at time $t$ depends only on the $m$ previous
observations at times $t-m,...,t-1$. We introduce and study a simple model of
market evolution, where strategies impact the market by their decision to buy
or sell. We show that the effect of optimal strategies using memory $m$ can
lead to "market conditions" that were not present initially, such as (1) market
bubbles and (2) the possibility for a strategy using memory $m' &gt; m$ to make a
bigger profit than was initially possible. We suggest ours as a framework to
rationalize the technological arms race of quantitative trading firms.
</summary>
    <author>
      <name>Jasmina Hasanhodzic</name>
    </author>
    <author>
      <name>Andrew W. Lo</name>
    </author>
    <author>
      <name>Emanuele Viola</name>
    </author>
    <link href="http://arxiv.org/abs/0908.4580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.4580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.0611v2</id>
    <updated>2010-07-05T00:02:40Z</updated>
    <published>2009-09-03T09:38:18Z</published>
    <title>Effects of Mechanical Coupling on the Dynamics of Balancing Tasks</title>
    <summary>  Coupled human balancing tasks are investigated based on both pseudo-neural
controllers characterized by time-delayed feedback with random gain and natural
human balancing tasks. It is shown numerically that, compared to single
balancing tasks, balancing tasks coupled by mechanical structures exhibit
enhanced stability against balancing errors in terms of both amplitude and
velocity and also improve the tracking ability of the controllers. We then
perform an experiment in which numerical pseudo-neural controllers are replaced
with natural human balancing tasks carried out using computer mice. The results
reveal that the coupling structure generates asymmetric tracking abilities in
subjects whose tracking abilities are nearly symmetric in their single
balancing tasks.
</summary>
    <author>
      <name>Katsutoshi Yoshida</name>
    </author>
    <author>
      <name>Atsushi Higeta</name>
    </author>
    <author>
      <name>Shinichi Watanabe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Innovative Computing, Information and
  Control, Vol.7, No.4, April 2011, pp.1661-1674</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.0611v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.0611v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1405v1</id>
    <updated>2009-09-08T06:43:54Z</updated>
    <published>2009-09-08T06:43:54Z</published>
    <title>A Hybrid Multi Objective Particle Swarm Optimization Method to Discover
  Biclusters in Microarray Data</title>
    <summary>  In recent years, with the development of microarray technique, discovery of
useful knowledge from microarray data has become very important. Biclustering
is a very useful data mining technique for discovering genes which have similar
behavior. In microarray data, several objectives have to be optimized
simultaneously and often these objectives are in conflict with each other. A
Multi Objective model is capable of solving such problems. Our method proposes
a Hybrid algorithm which is based on the Multi Objective Particle Swarm
Optimization for discovering biclusters in gene expression data. In our method,
we will consider a low level of overlapping amongst the biclusters and try to
cover all elements of the gene expression matrix. Experimental results in the
bench mark database show a significant improvement in both overlap among
biclusters and coverage of elements in the gene expression matrix.
</summary>
    <author>
      <name>Mohsen lashkargir</name>
    </author>
    <author>
      <name>S. Amirhassan Monadjemi</name>
    </author>
    <author>
      <name>Ahmad Baraani Dastjerdi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.1405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.5583v2</id>
    <updated>2010-08-31T17:00:19Z</updated>
    <published>2009-09-30T11:53:18Z</published>
    <title>Two-Phase Flow Complexity in Heterogeneous Media</title>
    <summary>  In this study, we investigate the appeared complexity of two-phase flow
(air/water) in a heterogeneous soil where the supposed porous media is
non-deformable media which is under the timedependent gas pressure. After
obtaining of governing equations and considering the capillary
pressuresaturation and permeability functions, the evolution of the model
unknown parameters were obtained. In this way, using COMSOL (FEMLAB) and fluid
flow/script Module, the role of heterogeneity in intrinsic permeability was
analysed. Also, the evolution of relative permeability of wetting and
non-wetting fluid, capillary pressure and other parameters were elicited. In
the last part, a complex network approach to analysis of emerged patterns will
be employed.
</summary>
    <author>
      <name>Hamed O. Ghaffari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author. A report /version 2- Due
  to copy right the manuscript is not available</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.5583v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.5583v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0663v7</id>
    <updated>2010-12-09T08:33:24Z</updated>
    <published>2009-10-05T03:08:43Z</published>
    <title>Transmission line inspires a new distributed algorithm to solve linear
  system of circuit</title>
    <summary>  Transmission line, or wire, is always troublesome to integrated circuits
designers, but it could be helpful to parallel computing researchers. This
paper proposes the Virtual Transmission Method (VTM), which is a new
distributed and stationary iterative algorithm to solve the linear system
extracted from circuit. It tears the circuit by virtual transmission lines to
achieve distributed computing. For the symmetric positive definite (SPD) linear
system, VTM is proved to be convergent. For the unsymmetrical linear system,
numerical experiments show that VTM is possible to achieve better convergence
property than the traditional stationary algorithms. VTM could be accelerated
by some preconditioning techniques, and the convergence speed of VTM is fast
when its preconditioner is properly chosen.
</summary>
    <author>
      <name>Fei Wei</name>
    </author>
    <author>
      <name>Huazhong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work was finished in Nov 2007. Recently we are preparing it for
  IEEE Trans. CAD. More info, see my web page at
  http://weifei00.googlepages.com</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.0663v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0663v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F10, 65F50, 68M14" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.0; B.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0928v1</id>
    <updated>2009-10-06T06:25:34Z</updated>
    <published>2009-10-06T06:25:34Z</published>
    <title>BioDiVinE: A Framework for Parallel Analysis of Biological Models</title>
    <summary>  In this paper a novel tool BioDiVinEfor parallel analysis of biological
models is presented. The tool allows analysis of biological models specified in
terms of a set of chemical reactions. Chemical reactions are transformed into a
system of multi-affine differential equations. BioDiVinE employs techniques for
finite discrete abstraction of the continuous state space. At that level,
parallel analysis algorithms based on model checking are provided. In the
paper, the key tool features are described and their application is
demonstrated by means of a case study.
</summary>
    <author>
      <name>Jiří Barnat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Luboš Brim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Ivana Černá</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Sven Dražan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Jana Fabriková</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Jan Láník</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>David Šafránek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Hongwu Ma</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Edinburgh</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.6.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.6.3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 6, 2009, pp. 31-45</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.0928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.3880v1</id>
    <updated>2009-10-20T15:37:52Z</updated>
    <published>2009-10-20T15:37:52Z</published>
    <title>Constraint-based Local Move Definitions for Lattice Protein Models
  Including Side Chains</title>
    <summary>  The simulation of a protein's folding process is often done via stochastic
local search, which requires a procedure to apply structural changes onto a
given conformation. Here, we introduce a constraint-based approach to enumerate
lattice protein structures according to k-local moves in arbitrary lattices.
Our declarative description is much more flexible for extensions than standard
operational formulations. It enables a generic calculation of k-local neighbors
in backbone-only and side chain models. We exemplify the procedure using a
simple hierarchical folding scheme.
</summary>
    <author>
      <name>Martin Mann</name>
    </author>
    <author>
      <name>Mohamed Abou Hamra</name>
    </author>
    <author>
      <name>Kathleen Steinhöfel</name>
    </author>
    <author>
      <name>Rolf Backofen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Proceedings of the Fifth Workshop on Constraint Based
  Methods for Bioinformatics (WCB09), 2009, 10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fifth Workshop on Constraint Based Methods
  for Bioinformatics (WCB09), 2009, Lisbon</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.3880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.3880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.6; G.2.1; J.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.2330v1</id>
    <updated>2009-11-12T09:04:01Z</updated>
    <published>2009-11-12T09:04:01Z</published>
    <title>Diffusion Controlled Reactions, Fluctuation Dominated Kinetics, and
  Living Cell Biochemistry</title>
    <summary>  In recent years considerable portion of the computer science community has
focused its attention on understanding living cell biochemistry and efforts to
understand such complication reaction environment have spread over wide front,
ranging from systems biology approaches, through network analysis (motif
identification) towards developing language and simulators for low level
biochemical processes. Apart from simulation work, much of the efforts are
directed to using mean field equations (equivalent to the equations of
classical chemical kinetics) to address various problems (stability,
robustness, sensitivity analysis, etc.). Rarely is the use of mean field
equations questioned. This review will provide a brief overview of the
situations when mean field equations fail and should not be used. These
equations can be derived from the theory of diffusion controlled reactions, and
emerge when assumption of perfect mixing is used.
</summary>
    <author>
      <name>Zoran Konkoli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.9.11</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.9.11" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 9, 2009, pp. 98-107</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.2330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.2330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.2829v1</id>
    <updated>2009-11-15T03:35:32Z</updated>
    <published>2009-11-15T03:35:32Z</published>
    <title>Proceedings Fifth Workshop on Developments in Computational
  Models--Computational Models From Nature</title>
    <summary>  The special theme of DCM 2009, co-located with ICALP 2009, concerned
Computational Models From Nature, with a particular emphasis on computational
models derived from physics and biology. The intention was to bring together
different approaches - in a community with a strong foundational background as
proffered by the ICALP attendees - to create inspirational cross-boundary
exchanges, and to lead to innovative further research. Specifically DCM 2009
sought contributions in quantum computation and information, probabilistic
models, chemical, biological and bio-inspired ones, including spatial models,
growth models and models of self-assembly. Contributions putting to the test
logical or algorithmic aspects of computing (e.g., continuous computing with
dynamical systems, or solid state computing models) were also very much
welcomed.
</summary>
    <author>
      <name>S. Barry Cooper</name>
    </author>
    <author>
      <name>Vincent Danos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.9" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 9, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.2829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.2829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4510v1</id>
    <updated>2009-11-23T22:57:45Z</updated>
    <published>2009-11-23T22:57:45Z</published>
    <title>Bigraphical models for protein and membrane interactions</title>
    <summary>  We present a bigraphical framework suited for modeling biological systems
both at protein level and at membrane level. We characterize formally bigraphs
corresponding to biologically meaningful systems, and bigraphic rewriting rules
representing biologically admissible interactions. At the protein level, these
bigraphic reactive systems correspond exactly to systems of kappa-calculus.
Membrane-level interactions are represented by just two general rules, whose
application can be triggered by protein-level interactions in a well-de\"ined
and precise way. This framework can be used to compare and merge models at
different abstraction levels; in particular, higher-level (e.g. mobility)
activities can be given a formal biological justification in terms of low-level
(i.e., protein) interactions. As examples, we formalize in our framework the
vesiculation and the phagocytosis processes.
</summary>
    <author>
      <name>Giorgio Bacci</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DiMI, University of Udine</arxiv:affiliation>
    </author>
    <author>
      <name>Davide Grohmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DiMI, University of Udine</arxiv:affiliation>
    </author>
    <author>
      <name>Marino Miculan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DiMI, University of Udine</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.11.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.11.1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 11, 2009, pp. 3-18</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.2; F.4.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4854v1</id>
    <updated>2009-11-25T14:17:40Z</updated>
    <published>2009-11-25T14:17:40Z</published>
    <title>A Process Calculus for Molecular Interaction Maps</title>
    <summary>  We present the MIM calculus, a modeling formalism with a strong biological
basis, which provides biologically-meaningful operators for representing the
interaction capabilities of molecular species. The operators of the calculus
are inspired by the reaction symbols used in Molecular Interaction Maps (MIMs),
a diagrammatic notation used by biologists. Models of the calculus can be
easily derived from MIM diagrams, for which an unambiguous and executable
interpretation is thus obtained. We give a formal definition of the syntax and
semantics of the MIM calculus, and we study properties of the formalism. A case
study is also presented to show the use of the calculus for modeling
biomolecular networks.
</summary>
    <author>
      <name>Roberto Barbuti</name>
    </author>
    <author>
      <name>Andrea Maggiolo-Schettini</name>
    </author>
    <author>
      <name>Paolo Milazzo</name>
    </author>
    <author>
      <name>Giovanni Pardini</name>
    </author>
    <author>
      <name>Aureliano Rama</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.11.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.11.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages; 8 figures; To be published on EPTCS, proceedings of MeCBIC
  2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 11, 2009, pp. 33-49</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4986v1</id>
    <updated>2009-11-26T00:26:39Z</updated>
    <published>2009-11-26T00:26:39Z</published>
    <title>New Solutions to the Firing Squad Synchronization Problems for Neural
  and Hyperdag P Systems</title>
    <summary>  We propose two uniform solutions to an open question: the Firing Squad
Synchronization Problem (FSSP), for hyperdag and symmetric neural P systems,
with anonymous cells. Our solutions take e_c+5 and 6e_c+7 steps, respectively,
where e_c is the eccentricity of the commander cell of the dag or digraph
underlying these P systems. The first and fast solution is based on a novel
proposal, which dynamically extends P systems with mobile channels. The second
solution is substantially longer, but is solely based on classical rules and
static channels. In contrast to the previous solutions, which work for
tree-based P systems, our solutions synchronize to any subset of the underlying
digraph; and do not require membrane polarizations or conditional rules, but
require states, as typically used in hyperdag and neural P systems.
</summary>
    <author>
      <name>Michael J. Dinneen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Auckland</arxiv:affiliation>
    </author>
    <author>
      <name>Yun-Bum Kim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Auckland</arxiv:affiliation>
    </author>
    <author>
      <name>Radu Nicolescu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Auckland</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.11.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.11.7" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 11, 2009, pp. 107-122</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.2; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4989v1</id>
    <updated>2009-11-26T00:39:34Z</updated>
    <published>2009-11-26T00:39:34Z</published>
    <title>Dependencies and Simultaneity in Membrane Systems</title>
    <summary>  Membrane system computations proceed in a synchronous fashion: at each step
all the applicable rules are actually applied. Hence each step depends on the
previous one. This coarse view can be refined by looking at the dependencies
among rule occurrences, by recording, for an object, which was the a rule that
produced it and subsequently (in a later step), which was the a rule that
consumed it. In this paper we propose a way to look also at the other main
ingredient in membrane system computations, namely the simultaneity in the rule
applications. This is achieved using zero-safe nets that allows to synchronize
transitions, i.e., rule occurrences. Zero-safe nets can be unfolded into
occurrence nets in a classical way, and to this unfolding an event structure
can be associated. The capability of capturing simultaneity of zero-safe nets
is transferred on the level of event structure by adding a way to express which
events occur simultaneously.
</summary>
    <author>
      <name>G. Michele Pinna</name>
    </author>
    <author>
      <name>Andrea Saba</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.11.10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.11.10" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 11, 2009, pp. 155-169</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.2; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.0893v1</id>
    <updated>2009-12-04T16:47:24Z</updated>
    <published>2009-12-04T16:47:24Z</published>
    <title>Performance Analysis on Molecular Dynamics Simulation of Protein Using
  GROMACS</title>
    <summary>  Development of computer technology in chemistry, bring many application of
chemistry. Not only the application to visualize the structure of molecule but
also to molecular dynamics simulation. One of them is Gromacs. Gromacs is an
example of molecular dynamics application developed by Groningen University.
This application is a non-commercial and able to work in the operating system
Linux. The main ability of Gromacs is to perform molecular dynamics simulation
and minimization energy. In this paper, the author discusses about how to work
Gromacs in molecular dynamics simulation of some protein. In the molecular
dynamics simulation, Gromacs does not work alone. Gromacs interact with pymol
and Grace. Pymol is an application to visualize molecule structure and Grace is
an application in Linux to display graphs. Both applications will support
analysis of molecular dynamics simulation.
</summary>
    <author>
      <name>A. D. Astuti</name>
    </author>
    <author>
      <name>A. B. Mutiara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.0893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.0893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1210v1</id>
    <updated>2010-01-08T07:55:44Z</updated>
    <published>2010-01-08T07:55:44Z</published>
    <title>Pure Parsimony Xor Haplotyping</title>
    <summary>  The haplotype resolution from xor-genotype data has been recently formulated
as a new model for genetic studies. The xor-genotype data is a cheaply
obtainable type of data distinguishing heterozygous from homozygous sites
without identifying the homozygous alleles. In this paper we propose a
formulation based on a well-known model used in haplotype inference: pure
parsimony. We exhibit exact solutions of the problem by providing polynomial
time algorithms for some restricted cases and a fixed-parameter algorithm for
the general case. These results are based on some interesting combinatorial
properties of a graph representation of the solutions. Furthermore, we show
that the problem has a polynomial time k-approximation, where k is the maximum
number of xor-genotypes containing a given SNP. Finally, we propose a heuristic
and produce an experimental analysis showing that it scales to real-world large
instances taken from the HapMap project.
</summary>
    <author>
      <name>Paola Bonizzoni</name>
    </author>
    <author>
      <name>Gianluca Della Vedova</name>
    </author>
    <author>
      <name>Riccardo Dondi</name>
    </author>
    <author>
      <name>Yuri Pirola</name>
    </author>
    <author>
      <name>Romeo Rizzi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCBB.2010.52</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCBB.2010.52" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE/ACM Trans. on Computational Biology and Bioinformatics 7.4
  (2010) 598-610</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1210v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1210v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3213v2</id>
    <updated>2012-05-21T19:13:53Z</updated>
    <published>2010-01-19T07:54:16Z</published>
    <title>Using Premia and Nsp for Constructing a Risk Management Benchmark for
  Testing Parallel Architecture</title>
    <summary>  Financial institutions have massive computations to carry out overnight which
are very demanding in terms of the consumed CPU. The challenge is to price many
different products on a cluster-like architecture. We have used the Premia
software to valuate the financial derivatives. In this work, we explain how
Premia can be embedded into Nsp, a scientific software like Matlab, to provide
a powerful tool to valuate a whole portfolio. Finally, we have integrated an
MPI toolbox into Nsp to enable to use Premia to solve a bunch of pricing
problems on a cluster. This unified framework can then be used to test
different parallel architectures.
</summary>
    <author>
      <name>Jean-Philippe Chancelier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <author>
      <name>Jérôme Lelong</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Lapeyre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1001.3213v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3213v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4061v1</id>
    <updated>2010-02-22T06:27:29Z</updated>
    <published>2010-02-22T06:27:29Z</published>
    <title>Flux Analysis in Process Models via Causality</title>
    <summary>  We present an approach for flux analysis in process algebra models of
biological systems. We perceive flux as the flow of resources in stochastic
simulations. We resort to an established correspondence between event
structures, a broadly recognised model of concurrency, and state transitions of
process models, seen as Petri nets. We show that we can this way extract the
causal resource dependencies in simulations between individual state
transitions as partial orders of events. We propose transformations on the
partial orders that provide means for further analysis, and introduce a
software tool, which implements these ideas. By means of an example of a
published model of the Rho GTP-binding proteins, we argue that this approach
can provide the substitute for flux analysis techniques on ordinary
differential equation models within the stochastic setting of process algebras.
</summary>
    <author>
      <name>Ozan Kahramanoğullari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Microsoft Research - University of Trento, Centre for Computational and Systems Biology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 20-39</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4062v1</id>
    <updated>2010-02-22T06:33:00Z</updated>
    <published>2010-02-22T06:33:00Z</published>
    <title>Modelling and Analysis of Biochemical Signalling Pathway Cross-talk</title>
    <summary>  Signalling pathways are abstractions that help life scientists structure the
coordination of cellular activity. Cross-talk between pathways accounts for
many of the complex behaviours exhibited by signalling pathways and is often
critical in producing the correct signal-response relationship. Formal models
of signalling pathways and cross-talk in particular can aid understanding and
drive experimentation. We define an approach to modelling based on the concept
that a pathway is the (synchronising) parallel composition of instances of
generic modules (with internal and external labels). Pathways are then composed
by (synchronising) parallel composition and renaming; different types of
cross-talk result from different combinations of synchronisation and renaming.
We define a number of generic modules in PRISM and five types of cross-talk:
signal flow, substrate availability, receptor function, gene expression and
intracellular communication. We show that Continuous Stochastic Logic
properties can both detect and distinguish the types of cross-talk. The
approach is illustrated with small examples and an analysis of the cross-talk
between the TGF-b/BMP, WNT and MAPK pathways.
</summary>
    <author>
      <name>Robin Donaldson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Glasgow</arxiv:affiliation>
    </author>
    <author>
      <name>Muffy Calder</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Glasgow</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 40-54</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4063v1</id>
    <updated>2010-02-22T06:36:41Z</updated>
    <published>2010-02-22T06:36:41Z</published>
    <title>Investigating modularity in the analysis of process algebra models of
  biochemical systems</title>
    <summary>  Compositionality is a key feature of process algebras which is often cited as
one of their advantages as a modelling technique. It is certainly true that in
biochemical systems, as in many other systems, model construction is made
easier in a formalism which allows the problem to be tackled compositionally.
In this paper we consider the extent to which the compositional structure which
is inherent in process algebra models of biochemical systems can be exploited
during model solution. In essence this means using the compositional structure
to guide decomposed solution and analysis.
  Unfortunately the dynamic behaviour of biochemical systems exhibits strong
interdependencies between the components of the model making decomposed
solution a difficult task. Nevertheless we believe that if such decomposition
based on process algebras could be established it would demonstrate substantial
benefits for systems biology modelling. In this paper we present our
preliminary investigations based on a case study of the pheromone pathway in
yeast, modelling in the stochastic process algebra Bio-PEPA.
</summary>
    <author>
      <name>Federica Ciocchetta</name>
    </author>
    <author>
      <name>Maria Luisa Guerriero</name>
    </author>
    <author>
      <name>Jane Hillston</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.4" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 55-69</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6; F.4; G.4; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4065v1</id>
    <updated>2010-02-22T06:40:24Z</updated>
    <published>2010-02-22T06:40:24Z</published>
    <title>BlenX-based compositional modeling of complex reaction mechanisms</title>
    <summary>  Molecular interactions are wired in a fascinating way resulting in complex
behavior of biological systems. Theoretical modeling provides a useful
framework for understanding the dynamics and the function of such networks. The
complexity of the biological networks calls for conceptual tools that manage
the combinatorial explosion of the set of possible interactions. A suitable
conceptual tool to attack complexity is compositionality, already successfully
used in the process algebra field to model computer systems. We rely on the
BlenX programming language, originated by the beta-binders process calculus, to
specify and simulate high-level descriptions of biological circuits. The
Gillespie's stochastic framework of BlenX requires the decomposition of
phenomenological functions into basic elementary reactions. Systematic
unpacking of complex reaction mechanisms into BlenX templates is shown in this
study. The estimation/derivation of missing parameters and the challenges
emerging from compositional model building in stochastic process algebras are
discussed. A biological example on circadian clock is presented as a case study
of BlenX compositionality.
</summary>
    <author>
      <name>Judit Zámborszky</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CoSBi</arxiv:affiliation>
    </author>
    <author>
      <name>Corrado Priami</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CoSBi</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 85-102</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4066v1</id>
    <updated>2010-02-22T06:42:38Z</updated>
    <published>2010-02-22T06:42:38Z</published>
    <title>Types for BioAmbients</title>
    <summary>  The BioAmbients calculus is a process algebra suitable for representing
compartmentalization, molecular localization and movements between
compartments. In this paper we enrich this calculus with a static type system
classifying each ambient with group types specifying the kind of compartments
in which the ambient can stay. The type system ensures that, in a well-typed
process, ambients cannot be nested in a way that violates the type hierarchy.
Exploiting the information given by the group types, we also extend the
operational semantics of BioAmbients with rules signalling errors that may
derive from undesired ambients' moves (i.e. merging incompatible tissues).
Thus, the signal of errors can help the modeller to detect and locate unwanted
situations that may arise in a biological system, and give practical hints on
how to avoid the undesired behaviour.
</summary>
    <author>
      <name>Sara Capecchi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Angelo Troina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.7" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 103-115</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.3; J.3; F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4067v1</id>
    <updated>2010-02-22T06:44:34Z</updated>
    <published>2010-02-22T06:44:34Z</published>
    <title>A Taxonomy of Causality-Based Biological Properties</title>
    <summary>  We formally characterize a set of causality-based properties of metabolic
networks. This set of properties aims at making precise several notions on the
production of metabolites, which are familiar in the biologists' terminology.
  From a theoretical point of view, biochemical reactions are abstractly
represented as causal implications and the produced metabolites as causal
consequences of the implication representing the corresponding reaction. The
fact that a reactant is produced is represented by means of the chain of
reactions that have made it exist. Such representation abstracts away from
quantities, stoichiometric and thermodynamic parameters and constitutes the
basis for the characterization of our properties. Moreover, we propose an
effective method for verifying our properties based on an abstract model of
system dynamics. This consists of a new abstract semantics for the system seen
as a concurrent network and expressed using the Chemical Ground Form calculus.
  We illustrate an application of this framework to a portion of a real
metabolic pathway.
</summary>
    <author>
      <name>Chiara Bodei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Andrea Bracciali</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Davide Chiarugi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Scienze Matematiche e Informatiche, Università di Siena</arxiv:affiliation>
    </author>
    <author>
      <name>Roberta Gori</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica - Università di Pisa</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.19.8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.19.8" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 19, 2010, pp. 116-133</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4079v1</id>
    <updated>2010-03-22T06:31:36Z</updated>
    <published>2010-03-22T06:31:36Z</published>
    <title>Gene Expression Data Knowledge Discovery using Global and Local
  Clustering</title>
    <summary>  To understand complex biological systems, the research community has produced
huge corpus of gene expression data. A large number of clustering approaches
have been proposed for the analysis of gene expression data. However,
extracting important biological knowledge is still harder. To address this
task, clustering techniques are used. In this paper, hybrid Hierarchical
k-Means algorithm is used for clustering and biclustering gene expression data
is used. To discover both local and global clustering structure biclustering
and clustering algorithms are utilized. A validation technique, Figure of Merit
is used to determine the quality of clustering results. Appropriate knowledge
is mined from the clusters by embedding a BLAST similarity search program into
the clustering and biclustering process. To discover both local and global
clustering structure biclustering and clustering algorithms are utilized. To
determine the quality of clustering results, a validation technique, Figure of
Merit is used. Appropriate knowledge is mined from the clusters by embedding a
BLAST similarity search program into the clustering and biclustering process.
</summary>
    <author>
      <name>Swathi. H</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3571v1</id>
    <updated>2010-04-20T20:42:34Z</updated>
    <published>2010-04-20T20:42:34Z</published>
    <title>Computer Aided Design Modeling for Heterogeneous Objects</title>
    <summary>  Heterogeneous object design is an active research area in recent years. The
conventional CAD modeling approaches only provide geometry and topology of the
object, but do not contain any information with regard to the materials of the
object and so can not be used for the fabrication of heterogeneous objects (HO)
through rapid prototyping. Current research focuses on computer-aided design
issues in heterogeneous object design. A new CAD modeling approach is proposed
to integrate the material information into geometric regions thus model the
material distributions in the heterogeneous object. The gradient references are
used to represent the complex geometry heterogeneous objects which have
simultaneous geometry intricacies and accurate material distributions. The
gradient references helps in flexible manipulability and control to
heterogeneous objects, which guarantees the local control over gradient regions
of developed heterogeneous objects. A systematic approach on data flow,
processing, computer visualization, and slicing of heterogeneous objects for
rapid prototyping is also presented.
</summary>
    <author>
      <name>Vikas Gupta</name>
    </author>
    <author>
      <name>K. S. Kasana</name>
    </author>
    <author>
      <name>Puneet Tandon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Computer-Aided-Design-Modeling-for-Heterogeneous-Objects.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI, Volume 7, Issue 2, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1395v3</id>
    <updated>2010-09-16T08:54:42Z</updated>
    <published>2010-05-09T13:25:58Z</published>
    <title>Fractal Weyl law for Linux Kernel Architecture</title>
    <summary>  We study the properties of spectrum and eigenstates of the Google matrix of a
directed network formed by the procedure calls in the Linux Kernel. Our results
obtained for various versions of the Linux Kernel show that the spectrum is
characterized by the fractal Weyl law established recently for systems of
quantum chaotic scattering and the Perron-Frobenius operators of dynamical
maps. The fractal Weyl exponent is found to be $\nu \approx 0.63$ that
corresponds to the fractal dimension of the network $d \approx 1.2$. The
eigenmodes of the Google matrix of Linux Kernel are localized on certain
principal nodes. We argue that the fractal Weyl law should be generic for
directed networks with the fractal dimension $d&lt;2$.
</summary>
    <author>
      <name>L. Ermann</name>
    </author>
    <author>
      <name>A. D. Chepelianskii</name>
    </author>
    <author>
      <name>D. L. Shepelyansky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2010-10774-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2010-10774-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">RevTex 6 pages, 7 figs, linked to arXiv:1003.5455[cs.SE]. Research at
  http://www.quantware.ups-tlse.fr/, Improved version, changed format</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B 79, 115-120 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.1395v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1395v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1853v1</id>
    <updated>2010-05-10T14:33:49Z</updated>
    <published>2010-05-10T14:33:49Z</published>
    <title>Lattice model refinement of protein structures</title>
    <summary>  To find the best lattice model representation of a given full atom protein
structure is a hard computational problem. Several greedy methods have been
suggested where results are usually biased and leave room for improvement. In
this paper we formulate and implement a Constraint Programming method to refine
such lattice structure models. We show that the approach is able to provide
better quality solutions. The prototype is implemented in COLA and is based on
limited discrepancy search. Finally, some promising extensions based on local
search are discussed.
</summary>
    <author>
      <name>Martin Mann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Bioinformatics, University Freiburg, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Alessandro Dal Palù</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dip. di Matematica, Università di Parma, Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of Workshop on Constraint Based Methods for
  Bioinformatics (WCB 2010); Jul 21, 2010; Edinburgh, UK (co-located with ICLP
  2010); 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1853v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1853v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2819v1</id>
    <updated>2010-05-17T06:58:07Z</updated>
    <published>2010-05-17T06:58:07Z</published>
    <title>SABRE: A Tool for Stochastic Analysis of Biochemical Reaction Networks</title>
    <summary>  The importance of stochasticity within biological systems has been shown
repeatedly during the last years and has raised the need for efficient
stochastic tools. We present SABRE, a tool for stochastic analysis of
biochemical reaction networks. SABRE implements fast adaptive uniformization
(FAU), a direct numerical approximation algorithm for computing transient
solutions of biochemical reaction networks. Biochemical reactions networks
represent biological systems studied at a molecular level and these reactions
can be modeled as transitions of a Markov chain. SABRE accepts as input the
formalism of guarded commands, which it interprets either as continuous-time or
as discrete-time Markov chains. Besides operating in a stochastic mode, SABRE
may also perform a deterministic analysis by directly computing a mean-field
approximation of the system under study. We illustrate the different
functionalities of SABRE by means of biological case studies.
</summary>
    <author>
      <name>Frederic Didier</name>
    </author>
    <author>
      <name>Thomas A. Henzinger</name>
    </author>
    <author>
      <name>Maria Mateescu</name>
    </author>
    <author>
      <name>Verena Wolf</name>
    </author>
    <link href="http://arxiv.org/abs/1005.2819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0168v1</id>
    <updated>2010-06-01T15:49:29Z</updated>
    <published>2010-06-01T15:49:29Z</published>
    <title>Perfusion Linearity and Its Applications</title>
    <summary>  Perfusion analysis computes blood flow parameters (blood volume, blood flow,
mean transit time) from the observed flow of contrast agent, passing through
the patient's vascular system. Perfusion deconvolution has been widely accepted
as the principal numerical tool for perfusion analysis, and is used routinely
in clinical applications. This extensive use of perfusion in clinical
decision-making makes numerical stability and robustness of perfusion
computations vital for accurate diagnostics and patient safety. The main goal
of this paper is to propose a novel approach for validating numerical
properties of perfusion algorithms. The approach is based on Perfusion
Linearity Property (PLP), which we find in perfusion deconvolution, as well as
in many other perfusion techniques. PLP allows one to study perfusion values as
weighted averages of the original imaging data. This, in turn, uncovers hidden
problems with the existing deconvolution techniques, and may be used to suggest
more reliable computational approaches and methodology.
</summary>
    <author>
      <name>Oleg Pianykh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2806v1</id>
    <updated>2010-06-14T19:07:42Z</updated>
    <published>2010-06-14T19:07:42Z</published>
    <title>A Metaheuristic Approach for IT Projects Portfolio Optimization</title>
    <summary>  Optimal selection of interdependent IT Projects for implementation in multi
periods has been challenging in the framework of real option valuation. This
paper presents a mathematical optimization model for multi-stage portfolio of
IT projects. The model optimizes the value of the portfolio within a given
budgetary and sequencing constraints for each period. These sequencing
constraints are due to time wise interdependencies among projects. A
Metaheuristic approach is well suited for solving this kind of a problem
definition and in this paper a genetic algorithm model has been proposed for
the solution. This optimization model and solution approach can help IT
managers taking optimal funding decision for projects prioritization in
multiple sequential periods. The model also gives flexibility to the managers
to generate alternative portfolio by changing the maximum and minimum number of
projects to be implemented in each sequential period.
</summary>
    <author>
      <name>Shashank Pushkar</name>
    </author>
    <author>
      <name>Abhijit Mustafi</name>
    </author>
    <author>
      <name>Akhileshwar Mishra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p42-47, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.2806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2813v1</id>
    <updated>2010-06-14T19:38:28Z</updated>
    <published>2010-06-14T19:38:28Z</published>
    <title>Algorithm for Predicting Protein Secondary Structure</title>
    <summary>  Predicting protein structure from amino acid sequence is one of the most
important unsolved problems of molecular biology and biophysics.Not only would
a successful prediction algorithm be a tremendous advance in the understanding
of the biochemical mechanisms of proteins, but, since such an algorithm could
conceivably be used to design proteins to carry out specific
functions.Prediction of the secondary structure of a protein (alpha-helix,
beta-sheet, coil) is an important step towards elucidating its three
dimensional structure as well as its function. In this research, we use
different Hidden Markov models for protein secondary structure prediction. In
this paper we have proposed an algorithm for predicting protein secondary
structure. We have used Hidden Markov model with sliding window for secondary
structure prediction.The secondary structure has three regular forms, for each
secondary structural element we are using one Hidden Markov Model.
</summary>
    <author>
      <name>K. K Senapati</name>
    </author>
    <author>
      <name>G. Sahoo</name>
    </author>
    <author>
      <name>D. Bhaumik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p68-71, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.2813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.4925v1</id>
    <updated>2010-06-25T07:57:26Z</updated>
    <published>2010-06-25T07:57:26Z</published>
    <title>Simulating information creation in social Semantic Web applications</title>
    <summary>  Appropriate ranking algorithms and incentive mechanisms are essential to the
creation of high-quality information by users of a social network. However,
evaluating such mechanisms in a quantifiable way is a difficult problem.
Studies of live social networks of limited utility, due to the subjective
nature of ranking and the lack of experimental control. Simulation provides a
valuable alternative: insofar as the simulation resembles the live social
network, fielding a new algorithm within a simulated network can predict the
effect it will have on the live network. In this paper, we propose a simulation
model based on the actor-conceptinstance model of semantic social networks,
then we evaluate the model against a number of common ranking algorithms.We
observe their effects on information creation in such a network, and we extend
our results to the evaluation of generic ranking algorithms and incentive
mechanisms.
</summary>
    <author>
      <name>Xixi Luo</name>
    </author>
    <author>
      <name>Xiaowu Chen</name>
    </author>
    <author>
      <name>Qingping Zhao</name>
    </author>
    <author>
      <name>Joshua Shinavier</name>
    </author>
    <link href="http://arxiv.org/abs/1006.4925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.4925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5099v1</id>
    <updated>2010-06-26T03:03:25Z</updated>
    <published>2010-06-26T03:03:25Z</published>
    <title>Stochastic Calculus of Wrapped Compartments</title>
    <summary>  The Calculus of Wrapped Compartments (CWC) is a variant of the Calculus of
Looping Sequences (CLS). While keeping the same expressiveness, CWC strongly
simplifies the development of automatic tools for the analysis of biological
systems. The main simplification consists in the removal of the sequencing
operator, thus lightening the formal treatment of the patterns to be matched in
a term (whose complexity in CLS is strongly affected by the variables matching
in the sequences).
  We define a stochastic semantics for this new calculus. As an application we
model the interaction between macrophages and apoptotic neutrophils and a
mechanism of gene regulation in E.Coli.
</summary>
    <author>
      <name>Mario Coppo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Ferruccio Damiani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Maurizio Drocco</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Elena Grassi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica and Molecular Biotechnology Center, Dipartimento di Genetica, Biologia e Biochimica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Angelo Troina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.28.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.28.6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 28, 2010, pp. 82-98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.5099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.3; J.3; F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1768v1</id>
    <updated>2010-07-11T10:48:37Z</updated>
    <published>2010-07-11T10:48:37Z</published>
    <title>StochKit-FF: Efficient Systems Biology on Multicore Architectures</title>
    <summary>  The stochastic modelling of biological systems is an informative, and in some
cases, very adequate technique, which may however result in being more
expensive than other modelling approaches, such as differential equations. We
present StochKit-FF, a parallel version of StochKit, a reference toolkit for
stochastic simulations. StochKit-FF is based on the FastFlow programming
toolkit for multicores and exploits the novel concept of selective memory. We
experiment StochKit-FF on a model of HIV infection dynamics, with the aim of
extracting information from efficiently run experiments, here in terms of
average and variance and, on a longer term, of more structured data.
</summary>
    <author>
      <name>Marco Aldinucci</name>
    </author>
    <author>
      <name>Andrea Bracciali</name>
    </author>
    <author>
      <name>Pietro Liò</name>
    </author>
    <author>
      <name>Anil Sorathiya</name>
    </author>
    <author>
      <name>Massimo Torquati</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages + cover page</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; D.3.2; C.1.3; G.3; I.6; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.1366v2</id>
    <updated>2011-02-11T00:52:21Z</updated>
    <published>2010-08-07T21:36:51Z</published>
    <title>Efficient Dealiased Convolutions without Padding</title>
    <summary>  Algorithms are developed for calculating dealiased linear convolution sums
without the expense of conventional zero-padding or phase-shift techniques. For
one-dimensional in-place convolutions, the memory requirements are identical
with the zero-padding technique, with the important distinction that the
additional work memory need not be contiguous with the input data. This
decoupling of data and work arrays dramatically reduces the memory and
computation time required to evaluate higher-dimensional in-place convolutions.
The technique also allows one to dealias the higher-order convolutions that
arise from Fourier transforming cubic and higher powers. Implicitly dealiased
convolutions can be built on top of state-of-the-art fast Fourier transform
libraries: vectorized multidimensional implementations for the complex and
centered Hermitian (pseudospectral) cases have been implemented in the
open-source software FFTW++.
</summary>
    <author>
      <name>John C. Bowman</name>
    </author>
    <author>
      <name>Malcolm Roberts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.1366v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.1366v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65R99, 65T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3147v1</id>
    <updated>2010-08-18T18:32:44Z</updated>
    <published>2010-08-18T18:32:44Z</published>
    <title>Proceedings First Workshop on Applications of Membrane computing,
  Concurrency and Agent-based modelling in POPulation biology</title>
    <summary>  This volume contains the papers presented at the first International Workshop
on Applications of Membrane Computing, Concurrency and Agent-based Modelling in
Population Biology (AMCA-POP 2010) held in Jena, Germany on August 25th, 2010
as a satellite event of the 11th Conference on Membrane Computing (CMC11).
  The aim of the workshop is to investigate whether formal modelling and
analysis techniques could be applied with profit to systems of interest for
population biology and ecology. The considered modelling notations include
membrane systems, Petri nets, agent-based notations, process calculi,
automata-based notations, rewriting systems and cellular automata. Such
notations enable the application of analysis techniques such as simulation,
model checking, abstract interpretation and type systems to study systems of
interest in disciplines such as population biology, ecosystem science,
epidemiology, genetics, sustainability science, evolution and other disciplines
in which population dynamics and interactions with the environment are studied.
Papers contain results and experiences in the modelling and analysis of systems
of interest in these fields.
</summary>
    <author>
      <name>Paolo Milazzo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Mario de J. Pérez Jiménez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universidad de Sevilla</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.33</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.33" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 33, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.3147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3301v1</id>
    <updated>2010-08-19T14:00:49Z</updated>
    <published>2010-08-19T14:00:49Z</published>
    <title>Modelling the Dynamics of an Aedes albopictus Population</title>
    <summary>  We present a methodology for modelling population dynamics with formal means
of computer science. This allows unambiguous description of systems and
application of analysis tools such as simulators and model checkers. In
particular, the dynamics of a population of Aedes albopictus (a species of
mosquito) and its modelling with the Stochastic Calculus of Looping Sequences
(Stochastic CLS) are considered. The use of Stochastic CLS to model population
dynamics requires an extension which allows environmental events (such as
changes in the temperature and rainfalls) to be taken into account. A simulator
for the constructed model is developed via translation into the specification
language Maude, and used to compare the dynamics obtained from the model with
real data.
</summary>
    <author>
      <name>Thomas Anung Basuki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UNU-IIST</arxiv:affiliation>
    </author>
    <author>
      <name>Antonio Cerone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UNU-IIST</arxiv:affiliation>
    </author>
    <author>
      <name>Roberto Barbuti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Andrea Maggiolo-Schettini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Milazzo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Pisa</arxiv:affiliation>
    </author>
    <author>
      <name>Elisabetta Rossi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Pisa</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.33.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.33.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings AMCA-POP 2010, arXiv:1008.3147</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 33, 2010, pp. 18-36</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.3301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3304v1</id>
    <updated>2010-08-19T14:00:57Z</updated>
    <published>2010-08-19T14:00:57Z</published>
    <title>An Analysis on the Influence of Network Topologies on Local and Global
  Dynamics of Metapopulation Systems</title>
    <summary>  Metapopulations are models of ecological systems, describing the interactions
and the behavior of populations that live in fragmented habitats. In this
paper, we present a model of metapopulations based on the multivolume
simulation algorithm tau-DPP, a stochastic class of membrane systems, that we
utilize to investigate the influence that different habitat topologies can have
on the local and global dynamics of metapopulations. In particular, we focus
our analysis on the migration rate of individuals among adjacent patches, and
on their capability of colonizing the empty patches in the habitat. We compare
the simulation results obtained for each habitat topology, and conclude the
paper with some proposals for other research issues concerning metapopulations.
</summary>
    <author>
      <name>Daniela Besozzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Cazzaniga</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Dario Pescini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Giancarlo Mauri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.33.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.33.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings AMCA-POP 2010, arXiv:1008.3147</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 33, 2010, pp. 1-17</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.3304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3551v1</id>
    <updated>2010-08-20T18:37:23Z</updated>
    <published>2010-08-20T18:37:23Z</published>
    <title>Inventory Allocation for Online Graphical Display Advertising</title>
    <summary>  We discuss a multi-objective/goal programming model for the allocation of
inventory of graphical advertisements. The model considers two types of
campaigns: guaranteed delivery (GD), which are sold months in advance, and
non-guaranteed delivery (NGD), which are sold using real-time auctions. We
investigate various advertiser and publisher objectives such as (a) revenue
from the sale of impressions, clicks and conversions, (b) future revenue from
the sale of NGD inventory, and (c) "fairness" of allocation. While the first
two objectives are monetary, the third is not. This combination of demand types
and objectives leads to potentially many variations of our model, which we
delineate and evaluate. Our experimental results, which are based on
optimization runs using real data sets, demonstrate the effectiveness and
flexibility of the proposed model.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <author>
      <name>Erik Vee</name>
    </author>
    <author>
      <name>Sergei Vassilvitskii</name>
    </author>
    <author>
      <name>John Tomlin</name>
    </author>
    <author>
      <name>Jayavel Shanmugasundaram</name>
    </author>
    <author>
      <name>Tasos Anastasakos</name>
    </author>
    <author>
      <name>Oliver Kennedy</name>
    </author>
    <link href="http://arxiv.org/abs/1008.3551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.1456v1</id>
    <updated>2010-10-07T15:35:24Z</updated>
    <published>2010-10-07T15:35:24Z</published>
    <title>A Hybrid Parallelization of AIM for Multi-Core Clusters: Implementation
  Details and Benchmark Results on Ranger</title>
    <summary>  This paper presents implementation details and empirical results for a hybrid
message passing and shared memory paralleliziation of the adaptive integral
method (AIM). AIM is implemented on a (near) petaflop supercomputing cluster of
quad-core processors and its accuracy, complexity, and scalability are
investigated by solving benchmark scattering problems. The timing and speedup
results on up to 1024 processors show that the hybrid MPI/OpenMP
parallelization of AIM exhibits better strong scalability (fixed problem size
speedup) than pure MPI parallelization of it when multiple cores are used on
each processor.
</summary>
    <author>
      <name>Fangzhou Wei</name>
    </author>
    <author>
      <name>Ali E. Yılmaz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 3 tables, 9 figures. Due to space constraints, some
  implementation details and empirical data are omitted in authors' another
  paper (reference [1]), which has been submitted to Parallel Computing. This
  paper here serves as a major reference with the implementation details and
  comprehensive empirical data</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.1456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.1456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.5562v1</id>
    <updated>2010-10-27T03:45:45Z</updated>
    <published>2010-10-27T03:45:45Z</published>
    <title>Fast Continuous Haar and Fourier Transforms of Rectilinear Polygons from
  VLSI Layouts</title>
    <summary>  We develop the pruned continuous Haar transform and the fast continuous
Fourier series, two fast and efficient algorithms for rectilinear polygons.
Rectilinear polygons are used in VLSI processes to describe design and mask
layouts of integrated circuits. The Fourier representation is at the heart of
many of these processes and the Haar transform is expected to play a major role
in techniques envisioned to speed up VLSI design. To ensure correct printing of
the constantly shrinking transistors and simultaneously handle their
increasingly large number, ever more computationally intensive techniques are
needed. Therefore, efficient algorithms for the Haar and Fourier transforms are
vital. We derive the complexity of both algorithms and compare it to that of
discrete transforms traditionally used in VLSI. We find a significant reduction
in complexity when the number of vertices of the polygons is small, as is the
case in VLSI layouts. This analysis is completed by an implementation and a
benchmark of the continuous algorithms and their discrete counterpart. We show
that on tested VLSI layouts the pruned continuous Haar transform is 5 to 25
times faster, while the fast continuous Fourier series is 1.5 to 3 times
faster.
</summary>
    <author>
      <name>Robin Scheibler</name>
    </author>
    <author>
      <name>Paul Hurley</name>
    </author>
    <author>
      <name>Amina Chebira</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.5562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.5562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0279v1</id>
    <updated>2010-11-01T09:55:23Z</updated>
    <published>2010-11-01T09:55:23Z</published>
    <title>Mobile Based Secure Digital Wallet for Peer to Peer Payment System</title>
    <summary>  E-commerce in today's conditions has the highest dependence on network
infrastructure of banking. However, when the possibility of communicating with
the Banking network is not provided, business activities will suffer. This
paper proposes a new approach of digital wallet based on mobile devices without
the need to exchange physical money or communicate with banking network. A
digital wallet is a software component that allows a user to make an electronic
payment in cash (such as a credit card or a digital coin), and hides the
low-level details of executing the payment protocol that is used to make the
payment. The main features of proposed architecture are secure awareness, fault
tolerance, and infrastructure-less protocol.
</summary>
    <author>
      <name>Majid Taghiloo</name>
    </author>
    <author>
      <name>Mohammad Ali Agheli</name>
    </author>
    <author>
      <name>Mohammad Reza Rezaeinezhad</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of UbiComp (IJU), Vol.1, No.4, October 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0489v1</id>
    <updated>2010-11-02T01:29:15Z</updated>
    <published>2010-11-02T01:29:15Z</published>
    <title>An Abstraction Theory for Qualitative Models of Biological Systems</title>
    <summary>  Multi-valued network models are an important qualitative modelling approach
used widely by the biological community. In this paper we consider developing
an abstraction theory for multi-valued network models that allows the state
space of a model to be reduced while preserving key properties of the model.
This is important as it aids the analysis and comparison of multi-valued
networks and in particular, helps address the well-known problem of state space
explosion associated with such analysis. We also consider developing techniques
for efficiently identifying abstractions and so provide a basis for the
automation of this task. We illustrate the theory and techniques developed by
investigating the identification of abstractions for two published MVN models
of the lysis-lysogeny switch in the bacteriophage lambda.
</summary>
    <author>
      <name>Richard Banks</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Newcastle University</arxiv:affiliation>
    </author>
    <author>
      <name>L. Jason Steggles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Newcastle University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 23-38</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3; F.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0490v1</id>
    <updated>2010-11-02T01:29:21Z</updated>
    <published>2010-11-02T01:29:21Z</published>
    <title>Computational Modeling for the Activation Cycle of G-proteins by
  G-protein-coupled Receptors</title>
    <summary>  In this paper, we survey five different computational modeling methods. For
comparison, we use the activation cycle of G-proteins that regulate cellular
signaling events downstream of G-protein-coupled receptors (GPCRs) as a driving
example. Starting from an existing Ordinary Differential Equations (ODEs)
model, we implement the G-protein cycle in the stochastic Pi-calculus using
SPiM, as Petri-nets using Cell Illustrator, in the Kappa Language using
Cellucidate, and in Bio-PEPA using the Bio-PEPA eclipse plug in. We also
provide a high-level notation to abstract away from communication primitives
that may be unfamiliar to the average biologist, and we show how to translate
high-level programs into stochastic Pi-calculus processes and chemical
reactions.
</summary>
    <author>
      <name>Yifei Bao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, Stevens Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Adriana Compagnoni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, Stevens Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Joseph Glavy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Chemical Biology and Biomedical Engineering, Stevens Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Tommy White</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Chemical Biology and Biomedical Engineering, Stevens Institute of Technology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 39-53</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0492v1</id>
    <updated>2010-11-02T01:29:39Z</updated>
    <published>2010-11-02T01:29:39Z</published>
    <title>Multiscale Bone Remodelling with Spatial P Systems</title>
    <summary>  Many biological phenomena are inherently multiscale, i.e. they are
characterized by interactions involving different spatial and temporal scales
simultaneously. Though several approaches have been proposed to provide
"multilayer" models, only Complex Automata, derived from Cellular Automata,
naturally embed spatial information and realize multiscaling with
well-established inter-scale integration schemas. Spatial P systems, a variant
of P systems in which a more geometric concept of space has been added, have
several characteristics in common with Cellular Automata. We propose such a
formalism as a basis to rephrase the Complex Automata multiscaling approach
and, in this perspective, provide a 2-scale Spatial P system describing bone
remodelling. The proposed model not only results to be highly faithful and
expressive in a multiscale scenario, but also highlights the need of a deep and
formal expressiveness study involving Complex Automata, Spatial P systems and
other promising multiscale approaches, such as our shape-based one already
resulted to be highly faithful.
</summary>
    <author>
      <name>Diletta Cacciagrano</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">School of Science and Technology - University of Camerino</arxiv:affiliation>
    </author>
    <author>
      <name>Flavio Corradini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">School of Science and Technology - University of Camerino</arxiv:affiliation>
    </author>
    <author>
      <name>Emanuela Merelli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">School of Science and Technology - University of Camerino</arxiv:affiliation>
    </author>
    <author>
      <name>Luca Tesei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">School of Science and Technology - University of Camerino</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 70-84</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0496v1</id>
    <updated>2010-11-02T01:30:06Z</updated>
    <published>2010-11-02T01:30:06Z</published>
    <title>Lumpability Abstractions of Rule-based Systems</title>
    <summary>  The induction of a signaling pathway is characterized by transient complex
formation and mutual posttranslational modification of proteins. To faithfully
capture this combinatorial process in a mathematical model is an important
challenge in systems biology. Exploiting the limited context on which most
binding and modification events are conditioned, attempts have been made to
reduce the combinatorial complexity by quotienting the reachable set of
molecular species, into species aggregates while preserving the deterministic
semantics of the thermodynamic limit. Recently we proposed a quotienting that
also preserves the stochastic semantics and that is complete in the sense that
the semantics of individual species can be recovered from the aggregate
semantics. In this paper we prove that this quotienting yields a sufficient
condition for weak lumpability and that it gives rise to a backward Markov
bisimulation between the original and aggregated transition system. We
illustrate the framework on a case study of the EGF/insulin receptor crosstalk.
</summary>
    <author>
      <name>Jerome Feret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, Paris, France</arxiv:affiliation>
    </author>
    <author>
      <name>Thomas Henzinger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute of Science and Technology, Vienna, Austria</arxiv:affiliation>
    </author>
    <author>
      <name>Heinz Koeppl</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EPFL, Lausanne, Switzerland</arxiv:affiliation>
    </author>
    <author>
      <name>Tatjana Petrov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EPFL, Lausanne, Switzerland</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 142-161</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0498v1</id>
    <updated>2010-11-02T01:37:03Z</updated>
    <published>2010-11-02T01:37:03Z</published>
    <title>Qualitative modelling and analysis of regulations in multi-cellular
  systems using Petri nets and topological collections</title>
    <summary>  In this paper, we aim at modelling and analyzing the regulation processes in
multi-cellular biological systems, in particular tissues.
  The modelling framework is based on interconnected logical regulatory
networks a la Rene Thomas equipped with information about their spatial
relationships. The semantics of such models is expressed through colored Petri
nets to implement regulation rules, combined with topological collections to
implement the spatial information.
  Some constraints are put on the the representation of spatial information in
order to preserve the possibility of an enumerative and exhaustive state space
exploration.
  This paper presents the modelling framework, its semantics, as well as a
prototype implementation that allowed preliminary experimentation on some
applications.
</summary>
    <author>
      <name>Jean-Louis Giavitto</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CNRS &amp; IBISC, University of Evry</arxiv:affiliation>
    </author>
    <author>
      <name>Hanna Klaudel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC, University of Evry</arxiv:affiliation>
    </author>
    <author>
      <name>Franck Pommereau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC, University of Evry</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.40.11</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.40.11" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2010, arXiv:1011.0051</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 40, 2010, pp. 162-177</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J3; I.6.5; I.6.4; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0953v1</id>
    <updated>2010-11-03T17:38:23Z</updated>
    <published>2010-11-03T17:38:23Z</published>
    <title>Overcoming Problems in the Measurement of Biological Complexity</title>
    <summary>  In a genetic algorithm, fluctuations of the entropy of a genome over time are
interpreted as fluctuations of the information that the genome's organism is
storing about its environment, being this reflected in more complex organisms.
The computation of this entropy presents technical problems due to the small
population sizes used in practice. In this work we propose and test an
alternative way of measuring the entropy variation in a population by means of
algorithmic information theory, where the entropy variation between two
generational steps is the Kolmogorov complexity of the first step conditioned
to the second one. As an example application of this technique, we report
experimental differences in entropy evolution between systems in which sexual
reproduction is present or absent.
</summary>
    <author>
      <name>Manuel Cebrian</name>
    </author>
    <author>
      <name>Manuel Alfonseca</name>
    </author>
    <author>
      <name>Alfonso Ortega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.0953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.1615v1</id>
    <updated>2010-12-07T21:34:26Z</updated>
    <published>2010-12-07T21:34:26Z</published>
    <title>Argudas: arguing with gene expression information</title>
    <summary>  In situ hybridisation gene expression information helps biologists identify
where a gene is expressed. However, the databases that republish the
experimental information are often both incomplete and inconsistent. This paper
examines a system, Argudas, designed to help tackle these issues. Argudas is an
evolution of an existing system, and so that system is reviewed as a means of
both explaining and justifying the behaviour of Argudas. Throughout the
discussion of Argudas a number of issues will be raised including the
appropriateness of argumentation in biology and the challenges faced when
integrating apparently similar online biological databases.
</summary>
    <author>
      <name>Kenneth McLeod</name>
    </author>
    <author>
      <name>Gus Ferguson</name>
    </author>
    <author>
      <name>Albert Burger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.1615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.1615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3956v1</id>
    <updated>2010-12-17T18:35:43Z</updated>
    <published>2010-12-17T18:35:43Z</published>
    <title>Advances in the Biomedical Applications of the EELA Project</title>
    <summary>  In the last years an increasing demand for Grid Infrastructures has resulted
in several international collaborations. This is the case of the EELA Project,
which has brought together collaborating groups of Latin America and Europe.
One year ago we presented this e-infrastructure used, among others, by the
Biomedical groups for the studies of oncological analysis, neglected diseases,
sequence alignments and computation phylogenetics. After this period, the
achieved advances are summarised in this paper.
</summary>
    <author>
      <name>Vicente Hernández</name>
    </author>
    <author>
      <name>Ignacio Blanquer</name>
    </author>
    <author>
      <name>Gabriel Aparicio</name>
    </author>
    <author>
      <name>Raul Isea</name>
    </author>
    <author>
      <name>Juan Luis Chavés</name>
    </author>
    <author>
      <name>Álvaro Hernández</name>
    </author>
    <author>
      <name>Henry Ricardo Mora</name>
    </author>
    <author>
      <name>Manuel Fernández</name>
    </author>
    <author>
      <name>Alicia Acero</name>
    </author>
    <author>
      <name>Esther Montes</name>
    </author>
    <author>
      <name>Rafael Mayo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the NETTAB Conference (2007). Vol. 7, pp. 145-156</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1012.3956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.4374v1</id>
    <updated>2010-12-20T15:56:28Z</updated>
    <published>2010-12-20T15:56:28Z</published>
    <title>Régularisation et optimisation pour l'imagerie sismique des fondations
  de pylônes</title>
    <summary>  This research report summarizes the progress of work carried out jointly by
the IRCCyN and the \'Ecole Polytechnique de Montr\'eal about the resolution of
the inverse problem for the seismic imaging of transmission overhead line
structure foundations. Several methods aimed at mapping the underground medium
are considered. More particularly, we focus on methods based on a bilinear
formulation of the forward problem on one hand (CSI, modified gradient, etc.)
and on methods based on a "primal" formulation on the other hand. The
performances of these methods are compared using synthetic data. This work was
partially funded by RTE (R\'eseau de Transport d'\'Electricit\'e), which has
initiated the project, and was carried out in collaboration with EDF R&amp;D
(\'Electricit\'e de France - Recherche et D\'eveloppement).
</summary>
    <author>
      <name>Denis Vautrin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institut de Recherche en Communications et Cybernétique de Nantes</arxiv:affiliation>
    </author>
    <author>
      <name>Matthieu Voorons</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">École Polytechnique de Montréal</arxiv:affiliation>
    </author>
    <author>
      <name>Jérôme Idier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institut de Recherche en Communications et Cybernétique de Nantes</arxiv:affiliation>
    </author>
    <author>
      <name>Yves Goussard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">École Polytechnique de Montréal</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">80 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.4374v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.4374v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.5074v1</id>
    <updated>2010-12-22T19:09:12Z</updated>
    <published>2010-12-22T19:09:12Z</published>
    <title>Power-Rate Allocation in DS/CDMA Based on Discretized Verhulst
  Equilibrium</title>
    <summary>  This paper proposes to extend the discrete Verhulst power equilibrium
approach, previously suggested in [1], to the power-rate optimal allocation
problem. Multirate users associated to different types of traffic are
aggregated to distinct user' classes, with the assurance of minimum rate
allocation per user and QoS. Herein, Verhulst power allocation algorithm was
adapted to the single-input-single-output DS/CDMA jointly power-rate control
problem. The analysis was carried out taking into account the convergence time,
quality of solution, in terms of the normalized squared error (NSE), when
compared with the analytical solution based on interference matrix inverse, and
computational complexity. Numerical results demonstrate the validity of the
proposed resource allocation methodology.
</summary>
    <author>
      <name>Lucas Dias H. Sampaio</name>
    </author>
    <author>
      <name>Moisés F. Lima</name>
    </author>
    <author>
      <name>Mario Lemes Proença Jr</name>
    </author>
    <author>
      <name>Taufik Abrão</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures, 2 tables, conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.5074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.5074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2017v2</id>
    <updated>2011-06-18T03:29:35Z</updated>
    <published>2011-02-10T00:50:54Z</published>
    <title>Synthesis of Mechanism for single- and hybrid-tasks using Differential
  Evolution</title>
    <summary>  The optimal dimensional synthesis for planar mechanisms using differential
evolution (DE) is demonstrated. Four examples are included: in the first case,
the synthesis of a mechanism for hybrid-tasks, considering path generation,
function generation, and motion generation, is carried out. The second and
third cases pertain to path generation, with and without prescribed timing.
Finally, the synthesis of an Ackerman mechanism is reported. Order defect
problem is solved by manipulating individuals instead of penalizing or
discretizing the search space for the parameters. A technique that consists in
applying a transformation in order to satisfy the Grashof and crank conditions
to generate an initial elitist population is introduced. As a result, the
evolutionary algorithm increases its efficiency.
</summary>
    <author>
      <name>F. Penunuri</name>
    </author>
    <author>
      <name>R. Peon-Escalante</name>
    </author>
    <author>
      <name>C. Villanueva</name>
    </author>
    <author>
      <name>D. Pech-Oy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final version accepted in Mechanism and Machine Theory</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mechanism and Machine Theory 46 (2011) 1335--1349</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.2017v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2017v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2654v1</id>
    <updated>2011-02-14T01:09:40Z</updated>
    <published>2011-02-14T01:09:40Z</published>
    <title>PORGY: Strategy-Driven Interactive Transformation of Graphs</title>
    <summary>  This paper investigates the use of graph rewriting systems as a modelling
tool, and advocates the embedding of such systems in an interactive
environment. One important application domain is the modelling of biochemical
systems, where states are represented by port graphs and the dynamics is driven
by rules and strategies. A graph rewriting tool's capability to interactively
explore the features of the rewriting system provides useful insights into
possible behaviours of the model and its properties. We describe PORGY, a
visual and interactive tool we have developed to model complex systems using
port graphs and port graph rewrite rules guided by strategies, and to navigate
in the derivation history. We demonstrate via examples some functionalities
provided by PORGY.
</summary>
    <author>
      <name>Oana Andrei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">School of Computing Science, University of Glasgow</arxiv:affiliation>
    </author>
    <author>
      <name>Maribel Fernández</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">King's College London</arxiv:affiliation>
    </author>
    <author>
      <name>Hélène Kirchner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux Sud-Ouest</arxiv:affiliation>
    </author>
    <author>
      <name>Guy Melançon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux Sud-Ouest</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Namet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">King's College London</arxiv:affiliation>
    </author>
    <author>
      <name>Bruno Pinaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux Sud-Ouest</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.48.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.48.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings TERMGRAPH 2011, arXiv:1102.2268</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 48, 2011, pp. 54-68</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.2654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2933v2</id>
    <updated>2011-03-31T17:12:17Z</updated>
    <published>2011-02-15T00:08:11Z</published>
    <title>A FEniCS-Based Programming Framework for Modeling Turbulent Flow by the
  Reynolds-Averaged Navier-Stokes Equations</title>
    <summary>  Finding an appropriate turbulence model for a given flow case usually calls
for extensive experimentation with both models and numerical solution methods.
This work presents the design and implementation of a flexible, programmable
software framework for assisting with numerical experiments in computational
turbulence. The framework targets Reynolds-averaged Navier-Stokes models,
discretized by finite element methods. The novel implementation makes use of
Python and the FEniCS package, the combination of which leads to compact and
reusable code, where model- and solver-specific code resemble closely the
mathematical formulation of equations and algorithms. The presented ideas and
programming techniques are also applicable to other fields that involve systems
of nonlinear partial differential equations. We demonstrate the framework in
two applications and investigate the impact of various linearizations on the
convergence properties of nonlinear solvers for a Reynolds-averaged
Navier-Stokes model.
</summary>
    <author>
      <name>Mikael Mortensen</name>
    </author>
    <author>
      <name>Hans Petter Langtangen</name>
    </author>
    <author>
      <name>Garth N. Wells</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advwatres.2011.02.013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advwatres.2011.02.013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Advances in Water Resources</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.2933v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2933v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4528v3</id>
    <updated>2011-03-17T20:19:37Z</updated>
    <published>2011-02-22T15:01:06Z</published>
    <title>Modelling the Dynamics of the Work-Employment System by Predator-Prey
  Interactions</title>
    <summary>  The broad application range of the predator-prey modelling enabled us to
apply it to represent the dynamics of the work-employment system. For the
adopted period, we conclude that this dynamics is chaotic in the beginning of
the time series and tends to less perturbed states, as time goes by, due to
public policies and hidden intrinsic system features. Basic Lotka-Volterra
approach was revised and adapted to the reality of the study. The final aim is
to provide managers with generalized theoretical elements that allow to a more
accurate understanding of the behavior of the work-employment system.
</summary>
    <author>
      <name>Nilo Serpa</name>
    </author>
    <author>
      <name>Jose Roberto Steiner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 11 figures and original formalism</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.4528v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4528v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.1778v1</id>
    <updated>2011-03-09T13:33:23Z</updated>
    <published>2011-03-09T13:33:23Z</published>
    <title>Pituitary Adenoma Segmentation</title>
    <summary>  Sellar tumors are approximately 10-15% among all intracranial neoplasms. The
most common sellar lesion is the pituitary adenoma. Manual segmentation is a
time-consuming process that can be shortened by using adequate algorithms. In
this contribution, we present a segmentation method for pituitary adenoma. The
method is based on an algorithm we developed recently in previous work where
the novel segmentation scheme was successfully used for segmentation of
glioblastoma multiforme and provided an average Dice Similarity Coefficient
(DSC) of 77%. This scheme is used for automatic adenoma segmentation. In our
experimental evaluation, neurosurgeons with strong experiences in the treatment
of pituitary adenoma performed manual slice-by-slice segmentation of 10
magnetic resonance imaging (MRI) cases. Afterwards, the segmentations were
compared with the segmentation results of the proposed method via the DSC. The
average DSC for all data sets was 77.49% +/- 4.52%. Compared with a manual
segmentation that took, on the average, 3.91 +/- 0.54 minutes, the overall
segmentation in our implementation required less than 4 seconds.
</summary>
    <author>
      <name>Jan Egger</name>
    </author>
    <author>
      <name>Miriam H. A. Bauer</name>
    </author>
    <author>
      <name>Daniela Kuhnt</name>
    </author>
    <author>
      <name>Bernd Freisleben</name>
    </author>
    <author>
      <name>Christopher Nimsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures, BIOSIGNAL, Berlin, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.1778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.1778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3571v2</id>
    <updated>2012-05-11T05:42:42Z</updated>
    <published>2011-03-28T12:35:11Z</published>
    <title>Visualization techniques for data mining of Latur district satellite
  imagery</title>
    <summary>  This study presents a new visualization tool for classification of satellite
imagery. Visualization of feature space allows exploration of patterns in the
image data and insight into the classification process and related uncertainty.
Visual Data Mining provides added value to image classifications as the user
can be involved in the classification process providing increased confidence in
and understanding of the results. In this study, we present a prototype
visualization tool for visual data mining (VDM) of satellite imagery. The
visualization tool is showcased in a classification study of highresolution
imageries of Latur district in Maharashtra state of India.
</summary>
    <author>
      <name>B. G. Kodge</name>
    </author>
    <author>
      <name>P. S. Hiremath</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Computational Research, Volume 2, Issue 1, 2010,
  pp-21-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.3571v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3571v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.7; H.2.8; I.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4720v1</id>
    <updated>2011-04-25T13:44:25Z</updated>
    <published>2011-04-25T13:44:25Z</published>
    <title>TripNet: A Method for Constructing Phylogenetic Networks from Triplets</title>
    <summary>  We present TripNet, a method for constructing phylogenetic networks from
triplets. We will present the motivations behind our approach and its
theoretical and empirical justification. To demonstrate the accuracy and
efficiency of TripNet, we performed two simulations and also applied the method
to five published data sets: Kreitman's data, a set of triplets from real yeast
data obtained from the Fungal Biodiversity Center in Utrecht, a collection of
110 highly recombinant Salmonella multi-locus sequence typing sequences, and
nrDNA ITS and cpDNA JSA sequence data of New Zealand alpine buttercups of
Ranunculus sect. Pseudadonis. Finally, we compare our results with those
already obtained by other authors using alternative methods. TripNet, data
sets, and supplementary files are freely available for download at
(www.bioinf.cs.ipm.ir/softwares/tripnet).
</summary>
    <author>
      <name>Ruzbeh Tusserkani</name>
    </author>
    <author>
      <name>Changiz Eslahchi</name>
    </author>
    <author>
      <name>Hadi Poormohammadi</name>
    </author>
    <author>
      <name>Azin Azadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4731v1</id>
    <updated>2011-04-25T15:05:04Z</updated>
    <published>2011-04-25T15:05:04Z</published>
    <title>An inflationary differential evolution algorithm for space trajectory
  optimization</title>
    <summary>  In this paper we define a discrete dynamical system that governs the
evolution of a population of agents. From the dynamical system, a variant of
Differential Evolution is derived. It is then demonstrated that, under some
assumptions on the differential mutation strategy and on the local structure of
the objective function, the proposed dynamical system has fixed points towards
which it converges with probability one for an infinite number of generations.
This property is used to derive an algorithm that performs better than standard
Differential Evolution on some space trajectory optimization problems. The
novel algorithm is then extended with a guided restart procedure that further
increases the performance, reducing the probability of stagnation in deceptive
local minima.
</summary>
    <author>
      <name>Massimiliano Vasile</name>
    </author>
    <author>
      <name>Edmondo Minisci</name>
    </author>
    <author>
      <name>Marco Locatelli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TEVC.2010.2087026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TEVC.2010.2087026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Evolutionary Computation 2011. ISSN 1089-778X</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2794v1</id>
    <updated>2011-06-02T06:52:02Z</updated>
    <published>2011-06-02T06:52:02Z</published>
    <title>Power Management during Scan Based Sequential Circuit Testing</title>
    <summary>  This paper shows that not every scan cell contributes equally to the power
consumption during scan based test. The transitions at some scan cells cause
more toggles at the internal signal lines of a circuit than the transitions at
other scan cells. Hence the transitions at these scan cells have a larger
impact on the power consumption during test application. These scan cells are
called power sensitive scan cells.A verilog based approach is proposed to
identify a set of power sensitive scan cells. Additional hardware is added to
freeze the outputs of power sensitive scan cells during scan shifting in order
to reduce the shift power consumption.when multiple scan chain is incorporated
along with freezing the power sensitive scan cell,over all power during testing
can be reduced to a larger extend.
</summary>
    <author>
      <name>Reshma. p</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACIJ 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1128v1</id>
    <updated>2011-07-05T06:01:20Z</updated>
    <published>2011-07-05T06:01:20Z</published>
    <title>AISMOTIF-An Artificial Immune System for DNA Motif Discovery</title>
    <summary>  Discovery of transcription factor binding sites is a much explored and still
exploring area of research in functional genomics. Many computational tools
have been developed for finding motifs and each of them has their own
advantages as well as disadvantages. Most of these algorithms need prior
knowledge about the data to construct background models. However there is not a
single technique that can be considered as best for finding regulatory motifs.
This paper proposes an artificial immune system based algorithm for finding the
transcription factor binding sites or motifs and two new weighted scores for
motif evaluation. The algorithm is enumerative, but sufficient pruning of the
pattern search space has been incorporated using immune system concepts. The
performance of AISMOTIF has been evaluated by comparing it with eight state of
art composite motif discovery algorithms and found that AISMOTIF predicts known
motifs as well as new motifs from the benchmark dataset without any prior
knowledge about the data.
</summary>
    <author>
      <name>K. R Seeja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 2, March 2011 IJCSI International Journal of Computer Science Issues,
  Vol. 8, Issue 2, March 2011, ISSN (Online): 1694-0814, pages 143-149</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.1128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.5951v1</id>
    <updated>2011-07-29T12:31:59Z</updated>
    <published>2011-07-29T12:31:59Z</published>
    <title>Optimal, scalable forward models for computing gravity anomalies</title>
    <summary>  We describe three approaches for computing a gravity signal from a density
anomaly. The first approach consists of the classical "summation" technique,
whilst the remaining two methods solve the Poisson problem for the
gravitational potential using either a Finite Element (FE) discretization
employing a multilevel preconditioner, or a Green's function evaluated with the
Fast Multipole Method (FMM). The methods utilizing the PDE formulation
described here differ from previously published approaches used in gravity
modeling in that they are optimal, implying that both the memory and
computational time required scale linearly with respect to the number of
unknowns in the potential field. Additionally, all of the implementations
presented here are developed such that the computations can be performed in a
massively parallel, distributed memory computing environment. Through numerical
experiments, we compare the methods on the basis of their discretization error,
CPU time and parallel scalability. We demonstrate the parallel scalability of
all these techniques by running forward models with up to $10^8$ voxels on
1000's of cores.
</summary>
    <author>
      <name>Dave A. May</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1365-246X.2011.05167.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1365-246X.2011.05167.x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 13 figures; accepted by Geophysical Journal International</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Geophysical Journal International, 187(1):161-177, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.5951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.5951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0786v1</id>
    <updated>2011-08-03T08:42:47Z</updated>
    <published>2011-08-03T08:42:47Z</published>
    <title>All good things come in threes - Three beads learn to swim with lattice
  Boltzmann and a rigid body solver</title>
    <summary>  We simulate the self-propulsion of devices in a fluid in the regime of low
Reynolds numbers. Each device consists of three bodies (spheres or capsules)
connected with two damped harmonic springs. Sinusoidal driving forces compress
the springs which are resolved within a rigid body physics engine. The latter
is consistently coupled to a 3D lattice Boltzmann framework for the fluid
dynamics. In simulations of three-sphere devices, we find that the propulsion
velocity agrees well with theoretical predictions. In simulations where some or
all spheres are replaced by capsules, we find that the asymmetry of the design
strongly affects the propelling efficiency.
</summary>
    <author>
      <name>Kristina Pickl</name>
    </author>
    <author>
      <name>Jan Götz</name>
    </author>
    <author>
      <name>Klaus Iglberger</name>
    </author>
    <author>
      <name>Jayant Pande</name>
    </author>
    <author>
      <name>Klaus Mecke</name>
    </author>
    <author>
      <name>Ana-Suncana Smith</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <link href="http://arxiv.org/abs/1108.0786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0651v1</id>
    <updated>2011-09-03T20:16:54Z</updated>
    <published>2011-09-03T20:16:54Z</published>
    <title>Mathematical Analysis of the BIBEE Approximation for Molecular
  Solvation: Exact Results for Spherical Inclusions</title>
    <summary>  We analyze the mathematically rigorous BIBEE (boundary-integral based
electrostatics estimation) approximation of the mixed-dielectric continuum
model of molecular electrostatics, using the analytically solvable case of a
spherical solute containing an arbitrary charge distribution. Our analysis,
which builds on Kirkwood's solution using spherical harmonics, clarifies
important aspects of the approximation and its relationship to Generalized Born
models. First, our results suggest a new perspective for analyzing fast
electrostatic models: the separation of variables between material properties
(the dielectric constants) and geometry (the solute dielectric boundary and
charge distribution). Second, we find that the eigenfunctions of the
reaction-potential operator are exactly preserved in the BIBEE model for the
sphere, which supports the use of this approximation for analyzing
charge-charge interactions in molecular binding. Third, a comparison of BIBEE
to the recent GB$\epsilon$ theory suggests a modified BIBEE model capable of
predicting electrostatic solvation free energies to within 4% of a full
numerical Poisson calculation. This modified model leads to a
projection-framework understanding of BIBEE and suggests opportunities for
future improvements.
</summary>
    <author>
      <name>Jaydeep P. Bardhan</name>
    </author>
    <author>
      <name>Matthew G. Knepley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3641485</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3641485" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Chemical Physics, 135(12):124107-124117, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.0651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1044v2</id>
    <updated>2011-09-08T07:57:48Z</updated>
    <published>2011-09-06T02:18:56Z</published>
    <title>Proceedings Third International Workshop on Computational Models for
  Cell Processes</title>
    <summary>  This volume contains the final versions of the papers presented at the 3rd
International Workshop on Computational Models for Cell Processes (CompMod
2011). The workshop took place on September 10, 2011 at the University of
Aachen, Germany, in conjunction with CONCUR 2011. The first edition of the
workshop (2008) took place in Turku, Finland, in conjunction with Formal
Methods 2008 and the second edition (2009) took place in Eindhoven, the
Netherlands, as well in conjunction with Formal Methods 2009. The goal of the
CompMod workshop series is to bring together researchers in Computer Science
(especially in Formal Methods) and Mathematics (both discrete and continuous),
interested in the opportunities and the challenges of Systems Biology.
</summary>
    <author>
      <name>Ion Petre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Åbo Akademi University</arxiv:affiliation>
    </author>
    <author>
      <name>Erik de Vink</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Eindhoven University of Technology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.67</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.67" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 67, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1044v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1044v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1062v1</id>
    <updated>2011-09-06T04:42:55Z</updated>
    <published>2011-09-06T04:42:55Z</published>
    <title>Review on Feature Selection Techniques and the Impact of SVM for Cancer
  Classification using Gene Expression Profile</title>
    <summary>  The DNA microarray technology has modernized the approach of biology research
in such a way that scientists can now measure the expression levels of
thousands of genes simultaneously in a single experiment. Gene expression
profiles, which represent the state of a cell at a molecular level, have great
potential as a medical diagnosis tool. But compared to the number of genes
involved, available training data sets generally have a fairly small sample
size for classification. These training data limitations constitute a challenge
to certain classification methodologies. Feature selection techniques can be
used to extract the marker genes which influence the classification accuracy
effectively by eliminating the un wanted noisy and redundant genes This paper
presents a review of feature selection techniques that have been employed in
micro array data based cancer classification and also the predominant role of
SVM for cancer classification.
</summary>
    <author>
      <name>G. Victo Sudha George</name>
    </author>
    <author>
      <name>V. Cyril Raj</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcses.2011.2302</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcses.2011.2302" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science &amp; Engineering Survey
  (IJCSES) Vol.2, No.3, International Journal of Computer Science &amp; Engineering
  Survey (IJCSES) Vol.2, No.3, August 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1364v1</id>
    <updated>2011-09-07T06:27:16Z</updated>
    <published>2011-09-07T06:27:16Z</published>
    <title>Programmable models of growth and mutation of cancer-cell populations</title>
    <summary>  In this paper we propose a systematic approach to construct mathematical
models describing populations of cancer-cells at different stages of disease
development. The methodology we propose is based on stochastic Concurrent
Constraint Programming, a flexible stochastic modelling language. The
methodology is tested on (and partially motivated by) the study of prostate
cancer. In particular, we prove how our method is suitable to systematically
reconstruct different mathematical models of prostate cancer growth - together
with interactions with different kinds of hormone therapy - at different levels
of refinement.
</summary>
    <author>
      <name>Luca Bortolussi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Mathematics and Informatics, University of Trieste, Italy.</arxiv:affiliation>
    </author>
    <author>
      <name>Alberto Policriti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Mathematics and Informatics, University of Udine, Italy. Institute of Applied Genomics, Udine, Italy.</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.67.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.67.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings CompMod 2011, arXiv:1109.1044</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 67, 2011, pp. 19-33</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3; I.6.5; I.6.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1365v1</id>
    <updated>2011-09-07T06:27:23Z</updated>
    <published>2011-09-07T06:27:23Z</published>
    <title>A semi-quantitative equivalence for abstracting from fast reactions</title>
    <summary>  Semantic equivalences are used in process algebra to capture the notion of
similar behaviour, and this paper proposes a semi-quantitative equivalence for
a stochastic process algebra developed for biological modelling. We consider
abstracting away from fast reactions as suggested by the Quasi-Steady-State
Assumption. We define a fast-slow bisimilarity based on this idea. We also show
congruence under an appropriate condition for the cooperation operator of
Bio-PEPA. The condition requires that there is no synchronisation over fast
actions, and this distinguishes fast-slow bisimilarity from weak bisimilarity.
We also show congruence for an operator which extends the reactions available
for a species. We characterise models for which it is only necessary to
consider the matching of slow transitions and we illustrate the equivalence on
two models of competitive inhibition.
</summary>
    <author>
      <name>Vashti Galpin</name>
    </author>
    <author>
      <name>Jane Hillston</name>
    </author>
    <author>
      <name>Federica Ciocchetta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.67.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.67.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings CompMod 2011, arXiv:1109.1044</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 67, 2011, pp. 34-49</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3563v2</id>
    <updated>2013-08-01T14:46:30Z</updated>
    <published>2011-09-16T09:42:03Z</published>
    <title>Verification, Validation and Testing of Kinetic Mechanisms of Hydrogen
  Combustion in Fluid Dynamic Computations</title>
    <summary>  A one-step, a two-step, an abridged, a skeletal and four detailed kinetic
schemes of hydrogen oxidation have been tested. A new skeletal kinetic scheme
of hydrogen oxidation has been developed. The CFD calculations were carried out
using ANSYS CFX software. Ignition delay times and speeds of flames were
derived from the computational results. The computational data obtained using
ANSYS CFX and CHEMKIN, and experimental data were compared. The precision,
reliability, and range of validity of the kinetic schemes in CFD simulations
were estimated. The impact of kinetic scheme on the results of computations was
discussed. The relationship between grid spacing, timestep, accuracy, and
computational cost were analyzed.
</summary>
    <author>
      <name>Victor P. Zhukov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5402/2012/475607</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5402/2012/475607" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The alternate reference of this paper: V.P. Zhukov, "Verification,
  Validation and Testing of Kinetic Models of Hydrogen Combustion in Fluid
  Dynamic Computations", Paper ID35 at 4th European Conference for Aerospace
  Sciences, Saint Petersburg, Russia, 4--8 July, 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ISRN Mechanical Engineering, vol. 2012, Article ID 475607, 11
  pages, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.3563v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3563v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.4928v2</id>
    <updated>2013-04-06T09:39:10Z</updated>
    <published>2011-09-22T19:46:02Z</published>
    <title>RPA: Probabilistic analysis of probe performance and robust
  summarization</title>
    <summary>  Probe-level models have led to improved performance in microarray studies but
the various sources of probe-level contamination are still poorly understood.
Data-driven analysis of probe performance can be used to quantify the
uncertainty in individual probes and to highlight the relative contribution of
different noise sources. Improved understanding of the probe-level effects can
lead to improved preprocessing techniques and microarray design.
  We have implemented probabilistic tools for probe performance analysis and
summarization on short oligonucleotide arrays. In contrast to standard
preprocessing approaches, the methods provide quantitative estimates of
probe-specific noise and affinity terms and tools to investigate these
parameters. Tools to incorporate prior information of the probes in the
analysis are provided as well. Comparisons to known probe-level error sources
and spike-in data sets validate the approach.
  Implementation is freely available in R/BioConductor:
http://www.bioconductor.org/packages/release/bioc/html/RPA.html
</summary>
    <author>
      <name>Leo Lahti</name>
    </author>
    <author>
      <name>Laura L. Elo</name>
    </author>
    <author>
      <name>Tero Aittokallio</name>
    </author>
    <author>
      <name>Samuel Kaski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Replaced by extended work which forms an independent publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.4928v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.4928v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0895v4</id>
    <updated>2012-07-02T14:07:13Z</updated>
    <published>2011-10-05T04:55:59Z</published>
    <title>Robust inversion via semistochastic dimensionality reduction</title>
    <summary>  We consider a class of inverse problems where it is possible to aggregate the
results of multiple experiments. This class includes problems where the forward
model is the solution operator to linear ODEs or PDEs. The tremendous size of
such problems motivates dimensionality reduction techniques based on randomly
mixing experiments. These techniques break down, however, when robust
data-fitting formulations are used, which are essential in cases of missing
data, unusually large errors, and systematic features in the data unexplained
by the forward model. We survey robust methods within a statistical framework,
and propose a semistochastic optimization approach that allows dimensionality
reduction. The efficacy of the methods are demonstrated for a large-scale
seismic inverse problem using the robust Student's t-distribution, where a
useful synthetic velocity model is recovered in the extreme scenario of 60%
data missing at random. The semistochastic approach achieves this recovery
using 20% of the effort required by a direct robust approach.
</summary>
    <author>
      <name>Aleksandr Aravkin</name>
    </author>
    <author>
      <name>Michael P. Friedlander</name>
    </author>
    <author>
      <name>Tristan van Leeuwen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10107-012-0571-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10107-012-0571-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Programming, 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Programming 134 (1), 101-125, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.0895v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0895v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1628v2</id>
    <updated>2012-10-11T13:17:06Z</updated>
    <published>2011-10-07T19:03:24Z</published>
    <title>Optimisation of hybrid high-modulus/high-strength carbon fiber
  reinforced plastic composite drive</title>
    <summary>  This study deals with the optimisation of hybrid composite drive shafts
operating at subcritical or supercritical speeds, using a genetic algorithm. A
formulation for the flexural vibrations of a composite drive shaft mounted on
viscoelastic supports including shear effects is developed. In particular, an
analytic stability criterion is developed to ensure the integrity of the system
in the supercritical regime. Then it is shown that the torsional strength can
be computed with the maximum stress criterion. A shell method is developed for
computing drive shaft torsional buckling. The optimisation of a helicopter tail
rotor driveline is then performed. In particular, original hybrid shafts
consisting of high-modulus and high-strength carbon fibre reinforced epoxy
plies were studied. The solutions obtained using the method presented here made
it possible to greatly decrease the number of shafts and the weight of the
driveline under subcritical conditions, and even more under supercritical
conditions. This study yielded some general rules for designing an optimum
composite shaft without any need for optimisation algorithms.
</summary>
    <author>
      <name>Olivier Montagnier</name>
    </author>
    <author>
      <name>Christian Hochard</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.matdes.2012.09.035</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.matdes.2012.09.035" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, preprint submitted to Materials and Design (Received 22
  February 2012; received in revised form 18 september 2012; accepted 21
  september 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1628v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1628v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1708v1</id>
    <updated>2011-10-08T08:35:04Z</updated>
    <published>2011-10-08T08:35:04Z</published>
    <title>Advancing Nuclear Physics Through TOPS Solvers and Tools</title>
    <summary>  At the heart of many scientific applications is the solution of algebraic
systems, such as linear systems of equations, eigenvalue problems, and
optimization problems, to name a few. TOPS, which stands for Towards Optimal
Petascale Simulations, is a SciDAC applied math center focused on the
development of solvers for tackling these algebraic systems, as well as the
deployment of such technologies in large-scale scientific applications of
interest to the U.S. Department of Energy. In this paper, we highlight some of
the solver technologies we have developed in optimization and matrix
computations. We also describe some accomplishments achieved using these
technologies in UNEDF, a SciDAC application project on nuclear physics.
</summary>
    <author>
      <name>E Ng</name>
    </author>
    <author>
      <name>J Sarich</name>
    </author>
    <author>
      <name>S M Wild</name>
    </author>
    <author>
      <name>T Munson</name>
    </author>
    <author>
      <name>H Aktulga</name>
    </author>
    <author>
      <name>C Yang</name>
    </author>
    <author>
      <name>P Maris</name>
    </author>
    <author>
      <name>J P Vary</name>
    </author>
    <author>
      <name>N Schunck</name>
    </author>
    <author>
      <name>M G Bertolli</name>
    </author>
    <author>
      <name>M Kortelainen</name>
    </author>
    <author>
      <name>W Nazarewicz</name>
    </author>
    <author>
      <name>T Papenbrock</name>
    </author>
    <author>
      <name>M V Stoitsov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SciDAC 2011 Conference, July 10-14, 2011, Denver, CO; 5 pages, 2
  tables, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.2055v1</id>
    <updated>2011-10-10T14:34:59Z</updated>
    <published>2011-10-10T14:34:59Z</published>
    <title>Computational homogenization of non-stationary transport processes in
  masonry structures</title>
    <summary>  A fully coupled transient heat and moisture transport in a masonry structure
is examined in this paper. Supported by several successful applications in
civil engineering the nonlinear diffusion model proposed by K\"{u}nzel is
adopted in the present study. A strong material heterogeneity together with a
significant dependence of the model parameters on initial conditions as well as
the gradients of heat and moisture fields vindicates the use of a hierarchical
modeling strategy to solve the problem of this kind. Attention is limited to
the classical first order homogenization in a spatial domain developed here in
the framework of a two step (meso-macro) multi-scale computational scheme (FE^2
problem). Several illustrative examples are presented to investigate the
influence of transient flow at the level of constituents (meso-scale) on the
macroscopic response including the effect of macro-scale boundary conditions. A
two-dimensional section of Charles Bridge subjected to actual climatic
conditions is analyzed next to confirm the suitability of algorithmic format of
FE^2 scheme for the parallel computing.
</summary>
    <author>
      <name>J. Sykora</name>
    </author>
    <author>
      <name>T. Krejci</name>
    </author>
    <author>
      <name>J. Kruis</name>
    </author>
    <author>
      <name>M. Sejnoha</name>
    </author>
    <link href="http://arxiv.org/abs/1110.2055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.2055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4639v1</id>
    <updated>2011-11-20T15:23:09Z</updated>
    <published>2011-11-20T15:23:09Z</published>
    <title>Cancer gene prioritization by integrative analysis of mRNA expression
  and DNA copy number data: a comparative review</title>
    <summary>  A variety of genome-wide profiling techniques are available to probe
complementary aspects of genome structure and function. Integrative analysis of
heterogeneous data sources can reveal higher-level interactions that cannot be
detected based on individual observations. A standard integration task in
cancer studies is to identify altered genomic regions that induce changes in
the expression of the associated genes based on joint analysis of genome-wide
gene expression and copy number profiling measurements. In this review, we
provide a comparison among various modeling procedures for integrating
genome-wide profiling data of gene copy number and transcriptional alterations
and highlight common approaches to genomic data integration. A transparent
benchmarking procedure is introduced to quantitatively compare the cancer gene
prioritization performance of the alternative methods. The benchmarking
algorithms and data sets are available at http://intcomp.r-forge.r-project.org
</summary>
    <author>
      <name>Leo Lahti</name>
    </author>
    <author>
      <name>Martin Schäfer</name>
    </author>
    <author>
      <name>Hans-Ulrich Klein</name>
    </author>
    <author>
      <name>Silvio Bicciato</name>
    </author>
    <author>
      <name>Martin Dugas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/bib/bbs005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/bib/bbs005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PDF file including supplementary material. 9 pages. Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6214v1</id>
    <updated>2011-11-27T02:02:53Z</updated>
    <published>2011-11-27T02:02:53Z</published>
    <title>Robust Max-Product Belief Propagation</title>
    <summary>  We study the problem of optimizing a graph-structured objective function
under \emph{adversarial} uncertainty. This problem can be modeled as a
two-persons zero-sum game between an Engineer and Nature. The Engineer controls
a subset of the variables (nodes in the graph), and tries to assign their
values to maximize an objective function. Nature controls the complementary
subset of variables and tries to minimize the same objective. This setting
encompasses estimation and optimization problems under model uncertainty, and
strategic problems with a graph structure. Von Neumann's minimax theorem
guarantees the existence of a (minimax) pair of randomized strategies that
provide optimal robustness for each player against its adversary.
  We prove several structural properties of this strategy pair in the case of
graph-structured payoff function. In particular, the randomized minimax
strategies (distributions over variable assignments) can be chosen in such a
way to satisfy the Markov property with respect to the graph. This
significantly reduces the problem dimensionality. Finally we introduce a
message passing algorithm to solve this minimax problem. The algorithm
generalizes max-product belief propagation to this new domain.
</summary>
    <author>
      <name>Morteza Ibrahimi</name>
    </author>
    <author>
      <name>Adel Javanmard</name>
    </author>
    <author>
      <name>Yashodhan Kanoria</name>
    </author>
    <author>
      <name>Andrea Montanari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0351v1</id>
    <updated>2012-01-01T13:34:55Z</updated>
    <published>2012-01-01T13:34:55Z</published>
    <title>Liquid-gas-solid flows with lattice Boltzmann: Simulation of floating
  bodies</title>
    <summary>  This paper presents a model for the simulation of liquid-gas-solid flows by
means of the lattice Boltzmann method. The approach is built upon previous
works for the simulation of liquid-solid particle suspensions on the one hand,
and on a liquid-gas free surface model on the other. We show how the two
approaches can be unified by a novel set of dynamic cell conversion rules. For
evaluation, we concentrate on the rotational stability of non-spherical rigid
bodies floating on a plane water surface - a classical hydrostatic problem
known from naval architecture. We show the consistency of our method in this
kind of flows and obtain convergence towards the ideal solution for the
measured heeling stability of a floating box.
</summary>
    <author>
      <name>Simon Bogner</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.camwa.2012.09.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.camwa.2012.09.012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, Preprint submitted to Computers and Mathematics with
  Applications Special Issue ICMMES 2011, Proceedings of the Eighth
  International Conference for Mesoscopic Methods in Engineering and Science</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0469v1</id>
    <updated>2012-01-02T14:10:57Z</updated>
    <published>2012-01-02T14:10:57Z</published>
    <title>Computing Critical $k$-tuples in Power Networks</title>
    <summary>  In this paper the problem of finding the sparsest (i.e., minimum cardinality)
critical $k$-tuple including one arbitrarily specified measurement is
considered. The solution to this problem can be used to identify weak points in
the measurement set, or aid the placement of new meters. The critical $k$-tuple
problem is a combinatorial generalization of the critical measurement
calculation problem. Using topological network observability results, this
paper proposes an efficient and accurate approximate solution procedure for the
considered problem based on solving a minimum-cut (Min-Cut) problem and
enumerating all its optimal solutions. It is also shown that the sparsest
critical $k$-tuple problem can be formulated as a mixed integer linear
programming (MILP) problem. This MILP problem can be solved exactly using
available solvers such as CPLEX and Gurobi. A detailed numerical study is
presented to evaluate the efficiency and the accuracy of the proposed Min-Cut
and MILP calculations.
</summary>
    <author>
      <name>Kin Cheong Sou</name>
    </author>
    <author>
      <name>Henrik Sandberg</name>
    </author>
    <author>
      <name>Karl Henrik Johansson</name>
    </author>
    <link href="http://arxiv.org/abs/1201.0469v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0469v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0942v2</id>
    <updated>2012-12-06T08:11:50Z</updated>
    <published>2012-01-04T17:35:27Z</published>
    <title>Competitive Comparison of Optimal Designs of Experiments for
  Sampling-based Sensitivity Analysis</title>
    <summary>  Nowadays, the numerical models of real-world structures are more precise,
more complex and, of course, more time-consuming. Despite the growth of a
computational effort, the exploration of model behaviour remains a complex
task. The sensitivity analysis is a basic tool for investigating the
sensitivity of the model to its inputs. One widely used strategy to assess the
sensitivity is based on a finite set of simulations for a given sets of input
parameters, i.e. points in the design space. An estimate of the sensitivity can
be then obtained by computing correlations between the input parameters and the
chosen response of the model. The accuracy of the sensitivity prediction
depends on the choice of design points called the design of experiments. The
aim of the presented paper is to review and compare available criteria
determining the quality of the design of experiments suitable for
sampling-based sensitivity analysis.
</summary>
    <author>
      <name>Eliska Janouchova</name>
    </author>
    <author>
      <name>Anna Kucerova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2013.04.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2013.04.009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures, 4 tables, CSC2011 special issue, corrected and
  extended after the first review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers &amp; Structures, 124, 47-60, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.0942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4499v1</id>
    <updated>2012-01-21T19:12:38Z</updated>
    <published>2012-01-21T19:12:38Z</published>
    <title>Mathematical and computational modeling for describing the basic
  behavior of free radicals and antioxidants within epithelial cells</title>
    <summary>  The traditional methods of the biology, based on illustrative descriptions
and linear logic explanations, are discussed. This work aims to improve this
approach by introducing alternative tools to describe and represent complex
biological systems. Two models were developed, one mathematical and another
computational, both were made in order to study the biological process between
free radicals and antioxidants. Each model was used to study the same process
but in different scenarios. The mathematical model was used to study the
biological process in an epithelial cells culture; this model was validated
with the experimental data of Anne Hanneken's research group from the
Department of Molecular and Experimental Medicine, published by the journal
Investigative Ophthalmology and Visual Science in July 2006. The computational
model was used to study the same process in an individual. The model was made
using C++ programming language, supported by the network theory of aging.
</summary>
    <author>
      <name>Alvaro Juan Ojeda Garcia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures. Treball de Recerca, gener de 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.4499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4914v1</id>
    <updated>2012-01-24T06:37:49Z</updated>
    <published>2012-01-24T06:37:49Z</published>
    <title>Effective Clustering Algorithms for Gene Expression Data</title>
    <summary>  Microarrays are made it possible to simultaneously monitor the expression
profiles of thousands of genes under various experimental conditions.
Identification of co-expressed genes and coherent patterns is the central goal
in microarray or gene expression data analysis and is an important task in
Bioinformatics research. In this paper, K-Means algorithm hybridised with
Cluster Centre Initialization Algorithm (CCIA) is proposed Gene Expression
Data. The proposed algorithm overcomes the drawbacks of specifying the number
of clusters in the K-Means methods. Experimental analysis shows that the
proposed method performs well on gene Expression Data when compare with the
traditional K- Means clustering and Silhouette Coefficients cluster measure.
</summary>
    <author>
      <name>T. Chandrasekhar</name>
    </author>
    <author>
      <name>K. Thangavel</name>
    </author>
    <author>
      <name>E. Elayaraja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications (0975 - 8887)
  Volume 32 - No.4, October 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.4914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2499v2</id>
    <updated>2013-01-19T21:11:11Z</updated>
    <published>2012-03-12T14:26:05Z</published>
    <title>A framework for integrated design of algorithmic architectural forms</title>
    <summary>  This paper presents a methodology and software tools for parametric design of
complex architectural objects, called digital or algorithmic forms. In order to
provide a flexible tool, the proposed design philosophy involves two open
source utilities Donkey and MIDAS written in Grasshopper algorithm editor and
C++, respectively, that are to be linked with a scripting-based architectural
modellers Rhinoceros, IntelliCAD and the open source Finite Element solver
OOFEM. The emphasis is put on the mechanical response in order to provide
architects with a consistent learning framework and an insight into structural
behaviour of designed objects. As demonstrated on three case studies, the
proposed modular solution is capable of handling objects of considerable
structural complexity, thereby accelerating the process of finding procedural
design parameters from orders of weeks to days or hours.
</summary>
    <author>
      <name>Ladislav Svoboda</name>
    </author>
    <author>
      <name>Jan Novák</name>
    </author>
    <author>
      <name>Lukáš Kurilla</name>
    </author>
    <author>
      <name>Jan Zeman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advengsoft.2013.05.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advengsoft.2013.05.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 15 figures, v2: Substantially revised after the first
  review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Engineering Software, 72, 109--118, (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.2499v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2499v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3055v2</id>
    <updated>2012-12-28T10:54:19Z</updated>
    <published>2012-03-14T11:43:21Z</published>
    <title>Application of sensitivity analysis in building energy simulations:
  combining first and second order elementary effects Methods</title>
    <summary>  Sensitivity analysis plays an important role in the understanding of complex
models. It helps to identify influence of input parameters in relation to the
outputs. It can be also a tool to understand the behavior of the model and then
can help in its development stage. This study aims to analyze and illustrate
the potential usefulness of combining first and second-order sensitivity
analysis, applied to a building energy model (ESP-r). Through the example of a
collective building, a sensitivity analysis is performed using the method of
elementary effects (also known as Morris method), including an analysis of
interactions between the input parameters (second order analysis). Importance
of higher-order analysis to better support the results of first order analysis,
highlighted especially in such complex model. Several aspects are tackled to
implement efficiently the multi-order sensitivity analysis: interval size of
the variables, management of non-linearity, usefulness of various outputs.
</summary>
    <author>
      <name>David Garcia Sanchez</name>
    </author>
    <author>
      <name>Bruno Lacarrière</name>
    </author>
    <author>
      <name>Marjorie Musy</name>
    </author>
    <author>
      <name>Bernard Bourges</name>
    </author>
    <link href="http://arxiv.org/abs/1203.3055v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3055v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1428v1</id>
    <updated>2012-05-07T15:24:56Z</updated>
    <published>2012-05-07T15:24:56Z</published>
    <title>High Velocity Penetration/Perforation Using Coupled Smooth Particle
  Hydrodynamics-Finite Element Method</title>
    <summary>  Finite element method (FEM) suffers from a serious mesh distortion problem
when used for high velocity impact analyses. The smooth particle hydrodynamics
(SPH) method is appropriate for this class of problems involving severe damages
but at considerable computational cost. It is beneficial if the latter is
adopted only in severely distorted regions and FEM further away. The coupled
smooth particle hydrodynamics - finite element method (SFM) has been adopted in
a commercial hydrocode LS-DYNA to study the perforation of Weldox 460E steel
and AA5083-H116 aluminum plates with varying thicknesses and various projectile
nose geometries including blunt, conical and ogival noses. Effects of the SPH
domain size and particle density are studied considering the friction effect
between the projectile and the target materials. The simulated residual
velocities and the ballistic limit velocities from the SFM agree well with the
published experimental data. The study shows that SFM is able to emulate the
same failure mechanisms of the steel and aluminum plates as observed in various
experimental investigations for initial impact velocity of 170 m/s and higher.
</summary>
    <author>
      <name>S. Swaddiwudhipong</name>
    </author>
    <author>
      <name>M. J. Islam</name>
    </author>
    <author>
      <name>Z. S. Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages; International Journal of Protective Structures 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.1428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="74C05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.5024v1</id>
    <updated>2012-05-22T10:28:29Z</updated>
    <published>2012-05-22T10:28:29Z</published>
    <title>Analytical Study of Hexapod miRNAs using Phylogenetic Methods</title>
    <summary>  MicroRNAs (miRNAs) are a class of non-coding RNAs that regulate gene
expression. Identification of total number of miRNAs even in completely
sequenced organisms is still an open problem. However, researchers have been
using techniques that can predict limited number of miRNA in an organism. In
this paper, we have used homology based approach for comparative analysis of
miRNA of hexapoda group .We have used Apis mellifera, Bombyx mori, Anopholes
gambiae and Drosophila melanogaster miRNA datasets from miRBase repository. We
have done pair wise as well as multiple alignments for the available miRNAs in
the repository to identify and analyse conserved regions among related species.
Unfortunately, to the best of our knowledge, miRNA related literature does not
provide in depth analysis of hexapods. We have made an attempt to derive the
commonality among the miRNAs and to identify the conserved regions which are
still not available in miRNA repositories. The results are good approximation
with a small number of mismatches. However, they are encouraging and may
facilitate miRNA biogenesis for
</summary>
    <author>
      <name>A. K. Mishra</name>
    </author>
    <author>
      <name>H. Chandrasekharan</name>
    </author>
    <link href="http://arxiv.org/abs/1205.5024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.5024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1305v1</id>
    <updated>2012-06-06T19:21:22Z</updated>
    <published>2012-06-06T19:21:22Z</published>
    <title>MACS: An Agent-Based Memetic Multiobjective Optimization Algorithm
  Applied to Space Trajectory Design</title>
    <summary>  This paper presents an algorithm for multiobjective optimization that blends
together a number of heuristics. A population of agents combines heuristics
that aim at exploring the search space both globally and in a neighborhood of
each agent. These heuristics are complemented with a combination of a local and
global archive. The novel agent- based algorithm is tested at first on a set of
standard problems and then on three specific problems in space trajectory
design. Its performance is compared against a number of state-of-the-art
multiobjective optimisation algorithms that use the Pareto dominance as
selection criterion: NSGA-II, PAES, MOPSO, MTS. The results demonstrate that
the agent-based search can identify parts of the Pareto set that the other
algorithms were not able to capture. Furthermore, convergence is statistically
better although the variance of the results is in some cases higher.
</summary>
    <author>
      <name>Massimiliano Vasile</name>
    </author>
    <author>
      <name>Federico Zuiani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1177/0954410011410274</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1177/0954410011410274" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Institution of Mechanical Engineers, Part G:
  Journal of Aerospace Engineering September 5, 2011 0954410011410274</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.1305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4626v1</id>
    <updated>2012-06-18T15:07:23Z</updated>
    <published>2012-06-18T15:07:23Z</published>
    <title>On-Line Portfolio Selection with Moving Average Reversion</title>
    <summary>  On-line portfolio selection has attracted increasing interests in machine
learning and AI communities recently. Empirical evidences show that stock's
high and low prices are temporary and stock price relatives are likely to
follow the mean reversion phenomenon. While the existing mean reversion
strategies are shown to achieve good empirical performance on many real
datasets, they often make the single-period mean reversion assumption, which is
not always satisfied in some real datasets, leading to poor performance when
the assumption does not hold. To overcome the limitation, this article proposes
a multiple-period mean reversion, or so-called Moving Average Reversion (MAR),
and a new on-line portfolio selection strategy named "On-Line Moving Average
Reversion" (OLMAR), which exploits MAR by applying powerful online learning
techniques. From our empirical results, we found that OLMAR can overcome the
drawback of existing mean reversion algorithms and achieve significantly better
results, especially on the datasets where the existing mean reversion
algorithms failed. In addition to superior trading performance, OLMAR also runs
extremely fast, further supporting its practical applicability to a wide range
of applications.
</summary>
    <author>
      <name>Bin Li</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTU</arxiv:affiliation>
    </author>
    <author>
      <name>Steven C. H. Hoi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTU</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5256v1</id>
    <updated>2012-06-20T14:58:18Z</updated>
    <published>2012-06-20T14:58:18Z</published>
    <title>Discovering Patterns in Biological Sequences by Optimal Segmentation</title>
    <summary>  Computational methods for discovering patterns of local correlations in
sequences are important in computational biology. Here we show how to determine
the optimal partitioning of aligned sequences into non-overlapping segments
such that positions in the same segment are strongly correlated while positions
in different segments are not. Our approach involves discovering the hidden
variables of a Bayesian network that interact with observed sequences so as to
form a set of independent mixture models. We introduce a dynamic program to
efficiently discover the optimal segmentation, or equivalently the optimal set
of hidden variables. We evaluate our approach on two computational biology
tasks. One task is related to the design of vaccines against polymorphic
pathogens and the other task involves analysis of single nucleotide
polymorphisms (SNPs) in human DNA. We show how common tasks in these problems
naturally correspond to inference procedures in the learned models. Error rates
of our learned models for the prediction of missing SNPs are up to 1/3 less
than the error rates of a state-of-the-art SNP prediction method. Source code
is available at www.uwm.edu/~joebock/segmentation.
</summary>
    <author>
      <name>Joseph Bockhorst</name>
    </author>
    <author>
      <name>Nebojsa Jojic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.5256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6439v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Gap Filling in the Plant Kingdom---Trait Prediction Using Hierarchical
  Probabilistic Matrix Factorization</title>
    <summary>  Plant traits are a key to understanding and predicting the adaptation of
ecosystems to environmental changes, which motivates the TRY project aiming at
constructing a global database for plant traits and becoming a standard
resource for the ecological community. Despite its unprecedented coverage, a
large percentage of missing data substantially constrains joint trait analysis.
Meanwhile, the trait data is characterized by the hierarchical phylogenetic
structure of the plant kingdom. While factorization based matrix completion
techniques have been widely used to address the missing data problem,
traditional matrix factorization methods are unable to leverage the
phylogenetic structure. We propose hierarchical probabilistic matrix
factorization (HPMF), which effectively uses hierarchical phylogenetic
information for trait prediction. We demonstrate HPMF's high accuracy,
effectiveness of incorporating hierarchical structure and ability to capture
trait correlation through experiments.
</summary>
    <author>
      <name>Hanhuai Shan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Minnesota</arxiv:affiliation>
    </author>
    <author>
      <name>Jens Kattge</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Max Planck Institute for Biogeochemistry</arxiv:affiliation>
    </author>
    <author>
      <name>Peter Reich</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Minnesota</arxiv:affiliation>
    </author>
    <author>
      <name>Arindam Banerjee</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Minnesota</arxiv:affiliation>
    </author>
    <author>
      <name>Franziska Schrodt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Minnesota</arxiv:affiliation>
    </author>
    <author>
      <name>Markus Reichstein</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Max Planck Institute for Biogeochemistry</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6439v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6439v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6459v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Bayesian Conditional Cointegration</title>
    <summary>  Cointegration is an important topic for time-series, and describes a
relationship between two series in which a linear combination is stationary.
Classically, the test for cointegration is based on a two stage process in
which first the linear relation between the series is estimated by Ordinary
Least Squares. Subsequently a unit root test is performed on the residuals. A
well-known deficiency of this classical approach is that it can lead to
erroneous conclusions about the presence of cointegration. As an alternative,
we present a framework for estimating whether cointegration exists using
Bayesian inference which is empirically superior to the classical approach.
Finally, we apply our technique to model segmented cointegration in which
cointegration may exist only for limited time. In contrast to previous
approaches our model makes no restriction on the number of possible
cointegration segments.
</summary>
    <author>
      <name>Chris Bracegirdle</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University College London</arxiv:affiliation>
    </author>
    <author>
      <name>David Barber</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University College London</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.0313v1</id>
    <updated>2012-07-02T09:18:53Z</updated>
    <published>2012-07-02T09:18:53Z</published>
    <title>Intellectual Management of Enterprise</title>
    <summary>  A new technology (in addition to ERP) is proposed to provide an increase of
profit and normal cash flow. This technology involves the next functions:
forming of intellectual interface on a natural language to communicate with a
control system; joint planning of production and sales to get the maximal
profit; an adaptation of control system to internal and external events. The
use of the natural language permits to overcome a barrier between the control
system and upper managers. To solve posed actual problems of management the
selection of information from a database and call to mathematical methods are
executed automatically. Optimal planning provides the maximal use of available
resources and opportunities of market. Adaptive control implements the
efficient reaction to critical events that lead up to a decrease of profit and
increase of accounts receivable.
</summary>
    <author>
      <name>Yuriy Ostapov</name>
    </author>
    <link href="http://arxiv.org/abs/1207.0313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.0313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1547v1</id>
    <updated>2012-07-06T07:54:16Z</updated>
    <published>2012-07-06T07:54:16Z</published>
    <title>Hybrid Forecasting of Exchange Rate by Using Chaos Wavelet SVM-Markov
  Model and Grey Relation Degree</title>
    <summary>  This paper proposes an exchange rate forecasting method by using the grey
relative combination approach of chaos wavelet SVM-Markov model. The problem of
short-term forecast of exchange rate by using the comprehensive method of the
phase space reconstitution and SVM method has been researched. We have
suggested a wavelet-SVR-Markov forecasting model to predict the finance time
series and demonstrated that can more improve the forecasting performance by
the rational combination of the forecast results through various combinational
tests. Our test result has been showed that the two-stage combination model is
more excellent than the normal combination model. Also we have comprehensively
estimated the combination forecast methods according to the forecasting
performance indicators.The estimated result have been shown that the
combination forecast methods on the basic of the degree of grey relation and
the optimal grey relation combination have fine forecast performance.
</summary>
    <author>
      <name>Kim Gol</name>
    </author>
    <author>
      <name>Ri Suk Yun</name>
    </author>
    <link href="http://arxiv.org/abs/1207.1547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2169v2</id>
    <updated>2012-11-10T05:19:32Z</updated>
    <published>2012-07-09T20:25:26Z</published>
    <title>High-throughput Genome-wide Association Analysis for Single and Multiple
  Phenotypes</title>
    <summary>  The variance component tests used in genomewide association studies of
thousands of individuals become computationally exhaustive when multiple traits
are analysed in the context of omics studies. We introduce two high-throughput
algorithms -- CLAK-CHOL and CLAK-EIG -- for single and multiple phenotype
genome-wide association studies (GWAS). The algorithms, generated with the help
of an expert system, reduce the computational complexity to the point that
thousands of traits can be analyzed for association with millions of
polymorphisms in a course of days on a standard workstation. By taking
advantage of problem specific knowledge, CLAK-CHOL and CLAK-EIG significantly
outperform the current state-of-the-art tools in both single and multiple trait
analysis.
</summary>
    <author>
      <name>Diego Fabregat-Traver</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Yurii S. Aulchenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute of Cytology and Genetics SD RAS</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1207.2169v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2169v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3437v1</id>
    <updated>2012-07-14T16:17:52Z</updated>
    <published>2012-07-14T16:17:52Z</published>
    <title>Robust Mission Design Through Evidence Theory and Multi-Agent
  Collaborative Search</title>
    <summary>  In this paper, the preliminary design of a space mission is approached
introducing uncertainties on the design parameters and formulating the
resulting reliable design problem as a multiobjective optimization problem.
Uncertainties are modelled through evidence theory and the belief, or
credibility, in the successful achievement of mission goals is maximised along
with the reliability of constraint satisfaction. The multiobjective
optimisation problem is solved through a novel algorithm based on the
collaboration of a population of agents in search for the set of highly
reliable solutions. Two typical problems in mission analysis are used to
illustrate the proposed methodology.
</summary>
    <author>
      <name>Massimiliano Vasile</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1196/annals.1370.024</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1196/annals.1370.024" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of the New York Academy of Science, Volume 1065, New Trends
  in Astrodynamics and Applications pages 152-173, December 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.3437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3442v1</id>
    <updated>2012-07-14T16:53:16Z</updated>
    <published>2012-07-14T16:53:16Z</published>
    <title>Approximated Computation of Belief Functions for Robust Design
  Optimization</title>
    <summary>  This paper presents some ideas to reduce the computational cost of
evidence-based robust design optimization. Evidence Theory crystallizes both
the aleatory and epistemic uncertainties in the design parameters, providing
two quantitative measures, Belief and Plausibility, of the credibility of the
computed value of the design budgets. The paper proposes some techniques to
compute an approximation of Belief and Plausibility at a cost that is a
fraction of the one required for an accurate calculation of the two values.
Some simple test cases will show how the proposed techniques scale with the
dimension of the problem. Finally a simple example of spacecraft system design
is presented.
</summary>
    <author>
      <name>Massimiliano Vasile</name>
    </author>
    <author>
      <name>Edmondo Minisci</name>
    </author>
    <author>
      <name>Quirien Wijnands</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AIAA-2012-1932 14th AIAA Non-Deterministic Approaches Conference.
  23-26 April 2012 Sheraton Waikiki, Honolulu, Hawaii</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3472v1</id>
    <updated>2012-07-15T01:30:56Z</updated>
    <published>2012-07-15T01:30:56Z</published>
    <title>Optimal Selection of Assets Investing Composition Plan based on Grey
  Multi Objective Programming method</title>
    <summary>  The problem for selection of appropriate assets investing composition
projects such as assets rationalization plays an important role in promotion of
business systems. We consider the assets investing composition plan problems
subject to grey multiobjective programming with the grey inequality
constraints. In this paper, we show in detail the entire process of the
application from modeling the case problem to generating its solution. To solve
the grey multi objective programming problem, we then develop and apply an
algorithm of grey multiple objective programming by weighting method and an
algorithm of grey multiple objective programming based on q -positioned
programming method. These algorithms all regard as of great importance
uncertainty (greyness) at grey multiobjective programming and simple and easy
the calculating process. The calculating examples of paper also show ability
and effectiveness of algorithms.
</summary>
    <author>
      <name>Gol Kim</name>
    </author>
    <author>
      <name>Ri Suk Yun</name>
    </author>
    <link href="http://arxiv.org/abs/1207.3472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3646v1</id>
    <updated>2012-07-16T12:20:16Z</updated>
    <published>2012-07-16T12:20:16Z</published>
    <title>OGCOSMO: An auxiliary tool for the study of the Universe within
  hierarchical scenario of structure formation</title>
    <summary>  In this work is presented the software OGCOSMO. This program was written
using high level design methodology (HLDM), that is based on the use of very
high level (VHL) programing language as main, and the use of the intermediate
level (IL) language only for the critical processing time. The languages used
are PYTHON (VHL) and FORTRAN (IL). The core of OGCOSMO is a package called
OGC{\_}lib. This package contains a group of modules for the study of
cosmological and astrophysical processes, such as: comoving distance, relation
between redshift and time, cosmic star formation rate, number density of dark
matter haloes and mass function of supermassive black holes (SMBHs). The
software is under development and some new features will be implemented for the
research of stochastic background of gravitational waves (GWs) generated by:
stellar collapse to form black holes, binary systems of SMBHs. Even more, we
show that the use of HLDM with PYTHON and FORTRAN is a powerful tool for
producing astrophysical softwares.
</summary>
    <author>
      <name>Eduardo dos Santos Pereira</name>
    </author>
    <author>
      <name>Oswaldo D. Miranda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3658v1</id>
    <updated>2012-07-16T12:50:30Z</updated>
    <published>2012-07-16T12:50:30Z</published>
    <title>Programing Using High Level Design With Python and FORTRAN: A Study Case
  in Astrophysics</title>
    <summary>  In this work, we present a short review about the high level design
methodology (HLDM), that is based on the use of very high level (VHL)
programing language as main, and the use of the intermediate level (IL)
language only for the critical processing time. The languages used are Python
(VHL) and FORTRAN (IL). Moreover, this methodology, making use of the oriented
object programing (OOP), permits to produce a readable, portable and reusable
code. Also is presented the concept of computational framework, that naturally
appears from the OOP paradigm. As an example, we present the framework called
PYGRAWC (Python framework for Gravitational Waves from Cosmological origin).
Even more, we show that the use of HLDM with Python and FORTRAN produces a
powerful tool for solving astrophysical problems.
</summary>
    <author>
      <name>Eduardo dos Santos Pereira</name>
    </author>
    <author>
      <name>Oswaldo D. Miranda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3658v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3658v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6821v1</id>
    <updated>2012-07-30T02:01:37Z</updated>
    <published>2012-07-30T02:01:37Z</published>
    <title>Proceedings 7th International Workshop on Developments of Computational
  Methods</title>
    <summary>  This volume contains the proceedings of the 7th International Workshop on
Developments in Computational Models (DCM 2011) which was held on Sunday July
3, 2011, in Zurich, Switzerland, as a satelite workshop of ICALP 2011.
  Recently several new models of computation have emerged, for instance for
bio-computing and quantum-computing, and in addition traditional models of
computation have been adapted to accommodate new demands or capabilities of
computer systems. The aim of DCM is to bring together researchers who are
currently developing new computational models or new features for traditional
computational models, in order to foster their interaction, to provide a forum
for presenting new ideas and work in progress, and to enable newcomers to learn
about current activities in this area.
</summary>
    <author>
      <name>Elham Kashefi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Edinburgh, UK</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Krivine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University Paris Diderot, France</arxiv:affiliation>
    </author>
    <author>
      <name>Femke van Raamsdonk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VU University Amsterdam, The Netherlands</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.88</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.88" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 88, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.6821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F3.1, F4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.7147v1</id>
    <updated>2012-07-31T02:06:26Z</updated>
    <published>2012-07-31T02:06:26Z</published>
    <title>A Calculus of Looping Sequences with Local Rules</title>
    <summary>  In this paper we present a variant of the Calculus of Looping Sequences (CLS
for short) with global and local rewrite rules. While global rules, as in CLS,
are applied anywhere in a given term, local rules can only be applied in the
compartment on which they are defined. Local rules are dynamic: they can be
added, moved and erased. We enrich the new calculus with a parallel semantics
where a reduction step is lead by any number of global and local rules that
could be performed in parallel. A type system is developed to enforce the
property that a compartment must contain only local rules with specific
features. As a running example we model some interactions happening in a cell
starting from its nucleus and moving towards its mitochondria.
</summary>
    <author>
      <name>Livio Bioglio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Mariangiola Dezani-Ciancaglini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Paola Giannini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <author>
      <name>Angelo Troina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Università di Torino</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.88.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.88.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings DCM 2011, arXiv:1207.6821</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 88, 2012, pp. 43-58</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.7147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.7147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.2; F.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.1934v1</id>
    <updated>2012-08-08T19:48:40Z</updated>
    <published>2012-08-08T19:48:40Z</published>
    <title>Technical report: CSVM dictionaries</title>
    <summary>  CSVM (CSV with Metadata) is a simple file format for tabular data. The
possible application domain is the same as typical spreadsheets files, but CSVM
is well suited for long term storage and the inter-conversion of RAW data. CSVM
embeds different levels for data, metadata and annotations in human readable
format and flat ASCII files. As a proof of concept, Perl and Python toolkits
were designed in order to handle CSVM data and objects in workflows. These
parsers can process CSVM files independently of data types, so it is possible
to use same data format and parser for a lot of scientific purposes. CSVM-1 is
the first version of CSVM specification, an extension of CSVM-1 for
implementing a translation system between CSVM files is presented in this
paper. The necessary data used to make the translation are also coded in
another CSVM file. This particular kind of CSVM is called a CSVM dictionary, it
is also readable by the current CSVM parser and it is fully supported by the
Python toolkit. This report presents a proposal for CSVM dictionaries, a
working example in chemistry, and some elements of Python toolkit usable to
handle these files.
</summary>
    <author>
      <name>Frédéric Rodriguez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPCMIB</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1208.1934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.1934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3122v1</id>
    <updated>2012-08-15T14:18:01Z</updated>
    <published>2012-08-15T14:18:01Z</published>
    <title>Defect Diagnosis in Rotors Systems by Vibrations Data Collectors Using
  Trending Software</title>
    <summary>  Vibration measurements have been used to reliably diagnose performance
problems in machinery and related mechanical products. A vibration data
collector can be used effectively to measure and analyze the machinery
vibration content in gearboxes, engines, turbines, fans, compressors, pumps and
bearings. Ideally, a machine will have little or no vibration, indicating that
the rotating components are appropriately balanced, aligned, and well
maintained. Quick analysis and assessment of the vibration content can lead to
fault diagnosis and prognosis of a machine's ability to continue running. The
aim of this research used vibration measurements to pinpoint mechanical defects
such as (unbalance, misalignment, resonance, and part loosening), consequently
diagnosis all necessary process for engineers and technicians who desire to
understand the vibration that exists in structures and machines.
  Keywords- vibration data collectors; analysis software; rotating components.
</summary>
    <author>
      <name>Hisham A. H. Al-Khazali</name>
    </author>
    <author>
      <name>Mohamad R. Askari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages,6 figures,1 pictuer,1 scheme</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJACSA 3 (2012) 33-43</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3681v1</id>
    <updated>2012-08-16T14:37:35Z</updated>
    <published>2012-08-16T14:37:35Z</published>
    <title>Calculations of Frequency Response Functions (FRF) Using Computer Smart
  Office Software and Nyquist Plot under Gyroscopic Effect Rotation</title>
    <summary>  Regenerated (FRF curves), synthesis of (FRF) curves there are two main
requirement in the form of response model, The first being that of regenerating
"Theoretical" curve for the frequency response function actually measured and
analysis and the second being that of synthesising the other functions which
were not measured,(FRF) that isolates the inherent dynamic properties of a
mechanical structure. Experimental modal parameters (frequency, damping, and
mode shape) are also obtained from a set of (FRF) measurements. The (FRF)
describes the input-output relationship between two points on a structure as a
function of frequency. Therefore, an (FRF) is actually defined between a single
input DOF (point &amp; direction), and a single output (DOF), although the FRF was
previously defined as a ratio of the Fourier transforms of an output and input
signal. In this paper we detection FRF curve using Nyquist plot under
gyroscopic effect in revolving structure using computer smart office software.
  Keywords - FRF curve; modal test; Nyquist plot; software engineering;
gyroscopic effect; smart office.
</summary>
    <author>
      <name>Hisham A. H. Al-Khazali</name>
    </author>
    <author>
      <name>Mohamad R. Askari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 11 figures, 1 picture</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IRACST - International Journal of Computer Science and Information
  Technology &amp; Security (IJCSITS), Vol. 1, No. 2 (2011) pp. 90-97</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3851v1</id>
    <updated>2012-08-19T16:01:19Z</updated>
    <published>2012-08-19T16:01:19Z</published>
    <title>A Model of the Cellular Iron Homeostasis Network Using Semi-Formal
  Methods for Parameter Space Exploration</title>
    <summary>  This paper presents a novel framework for the modeling of biological
networks. It makes use of recent tools analyzing the robust satisfaction of
properties of (hybrid) dynamical systems. The main challenge of this approach
as applied to biological systems is to get access to the relevant parameter
sets despite gaps in the available knowledge. An initial estimate of useful
parameters was sought by formalizing the known behavior of the biological
network in the STL logic using the tool Breach. Then, once a set of parameter
values consistent with known biological properties was found, we tried to
locally expand it into the largest possible valid region. We applied this
methodology in an effort to model and better understand the complex network
regulating iron homeostasis in mammalian cells. This system plays an important
role in many biological functions, including erythropoiesis, resistance against
infections, and proliferation of cancer cells.
</summary>
    <author>
      <name>Nicolas Mobilia</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UJF-Grenoble 1 / CNRS TIMC-IMAG UMR 5525</arxiv:affiliation>
    </author>
    <author>
      <name>Alexandre Donzé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of California Berkeley, EECS Department</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Marc Moulis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UJF-Grenoble 1 / CNRS UMR 4952, Institut de Recherches en Technologies et Sciences pour le Vivant</arxiv:affiliation>
    </author>
    <author>
      <name>Éric Fanchon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UJF-Grenoble 1 / CNRS TIMC-IMAG UMR 5525</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 42-57</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3853v1</id>
    <updated>2012-08-19T16:01:35Z</updated>
    <published>2012-08-19T16:01:35Z</published>
    <title>On Expressing and Monitoring Oscillatory Dynamics</title>
    <summary>  To express temporal properties of dense-time real-valued signals, the Signal
Temporal Logic (STL) has been defined by Maler et al. The work presented a
monitoring algorithm deciding the satisfiability of STL formulae on finite
discrete samples of continuous signals. The logic has been used to express and
analyse biological systems, but it is not expressive enough to sufficiently
distinguish oscillatory properties important in biology. In this paper we
define the extended logic STL* in which STL is augmented with a signal-value
freezing operator allowing us to express (and distinguish) detailed properties
of biological oscillations. The logic is supported by a monitoring algorithm
prototyped in Matlab. The monitoring procedure of STL* is evaluated on a
biologically-relevant case study.
</summary>
    <author>
      <name>Petr Dluhoš</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>Luboš Brim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <author>
      <name>David Šafránek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Masaryk University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 73-87</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3853v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3853v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3854v1</id>
    <updated>2012-08-19T16:01:54Z</updated>
    <published>2012-08-19T16:01:54Z</published>
    <title>Hybrid models of the cell cycle molecular machinery</title>
    <summary>  Piecewise smooth hybrid systems, involving continuous and discrete variables,
are suitable models for describing the multiscale regulatory machinery of the
biological cells. In hybrid models, the discrete variables can switch on and
off some molecular interactions, simulating cell progression through a series
of functioning modes. The advancement through the cell cycle is the archetype
of such an organized sequence of events. We present an approach, inspired from
tropical geometry ideas, allowing to reduce, hybridize and analyse cell cycle
models consisting of polynomial or rational ordinary differential equations.
</summary>
    <author>
      <name>Vincent Noel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rennes 1</arxiv:affiliation>
    </author>
    <author>
      <name>Dima Grigoriev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CNRS, University of Lille</arxiv:affiliation>
    </author>
    <author>
      <name>Sergei Vakulenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Russian Academy of Sciences, St. Petersburg</arxiv:affiliation>
    </author>
    <author>
      <name>Ovidiu Radulescu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Montpellier 2</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 88-105</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3856v1</id>
    <updated>2012-08-19T16:02:05Z</updated>
    <published>2012-08-19T16:02:05Z</published>
    <title>Statistical Model Checking for Stochastic Hybrid Systems</title>
    <summary>  This paper presents novel extensions and applications of the UPPAAL-SMC model
checker. The extensions allow for statistical model checking of stochastic
hybrid systems. We show how our race-based stochastic semantics extends to
networks of hybrid systems, and indicate the integration technique applied for
implementing this semantics in the UPPAAL-SMC simulation engine. We report on
two applications of the resulting tool-set coming from systems biology and
energy aware buildings.
</summary>
    <author>
      <name>Alexandre David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalborg University</arxiv:affiliation>
    </author>
    <author>
      <name>Dehui Du</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">East China Normal University</arxiv:affiliation>
    </author>
    <author>
      <name>Kim G. Larsen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalborg University</arxiv:affiliation>
    </author>
    <author>
      <name>Axel Legay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rennes</arxiv:affiliation>
    </author>
    <author>
      <name>Marius Mikučionis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalborg University</arxiv:affiliation>
    </author>
    <author>
      <name>Danny Bøgsted Poulsen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aalborg University</arxiv:affiliation>
    </author>
    <author>
      <name>Sean Sedwards</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rennes</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.92.9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.92.9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2012, arXiv:1208.3151</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 92, 2012, pp. 122-136</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.3856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5316v1</id>
    <updated>2012-08-27T07:56:06Z</updated>
    <published>2012-08-27T07:56:06Z</published>
    <title>How Non-linearity will Transform Information Systems</title>
    <summary>  One 'problem' with the 21st century world, particularly the economic and
business worlds, is the phenomenal and increasing number of interconnections
between economic agents (consumers, firms, banks, markets, national economies).
This implies that such agents are all interacting and consequently giving raise
to enormous degrees of non-linearity, a.k.a. complexity. Complexity often
brings with it unexpected phenomena, such as chaos and emerging behaviour, that
can become challenges for the survival of economic agents and systems.
Developing econophysics approaches are beginning to apply, to the 'economic
web', methods and models that have been used in physics and/or systems theory
to tackle non-linear domains. The paper gives an account of the research in
progress in this field and shows its implications for enteprise information
systems, anticipating the emergence of software that will allow to reflect the
complexity of the business world, as holistic risk management becomes a mandate
for financial institutions and business organizations.
</summary>
    <author>
      <name>Paolo Magrassi</name>
    </author>
    <link href="http://arxiv.org/abs/1208.5316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2641v1</id>
    <updated>2012-09-12T15:29:12Z</updated>
    <published>2012-09-12T15:29:12Z</published>
    <title>C-PASS-PC: A Cloud-driven Prototype of Multi-Center Proactive
  Surveillance System for Prostate Cancer</title>
    <summary>  Currently there are many clinical trials using paper case report forms as the
primary data collection tool. Cloud Computing platforms provide big potential
for increasing efficiency through a web-based data collection interface,
especially for large-scale multi-center trials. Traditionally, clinical and
biological data for multi-center trials are stored in one dedicated,
centralized database system running at a data coordinating center (DCC). This
paper presents C-PASS-PC, a cloud-driven prototype of multi-center proactive
surveillance system for prostate cancer. The prototype is developed in PHP,
JQuery and CSS with an Oracle backend in a local Web server and database server
and deployed on Google App Engine (GAE) and Google Cloud SQL-MySQL. The
deploying process is fast and easy to follow. The C-PASS-PC prototype can be
accessed through an SSL-enabled web browser. Our approach proves the concept
that cloud computing platforms such as GAE is a suitable and flexible solution
in the near future for multi-center clinical trials.
</summary>
    <author>
      <name>Haibin Wang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIT 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.2641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2660v1</id>
    <updated>2012-09-12T16:47:23Z</updated>
    <published>2012-09-12T16:47:23Z</published>
    <title>Review of strategies for a comprehensive simulation in sputtering
  devices</title>
    <summary>  The development of sputtering facilities, at the moment, is mainly pursued
through experimental tests, or simply by expertise in the field, and relies
much less on numerical simulation of the process environment. This leads to
great efforts and empirically, roughly optimized solutions: in fact, the
simulation of these devices, at the state of art, is quite good in predicting
the behavior of single steps of the overall deposition process, but it seems
still ahead a full integration among the tools simulating the various phenomena
involved in a sputter. We summarize here the techniques and codes already
available for problems of interest in sputtering facilities, and we try to
outline the possible features of a comprehensive simulation framework. This
framework should be able to integrate the single paradigms, dealing with
aspects going from the plasma environment up to the distribution and properties
of the deposited film, not only on the surface of the substrate, but also on
the walls of the process chamber.
</summary>
    <author>
      <name>Antonio A. Gentile</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.2660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.plasm-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3916v1</id>
    <updated>2012-09-18T11:57:44Z</updated>
    <published>2012-09-18T11:57:44Z</published>
    <title>Qualitative Modelling via Constraint Programming: Past, Present and
  Future</title>
    <summary>  Qualitative modelling is a technique integrating the fields of theoretical
computer science, artificial intelligence and the physical and biological
sciences. The aim is to be able to model the behaviour of systems without
estimating parameter values and fixing the exact quantitative dynamics.
Traditional applications are the study of the dynamics of physical and
biological systems at a higher level of abstraction than that obtained by
estimation of numerical parameter values for a fixed quantitative model.
Qualitative modelling has been studied and implemented to varying degrees of
sophistication in Petri nets, process calculi and constraint programming. In
this paper we reflect on the strengths and weaknesses of existing frameworks,
we demonstrate how recent advances in constraint programming can be leveraged
to produce high quality qualitative models, and we describe the advances in
theory and technology that would be needed to make constraint programming the
best option for scientific investigation in the broadest sense.
</summary>
    <author>
      <name>Thomas W. Kelsey</name>
    </author>
    <author>
      <name>Lars Kotthoff</name>
    </author>
    <author>
      <name>Christoffer A. Jefferson</name>
    </author>
    <author>
      <name>Stephen A. Linton</name>
    </author>
    <author>
      <name>Ian Miguel</name>
    </author>
    <author>
      <name>Peter Nightingale</name>
    </author>
    <author>
      <name>Ian P. Gent</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages plus references</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5905v2</id>
    <updated>2012-11-11T14:40:27Z</updated>
    <published>2012-09-26T11:47:33Z</published>
    <title>An Efficient Biological Sequence Compression Technique Using LUT And
  Repeat In The Sequence</title>
    <summary>  Data compression plays an important role to deal with high volumes of DNA
sequences in the field of Bioinformatics. Again data compression techniques
directly affect the alignment of DNA sequences. So the time needed to
decompress a compressed sequence has to be given equal priorities as with
compression ratio. This article contains first introduction then a brief review
of different biological sequence compression after that my proposed work then
our two improved Biological sequence compression algorithms after that result
followed by conclusion and discussion, future scope and finally references.
These algorithms gain a very good compression factor with higher saving
percentage and less time for compression and decompression than the previous
Biological Sequence compression algorithms. Keywords: Hash map table, Tandem
repeats, compression factor, compression time, saving percentage, compression,
decompression process.
</summary>
    <author>
      <name>Subhankar Roy</name>
    </author>
    <author>
      <name>Sunirmal Khatua</name>
    </author>
    <author>
      <name>Sudipta Roy</name>
    </author>
    <author>
      <name>Samir K. Bandyopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.5905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0957v1</id>
    <updated>2012-10-22T15:30:04Z</updated>
    <published>2012-10-22T15:30:04Z</published>
    <title>Adaptive Bee Colony in an Artificial Bee Colony for Solving Engineering
  Design Problems</title>
    <summary>  A wide range of engineering design problems have been solved by the
algorithms that simulates collective intelligence in swarms of birds or
insects. The Artificial Bee Colony or ABC is one of the recent additions to the
class of swarm intelligence based algorithms that mimics the foraging behavior
of honey bees. ABC consists of three groups of bees namely employed, onlooker
and scout bees. In ABC, the food locations represent the potential candidate
solution. In the present study an attempt is made to generate the population of
food sources (Colony Size) adaptively and the variant is named as A-ABC. A-ABC
is further enhanced to improve convergence speed and exploitation capability,
by employing the concept of elitism, which guides the bees towards the best
food source. This enhanced variant is called E-ABC. The proposed algorithms are
validated on a set of standard benchmark problems with varying dimensions taken
from literature and on five engineering design problems. The numerical results
are compared with the basic ABC and three recent variant of ABC. Numerically
and statistically simulated results illustrate that the proposed method is very
efficient and competitive.
</summary>
    <author>
      <name>Tarun Kumar Sharma</name>
    </author>
    <author>
      <name>Millie Pant</name>
    </author>
    <author>
      <name>V. P. Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Mechanical Engineering and its Applications (AMEA), 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1526v2</id>
    <updated>2012-11-08T13:54:13Z</updated>
    <published>2012-11-07T12:47:57Z</published>
    <title>Explosion prediction of oil gas using SVM and Logistic Regression</title>
    <summary>  The prevention of dangerous chemical accidents is a primary problem of
industrial manufacturing. In the accidents of dangerous chemicals, the oil gas
explosion plays an important role. The essential task of the explosion
prevention is to estimate the better explosion limit of a given oil gas. In
this paper, Support Vector Machines (SVM) and Logistic Regression (LR) are used
to predict the explosion of oil gas. LR can get the explicit probability
formula of explosion, and the explosive range of the concentrations of oil gas
according to the concentration of oxygen. Meanwhile, SVM gives higher accuracy
of prediction. Furthermore, considering the practical requirements, the effects
of penalty parameter on the distribution of two types of errors are discussed.
</summary>
    <author>
      <name>Xiaofei Wang</name>
    </author>
    <author>
      <name>Mingming Zhang</name>
    </author>
    <author>
      <name>Liyong Shen</name>
    </author>
    <author>
      <name>Suixiang Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14pages,7 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.1526v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1526v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P30, 68T05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2194v1</id>
    <updated>2012-11-09T17:41:16Z</updated>
    <published>2012-11-09T17:41:16Z</published>
    <title>A Novel Anticlustering Filtering Algorithm for the Prediction of Genes
  as a Drug Target</title>
    <summary>  The high-throughput data generated by microarray experiments provides
complete set of genes being expressed in a given cell or in an organism under
particular conditions. The analysis of these enormous data has opened a new
dimension for the researchers. In this paper we describe a novel algorithm to
microarray data analysis focusing on the identification of genes that are
differentially expressed in particular internal or external conditions and
which could be potential drug targets. The algorithm uses the time-series gene
expression data as an input and recognizes genes which are expressed
differentially. This algorithm implements standard statistics-based gene
functional investigations, such as the log transformation, mean, log-sigmoid
function, coefficient of variations, etc. It does not use clustering analysis.
The proposed algorithm has been implemented in Perl. The time-series gene
expression data on yeast Saccharomyces cerevisiae from the Stanford Microarray
Database (SMD)consisting of 6154 genes have been taken for the validation of
the algorithm. The developed method extracted 48 genes out of total 6154 genes.
These genes are mostly responsible for the yeast's resistants at a high
temperature.
</summary>
    <author>
      <name>Khalid Raza</name>
    </author>
    <author>
      <name>Akhilesh Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5923/j.ajbe.20120205.03</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5923/j.ajbe.20120205.03" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures and 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">American Journal of Biomedical Engineering 2012, 2(5):206-211</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.2194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2743v1</id>
    <updated>2012-11-12T19:19:04Z</updated>
    <published>2012-11-12T19:19:04Z</published>
    <title>Systematic and Integrative Analysis of Proteomic Data using
  Bioinformatics Tools</title>
    <summary>  The analysis and interpretation of relationships between biological molecules
is done with the help of networks. Networks are used ubiquitously throughout
biology to represent the relationships between genes and gene products. Network
models have facilitated a shift from the study of evolutionary conservation
between individual gene and gene products towards the study of conservation at
the level of pathways and complexes. Recent work has revealed much about
chemical reactions inside hundreds of organisms as well as universal
characteristics of metabolic networks, which shed light on the evolution of the
networks. However, characteristics of individual metabolites have been
neglected in this network. The current paper provides an overview of
bioinformatics software used in visualization of biological networks using
proteomic data, their main functions and limitations of the software.
</summary>
    <author>
      <name>Rashmi Rameshwari</name>
    </author>
    <author>
      <name>T. V. Prasad</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Computer Science and
  Applications, 2(5), 2011, 29-35</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.2743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4094v1</id>
    <updated>2012-11-17T09:15:07Z</updated>
    <published>2012-11-17T09:15:07Z</published>
    <title>Implementing the Stochastics Brane Calculus in a Generic Stochastic
  Abstract Machine</title>
    <summary>  In this paper, we deal with the problem of implementing an abstract machine
for a stochastic version of the Brane Calculus. Instead of defining an ad hoc
abstract machine, we consider the generic stochastic abstract machine
introduced by Lakin, Paulev\'e and Phillips. The nested structure of membranes
is flattened into a set of species where the hierarchical structure is
represented by means of names. In order to reduce the overhead introduced by
this encoding, we modify the machine by adding a copy-on-write optimization
strategy. We prove that this implementation is adequate with respect to the
stochastic structural operational semantics recently given for the Brane
Calculus. These techniques can be ported also to other stochastic calculi
dealing with nested structures.
</summary>
    <author>
      <name>Marino Miculan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics and Computer Science, University of Udine, Italy</arxiv:affiliation>
    </author>
    <author>
      <name>Ilaria Sambarino</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics and Computer Science, University of Udine, Italy</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.100.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.100.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MeCBIC 2012, arXiv:1211.3476</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 100, 2012, pp. 82-100</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.2; F.4.2; G.3; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4218v2</id>
    <updated>2012-11-21T12:40:27Z</updated>
    <published>2012-11-18T13:05:54Z</published>
    <title>Modeling Earthen Dike Stability: Sensitivity Analysis and Automatic
  Calibration of Diffusivities Based on Live Sensor Data</title>
    <summary>  The paper describes concept and implementation details of integrating a
finite element module for dike stability analysis Virtual Dike into an early
warning system for flood protection. The module operates in real-time mode and
includes fluid and structural sub-models for simulation of porous flow through
the dike and for dike stability analysis. Real-time measurements obtained from
pore pressure sensors are fed into the simulation module, to be compared with
simulated pore pressure dynamics. Implementation of the module has been
performed for a real-world test case - an earthen levee protecting a sea-port
in Groningen, the Netherlands. Sensitivity analysis and calibration of
diffusivities have been performed for tidal fluctuations. An algorithm for
automatic diffusivities calibration for a heterogeneous dike is proposed and
studied. Analytical solutions describing tidal propagation in one-dimensional
saturated aquifer are employed in the algorithm to generate initial estimates
of diffusivities.
</summary>
    <author>
      <name>N. B. Melnikova</name>
    </author>
    <author>
      <name>V. V. Krzhizhanovskaya</name>
    </author>
    <author>
      <name>P. M. A. Sloot</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jhydrol.2013.05.031</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jhydrol.2013.05.031" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Hydrology 496 (2013), pp. 154-165</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4218v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4218v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4464v1</id>
    <updated>2012-11-19T15:32:55Z</updated>
    <published>2012-11-19T15:32:55Z</published>
    <title>Free-surface flow simulations for discharge-based operation of hydraulic
  structure gates</title>
    <summary>  We combine non-hydrostatic flow simulations of the free surface with a
discharge model based on elementary gate flow equations for decision support in
operation of hydraulic structure gates. A water level-based gate control used
in most of today's general practice does not take into account the fact that
gate operation scenarios producing similar total discharged volumes and similar
water levels may have different local flow characteristics. Accurate and timely
prediction of local flow conditions around hydraulic gates is important for
several aspects of structure management: ecology, scour, flow-induced gate
vibrations and waterway navigation. The modelling approach is described and
tested for a multi-gate sluice structure regulating discharge from a river to
the sea. The number of opened gates is varied and the discharge is stabilized
with automated control by varying gate openings. The free-surface model was
validated for discharge showing a correlation coefficient of 0.994 compared to
experimental data. Additionally, we show the analysis of CFD results for
evaluating bed stability and gate vibrations.
</summary>
    <author>
      <name>C. D. Erdbrink</name>
    </author>
    <author>
      <name>V. V. Krzhizhanovskaya</name>
    </author>
    <author>
      <name>P. M. A. Sloot</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2166/hydro.2013.215</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2166/hydro.2013.215" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Hydroinformatics, V. 16, N 1, pp. 189-206, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="76D05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4654v1</id>
    <updated>2012-11-20T02:59:28Z</updated>
    <published>2012-11-20T02:59:28Z</published>
    <title>Application of Data mining in Protein sequence Classification</title>
    <summary>  Protein sequence classification involves feature selection for accurate
classification. Popular protein sequence classification techniques involve
extraction of specific features from the sequences. Researchers apply some
well-known classification techniques like neural networks, Genetic algorithm,
Fuzzy ARTMAP,Rough Set Classifier etc for accurate classification. This paper
presents a review is with three different classification models such as neural
network model, fuzzy ARTMAP model and Rough set classifier model. This is
followed by a new technique for classifying protein sequences. The proposed
model is typically implemented with an own designed tool and tries to reduce
the computational overheads encountered by earlier approaches and increase the
accuracy of classification
</summary>
    <author>
      <name>Suprativ Saha</name>
    </author>
    <author>
      <name>Rituparna Chaki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdms.2012.4508</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdms.2012.4508" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 Pages, 7 Figures, 3 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Database Management Systems ( IJDMS )
  Vol.4, No.5, October 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5890v1</id>
    <updated>2012-11-26T09:09:21Z</updated>
    <published>2012-11-26T09:09:21Z</published>
    <title>Adaptive Control of Enterprise</title>
    <summary>  Modern progress in artificial intelligence permits to realize algorithms of
adaptation for critical events (in addition to ERP). A production emergence, an
appearance of new competitive goods, a major change in financial state of
partners, a radical change in exchange rate, a change in custom and tax
legislation, a political and energy crisis, an ecocatastrophe can lead up to a
decrease of profit or bankruptcy of enterprise. Therefore it is necessary to
assess a probability of threat and to take preventive actions. If a critical
event took place, one must estimate restoration expenses and possible
consequences as well as to prepare appropriate propositions. This is provided
using modern methods of diagnostics, prediction, and decision making as well as
an inference engine and semantic analysis. Mathematical methods in use are
called in algorithms of adaptation automatically. Because the enterprise is a
complex system, to overcome complexity of control it is necessary to apply
semantic representations. Such representations are formed from descriptions of
events, facts, persons, organizations, goods, operations, scripts on a natural
language. Semantic representations permit as well to formulate actual problems
and to find ways to resolve these problems.
</summary>
    <author>
      <name>Yuriy Ostapov</name>
    </author>
    <link href="http://arxiv.org/abs/1211.5890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1037v1</id>
    <updated>2012-12-05T14:28:40Z</updated>
    <published>2012-12-05T14:28:40Z</published>
    <title>Modeling Movements in Oil, Gold, Forex and Market Indices using Search
  Volume Index and Twitter Sentiments</title>
    <summary>  Study of the forecasting models using large scale microblog discussions and
the search behavior data can provide a good insight for better understanding
the market movements. In this work we collected a dataset of 2 million tweets
and search volume index (SVI from Google) for a period of June 2010 to
September 2011. We perform a study over a set of comprehensive causative
relationships and developed a unified approach to a model for various market
securities like equity (Dow Jones Industrial Average-DJIA and NASDAQ-100),
commodity markets (oil and gold) and Euro Forex rates. We also investigate the
lagged and statistically causative relations of Twitter sentiments developed
during active trading days and market inactive days in combination with the
search behavior of public before any change in the prices/ indices. Our results
show extent of lagged significance with high correlation value upto 0.82
between search volumes and gold price in USD. We find weekly accuracy in
direction (up and down prediction) uptil 94.3% for DJIA and 90% for NASDAQ-100
with significant reduction in mean average percentage error for all the
forecasting models.
</summary>
    <author>
      <name>Tushar Rao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NSIT-Delhi</arxiv:affiliation>
    </author>
    <author>
      <name>Saket Srivastava</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IIIT-Delhi</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, 9 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.1037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1360v1</id>
    <updated>2012-12-06T16:03:10Z</updated>
    <published>2012-12-06T16:03:10Z</published>
    <title>Physics inspired algorithms for (co)homology computation</title>
    <summary>  The issue of computing (co)homology generators of a cell complex is gaining a
pivotal role in various branches of science. While this issue can be rigorously
solved in polynomial time, it is still overly demanding for large scale
problems. Drawing inspiration from low-frequency electrodynamics, this paper
presents a physics inspired algorithm for first cohomology group computations
on three-dimensional complexes. The algorithm is general and exhibits orders of
magnitude speed up with respect to competing ones, allowing to handle problems
not addressable before. In particular, when generators are employed in the
physical modeling of magneto-quasistatic problems, this algorithm solves one of
the most long-lasting problems in low-frequency computational electromagnetics.
In this case, the effectiveness of the algorithm and its ease of implementation
may be even improved by introducing the novel concept of \textit{lazy
cohomology generators}.
</summary>
    <author>
      <name>Paweł Dłotko</name>
    </author>
    <author>
      <name>Ruben Specogna</name>
    </author>
    <link href="http://arxiv.org/abs/1212.1360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3032v2</id>
    <updated>2013-03-21T09:12:11Z</updated>
    <published>2012-12-13T01:39:08Z</published>
    <title>Efficiency improvement of the frequency-domain BEM for rapid transient
  elastodynamic analysis</title>
    <summary>  The frequency-domain fast boundary element method (BEM) combined with the
exponential window technique leads to an efficient yet simple method for
elastodynamic analysis. In this paper, the efficiency of this method is further
enhanced by three strategies. Firstly, we propose to use exponential window
with large damping parameter to improve the conditioning of the BEM matrices.
Secondly, the frequency domain windowing technique is introduced to alleviate
the severe Gibbs oscillations in time-domain responses caused by large damping
parameters. Thirdly, a solution extrapolation scheme is applied to obtain
better initial guesses for solving the sequential linear systems in the
frequency domain. Numerical results of three typical examples with the problem
size up to 0.7 million unknowns clearly show that the first and third
strategies can significantly reduce the computational time. The second strategy
can effectively eliminate the Gibbs oscillations and result in accurate
time-domain responses.
</summary>
    <author>
      <name>Jinyou Xiao</name>
    </author>
    <author>
      <name>Wenjing Ye</name>
    </author>
    <author>
      <name>Lihua Wen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-013-0852-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-013-0852-9" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Mechanics, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3032v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3032v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3924v1</id>
    <updated>2012-12-17T08:20:43Z</updated>
    <published>2012-12-17T08:20:43Z</published>
    <title>Building ventilation: A pressure airflow model computer generation and
  elements of validation</title>
    <summary>  The calculation of airflows is of great importance for detailed building
thermal simulation computer codes, these airflows most frequently constituting
an important thermal coupling between the building and the outside on one hand,
and the different thermal zones on the other. The driving effects of air
movement, which are the wind and the thermal buoyancy, are briefly outlined and
we look closely at their coupling in the case of buildings, by exploring the
difficulties associated with large openings. Some numerical problems tied to
the resolving of the non-linear system established are also covered. Part of a
detailled simulation software (CODYRUN), the numerical implementation of this
airflow model is explained, insisting on data organization and processing
allowing the calculation of the airflows. Comparisons are then made between the
model results and in one hand analytical expressions and in another and
experimental measurements in case of a collective dwelling.
</summary>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>A. P. Lauret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>L. Adelard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>T. A. Mara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Energy and Buildings 29, 3 (1999) 283-292</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3925v1</id>
    <updated>2012-12-17T08:21:02Z</updated>
    <published>2012-12-17T08:21:02Z</published>
    <title>Elaboration of global quality standards for natural and low energy
  cooling in French tropical island buildings</title>
    <summary>  Electric load profiles of tropical islands in developed countries are
characterised by morning, midday and evening peaks arising from all year round
high power demand in the commercial and residential sectors, due mostly to air
conditioning appliances and bad thermal conception of the building. The work
presented in this paper has led to the conception of a global quality standards
obtained through optimized bioclimatic urban planning and architectural design,
the use of passive cooling architectural components, natural ventilation and
energy efficient systems such as solar water heaters. We evaluated, with the
aid of an airflow and thermal building simulation software (CODYRUN), the
impact of each technical solution on thermal comfort within the building. These
technical solutions have been implemented in 280 new pilot dwelling projects
through the year 1996.
</summary>
    <author>
      <name>F. Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>J. C. Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">cited By (since 1996) 13</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Building and Environment 34, 1 (1999) 71-83</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3928v1</id>
    <updated>2012-12-17T08:22:49Z</updated>
    <published>2012-12-17T08:22:49Z</published>
    <title>A validation methodology aid for improving a thermal building model:
  Case of diffuse radiation accounting in a tropical climate</title>
    <summary>  As part of our efforts to complete the software CODYRUN validation, we chose
as test building a block of flats constructed in Reunion Island, which has a
humid tropical climate. The sensitivity analysis allowed us to study the
effects of both diffuse and direct solar radiation on our model of this
building. With regard to the choice and location of sensors, this stage of the
study also led us to measure the solar radiation falling on the windows. The
comparison of measured and predicted radiation clearly showed that our
predictions over-estimated the incoming solar radiation, and we were able to
trace the problem to the algorithm which calculates diffuse solar radiation. By
calculating view factors between the windows and the associated shading
devices, changes to the original program allowed us to improve the predictions,
and so this article shows the importance of sensitivity analysis in this area
of research.
</summary>
    <author>
      <name>A. J. P. Lauret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>T. A. Mara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>L. Adelard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>F. Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Energy and Buildings 33, 7 (2001) 711-718</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3930v1</id>
    <updated>2012-12-17T08:23:27Z</updated>
    <published>2012-12-17T08:23:27Z</published>
    <title>Detailed weather data generator for building simulations</title>
    <summary>  Thermal buildings simulation softwares need meteorological files in thermal
comfort, energetic evaluation studies. Few tools can make significant
meteorological data available such as generated typical year, representative
days, or artificial meteorological database. This paper deals about the
presentation of a new software, RUNEOLE, used to provide weather data in
buildings applications with a method adapted to all kind of climates. RUNEOLE
associates three modules of description, modelling and generation of weather
data. The statistical description of an existing meteorological database makes
typical representative days available and leads to the creation of model
libraries. The generation module leads to the generation of non existing
sequences. This software tends to be usable for the searchers and designers, by
means of interactivity, facilitated use and easy communication. The conceptual
basis of this tool will be exposed and we'll propose two examples of
applications in building physics for tropical humid climates.
</summary>
    <author>
      <name>L. Adelard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>F. Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>J. -C. Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Energy and Buildings 31, 1 (2000) 75-88</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5095v1</id>
    <updated>2012-12-20T15:47:50Z</updated>
    <published>2012-12-20T15:47:50Z</published>
    <title>Modelling of Optimal Design of Manufacturing Cell Layout Considering
  Material Flow and Closeness Rating Factors</title>
    <summary>  Developing a group of machine cells and their corresponding part families to
minimize the inter-cell and intra-cell material flow is the basic objective of
the designing of a cellular manufacturing system (CMS). Afterwards achieving a
competent cell layout is essential in order to minimize the total inter-cell
part travels, which is principally noteworthy. There are plentiful articles of
CMS literature which considered cell formation problems; however cell layout
topic has rarely been addressed. Therefore this research is intended to focus
on an adapted mathematical model of the layout design problem considering
material handling cost and closeness ratings of manufacturing cells. Owing to
the combinatorial class of the said problem, an efficient NP-hard technique
based on Simulated Annealing metaheuristic is proposed henceforth. Some test
problems are solved using the proposed technique. Computational results show
that the proposed metaheuristic approach is extremely effective and efficient
in terms of solution quality and computational complexity.
</summary>
    <author>
      <name>T. Ghosh</name>
    </author>
    <author>
      <name>P. K. Dan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 4th International &amp; 25th AIMTDR Conference, December
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5255v1</id>
    <updated>2012-12-18T07:39:56Z</updated>
    <published>2012-12-18T07:39:56Z</published>
    <title>A Comparison between CODYRUN and TRNSYS, simulation models for thermal
  buildings behaviour</title>
    <summary>  Simulation codes of thermal behaviour could significantly improve housing
construction design. Among the existing software, CODYRUN and TRNSYS are
calculations codes of different conceptions. CODYRUN is exclusively dedicated
to housing thermal behaviour, whereas TRNSYS is more generally used on any
thermal system. The purpose of this article is to compare these two instruments
in two different conditions . We will first modelize a mono-zone test cell, and
analyse the results by means of signal treatment methods. Then, we will
modelize a real case of multi-zone housing, representative of housing in wet
tropical climates. We could so evaluate influences of meteorological and
building description data on model errors.
</summary>
    <author>
      <name>Franck Lucas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Alex Mara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>François Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Word Renewable Energy Congress, Florence : Italy (1998)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5255v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5255v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5256v1</id>
    <updated>2012-12-18T12:37:04Z</updated>
    <published>2012-12-18T12:37:04Z</published>
    <title>Thermal Building Simulation and Computer Generation of Nodal Models</title>
    <summary>  The designer's preoccupation to reduce the energy needs and get a better
thermal quality of ambiances helped in the development of several packages
simulating the dynamic behaviour of buildings. This paper shows the adaptation
of a method of thermal analysis, the nodal analysis, linked to the case of
building's thermal behaviour. We take successively an interest in the case of
conduction into a wall, in the coupling with superficial exchanges and finally
in the constitution of thermal state models of the building. Big variations
existing from one building to another, it's necessary to build the thermal
model from the building description. This article shows the chosen method in
the case of our thermal simulation program for buildings, CODYRUN
</summary>
    <author>
      <name>H. Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>J. P. Chabriat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LE2P</arxiv:affiliation>
    </author>
    <author>
      <name>B. Grondin-Perez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LE2P</arxiv:affiliation>
    </author>
    <author>
      <name>C. Tourrand</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CETHIL</arxiv:affiliation>
    </author>
    <author>
      <name>J. Brau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CETHIL</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Building and Environment 31, 3 (1996) 207-214</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5262v1</id>
    <updated>2012-12-20T13:25:56Z</updated>
    <published>2012-12-20T13:25:56Z</published>
    <title>A multimodel approach to building thermal simulation for design and
  research purposes</title>
    <summary>  The designers pre-occupation to reduce energy consumption and to achieve
better thermal ambience levels, has favoured the setting up of numerous
building thermal dynamic simulation programs. The progress in the modelling of
phenomenas and its transfer into the professional field has resulted in various
numerical approaches ranging from softwares dedicated to architects for design
use to tools for laboratory use by the expert thermal researcher. This analysis
shows that each approach tends to fulfil the specific needs of a certain kind
of manipulator only, in the building conception process. Our objective is
notably different as it is a tool which can be used from the very initial stage
of a construction project, to the energy audit for the existing building. In
each of these cases, the objective results, the precision advocated and the
time delay of the results are different parameters which call for a multiple
model approach of the building system
</summary>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>François Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Claude Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Brau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CETHIL</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">cited By (since 1996) 20</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Energy and Buildings 28, 1 (1998) 71-78</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5263v1</id>
    <updated>2012-12-20T13:28:22Z</updated>
    <published>2012-12-20T13:28:22Z</published>
    <title>Use of BESTEST procedure to improve a building thermal simulation
  program</title>
    <summary>  Validation of building energy simulation programs is of major interest to
both users and modellers. To achieve such a task, it is essential to apply a
methodology based on a priori test and empirical validation. A priori test
consists in verifying that models embedded in a program and their
implementation are correct. this should be achieved before carrying out
experiments. The aim of this report is to present results from the application
of the BESTEST procedure to our code. We will emphasise the way it allows to
find bugs in our program and also how it permits to qualify models of heat
transfer by conduction
</summary>
    <author>
      <name>Ted Soubdhan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRER</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Alex Mara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Anis Younès</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMFS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">World Renewable Energy Congress VI Renewables: The Energy for the
  21st Century World Renewable Energy Congress VI 1-7 July 2000 Brighton, UK,
  Elsevier (Ed.) (2000) 1800-1803</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5264v1</id>
    <updated>2012-12-20T14:53:44Z</updated>
    <published>2012-12-20T14:53:44Z</published>
    <title>Statistical Traffic State Analysis in Large-scale Transportation
  Networks Using Locality-Preserving Non-negative Matrix Factorization</title>
    <summary>  Statistical traffic data analysis is a hot topic in traffic management and
control. In this field, current research progresses focus on analyzing traffic
flows of individual links or local regions in a transportation network. Less
attention are paid to the global view of traffic states over the entire
network, which is important for modeling large-scale traffic scenes. Our aim is
precisely to propose a new methodology for extracting spatio-temporal traffic
patterns, ultimately for modeling large-scale traffic dynamics, and long-term
traffic forecasting. We attack this issue by utilizing Locality-Preserving
Non-negative Matrix Factorization (LPNMF) to derive low-dimensional
representation of network-level traffic states. Clustering is performed on the
compact LPNMF projections to unveil typical spatial patterns and temporal
dynamics of network-level traffic states. We have tested the proposed method on
simulated traffic data generated for a large-scale road network, and reported
experimental results validate the ability of our approach for extracting
meaningful large-scale space-time traffic patterns. Furthermore, the derived
clustering results provide an intuitive understanding of spatial-temporal
characteristics of traffic flows in the large-scale network, and a basis for
potential long-term forecasting.
</summary>
    <author>
      <name>Yufei Han</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Fabien Moutarde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CAOR</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IET Intelligent Transport Systems (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5592v1</id>
    <updated>2012-12-21T13:50:14Z</updated>
    <published>2012-12-21T13:50:14Z</published>
    <title>Multiple model software for airflow and thermal building simulation. A
  case study under tropical humid climate, in Réunion Island</title>
    <summary>  The first purpose of our work has been to allow -as far as heat transfer
modes, airflow calculation and meteorological data reconstitution are
concerned- the integration of diverse interchangeable physical models in a
single software tool for professional use, CODYRUN. The designer's objectives,
precision requested and calculation time consideration, lead us to design a
structure accepting selective use of models, taking into account multizone
description and airflow patterns. With a building case study in Reunion Island,
we first analyse the sensibility of the thermal model to diffuse radiation
reconstitution on tilted surfaces. Then, a realistic balance between precision
required and calculation time leads us to select detailed models for the zone
of main interest, but to choose simplified models for the other zones.
</summary>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Claude Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Brau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CETHIL</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Building Simulation Conference 1993, Adela\"ide : Australia (1993)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5599v1</id>
    <updated>2012-12-21T18:55:04Z</updated>
    <published>2012-12-21T18:55:04Z</published>
    <title>Elaboration of a new tool for weather data sequences generation</title>
    <summary>  This paper deals about the presentation of a new software RUNEOLE used to
provide weather data in buildings physics. RUNEOLE associates three modules
leading to the description, the modelling and the generation of weather data.
The first module is dedicated to the description of each climatic variable
included in the database. Graphic representation is possible (with histograms
for example). Mathematical tools used to compare statistical distributions,
determine daily characteristic evolutions, find typical days, and the
correlations between the different climatic variables have been elaborated in
the second module. Artificial weather datafiles adapted to different simulation
codes are available at the issue of the third module. This tool can then be
used in HVAC system evaluation, or in the study of thermal comfort. The studied
buildings can then be tested under different thermal, aeraulic, and radiative
solicitations, leading to a best understanding of their behaviour for example
in humid climates.
</summary>
    <author>
      <name>Laetitia Adelard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Alex Mara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Claude Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Available from http://www.ibpsa.org/m_bs1999.asp; IBPSA'99,
  International Building Performance Association, Tokyo : Japan (1999)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5664v1</id>
    <updated>2012-12-22T07:40:43Z</updated>
    <published>2012-12-22T07:40:43Z</published>
    <title>Weather sequences for predicting HVAC system behaviour in residential
  units located in tropical climates</title>
    <summary>  The purpose of our research deals with the description of a methodology for
the definition of specific weather sequences and their influence on the energy
needs of HVAC system. We'll apply the method on the tropical Reunion Island.
The methodological approach based on a detailed analysis of weather sequences
leads to a classification of climatic situations that can be applied to the
site. These sequences have been used to simulate buildings and air handling
systems thanks to a thermal simulation code, CODYRUN. Results bring to the
light how necessary it is to have coherent meteorological data for this kind of
simulation.
</summary>
    <author>
      <name>Laetitia Adelard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>François Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Florence Pignolet-Tardan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Claude Gatina</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Available from http://www.ibpsa.org/m_bs1997.asp. arXiv admin note:
  text overlap with arXiv:1212.3930</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IBPSA Building Simulation 97, Prague : Czech Republic (1997)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0363v1</id>
    <updated>2013-01-03T02:01:10Z</updated>
    <published>2013-01-03T02:01:10Z</published>
    <title>Employing functional interactions for characterization and detection of
  sparse complexes from yeast PPI networks</title>
    <summary>  Over the last few years, several computational techniques have been devised
to recover protein complexes from the protein interaction (PPI) networks of
organisms. These techniques model "dense" subnetworks within PPI networks as
complexes. However, our comprehensive evaluations revealed that these
techniques fail to reconstruct many 'gold standard' complexes that are "sparse"
in the networks (only 71 recovered out of 123 known yeast complexes embedded in
a network of 9704 interactions among 1622 proteins). In this work, we propose a
novel index called Component-Edge (CE) score to quantitatively measure the
notion of "complex derivability" from PPI networks. Using this index, we
theoretically categorize complexes as "sparse" or "dense" with respect to a
given network. We then devise an algorithm SPARC that selectively employs
functional interactions to improve the CE scores of predicted complexes, and
thereby elevates many of the "sparse" complexes to "dense". This empowers
existing methods to detect these "sparse" complexes. We demonstrate that our
approach is effective in reconstructing significantly many complexes missed
previously (104 recovered out of the 123 known complexes or ~47% improvement).
</summary>
    <author>
      <name>Sriganesh Srihari</name>
    </author>
    <author>
      <name>Hon Wai Leong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1504/IJBRA.2012.048962</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1504/IJBRA.2012.048962" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 Tables, 1 Figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int J Bioinform Res Appl. 2012, 8(3-4):286-304</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.0363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92-08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1409v3</id>
    <updated>2013-07-23T18:32:10Z</updated>
    <published>2013-01-08T04:40:27Z</published>
    <title>A Dual Number Approach for Numerical Calculation of Velocity and
  Acceleration in the Spherical 4R Mechanism</title>
    <summary>  This paper proposes a methodology to calculate both the first and second
derivatives of a vector function of one variable in a single computation step.
The method is based on the nested application of the dual number approach for
first order derivatives.
  It has been implemented in Fortran language, a module which contains the dual
version of elementary functions as well as more complex functions, which are
common in the field of rotational kinematics. Since we have three quantities of
interest, namely the function itself and its first and second derivative, our
basic numerical entity has three elements. Then, for a given vector function
$f:\mathbb{R}\to \mathbb{R}^m$, its dual version will have the form
$\tilde{f}:\mathbb{R}^3\to \mathbb{R}^{3m}$.
  As a study case, the proposed methodology is used to calculate the velocity
and acceleration of a point moving on the coupler-point curve generated by a
spherical four-bar mechanism.
</summary>
    <author>
      <name>F. Penunuri</name>
    </author>
    <author>
      <name>R. Peon-Escalante</name>
    </author>
    <author>
      <name>C. Villanueva</name>
    </author>
    <author>
      <name>O. Mendoza</name>
    </author>
    <author>
      <name>Carlos A. Cruz-Villar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.1409v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1409v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5595v1</id>
    <updated>2013-01-20T17:52:48Z</updated>
    <published>2013-01-20T17:52:48Z</published>
    <title>A discrete analysis of metal-v belt drive</title>
    <summary>  The metal-V belt drive includes a large number of parts which interact
between them to transmit power from the input to the output pulleys. A
compression belt composed of a great number of struts is maintained by a
tension flat belt. Power is them shared into the two belts that moves generally
in opposite directions. Due to the particular geometry of the elements and to
the great number of parts, a numerical approach achieves the global equilibrium
of the mechanism from the elementary part equilibrium. Sliding arc on each
pulley can be thus defined both for the compression and tension belts. Finally,
power sharing can be calculated as differential motion between the belts, is
defined. The first part of the paper will present the different steps of the
quasi-static mechanical analysis and their numerical implementations. Load
distributions, speed profiles and sliding angle values will be discussed. The
second part of the paper will deal to a systematic use of the computer
software. Speed ratio, transmitted torque, strut geometry and friction
coefficients effect will be analysed with the output parameter variations.
Finally, the effect pulley deformable flanges will be discussed.
</summary>
    <author>
      <name>Antoine Karam</name>
    </author>
    <author>
      <name>Daniel Play</name>
    </author>
    <link href="http://arxiv.org/abs/1301.5595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.0317v1</id>
    <updated>2013-02-01T23:42:35Z</updated>
    <published>2013-02-01T23:42:35Z</published>
    <title>Distributed simulation of city inundation by coupled surface and
  subsurface porous flow for urban flood decision support system</title>
    <summary>  We present a decision support system for flood early warning and disaster
management. It includes the models for data-driven meteorological predictions,
for simulation of atmospheric pressure, wind, long sea waves and seiches; a
module for optimization of flood barrier gates operation; models for stability
assessment of levees and embankments, for simulation of city inundation
dynamics and citizens evacuation scenarios. The novelty of this paper is a
coupled distributed simulation of surface and subsurface flows that can predict
inundation of low-lying inland zones far from the submerged waterfront areas,
as observed in St. Petersburg city during the floods. All the models are
wrapped as software services in the CLAVIRE platform for urgent computing,
which provides workflow management and resource orchestration.
</summary>
    <author>
      <name>V. V. Krzhizhanovskaya</name>
    </author>
    <author>
      <name>N. B. Melnikova</name>
    </author>
    <author>
      <name>A. M. Chirkin</name>
    </author>
    <author>
      <name>S. V. Ivanov</name>
    </author>
    <author>
      <name>A. V. Boukhanovsky</name>
    </author>
    <author>
      <name>P. M. A. Sloot</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.procs.2013.05.270</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.procs.2013.05.270" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pre-print submitted to the 2013 International Conference on
  Computational Science</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Procedia Computer Science, Volume 18, 2013, Pages 1046-1056</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.0317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.0317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4136v1</id>
    <updated>2013-02-17T23:53:52Z</updated>
    <published>2013-02-17T23:53:52Z</published>
    <title>Post-buckling Solutions of Hyper-elastic Beam by Canonical Dual Finite
  Element Method</title>
    <summary>  Post buckling problem of a large deformed beam is analyzed using canonical
dual finite element method (CD-FEM). The feature of this method is to choose
correctly the canonical dual stress so that the original non-convex potential
energy functional is reformulated in a mixed complementary energy form with
both displacement and stress fields, and a pure complementary energy is
explicitly formulated in finite dimensional space. Based on the canonical
duality theory and the associated triality theorem, a primal-dual algorithm is
proposed, which can be used to find all possible solutions of this nonconvex
post-buckling problem. Numerical results show that the global maximum of the
pure-complementary energy leads to a stable buckled configuration of the beam.
While the local extrema of the pure-complementary energy present unstable
deformation states, especially. We discovered that the unstable buckled state
is very sensitive to the number of total elements and the external loads.
Theoretical results are verified through numerical examples and some
interesting phenomena in post-bifurcation of this large deformed beam are
observed.
</summary>
    <author>
      <name>Kun Cai</name>
    </author>
    <author>
      <name>David Y. Gao</name>
    </author>
    <author>
      <name>Qing H. Qin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5150v4</id>
    <updated>2013-06-30T23:25:53Z</updated>
    <published>2013-02-20T23:57:10Z</published>
    <title>Measuring Agglomeration of Agglomerated Particles Pictures</title>
    <summary>  In this article, we introduce a novel geometrical index $\delta_{agg}$, which
is associated with the Euler number and is obtained by an image processing
procedure for a given digital picture of aggregated particles such that
$\delta_{agg}$ exhibits the degree of the agglomerations of the particles. In
the previous work (Matsutani, Shimosako, Wang, Appl.Math.Modeling {\bf{37}}
(2013), 4007-4022), we proposed an algorithm to construct a picture of
agglomerated particles as a Monte-Carlo simulation whose agglomeration degree
is controlled by $\gamma_{agg} \in (0,1)$. By applying the image processing
procedure to the pictures of the agglomeration particles constructed following
the algorithm, we show that $\delta_{agg}$ statistically reproduces the
agglomeration parameter $\gamma_{agg}$.
</summary>
    <author>
      <name>Shigeki Matsutani</name>
    </author>
    <author>
      <name>Yoshiyuki Shimosako</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">agglomeration, digital image processing procedure, Euler number</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5150v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5150v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5941v1</id>
    <updated>2013-02-24T19:23:56Z</updated>
    <published>2013-02-24T19:23:56Z</published>
    <title>Optimization of thermal comfort in building through envelope design</title>
    <summary>  Due to the current environmental situation, energy saving has become the
leading drive in modern research. Although the residential houses in tropical
climate do not use air conditioning to maintain thermal comfort in order to
avoid use of electricity. As the thermal comfort is maintained by adequate
envelope composition and natural ventilation, this paper shows that it is
possible to determine the thickness of envelope layers for which the best
thermal comfort is obtained. The building is modeled in EnergyPlus software and
HookeJeves optimization methodology. The investigated house is a typical
residential house one-storey high with five thermal zones located at Reunion
Island, France. Three optimizations are performed such as the optimization of
the thickness of the concrete block layer, of the wood layer, and that of the
thermal insulation layer. The results show optimal thickness of thermal
envelope layers that yield the maximum TC according to Fanger predicted mean
vote.
</summary>
    <author>
      <name>Milorad Bojic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Alexandre Patou Parvedy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Efficiency, Cost, Optimization,
  Simulation and Environmental Impact of Energy Systems, ECOS 2012, Perigia :
  Italy (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.5941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5942v1</id>
    <updated>2013-02-24T19:24:26Z</updated>
    <published>2013-02-24T19:24:26Z</published>
    <title>Performances of Low Temperature Radiant Heating Systems</title>
    <summary>  Low temperature heating panel systems offer distinctive advantages in terms
of thermal comfort and energy consumption, allowing work with low exergy
sources. The purpose of this paper is to compare floor, wall, ceiling, and
floor-ceiling panel heating systems in terms of energy, exergy and CO2
emissions. Simulation results for each of the analyzed panel system are given
by its energy (the consumption of gas for heating, electricity for pumps and
primary energy) and exergy consumption, the price of heating, and its carbon
dioxide emission. Then, the values of the air temperatures of rooms are
investigated and that of the surrounding walls and floors. It is found that the
floor-ceiling heating system has the lowest energy, exergy, CO2 emissions,
operating costs, and uses boiler of the lowest power. The worst system by all
these parameters is the classical ceiling heating
</summary>
    <author>
      <name>Milorad Bojić</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Dragan Cvetkovic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Jasmina Skerlić</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Danijela Nikolić</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Second International Conference on Building Energy and Environment,
  COBEE 2012, Colorado : United States (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0156v1</id>
    <updated>2013-03-01T12:46:06Z</updated>
    <published>2013-03-01T12:46:06Z</published>
    <title>Exploiting the Accumulated Evidence for Gene Selection in Microarray
  Gene Expression Data</title>
    <summary>  Machine Learning methods have of late made significant efforts to solving
multidisciplinary problems in the field of cancer classification using
microarray gene expression data. Feature subset selection methods can play an
important role in the modeling process, since these tasks are characterized by
a large number of features and a few observations, making the modeling a
non-trivial undertaking. In this particular scenario, it is extremely important
to select genes by taking into account the possible interactions with other
gene subsets. This paper shows that, by accumulating the evidence in favour (or
against) each gene along the search process, the obtained gene subsets may
constitute better solutions, either in terms of predictive accuracy or gene
size, or in both. The proposed technique is extremely simple and applicable at
a negligible overhead in cost.
</summary>
    <author>
      <name>G. Prat</name>
    </author>
    <author>
      <name>Ll. Belanche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 algorithms A shorter version of this paper appeared in
  the Procs. of the 19th European Conference on Artificial Intelligence (ECAI
  2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.0156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1725v2</id>
    <updated>2013-03-08T06:13:06Z</updated>
    <published>2013-03-07T15:54:47Z</published>
    <title>Exact Conditional and Unconditional Cramèr-Rao Bounds for Near Field
  Localization</title>
    <summary>  This paper considers the Cram\`er-Rao lower Bound (CRB) for the source
localization problem in the near field. More specifically, we use the exact
expression of the delay parameter for the CRB derivation and show how this
exact CRB can be significantly different from the one given in the literature
and based on an approximate time delay expression (usually considered in the
Fresnel region). This CRB derivation is then generalized by considering the
exact expression of the received power profile (i.e., variable gain case)
which, to our best knowledge, has been ignored in the literature. Finally, we
exploit the CRB expression to introduce the new concept of Near Field
Localization (NFL) region for a target localization performance associated to
the application at hand. We illustrate the usefulness of the proposed CRB
derivation and its developments as well as the NFL region concept through
numerical simulations in different scenarios.
</summary>
    <author>
      <name>Youcef Begriche</name>
    </author>
    <author>
      <name>Messaoud Thameri</name>
    </author>
    <author>
      <name>Karim Abed-Meraim</name>
    </author>
    <link href="http://arxiv.org/abs/1303.1725v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.1725v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.3614v1</id>
    <updated>2013-03-14T21:09:50Z</updated>
    <published>2013-03-14T21:09:50Z</published>
    <title>Implicit Simulation Methods for Stochastic Chemical Kinetics</title>
    <summary>  In biochemical systems some of the chemical species are present with only
small numbers of molecules. In this situation discrete and stochastic
simulation approaches are more relevant than continuous and deterministic ones.
The fundamental Gillespie's stochastic simulation algorithm (SSA) accounts for
every reaction event, which occurs with a probability determined by the
configuration of the system. This approach requires a considerable
computational effort for models with many reaction channels and chemical
species. In order to improve efficiency, tau-leaping methods represent multiple
firings of each reaction during a simulation step by Poisson random variables.
For stiff systems the mean of this variable is treated implicitly in order to
ensure numerical stability.
  This paper develops fully implicit tau-leaping-like algorithms that treat
implicitly both the mean and the variance of the Poisson variables. The
construction is based on adapting weakly convergent discretizations of
stochastic differential equations to stochastic chemical kinetic systems.
Theoretical analyses of accuracy and stability of the new methods are performed
on a standard test problem. Numerical results demonstrate the performance of
the proposed tau-leaping methods.
</summary>
    <author>
      <name>Tae-Hyuk Ahn</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <author>
      <name>Xiaoying Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Prepare submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.3614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.3614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4194v3</id>
    <updated>2013-05-18T23:07:37Z</updated>
    <published>2013-03-18T09:34:10Z</published>
    <title>The ForMaRE Project - Formal Mathematical Reasoning in Economics</title>
    <summary>  The ForMaRE project applies formal mathematical reasoning to economics. We
seek to increase confidence in economics' theoretical results, to aid in
discovering new results, and to foster interest in formal methods, i.e.
computer-aided reasoning, within economics. To formal methods, we seek to
contribute user experience feedback from new audiences, as well as new
challenge problems. In the first project year, we continued earlier game theory
studies but then focused on auctions, where we are building a toolbox of
formalisations, and have started to study matching and financial risk.
  In parallel to conducting research that connects economics and formal
methods, we organise events and provide infrastructure to connect both
communities, from fostering mutual awareness to targeted matchmaking. These
efforts extend beyond economics, towards generally enabling domain experts to
use mechanised reasoning.
</summary>
    <author>
      <name>Christoph Lange</name>
    </author>
    <author>
      <name>Colin Rowat</name>
    </author>
    <author>
      <name>Manfred Kerber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Intelligent Computer Mathematics, 8--12 July, Bath, UK.
  Published as number 7961 in Lecture Notes in Artificial Intelligence,
  Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.4194v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4194v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B26, 68T15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4; I.2.3; K.6.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.5452v2</id>
    <updated>2014-05-05T16:34:01Z</updated>
    <published>2013-03-21T20:18:16Z</published>
    <title>Fast Computation of the Series Impedance of Power Cables with Inclusion
  of Skin and Proximity Effects</title>
    <summary>  We present an efficient numerical technique for calculating the series
impedance matrix of systems with round conductors. The method is based on a
surface admittance operator in combination with the method of moments and it
accurately predicts both skin and proximity effects. Application to a
three-phase armored cable with wire screens demonstrates a speed-up by a factor
of about 100 compared to a finite elements computation. The inclusion of
proximity effect in combination with the high efficiency makes the new method
very attractive for cable modeling within EMTP-type simulation tools.
Currently, these tools can only take skin effect into account.
</summary>
    <author>
      <name>Utkarsh R. Patel</name>
    </author>
    <author>
      <name>Bjorn Gustavsen</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPWRD.2013.2267098</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPWRD.2013.2267098" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted for publication to IEEE Transactions on Power Delivery.
  Update: Published in IEEE Transactions on Power Delivery with the revised
  title of "An Equivalent Surface Current Approach for the Computation of the
  Series Impedance of Power Cables with Inclusion of Skin and Proximity
  Effects"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. on Power Delivery, vol. 28, pp. 2474-2482, Oct. 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1303.5452v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.5452v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6314v2</id>
    <updated>2013-11-28T22:43:16Z</updated>
    <published>2013-03-25T21:12:55Z</published>
    <title>Numerical model of elastic laminated glass beams under finite strain</title>
    <summary>  Laminated glass structures are formed by stiff layers of glass connected with
a compliant plastic interlayer. Due to their slenderness and heterogeneity,
they exhibit a complex mechanical response that is difficult to capture by
single-layer models even in the elastic range. The purpose of this paper is to
introduce an efficient and reliable finite element approach to the simulation
of the immediate response of laminated glass beams. It proceeds from a refined
plate theory due to Mau (1973), as we treat each layer independently and
enforce the compatibility by the Lagrange multipliers. At the layer level, we
adopt the finite-strain shear deformable formulation of Reissner (1972) and the
numerical framework by Ibrahimbegovi\'{c} and Frey (1993). The resulting system
is solved by the Newton method with consistent linearization. By comparing the
model predictions against available experimental data, analytical methods and
two-dimensional finite element simulations, we demonstrate that the proposed
formulation is reliable and provides accuracy comparable to the detailed
two-dimensional finite element analyzes. As such, it offers a convenient basis
to incorporate more refined constitutive description of the interlayer.
</summary>
    <author>
      <name>Alena Zemanová</name>
    </author>
    <author>
      <name>Jan Zeman</name>
    </author>
    <author>
      <name>Michal Šejnoha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.acme.2014.03.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.acme.2014.03.005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Moderate revisions; 17 pages, 6 figures, 8 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archives of Civil and Mechanical Engineering, 14 (4), 734--744,
  (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1303.6314v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6314v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1625v1</id>
    <updated>2013-04-05T07:13:58Z</updated>
    <published>2013-04-05T07:13:58Z</published>
    <title>Mathematical modeling of thermal stabilization of vertical wells on high
  performance computing systems</title>
    <summary>  Temperature stabilization of oil and gas wells is used to ensure stability
and prevent deformation of a subgrade estuary zone. In this work, we consider
the numerical simulation of thermal stabilization using vertical seasonal
freezing columns.
  A mathematical model of such problems is described by a time-dependent
temperature equation with phase transitions from water to ice. The resulting
equation is a standard nonlinear parabolic equation.
  Numerical implementation is based on the finite element method using the
package Fenics. After standard purely implicit approximation in time and simple
linearization, we obtain a system of linear algebraic equations. Because the
size of freezing columns are substantially less than the size of the modeled
area, we obtain mesh refinement near columns. Due to this, we get a large
system of equations which are solved using high performance computing systems.
</summary>
    <author>
      <name>Natalia V. Pavlova</name>
    </author>
    <author>
      <name>Petr N. Vabishchevich</name>
    </author>
    <author>
      <name>Maria V. Vasilyeva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2170v1</id>
    <updated>2013-04-08T11:22:12Z</updated>
    <published>2013-04-08T11:22:12Z</published>
    <title>On sampling SCJ rearrangement scenarios</title>
    <summary>  The Single Cut or Join (SCJ) operation on genomes, generalizing chromosome
evolution by fusions and fissions, is the computationally simplest known model
of genome rearrangement. While most genome rearrangement problems are already
hard when comparing three genomes, it is possible to compute in polynomial time
a most parsimonious SCJ scenario for an arbitrary number of genomes related by
a binary phylogenetic tree.
  Here we consider the problems of sampling and counting the most parsimonious
SCJ scenarios. We show that both the sampling and counting problems are easy
for two genomes, and we relate SCJ scenarios to alternating permutations.
However, for an arbitrary number of genomes related by a binary phylogenetic
tree, the counting and sampling problems become hard. We prove that if a Fully
Polynomial Randomized Approximation Scheme or a Fully Polynomial Almost Uniform
Sampler exist for the most parsimonious SCJ scenario, then RP = NP.
  The proof has a wider scope than genome rearrangements: the same result holds
for parsimonious evolutionary scenarios on any set of discrete characters.
</summary>
    <author>
      <name>Istvan Miklos</name>
    </author>
    <author>
      <name>Sandor Z. Kiss</name>
    </author>
    <author>
      <name>Eric Tannier</name>
    </author>
    <link href="http://arxiv.org/abs/1304.2170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2: Computations on discrete structures, G.2.1: Counting problems" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2272v1</id>
    <updated>2013-04-08T17:13:39Z</updated>
    <published>2013-04-08T17:13:39Z</published>
    <title>Algorithms for Large-scale Whole Genome Association Analysis</title>
    <summary>  In order to associate complex traits with genetic polymorphisms, genome-wide
association studies process huge datasets involving tens of thousands of
individuals genotyped for millions of polymorphisms. When handling these
datasets, which exceed the main memory of contemporary computers, one faces two
distinct challenges: 1) Millions of polymorphisms come at the cost of hundreds
of Gigabytes of genotype data, which can only be kept in secondary storage; 2)
the relatedness of the test population is represented by a covariance matrix,
which, for large populations, can only fit in the combined main memory of a
distributed architecture. In this paper, we present solutions for both
challenges: The genotype data is streamed from and to secondary storage using a
double buffering technique, while the covariance matrix is kept across the main
memory of a distributed memory system. We show that these methods sustain
high-performance and allow the analysis of enormous dataset
</summary>
    <author>
      <name>Elmar Peise</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Diego Fabregat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <author>
      <name>Yurii Aulchenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute of Cytology and Genetics, Novosibirsk</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1304.2272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2948v1</id>
    <updated>2013-04-10T13:23:06Z</updated>
    <published>2013-04-10T13:23:06Z</published>
    <title>Un modèle booléen pour l'énumération des siphons et des pièges
  minimaux dans les réseaux de Petri</title>
    <summary>  Petri-nets are a simple formalism for modeling concurrent computation.
Recently, they have emerged as a powerful tool for the modeling and analysis of
biochemical reaction networks, bridging the gap between purely qualitative and
quantitative models. These networks can be large and complex, which makes their
study difficult and computationally challenging. In this paper, we focus on two
structural properties of Petri-nets, siphons and traps, that bring us
information about the persistence of some molecular species. We present two
methods for enumerating all minimal siphons and traps of a Petri-net by
iterating the resolution of a boolean model interpreted as either a SAT or a
CLP(B) program. We compare the performance of these methods with a
state-of-the-art dedicated algorithm of the Petri-net community. We show that
the SAT and CLP(B) programs are both faster. We analyze why these programs
perform so well on the models of the repository of biological models
biomodels.net, and propose some hard instances for the problem of minimal
siphons enumeration.
</summary>
    <author>
      <name>Faten Nabli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>François Fages</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Martinez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Sylvain Soliman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">JFPC 2012 (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.2948v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2948v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5706v1</id>
    <updated>2013-04-21T08:35:51Z</updated>
    <published>2013-04-21T08:35:51Z</published>
    <title>Calculation and analysis of solitary waves and kinks in elastic tubes</title>
    <summary>  The paper is devoted to analysis of different models that describe waves in
fluid-filled and gas-filled elastic tubes and development of methods of
calculation and numerical analysis of solutions with solitary waves and kinks
for these models. Membrane model and plate model are used for tube. Two types
of solitary waves are found. One-parametric families are stable and may be used
as shock structures. Null-parametric solitary waves are unstable. The process
of split of such solitary waves is investigated. It may lead to appearance of
solutions with kinks. Kink solutions are null-parametric and stable. General
theory of reversible shocks is used for analysis of numerical solutions.
</summary>
    <author>
      <name>I. B. Bakholdin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.5706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.PS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35Q35, 35Q53, 74F10, 65Z05, 68-04, 37K40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6099v2</id>
    <updated>2013-07-12T10:10:35Z</updated>
    <published>2013-04-19T08:11:55Z</published>
    <title>Soft computing-based calibration of microplane M4 model parameters:
  Methodology and validation</title>
    <summary>  Constitutive models for concrete based on the microplane concept have
repeatedly proven their ability to well-reproduce its non-linear response on
material as well as structural scales. The major obstacle to a routine
application of this class of models is, however, the calibration of
microplane-related constants from macroscopic data. The goal of this paper is
two-fold: (i) to introduce the basic ingredients of a robust inverse procedure
for the determination of dominant parameters of the M4 model proposed by Bazant
and co-workers based on cascade Artificial Neural Networks trained by
Evolutionary Algorithm and (ii) to validate the proposed methodology against a
representative set of experimental data. The obtained results demonstrate that
the soft computing-based method is capable of delivering the searched response
with an accuracy comparable to the values obtained by expert users.
</summary>
    <author>
      <name>A. Kucerova</name>
    </author>
    <author>
      <name>M. Leps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advengsoft.2014.01.013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advengsoft.2014.01.013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 12 figures, 14 tables, submitted to Advances in Engineering
  Software, corrected and extended after the first review</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Engineering Software, 72, 226-235, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.6099v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6099v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6476v1</id>
    <updated>2013-04-24T03:29:23Z</updated>
    <published>2013-04-24T03:29:23Z</published>
    <title>Remote Homology Detection in Proteins Using Graphical Models</title>
    <summary>  Given the amino acid sequence of a protein, researchers often infer its
structure and function by finding homologous, or evolutionarily-related,
proteins of known structure and function. Since structure is typically more
conserved than sequence over long evolutionary distances, recognizing remote
protein homologs from their sequence poses a challenge.
  We first consider all proteins of known three-dimensional structure, and
explore how they cluster according to different levels of homology. An
automatic computational method reasonably approximates a human-curated
hierarchical organization of proteins according to their degree of homology.
  Next, we return to homology prediction, based only on the one-dimensional
amino acid sequence of a protein. Menke, Berger, and Cowen proposed a Markov
random field model to predict remote homology for beta-structural proteins, but
their formulation was computationally intractable on many beta-strand
topologies.
  We show two different approaches to approximate this random field, both of
which make it computationally tractable, for the first time, on all protein
folds. One method simplifies the random field itself, while the other retains
the full random field, but approximates the solution through stochastic search.
Both methods achieve improvements over the state of the art in remote homology
detection for beta-structural protein folds.
</summary>
    <author>
      <name>Noah M. Daniels</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCBB.2014.2344682</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCBB.2014.2344682" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Doctoral dissertation</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2322v1</id>
    <updated>2013-05-10T12:16:41Z</updated>
    <published>2013-05-10T12:16:41Z</published>
    <title>Simulation of a typical house in the region of Antananarivo, Madagascar.
  Determination of passive solutions using local materials</title>
    <summary>  This paper deals with new proposals for the design of passive solutions
adapted to the climate of the highlands of Madagascar. While the strongest
population density is located in the central highlands, the problem of thermal
comfort in buildings occurs mainly during winter time. Currently, people use
raw wood to warm the poorly designed houses. This leads to a large scale
deforestation of the areas and causes erosion and environmental problems. The
methodology used consisted of the identification of a typical building and of a
typical meteorological year. Simulations were carried out using a thermal and
airflow software (CODYRUN) to improve each building component (roof, walls,
windows, and soil) in such a way as to estimate the influence of some technical
solutions on each component in terms of thermal comfort. The proposed solutions
also took into account the use of local materials and the standard of living of
the country.
</summary>
    <author>
      <name>Harimalala Razanamanampisoa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Zely Arivelo Randriamanantany</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Hery Tiana Rakotondramiarana</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>François Garde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Madagascar Conference in High-Energy Physics
  (HEP-MAD 07), Antanarivo : Madagascar (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.2322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3149v1</id>
    <updated>2013-05-14T13:23:19Z</updated>
    <published>2013-05-14T13:23:19Z</published>
    <title>Qualitative detection of oil adulteration with machine learning
  approaches</title>
    <summary>  The study focused on the machine learning analysis approaches to identify the
adulteration of 9 kinds of edible oil qualitatively and answered the following
three questions: Is the oil sample adulterant? How does it constitute? What is
the main ingredient of the adulteration oil? After extracting the
high-performance liquid chromatography (HPLC) data on triglyceride from 370 oil
samples, we applied the adaptive boosting with multi-class Hamming loss
(AdaBoost.MH) to distinguish the oil adulteration in contrast with the support
vector machine (SVM). Further, we regarded the adulterant oil and the pure oil
samples as ones with multiple labels and with only one label, respectively.
Then multi-label AdaBoost.MH and multi-label learning vector quantization
(ML-LVQ) model were built to determine the ingredients and their relative ratio
in the adulteration oil. The experimental results on six measures show that
ML-LVQ achieves better performance than multi-label AdaBoost.MH.
</summary>
    <author>
      <name>Xiao-Bo Jin</name>
    </author>
    <author>
      <name>Qiang Lu</name>
    </author>
    <author>
      <name>Feng Wang</name>
    </author>
    <author>
      <name>Quan-gong Huo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5796v2</id>
    <updated>2013-07-18T20:32:52Z</updated>
    <published>2013-05-24T17:00:00Z</published>
    <title>Efficient methods for computing observation impact in 4D-Var data
  assimilation</title>
    <summary>  This paper presents a practical computational approach to quantify the effect
of individual observations in estimating the state of a system. Such an
analysis can be used for pruning redundant measurements, and for designing
future sensor networks. The mathematical approach is based on computing the
sensitivity of the reanalysis (unconstrained optimization solution) with
respect to the data. The computational cost is dominated by the solution of a
linear system, whose matrix is the Hessian of the cost function, and is only
available in operator form. The right hand side is the gradient of a scalar
cost function that quantifies the forecast error of the numerical model. The
use of adjoint models to obtain the necessary first and second order
derivatives is discussed. We study various strategies to accelerate the
computation, including matrix-free iterative solvers, preconditioners, and an
in-house multigrid solver. Experiments are conducted on both a small-size
shallow-water equations model, and on a large-scale numerical weather
prediction model, in order to illustrate the capabilities of the new
methodology.
</summary>
    <author>
      <name>Alexandru Cioaca</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <author>
      <name>Eric de Sturler</name>
    </author>
    <link href="http://arxiv.org/abs/1305.5796v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5796v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.7422v1</id>
    <updated>2013-05-31T14:36:59Z</updated>
    <published>2013-05-31T14:36:59Z</published>
    <title>Evaluating Different Cost-Benefit Analysis Methods for Port Security
  Operations</title>
    <summary>  Service industries, such as ports, are attentive to their standards, a smooth
service flow and economic viability. Cost benefit analysis has proven itself as
a useful tool to support this type of decision making; it has been used by
businesses and governmental agencies for many years. In this book chapter we
demonstrate different modelling methods that are used for estimating input
factors required for conducting cost benefit analysis based on a single case
study. These methods are: scenario analysis, decision trees, Monte-Carlo
simulation modelling and discrete event simulation modelling. Our aims are, on
the one hand, to guide the analyst through the modelling processes and, on the
other hand, to demonstrate what additional decision support information can be
obtained from applying each of these modelling methods.
</summary>
    <author>
      <name>Galina Sherman</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>David Menachof</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Decision Making in Service Industries: A Practical Approach, 279-302,
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.7422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.7422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.7424v1</id>
    <updated>2013-05-31T14:39:34Z</updated>
    <published>2013-05-31T14:39:34Z</published>
    <title>Investigating the effectiveness of Variance Reduction Techniques in
  Manufacturing, Call Center and Cross-docking Discrete Event Simulation Models</title>
    <summary>  Variance reduction techniques have been shown by others in the past to be a
useful tool to reduce variance in Simulation studies. However, their
application and success in the past has been mainly domain specific, with
relatively little guidelines as to their general applicability, in particular
for novices in this area. To facilitate their use, this study aims to
investigate the robustness of individual techniques across a set of scenarios
from different domains. Experimental results show that Control Variates is the
only technique which achieves a reduction in variance across all domains.
Furthermore, applied individually, Antithetic Variates and Control Variates
perform particularly well in the Cross-docking scenarios, which was previously
unknown.
</summary>
    <author>
      <name>Adrian Adewunmi</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Use Cases of Discrete Event Simulation Appliance and Research.
  Bangsow, Steffen (Ed.). Springer Berlin Heidelberg, 1-24, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.7424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.7424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.7458v1</id>
    <updated>2013-05-31T15:40:49Z</updated>
    <published>2013-05-31T15:40:49Z</published>
    <title>Validation of a Microsimulation of the Port of Dover</title>
    <summary>  Modelling and simulating the traffic of heavily used but secure environments
such as seaports and airports is of increasing importance. Errors made when
simulating these environments can have long standing economic, social and
environmental implications. This paper discusses issues and problems that may
arise when designing a simulation strategy. Data for the Port is presented,
methods for lightweight vehicle assessment that can be used to calibrate and
validate simulations are also discussed along with a diagnosis of
overcalibration issues. We show that decisions about where the intelligence
lies in a system has important repercussions for the reliability of system
statistics. Finally, conclusions are drawn about how microsimulations can be
moved forward as a robust planning tool for the 21st century.
</summary>
    <author>
      <name>Chris Roadknight</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Galina Sherman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational Science 3 (1-2), 56-66, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.7458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.7458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0747v1</id>
    <updated>2013-07-02T16:19:54Z</updated>
    <published>2013-07-02T16:19:54Z</published>
    <title>Simulating the Dynamics of T Cell Subsets Throughout the Lifetime</title>
    <summary>  It is widely accepted that the immune system undergoes age-related changes
correlating with increased disease in the elderly. T cell subsets have been
implicated. The aim of this work is firstly to implement and validate a
simulation of T regulatory cell (Treg) dynamics throughout the lifetime, based
on a model by Baltcheva. We show that our initial simulation produces an
inversion between precursor and mature Treys at around 20 years of age, though
the output differs significantly from the original laboratory dataset.
Secondly, this report discusses development of the model to incorporate new
data from a cross-sectional study of healthy blood donors addressing balance
between Treys and Th17 cells with novel markers for Treg. The potential for
simulation to add insight into immune aging is discussed.
</summary>
    <author>
      <name>Stephanie Foan</name>
    </author>
    <author>
      <name>Andrew Jackson</name>
    </author>
    <author>
      <name>Ian Spendlove</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 10th International Conference on Artificial Immune
  Systems (ICARIS 2011), LNCS Volume 6825, Cambridge, UK, pp 71-76</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0749v1</id>
    <updated>2013-07-02T16:31:44Z</updated>
    <published>2013-07-02T16:31:44Z</published>
    <title>Comparing Decison Support Tools for Cargo Screening Processes</title>
    <summary>  When planning to change operations at ports there are two key stake holders
with very different interests involved in the decision making processes. Port
operators are attentive to their standards, a smooth service flow and economic
viability while border agencies are concerned about national security. The time
taken for security checks often interferes with the compliance to service
standards that port operators would like to achieve. Decision support tools as
for example Cost-Benefit Analysis or Multi Criteria Analysis are useful helpers
to better understand the impact of changes to a system. They allow
investigating future scenarios and helping to find solutions that are
acceptable for all parties involved in port operations. In this paper we
evaluate two different modelling methods, namely scenario analysis and discrete
event simulation. These are useful for driving the decision support tools (i.e.
they provide the inputs the decision support tools require). Our aims are, on
the one hand, to guide the reader through the modelling processes and, on the
other hand, to demonstrate what kind of decision support information one can
obtain from the different modelling methods presented.
</summary>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>Galina Sherman</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>David Menachof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 10th International Conference on Modeling and Applied Simulation
  (MAS), 12-14 September, Rome, Italy, 31-39</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1073v1</id>
    <updated>2013-07-03T16:43:23Z</updated>
    <published>2013-07-03T16:43:23Z</published>
    <title>Modelling Reactive and Proactive Behaviour in Simulation: A Case Study
  in a University Organisation</title>
    <summary>  Simulation is a well established what-if scenario analysis tool in
Operational Research (OR). While traditionally Discrete Event Simulation (DES)
and System Dynamics Simulation (SDS) are the predominant simulation techniques
in OR, a new simulation technique, namely Agent-Based Simulation (ABS), has
emerged and is gaining more attention. In our research we focus on discrete
simulation methods (i.e. DES and ABS). The contribution made by this paper is
the comparison of DES and combined DES/ABS for modelling human reactive and
different level of detail of human proactive behaviour in service systems. The
results of our experiments show that the level of proactiveness considered in
the model has a big impact on the simulation output. However, there is not a
big difference between the results from the DES and the combined DES/ABS
simulation models. Therefore, for service systems of the type we investigated
we would suggest to use DES as the preferred analysis tool.
</summary>
    <author>
      <name>Mazlina Abdul Majid</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Gameon-Arabia, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1078v1</id>
    <updated>2013-07-03T16:55:32Z</updated>
    <published>2013-07-03T16:55:32Z</published>
    <title>Investigating the Detection of Adverse Drug Events in a UK General
  Practice Electronic Health-Care Database</title>
    <summary>  Data-mining techniques have frequently been developed for Spontaneous
reporting databases. These techniques aim to find adverse drug events
accurately and efficiently. Spontaneous reporting databases are prone to
missing information, under reporting and incorrect entries. This often results
in a detection lag or prevents the detection of some adverse drug events. These
limitations do not occur in electronic health-care databases. In this paper,
existing methods developed for spontaneous reporting databases are implemented
on both a spontaneous reporting database and a general practice electronic
health-care database and compared. The results suggests that the application of
existing methods to the general practice database may help find signals that
have gone undetected when using the spontaneous reporting system database. In
addition the general practice database provides far more supplementary
information, that if incorporated in analysis could provide a wealth of
information for identifying adverse events more accurately.
</summary>
    <author>
      <name>Jenna Reps</name>
    </author>
    <author>
      <name>Jan Feyereisl</name>
    </author>
    <author>
      <name>Jonathan M. Garibaldi</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Jack E. Gibson</name>
    </author>
    <author>
      <name>Richard B. Hubbard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UKCI 2011, the 11th Annual Workshop on Computational Intelligence,
  Manchester, pp 167-173</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1079v1</id>
    <updated>2013-07-03T17:03:31Z</updated>
    <published>2013-07-03T17:03:31Z</published>
    <title>Application of a clustering framework to UK domestic electricity data</title>
    <summary>  This paper takes an approach to clustering domestic electricity load profiles
that has been successfully used with data from Portugal and applies it to UK
data. Clustering techniques are applied and it is found that the preferred
technique in the Portuguese work (a two stage process combining Self Organised
Maps and Kmeans) is not appropriate for the UK data. The work shows that up to
nine clusters of households can be identified with the differences in usage
profiles being visually striking. This demonstrates the appropriateness of
breaking the electricity usage patterns down to more detail than the two load
profiles currently published by the electricity industry. The paper details
initial results using data collected in Milton Keynes around 1990. Further work
is described and will concentrate on building accurate and meaningful clusters
of similar electricity users in order to better direct demand side management
initiatives to the most relevant target customers.
</summary>
    <author>
      <name>Ian Dent</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Tom Rodden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UKCI 2011, the 11th Annual Workshop on Computational Intelligence,
  Manchester, pp 161-166</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1380v1</id>
    <updated>2013-07-04T15:45:09Z</updated>
    <published>2013-07-04T15:45:09Z</published>
    <title>The Application of a Data Mining Framework to Energy Usage Profiling in
  Domestic Residences using UK data</title>
    <summary>  This paper describes a method for defining representative load profiles for
domestic electricity users in the UK. It considers bottom up and clustering
methods and then details the research plans for implementing and improving
existing framework approaches based on the overall usage profile. The work
focuses on adapting and applying analysis framework approaches to UK energy
data in order to determine the effectiveness of creating a few (single figures)
archetypical users with the intention of improving on the current methods of
determining usage profiles. The work is currently in progress and the paper
details initial results using data collected in Milton Keynes around 1990.
Various possible enhancements to the work are considered including a split
based on temperature to reflect the varying UK weather conditions.
</summary>
    <author>
      <name>Ian Dent</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Tom Rodden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Buildings Do Not Use Energy, People Do Research Student Conference,
  Bath, UK, 2011. arXiv admin note: text overlap with arXiv:1307.1079</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1385v1</id>
    <updated>2013-07-04T15:55:33Z</updated>
    <published>2013-07-04T15:55:33Z</published>
    <title>Creating Personalised Energy Plans. From Groups to Individuals using
  Fuzzy C Means Clustering</title>
    <summary>  Changes in the UK electricity market mean that domestic users will be
required to modify their usage behaviour in order that supplies can be
maintained. Clustering allows usage profiles collected at the household level
to be clustered into groups and assigned a stereotypical profile which can be
used to target marketing campaigns. Fuzzy C Means clustering extends this by
allowing each household to be a member of many groups and hence provides the
opportunity to make personalised offers to the household dependent on their
degree of membership of each group. In addition, feedback can be provided on
how user's changing behaviour is moving them towards more "green" or cost
effective stereotypical usage.
</summary>
    <author>
      <name>Ian Dent</name>
    </author>
    <author>
      <name>Christian Wagner</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Tom Rodden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Digital Engagement 11, Newcastle, November 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1390v1</id>
    <updated>2013-07-04T16:15:11Z</updated>
    <published>2013-07-04T16:15:11Z</published>
    <title>Systems Dynamics or Agent-Based Modelling for Immune Simulation?</title>
    <summary>  In immune system simulation there are two competing simulation approaches:
System Dynamics Simulation (SDS) and Agent-Based Simulation (ABS). In the
literature there is little guidance on how to choose the best approach for a
specific immune problem. Our overall research aim is to develop a framework
that helps researchers with this choice. In this paper we investigate if it is
possible to easily convert simulation models between approaches. With no
explicit guidelines available from the literature we develop and test our own
set of guidelines for converting SDS models into ABS models in a non-spacial
scenario. We also define guidelines to convert ABS into SDS considering a
non-spatial and a spatial scenario. After running some experiments with the
developed models we found that in all cases there are significant differences
between the results produced by the different simulation methods.
</summary>
    <author>
      <name>Grazziela P Figueredo</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 10th International Conference on Artificial Immune
  Systems (ICARIS 2011), LNCS Volume 6825, Cambridge, UK, pp 81-94, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1466v1</id>
    <updated>2013-07-04T16:42:02Z</updated>
    <published>2013-07-04T16:42:02Z</published>
    <title>Detect adverse drug reactions for the drug Pravastatin</title>
    <summary>  Adverse drug reaction (ADR) is widely concerned for public health issue. ADRs
are one of most common causes to withdraw some drugs from market. Prescription
event monitoring (PEM) is an important approach to detect the adverse drug
reactions. The main problem to deal with this method is how to automatically
extract the medical events or side effects from high-throughput medical data,
which are collected from day to day clinical practice. In this study we propose
an original approach to detect the ADRs using feature matrix and feature
selection. The experiments are carried out on the drug Pravastatin. Major side
effects for the drug are detected. The detected ADRs are based on computerized
method, further investigation is needed.
</summary>
    <author>
      <name>Yihui Liu</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5th International Conference on Biomedical Engineering and
  Informatics (BMEI), pp 1188-1192, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1597v2</id>
    <updated>2013-07-08T13:37:04Z</updated>
    <published>2013-07-05T12:43:04Z</published>
    <title>A Beginners Guide to Systems Simulation in Immunology</title>
    <summary>  Some common systems modelling and simulation approaches for immune problems
are Monte Carlo simulations, system dynamics, discrete-event simulation and
agent-based simulation. These methods, however, are still not widely adopted in
immunology research. In addition, to our knowledge, there is few research on
the processes for the development of simulation models for the immune system.
Hence, for this work, we have two contributions to knowledge. The first one is
to show the importance of systems simulation to help immunological research and
to draw the attention of simulation developers to this research field. The
second contribution is the introduction of a quick guide containing the main
steps for modelling and simulation in immunology, together with challenges that
occur during the model development. Further, this paper introduces an example
of a simulation problem, where we test our guidelines.
</summary>
    <author>
      <name>Grazziela P. Figueredo</name>
    </author>
    <author>
      <name>Peer-Olaf Siebers</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Stephanie Foan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 11th Int. Conf. on Artificial Immune Systems, pp
  57-71, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.1597v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1597v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2001v1</id>
    <updated>2013-07-08T09:28:27Z</updated>
    <published>2013-07-08T09:28:27Z</published>
    <title>Variance in System Dynamics and Agent Based Modelling Using the SIR
  Model of Infectious Disease</title>
    <summary>  Classical deterministic simulations of epidemiological processes, such as
those based on System Dynamics, produce a single result based on a fixed set of
input parameters with no variance between simulations. Input parameters are
subsequently modified on these simulations using Monte-Carlo methods, to
understand how changes in the input parameters affect the spread of results for
the simulation. Agent Based simulations are able to produce different output
results on each run based on knowledge of the local interactions of the
underlying agents and without making any changes to the input parameters. In
this paper we compare the influence and effect of variation within these two
distinct simulation paradigms and show that the Agent Based simulation of the
epidemiological SIR (Susceptible, Infectious, and Recovered) model is more
effective at capturing the natural variation within SIR compared to an
equivalent model using System Dynamics with Monte-Carlo simulation. To
demonstrate this effect, the SIR model is implemented using both System
Dynamics (with Monte-Carlo simulation) and Agent Based Modelling based on
previously published empirical data.
</summary>
    <author>
      <name>Aslam Ahmed</name>
    </author>
    <author>
      <name>Julie Greensmith</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 26th European Conference on Modelling and
  Simulation (ECMS), Koblenz, Germany, May 2012, pp 9-15, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.2001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2789v1</id>
    <updated>2013-07-10T13:33:57Z</updated>
    <published>2013-07-10T13:33:57Z</published>
    <title>Computer Simulation of 3-D Finite-Volume Liquid Transport in Fibrous
  Materials: a Physical Model for Ink Seepage into Paper</title>
    <summary>  A physical model for the simulation ink/paper interaction at the mesoscopic
scale is developed. It is based on the modified Ising model, and is generalized
to consider the restriction of the finite-volume of ink and also its dynamic
seepage. This allows the model to obtain the ink distribution within the paper
volume. At the mesoscopic scale, the paper is modeled using a discretized fiber
structure. The ink distribution is obtained by solving its equivalent
optimization problem, which is solved using a modified genetic algorithm, along
with a new boundary condition and the quasi-linear technique. The model is able
to simulate the finite-volume distribution of ink.
</summary>
    <author>
      <name>Reza Farrahi Moghaddam</name>
    </author>
    <author>
      <name>Fereydoun Farrahi Moghaddam</name>
    </author>
    <author>
      <name>Mohamed Cheriet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.2789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3337v1</id>
    <updated>2013-07-12T06:20:59Z</updated>
    <published>2013-07-12T06:20:59Z</published>
    <title>Unsupervised Gene Expression Data using Enhanced Clustering Method</title>
    <summary>  Microarrays are made it possible to simultaneously monitor the expression
profiles of thousands of genes under various experimental conditions.
Identification of co-expressed genes and coherent patterns is the central goal
in microarray or gene expression data analysis and is an important task in
bioinformatics research. Feature selection is a process to select features
which are more informative. It is one of the important steps in knowledge
discovery. The problem is that not all features are important. Some of the
features may be redundant, and others may be irrelevant and noisy. In this work
the unsupervised Gene selection method and Enhanced Center Initialization
Algorithm (ECIA) with K-Means algorithms have been applied for clustering of
Gene Expression Data. This proposed clustering algorithm overcomes the
drawbacks in terms of specifying the optimal number of clusters and
initialization of good cluster centroids. Gene Expression Data show that could
identify compact clusters with performs well in terms of the Silhouette
Coefficients cluster measure.
</summary>
    <author>
      <name>T. Chandrasekhar</name>
    </author>
    <author>
      <name>K. Thangavel</name>
    </author>
    <author>
      <name>E. Elayaraja</name>
    </author>
    <author>
      <name>E. N. Sathishkumar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICE-CCN.2013.6528554</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICE-CCN.2013.6528554" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figures, conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Emerging Trends in Computing,
  Communication and Nanotechnology (ICE-CCN), 25-26 March 2013, Page(s): 518 -
  522</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3712v1</id>
    <updated>2013-07-14T08:51:19Z</updated>
    <published>2013-07-14T08:51:19Z</published>
    <title>Reconstruction of gene regulatory network of colon cancer using
  information theoretic approach</title>
    <summary>  Reconstruction of gene regulatory networks or 'reverse-engineering' is a
process of identifying gene interaction networks from experimental microarray
gene expression profile through computation techniques. In this paper, we tried
to reconstruct cancer-specific gene regulatory network using information
theoretic approach - mutual information. The considered microarray data
consists of large number of genes with 20 samples - 12 samples from colon
cancer patient and 8 from normal cell. The data has been preprocessed and
normalized. A t-test statistics has been applied to filter differentially
expressed genes. The interaction between filtered genes has been computed using
mutual information and ten different networks has been constructed with varying
number of interactions ranging from 30 to 500. We performed the topological
analysis of the reconstructed network, revealing a large number of interactions
in colon cancer. Finally, validation of the inferred results has been done with
available biological databases and literature.
</summary>
    <author>
      <name>Khalid Raza</name>
    </author>
    <author>
      <name>Rafat Parveen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/cp.2013.2357</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/cp.2013.2357" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Confluence 2013: The Next Generation Information Technology Summit
  (4th International Conference), pp. 461 - 466</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1365v1</id>
    <updated>2013-08-06T18:11:15Z</updated>
    <published>2013-08-06T18:11:15Z</published>
    <title>Mathematical model of concentrating solar cooker</title>
    <summary>  The main purpose of this work is to obtain a mathematical model consistent
with the thermal behavior of concentrating solar cookers, such as
Jorhejpataranskua. We also want to simulate different conditions respect to the
parameters involved of several materials for its construction and efficiency.
The model is expressed in terms of a coupled nonlinear system of differential
equations which are solved using Mathematica 8. The results obtained by our
model are compared with measurements of solar cooker in field testing
operation. We obtained good results in agreement with experimental data.
Moreover, the simulation results are used by calculating cooking power and
standardized cooking power of solar cooker for different parameters.
</summary>
    <author>
      <name>Mauricio González Avilés</name>
    </author>
    <author>
      <name>José Juan González Avilés</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Solar cooker, thermal model; mathematical model</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.1365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1464v1</id>
    <updated>2013-08-07T02:24:20Z</updated>
    <published>2013-08-07T02:24:20Z</published>
    <title>ManyClaw: Slicing and dicing Riemann solvers for next generation highly
  parallel architectures</title>
    <summary>  Next generation computer architectures will include order of magnitude more
intra-node parallelism; however, many application programmers have a difficult
time keeping their codes current with the state-of-the-art machines. In this
context, we analyze Hyperbolic PDE solvers, which are used in the solution of
many important applications in science and engineering. We present ManyClaw, a
project intended to explore the exploitation of intra-node parallelism in
hyperbolic PDE solvers via the Clawpack software package for solving hyperbolic
PDEs. Our goal is to separate the low level parallelism and the physical
equations thus providing users the capability to leverage intra-node
parallelism without explicitly writing code to take advantage of newer
architectures.
</summary>
    <author>
      <name>Andy R. Terrel</name>
    </author>
    <author>
      <name>Kyle T. Mandli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TACC-Intel Symposium on Highly Parallel Architectures. 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.1464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.4; D.1.3; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2307v1</id>
    <updated>2013-08-10T13:07:07Z</updated>
    <published>2013-08-10T13:07:07Z</published>
    <title>Finite Element Model Updating Using Fish School Search Optimization
  Method</title>
    <summary>  A recent nature inspired optimization algorithm, Fish School Search (FSS) is
applied to the finite element model (FEM) updating problem. This method is
tested on a GARTEUR SM-AG19 aeroplane structure. The results of this algorithm
are compared with two other metaheuristic algorithms; Genetic Algorithm (GA)
and Particle Swarm Optimization (PSO). It is observed that on average, the FSS
and PSO algorithms give more accurate results than the GA. A minor modification
to the FSS is proposed. This modification improves the performance of FSS on
the FEM updating problem which has a constrained search space.
</summary>
    <author>
      <name>I. Boulkabeit</name>
    </author>
    <author>
      <name>L. Mthembu</name>
    </author>
    <author>
      <name>T. Marwala</name>
    </author>
    <author>
      <name>F. De Lima Neto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the 1st BRICS Countries &amp; 11th CBIC Brazilian Congress
  on Computational Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.2307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5906v1</id>
    <updated>2013-08-23T12:08:54Z</updated>
    <published>2013-08-23T12:08:54Z</published>
    <title>Biological effects and equivalent doses in radiotherapy: a software
  solution</title>
    <summary>  The limits of TDF (time, dose, and fractionation) and linear quadratic models
have been known for a long time. Medical physicists and physicians are required
to provide fast and reliable interpretations regarding the delivered doses or
any future prescriptions relating to treatment changes. We therefore propose a
calculation interface under the GNU license to be used for equivalent doses,
biological doses, and normal tumor complication probability (Lyman model). The
methodology used draws from several sources: the linear-quadratic-linear model
of Astrahan, the repopulation effects of Dale, and the prediction of
multi-fractionated treatments of Thames. The results are obtained from an
algorithm that minimizes an ad-hoc cost function, and then compared to the
equivalent dose computed using standard calculators in seven French
radiotherapy centers.
</summary>
    <author>
      <name>Cyril Voyant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPE, CHD Castellucio</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel Julian</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CHD Castellucio</arxiv:affiliation>
    </author>
    <author>
      <name>Rudy Roustit</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CHD Castellucio</arxiv:affiliation>
    </author>
    <author>
      <name>Katia Biffi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CHD Castellucio</arxiv:affiliation>
    </author>
    <author>
      <name>Celine Lantieri Marcovici</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CHD Castellucio</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">reports of practical oncology and radiotherapy (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.5906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0781v1</id>
    <updated>2013-08-31T01:09:23Z</updated>
    <published>2013-08-31T01:09:23Z</published>
    <title>An Exploratory Data Survey of Drug Name Incidence and Prevalence From
  the FDA's Adverse Event Reporting System, 2004 to 2012Q2</title>
    <summary>  Drug Names, Population Level Surveillance and the FDA's Adverse Event
Reporting System: An Exploratory Data Survey of Drug Name Incidence and
Prevalence, 2004-2012Q2 Purpose: To count and monitor the drug names reported
in the publicly available version of the Federal Adverse Event Reporting System
(FAERS) from 2004 to 2012Q2 in a maximized sensitivity relational model.
Methods: Data mining and data modeling was conducted and event based summary
statistics with plots were created from over nine continuous years of
continuous FAERS data. Results: This FAERS model contains 344,452 individual
drug names and 432,541,994 count references which occurred across 4,148,761
human subjects in the 34 quarter study period. Plots for the top 100 scoring
drug name references are reported by year and quarter; the top 100 drug names
contain 143,384,240 references or 33% of all drug name references over 34
quarters of continuous FAERS data. Conclusions: While FAERS contains many drugs
and adverse event reports, its data pertains to very few of them. Drug name
incidence lends timely and effective surveillance of large populations of
Averse Event Reports and does not require the cause of the AE, nor its validity
to be known to detect a mass poisoning.
</summary>
    <author>
      <name>Nick Williams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 Figures 19 Pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.0781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="20 90 2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0870v1</id>
    <updated>2013-09-03T23:41:28Z</updated>
    <published>2013-09-03T23:41:28Z</published>
    <title>A hybrid mammalian cell cycle model</title>
    <summary>  Hybrid modeling provides an effective solution to cope with multiple time
scales dynamics in systems biology. Among the applications of this method, one
of the most important is the cell cycle regulation. The machinery of the cell
cycle, leading to cell division and proliferation, combines slow growth,
spatio-temporal re-organisation of the cell, and rapid changes of regulatory
proteins concentrations induced by post-translational modifications. The
advancement through the cell cycle comprises a well defined sequence of stages,
separated by checkpoint transitions. The combination of continuous and discrete
changes justifies hybrid modelling approaches to cell cycle dynamics. We
present a piecewise-smooth version of a mammalian cell cycle model, obtained by
hybridization from a smooth biochemical model. The approximate hybridization
scheme, leading to simplified reaction rates and binary event location
functions, is based on learning from a training set of trajectories of the
smooth model. We discuss several learning strategies for the parameters of the
hybrid model.
</summary>
    <author>
      <name>Vincent Noël</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Université de Rennes 1</arxiv:affiliation>
    </author>
    <author>
      <name>Sergey Vakulenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Saint Petersburg State University of Technology and Design</arxiv:affiliation>
    </author>
    <author>
      <name>Ovidiu Radulescu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Université de Montpellier 2</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.125.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.125.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2013, arXiv:1308.5724</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 125, 2013, pp. 68-83</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.0870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0872v1</id>
    <updated>2013-09-03T23:41:44Z</updated>
    <published>2013-09-03T23:41:44Z</published>
    <title>Producing a Set of Models for the Iron Homeostasis Network</title>
    <summary>  This paper presents a method for modeling biological systems which combines
formal techniques on intervals, numerical simulations and satisfaction of
Signal Temporal Logic (STL) formulas. The main modeling challenge addressed by
this approach is the large uncertainty in the values of the parameters due to
the experimental difficulties of getting accurate biological data. This method
considers intervals for each parameter and a formal description of the expected
behavior of the model. In a first step, it produces reduced intervals of
possible parameter values. Then by performing a systematic search in these
intervals, it defines sets of parameter values used in the next step. This
procedure aims at finding a sub-space where the model robustly behaves as
expected. We apply this method to the modeling of the cellular iron homeostasis
network in erythroid progenitors. The produced model describes explicitly the
regulation mechanism which acts at the translational level.
</summary>
    <author>
      <name>Nicolas Mobilia</name>
    </author>
    <author>
      <name>Alexandre Donzé</name>
    </author>
    <author>
      <name>Jean Marc Moulis</name>
    </author>
    <author>
      <name>Éric Fanchon</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.125.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.125.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings HSB 2013, arXiv:1308.5724</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 125, 2013, pp. 92-98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.0872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1199v1</id>
    <updated>2013-09-04T22:22:52Z</updated>
    <published>2013-09-04T22:22:52Z</published>
    <title>Experiences with Automated Build and Test for Geodynamics Simulation
  Codes</title>
    <summary>  The Computational Infrastructure for Geodynamics (CIG) is an NSF funded
project that develops, supports, and disseminates community-accessible software
for the geodynamics research community. CIG software supports a variety of
computational geodynamic research from mantle and core dynamics, to crustal and
earthquake dynamics, to magma migration and seismology. To support this type of
project a backend computational infrastructure is necessary.
  Part of this backend infrastructure is an automated build and testing system
to ensure codes and changes to them are compatible with multiple platforms and
that the changes do not significantly affect the scientific results. In this
paper we describe the build and test infrastructure for CIG based on the BaTLab
system, how it is organized, and how it assists in operations. We demonstrate
the use of this type of testing for a suite of geophysics codes, show why codes
may compile on one platform but not on another, and demonstrate how minor
changes may alter the computed results in unexpected ways that can influence
the scientific interpretation. Finally, we examine result comparison between
platforms and show how the compiler or operating system may affect results.
</summary>
    <author>
      <name>Eric M. Heien</name>
    </author>
    <author>
      <name>Todd L. Miller</name>
    </author>
    <author>
      <name>Becky Gietzel</name>
    </author>
    <author>
      <name>Louise H. Kellogg</name>
    </author>
    <link href="http://arxiv.org/abs/1309.1199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.4429v1</id>
    <updated>2013-09-17T19:12:06Z</updated>
    <published>2013-09-17T19:12:06Z</published>
    <title>Comsol Simulations of Cracking in Point Loaded Masonry with Randomly
  Distributed Material Properties</title>
    <summary>  This paper describes COMSOL simulations of the stress and crack development
in the area where a masonry wall supports a floor. In these simulations one of
the main material properties of calcium silicate, its E-value, was assigned
randomly to the finite elements of the modeled specimen. Calcium silicate is a
frequently used building material with a relatively brittle fracture
characteristic. Its initial E-value varies, as well as tensile strength and
post peak behavior. Therefore, in the simulation, initial E-values were
randomly assigned to the elements of the model and a step function used for
describing the descending branch. The method also allows for variation in
strength to be taken into account in future research. The performed non-linear
simulation results are compared with experimental findings. They show the
stress distribution and cracking behavior in point loaded masonry when varying
material properties are used.
</summary>
    <author>
      <name>A. T. Vermeltfoort</name>
    </author>
    <author>
      <name>A. W. M. Van Schijndel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.4429v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.4429v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5333v3</id>
    <updated>2013-10-14T23:43:33Z</updated>
    <published>2013-09-20T17:23:02Z</published>
    <title>Power Grid Simulation using Matrix Exponential Method with Rational
  Krylov Subspaces</title>
    <summary>  One well adopted power grid simulation methodology is to factorize matrix
once and perform only backward forward substitution with a deliberately chosen
step size along the simulation. Since the required simulation time is usually
long for the power grid design, the costly factorization is amortized. However,
such fixed step size cannot exploit larger step size for the low frequency
response in the power grid to speedup the simulation. In this work, we utilize
the matrix exponential method with the rational Krylov subspace approximation
to enable adaptive step size in the power grid simulation. The kernel operation
in our method only demands one factorization and backward forward
substitutions. Moreover, the rational Krylov subspace approximation can relax
the stiffness constraint of the previous works. The cheap computation of
adaptivity in our method could exploit the long low frequency response in a
power grid and significantly accelerate the simulation. The experimental
results show that our method achieves up to 18X speedup over the trapezoidal
method with fixed step size.
</summary>
    <author>
      <name>Hao Zhuang</name>
    </author>
    <author>
      <name>Shih-Hung Weng</name>
    </author>
    <author>
      <name>Chung-Kuan Cheng</name>
    </author>
    <link href="http://arxiv.org/abs/1309.5333v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5333v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5574v1</id>
    <updated>2013-09-22T07:51:10Z</updated>
    <published>2013-09-22T07:51:10Z</published>
    <title>Image-guided therapy system for interstitial gynecologic brachytherapy
  in a multimodality operating suite</title>
    <summary>  In this contribution, an image-guided therapy system supporting gynecologic
radiation therapy is introduced. The overall workflow of the presented system
starts with the arrival of the patient and ends with follow-up examinations by
imaging and a superimposed visualization of the modeled device from a PACS
system. Thereby, the system covers all treatments stages (pre-, intra- and
postoperative) and has been designed and constructed by a computer scientist
with feedback from an interdisciplinary team of physicians and engineers. This
integrated medical system enables dispatch of diagnostic images directly after
acquisition to a processing workstation that has an on-board 3D Computer Aided
Design model of a medical device. Thus, allowing precise identification of
catheter location in the 3D imaging model which later provides rapid feedback
to the clinician regarding device location. Moreover, the system enables the
ability to perform patient-specific pre-implant evaluation by assessing the
placement of interstitial needles prior to an intervention via virtual template
matching with a diagnostic scan.
</summary>
    <author>
      <name>Jan Egger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/2193-1801-2-395</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/2193-1801-2-395" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SpringerPlus 2013 2:395</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.5574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5677v1</id>
    <updated>2013-09-23T01:16:42Z</updated>
    <published>2013-09-23T01:16:42Z</published>
    <title>Checkerboard Problem to Topology Optimization of Continuum Structures</title>
    <summary>  The area of topology optimization of continuum structures of which is allowed
to change in order to improve the performance is now dominated by methods that
employ the material distribution concept. The typical methods of the topology
optimization based on the structural optimization of two phase composites are
the so-called variable density ones, like the SIMP (Solid Isotropic Material
with Penalization) and the BESO (Bi-directional Evolutional Structure
Optimization). The topology optimization problem refers to the saddle-point
variation one as well as the so-called Stokes flow problem of the compressive
fluid. The checkerboard patterns often appear in the results computed by the
SIMP and the BESO in which the Q1-P0 element is used for FEM (Finite Element
Method), since these patterns are more favourable than uniform density regions.
Computational experiments of SIMP and BESO have shown that filtering of
sensitivity information of the optimization problem is a highly efficient way
that the checkerboard patterns disappeared and to ensure mesh-independency. SIn
this paper, we discuss the theoretical basis for the filtering method of the
SIMP and the BESO and as a result, the filtering method can be understood by
the theorem of partition of unity and the convolution operator of low-pass
filter.
</summary>
    <author>
      <name>Jun-ichi Koga</name>
    </author>
    <author>
      <name>Jiro Koga</name>
    </author>
    <author>
      <name>Shunji Homma</name>
    </author>
    <link href="http://arxiv.org/abs/1309.5677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.6919v1</id>
    <updated>2013-09-26T14:30:13Z</updated>
    <published>2013-09-26T14:30:13Z</published>
    <title>Accurate Profiling of Microbial Communities from Massively Parallel
  Sequencing using Convex Optimization</title>
    <summary>  We describe the Microbial Community Reconstruction ({\bf MCR}) Problem, which
is fundamental for microbiome analysis. In this problem, the goal is to
reconstruct the identity and frequency of species comprising a microbial
community, using short sequence reads from Massively Parallel Sequencing (MPS)
data obtained for specified genomic regions. We formulate the problem
mathematically as a convex optimization problem and provide sufficient
conditions for identifiability, namely the ability to reconstruct species
identity and frequency correctly when the data size (number of reads) grows to
infinity. We discuss different metrics for assessing the quality of the
reconstructed solution, including a novel phylogenetically-aware metric based
on the Mahalanobis distance, and give upper-bounds on the reconstruction error
for a finite number of reads under different metrics. We propose a scalable
divide-and-conquer algorithm for the problem using convex optimization, which
enables us to handle large problems (with $\sim10^6$ species). We show using
numerical simulations that for realistic scenarios, where the microbial
communities are sparse, our algorithm gives solutions with high accuracy, both
in terms of obtaining accurate frequency, and in terms of species phylogenetic
resolution.
</summary>
    <author>
      <name>Or Zuk</name>
    </author>
    <author>
      <name>Amnon Amir</name>
    </author>
    <author>
      <name>Amit Zeisel</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Noam Shental</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in SPIRE 13</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.6919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.6919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7119v3</id>
    <updated>2017-01-07T00:01:32Z</updated>
    <published>2013-09-27T05:35:50Z</published>
    <title>Stock price direction prediction by directly using prices data: an
  empirical study on the KOSPI and HSI</title>
    <summary>  The prediction of a stock market direction may serve as an early
recommendation system for short-term investors and as an early financial
distress warning system for long-term shareholders. Many stock prediction
studies focus on using macroeconomic indicators, such as CPI and GDP, to train
the prediction model. However, daily data of the macroeconomic indicators are
almost impossible to obtain. Thus, those methods are difficult to be employed
in practice. In this paper, we propose a method that directly uses prices data
to predict market index direction and stock price direction. An extensive
empirical study of the proposed method is presented on the Korean Composite
Stock Price Index (KOSPI) and Hang Seng Index (HSI), as well as the individual
constituents included in the indices. The experimental results show notably
high hit ratios in predicting the movements of the individual constituents in
the KOSPI and HIS.
</summary>
    <author>
      <name>Yanshan Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1504/IJBIDM.2014.065091</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1504/IJBIDM.2014.065091" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in International Journal of Business Intelligence and Data Mining,
  2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.7119v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7119v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7688v1</id>
    <updated>2013-09-30T01:05:30Z</updated>
    <published>2013-09-30T01:05:30Z</published>
    <title>Evolution and development of complex computational systems using the
  paradigm of metabolic computing in Epigenetic Tracking</title>
    <summary>  Epigenetic Tracking (ET) is an Artificial Embryology system which allows for
the evolution and development of large complex structures built from artificial
cells. In terms of the number of cells, the complexity of the bodies generated
with ET is comparable with the complexity of biological organisms. We have
previously used ET to simulate the growth of multicellular bodies with
arbitrary 3-dimensional shapes which perform computation using the paradigm of
"metabolic computing". In this paper we investigate the memory capacity of such
computational structures and analyse the trade-off between shape and
computation. We now plan to build on these foundations to create a
biologically-inspired model in which the encoding of the phenotype is efficient
(in terms of the compactness of the genome) and evolvable in tasks involving
non-trivial computation, robust to damage and capable of self-maintenance and
self-repair.
</summary>
    <author>
      <name>Alessandro Fontana</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Adam Mickiewicz University</arxiv:affiliation>
    </author>
    <author>
      <name>Borys Wróbel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Adam Mickiewicz University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 27-34</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7691v1</id>
    <updated>2013-09-30T01:05:59Z</updated>
    <published>2013-09-30T01:05:59Z</published>
    <title>A model of protocell based on the introduction of a semi-permeable
  membrane in a stochastic model of catalytic reaction networks</title>
    <summary>  In this work we introduce some preliminary analyses on the role of a
semi-permeable membrane in the dynamics of a stochastic model of catalytic
reaction sets (CRSs) of molecules. The results of the simulations performed on
ensembles of randomly generated reaction schemes highlight remarkable
differences between this very simple protocell description model and the
classical case of the continuous stirred-tank reactor (CSTR). In particular, in
the CSTR case, distinct simulations with the same reaction scheme reach the
same dynamical equilibrium, whereas, in the protocell case, simulations with
identical reaction schemes can reach very different dynamical states, despite
starting from the same initial conditions.
</summary>
    <author>
      <name>Roberto Serra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Modena and Reggio Emilia</arxiv:affiliation>
    </author>
    <author>
      <name>Alessandro Filisetti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">European Centre for Living Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Alex Graudenzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Informatics, Systems and Communication University of Milan Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Chiara Damiani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Informatics, Systems and Communication University of Milan Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Marco Villani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Modena and Reggio Emilia</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 70-73</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7693v1</id>
    <updated>2013-09-30T01:06:23Z</updated>
    <published>2013-09-30T01:06:23Z</published>
    <title>Analysis of the spatial and dynamical properties of a multiscale model
  of intestinal crypts</title>
    <summary>  The preliminary analyses on a multiscale model of intestinal crypt dynamics
are here presented. The model combines a morphological model, based on the
Cellular Potts Model (CPM), and a gene regulatory network model, based on Noisy
Random Boolean Networks (NRBNs). Simulations suggest that the stochastic
differentiation process is itself sufficient to ensure the general homeostasis
in the asymptotic states, as proven by several measures.
</summary>
    <author>
      <name>Giulio Caravagna</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Sistemistica e Comunicazione, Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Alex Graudenzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Sistemistica e Comunicazione, Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Marco Antoniotti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dipartimento di Informatica, Sistemistica e Comunicazione, Università degli Studi di Milano-Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Giovanni de Matteis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics and Information Sciences, Northumbria University, Pandon Building, Camden Street, Newcastle Upon Tyne, England, U.K.</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.12" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 79-82</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7694v1</id>
    <updated>2013-09-30T01:06:30Z</updated>
    <published>2013-09-30T01:06:30Z</published>
    <title>Self Organizing Maps to efficiently cluster and functionally interpret
  protein conformational ensembles</title>
    <summary>  An approach that combines Self-Organizing maps, hierarchical clustering and
network components is presented, aimed at comparing protein conformational
ensembles obtained from multiple Molecular Dynamic simulations. As a first
result the original ensembles can be summarized by using only the
representative conformations of the clusters obtained. In addition the network
components analysis allows to discover and interpret the dynamic behavior of
the conformations won by each neuron. The results showed the ability of this
approach to efficiently derive a functional interpretation of the protein
dynamics described by the original conformational ensemble, highlighting its
potential as a support for protein engineering.
</summary>
    <author>
      <name>Domenico Fraccalvieri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Earth and Environmental Sciences, University of Milano Bicocca, Milano IT</arxiv:affiliation>
    </author>
    <author>
      <name>Laura Bonati</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Earth and Environmental Sciences, University of Milano Bicocca, Milano IT</arxiv:affiliation>
    </author>
    <author>
      <name>Fabio Stella</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Informatics, Systems and Communication, University of Milano Bicocca, Milano IT</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.13</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.13" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 83-86</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7695v1</id>
    <updated>2013-09-30T01:06:39Z</updated>
    <published>2013-09-30T01:06:39Z</published>
    <title>GPU-powered Simulation Methodologies for Biological Systems</title>
    <summary>  The study of biological systems witnessed a pervasive cross-fertilization
between experimental investigation and computational methods. This gave rise to
the development of new methodologies, able to tackle the complexity of
biological systems in a quantitative manner. Computer algorithms allow to
faithfully reproduce the dynamics of the corresponding biological system, and,
at the price of a large number of simulations, it is possible to extensively
investigate the system functioning across a wide spectrum of natural
conditions. To enable multiple analysis in parallel, using cheap, diffused and
highly efficient multi-core devices we developed GPU-powered simulation
algorithms for stochastic, deterministic and hybrid modeling approaches, so
that also users with no knowledge of GPUs hardware and programming can easily
access the computing power of graphics engines.
</summary>
    <author>
      <name>Daniela Besozzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Milano</arxiv:affiliation>
    </author>
    <author>
      <name>Giulio Caravagna</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Milano Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Cazzaniga</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bergamo</arxiv:affiliation>
    </author>
    <author>
      <name>Marco Nobile</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Milano Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Dario Pescini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Milano Bicocca</arxiv:affiliation>
    </author>
    <author>
      <name>Alessandro Re</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Milano Bicocca</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.130.14</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.130.14" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings Wivace 2013, arXiv:1309.7122</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 130, 2013, pp. 87-91</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3360v1</id>
    <updated>2013-10-12T11:08:54Z</updated>
    <published>2013-10-12T11:08:54Z</published>
    <title>A Probabilistic Approach to Risk Mapping for Mt. Etna</title>
    <summary>  We evaluate susceptibility to lava flows on Mt. Etna based on specially
designed die-toss experiments using probabilities for type, time and place of
activation from the volcano's 400-year recorded history and current studies on
its known fractures and fissures. The types of activations were forcast using a
table of probabilities for events, typed by duration and volume of ejecta.
Lengths of time were represented by the number of activations to expect within
a given time-frame, calculated assuming Poisson-distributed inter-arrival times
for activations. Locations of future activations were forecast with a
probability distribution function for activation probabilities. Most likely
scenarios for risk and resulting topography were generated for Etna's next
activation (average 7.76 years), the next 25, 50 and 100 years. Forecasts for
areas most likely affected are in good agreement with previous risk studies
made. Forecasts for risks of lava invasions, as well as future topographies
might be a first. Threats to lifelines are also discussed.
</summary>
    <author>
      <name>Vena Pearl Bongolan</name>
    </author>
    <author>
      <name>Rocco Rongo</name>
    </author>
    <author>
      <name>Valeria Lupiano</name>
    </author>
    <author>
      <name>Donato D'Ambrosio</name>
    </author>
    <author>
      <name>William Spataro</name>
    </author>
    <author>
      <name>Giulio Iovine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Most recent presentation of related material was at the IMACS 2013
  World Congress, August 26-30, 2013, San Lorenzo de El Escorial, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="86-08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.4495v1</id>
    <updated>2013-10-16T15:01:19Z</updated>
    <published>2013-10-16T15:01:19Z</published>
    <title>Multiple Attractor Cellular Automata (MACA) for Addressing Major
  Problems in Bioinformatics</title>
    <summary>  CA has grown as potential classifier for addressing major problems in
bioinformatics. Lot of bioinformatics problems like predicting the protein
coding region, finding the promoter region, predicting the structure of protein
and many other problems in bioinformatics can be addressed through Cellular
Automata. Even though there are some prediction techniques addressing these
problems, the approximate accuracy level is very less. An automated procedure
was proposed with MACA (Multiple Attractor Cellular Automata) which can address
all these problems. The genetic algorithm is also used to find rules with good
fitness values. Extensive experiments are conducted for reporting the accuracy
of the proposed tool. The average accuracy of MACA when tested with ENCODE,
BG570, HMR195, Fickett and Tongue, ASP67 datasets is 78%.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <author>
      <name>SSSN Usha Devi Nedunuri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1310.4342</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Review of Bioinformatics and Biometrics (RBB) Volume 2 Issue 3,
  September 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.4495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.4495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5022v1</id>
    <updated>2013-10-18T13:55:59Z</updated>
    <published>2013-10-18T13:55:59Z</published>
    <title>Division of the Energy Market into Zones in Variable Weather Conditions
  using Locational Marginal Prices</title>
    <summary>  Adopting a zonal structure of electricity market requires specification of
zones' borders. One of the approaches to identify zones is based on clustering
of Locational Marginal Prices (LMP). The purpose of the paper is twofold: (i)
we extend the LMP methodology by taking into account variable weather
conditions and (ii) we point out some weaknesses of the method and suggest
their potential solutions. The offered extension comprises simulations based on
the Optimal Power Flow (OPF) algorithm and twofold clustering method. First,
LMP are calculated by OPF for each of scenario representing different weather
conditions. Second, hierarchical clustering based on Ward's criterion is used
on each realization of the prices separately. Then, another clustering method,
i.e. consensus clustering, is used to aggregate the results from all
simulations and to find the global division into zones. The offered method of
aggregation is not limited only to LMP methodology and is universal.
</summary>
    <author>
      <name>Karol Wawrzyniak</name>
    </author>
    <author>
      <name>Grzegorz Orynczak</name>
    </author>
    <author>
      <name>Michal Klos</name>
    </author>
    <author>
      <name>Aneta Goska</name>
    </author>
    <author>
      <name>Marcin Jakubek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5025v1</id>
    <updated>2013-10-18T14:10:50Z</updated>
    <published>2013-10-18T14:10:50Z</published>
    <title>The Optimal Division of the Energy Market into Zones: Comparison of Two
  Methodologies under Variable Wind Conditions</title>
    <summary>  We compare two competing methodologies of market zones identification under
the criterion of social welfare maximization: (i) consensus clustering of
Locational Marginal Prices over different wind scenarios and (ii) congestion
contribution identification with congested lines identified across variable
wind generation outputs. We test the division of market into zones based on
each of the two methodologies using a welfare criterion, i.e., comparing the
cost of supplying energy on uniform market (including readjustments made on a
balancing market to overcome the congestion) with cost on k-zone market. A
division which maximizes the welfare is considered as the optimum.
</summary>
    <author>
      <name>Karol Wawrzyniak</name>
    </author>
    <author>
      <name>Michal Klos</name>
    </author>
    <author>
      <name>Grzegorz Orynczak</name>
    </author>
    <author>
      <name>Marcin Jakubek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6876v2</id>
    <updated>2013-12-10T16:39:16Z</updated>
    <published>2013-10-25T11:00:02Z</published>
    <title>Application of Fourier and Wavelet Transform for analysing 300 years
  Sunspot numbers to Explain the Solar Cycles</title>
    <summary>  In this paper Fourier Transform and Wavelet Transform are applied in case of
recent 300 years of sunspot numbers to explain the solar cycles. Here basically
parallel study of Fourier and Wavelet analysis are done and we have observed
that the better result can be obtained from Wavelet analysis during sunspot
number analysis. We are able to show various minima and maxima in the recent
ages of solar cycles with this tool. The exact periodicity and other possible
periodicities in the cyclic phenomenon of sunspot activity are determined.
</summary>
    <author>
      <name>Sabyasachi Mukhopadhyay</name>
    </author>
    <author>
      <name>Debadatta Dash</name>
    </author>
    <author>
      <name>Asish Mitra</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to some modifications
  are required for current paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6876v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6876v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.8583v1</id>
    <updated>2013-10-31T16:41:44Z</updated>
    <published>2013-10-31T16:41:44Z</published>
    <title>A Hybrid Local Search for Simplified Protein Structure Prediction</title>
    <summary>  Protein structure prediction based on Hydrophobic-Polar energy model
essentially becomes searching for a conformation having a compact hydrophobic
core at the center. The hydrophobic core minimizes the interaction energy
between the amino acids of the given protein. Local search algorithms can
quickly find very good conformations by moving repeatedly from the current
solution to its "best" neighbor. However, once such a compact hydrophobic core
is found, the search stagnates and spends enormous effort in quest of an
alternative core. In this paper, we attempt to restructure segments of a
conformation with such compact core. We select one large segment or a number of
small segments and apply exhaustive local search. We also apply a mix of
heuristics so that one heuristic can help escape local minima of another. We
evaluated our algorithm by using Face Centered Cubic (FCC) Lattice on a set of
standard benchmark proteins and obtain significantly better results than that
of the state-of-the-art methods.
</summary>
    <author>
      <name>Swakkhar Shatabda</name>
    </author>
    <author>
      <name>M. A. Hakim Newton</name>
    </author>
    <author>
      <name>Duc Nghia Pham</name>
    </author>
    <author>
      <name>Abdul Sattar</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Bioinformatics
  Models, Methods and Algorithms, Barcelona, Spain, 11 - 14 February, 2013.
  SciTePress 2013 ISBN 978-989-8565-35-8 pages:158-163</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.8583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.8583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0534v1</id>
    <updated>2013-11-03T21:42:26Z</updated>
    <published>2013-11-03T21:42:26Z</published>
    <title>Accurate curve fits of IAPWS data for high-pressure, high-temperature
  single-phase liquid water based on the stiffened gas equation of state</title>
    <summary>  We present a series of optimal (in the sense of least-squares) curve fits for
the stiffened gas equation of state for single-phase liquid water. At high
pressures and (subcritical) temperatures, the parameters produced by these
curve fits are found to have very small relative errors: less than $1\%$ in the
pressure model, and less than $2\%$ in the temperature model. At low pressures
and temperatures, especially near the liquid-vapor transition line, the error
in the curve fits increases rapidly. The smallest pressure value for which
curve fits are reported in the present work is 25 MPa, high enough to ensure
that the fluid remains a single-phase liquid up to the maximum subcritical
temperature of approximately 647K.
</summary>
    <author>
      <name>John W. Peterson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0790v2</id>
    <updated>2014-02-17T17:29:17Z</updated>
    <published>2013-11-04T17:48:27Z</published>
    <title>A Discontinuous Galerkin Time Domain Framework for Periodic Structures
  Subject To Oblique Excitation</title>
    <summary>  A nodal Discontinuous Galerkin (DG) method is derived for the analysis of
time-domain (TD) scattering from doubly periodic PEC/dielectric structures
under oblique interrogation. Field transformations are employed to elaborate a
formalism that is free from any issues with causality that are common when
applying spatial periodic boundary conditions simultaneously with incident
fields at arbitrary angles of incidence. An upwind numerical flux is derived
for the transformed variables, which retains the same form as it does in the
original Maxwell problem for domains without explicitly imposed periodicity.
This, in conjunction with the amenability of the DG framework to non-conformal
meshes, provides a natural means of accurately solving the first order TD
Maxwell equations for a number of periodic systems of engineering interest.
Results are presented that substantiate the accuracy and utility of our method.
</summary>
    <author>
      <name>Nicholas C. Miller</name>
    </author>
    <author>
      <name>Andrew D. Baczewski</name>
    </author>
    <author>
      <name>John D. Albrecht</name>
    </author>
    <author>
      <name>Balasubramaniam Shanker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAP.2014.2324012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAP.2014.2324012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE TAP on August 5th, 2013. Revision submitted on
  February 3rd, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0790v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0790v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3837v1</id>
    <updated>2013-11-15T12:58:28Z</updated>
    <published>2013-11-15T12:58:28Z</published>
    <title>SBML for optimizing decision support's tools</title>
    <summary>  Many theoretical works and tools on epidemiological field reflect the
emphasis on decision-making Tools by both public health and the scientific
community, which continues to increase. Indeed, in the epidemiological field,
modeling tools are proving a very important way in helping to make decision.
However, the variety, the large volume of data and the nature of epidemics lead
us to seek solutions to alleviate the heavy burden imposed on both experts and
developers. In this paper, we present a new approach: the passage of an
epidemic model realized in Bio-PEPA to a narrative language using the basics of
SBML language. Our goal is to allow on one hand, epidemiologists to verify and
validate the model, and the other hand, developers to optimize the model in
order to achieve a better model of decision making. We also present some
preliminary results and some suggestions to improve the simulated model.
</summary>
    <author>
      <name>Dalila Hamami</name>
    </author>
    <author>
      <name>Baghdad Atmani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/csit.2013.3810</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/csit.2013.3810" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Aircc.Proc. 3.8 (2013) 109-119</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1311.3837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3840v1</id>
    <updated>2013-11-15T13:09:19Z</updated>
    <published>2013-11-15T13:09:19Z</published>
    <title>Mixing Energy Models in Genetic Algorithms for On-Lattice Protein
  Structure Prediction</title>
    <summary>  Protein structure prediction (PSP) is computationally a very challenging
problem. The challenge largely comes from the fact that the energy function
that needs to be minimised in order to obtain the native structure of a given
protein is not clearly known. A high resolution 20x20 energy model could better
capture the behaviour of the actual energy function than a low resolution
energy model such as hydrophobic polar. However, the fine grained details of
the high resolution interaction energy matrix are often not very informative
for guiding the search. In contrast, a low resolution energy model could
effectively bias the search towards certain promising directions. In this
paper, we develop a genetic algorithm that mainly uses a high resolution energy
model for protein structure evaluation but uses a low resolution HP energy
model in focussing the search towards exploring structures that have
hydrophobic cores. We experimentally show that this mixing of energy models
leads to significant lower energy structures compared to the state-of-the-art
results.
</summary>
    <author>
      <name>Mahmood A. Rashid</name>
    </author>
    <author>
      <name>M. A. Hakim Newton</name>
    </author>
    <author>
      <name>Md. Tamjidul Hoque</name>
    </author>
    <author>
      <name>Abdul Sattar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1155/2013/924137</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1155/2013/924137" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Volume 2013, 15 pages, BioMed Research International, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4570v1</id>
    <updated>2013-11-18T22:10:14Z</updated>
    <published>2013-11-18T22:10:14Z</published>
    <title>Numerical modeling of friction stir welding process: a literature review</title>
    <summary>  This survey presents a literature review on friction stir welding (FSW)
modeling with a special focus on the heat generation due to the contact
conditions between the FSW tool and the workpiece. The physical process is
described and the main process parameters that are relevant to its modeling are
highlighted. The contact conditions (sliding/sticking) are presented as well as
an analytical model that allows estimating the associated heat generation. The
modeling of the FSW process requires the knowledge of the heat loss mechanisms,
which are discussed mainly considering the more commonly adopted formulations.
Different approaches that have been used to investigate the material flow are
presented and their advantages/drawbacks are discussed. A reliable FSW process
modeling depends on the fine tuning of some process and material parameters.
Usually, these parameters are achieved with base on experimental data. The
numerical modeling of the FSW process can help to achieve such parameters with
less effort and with economic advantages.
</summary>
    <author>
      <name>Diogo Mariano Neto</name>
    </author>
    <author>
      <name>Pedro Neto</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00170-012-4154-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00170-012-4154-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Advanced Manufacturing Technology</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Volume 65, 2013 , pp 115-126</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1311.4570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6460v1</id>
    <updated>2013-11-25T20:59:34Z</updated>
    <published>2013-11-25T20:59:34Z</published>
    <title>Wavelet Transform-Based Analysis of QRS complex in ECG Signals</title>
    <summary>  In the present paper we have reported a wavelet based time-frequency
multiresolution analysis of an ECG signal. The ECG (electrocardiogram), which
records hearts electrical activity, is able to provide with useful information
about the type of Cardiac disorders suffered by the patient depending upon the
deviations from normal ECG signal pattern. We have plotted the coefficients of
continuous wavelet transform using Morlet wavelet. We used different ECG signal
available at MIT-BIH database and performed a comparative study. We
demonstrated that the coefficient at a particular scale represents the presence
of QRS signal very efficiently irrespective of the type or intensity of noise,
presence of unusually high amplitude of peaks other than QRS peaks and Base
line drift errors. We believe that the current studies can enlighten the path
towards development of very lucid and time efficient algorithms for identifying
and representing the QRS complexes that can be done with normal computers and
processors.
</summary>
    <author>
      <name>Swapnil Barmase</name>
    </author>
    <author>
      <name>Saurav Das</name>
    </author>
    <author>
      <name>Sabyasachi Mukhopadhyay</name>
    </author>
    <link href="http://arxiv.org/abs/1311.6460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.0465v1</id>
    <updated>2013-12-02T14:14:04Z</updated>
    <published>2013-12-02T14:14:04Z</published>
    <title>A pattern-driven approach to biomedical ontology engineering</title>
    <summary>  Developing ontologies can be expensive, time-consuming, as well as difficult
to develop and maintain. This is especially true for more expressive and/or
larger ontologies. Some ontologies are, however, relatively repetitive, reusing
design patterns; building these with both generic and bespoke patterns should
reduce duplication and increase regularity which in turn should impact on the
cost of development.
  Here we report on the usage of patterns applied to two biomedical ontologies:
firstly a novel ontology for karyotypes which has been built ground-up using a
pattern based approach; and, secondly, our initial refactoring of the SIO
ontology to make explicit use of patterns at development time. To enable this,
we use the Tawny-OWL library which enables full-programmatic development of
ontologies. We show how this approach can generate large numbers of classes
from much simpler data structures which is highly beneficial within biomedical
ontology engineering.
</summary>
    <author>
      <name>Jennifer D. Warrender</name>
    </author>
    <author>
      <name>Phillip Lord</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, submitted to SWAT4LS 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.0465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.0465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2140v1</id>
    <updated>2013-12-07T20:27:20Z</updated>
    <published>2013-12-07T20:27:20Z</published>
    <title>A Comparative Study on Remote Tracking of Parkinsons Disease Progression
  Using Data Mining Methods</title>
    <summary>  In recent years, applications of data mining methods are become more popular
in many fields of medical diagnosis and evaluations. The data mining methods
are appropriate tools for discovering and extracting of available knowledge in
medical databases. In this study, we divided 11 data mining algorithms into
five groups which are applied to a data set of patients clinical variables data
with Parkinsons Disease (PD) to study the disease progression. The data set
includes 22 properties of 42 people that all of our algorithms are applied to
this data set. The Decision Table with 0.9985 correlation coefficients has the
best accuracy and Decision Stump with 0.7919 correlation coefficients has the
lowest accuracy.
</summary>
    <author>
      <name>Peyman Mohammadi</name>
    </author>
    <author>
      <name>Abdolreza Hatamlou</name>
    </author>
    <author>
      <name>Mohammad Masdari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages, 4 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.2140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2841v1</id>
    <updated>2013-12-10T15:50:39Z</updated>
    <published>2013-12-10T15:50:39Z</published>
    <title>Predictive Comparative QSAR Analysis Of As 5-Nitofuran-2-YL Derivatives
  Myco bacterium tuberculosis H37RV Inhibitors Bacterium Tuberculosis H37RV
  Inhibitors</title>
    <summary>  Antitubercular activity of 5-nitrofuran-2-yl Derivatives series were
subjected to Quantitative Structure Activity Relationship (QSAR) Analysis with
an effort to derive and understand a correlation between the biological
activity as response variable and different molecular descriptors as
independent variables. QSAR models are built using 40 molecular descriptor
dataset. Different statistical regression expressions were got using Partial
Least Squares (PLS),Multiple Linear Regression (MLR) and Principal Component
Regression (PCR) techniques. The among these technique, Partial Least Square
Regression (PLS) technique has shown very promising result as compared to MLR
technique A QSAR model was build by a training set of 30 molecules with
correlation coefficient ($r^2$) of 0.8484, significant cross validated
correlation coefficient ($q^2$) is 0.0939, F test is 48.5187, ($r^2$) for
external test set (pred$_r^2$) is -0.5604, coefficient of correlation of
predicted data set (pred$_r^2se$) is 0.7252 and degree of freedom is 26 by
Partial Least Squares Regression technique.
</summary>
    <author>
      <name> Doreswamy</name>
    </author>
    <author>
      <name>Chanabasayya . M. Vastrad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/hiij.2013.2404</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/hiij.2013.2404" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">published Health Informatics- An International Journal (HIIJ)
  Vol.2, No.4, November 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.2841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2859v1</id>
    <updated>2013-12-10T16:24:28Z</updated>
    <published>2013-12-10T16:24:28Z</published>
    <title>A Robust Missing Value Imputation Method MifImpute For Incomplete
  Molecular Descriptor Data And Comparative Analysis With Other Missing Value
  Imputation Methods</title>
    <summary>  Missing data imputation is an important research topic in data mining.
Large-scale Molecular descriptor data may contains missing values (MVs).
However, some methods for downstream analyses, including some prediction tools,
require a complete descriptor data matrix. We propose and evaluate an iterative
imputation method MiFoImpute based on a random forest. By averaging over many
unpruned regression trees, random forest intrinsically constitutes a multiple
imputation scheme. Using the NRMSE and NMAE estimates of random forest, we are
able to estimate the imputation error. Evaluation is performed on two molecular
descriptor datasets generated from a diverse selection of pharmaceutical fields
with artificially introduced missing values ranging from 10% to 30%. The
experimental result demonstrates that missing values has a great impact on the
effectiveness of imputation techniques and our method MiFoImpute is more robust
to missing value than the other ten imputation methods used as benchmark.
Additionally, MiFoImpute exhibits attractive computational efficiency and can
cope with high-dimensional data.
</summary>
    <author>
      <name> Doreswamy</name>
    </author>
    <author>
      <name>Chanabasayya . M. Vastrad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsa.2013.3406</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsa.2013.3406" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1105.0828 by other authors
  without attribution</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published International Journal on Computational Sciences &amp;
  Applications (IJCSA) Vol.3, No4, August 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.2859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2861v1</id>
    <updated>2013-12-10T16:35:25Z</updated>
    <published>2013-12-10T16:35:25Z</published>
    <title>Identification Of Outliers In Oxazolines AND Oxazoles High Dimension
  Molecular Descriptor Dataset Using Principal Component Outlier Detection
  Algorithm And Comparative Numerical Study Of Other Robust Estimators</title>
    <summary>  From the past decade outlier detection has been in use. Detection of outliers
is an emerging topic and is having robust applications in medical sciences and
pharmaceutical sciences. Outlier detection is used to detect anomalous
behaviour of data. Typical problems in Bioinformatics can be addressed by
outlier detection. A computationally fast method for detecting outliers is
shown, that is particularly effective in high dimensions. PrCmpOut algorithm
make use of simple properties of principal components to detect outliers in the
transformed space, leading to significant computational advantages for high
dimensional data. This procedure requires considerably less computational time
than existing methods for outlier detection. The properties of this estimator
(Outlier error rate (FN), Non-Outlier error rate(FP) and computational costs)
are analyzed and compared with those of other robust estimators described in
the literature through simulation studies. Numerical evidence based Oxazolines
and Oxazoles molecular descriptor dataset shows that the proposed method
performs well in a variety of situations of practical interest. It is thus a
valuable companion to the existing outlier detection methods.
</summary>
    <author>
      <name> Doreswamy</name>
    </author>
    <author>
      <name>Chanabasayya . M. Vastrad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdkp.2013.3405</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdkp.2013.3405" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published International Journal of Data Mining &amp; Knowledge
  Management Process (IJDKP) Vol.3, No.4, July 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.2861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3808v1</id>
    <updated>2013-12-13T13:45:52Z</updated>
    <published>2013-12-13T13:45:52Z</published>
    <title>Information Maps: A Practical Approach to Position Dependent
  Parameterization</title>
    <summary>  In this contribution a practical approach to determine and store position
dependent parameters is presented. These parameters can be obtained, among
others, using experimental results or expert knowledge and are stored in
'Information Maps'. Each Information Map can be interpreted as a kind of static
grid map and the framework allows to link different maps hierarchically. The
Information Maps can be local or global, with static and dynamic information in
it. One application of Information Maps is the representation of position
dependent characteristics of a sensor. Thus, for instance, it is feasible to
store arbitrary attributes of a sensor's preprocessing in an Information Map
and utilize them by simply taking the map value at the current position. This
procedure is much more efficient than using the attributes of the sensor
itself. Some examples where and how Information Maps can be used are presented
in this publication. The Information Map is meant to be a simple and practical
approach to the problem of position dependent parameterization in all kind of
algorithms when the analytical description is not possible or can not be
implemented efficiently.
</summary>
    <author>
      <name>Benjamin wilking</name>
    </author>
    <author>
      <name>Daniel Meissner</name>
    </author>
    <author>
      <name>Stephan Reuter</name>
    </author>
    <author>
      <name>Klaus Dietmayer</name>
    </author>
    <link href="http://arxiv.org/abs/1312.3808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5354v2</id>
    <updated>2014-07-28T09:44:01Z</updated>
    <published>2013-12-18T22:08:07Z</published>
    <title>Classification of Human Ventricular Arrhythmia in High Dimensional
  Representation Spaces</title>
    <summary>  We studied classification of human ECGs labelled as normal sinus rhythm,
ventricular fibrillation and ventricular tachycardia by means of support vector
machines in different representation spaces, using different observation
lengths. ECG waveform segments of duration 0.5-4 s, their Fourier magnitude
spectra, and lower dimensional projections of Fourier magnitude spectra were
used for classification. All considered representations were of much higher
dimension than in published studies. Classification accuracy improved with
segment duration up to 2 s, with 4 s providing little improvement. We found
that it is possible to discriminate between ventricular tachycardia and
ventricular fibrillation by the present approach with much shorter runs of ECG
(2 s, minimum 86% sensitivity per class) than previously imagined. Ensembles of
classifiers acting on 1 s segments taken over 5 s observation windows gave best
results, with sensitivities of detection for all classes exceeding 93%.
</summary>
    <author>
      <name>Yaqub Alwan</name>
    </author>
    <author>
      <name>Zoran Cvetkovic</name>
    </author>
    <author>
      <name>Michael Curtis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 tables, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5354v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5354v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1152v3</id>
    <updated>2015-01-09T14:24:19Z</updated>
    <published>2014-01-06T17:42:41Z</published>
    <title>Hygro-thermo-mechanical analysis of spalling in concrete walls at high
  temperatures as a moving boundary problem</title>
    <summary>  A mathematical model allowing coupled hygro-thermo-mechanical analysis of
spalling in concrete walls at high temperatures by means of the moving boundary
problem is presented. A simplified mechanical approach to account for effects
of thermal stresses and pore pressure build-up on spalling is incorporated into
the model. The numerical algorithm based on finite element discretization in
space and the semi-implicit method for discretization in time is presented. The
validity of the developed model is carefully examined by a comparison between
experimental tests performed by Kalifa et al. (2000) and Mindeguia (2009) on
concrete prismatic specimens under unidirectional heating of temperature of 600
${\deg}$C and ISO 834 fire curve and the results obtained from the numerical
model.
</summary>
    <author>
      <name>Michal Beneš</name>
    </author>
    <author>
      <name>Radek Štefan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijheatmasstransfer.2015.01.050</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijheatmasstransfer.2015.01.050" rel="related"/>
    <link href="http://arxiv.org/abs/1401.1152v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1152v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1308v1</id>
    <updated>2014-01-07T08:32:54Z</updated>
    <published>2014-01-07T08:32:54Z</published>
    <title>Dynamic Assignment in Microsimulations of Pedestrians</title>
    <summary>  A generic method for dynamic assignment used with microsimulation of
pedestrian dynamics is introduced. As pedestrians - unlike vehicles - do not
move on a network, but on areas they in principle can choose among an infinite
number of routes. To apply assignment algorithms one has to select for each OD
pair a finite (realistically a small) number of relevant representatives from
these routes. This geometric task is the main focus of this contribution. The
main task is to find for an OD pair the relevant routes to be used with common
assignment methods. The method is demonstrated for one single OD pair and
exemplified with an example.
</summary>
    <author>
      <name>Tobias Kretz</name>
    </author>
    <author>
      <name>Karsten Lehmann</name>
    </author>
    <author>
      <name>Ingmar Hofsäß</name>
    </author>
    <author>
      <name>Axel Leonhardt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contribution to 93rd Annual Meeting of the Transportation Research
  Board (TRB) 2014. Contribution no. 14-0941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in Annual Meeting of the Transportation Research Board, 14-0941
  (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.1308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1916v1</id>
    <updated>2014-01-09T07:58:06Z</updated>
    <published>2014-01-09T07:58:06Z</published>
    <title>Multiple-output support vector regression with a firefly algorithm for
  interval-valued stock price index forecasting</title>
    <summary>  Highly accurate interval forecasting of a stock price index is fundamental to
successfully making a profit when making investment decisions, by providing a
range of values rather than a point estimate. In this study, we investigate the
possibility of forecasting an interval-valued stock price index series over
short and long horizons using multi-output support vector regression (MSVR).
Furthermore, this study proposes a firefly algorithm (FA)-based approach, built
on the established MSVR, for determining the parameters of MSVR (abbreviated as
FA-MSVR). Three globally traded broad market indices are used to compare the
performance of the proposed FA-MSVR method with selected counterparts. The
quantitative and comprehensive assessments are performed on the basis of
statistical criteria, economic criteria, and computational cost. In terms of
statistical criteria, we compare the out-of-sample forecasting using
goodness-of-forecast measures and testing approaches. In terms of economic
criteria, we assess the relative forecast performance with a simple trading
strategy. The results obtained in this study indicate that the proposed FA-MSVR
method is a promising alternative for forecasting interval-valued financial
time series.
</summary>
    <author>
      <name>Tao Xiong</name>
    </author>
    <author>
      <name>Yukun Bao</name>
    </author>
    <author>
      <name>Zhongyi Hu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.knosys.2013.10.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.knosys.2013.10.012" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Knowledge-based Systems. 55, 2013:87-100</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.1916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.2000v1</id>
    <updated>2014-01-09T13:44:28Z</updated>
    <published>2014-01-09T13:44:28Z</published>
    <title>A model project for reproducible papers: critical temperature for the
  Ising model on a square lattice</title>
    <summary>  In this paper we present a simple, yet typical simulation in statistical
physics, consisting of large scale Monte Carlo simulations followed by an
involved statistical analysis of the results. The purpose is to provide an
example publication to explore tools for writing reproducible papers. The
simulation estimates the critical temperature where the Ising model on the
square lattice becomes magnetic to be Tc /J = 2.26934(6) using a finite size
scaling analysis of the crossing points of Binder cumulants. We provide a
virtual machine which can be used to reproduce all figures and results.
</summary>
    <author>
      <name>M. Dolfi</name>
    </author>
    <author>
      <name>J. Gukelberger</name>
    </author>
    <author>
      <name>A. Hehn</name>
    </author>
    <author>
      <name>J. Imriška</name>
    </author>
    <author>
      <name>K. Pakrouski</name>
    </author>
    <author>
      <name>T. F. Rønnow</name>
    </author>
    <author>
      <name>M. Troyer</name>
    </author>
    <author>
      <name>I. Zintchenko</name>
    </author>
    <author>
      <name>F. Chirigati</name>
    </author>
    <author>
      <name>J. Freire</name>
    </author>
    <author>
      <name>D. Shasha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Authors are listed in alphabetical order by institution and name. 5
  pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.2000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.2000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5162v1</id>
    <updated>2014-01-21T03:20:10Z</updated>
    <published>2014-01-21T03:20:10Z</published>
    <title>A Simple Software Application for Simulating Commercially Available
  Solar Panels</title>
    <summary>  This article addresses the formulation and validation of a simple PC based
software application developed for simulating commercially available solar
panels. The important feature of this application is its capability to produce
speedy results in the form of solar panel output characteristics at given
environmental conditions by using minimal input data. Besides, it is able to
deliver critical information about the maximum power point of the panel at a
given environmental condition in quick succession. The application is based on
a standard equation which governs solar panels and works by means of estimating
unknown parameters in the equation to fit a given solar panel. The process of
parameter estimation is described in detail with the aid of equations and data
of a commercial solar panel. A validation of obtained results for commercial
solar panels is also presented by comparing the panel manufacturers' results
with the results generated by the application. In addition, implications of the
obtained results are discussed along with possible improvements to the
developed software application.
</summary>
    <author>
      <name>Nalika Ulapane</name>
    </author>
    <author>
      <name>Sunil Abeyratne</name>
    </author>
    <author>
      <name>Prabath Binduhewa</name>
    </author>
    <author>
      <name>Chamari Dhanapala</name>
    </author>
    <author>
      <name>Shyama Wickramasinghe</name>
    </author>
    <author>
      <name>Nimal Rathnayake</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7321/jscse.v2.n5.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7321/jscse.v2.n5.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 8 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Soft Computing And Software Engineering
  (JSCSE) e-ISSN: 2251-7545 Vol.2, No.5, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.5162v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5162v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6484v1</id>
    <updated>2014-01-25T01:48:14Z</updated>
    <published>2014-01-25T01:48:14Z</published>
    <title>Identification of Protein Coding Regions in Genomic DNA Using
  Unsupervised FMACA Based Pattern Classifier</title>
    <summary>  Genes carry the instructions for making proteins that are found in a cell as
a specific sequence of nucleotides that are found in DNA molecules. But, the
regions of these genes that code for proteins may occupy only a small region of
the sequence. Identifying the coding regions play a vital role in understanding
these genes. In this paper we propose a unsupervised Fuzzy Multiple Attractor
Cellular Automata (FMCA) based pattern classifier to identify the coding region
of a DNA sequence. We propose a distinct K-Means algorithm for designing FMACA
classifier which is simple, efficient and produces more accurate classifier
than that has previously been obtained for a range of different sequence
lengths. Experimental results confirm the scalability of the proposed
Unsupervised FCA based classifier to handle large volume of datasets
irrespective of the number of classes, tuples and attributes. Good
classification accuracy has been established.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1312.2642</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSNS International Journal of Computer Science and Network
  Security, VOL.8 No.1, January 2008,305-310</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.6484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.8192v3</id>
    <updated>2014-08-06T09:45:46Z</updated>
    <published>2014-01-31T15:28:12Z</published>
    <title>The Scheme of a Novel Methodology for Zonal Division Based on Power
  Transfer Distribution Factors</title>
    <summary>  One of the methodologies that carry out the division of the electrical grid
into zones is based on the aggregation of nodes characterized by similar Power
Transfer Distribution Factors (PTDFs). Here, we point out that satisfactory
clustering algorithm should take into account two aspects. First, nodes of
similar impact on cross-border lines should be grouped together. Second,
cross-border power flows should be relatively insensitive to differences
between real and assumed Generation Shift Key matrices. We introduce a
theoretical basis of a novel clustering algorithm (BubbleClust) that fulfills
these requirements and we perform a case study to illustrate social welfare
consequences of the division.
</summary>
    <author>
      <name>Michal Klos</name>
    </author>
    <author>
      <name>Karol Wawrzyniak</name>
    </author>
    <author>
      <name>Marcin Jakubek</name>
    </author>
    <author>
      <name>Grzegorz Orynczak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.8192v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.8192v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1485v1</id>
    <updated>2014-02-06T20:55:49Z</updated>
    <published>2014-02-06T20:55:49Z</published>
    <title>Uncertainty Propagation in Elasto-Plastic Material</title>
    <summary>  Macroscopically heterogeneous materials, characterised mostly by comparable
heterogeneity lengthscale and structural sizes, can no longer be modelled by
deterministic approach instead. It is convenient to introduce stochastic
approach with uncertain material parameters quantified as random fields and/or
random variables. The present contribution is devoted to propagation of these
uncertainties in mechanical modelling of inelastic behaviour. In such case the
Monte Carlo method is the traditional approach for solving the proposed
problem. Nevertheless, convergence rate is relatively slow, thus new methods
(e.g. stochastic Galerkin method, stochastic collocation approach, etc.) have
been recently developed to offer fast convergence for sufficiently smooth
solution in the probability space. Our goal is to accelerate the uncertainty
propagation using a polynomial chaos expansion based on stochastic collocation
method. The whole concept is demonstrated on a simple numerical example of
uniaxial test at a material point where interesting phenomena can be clearly
understood.
</summary>
    <author>
      <name>Jan Sýkora</name>
    </author>
    <author>
      <name>Anna Kučerová</name>
    </author>
    <link href="http://arxiv.org/abs/1402.1485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1637v1</id>
    <updated>2014-02-07T13:42:54Z</updated>
    <published>2014-02-07T13:42:54Z</published>
    <title>Vertical Clustering of 3D Elliptical Helical Data</title>
    <summary>  This research proposes an effective vertical clustering strategy of 3D data
in an elliptical helical shape based on 2D geometry. The clustering object is
an elliptical cross-sectioned metal pipe which is been bended in to an
elliptical helical shape which is used in wearable muscle support designing for
welfare industry. The aim of this proposed method is to maximize the vertical
clustering (vertical partitioning) ability of surface data in order to run the
product evaluation process addressed in research [2]. The experiment results
prove that the proposed method outperforms the existing threshold no of
clusters that preserves the vertical shape than applying the conventional 3D
data. This research also proposes a new product testing strategy that provides
the flexibility in computer aided testing by not restricting the sequence
depending measurements which apply weight on measuring process. The clustering
algorithms used for the experiments in this research are self-organizing map
(SOM) and K-medoids.
</summary>
    <author>
      <name>Wasantha Samarathunga</name>
    </author>
    <author>
      <name>Masatoshi Seki</name>
    </author>
    <author>
      <name>Hidenobu Saito</name>
    </author>
    <author>
      <name>Ken Ichiryu</name>
    </author>
    <author>
      <name>Yasuhiro Ohyama</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology, volume 6
  number 2,Dec 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.1637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2440v1</id>
    <updated>2014-02-11T10:59:00Z</updated>
    <published>2014-02-11T10:59:00Z</published>
    <title>Validation Experiments for LBM Simulations of Electron Beam Melting</title>
    <summary>  This paper validates 3D simulation results of electron beam melting (EBM)
processes comparing experimental and numerical data. The physical setup is
presented which is discretized by a three dimensional (3D) thermal lattice
Boltzmann method (LBM). An experimental process window is used for the
validation depending on the line energy injected into the metal powder bed and
the scan velocity of the electron beam. In the process window the EBM products
are classified into the categories, porous, good and swelling, depending on the
quality of the surface. The same parameter sets are used to generate a
numerical process window. A comparison of numerical and experimental process
windows shows a good agreement. This validates the EBM model and justifies
simulations for future improvements of EBM processes. In particular numerical
simulations can be used to explain future process window scenarios and find the
best parameter set for a good surface quality and dense products.
</summary>
    <author>
      <name>Regina Ammer</name>
    </author>
    <author>
      <name>Matthias Markl</name>
    </author>
    <author>
      <name>Vera Jüchter</name>
    </author>
    <author>
      <name>Carolin Körner</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to "International Journal of Modern Physics C"</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.2440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2845v2</id>
    <updated>2014-08-04T18:06:35Z</updated>
    <published>2014-02-12T15:16:11Z</published>
    <title>Efficient Localization of Discontinuities in Complex Computational
  Simulations</title>
    <summary>  Surrogate models for computational simulations are input-output
approximations that allow computationally intensive analyses, such as
uncertainty propagation and inference, to be performed efficiently. When a
simulation output does not depend smoothly on its inputs, the error and
convergence rate of many approximation methods deteriorate substantially. This
paper details a method for efficiently localizing discontinuities in the input
parameter domain, so that the model output can be approximated as a piecewise
smooth function. The approach comprises an initialization phase, which uses
polynomial annihilation to assign function values to different regions and thus
seed an automated labeling procedure, followed by a refinement phase that
adaptively updates a kernel support vector machine representation of the
separating surface via active learning. The overall approach avoids structured
grids and exploits any available simplicity in the geometry of the separating
surface, thus reducing the number of model evaluations required to localize the
discontinuity. The method is illustrated on examples of up to eleven
dimensions, including algebraic models and ODE/PDE systems, and demonstrates
improved scaling and efficiency over other discontinuity localization
approaches.
</summary>
    <author>
      <name>Alex A. Gorodetsky</name>
    </author>
    <author>
      <name>Youssef M. Marzouk</name>
    </author>
    <link href="http://arxiv.org/abs/1402.2845v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2845v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3173v1</id>
    <updated>2014-02-13T15:10:26Z</updated>
    <published>2014-02-13T15:10:26Z</published>
    <title>Homogenization of coupled heat and moisture transport in masonry
  structures including interfaces</title>
    <summary>  Homogenization of a simultaneous heat and moisture flow in a masonry wall is
presented in this paper. The principle objective is to examine an impact of the
assumed imperfect hydraulic contact on the resulting homogenized properties.
Such a contact is characterized by a certain mismatching resistance allowing us
to represent a discontinuous evolution of temperature and moisture fields
across the interface, which is in general attributed to discontinuous capillary
pressures caused by different pore size distributions of the adjacent porous
materials. In achieving this, two particular laboratory experiments were
performed to provide distributions of temperature and relative humidity in a
sample of the masonry wall, which in turn served to extract the corresponding
jumps and subsequently to obtain the required interface transition parameters
by matching numerical predictions and experimental results. The results suggest
a low importance of accounting for imperfect hydraulic contact for the
derivation of macroscopic homogenized properties. On the other hand, they
strongly support the need for a fully coupled multi-scale analysis due to
significant dependence of the homogenized properties on actual moisture
gradients and corresponding values of both macroscopic temperature and relative
humidity.
</summary>
    <author>
      <name>Jan Sýkora</name>
    </author>
    <author>
      <name>Michal Šejnoha</name>
    </author>
    <author>
      <name>Jiří Šejnoha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.amc.2011.02.050</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.amc.2011.02.050" rel="related"/>
    <link href="http://arxiv.org/abs/1402.3173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4101v1</id>
    <updated>2014-02-17T19:56:22Z</updated>
    <published>2014-02-17T19:56:22Z</published>
    <title>First steps to Virtual Mammography: Simulating external compressions of
  the breast with the Surface Evolver</title>
    <summary>  In this paper we introduce a computational modelling that reproduces the
breast compression processes used to obtain the mammogram. The main result is a
programme in which one can track the first steps of virtual mammography. On the
one hand, our modelling enables addition of structures that represent different
tissues, muscles and glands in the breast. On the other hand, we shall validate
and implement it by means of laboratory tests with phantoms. To the best of our
knowledge, these two characteristics do confer originality to our research.
This is because their interrelation seems not to be properly established
elsewhere yet. We conclude that our model reproduces the same shapes and
measurements really taken from the volunteer's breasts.
</summary>
    <author>
      <name>Marcelo Zanchetta do Nascimento</name>
    </author>
    <author>
      <name>Valério Ramos Batista</name>
    </author>
    <link href="http://arxiv.org/abs/1402.4101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5466v1</id>
    <updated>2014-02-22T02:52:52Z</updated>
    <published>2014-02-22T02:52:52Z</published>
    <title>Predictive Comparative QSAR analysis of Sulfathiazole Analogues as
  Mycobacterium Tuberculosis H37RV Inhabitors</title>
    <summary>  Antitubercular activity of Sulfathiazole Derivitives series were subjected to
Quantitative Structure Activity Relationship (QSAR) Analysis with an attempt to
derive and understand a correlation between the Biologically Activity as
dependent variable and various descriptors as independent variables. QSAR
models generated using 28 compounds. Several statistical regression expressions
were obtained using Partial Least Squares (PLS) Regression, Multiple Linear
Regression (MLR) and Principal Component Regression (PCR) methods. The among
these methods, Partial Least Square Regression (PLS) method has shown very
promising result as compare to other two methods. A QSAR model was generated by
a training set of 18 molecules with correlation coefficient r (r square) of
0.9191, significant cross validated correlation coefficient (q square) of
0.8300, F test of 53.5783, r square for external test set pred_r square
-3.6132, coefficient of correlation of predicted data set pred_r_se square
1.4859 and degree of freedom 14 by Partial Least Squares Regression Method.
</summary>
    <author>
      <name> Doreswamy</name>
    </author>
    <author>
      <name>Chanabasyya M. Vastrad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1312.2841</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">published 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.5466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6366v1</id>
    <updated>2014-02-25T23:02:08Z</updated>
    <published>2014-02-25T23:02:08Z</published>
    <title>LSSVM-ABC Algorithm for Stock Price prediction</title>
    <summary>  In this paper, Artificial Bee Colony (ABC) algorithm which inspired from the
behavior of honey bees swarm is presented. ABC is a stochastic population-based
evolutionary algorithm for problem solving. ABC algorithm, which is considered
one of the most recently swarm intelligent techniques, is proposed to optimize
least square support vector machine (LSSVM) to predict the daily stock prices.
The proposed model is based on the study of stocks historical data, technical
indicators and optimizing LSSVM with ABC algorithm. ABC selects best free
parameters combination for LSSVM to avoid over-fitting and local minima
problems and improve prediction accuracy. LSSVM optimized by Particle swarm
optimization (PSO) algorithm, LSSVM, and ANN techniques are used for comparison
with proposed model. Proposed model tested with twenty datasets representing
different sectors in S&amp;P 500 stock market. Results presented in this paper show
that the proposed model has fast convergence speed, and it also achieves better
accuracy than compared techniques in most cases.
</summary>
    <author>
      <name>Osman Hegazy</name>
    </author>
    <author>
      <name>Omar S. Soliman</name>
    </author>
    <author>
      <name>Mustafa Abdul Salam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. International Journal of Computer Trends and Technology
  (IJCTT)2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.6366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6636v1</id>
    <updated>2014-02-19T10:21:34Z</updated>
    <published>2014-02-19T10:21:34Z</published>
    <title>Analysis of Multibeam SONAR Data using Dissimilarity Representations</title>
    <summary>  This paper considers the problem of low-dimensional visualisation of very
high dimensional information sources for the purpose of situation awareness in
the maritime environment. In response to the requirement for human decision
support aids to reduce information overload (and specifically, data amenable to
inter-point relative similarity measures) appropriate to the below-water
maritime domain, we are investigating a preliminary prototype topographic
visualisation model. The focus of the current paper is on the mathematical
problem of exploiting a relative dissimilarity representation of signals in a
visual informatics mapping model, driven by real-world sonar systems. An
independent source model is used to analyse the sonar beams from which a simple
probabilistic input model to represent uncertainty is mapped to a latent
visualisation space where data uncertainty can be accommodated. The use of
euclidean and non-euclidean measures are used and the motivation for future use
of non-euclidean measures is made. Concepts are illustrated using a simulated
64 beam weak SNR dataset with realistic sonar targets.
</summary>
    <author>
      <name>Iain Rice</name>
    </author>
    <author>
      <name>Roger Benton</name>
    </author>
    <author>
      <name>Les Hart</name>
    </author>
    <author>
      <name>David Lowe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at IMA Mathematics in Defence 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.6636v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6636v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0306v1</id>
    <updated>2014-03-03T04:09:30Z</updated>
    <published>2014-03-03T04:09:30Z</published>
    <title>An extended isogeometric analysis for vibration of cracked FGM plates
  using higher-order shear deformation theory</title>
    <summary>  A novel and effective formulation that combines the eXtended IsoGeometric
Approach (XIGA) and Higher-order Shear Deformation Theory (HSDT) is proposed to
study the free vibration of cracked Functionally Graded Material (FGM) plates.
Herein, the general HSDT model with five unknown variables per node is applied
for calculating the stiffness matrix without needing Shear Correction Factor
(SCF). In order to model the discontinuous and singular phenomena in the
cracked plates, IsoGeometric Analysis (IGA) utilizing the Non-Uniform Rational
B-Spline (NURBS) functions is incorporated with enrichment functions through
the partition of unity method. NURBS basis functions with their inherent
arbitrary high order smoothness permit the C1 requirement of the HSDT model.
The material properties of the FGM plates vary continuously through the plate
thickness according to an exponent function. The effects of gradient index,
crack length, crack location, length to thickness on the natural frequencies
and mode shapes of simply supported and clamped FGM plate are studied.
Numerical examples are provided to show excellent performance of the proposed
method compared with other published solutions in the literature.
</summary>
    <author>
      <name>Loc V. Tran</name>
    </author>
    <author>
      <name>Vinh Phu Nguyen</name>
    </author>
    <author>
      <name>M. Abdel Wahab</name>
    </author>
    <author>
      <name>H. Nguyen-Xuan</name>
    </author>
    <link href="http://arxiv.org/abs/1403.0306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0307v1</id>
    <updated>2014-03-03T04:10:48Z</updated>
    <published>2014-03-03T04:10:48Z</published>
    <title>Isogeometric finite element analysis of laminated composite plates based
  on a four variable refined plate theory</title>
    <summary>  In this paper, a novel and effective formulation based on isogeometric
approach (IGA) and Refined Plate Theory (RPT) is proposed to study the behavior
of laminated composite plates. Using many kinds of higher-order distributed
functions, RPT model naturally satisfies the traction-free boundary conditions
at plate surfaces and describes the non-linear distribution of shear stresses
without requiring shear correction factor (SCF). IGA utilizes the basis
functions, namely B-splines or non-uniform rational B-splines (NURBS), which
achieve easily the smoothness of any arbitrary order. It hence satisfies the C1
requirement of the RPT model. The static, dynamic and buckling analysis of
rectangular plates is investigated for different boundary conditions. Numerical
results show high effectiveness of the present formulation.
</summary>
    <author>
      <name>Loc V. Tran</name>
    </author>
    <author>
      <name>Chien H. Thai</name>
    </author>
    <author>
      <name>Buntara S. Gan</name>
    </author>
    <author>
      <name>H. Nguyen-Xuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1310.1847</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.0307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.1317v1</id>
    <updated>2014-03-06T01:42:41Z</updated>
    <published>2014-03-06T01:42:41Z</published>
    <title>Hardware software co-design of the Aho-Corasick algorithm: Scalable for
  protein identification?</title>
    <summary>  Pattern matching is commonly required in many application areas and
bioinformatics is a major area of interest that requires both exact and
approximate pattern matching. Much work has been done in this area, yet there
is still a significant space for improvement in efficiency, flexibility, and
throughput. This paper presents a hardware software co-design of Aho-Corasick
algorithm in Nios II soft-processor and a study on its scalability for a
pattern matching application. A software only approach is used to compare the
throughput and the scalability of the hardware software co-design approach.
According to the results we obtained, we conclude that the hardware software
co-design implementation shows a maximum of 10 times speed up for pattern size
of 1200 peptides compared to the software only implementation. The results also
show that the hardware software co-design approach scales well for increasing
data size compared to the software only approach.
</summary>
    <author>
      <name>S. M. Vidanagamachchi</name>
    </author>
    <author>
      <name>S. D. Dewasurendra</name>
    </author>
    <author>
      <name>R. G. Ragel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIInfS.2013.6732003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIInfS.2013.6732003" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Industrial and Information Systems (ICIIS), 2013 8th IEEE
  International Conference on, pp. 321-325, 17-20 Dec. 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.1317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.1317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.1319v1</id>
    <updated>2014-03-06T01:46:05Z</updated>
    <published>2014-03-06T01:46:05Z</published>
    <title>Hardware accelerated protein inference framework</title>
    <summary>  Protein inference plays a vital role in the proteomics study. Two major
approaches could be used to handle the problem of protein inference; top-down
and bottom-up. This paper presents a framework for protein inference, which
uses hardware accelerated protein inference framework for handling the most
important step in a bottom-up approach, viz. peptide identification during the
assembling process. In our framework, identified peptides and their
probabilities are used to predict the most suitable reference protein cluster
for a given input amino acid sequence with the probability of identified
peptides. The framework is developed on an FPGA where hardware software
co-design techniques are used to accelerate the computationally intensive parts
of the protein inference process. In the paper we have measured, compared and
reported the time taken for the protein inference process in our framework
against a pure software implementation.
</summary>
    <author>
      <name>S. M. Vidanagamachchi</name>
    </author>
    <author>
      <name>S. D. Dewasurendra</name>
    </author>
    <author>
      <name>R. G. Ragel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIInfS.2013.6732061</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIInfS.2013.6732061" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Industrial and Information Systems (ICIIS), 2013 8th IEEE
  International Conference on, pp. 649-653, 17-20 Dec. 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.1319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.1319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.1336v1</id>
    <updated>2014-03-06T03:46:38Z</updated>
    <published>2014-03-06T03:46:38Z</published>
    <title>An Extensive Repot on the Efficiency of AIS-INMACA (A Novel Integrated
  MACA based Clonal Classifier for Protein Coding and Promoter Region
  Prediction)</title>
    <summary>  This paper exclusively reports the efficiency of AIS-INMACA. AIS-INMACA has
created good impact on solving major problems in bioinformatics like protein
region identification and promoter region prediction with less time (Pokkuluri
Kiran Sree, 2014). This AIS-INMACA is now came with several variations
(Pokkuluri Kiran Sree, 2014) towards projecting it as a tool in bioinformatics
for solving many problems in bioinformatics. So this paper will be very much
useful for so many researchers who are working in the domain of bioinformatics
with cellular automata.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages, Review of Bioinformatics and Biometrics (RBB) Volume 3 Issue
  1, March 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.1336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.1336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.2000v1</id>
    <updated>2014-03-08T19:25:36Z</updated>
    <published>2014-03-08T19:25:36Z</published>
    <title>A Galois-Connection between Myers-Briggs' Type Indicators and Szondi's
  Personality Profiles</title>
    <summary>  We propose a computable Galois-connection between Myers-Briggs' Type
Indicators (MBTIs), the most widely-used personality measure for
non-psychiatric populations (based on C.G. Jung's personality types), and
Szondi's personality profiles (SPPs), a less well-known but, as we show, finer
personality measure for psychiatric as well as non-psychiatric populations
(conceived as a unification of the depth psychology of S. Freud, C.G. Jung, and
A. Adler). The practical significance of our result is that our
Galois-connection provides a pair of computable, interpreting translations
between the two personality spaces of MBTIs and SPPs: one concrete from
MBTI-space to SPP-space (because SPPs are finer) and one abstract from
SPP-space to MBTI-space (because MBTIs are coarser). Thus Myers-Briggs' and
Szondi's personality-test results are mutually interpretable and
inter-translatable, even automatically by computers.
</summary>
    <author>
      <name>Simon Kramer</name>
    </author>
    <link href="http://arxiv.org/abs/1403.2000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.2000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4881v1</id>
    <updated>2014-03-19T16:54:23Z</updated>
    <published>2014-03-19T16:54:23Z</published>
    <title>Comparing Numerical Integration Schemes for Time-Continuous
  Car-Following Models</title>
    <summary>  When simulating trajectories by integrating time-continuous car-following
models, standard integration schemes such as the forth-order Runge-Kutta method
(RK4) are rarely used while the simple Euler's method is popular among
researchers. We compare four explicit methods: Euler's method, ballistic
update, Heun's method (trapezoidal rule), and the standard forth-order RK4. As
performance metrics, we plot the global discretization error as a function of
the numerical complexity. We tested the methods on several time-continuous
car-following models in several multi-vehicle simulation scenarios with and
without discontinuities such as stops or a discontinuous behavior of an
external leader. We find that the theoretical advantage of RK4 (consistency
order~4) only plays a role if both the acceleration function of the model and
the external data of the simulation scenario are sufficiently often
differentiable. Otherwise, we obtain lower (and often fractional) consistency
orders. Although, to our knowledge, Heun's method has never been used for
integrating car-following models, it turns out to be the best scheme for many
practical situations. The ballistic update always prevails Euler's method
although both are of first order.
</summary>
    <author>
      <name>Martin Treiber</name>
    </author>
    <author>
      <name>Venkatesan Kanagaraj</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2014.09.061</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2014.09.061" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Transportation Research Part B: Methodological</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A: Statistical Mechanics and its Applications 419C,
  pp.183-195 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.4881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.6048v1</id>
    <updated>2014-03-24T17:27:59Z</updated>
    <published>2014-03-24T17:27:59Z</published>
    <title>Computer-Aided Discovery and Categorisation of Personality Axioms</title>
    <summary>  We propose a computer-algebraic, order-theoretic framework based on
intuitionistic logic for the computer-aided discovery of personality axioms
from personality-test data and their mathematical categorisation into formal
personality theories in the spirit of F.~Klein's Erlanger Programm for
geometrical theories. As a result, formal personality theories can be
automatically generated, diagrammatically visualised, and mathematically
characterised in terms of categories of invariant-preserving transformations in
the sense of Klein and category theory. Our personality theories and categories
are induced by implicational invariants that are ground instances of
intuitionistic implication, which we postulate as axioms. In our mindset, the
essence of personality, and thus mental health and illness, is its invariance.
The truth of these axioms is algorithmically extracted from histories of
partially-ordered, symbolic data of observed behaviour. The personality-test
data and the personality theories are related by a Galois-connection in our
framework. As data format, we adopt the format of the symbolic values generated
by the Szondi-test, a personality test based on L.~Szondi's unifying,
depth-psychological theory of fate analysis.
</summary>
    <author>
      <name>Simon Kramer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">related to arXiv:1403.2000</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IfCoLog Journal of Logics and their Applications, 1(2), 2014,
  Pages 107-133</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.6048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.6048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.6167v3</id>
    <updated>2015-09-28T15:51:35Z</updated>
    <published>2014-03-24T22:03:07Z</published>
    <title>MoM-SO: a Complete Method for Computing the Impedance of Cable Systems
  Including Skin, Proximity, and Ground Return Effects</title>
    <summary>  The availability of accurate and broadband models for underground and
submarine cable systems is of paramount importance for the correct prediction
of electromagnetic transients in power grids. Recently, we proposed the MoM-SO
method for extracting the series impedance of power cables while accounting for
skin and proximity effect in the conductors. In this paper, we extend the
method to include ground return effects and to handle cables placed inside a
tunnel. Numerical tests show that the proposed method is more accurate than
widely-used analytic formulas, and is much faster than existing proximity-aware
approaches like finite elements. For a three-phase cable system in a tunnel,
the proposed method requires only 0.3 seconds of CPU time per frequency point,
against the 8.3 minutes taken by finite elements, for a speed up beyond 1000 X.
</summary>
    <author>
      <name>Utkarsh R. Patel</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPWRD.2014.2378594</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPWRD.2014.2378594" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has now been published in the IEEE Trans. on Power
  Delivery in Oct. 2015, vol. 30, no. 5, pp. 2110-2118. DOI:
  10.1109/TPWRD.2014.2378594</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. on Power Delivery in Oct. 2015, vol. 30, no. 5, pp.
  2110-2118</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.6167v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.6167v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7481v1</id>
    <updated>2014-03-28T18:41:39Z</updated>
    <published>2014-03-28T18:41:39Z</published>
    <title>Indexing large genome collections on a PC</title>
    <summary>  Motivation: The availability of thousands of invidual genomes of one species
should boost rapid progress in personalized medicine or understanding of the
interaction between genotype and phenotype, to name a few applications. A key
operation useful in such analyses is aligning sequencing reads against a
collection of genomes, which is costly with the use of existing algorithms due
to their large memory requirements.
  Results: We present MuGI, Multiple Genome Index, which reports all
occurrences of a given pattern, in exact and approximate matching model,
against a collection of thousand(s) genomes. Its unique feature is the small
index size fitting in a standard computer with 16--32\,GB, or even 8\,GB, of
RAM, for the 1000GP collection of 1092 diploid human genomes. The solution is
also fast. For example, the exact matching queries are handled in average time
of 39\,$\mu$s and with up to 3 mismatches in 373\,$\mu$s on the test PC with
the index size of 13.4\,GB. For a smaller index, occupying 7.4\,GB in memory,
the respective times grow to 76\,$\mu$s and 917\,$\mu$s.
  Availability: Software and Suuplementary material:
\url{http://sun.aei.polsl.pl/mugi}.
</summary>
    <author>
      <name>Agnieszka Danek</name>
    </author>
    <author>
      <name>Sebastian Deorowicz</name>
    </author>
    <author>
      <name>Szymon Grabowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0109384</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0109384" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLOS ONE, Article no.0109384 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.7481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.0453v1</id>
    <updated>2014-04-02T04:18:06Z</updated>
    <published>2014-04-02T04:18:06Z</published>
    <title>Cellular Automata and Its Applications in Bioinformatics: A Review</title>
    <summary>  This paper aims at providing a survey on the problems that can be easily
addressed by cellular automata in bioinformatics. Some of the authors have
proposed algorithms for addressing some problems in bioinformatics but the
application of cellular automata in bioinformatics is a virgin field in
research. None of the researchers has tried to relate the major problems in
bioinformatics and find a common solution. Extensive literature surveys were
conducted. We have considered some papers in various journals and conferences
for conduct of our research. This paper provides intuition towards relating
various problems in bioinformatics logically and tries to attain a common frame
work for addressing the same.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <author>
      <name>SSSN Usha Devi N</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Global Perspectives on Artificial Intelligence (GPAI) Volume 2
  Issue 2, Pages 16-22 April 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.0453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.0453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1144v1</id>
    <updated>2014-04-04T03:31:29Z</updated>
    <published>2014-04-04T03:31:29Z</published>
    <title>AIS-MACA- Z: MACA based Clonal Classifier for Splicing Site, Protein
  Coding and Promoter Region Identification in Eukaryotes</title>
    <summary>  Bioinformatics incorporates information regarding biological data storage,
accessing mechanisms and presentation of characteristics within this data. Most
of the problems in bioinformatics and be addressed efficiently by computer
techniques. This paper aims at building a classifier based on Multiple
Attractor Cellular Automata (MACA) which uses fuzzy logic with version Z to
predict splicing site, protein coding and promoter region identification in
eukaryotes. It is strengthened with an artificial immune system technique
(AIS), Clonal algorithm for choosing rules of best fitness. The proposed
classifier can handle DNA sequences of lengths 54,108,162,252,354. This
classifier gives the exact boundaries of both protein and promoter regions with
an average accuracy of 90.6%. This classifier can predict the splicing site
with 97% accuracy. This classifier was tested with 1, 97,000 data components
which were taken from Fickett &amp; Toung , EPDnew, and other sequences from a
renowned medical university.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <author>
      <name>SSSN Usha Devi N</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6,1-6 Pages, Journal of Artificial Intelligence Research &amp; Advances
  Volume 1, Issue 1,2014. arXiv admin note: text overlap with arXiv:1403.5933,
  arXiv:1404.0453</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.1144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2872v1</id>
    <updated>2014-04-10T16:29:09Z</updated>
    <published>2014-04-10T16:29:09Z</published>
    <title>TreQ-CG: Clustering Accelerates High-Throughput Sequencing Read Mapping</title>
    <summary>  As high-throughput sequencers become standard equipment outside of sequencing
centers, there is an increasing need for efficient methods for pre-processing
and primary analysis. While a vast literature proposes methods for HTS data
analysis, we argue that significant improvements can still be gained by
exploiting expensive pre-processing steps which can be amortized with savings
from later stages. We propose a method to accelerate and improve read mapping
based on an initial clustering of possibly billions of high-throughput
sequencing reads, yielding clusters of high stringency and a high degree of
overlap. This clustering improves on the state-of-the-art in running time for
small datasets and, for the first time, makes clustering high-coverage human
libraries feasible. Given the efficiently computed clusters, only one
representative read from each cluster needs to be mapped using a traditional
readmapper such as BWA, instead of individually mapping all reads. On human
reads, all processing steps, including clustering and mapping, only require
11%-59% of the time for individually mapping all reads, achieving speed-ups for
all readmappers, while minimally affecting mapping quality. This accelerates a
highly sensitive readmapper such as Stampy to be competitive with a fast
readmapper such as BWA on unclustered reads.
</summary>
    <author>
      <name>Md Pavel Mahmud</name>
    </author>
    <author>
      <name>Alexander Schliep</name>
    </author>
    <link href="http://arxiv.org/abs/1404.2872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3329v1</id>
    <updated>2014-04-12T23:50:21Z</updated>
    <published>2014-04-12T23:50:21Z</published>
    <title>Portfolio Selection Under Buy-In Threshold Constraints Using DC
  Programming and DCA</title>
    <summary>  In matter of Portfolio selection, we consider a generalization of the
Markowitz Mean-Variance model which includes buy-in threshold constraints.
These constraints limit the amount of capital to be invested in each asset and
prevent very small investments in any asset. The new model can be converted
into a NP-hard mixed integer quadratic programming problem. The purpose of this
paper is to investigate a continuous approach based on DC programming and DCA
for solving this new model. DCA is a local continuous approach to solve a wide
variety of nonconvex programs for which it provided quite often a global
solution and proved to be more robust and efficient than standard methods.
Preliminary comparative results of DCA and a classical Branch-and-Bound
algorithm will be presented. These results show that DCA is an efficient and
promising approach for the considered portfolio selection problem.
</summary>
    <author>
      <name>Hoai An Le Thi</name>
    </author>
    <author>
      <name>Mahdi Moeini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICSSSM.2006.320630</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICSSSM.2006.320630" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of third International Conference on Service Systems and
  Service Management (SSSM'06/IEEE), Troyes, Oct. 2006, pp. 296-300 (2006).
  arXiv admin note: text overlap with arXiv:cs/0501005 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4275v9</id>
    <updated>2016-09-09T00:09:25Z</updated>
    <published>2014-04-15T04:13:37Z</published>
    <title>A Bitcoin system with no mining and no history transactions: Build a
  compact Bitcoin system</title>
    <summary>  We give an explicit definition of decentralization and show you that
decentralization is almost impossible for the current stage and Bitcoin is the
first truly noncentralized currency in the currency history. We propose a new
framework of noncentralized cryptocurrency system with an assumption of the
existence of a weak adversary for a bank alliance. It abandons the mining
process and blockchain, and removes history transactions from data
synchronization. We propose a consensus algorithm named Converged Consensus for
a noncentralized cryptocurrency system.
</summary>
    <author>
      <name>Xiaochao Qian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Call for collaborators</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.4275v9" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4275v9" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4282v4</id>
    <updated>2016-09-06T08:30:03Z</updated>
    <published>2014-04-16T15:23:49Z</published>
    <title>Modeling the wind circulation around mills with a Lagrangian stochastic
  approach</title>
    <summary>  This work aims at introducing model methodology and numerical studies related
to a Lagrangian stochastic approach applied to the computation of the wind
circulation around mills. We adapt the Lagrangian stochastic downscaling method
that we have introduced in [3] and [4] to the atmospheric boundary layer and we
introduce here a Lagrangian version of the actuator disc methods to take
account of the mills. We present our numerical method and numerical experiments
in the case of non rotating and rotating actuator disc models. We also present
some features of our numerical method, in particular the computation of the
probability distribution of the wind in the wake zone, as a byproduct of the
fluid particle model and the associated PDF method.
</summary>
    <author>
      <name>Mireille Bossy</name>
    </author>
    <author>
      <name>Jose Espina</name>
    </author>
    <author>
      <name>Jacques Morice</name>
    </author>
    <author>
      <name>Cristian Paris</name>
    </author>
    <author>
      <name>Antoine Rousseau</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SMAI-Journal of computational mathematics, 2 (2016), p. 177-214
  ISSN 2426-8399</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.4282v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4282v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4304v1</id>
    <updated>2014-04-16T16:27:53Z</updated>
    <published>2014-04-16T16:27:53Z</published>
    <title>Automated Classification of Airborne Laser Scanning Point Clouds</title>
    <summary>  Making sense of the physical world has always been at the core of mapping. Up
until recently, this has always dependent on using the human eye. Using
airborne lasers, it has become possible to quickly "see" more of the world in
many more dimensions. The resulting enormous point clouds serve as data sources
for applications far beyond the original mapping purposes ranging from flooding
protection and forestry to threat mitigation. In order to process these large
quantities of data, novel methods are required. In this contribution, we
develop models to automatically classify ground cover and soil types. Using the
logic of machine learning, we critically review the advantages of supervised
and unsupervised methods. Focusing on decision trees, we improve accuracy by
including beam vector components and using a genetic algorithm. We find that
our approach delivers consistently high quality classifications, surpassing
classical methods.
</summary>
    <author>
      <name>Christoph Waldhauser</name>
    </author>
    <author>
      <name>Ronald Hochreiter</name>
    </author>
    <author>
      <name>Johannes Otepka</name>
    </author>
    <author>
      <name>Norbert Pfeifer</name>
    </author>
    <author>
      <name>Sajid Ghuffar</name>
    </author>
    <author>
      <name>Karolina Korzeniowska</name>
    </author>
    <author>
      <name>Gerald Wagner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-08985-0_12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-08985-0_12" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Solving Computationally Expensive Engineering Problems.
  Springer Proceedings in Mathematics &amp; Statistics Volume 97: 269-292. 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.4304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5062v1</id>
    <updated>2014-04-20T18:31:52Z</updated>
    <published>2014-04-20T18:31:52Z</published>
    <title>Rapid prototyping for sling design optimization</title>
    <summary>  This paper deals with combination of two modern engineering methods in order
to optimise the shape of a representative casting product. The product being
analysed is a sling, which is used to attach pulling rope in timber
transportation. The first step was 3D modelling and static stress/strain
analysis using CAD/CAE software NX4. The slinger shape optimization was
performed using Traction method, by means of software Optishape-TS. To define
constraints for shape optimization, FEA software FEMAP was used. The mould
pattern with optimized 3D shape was then prepared using Fused Deposition
Modelling (FDM) Rapid prototyping method. The sling mass decreased by 20%,
while signifficantly better stress distribution was achieved, with maximum
stress 3.5 times less than initial value. The future researches should use 3D
scanning technology in order to provide more accurate 3D model of initial part.
Results of this research can be used by toolmakers in order to engage FEA/RP
technology to design and manufacture lighter products with acceptable stress
distribution.
</summary>
    <author>
      <name>Nermina Zaimovic-Uzunovic</name>
    </author>
    <author>
      <name>Samir Lemes</name>
    </author>
    <author>
      <name>Damir Curic</name>
    </author>
    <author>
      <name>Alan Topcic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISSN 1854-6250</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Production, Engineering &amp; Management 6(2011)4, 271-280</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.5062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5458v1</id>
    <updated>2014-04-22T11:34:04Z</updated>
    <published>2014-04-22T11:34:04Z</published>
    <title>Complex Workflow Management and Integration of Distributed Computing
  Resources by Science Gateway Portal for Molecular Dynamics Simulations in
  Materials Science</title>
    <summary>  The "IMP Science Gateway Portal" (http://scigate.imp.kiev.ua) for complex
workflow management and integration of distributed computing resources (like
clusters, service grids, desktop grids, clouds) is presented. It is created on
the basis of WS-PGRADE and gUSE technologies, where WS-PGRADE is designed for
science workflow operation and gUSE - for smooth integration of available
resources for parallel and distributed computing in various heterogeneous
distributed computing infrastructures (DCI). The typical scientific workflow
with possible scenarios of its preparation and usage is considered. Several
typical science applications (scientific workflows) are considered for
molecular dynamics (MD) simulations of complex behavior of various
nanostructures (nanoindentation of graphene layers, defect system relaxation in
metal nanocrystals, thermal stability of boron nitride nanotubes, etc.). The
advantages and drawbacks of the solution are shortly analyzed in the context of
its practical applications for MD simulations in materials science, physics and
nanotechnologies with available heterogeneous DCIs.
</summary>
    <author>
      <name>Yuri Gordienko</name>
    </author>
    <author>
      <name>Lev Bekenov</name>
    </author>
    <author>
      <name>Olexandr Gatsenko</name>
    </author>
    <author>
      <name>Elena Zasimchuk</name>
    </author>
    <author>
      <name>Valentin Tatarenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures; Proc. of Third International Conference "High
  Performance Computing" HPC-UA 2013 (Ukraine, Kyiv, October 7-11, 2013)
  (http://hpc-ua.org/hpc-ua-13/proceedings). ISBN 978-966-7690-16-8 (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.5458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6020v1</id>
    <updated>2014-04-24T03:52:24Z</updated>
    <published>2014-04-24T03:52:24Z</published>
    <title>A Fast Multiple Attractor Cellular Automata with Modified Clonal
  Classifier for Splicing Site Prediction in Human Genome</title>
    <summary>  Bioinformatics encompass storing, analyzing and interpreting the biological
data. Most of the challenges for Machine Learning methods like Cellular
Automata is to furnish the functional information with the corresponding
biological sequences. In eukaryotes DNA is divided into introns and exons. The
introns will be removed to make the coding region by a process called splicing.
By indentifying a splice site we can easily specify the DNA sequence category
(Donor/Accepter/Neither).Splicing sites play an important role in understanding
the genes. A class of CA which can handle fuzzy logic is employed with modified
clonal algorithm is proposed to identify the splicing site. This classifier is
tested with Irvine Primate Splice Junction Database. It is compared with
NNspIICE, GENIO, HSPL and SPIICE VIEW. The reported accuracy and efficiency of
prediction is quite promising.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <author>
      <name>SSSN Usha Devi N</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Four Pages, Global Perspectives on Artificial Intelligence (GPAI)
  Volume 2, April 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6384v1</id>
    <updated>2014-04-25T10:53:33Z</updated>
    <published>2014-04-25T10:53:33Z</published>
    <title>CATOS: Computer Aided Training/Observing System</title>
    <summary>  In animal behavioral biology, there are several cases in which an autonomous
observing/training system would be useful. 1) Observation of certain species
continuously, or for documenting specific events, which happen irregularly; 2)
Longterm intensive training of animals in preparation for behavioral
experiments; and 3) Training and testing of animals without human interference,
to eliminate potential cues and biases induced by humans. The primary goal of
this study is to build a system named CATOS (Computer Aided Training/Observing
System) that could be used in the above situations. As a proof of concept, the
system was built and tested in a pilot experiment, in which cats were trained
to press three buttons differently in response to three different sounds (human
speech) to receive food rewards. The system was built in use for about 6
months, successfully training two cats. One cat learned to press a particular
button, out of three buttons, to obtain the food reward with over 70 percent
correctness.
</summary>
    <author>
      <name>Jinook Oh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6866v6</id>
    <updated>2015-10-28T10:24:30Z</updated>
    <published>2014-04-28T05:03:21Z</published>
    <title>Detecting "protein words" through unsupervised word segmentation</title>
    <summary>  Unsupervised word segmentation methods were applied to analyze the protein
sequence. Protein sequences, such as 'MTMDKSELVQKA...', were used as input to
these methods. Segmented 'protein word' sequences, such as 'MTM DKSE LVQKA',
were then obtained. We compare the 'protein words' produced by unsupervised
segmentation and the protein secondary structure segmentation. An interesting
finding is that the unsupervised word segmentation is more efficient than
secondary structure segmentation in expressing information. Our experiment also
suggests there may be some 'protein ruins' in current noncoding regions.
</summary>
    <author>
      <name>Wang Liang</name>
    </author>
    <author>
      <name>Zhao KaiYong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages,8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6866v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6866v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0549v1</id>
    <updated>2014-05-03T02:31:07Z</updated>
    <published>2014-05-03T02:31:07Z</published>
    <title>Classification of Diabetes Mellitus using Modified Particle Swarm
  Optimization and Least Squares Support Vector Machine</title>
    <summary>  Diabetes Mellitus is a major health problem all over the world. Many
classification algorithms have been applied for its diagnoses and treatment. In
this paper, a hybrid algorithm of Modified-Particle Swarm Optimization and
Least Squares- Support Vector Machine is proposed for the classification of
type II DM patients. LS-SVM algorithm is used for classification by finding
optimal hyper-plane which separates various classes. Since LS-SVM is so
sensitive to the changes of its parameter values, Modified-PSO algorithm is
used as an optimization technique for LS-SVM parameters. This will Guarantee
the robustness of the hybrid algorithm by searching for the optimal values for
LS-SVM parameters. The pro-posed Algorithm is implemented and evaluated using
Pima Indians Diabetes Data set from UCI repository of machine learning
databases. It is also compared with different classifier algorithms which were
applied on the same database. The experimental results showed the superiority
of the proposed algorithm which could achieve an average classification
accuracy of 97.833%.
</summary>
    <author>
      <name>Omar S. Soliman</name>
    </author>
    <author>
      <name>Eman AboElhamd</name>
    </author>
    <link href="http://arxiv.org/abs/1405.0549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0560v1</id>
    <updated>2014-05-03T08:15:32Z</updated>
    <published>2014-05-03T08:15:32Z</published>
    <title>Numerical Investigation of Effects of Compound Angle and Length to
  Diameter Ratio on Adiabatic Film Cooling Effectiveness</title>
    <summary>  A modification has been done in the normal injection hole of 35 degree, by
injecting the cold fluid at different angles(compound angle) in lateral
direction, providing a significant change in the shape of holes which later we
found in our numerical investigation giving good quality of effectiveness in
cooling. Different L/D ratios are also studied for each compound angle. The
numerical simulation is performed based on Reynolds Averaged
Navier-Stokes(RANS) equations with k-epsilon turbulence model by using
Fluent(Commercial Software). Adiabatic Film Cooling Effectiveness has been
studied for compound angles of (0, 30, 45 and 60 degrees) and L/D ratios of (1,
2, 3 and 4) on a hole of 6mm diameter with blowing ratio 0.5. The findings are
obtained from the results, concludes that the trend of laterally averaged
adiabatic effectiveness is the function of L/D ratio and compound angle.
</summary>
    <author>
      <name>Vidit Sharma</name>
    </author>
    <author>
      <name>Ashish Garg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 22 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0877v1</id>
    <updated>2014-05-05T12:45:11Z</updated>
    <published>2014-05-05T12:45:11Z</published>
    <title>A Galois-Connection between Cattell's and Szondi's Personality Profiles</title>
    <summary>  We propose a computable Galois-connection between, on the one hand, Cattell's
16-Personality-Factor (16PF) Profiles, one of the most comprehensive and
widely-used personality measures for non-psychiatric populations and their
containing PsychEval Personality Profiles (PPPs) for psychiatric populations,
and, on the other hand, Szondi's personality profiles (SPPs), a less well-known
but, as we show, finer personality measure for psychiatric as well as
non-psychiatric populations (conceived as a unification of the depth psychology
of S. Freud, C.G. Jung, and A. Adler). The practical significance of our result
is that our Galois-connection provides a pair of computable, interpreting
translations between the two personality spaces of PPPs (containing the 16PFs)
and SPPs: one concrete from PPP-space to SPP-space (because SPPs are finer than
PPPs) and one abstract from SPP-space to PPP-space (because PPPs are coarser
than SPPs). Thus Cattell's and Szondi's personality-test results are mutually
interpretable and inter-translatable, even automatically by computers.
</summary>
    <author>
      <name>Simon Kramer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">closely related to arXiv:1403.2000 as explained in the first
  paragraph</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3166v1</id>
    <updated>2014-05-13T14:35:18Z</updated>
    <published>2014-05-13T14:35:18Z</published>
    <title>Clonal-Based Cellular Automata in Bioinformatics</title>
    <summary>  This paper aims at providing a survey on the problems that can be easily
addressed by clonalbased cellular automata in bioinformatics. Researchers try
to address the problems in bioinformatics independent of each problem. None of
the researchers has tried to relate the major problems in bioinformatics and
find a solution using common frame work. We tried to find various problems in
bioinformatics which can be addressed easily by clonal based cellular automata.
Extensive literature survey is conducted. We have considered some papers in
various journals and conferences for conduct of our research. This paper
provides intuition towards relating various problems in bioinformatics
logically and tries to attain a common frame work with respect to clonal based
cellular automata classifier for addressing the same.
</summary>
    <author>
      <name>Pokkuluri Kiran Sree</name>
    </author>
    <author>
      <name>Inampudi Ramesh Babu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 Pages. arXiv admin note: substantial text overlap with
  arXiv:1404.0453</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Advanced Research in Applied Artificial Intelligence &amp;
  Neural Network Vol.1, Issue1, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.3166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3302v3</id>
    <updated>2015-07-27T16:48:19Z</updated>
    <published>2014-05-13T20:44:40Z</published>
    <title>Computational homogenization of fibrous piezoelectric materials</title>
    <summary>  Flexible piezoelectric devices made of polymeric materials are widely used
for micro- and nano-electro-mechanical systems. In particular, numerous recent
applications concern energy harvesting. Due to the importance of computational
modeling to understand the influence that microscale geometry and constitutive
variables exert on the macroscopic behavior, a numerical approach is developed
here for multiscale and multiphysics modeling of thin piezoelectric sheets made
of aligned arrays of polymeric nanofibers, manufactured by electrospinning. At
the microscale, the representative volume element consists in piezoelectric
polymeric nanofibers, assumed to feature a piezoelastic behavior and subjected
to electromechanical contact constraints. The latter are incorporated into the
virtual work equations by formulating suitable electric, mechanical and
coupling potentials and the constraints are enforced by using the penalty
method. From the solution of the micro-scale boundary value problem, a suitable
scale transition procedure leads to identifying the performance of a
macroscopic thin piezoelectric shell element.
</summary>
    <author>
      <name>Claudio Maruccio</name>
    </author>
    <author>
      <name>Laura De Lorenzis</name>
    </author>
    <author>
      <name>Luana Persano</name>
    </author>
    <author>
      <name>Dario Pisignano</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-015-1147-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-015-1147-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 13 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Mechanics, Volume 55, Issue 5, pp. 983-998, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.3302v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3302v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4044v1</id>
    <updated>2014-05-16T01:26:35Z</updated>
    <published>2014-05-16T01:26:35Z</published>
    <title>Seismic Wave Scattering Through a Compressed Hybrid BEM/FEM Method</title>
    <summary>  Approximated numerical techniques, for the solution of the elastic wave
scattering problem over semi-infinite domains are reviewed. The approximations
involve the representation of the half-space by a boundary condition described
in terms of 2D boundary element discretizations. The classical BEM matrices are
initially re-written into the form of a dense dynamic stiffness matrix and
later approximated to a banded matrix. The resulting final banded matrix is
then used like a standard finite element to solve the wave scattering problem
at lower memory requirements. The accuracy of the reviewed methods is
benchmarked against the classical problems of a semi-circular and a rectangular
canyon. Results are presented in the time and frequency domain, as well as in
terms of relative errors in the considered approximations. The main goal of the
paper is to give the analyst a method that can be used at the practising level
where an approximate solution is enough in order to support engineering
decisions.
</summary>
    <author>
      <name>Nicolás Guarín-Zapata</name>
    </author>
    <author>
      <name>Juan Gómez</name>
    </author>
    <author>
      <name>Juan Jaramillo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.4044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4201v2</id>
    <updated>2014-05-29T16:07:41Z</updated>
    <published>2014-05-16T15:12:34Z</published>
    <title>Exploiting Prior Knowledge in Compressed Sensing Wireless ECG Systems</title>
    <summary>  Recent results in telecardiology show that compressed sensing (CS) is a
promising tool to lower energy consumption in wireless body area networks for
electrocardiogram (ECG) monitoring. However, the performance of current
CS-based algorithms, in terms of compression rate and reconstruction quality of
the ECG, still falls short of the performance attained by state-of-the-art
wavelet based algorithms. In this paper, we propose to exploit the structure of
the wavelet representation of the ECG signal to boost the performance of
CS-based methods for compression and reconstruction of ECG signals. More
precisely, we incorporate prior information about the wavelet dependencies
across scales into the reconstruction algorithms and exploit the high fraction
of common support of the wavelet coefficients of consecutive ECG segments.
Experimental results utilizing the MIT-BIH Arrhythmia Database show that
significant performance gains, in terms of compression rate and reconstruction
quality, can be obtained by the proposed algorithms compared to current
CS-based methods.
</summary>
    <author>
      <name>Luisa F. Polania</name>
    </author>
    <author>
      <name>Rafael E. Carrillo</name>
    </author>
    <author>
      <name>Manuel Blanco-Velasco</name>
    </author>
    <author>
      <name>Kenneth E. Barner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JBHI.2014.2325017</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JBHI.2014.2325017" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at IEEE Journal of Biomedical and Health
  Informatics</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.4201v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4201v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4890v1</id>
    <updated>2014-05-19T20:51:16Z</updated>
    <published>2014-05-19T20:51:16Z</published>
    <title>A Revised Incremental Conductance MPPT Algorithm for Solar PV Generation
  Systems</title>
    <summary>  A revised Incremental Conductance (IncCond) maximum power point tracking
(MPPT) algorithm for PV generation systems is proposed in this paper. The
commonly adopted traditional IncCond method uses a constant step size for
voltage adjustment and is difficult to achieve both a good tracking performance
and quick elimination of the oscillations, especially under the dramatic
changes of the environment conditions. For the revised algorithm, the
incremental voltage change step size is adaptively adjusted based on the slope
of the power-voltage (P-V) curve. An accelerating factor and a decelerating
factor are further applied to adjust the voltage step change considering
whether the sign of the P-V curve slope remains the same or not in a subsequent
tracking step. In addition, the upper bound of the maximum voltage step change
is also updated considering the information of sign changes. The revised MPPT
algorithm can quickly track the maximum power points (MPPs) and remove the
oscillation of the actual operation points around the real MPPs. The
effectiveness of the revised algorithm is demonstrated using a simulation.
</summary>
    <author>
      <name>Meng Yue</name>
    </author>
    <author>
      <name>Xiaoyu Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1405.4890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5148v1</id>
    <updated>2014-05-20T16:33:25Z</updated>
    <published>2014-05-20T16:33:25Z</published>
    <title>Determination of Boiling Range of Xylene Mixed in PX Device Using
  Artificial Neural Networks</title>
    <summary>  Determination of boiling range of xylene mixed in PX device is currently a
crucial topic in the practical applications because of the recent disputes of
PX project in China. In our study, instead of determining the boiling range of
xylene mixed by traditional approach in laboratory or industry, we successfully
established two Artificial Neural Networks (ANNs) models to determine the
initial boiling point and final boiling point respectively. Results show that
the Multilayer Feedforward Neural Networks (MLFN) model with 7 nodes (MLFN-7)
is the best model to determine the initial boiling point of xylene mixed, with
the RMS error 0.18; while the MLFN model with 4 nodes (MLFN-4) is the best
model to determine the final boiling point of xylene mixed, with the RMS error
0.75. The training and testing processes both indicate that the models we
developed are robust and precise. Our research can effectively avoid the damage
of the PX device to human body and environment.
</summary>
    <author>
      <name>Ting Zhu</name>
    </author>
    <author>
      <name>Yuxuan Zhu</name>
    </author>
    <author>
      <name>Hong Yang</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <link href="http://arxiv.org/abs/1405.5148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5197v2</id>
    <updated>2014-11-03T21:55:51Z</updated>
    <published>2014-05-20T19:29:51Z</published>
    <title>Optimization of Vehicle Dynamics based on Multibody Models using Adjoint
  Sensitivity Analysis</title>
    <summary>  Multibody dynamics simulations have become widely used tools for vehicle
systems analysis and design. As this approach evolves, it becomes able to
provide additional information for various types of analyses. One very
important direction is the optimization of multibody systems. Sensitivity
analysis of multibody system dynamics is essential for design optimization.
Dynamic sensitivities, when needed, are often calculated by means of finite
differences. However, depending of the number of parameters involved, this
procedure can be computationally expensive. Moreover, in many cases the results
suffer from low accuracy when real perturbations are used. This paper develops
the adjoint sensitivity analysis of multibody systems in the context of penalty
formulations. The resulting sensitivities are applied to perform dynamical
optimization of a full vehicle system.
</summary>
    <author>
      <name>Yitao Zhu</name>
    </author>
    <author>
      <name>Corina Sandu</name>
    </author>
    <author>
      <name>Daniel Dopico</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">I tried to replace this paper with a new one which has corrected
  several errors in this paper. However, I didn't know how to replace it at
  that time, I submitted a new one "Dynamic Response Optimization of Complex
  Multibody Systems in a Penalty Formulation using Adjoint Sensitivity", the
  identifier is arXiv:1410.8422. Since I have already submitted that one, I
  want to withdraw this one</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5197v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5197v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5206v1</id>
    <updated>2014-05-20T19:52:43Z</updated>
    <published>2014-05-20T19:52:43Z</published>
    <title>Application of Multilayer Feedforward Neural Networks in Predicting Tree
  Height and Forest Stock Volume of Chinese Fir</title>
    <summary>  Wood increment is critical information in forestry management. Previous
studies used mathematics models to describe complex growing pattern of forest
stand, in order to determine the dynamic status of growing forest stand in
multiple conditions. In our research, we aimed at studying non-linear
relationships to establish precise and robust Artificial Neural Networks (ANN)
models to predict the precise values of tree height and forest stock volume
based on data of Chinese fir. Results show that Multilayer Feedforward Neural
Networks with 4 nodes (MLFN-4) can predict the tree height with the lowest RMS
error (1.77); Multilayer Feedforward Neural Networks with 7 nodes (MLFN-7) can
predict the forest stock volume with the lowest RMS error (4.95). The training
and testing process have proved that our models are precise and robust.
</summary>
    <author>
      <name>Xiaohui Huang</name>
    </author>
    <author>
      <name>Xing Hu</name>
    </author>
    <author>
      <name>Weichang Jiang</name>
    </author>
    <author>
      <name>Zhi Yang</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <link href="http://arxiv.org/abs/1405.5206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5550v1</id>
    <updated>2014-05-21T20:30:22Z</updated>
    <published>2014-05-21T20:30:22Z</published>
    <title>Application of Artificial Neural Networks in Predicting Abrasion
  Resistance of Solution Polymerized Styrene-Butadiene Rubber Based Composites</title>
    <summary>  Abrasion resistance of solution polymerized styrene-butadiene rubber (SSBR)
based composites is a typical and crucial property in practical applications.
Previous studies show that the abrasion resistance can be calculated by the
multiple linear regression model. In our study, considering this relationship
can also be described into the non-linear conditions, a Multilayer Feed-forward
Neural Networks model with 3 nodes (MLFN-3) was successfully established to
describe the relationship between the abrasion resistance and other properties,
using 23 groups of data, with the RMS error 0.07. Our studies have proved that
Artificial Neural Networks (ANN) model can be used to predict the SSBR-based
composites, which is an accurate and robust process.
</summary>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Dazuo Yang</name>
    </author>
    <author>
      <name>Fudi Chen</name>
    </author>
    <author>
      <name>Yibing Zhou</name>
    </author>
    <author>
      <name>Zhilong Xiu</name>
    </author>
    <link href="http://arxiv.org/abs/1405.5550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0930v1</id>
    <updated>2014-06-04T02:44:57Z</updated>
    <published>2014-06-04T02:44:57Z</published>
    <title>ACO Implementation for Sequence Alignment with Genetic Algorithms</title>
    <summary>  In this paper, we implement Ant Colony Optimization (ACO) for sequence
alignment. ACO is a meta-heuristic recently developed for nearest neighbor
approximations in large, NP-hard search spaces. Here we use a genetic algorithm
approach to evolve the best parameters for an ACO designed to align two
sequences. We then used the best parameters found to interpolate approximate
optimal parameters for a given string length within a range. The basis of our
comparison is the alignment given by the Needleman-Wunsch algorithm. We found
that ACO can indeed be applied to sequence alignment. While it is
computationally expensive compared to other equivalent algorithms, it is a
promising algorithm that can be readily applied to a variety of other
biological problems.
</summary>
    <author>
      <name>Aaron Lee</name>
    </author>
    <author>
      <name>Livia King</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Report 6 pages, 4 figures, Supplementary material 11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1062v1</id>
    <updated>2014-06-03T19:29:04Z</updated>
    <published>2014-06-03T19:29:04Z</published>
    <title>An Innovative Wireless Cardiac Rhythm Management (iCRM) System</title>
    <summary>  In this paper, we propose a wireless Communicator to manage and enhance a
Cardiac Rhythm Management System. The system includes: (1) an on-body wireless
Electrocardiogram (ECG), (2) an Intracardiac Electrogram (EGM) embedded inside
an Implantable Cardioverter/Defibrillator, and (3) a Communicator (with a
resident Learning System). The first two devices are existing technology
available in the market and are emulated using data from the Physionet
database, while the Communicator was designed and implemented by our research
team. The value of the information obtained by combining the information
supplied by (1) and (2), presented to the Communicator, improves decision
making regarding use of the actuator or other actions. Preliminary results show
a high level of confidence in the decisions made by the Communicator. For
example, excellent accuracy is achieved in predicting atrial arrhythmia in 8
patients using only external ECG when we used a neural network.
</summary>
    <author>
      <name>Gabriel E. Arrobo</name>
    </author>
    <author>
      <name>Calvin A. Perumalla</name>
    </author>
    <author>
      <name>Stanley B. Hanke</name>
    </author>
    <author>
      <name>Thomas P. Ketterl</name>
    </author>
    <author>
      <name>Peter J. Fabri</name>
    </author>
    <author>
      <name>Richard D. Gitlin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/WTS.2014.6835035</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/WTS.2014.6835035" rel="related"/>
    <link href="http://arxiv.org/abs/1406.1062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7042v1</id>
    <updated>2014-06-26T22:50:43Z</updated>
    <published>2014-06-26T22:50:43Z</published>
    <title>Structure-Preserving Reduction of Finite-Difference Time-Domain
  Equations with Controllable Stability Beyond the CFL Limit</title>
    <summary>  The timestep of the Finite-Difference Time-Domain method (FDTD) is
constrained by the stability limit known as the Courant-Friedrichs-Lewy (CFL)
condition. This limit can make FDTD simulations quite time consuming for
structures containing small geometrical details. Several methods have been
proposed in the literature to extend the CFL limit, including implicit FDTD
methods and filtering techniques. In this paper, we propose a novel approach
which combines model order reduction and a perturbation algorithm to accelerate
FDTD simulations beyond the CFL barrier. We compare the proposed algorithm
against existing implicit and explicit CFL extension techniques, demonstrating
increased accuracy and performance on a large number of test cases, including
resonant cavities, a waveguide structure, a focusing metascreen and a
microstrip filter.
</summary>
    <author>
      <name>Xihao Li</name>
    </author>
    <author>
      <name>Costas D. Sarris</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMTT.2014.2366140</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMTT.2014.2366140" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Microw. Theory Techn., vol. 62, no. 12, pp. 3228-3238,
  2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.7042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2084v1</id>
    <updated>2014-07-08T13:57:28Z</updated>
    <published>2014-07-08T13:57:28Z</published>
    <title>Analyzing Chromatin Using Tiled Binned Scatterplot Matrices</title>
    <summary>  Background: Over the last years, more and more biological data became
available. Besides the pure amount of new data, also its dimensionality - the
number of different attributes per data point - increased. Recently, especially
the amount of data on chromatin and its modifications increased considerably.
In the field of epigenetics, appropriate visualization tools designed for
highlighting the different aspects of epigenetic data are currently not
available. Results: We present a tool called TiBi-Scatter enabling correlation
analysis in 2D. This approach allows for analyzing multidimensional data while
keeping the use of resources such as memory small. Thus, it is in particular
applicable to large data sets. Conclusions: TiBi-Scatter is a resource-friendly
and easy to use tool that allows for the hypothesis-free analysis of large
multidimensional biological data sets.
</summary>
    <author>
      <name>Dirk Zeckzer</name>
    </author>
    <author>
      <name>Daniel Gerighausen</name>
    </author>
    <author>
      <name>Lydia Steiner</name>
    </author>
    <author>
      <name>Sonja J. Prohaska</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">BioVis 2014 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3661v1</id>
    <updated>2014-07-14T14:11:42Z</updated>
    <published>2014-07-14T14:11:42Z</published>
    <title>Modeling structural change in spatial system dynamics: A Daisyworld
  example</title>
    <summary>  System dynamics (SD) is an effective approach for helping reveal the temporal
behavior of complex systems. Although there have been recent developments in
expanding SD to include systems' spatial dependencies, most applications have
been restricted to the simulation of diffusion processes; this is especially
true for models on structural change (e.g. LULC modeling). To address this
shortcoming, a Python program is proposed to tightly couple SD software to a
Geographic Information System (GIS). The approach provides the required
capacities for handling bidirectional and synchronized interactions of
operations between SD and GIS. In order to illustrate the concept and the
techniques proposed for simulating structural changes, a fictitious environment
called Daisyworld has been recreated in a spatial system dynamics (SSD)
environment. The comparison of spatial and non-spatial simulations emphasizes
the importance of considering spatio-temporal feedbacks. Finally, practical
applications of structural change models in agriculture and disaster management
are proposed.
</summary>
    <author>
      <name>Christian Neuwirth</name>
    </author>
    <author>
      <name>Angela Peck</name>
    </author>
    <author>
      <name>Slobodan Simonovic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.envsoft.2014.11.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.envsoft.2014.11.026" rel="related"/>
    <link href="http://arxiv.org/abs/1407.3661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4650v1</id>
    <updated>2014-07-17T12:12:35Z</updated>
    <published>2014-07-17T12:12:35Z</published>
    <title>Protein Folding in the Hexagonal Prism Lattice with Diagonals</title>
    <summary>  Predicting protein secondary structure using lattice model is one of the most
studied computational problem in bioinformatics. Here secondary structure or
three dimensional structure of protein is predicted from its amino acid
sequence. Secondary structure refers to local sub-structures of protein. Mostly
founded secondary structures are alpha helix and beta sheets. Since, it is a
problem of great potential complexity many simplified energy model have been
proposed in literature on basis of interaction of amino acid residue in
protein. Here we use well researched Hydrophobic-Polar (HP) energy model. In
this paper, we proposed hexagonal prism lattice with diagonal that can overcome
the problems of other lattice structure, e.g., parity problem. We give two
approximation algorithm for protein folding on this lattice. Our first
algorithm leads us to similar structure of helix structure which is commonly
found in protein structure. This motivated us to find next algorithm which
improves the algorithm ratio of 9/7.
</summary>
    <author>
      <name>Dipan Lal Shaw</name>
    </author>
    <author>
      <name>M. Sohel Rahman</name>
    </author>
    <author>
      <name>A. S. M. Sohidull Islam</name>
    </author>
    <author>
      <name>Shuvasish Karmaker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 page, 8 figure, ISSAC</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.4650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.8476v2</id>
    <updated>2014-08-06T12:48:43Z</updated>
    <published>2014-07-31T16:17:39Z</published>
    <title>A comparative study between seasonal wind speed by Fourier and Wavelet
  analysis</title>
    <summary>  Wind Energy is a useful resource for Renewable energy purpose. Wind speed
plays a vital role for wind energy calculation of certain location. So, it is
very much necessary to know the wind speed data characteristics. In this paper
fourier and wavelet transform are applied to study the wind speed data. We have
compared wind speed of winter with summer by taking their speed into account
using various discrete wavelets namely Haar and Daubechies-4 (Db-4). Also the
periodicity of wind speed is checked using Continuous Wavelet Transform (MCWT)
like Morlet. Thereafter a comparative study is done for detecting the
periodicity of both summer and winter. Then wavelet coherence is checked
between these two data for extracting the phase coherency information.
</summary>
    <author>
      <name>Sabyasachi Mukhopadhyay</name>
    </author>
    <author>
      <name>Debadatta Dash</name>
    </author>
    <author>
      <name>Asish Mitra</name>
    </author>
    <author>
      <name>Paritosh Bhattacharya</name>
    </author>
    <link href="http://arxiv.org/abs/1407.8476v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.8476v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0889v2</id>
    <updated>2014-08-06T04:22:26Z</updated>
    <published>2014-08-05T08:37:11Z</published>
    <title>Computing With Contextual Numbers</title>
    <summary>  Self Organizing Map (SOM) has been applied into several classical modeling
tasks including clustering, classification, function approximation and
visualization of high dimensional spaces. The final products of a trained SOM
are a set of ordered (low dimensional) indices and their associated high
dimensional weight vectors. While in the above-mentioned applications, the
final high dimensional weight vectors play the primary role in the
computational steps, from a certain perspective, one can interpret SOM as a
nonparametric encoder, in which the final low dimensional indices of the
trained SOM are pointer to the high dimensional space. We showed how using a
one-dimensional SOM, which is not common in usual applications of SOM, one can
develop a nonparametric mapping from a high dimensional space to a continuous
one-dimensional numerical field. These numerical values, called contextual
numbers, are ordered in a way that in a given context, similar numbers refer to
similar high dimensional states. Further, as these numbers can be treated
similarly to usual continuous numbers, they can be replaced with their
corresponding high dimensional states within any data driven modeling problem.
As a potential application, we showed how using contextual numbers could be
used for the problem of high dimensional spatiotemporal dynamics.
</summary>
    <author>
      <name>Vahid Moosavi</name>
    </author>
    <link href="http://arxiv.org/abs/1408.0889v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0889v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1589v1</id>
    <updated>2014-08-07T13:48:31Z</updated>
    <published>2014-08-07T13:48:31Z</published>
    <title>Simulating Organogenesis in COMSOL: Image-based Modeling</title>
    <summary>  Mathematical Modelling has a long history in developmental biology. Advances
in experimental techniques and computational algorithms now permit the
development of increasingly more realistic models of organogenesis. In
particular, 3D geometries of developing organs have recently become available.
In this paper, we show how to use image-based data for simulations of
organogenesis in COMSOL Multiphysics. As an example, we use limb bud
development, a classical model system in mouse developmental biology. We
discuss how embryonic geometries with several subdomains can be read into
COMSOL using the Matlab LiveLink, and how these can be used to simulate models
on growing embryonic domains. The ALE method is used to solve signaling models
even on strongly deforming domains.
</summary>
    <author>
      <name>Zahra Karimaddini</name>
    </author>
    <author>
      <name>Erkan Unal</name>
    </author>
    <author>
      <name>Denis Menshykau</name>
    </author>
    <author>
      <name>Dagmar Iber</name>
    </author>
    <link href="http://arxiv.org/abs/1408.1589v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1589v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4599v1</id>
    <updated>2014-08-20T10:40:39Z</updated>
    <published>2014-08-20T10:40:39Z</published>
    <title>ls1 mardyn: The massively parallel molecular dynamics code for large
  systems</title>
    <summary>  The molecular dynamics simulation code ls1 mardyn is presented. It is a
highly scalable code, optimized for massively parallel execution on
supercomputing architectures, and currently holds the world record for the
largest molecular simulation with over four trillion particles. It enables the
application of pair potentials to length and time scales which were previously
out of scope for molecular dynamics simulation. With an efficient dynamic load
balancing scheme, it delivers high scalability even for challenging
heterogeneous configurations. Presently, multi-center rigid potential models
based on Lennard-Jones sites, point charges and higher-order polarities are
supported. Due to its modular design, ls1 mardyn can be extended to new
physical models, methods, and algorithms, allowing future users to tailor it to
suit their respective needs. Possible applications include scenarios with
complex geometries, e.g. for fluids at interfaces, as well as non-equilibrium
molecular dynamics simulation of heat and mass transfer.
</summary>
    <author>
      <name>Christoph Niethammer</name>
    </author>
    <author>
      <name>Stefan Becker</name>
    </author>
    <author>
      <name>Martin Bernreuther</name>
    </author>
    <author>
      <name>Martin Buchholz</name>
    </author>
    <author>
      <name>Wolfgang Eckhardt</name>
    </author>
    <author>
      <name>Alexander Heinecke</name>
    </author>
    <author>
      <name>Stephan Werth</name>
    </author>
    <author>
      <name>Hans-Joachim Bungartz</name>
    </author>
    <author>
      <name>Colin W. Glass</name>
    </author>
    <author>
      <name>Hans Hasse</name>
    </author>
    <author>
      <name>Jadran Vrabec</name>
    </author>
    <author>
      <name>Martin Horsch</name>
    </author>
    <link href="http://arxiv.org/abs/1408.4599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4849v1</id>
    <updated>2014-08-21T00:55:35Z</updated>
    <published>2014-08-21T00:55:35Z</published>
    <title>Swarm Intelligence Based Multi-phase OPF For Peak Power Loss Reduction
  In A Smart Grid</title>
    <summary>  Recently there has been increasing interest in improving smart grids
efficiency using computational intelligence. A key challenge in future smart
grid is designing Optimal Power Flow tool to solve important planning problems
including optimal DG capacities. Although, a number of OPF tools exists for
balanced networks there is a lack of research for unbalanced multi-phase
distribution networks. In this paper, a new OPF technique has been proposed for
the DG capacity planning of a smart grid. During the formulation of the
proposed algorithm, multi-phase power distribution system is considered which
has unbalanced loadings, voltage control and reactive power compensation
devices. The proposed algorithm is built upon a co-simulation framework that
optimizes the objective by adapting a constriction factor Particle Swarm
optimization. The proposed multi-phase OPF technique is validated using IEEE
8500-node benchmark distribution system.
</summary>
    <author>
      <name>Adnan Anwar</name>
    </author>
    <author>
      <name>A. N. Mahmood</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/PESGM.2014.6939824</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/PESGM.2014.6939824" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE PES GM 2014, Washington DC, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.4849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4965v1</id>
    <updated>2014-08-21T11:32:53Z</updated>
    <published>2014-08-21T11:32:53Z</published>
    <title>A Domain Specific Approach to Heterogeneous Computing: From Availability
  to Accessibility</title>
    <summary>  We advocate a domain specific software development methodology for
heterogeneous computing platforms such as Multicore CPUs, GPUs and FPGAs. We
argue that three specific benefits are realised from adopting such an approach:
portable, efficient implementations across heterogeneous platforms; domain
specific metrics of quality that characterise platforms in a form software
developers will understand; automatic, optimal partitioning across the
available computing resources. These three benefits allow a development
methodology for software developers where they describe their computational
problems in a single, easy to understand form, and after a modeling procedure
on the available resources, select how they would like to trade between various
domain specific metrics. Our work on the Forward Financial Framework ($F^3$)
demonstrates this methodology in practise. We are able to execute a range of
computational finance option pricing tasks efficiently upon a wide range of
CPU, GPU and FPGA computing platforms. We can also create accurate financial
domain metric models of walltime latency and statistical confidence.
Furthermore, we believe that we can support automatic, optimal partitioning
using this execution and modelling capability.
</summary>
    <author>
      <name>Gordon Inggs</name>
    </author>
    <author>
      <name>David Thomas</name>
    </author>
    <author>
      <name>Wayne Luk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.4965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5380v1</id>
    <updated>2014-08-22T18:56:30Z</updated>
    <published>2014-08-22T18:56:30Z</published>
    <title>Evolving Modular Genetic Regulatory Networks with a Recursive, Top-Down
  Approach</title>
    <summary>  Being able to design genetic regulatory networks (GRNs) to achieve a desired
cellular function is one of the main goals of synthetic biology. However,
determining minimal GRNs that produce desired time-series behaviors is
non-trivial. In this paper, we propose a 'top-down' approach to evolving small
GRNs and then use these to recursively boot-strap the identification of larger,
more complex, modular GRNs. We start with relatively dense GRNs and then use
differential evolution (DE) to evolve interaction coefficients. When the target
dynamical behavior is found embedded in a dense GRN, we narrow the focus of the
search and begin aggressively pruning out excess interactions at the end of
each generation. We first show that the method can quickly rediscover known
small GRNs for a toggle switch and an oscillatory circuit. Next we include
these GRNs as non-evolvable subnetworks in the subsequent evolution of more
complex, modular GRNs. Successful solutions found in canonical DE where we
truncated small interactions to zero, with or without an interaction penalty
term, invariably contained many excess interactions. In contrast, by
incorporating aggressive pruning and the penalty term, the DE was able to find
minimal or nearly minimal GRNs in all test problems.
</summary>
    <author>
      <name>Javier Garcia-Bernardo</name>
    </author>
    <author>
      <name>Margaret J. Eppstein</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11693-015-9179-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11693-015-9179-5" rel="related"/>
    <link href="http://arxiv.org/abs/1408.5380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0367v2</id>
    <updated>2014-10-14T13:03:37Z</updated>
    <published>2014-09-01T11:16:21Z</published>
    <title>"Share and Enjoy": Publishing Useful and Usable Scientific Models</title>
    <summary>  The reproduction and replication of reported scientific results is a hot
topic within the academic community. The retraction of numerous studies from a
wide range of disciplines, from climate science to bioscience, has drawn the
focus of many commentators, but there exists a wider socio-cultural problem
that pervades the scientific community. Sharing code, data and models often
requires extra effort; this is currently seen as a significant overhead that
may not be worth the time investment.
  Automated systems, which allow easy reproduction of results, offer the
potential to incentivise a culture change and drive the adoption of new
techniques to improve the efficiency of scientific exploration. In this paper,
we discuss the value of improved access and sharing of the two key types of
results arising from work done in the computational sciences: models and
algorithms. We propose the development of an integrated cloud-based system
underpinning computational science, linking together software and data
repositories, toolchains, workflows and outputs, providing a seamless automated
infrastructure for the verification and validation of scientific models and in
particular, performance benchmarks.
</summary>
    <author>
      <name>Tom Crick</name>
    </author>
    <author>
      <name>Benjamin A. Hall</name>
    </author>
    <author>
      <name>Samin Ishtiaq</name>
    </author>
    <author>
      <name>Kenji Takeda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for the 1st International Workshop on Recomputability (part
  of UCC 2014); 5 pages, LaTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.0367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0718v1</id>
    <updated>2014-09-02T14:12:59Z</updated>
    <published>2014-09-02T14:12:59Z</published>
    <title>An Approach for Assessing Clustering of Households by Electricity Usage</title>
    <summary>  How a household varies their regular usage of electricity is useful
information for organisations to allow accurate targeting of behaviour
modification initiatives with the aim of improving the overall efficiency of
the electricity network. The variability of regular activities in a household
is one possible indication of that household's willingness to accept incentives
to change their behaviour.
  An approach is presented for identifying a way of representing the
variability of a household's behaviour and developing an efficient way of
clustering the households, using these measures of variability, into a few,
usable groupings.
  To evaluate the effectiveness of the variability measures, a number of
cluster validity indexes are explored with regard to how the indexes vary with
the number of clusters, the number of attributes, and the quality of the
attributes. The Cluster Dispersion Indicator (CDI) and the Davies-Boulden
Indicator (DBI) are selected for future work developing various indicators of
household behaviour variability.
  The approach is tested using data from 180 UK households monitored for over a
year at a sampling interval of 5 minutes. Data is taken from the evening peak
electricity usage period of 4pm to 8pm.
</summary>
    <author>
      <name>Ian Dent</name>
    </author>
    <author>
      <name>Tony Craig</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Tom Rodden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UKCI 2012, the 12th Annual Workshop on Computational Intelligence,
  Heriot-Watt University, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.0718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1057v1</id>
    <updated>2014-09-03T12:23:50Z</updated>
    <published>2014-09-03T12:23:50Z</published>
    <title>Augmented Neural Networks for Modelling Consumer Indebtness</title>
    <summary>  Consumer Debt has risen to be an important problem of modern societies,
generating a lot of research in order to understand the nature of consumer
indebtness, which so far its modelling has been carried out by statistical
models. In this work we show that Computational Intelligence can offer a more
holistic approach that is more suitable for the complex relationships an
indebtness dataset has and Linear Regression cannot uncover. In particular, as
our results show, Neural Networks achieve the best performance in modelling
consumer indebtness, especially when they manage to incorporate the significant
and experimentally verified results of the Data Mining process in the model,
exploiting the flexibility Neural Networks offer in designing their topology.
This novel method forms an elaborate framework to model Consumer indebtness
that can be extended to any other real world application.
</summary>
    <author>
      <name>Alexandros Ladas</name>
    </author>
    <author>
      <name>Jonathan M. Garibaldi</name>
    </author>
    <author>
      <name>Rodrigo Scarpel</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2014 World Congress on Computational Intelligence
  (WCCI 2014), pp. 3086-3093, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.1057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4824v1</id>
    <updated>2014-09-16T22:31:11Z</updated>
    <published>2014-09-16T22:31:11Z</published>
    <title>Uncertainty Quantification for Integrated Circuits: Stochastic Spectral
  Methods</title>
    <summary>  Due to significant manufacturing process variations, the performance of
integrated circuits (ICs) has become increasingly uncertain. Such uncertainties
must be carefully quantified with efficient stochastic circuit simulators. This
paper discusses the recent advances of stochastic spectral circuit simulators
based on generalized polynomial chaos (gPC). Such techniques can handle both
Gaussian and non-Gaussian random parameters, showing remarkable speedup over
Monte Carlo for circuits with a small or medium number of parameters. We focus
on the recently developed stochastic testing and the application of
conventional stochastic Galerkin and stochastic collocation schemes to
nonlinear circuit problems. The uncertainty quantification algorithms for
static, transient and periodic steady-state simulations are presented along
with some practical simulation results. Some open problems in this field are
discussed.
</summary>
    <author>
      <name>Zheng Zhang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name> Ibrahim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name>M. Elfadel</name>
    </author>
    <author>
      <name>Luca Daniel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in Proc. ICCCAD 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. Conf. Computer-Aided Design, pp. 803-810, San Jose, CA, Nov.
  2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.4824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4826v1</id>
    <updated>2014-09-16T22:46:49Z</updated>
    <published>2014-09-16T22:46:49Z</published>
    <title>Efficient Uncertainty Quantification for the Periodic Steady State of
  Forced and Autonomous Circuits</title>
    <summary>  This brief paper proposes an uncertainty quantification method for the
periodic steady-state (PSS) analysis with both Gaussian and non-Gaussian
variations. Our stochastic testing formulation for the PSS problem provides
superior efficiency over both Monte Carlo methods and existing spectral
methods. The numerical implementation of a stochastic shooting Newton solver is
presented for both forced and autonomous circuits. Simulation results on some
analog/RF circuits are reported to show the effectiveness of our proposed
algorithms.
</summary>
    <author>
      <name>Zheng Zhang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name>Tarek A. El-Moselhy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Maffezzoni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name> Ibrahim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Abe</arxiv:affiliation>
    </author>
    <author>
      <name>M. Elfadel</name>
    </author>
    <author>
      <name>Luca Daniel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCSII.2013.2278110</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCSII.2013.2278110" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published by IEEE Trans Circuits and Systems II: Express Briefs in
  2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Circuits and Systems II: Express Briefs, vol. 60,
  no.10, pp. 687-691, (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.4826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5774v1</id>
    <updated>2014-09-03T09:07:53Z</updated>
    <published>2014-09-03T09:07:53Z</published>
    <title>Attributes for Causal Inference in Longitudinal Observational Databases</title>
    <summary>  The pharmaceutical industry is plagued by the problem of side effects that
can occur anytime a prescribed medication is ingested. There has been a recent
interest in using the vast quantities of medical data available in longitudinal
observational databases to identify causal relationships between drugs and
medical events. Unfortunately the majority of existing post marketing
surveillance algorithms measure how dependant or associated an event is on the
presence of a drug rather than measuring causality. In this paper we
investigate potential attributes that can be used in causal inference to
identify side effects based on the Bradford-Hill causality criteria. Potential
attributes are developed by considering five of the causality criteria and
feature selection is applied to identify the most suitable of these attributes
for detecting side effects. We found that attributes based on the specificity
criterion may improve side effect signalling algorithms but the experiment and
dosage criteria attributes investigated in this paper did not offer sufficient
additional information.
</summary>
    <author>
      <name>Jenna Reps</name>
    </author>
    <author>
      <name>Jonathan M. Garibaldi</name>
    </author>
    <author>
      <name>Uwe Aickelin</name>
    </author>
    <author>
      <name>Daniele Soria</name>
    </author>
    <author>
      <name>Jack E. Gibson</name>
    </author>
    <author>
      <name>Richard B. Hubbard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 26th IEEE International Symposium on Computer-Based Medical
  Systems, Porto, pp. 548 - 549, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.5774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4399v1</id>
    <updated>2014-10-16T12:46:27Z</updated>
    <published>2014-10-16T12:46:27Z</published>
    <title>Constrained Runs algorithm as a lifting operator for the Boltzmann
  equation</title>
    <summary>  Lifting operators play an important role in starting a kinetic Boltzmann
model from given macroscopic information. The macroscopic variables need to be
mapped to the distribution functions, mesoscopic variables of the Boltzmann
model. A well-known numerical method for the initialization of Boltzmann models
is the Constrained Runs algorithm. This algorithm is used in literature for the
initialization of lattice Boltzmann models, special discretizations of the
Boltzmann equation. It is based on the attraction of the dynamics toward the
slow manifold and uses lattice Boltzmann steps to converge to the desired
dynamics on the slow manifold. We focus on applying the Constrained Runs
algorithm to map density, average flow velocity, and temperature, the
macroscopic variables, to distribution functions. Furthermore, we do not
consider only lattice Boltzmann models. We want to perform the algorithm for
different discretizations of the Boltzmann equation and consider a standard
finite volume discretization.
</summary>
    <author>
      <name>Ynte Vanderhoydonc</name>
    </author>
    <author>
      <name>Wim Vanroose</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to SIAM MMS</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.4399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4428v1</id>
    <updated>2014-10-16T13:58:04Z</updated>
    <published>2014-10-16T13:58:04Z</published>
    <title>Initialization of lattice Boltzmann models with the help of the
  numerical Chapman-Enskog expansion</title>
    <summary>  We extend the applicability of the numerical Chapman-Enskog expansion as a
lifting operator for lattice Boltzmann models to map density and momentum to
distribution functions. In earlier work [Vanderhoydonc et al. Multiscale Model.
Simul. 10(3): 766-791, 2012] such an expansion was constructed in the context
of lifting only the zeroth order velocity moment, namely the density. A lifting
operator is necessary to convert information from the macroscopic to the
mesoscopic scale. This operator is used for the initialization of lattice
Boltzmann models. Given only density and momentum, the goal is to initialize
the distribution functions of lattice Boltzmann models. For this
initialization, the numerical Chapman-Enskog expansion is used in this paper.
</summary>
    <author>
      <name>Ynte Vanderhoydonc</name>
    </author>
    <author>
      <name>Wim Vanroose</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.procs.2013.05.269</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.procs.2013.05.269" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1108.4919</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Procedia Computer Science, vol 18, pp. 1036-1045 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.4428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4598v1</id>
    <updated>2014-10-16T22:29:10Z</updated>
    <published>2014-10-16T22:29:10Z</published>
    <title>TiQuant: Software for tissue analysis, quantification and surface
  reconstruction</title>
    <summary>  Motivation: TiQuant is a modular software tool for efficient quantification
of biological tissues based on volume data obtained by biomedical image
modalities. It includes a number of versatile image and volume processing
chains tailored to the analysis of different tissue types which have been
experimentally verified. TiQuant implements a novel method for the
reconstruction of three-dimensional surfaces of biological systems, data that
often cannot be obtained experimentally but which is of utmost importance for
tissue modelling in systems biology. Availability: TiQuant is freely available
for non-commercial use at msysbio.com/tiquant. Windows, OSX and Linux are
supported.
</summary>
    <author>
      <name>Adrian Friebel</name>
    </author>
    <author>
      <name>Johannes Neitsch</name>
    </author>
    <author>
      <name>Tim Johann</name>
    </author>
    <author>
      <name>Seddik Hammad</name>
    </author>
    <author>
      <name>Jan G. Hengstler</name>
    </author>
    <author>
      <name>Dirk Drasdo</name>
    </author>
    <author>
      <name>Stefan Hoehme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.4598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6335v1</id>
    <updated>2014-10-23T12:10:11Z</updated>
    <published>2014-10-23T12:10:11Z</published>
    <title>Application of reactive transport modelling to growth and transport of
  microorganisms in the capillary fringe</title>
    <summary>  A multicomponent multiphase reactive transport simulator has been developed
to facilitate the investigation of a large variety of phenomena in porous media
including component transport, diffusion, microbiological growth and decay,
cell attachment and detachment and phase exchange. The coupled problem is
solved using operator splitting. This approach allows a flexible adaptation of
the solution strategy to the concrete problem.
  Moreover, the individual submodels were optimised to be able to describe
behaviour of Escherichia coli (HB101 K12 pGLO) in the capillary fringe in the
presence or absence of dissolved organic carbon and oxygen under steady-state
and flow conditions. Steady-state and flow through experiments in a Hele-Shaw
cell, filled with quartz sand, were conducted to study eutrophic bacterial
growth and transport in both saturated and unsaturated porous media. As E. coli
cells can form the green fluorescent protein (GFP), the cell densities,
calculated by evaluation of measured fluorescence intensities (in situ
detection) were compared with the cell densities computed by numerical
simulation. The comparison showed the laboratory experiments can be well
described by our mathematical model.
</summary>
    <author>
      <name>Pavel Hron</name>
    </author>
    <author>
      <name>Daniel Jost</name>
    </author>
    <author>
      <name>Peter Bastian</name>
    </author>
    <author>
      <name>Claudia Gallert</name>
    </author>
    <author>
      <name>Josef Winter</name>
    </author>
    <author>
      <name>Olaf Ippisch</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6951v2</id>
    <updated>2015-06-27T03:36:32Z</updated>
    <published>2014-10-25T19:09:53Z</published>
    <title>Observation of the Kibble-Zurek Mechanism in Microscopic Acoustic
  Cracking Noises</title>
    <summary>  The fast evolution of microstructure is key to understanding crackling
phenomena. It has been proposed that formation of a nonlinear zone around a
moving crack tip controls the crack tip velocity. Progress in understanding the
physics of this critical zone has been limited due to the lack of hard data
describing the detailed complex physical processes that occur within. For the
first time, we show that the signature of the non-linear elastic zone around a
microscopic dynamic crack maps directly to generic phases of acoustic noises,
supporting the formation of a strongly weak zone near the moving crack tips. We
additionally show that the rate of traversing to non-linear zone controls the
rate of weakening, i.e. speed of global rupture propagation. We measure the
power-law dependence of nonlinear zone size on the traversing rate, and show
that our observations are in agreement with the Kibble-Zurek mechanism (KZM) .
</summary>
    <author>
      <name>H. O. Ghaffari</name>
    </author>
    <author>
      <name>P. Benson</name>
    </author>
    <author>
      <name>K. Xia</name>
    </author>
    <author>
      <name>R. P. Young</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep21210</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep21210" rel="related"/>
    <link href="http://arxiv.org/abs/1410.6951v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6951v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7704v2</id>
    <updated>2015-01-16T17:25:12Z</updated>
    <published>2014-10-28T17:19:13Z</published>
    <title>Model Checking Gene Regulatory Networks</title>
    <summary>  The behaviour of gene regulatory networks (GRNs) is typically analysed using
simulation-based statistical testing-like methods. In this paper, we
demonstrate that we can replace this approach by a formal verification-like
method that gives higher assurance and scalability. We focus on Wagner weighted
GRN model with varying weights, which is used in evolutionary biology. In the
model, weight parameters represent the gene interaction strength that may
change due to genetic mutations. For a property of interest, we synthesise the
constraints over the parameter space that represent the set of GRNs satisfying
the property. We experimentally show that our parameter synthesis procedure
computes the mutational robustness of GRNs -an important problem of interest in
evolutionary biology- more efficiently than the classical simulation method. We
specify the property in linear temporal logics. We employ symbolic bounded
model checking and SMT solving to compute the space of GRNs that satisfy the
property, which amounts to synthesizing a set of linear constraints on the
weights.
</summary>
    <author>
      <name>Mirco Giacobbe</name>
    </author>
    <author>
      <name>Calin C. Guet</name>
    </author>
    <author>
      <name>Ashutosh Gupta</name>
    </author>
    <author>
      <name>Thomas A. Henzinger</name>
    </author>
    <author>
      <name>Tiago Paixao</name>
    </author>
    <author>
      <name>Tatjana Petrov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 20 references, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.7704v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7704v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7851v1</id>
    <updated>2014-10-29T01:11:14Z</updated>
    <published>2014-10-29T01:11:14Z</published>
    <title>Efficient optimisation of structures using tabu search</title>
    <summary>  This paper presents a novel approach to the optimisation of structures using
a Tabu search (TS) method. TS is a metaheuristic which is used to guide local
search methods towards a globally optimal solution by using flexible memory
cycles of differing time spans. Results are presented for the well established
ten bar truss problem and compared to results published in the literature. In
the first example a truss is optimised to minimise mass and the results
compared to results obtained using an alternative TS implementation. In the
second example, the problem has multiple objectives that are compounded into a
single objective function value using game theory. In general the results
demonstrate that the TS method is capable of solving structural optimisation
problems at least as efficiently as other numerical optimisation approaches.
</summary>
    <author>
      <name>Andy M. Connor</name>
    </author>
    <author>
      <name>Keith A. Seffen</name>
    </author>
    <author>
      <name>Geoffrey T. Parks</name>
    </author>
    <author>
      <name>P. John Clarkson</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Connor, A.M., Seffen, K.A., Clarkson, P.J. &amp; Parks, G.T. (1999)
  "Efficient optimisation of structures using tabu search" Proceedings of the
  1st ASMO/ISSMO Conference on Engineering Design Optimization, 127-134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.7851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8616v1</id>
    <updated>2014-10-31T02:05:09Z</updated>
    <published>2014-10-31T02:05:09Z</published>
    <title>Data Driven Prognosis: A multi-physics approach verified via balloon
  burst experiment</title>
    <summary>  A multi-physics formulation for Data Driven Prognosis (DDP) is developed.
Unlike traditional predictive strategies that require controlled off-line
measurements or training for determination of constitutive parameters to derive
the transitional statistics, the proposed DDP algorithm relies solely on in
situ measurements. It utilizes a deterministic mechanics framework, but the
stochastic nature of the solution arises naturally from the underlying
assumptions regarding the order of the conservation potential as well as the
number of dimensions involved. The proposed DDP scheme is capable of predicting
onset of instabilities. Since the need for off-line testing (or training) is
obviated, it can be easily implemented for systems where such a priori testing
is difficult or even impossible to conduct. The prognosis capability is
demonstrated here via a balloon burst experiment where the instability is
predicted utilizing only on-line visual observations. The DDP scheme never
failed to predict the incipient failure, and no false positives were issued.
The DDP algorithm is applicable to others types of datasets. Time horizons of
DDP predictions can be adjusted by using memory over different time windows.
Thus, a big dataset can be parsed in time to make a range of predictions over
varying time horizons.
</summary>
    <author>
      <name>Abhijit Chandra</name>
    </author>
    <author>
      <name>Oliva Kar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rspa.2014.0525</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rspa.2014.0525" rel="related"/>
    <link href="http://arxiv.org/abs/1410.8616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8674v1</id>
    <updated>2014-10-31T09:00:37Z</updated>
    <published>2014-10-31T09:00:37Z</published>
    <title>Finite element model based on refined plate theories for laminated glass
  units</title>
    <summary>  Laminated glass units exhibit complex response as a result of different
mechanical behavior and properties of glass and polymer foil. We aim to develop
a finite element model for elastic laminated glass plates based on the refined
plate theory by Mau. For a geometrically nonlinear description of the behavior
of units, each layer behaves according to the Reissner-Mindlin kinematics,
complemented with membrane effects and the von K\'{a}rm\'{a}n assumptions.
Nodal Lagrange multipliers enforce the compatibility of independent layers in
this approach. We have derived the discretized model by the energy-minimization
arguments, assuming that the unknown fields are approximated by bi-linear
functions at the element level, and solved the resulting system by the Newton
method with consistent linearization. We have demonstrated through verification
and validation examples that the proposed formulation is reliable and
accurately reproduces the behavior of laminated glass units. This study
represents a first step to the development of a comprehensive, mechanics-based
model for laminated glass systems that is suitable for implementation in common
engineering finite element solvers.
</summary>
    <author>
      <name>Alena Zemanová</name>
    </author>
    <author>
      <name>Jan Zeman</name>
    </author>
    <author>
      <name>Michal Šejnoha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1590/1679-78251676</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1590/1679-78251676" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 10 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Latin American Journal of Solids and Structures 15(6):1158--1180,
  2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.8674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2684v3</id>
    <updated>2017-01-10T19:39:39Z</updated>
    <published>2014-11-11T02:35:50Z</published>
    <title>Dual Algorithms</title>
    <summary>  The cubic spline interpolation method, the Runge--Kutta method, and the
Newton-Raphson method are extended to dual versions (developed in the context
of dual numbers). This extension allows the calculation of the derivatives of
complicated compositions of functions which are not necessarily defined by a
closed form expression. The code for the algorithms has been written in Fortran
and some examples are presented. Among them, we use the dual Newton--Raphson
method to obtain the derivatives of the output angle in the RRRCR spatial
mechanism; we use the dual normal cubic spline interpolation algorithm to
obtain the thermal diffusivity using photothermal techniques; and we use the
dual Runge--Kutta method to obtain the derivatives of functions depending on
the solution of the Duffing equation.
</summary>
    <author>
      <name>F. Penunuri</name>
    </author>
    <author>
      <name>O. Carvente</name>
    </author>
    <author>
      <name>M. A. Zambrano-Arjona</name>
    </author>
    <author>
      <name>Carlos A. Cruz-Villar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2684v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2684v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3508v1</id>
    <updated>2014-11-13T11:39:39Z</updated>
    <published>2014-11-13T11:39:39Z</published>
    <title>Geometrically nonlinear isogeometric analysis of laminated composite
  plates based on higher-order shear deformation theory</title>
    <summary>  In this paper, we present an effectively numerical approach based on
isogeometric analysis (IGA) and higher-order shear deformation theory (HSDT)
for geometrically nonlinear analysis of laminated composite plates. The HSDT
allows us to approximate displacement field that ensures by itself the
realistic shear strain energy part without shear correction factors. IGA
utilizing basis functions namely B-splines or non-uniform rational B-splines
(NURBS) enables to satisfy easily the stringent continuity requirement of the
HSDT model without any additional variables. The nonlinearity of the plates is
formed in the total Lagrange approach based on the von-Karman strain
assumptions. Numerous numerical validations for the isotropic, orthotropic,
cross-ply and angle-ply laminated plates are provided to demonstrate the
effectiveness of the proposed method.
</summary>
    <author>
      <name>Loc V. Tran</name>
    </author>
    <author>
      <name>Jaehong Lee</name>
    </author>
    <author>
      <name>H. Nguyen-Van</name>
    </author>
    <author>
      <name>H. Nguyen-Xuan</name>
    </author>
    <author>
      <name>M. Abdel Wahab</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijnonlinmec.2015.02.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijnonlinmec.2015.02.007" rel="related"/>
    <link href="http://arxiv.org/abs/1411.3508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3923v1</id>
    <updated>2014-11-13T15:49:40Z</updated>
    <published>2014-11-13T15:49:40Z</published>
    <title>Robust topology optimisation of microstructural details without length
  scale separation - using a spectral coarse basis preconditioner</title>
    <summary>  This paper applies topology optimisation to the design of structures with
periodic microstructural details without length scale separation, i.e.
considering the complete macroscopic structure and its response, while
resolving all microstructural details, as compared to the often used
homogenisation approach. The approach takes boundary conditions into account
and ensures connected and macroscopically optimised microstructures regardless
of the difference in micro- and macroscopic length scales. This results in
microstructures tailored for specific applications rather than specific
properties.
  Dealing with the complete macroscopic structure and its response is
computationally challenging as very fine discretisations are needed in order to
resolve all microstructural details. Therefore, this article shows the benefits
of applying a contrast-independent spectral preconditioner based on the
multiscale finite element method (MsFEM) to large structures with
fully-resolved microstructural details.
  The density-based topology optimisation approach combined with a Heaviside
projection filter and a stochastic robust formulation is used on various
problems, with both periodic and layered microstructures. The presented
approach is shown to allow for the topology optimisation of very large problems
in \textsc{Matlab}, specifically a problem with 26 million displacement degrees
of freedom in 26 hours using a single computational thread.
</summary>
    <author>
      <name>Joe Alexandersen</name>
    </author>
    <author>
      <name>Boyan S. Lazarov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2015.02.028</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2015.02.028" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Comput.Method.Appl.M. 290 (2015) 156-182</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.3923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4037v2</id>
    <updated>2015-04-09T13:06:43Z</updated>
    <published>2014-11-14T20:44:35Z</published>
    <title>Measure of combined effects of morphological parameters of inclusions
  within composite materials via stochastic homogenization to determine
  effective mechanical properties</title>
    <summary>  In our previous papers we have described efficient and reliable methods of
generation of representative volume elements (RVE) perfectly suitable for
analysis of composite materials via stochastic homogenization.
  In this paper we profit from these methods to analyze the influence of the
morphology on the effective mechanical properties of the samples. More
precisely, we study the dependence of main mechanical characteristics of a
composite medium on various parameters of the mixture of inclusions composed of
spheres and cylinders. On top of that we introduce various imperfections to
inclusions and observe the evolution of effective properties related to that.
  The main computational approach used throughout the work is the FFT-based
homogenization technique, validated however by comparison with the direct
finite elements method. We give details on the features of the method and the
validation campaign as well.
  Keywords: Composite materials, Cylindrical and spherical reinforcements,
Mechanical properties, Stochastic homogenization.
</summary>
    <author>
      <name>Vladimir Salnikov</name>
    </author>
    <author>
      <name>Sophie Lemaitre</name>
    </author>
    <author>
      <name>Daniel Choï</name>
    </author>
    <author>
      <name>Philippe Karamian-Surville</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruct.2015.03.076</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruct.2015.03.076" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, updated figures, version accepted to Composite Structures
  2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.4037v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4037v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4110v2</id>
    <updated>2014-12-17T07:51:04Z</updated>
    <published>2014-11-15T03:47:16Z</published>
    <title>Dynamic aerodynamic-structural coupling numerical simulation on the
  flexible wing of a cicada based on ansys</title>
    <summary>  Most biological flyers undergo orderly deformation in flight, and the
deformations of wings lead to complex fluid-structure interactions. In this
paper, an aerodynamic-structural coupling method of flapping wing is developed
based on ANSYS to simulate the flapping of flexible wing. Fluent module and
Transient Structural module are connected through the System Coupling module to
make a two-way fluid-structure Coupling computational framework. Comparing with
the rigid wing of a cicada, the coupling results of the flexible wing shows
that the flexible deformation can increase the aerodynamic performances of
flapping flight.
</summary>
    <author>
      <name>Dong Qiang</name>
    </author>
    <author>
      <name>Zhang Xi-Jin</name>
    </author>
    <author>
      <name>Zhao Ning</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures, International Journal of Recent advances in
  Mechanical Engineering (IJMECH) Vol.3, No.4, November 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.4110v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4110v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="74F10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4679v1</id>
    <updated>2014-11-17T21:40:36Z</updated>
    <published>2014-11-17T21:40:36Z</published>
    <title>Pseudo Dynamic Transitional Modeling of Building Heating Energy Demand
  Using Artificial Neural Network</title>
    <summary>  This paper presents the building heating demand prediction model with
occupancy profile and operational heating power level characteristics in short
time horizon (a couple of days) using artificial neural network. In addition,
novel pseudo dynamic transitional model is introduced, which consider time
dependent attributes of operational power level characteristics and its effect
in the overall model performance is outlined. Pseudo dynamic model is applied
to a case study of French Institution building and compared its results with
static and other pseudo dynamic neural network models. The results show the
coefficients of correlation in static and pseudo dynamic neural network model
of 0.82 and 0.89 (with energy consumption error of 0.02%) during the learning
phase, and 0.61 and 0.85 during the prediction phase respectively. Further,
orthogonal array design is applied to the pseudo dynamic model to check the
schedule of occupancy profile and operational heating power level
characteristics. The results show the new schedule and provide the robust
design for pseudo dynamic model. Due to prediction in short time horizon, it
finds application for Energy Services Company (ESCOs) to manage the heating
load for dynamic control of heat production system.
</summary>
    <author>
      <name>S. Paudel</name>
    </author>
    <author>
      <name>M. Elmtiri</name>
    </author>
    <author>
      <name>W. L. Kling</name>
    </author>
    <author>
      <name>O. Le Corre</name>
    </author>
    <author>
      <name>B. Lacarriere</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.enbuild.2013.11.051</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.enbuild.2013.11.051" rel="related"/>
    <link href="http://arxiv.org/abs/1411.4679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.6884v1</id>
    <updated>2014-11-21T15:04:31Z</updated>
    <published>2014-11-21T15:04:31Z</published>
    <title>Proportional Topology Optimization: A new non-gradient method for
  solving stress constrained and minimum compliance problems and its
  implementation in MATLAB</title>
    <summary>  A new topology optimization method called the Proportional Topology
Optimization (PTO) is presented. As a non-gradient method, PTO is simple to
understand, easy to implement, and is also efficient and accurate at the same
time. It is implemented into two MATLAB programs to solve the stress
constrained and minimum compliance problems. Descriptions of the algorithm and
computer programs are provided in detail. The method is applied to solve three
numerical examples for both types of problems. The method shows comparable
efficiency and accuracy with an existing gradient optimality criteria method.
Also, the PTO stress constrained algorithm and minimum compliance algorithm are
compared by feeding output from one algorithm to the other in an alternative
manner, where the former yields lower maximum stress and volume fraction but
higher compliance compared to the latter. Advantages and disadvantages of the
proposed method and future works are discussed. The computer programs are
self-contained and publicly shared in the website www.ptomethod.org.
</summary>
    <author>
      <name>Emre Biyikli</name>
    </author>
    <author>
      <name>Albert C. To</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0145041</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0145041" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures, and 2 appendices (MATLAB codes)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PloS one 10.12 (2015): e0145041</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.6884v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.6884v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7462v1</id>
    <updated>2014-11-27T03:45:43Z</updated>
    <published>2014-11-27T03:45:43Z</published>
    <title>Optimal Boundary Control for Water Hammer Suppression in Fluid
  Transmission Pipelines</title>
    <summary>  When fluid flow in a pipeline is suddenly halted, a pressure surge or wave is
created within the pipeline. This phenomenon, called water hammer, can cause
major damage to pipelines, including pipeline ruptures. In this paper, we model
the problem of mitigating water hammer during valve closure by an optimal
boundary control problem involving a nonlinear hyperbolic PDE system that
describes the fluid flow along the pipeline. The control variable in this
system represents the valve boundary actuation implemented at the pipeline
terminus. To solve the boundary control problem, we first use {the method of
lines} to obtain a finite-dimensional ODE model based on the original PDE
system. Then, for the boundary control design, we apply the control
parameterization method to obtain an approximate optimal parameter selection
problem that can be solved using nonlinear optimization techniques such as
Sequential Quadratic Programming (SQP). We conclude the paper with simulation
results demonstrating the capability of optimal boundary control to
significantly reduce flow fluctuation.
</summary>
    <author>
      <name>Tehuan Chen</name>
    </author>
    <author>
      <name>Chao Xu</name>
    </author>
    <author>
      <name>Zhigang Ren</name>
    </author>
    <author>
      <name>Ryan Loxton</name>
    </author>
    <link href="http://arxiv.org/abs/1411.7462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5517v1</id>
    <updated>2014-12-17T18:47:57Z</updated>
    <published>2014-12-17T18:47:57Z</published>
    <title>A perceptual hash function to store and retrieve large scale DNA
  sequences</title>
    <summary>  This paper proposes a novel approach for storing and retrieving massive DNA
sequences.. The method is based on a perceptual hash function, commonly used to
determine the similarity between digital images, that we adapted for DNA
sequences. Perceptual hash function presented here is based on a Discrete
Cosine Transform Sign Only (DCT-SO). Each nucleotide is encoded as a fixed gray
level intensity pixel and the hash is calculated from its significant frequency
characteristics. This results to a drastic data reduction between the sequence
and the perceptual hash. Unlike cryptographic hash functions, perceptual hashes
are not affected by "avalanche effect" and thus can be compared. The similarity
distance between two hashes is estimated with the Hamming Distance, which is
used to retrieve DNA sequences. Experiments that we conducted show that our
approach is relevant for storing massive DNA sequences, and retrieving them.
</summary>
    <author>
      <name>Jocelyn De Goer De Herve</name>
    </author>
    <author>
      <name>Myoung-Ah Kang</name>
    </author>
    <author>
      <name>Xavier Bailly</name>
    </author>
    <author>
      <name>Engelbert Mephu Nguifo</name>
    </author>
    <link href="http://arxiv.org/abs/1412.5517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6306v1</id>
    <updated>2014-12-19T11:53:38Z</updated>
    <published>2014-12-19T11:53:38Z</published>
    <title>Multiprocessor System Dedicated to Multi-Rotor Mini-UAV Capable of 3D
  flying</title>
    <summary>  The paper describes an electronic multiprocessor system that assures
functionality of a miniature UAV capable of 3D flying. The apparatus consists
of six independently controlled brushless DC motors, each having a propeller
attached to it. Since the brushless motor requires complex algorithms in order
to achieve maximum torque, efficiency and response time a DSP must be used. All
the motors are then controlled by a main microprocessor which is capable of
reading sensors (Inertial Measurement Unit (IMU)-orientation and GPS),
receiving input commands (remote controller or trajectory plan) and sending
independent commands to each of the six motors. The apparatus contains a total
of eight microcontrollers: the main unit, the IMU mathematical processor and
one microcontroller for each of the six brushless DC motors. Applications for
such an apparatus could include not only military, but also search-and-rescue,
geodetics, aerial photography and aerial assistance.
</summary>
    <author>
      <name>Adrian-Ioan Lita</name>
    </author>
    <author>
      <name>Ioan Plotog</name>
    </author>
    <author>
      <name>Lidia Dobrescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference of Scientific Paper AFASES 2014 Brasov,
  22-24 May 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6383v1</id>
    <updated>2014-12-19T15:40:00Z</updated>
    <published>2014-12-19T15:40:00Z</published>
    <title>SPySort: Neuronal Spike Sorting with Python</title>
    <summary>  Extracellular recordings with multi-electrode arrays is one of the basic
tools of contemporary neuroscience. These recordings are mostly used to monitor
the activities, understood as sequences of emitted action potentials, of many
individual neurons. But the raw data produced by extracellular recordings are
most commonly a mixture of activities from several neurons. In order to get the
activities of the individual contributing neurons, a pre-processing step called
spike sorting is required. We present here a pure Python implementation of a
well tested spike sorting procedure. The latter was designed in a modular way
in order to favour a smooth transition from an interactive sorting, for
instance with IPython, to an automatic one. Surprisingly enough - or sadly
enough, depending on one's view point -, recoding our now 15 years old
procedure into Python was the occasion of major methodological improvements.
</summary>
    <author>
      <name>Christophe Pouzat</name>
    </author>
    <author>
      <name>Georgios Is. Detorakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6386v1</id>
    <updated>2014-12-19T15:43:09Z</updated>
    <published>2014-12-19T15:43:09Z</published>
    <title>Using Python to Dive into Signalling Data with CellNOpt and BioServices</title>
    <summary>  Systems biology is an inter-disciplinary field that studies systems of
biological components at different scales, which may be molecules, cells or
entire organism. In particular, systems biology methods are applied to
understand functional deregulations within human cells (e.g., cancers). In this
context, we present several python packages linked to CellNOptR (R package),
which is used to build predictive logic models of signalling networks by
training networks (derived from literature) to signalling (phospho-proteomic)
data. The first package (cellnopt.wrapper) is a wrapper based on RPY2 that
allows a full access to CellNOptR functionalities within Python. The second one
(cellnopt.core) was designed to ease the manipulation and visualisation of data
structures used in CellNOptR, which was achieved by using Pandas, NetworkX and
matplotlib. Systems biology also makes extensive use of web resources and
services. We will give an overview and status of BioServices, which allows one
to access programmatically to web resources used in life science and how it can
be combined with CellNOptR.
</summary>
    <author>
      <name>Thomas Cokelaer</name>
    </author>
    <author>
      <name>Julio Saez-Rodriguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6410v1</id>
    <updated>2014-12-19T16:09:16Z</updated>
    <published>2014-12-19T16:09:16Z</published>
    <title>A Python-based Post-processing Toolset For Seismic Analyses</title>
    <summary>  This paper discusses the design and implementation of a Python-based toolset
to aid in assessing the response of the UK's Advanced Gas Reactor nuclear power
stations to earthquakes. The seismic analyses themselves are carried out with a
commercial Finite Element solver, but understanding the raw model output this
produces requires customised post-processing and visualisation tools. Extending
the existing tools had become increasingly difficult and a decision was made to
develop a new, Python-based toolset. This comprises of a post-processing
framework (aftershock) which includes an embedded Python interpreter, and a
plotting package (afterplot) based on numpy and matplotlib. The new toolset had
to be significantly more flexible and easier to maintain than the existing
code-base, while allowing the majority of development to be carried out by
engineers with little training in software development. The resulting
architecture will be described with a focus on exploring how the design drivers
were met and the successes and challenges arising from the choices made.
</summary>
    <author>
      <name>Steve Brasier</name>
    </author>
    <author>
      <name>Fred Pollard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6412v1</id>
    <updated>2014-12-19T16:12:02Z</updated>
    <published>2014-12-19T16:12:02Z</published>
    <title>Numerical simulation of liver perfusion: from CT scans to FE model</title>
    <summary>  We use a collection of Python programs for numerical simulation of liver
perfusion. We have an application for semi-automatic generation of a finite
element mesh of the human liver from computed tomography scans and for
reconstruction of the liver vascular structure. When the real vascular trees
can not be obtained from the CT data we generate artificial trees using the
constructive optimization method. The generated FE mesh and vascular trees are
imported into SfePy (Simple Finite Elements in Python) and numerical
simulations are performed in order to get the pressure distribution and
perfusion flows in the liver tissue. In the post-processing steps we calculate
transport of a contrast fluid through the liver parenchyma.
</summary>
    <author>
      <name>Vladimír Lukeš</name>
    </author>
    <author>
      <name>Miroslav Jiřík</name>
    </author>
    <author>
      <name>Alena Jonášová</name>
    </author>
    <author>
      <name>Eduard Rohan</name>
    </author>
    <author>
      <name>Ondřej Bublík</name>
    </author>
    <author>
      <name>Robert Cimrman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6850v2</id>
    <updated>2015-04-05T22:59:50Z</updated>
    <published>2014-12-22T00:55:39Z</published>
    <title>Synthesis Method for the Spherical 4R Mechanism with Minimum Center of
  Mass Acceleration</title>
    <summary>  In the mechanisms area, minimization of the magnitude of the acceleration of
the center of mass (ACoM) implies shaking force balancing. For a mechanism
operating in cycles, the case when the ACoM is zero implies that the
gravitational potential energy (GPE) is constant. This article shows an
efficient and effective optimum synthesis method for minimum acceleration of
the center of mass of a spherical 4R mechanism by using dual functions and the
counterweights balancing method. Once the dual function for ACoM has been
written, one can minimize the shaking forces from a kinematic point of view. We
present the synthesis of a spherical 4R mechanism for the case of a path
generation task. The synthesis process involves the optimization of two
objective functions, this multiobjective problem is solved by using the
weighted sum method implemented in the evolutionary algorithm known as
Differential Evolution.
</summary>
    <author>
      <name>O. Mendoza-Trejo</name>
    </author>
    <author>
      <name>Carlos A. Cruz-Villar</name>
    </author>
    <author>
      <name>R. Peón-Escalante</name>
    </author>
    <author>
      <name>M. A. Zambrano-Arjona</name>
    </author>
    <author>
      <name>F. Penunuri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6850v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6850v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7386v1</id>
    <updated>2014-12-21T13:18:39Z</updated>
    <published>2014-12-21T13:18:39Z</published>
    <title>A web-based tool to Analyze Semantic Similarity Networks</title>
    <summary>  In computational biology, biological entities such as genes or proteins are
usually annotated with terms extracted from Gene Ontology (GO). The functional
similarity among terms of an ontology is evaluated by using Semantic Similarity
Measures (SSM). More recently, the extensive application of SSMs yielded to the
Semantic Similarity Networks (SSNs). SSNs are edge-weighted graphs where the
nodes are concepts (e.g. proteins) and each edge has an associated weight that
represents the semantic similarity among related pairs of nodes. The analysis
of SSNs may reveal biologically meaningful knowledge. For these aims, the need
for the introduction of tool able to manage and analyze SSN arises.
Consequently we developed SSN-Analyzer a web based tool able to build and
preprocess SSN. As proof of concept we demonstrate that community detection
algorithms applied to filtered (thresholded) networks, have better performances
in terms of biological relevance of the results, with respect to the use of raw
unfiltered networks.
</summary>
    <author>
      <name>Mario Cannataro</name>
    </author>
    <author>
      <name>Pietro Hiram Guzzi</name>
    </author>
    <author>
      <name>Marianna Milano</name>
    </author>
    <author>
      <name>Pierangelo Veltri</name>
    </author>
    <link href="http://arxiv.org/abs/1412.7386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7811v1</id>
    <updated>2014-12-25T11:33:59Z</updated>
    <published>2014-12-25T11:33:59Z</published>
    <title>A Structured Hardware Software Architecture for Peptide Based Diagnosis
  of Baylisascaris Procyonis Infection (ICIAfS14)</title>
    <summary>  The problem of inferring proteins from complex peptide cocktails (digestion
products of biological samples) in shotgun proteomic workflow sets extreme
demands on computational resources in respect of the required very high
processing throughputs, rapid processing rates and reliability of results. This
is exacerbated by the fact that, in general, a given protein cannot be defined
by a fixed sequence of amino acids due to the existence of splice variants and
isoforms of that protein. Therefore, the problem of protein inference could be
considered as one of identifying sequences of amino acids with some limited
tolerance. In the current paper a model-based hardware acceleration of a
structured and practical inference approach is developed and validated on a
mass spectrometry experiment of realistic size. We have achieved 10 times
maximum speed-up in the co-designed workflow compared to a similar
software-only workflow run on the processor used for co-design.
</summary>
    <author>
      <name>S. M. Vidanagamachchi</name>
    </author>
    <author>
      <name>S. D. Dewasurendra</name>
    </author>
    <author>
      <name>R. G. Ragel</name>
    </author>
    <author>
      <name>M. Niranjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">appears in The 7th International Conference on Information and
  Automation for Sustainability (ICIAfS) 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.7811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7929v2</id>
    <updated>2014-12-30T11:32:32Z</updated>
    <published>2014-12-26T11:50:51Z</published>
    <title>Designing pricing schemes based on progressive tariff and consumer
  grouping in migration to a future smart grid</title>
    <summary>  We study the design of pricing schemes for a group of consumers with smart
meters (e.g., in a Greenfield area) who are connected through a gateway to a
traditional electricity greed with a progressive tariff. Because the
progressive tariff cannot take into account the time aspect of electricity
demands, we apply it to consumers in both an individual and a group basis over
a shorter time period, which can flatten the overall demand over time and
thereby reduce peak load. This scenario for the coexistence of traditional and
smart girds and the pricing schemes under this scenario can enable smooth
migration to a future smart grid.
</summary>
    <author>
      <name>Kyeong Soo Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, to be presented at International Conference on
  Information and Convergence Technology for Smart Society (ICICTS) 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.7929v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7929v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01392v1</id>
    <updated>2015-01-07T08:39:52Z</updated>
    <published>2015-01-07T08:39:52Z</published>
    <title>DSSI for pile supported asymmetrical buildings : a review</title>
    <summary>  With the reference of the several documents in the field of soil structure
interaction a document of present and past literature has been made with the
including a main focus on interaction of pile supported frames. This study
focuses on the complexity and excessive simplification of the model for
foundation system and structures, and should be carried forward for its
significance. The review is carried out including analytical, experimental and
numerical approaches considered in the past study. The perusal of literature
reveals that very few studies investigated on asymmetrical buildings supported
on pile foundations. In this paper, an attempt is made to understand research
carried out in pile soil structure interaction and research gap along with the
scope of research has been identified to carry out the present research work.
</summary>
    <author>
      <name>Pallavi Badry</name>
    </author>
    <author>
      <name>Neelima Satyam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01779v4</id>
    <updated>2016-10-25T12:16:38Z</updated>
    <published>2015-01-08T09:48:58Z</published>
    <title>Reviving the Two-state Markov Chain Approach (Technical Report)</title>
    <summary>  Probabilistic Boolean networks (PBNs) is a well-established computational
framework for modelling biological systems. The steady-state dynamics of PBNs
is of crucial importance in the study of such systems. However, for large PBNs,
which often arise in systems biology, obtaining the steady-state distribution
poses a significant challenge. In fact, statistical methods for steady-state
approximation are the only viable means when dealing with large networks. In
this paper, we revive the two-state Markov chain approach presented in the
literature. We first identify a problem of generating biased results, due to
the size of the initial sample with which the approach needs to start and we
propose a few heuristics to avoid such a pitfall. Second, we conduct an
extensive experimental comparison of the two-state Markov chain approach and
another approach based on the Skart method and we show that statistically the
two-state Markov chain has a better performance. Finally, we apply this
approach to a large PBN model of apoptosis in hepatocytes.
</summary>
    <author>
      <name>Andrzej Mizera</name>
    </author>
    <author>
      <name>Jun Pang</name>
    </author>
    <author>
      <name>Qixia Yuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01779v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01779v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03015v1</id>
    <updated>2015-01-13T14:24:58Z</updated>
    <published>2015-01-13T14:24:58Z</published>
    <title>Exploring the efficacy of molecular fragments of different complexity in
  computational SAR modeling</title>
    <summary>  An important first step in computational SAR modeling is to transform the
compounds into a representation that can be processed by predictive modeling
techniques. This is typically a feature vector where each feature indicates the
presence or absence of a molecular fragment. While the traditional approach to
SAR modeling employed size restricted fingerprints derived from path fragments,
much research in recent years focussed on mining more complex graph based
fragments. Today, there seems to be a growing consensus in the data mining
community that these more expressive fragments should be more useful. We
question this consensus and show experimentally that fragments of low
complexity, i.e. sequences, perform better than equally large sets of more
complex ones, an effect we explain by pairwise correlation among fragments and
the ability of a fragment set to encode compounds from different classes
distinctly. The size restriction on these sets is based on ordering the
fragments by class-correlation scores. In addition, we also evaluate the
effects of using a significance value instead of a length restriction for path
fragments and find a significant reduction in the number of features with
little loss in performance.
</summary>
    <author>
      <name>Albrecht Zimmermann</name>
    </author>
    <author>
      <name>Björn Bringmann</name>
    </author>
    <author>
      <name>Luc De Raedt</name>
    </author>
    <link href="http://arxiv.org/abs/1501.03015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03994v1</id>
    <updated>2015-01-16T14:45:29Z</updated>
    <published>2015-01-16T14:45:29Z</published>
    <title>Numerical modelling of sandstone uniaxial compression test using a
  mix-mode cohesive fracture model</title>
    <summary>  A mix-mode cohesive fracture model considering tension, compression and shear
material behaviour is presented, which has wide applications to geotechnical
problems. The model considers both elastic and inelastic displacements.
Inelastic displacement comprises fracture and plastic displacements. The norm
of inelastic displacement is used to control the fracture behaviour. Meantime,
a failure function describing the fracture strength is proposed. Using the
internal programming FISH, the cohesive fracture model is programmed into a
hybrid distinct element algorithm as encoded in Universal Distinct Element Code
(UDEC). The model is verified through uniaxial tension and direct shear tests.
The developed model is then applied to model the behaviour of a uniaxial
compression test on Gosford sandstone. The modelling results indicate that the
proposed cohesive fracture model is capable of simulating combined failure
behaviour applicable to rock.
</summary>
    <author>
      <name>Yilin Gui</name>
    </author>
    <author>
      <name>Ha H. Bui</name>
    </author>
    <author>
      <name>Jayantha Kodikara</name>
    </author>
    <link href="http://arxiv.org/abs/1501.03994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04000v1</id>
    <updated>2015-01-16T14:52:42Z</updated>
    <published>2015-01-16T14:52:42Z</published>
    <title>Large deformation and post-failure simulations of segmental retaining
  walls using mesh-free method (SPH)</title>
    <summary>  Numerical methods are extremely useful in gaining insights into the behaviour
of reinforced soil retaining walls. However, traditional numerical approaches
such as limit equilibrium or finite element methods are unable to simulate
large deformation and post-failure behaviour of soils and retaining wall blocks
in the reinforced soil retaining walls system. To overcome this limitation, a
novel numerical approach is developed aiming to predict accurately the large
deformation and post-failure behaviour of soil and segmental wall blocks.
Herein, soil is modelled using an elasto-plastic constitutive model, while
segmental wall blocks are assumed rigid with full degrees of freedom. A soft
contact model is proposed to simulate the interaction between soil-block and
block-block. A two dimensional experiment of reinforced soil retaining walls
collapse was conducted to verify the numerical results. It is shown that the
proposed method can simulate satisfactory post-failure behaviour of segmental
wall blocks in reinforced soil retaining wall systems. The comparison showed
that the proposed method can provide satisfactory agreement with experiments.
</summary>
    <author>
      <name>H. H. Bui</name>
    </author>
    <author>
      <name>J. A. Kodikara</name>
    </author>
    <author>
      <name>R. Pathegama</name>
    </author>
    <author>
      <name>A. Bouazza</name>
    </author>
    <author>
      <name>A. Haque</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04741v1</id>
    <updated>2015-01-20T09:06:34Z</updated>
    <published>2015-01-20T09:06:34Z</published>
    <title>Adjoint Lattice Boltzmann for Topology Optimization on multi-GPU
  architecture</title>
    <summary>  In this paper we present a topology optimization technique applicable to a
broad range of flow design problems. We propose also a discrete adjoint
formulation effective for a wide class of Lattice Boltzmann Methods (LBM). This
adjoint formulation is used to calculate sensitivity of the LBM solution to
several type of parameters, both global and local. The numerical scheme for
solving the adjoint problem has many properties of the original system,
including locality and explicit time-stepping. Thus it is possible to integrate
it with the standard LBM solver, allowing for straightforward and efficient
parallelization (overcoming limitations typical for discrete adjoint solvers).
This approach is successfully used for the channel flow to design a
free-topology mixer and a heat exchanger. Both resulting geometries being very
complex maximize their objective functions, while keeping viscous losses at
acceptable level.
</summary>
    <author>
      <name>Łukasz Łaniewski-Wołłk</name>
    </author>
    <author>
      <name>Jacek Rokicki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 11 figures, 3 tables, preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.04741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.05810v1</id>
    <updated>2015-01-23T14:30:21Z</updated>
    <published>2015-01-23T14:30:21Z</published>
    <title>Ultrascale Simulations of Non-smooth Granular Dynamics</title>
    <summary>  This article presents new algorithms for massively parallel granular dynamics
simulations on distributed memory architectures using a domain partitioning
approach. Collisions are modelled with hard contacts in order to hide their
micro-dynamics and thus to extend the time and length scales that can be
simulated. The multi-contact problem is solved using a non-linear block
Gauss-Seidel method that is conforming to the subdomain structure. The parallel
algorithms employ a sophisticated protocol between processors that delegate
algorithmic tasks such as contact treatment and position integration uniquely
and robustly to the processors. Communication overhead is minimized through
aggressive message aggregation, leading to excellent strong and weak scaling.
The robustness and scalability is assessed on three clusters including two
peta-scale supercomputers with up to 458752 processor cores. The simulations
can reach unprecedented resolution of up to ten billion non-spherical particles
and contacts.
</summary>
    <author>
      <name>Tobias Preclik</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <link href="http://arxiv.org/abs/1501.05810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.05810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05 (Primary), 70F35, 70F40, 70E55 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06873v1</id>
    <updated>2015-01-27T19:18:00Z</updated>
    <published>2015-01-27T19:18:00Z</published>
    <title>Truss Analysis Discussion and Interpretation Using Linear Systems of
  Equalities and Inequalities</title>
    <summary>  This paper shows the complementary roles of mathematical and engineering
points of view when dealing with truss analysis problems involving systems of
linear equations and inequalities. After the compatibility condition and the
mathematical structure of the general solution of a system of linear equations
is discussed, the truss analysis problem is used to illustrate its mathematical
and engineering multiple aspects, including an analysis of the compatibility
conditions and a physical interpretation of the general solution, and the
generators of the resulting affine space. Next, the compatibility and the
mathematical structure of the general solution of linear systems of
inequalities are analyzed and the truss analysis problem revisited adding some
inequality constraints, and discussing how they affect the resulting general
solution and many other aspects of it. Finally, some conclusions are drawn.
</summary>
    <author>
      <name>R. Mínguez</name>
    </author>
    <author>
      <name>E. Castillo</name>
    </author>
    <author>
      <name>R. Pruneda</name>
    </author>
    <author>
      <name>C. Solares</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages and 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07400v1</id>
    <updated>2015-01-29T10:21:24Z</updated>
    <published>2015-01-29T10:21:24Z</published>
    <title>Resilience for Exascale Enabled Multigrid Methods</title>
    <summary>  With the increasing number of components and further miniaturization the mean
time between faults in supercomputers will decrease. System level fault
tolerance techniques are expensive and cost energy, since they are often based
on redundancy. Also classical check-point-restart techniques reach their limits
when the time for storing the system state to backup memory becomes excessive.
Therefore, algorithm-based fault tolerance mechanisms can become an attractive
alternative. This article investigates the solution process for elliptic
partial differential equations that are discretized by finite elements. Faults
that occur in the parallel geometric multigrid solver are studied in various
model scenarios. In a standard domain partitioning approach, the impact of a
failure of a core or a node will affect one or several subdomains. Different
strategies are developed to compensate the effect of such a failure
algorithmically. The recovery is achieved by solving a local subproblem with
Dirichlet boundary conditions using local multigrid cycling algorithms.
Additionally, we propose a superman strategy where extra compute power is
employed to minimize the time of the recovery process.
</summary>
    <author>
      <name>Markus Huber</name>
    </author>
    <author>
      <name>Björn Gmeiner</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <author>
      <name>Barbara Wohlmuth</name>
    </author>
    <link href="http://arxiv.org/abs/1501.07400v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07400v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10, 68N30, 65N55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00495v1</id>
    <updated>2015-01-30T20:19:29Z</updated>
    <published>2015-01-30T20:19:29Z</published>
    <title>A Study of the Matter of SPH Application to Saturated Soil Problems</title>
    <summary>  We present an application of SPH to saturated soilproblems. Herein, the
standard SPH formulation was improved to model saturated soil. It is shown that
the proposed formulation could yield several advantages such as: it takes into
account the pore-water pressure in an accurate manner, it automatically
satisfies the dynamics boundary conditions between submerged soil and water,
and it reduced the computational cost. Discussions on the use of the standard
and the new SPH formulations are also given through some numerical tests.
Furthermore, some techniques to obtained correct SPH solution are also proposed
and discussed. To the end, this paper suggests that the proposed SPH
formulation should be considered as the basic formulation for further
developments of SPH for soil-water couple problems
</summary>
    <author>
      <name>H. Bui</name>
    </author>
    <author>
      <name>R. Fukagawa</name>
    </author>
    <author>
      <name>K. Sako</name>
    </author>
    <link href="http://arxiv.org/abs/1502.00495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01227v1</id>
    <updated>2015-02-04T15:11:57Z</updated>
    <published>2015-02-04T15:11:57Z</published>
    <title>Modeling Curved Carbon Fiber Composite (CFC) Structures in the
  Transmission-Line Modeling (TLM) Method</title>
    <summary>  A new embedded model for curved thin panels is developed in the Transmission
Line Modeling (TLM) method. In this model, curved panels are first linearized
and then embedded between adjacent 2D TLM nodes allowing for arbitrary
positioning between adjacent node centers. The embedded model eliminates the
necessity for fine discretization thus reducing the run time and memory
requirements for the calculation. The accuracy and convergence of the model are
verified by comparing the resonant frequencies of an elliptical cylinder formed
using carbon fiber composite (CFC) materials with those of the equivalent metal
cylinder. Furthermore, the model is used to analyze the shielding performance
of CFC airfoil NACA2415.
</summary>
    <author>
      <name>Xuesong Meng</name>
    </author>
    <author>
      <name>Phillip Sewell</name>
    </author>
    <author>
      <name>Sendy Phang</name>
    </author>
    <author>
      <name>Ana Vukovic</name>
    </author>
    <author>
      <name>Trevor M. Benson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TEMC.2015.2400055</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TEMC.2015.2400055" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures, accepted for publication in IEEE Transactions on
  EMC</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electromagnetic Compatibility, IEEE Transactions on (Volume:PP ,
  Issue: 99 ), 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.01227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03645v2</id>
    <updated>2015-07-27T13:23:04Z</updated>
    <published>2015-02-12T13:21:09Z</published>
    <title>Numerical simulation of skin transport using Parareal</title>
    <summary>  In-silico investigation of skin permeation is an important but also
computationally demanding problem. To resolve all scales involved in full
detail will not only require exascale computing capacities but also suitable
parallel algorithms. This article investigates the applicability of the
time-parallel Parareal algorithm to a brick and mortar setup, a precursory
problem to skin permeation. The C++ library Lib4PrM implementing Parareal is
combined with the UG4 simulation framework, which provides the spatial
discretization and parallelization. The combination's performance is studied
with respect to convergence and speedup. It is confirmed that anisotropies in
the domain and jumps in diffusion coefficients only have a minor impact on
Parareal's convergence. The influence of load imbalances in time due to
differences in number of iterations required by the spatial solver as well as
spatio-temporal weak scaling is discussed.
</summary>
    <author>
      <name>Andreas Kreienbuehl</name>
    </author>
    <author>
      <name>Arne Naegel</name>
    </author>
    <author>
      <name>Daniel Ruprecht</name>
    </author>
    <author>
      <name>Robert Speck</name>
    </author>
    <author>
      <name>Gabriel Wittum</name>
    </author>
    <author>
      <name>Rolf Krause</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00791-015-0246-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00791-015-0246-y" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computing and Visualization in Science 17(2), pp. 99-108, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.03645v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03645v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03774v1</id>
    <updated>2015-02-12T19:07:19Z</updated>
    <published>2015-02-12T19:07:19Z</published>
    <title>Diagnosis of diabetes using classification mining techniques</title>
    <summary>  Diabetes has affected over 246 million people worldwide with a majority of
them being women. According to the WHO report, by 2025 this number is expected
to rise to over 380 million. The disease has been named the fifth deadliest
disease in the United States with no imminent cure in sight. With the rise of
information technology and its continued advent into the medical and healthcare
sector, the cases of diabetes as well as their symptoms are well documented.
This paper aims at finding solutions to diagnose the disease by analyzing the
patterns found in the data through classification analysis by employing
Decision Tree and Na\"ive Bayes algorithms. The research hopes to propose a
quicker and more efficient technique of diagnosing the disease, leading to
timely treatment of the patients.
</summary>
    <author>
      <name>Aiswarya Iyer</name>
    </author>
    <author>
      <name>S. Jeyalatha</name>
    </author>
    <author>
      <name>Ronak Sumbaly</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdkp.2015.5101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdkp.2015.5101" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP), Vol.5, No.1, January 2015, pp. 1-14</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.03774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06564v1</id>
    <updated>2014-12-05T13:19:29Z</updated>
    <published>2014-12-05T13:19:29Z</published>
    <title>Challenges and characterization of a Biological system on Grid by means
  of the PhyloGrid application</title>
    <summary>  In this work we present a new application that is being developed. PhyloGrid
is able to perform large-scale phylogenetic calculations as those that have
been made for estimating the phylogeny of all the sequences already stored in
the public NCBI database. The further analysis has been focused on checking the
origin of the HIV-1 disease by means of a huge number of sequences that sum up
to 2900 taxa. Such a study has been able to be done by the implementation of a
workflow in Taverna.
</summary>
    <author>
      <name>Raul Isea</name>
    </author>
    <author>
      <name>Esther Montes</name>
    </author>
    <author>
      <name>Antonio J. Rubio-Montero</name>
    </author>
    <author>
      <name>Rafael Mayo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, appears in Proceedings of the First EELA-2
  Conference, 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.07847v2</id>
    <updated>2015-07-29T05:30:52Z</updated>
    <published>2015-02-27T09:59:10Z</published>
    <title>The QC Relaxation: Theoretical and Computational Results on Optimal
  Power Flow</title>
    <summary>  Convex relaxations of the power flow equations and, in particular, the
Semi-Definite Programming (SDP) and Second-Order Cone (SOC) relaxations, have
attracted significant interest in recent years. The Quadratic Convex (QC)
relaxation is a departure from these relaxations in the sense that it imposes
constraints to preserve stronger links between the voltage variables through
convex envelopes of the polar representation. This paper is a systematic study
of the QC relaxation for AC Optimal Power Flow with realistic side constraints.
The main theoretical result shows that the QC relaxation is stronger than the
SOC relaxation and neither dominates nor is dominated by the SDP relaxation. In
addition, comprehensive computational results show that the QC relaxation may
produce significant improvements in accuracy over the SOC relaxation at a
reasonable computational cost, especially for networks with tight bounds on
phase angle differences. The QC and SOC relaxations are also shown to be
significantly faster and reliable compared to the SDP relaxation given the
current state of the respective solvers.
</summary>
    <author>
      <name>Carleton Coffrin</name>
    </author>
    <author>
      <name>Hassan L. Hijazi</name>
    </author>
    <author>
      <name>Pascal Van Hentenryck</name>
    </author>
    <link href="http://arxiv.org/abs/1502.07847v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.07847v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01786v1</id>
    <updated>2015-04-08T00:11:17Z</updated>
    <published>2015-04-08T00:11:17Z</published>
    <title>ADM-CLE approach for detecting slow variables in continuous time Markov
  chains and dynamic data</title>
    <summary>  A method for detecting intrinsic slow variables in high-dimensional
stochastic chemical reaction networks is developed and analyzed. It combines
anisotropic diffusion maps (ADM) with approximations based on the chemical
Langevin equation (CLE). The resulting approach, called ADM-CLE, has the
potential of being more efficient than the ADM method for a large class of
chemical reaction systems, because it replaces the computationally most
expensive step of ADM (running local short bursts of simulations) by using an
approximation based on the CLE. The ADM-CLE approach can be used to estimate
the stationary distribution of the detected slow variable, without any a-priori
knowledge of it. If the conditional distribution of the fast variables can be
obtained analytically, then the resulting ADM-CLE approach does not make any
use of Monte Carlo simulations to estimate the distributions of both slow and
fast variables.
</summary>
    <author>
      <name>Mihai Cucuringu</name>
    </author>
    <author>
      <name>Radek Erban</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06664v1</id>
    <updated>2015-04-24T23:23:33Z</updated>
    <published>2015-04-24T23:23:33Z</published>
    <title>Fast and Rigorous DC Solution in Finite Element Method for Integrated
  Circuit Analysis</title>
    <summary>  Large scale circuit simulation, such as power delivery network analysis, has
become increasingly challenge in the VLSI design verification flow. Power
delivery network can be simulated by both SPICE-type circuit-based model and
eletromagnetics-based model when full-wave accuracy is desired. In the early
time of the time domain finite element simulation for integrated circuit, the
modes having the highest eigenvalues supported by the numerical system will be
excited. Because of the band limited source, after the early time, the modes
having a resonance frequency well beyond the input frequency band will die
down, and all physically important high-order modes and DC mode will show up
and become dominant. Among these modes, the DC mode is the last one to show up.
Although the convergence criterion is not applied on the DC mode, the existence
of DC mode in the field solution will deteriorate the convergence rate of the
first several high order modes. Therefore, this paper first analyzed the
mathematic characteristics of the DC mode and proposed a rigorous and fast
solution to extract the DC mode from the numerical system in order to speed up
the convergence rate. Experimental results demonstrated the robustness and
superior performance of this method.
</summary>
    <author>
      <name>Q. He</name>
    </author>
    <link href="http://arxiv.org/abs/1504.06664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07499v1</id>
    <updated>2015-04-28T14:32:52Z</updated>
    <published>2015-04-28T14:32:52Z</published>
    <title>Computation of thermal properties via 3D homogenization of multiphase
  materials using FFT-based accelerated scheme</title>
    <summary>  In this paper we study the thermal effective behaviour for 3D multiphase
composite material consisting of three isotropic phases which are the matrix,
the inclusions and the coating media. For this purpose we use an accelerated
FFT-based scheme initially proposed in Eyre and Milton (1999) to evaluate the
thermal conductivity tensor. Matrix and spherical inclusions media are polymers
with similar properties whereas the coating medium is metallic hence better
conducting. Thus, the contrast between the coating and the others media is very
large. For our study, we use RVEs (Representative volume elements) generated by
RSA (Random Sequential Adsorption) method developed in our previous works,
then, we compute effective thermal properties using an FFT-based homogenization
technique validated by comparison with the direct finite elements method. We
study the thermal behaviour of the 3D-multiphase composite material and we show
what features should be taken into account to make the computational approach
efficient.
</summary>
    <author>
      <name>Sophie Lemaitre</name>
    </author>
    <author>
      <name>Vladimir Salnikov</name>
    </author>
    <author>
      <name>Daniel Choi</name>
    </author>
    <author>
      <name>Philippe Karamian</name>
    </author>
    <link href="http://arxiv.org/abs/1504.07499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00078v1</id>
    <updated>2015-05-01T03:01:11Z</updated>
    <published>2015-05-01T03:01:11Z</published>
    <title>Cyber physical modeling of distributed resources for distribution system
  operations</title>
    <summary>  Co-simulation platforms are necessary to study the interactions of complex
systems integrated in future smart grids. The Virtual Grid Integration
Laboratory (VirGIL) is a modular co-simulation platform designed to study
interactions between demand response strategies, building comfort,
communication networks, and power system operation. This paper presents the
coupling of power systems, buildings, communications and control under a master
algorithm. There are two objectives. First, to use a modular architecture for
VirGIL, based on the Functional Mock-up Interface (FMI), where several
different modules can be added, exchanged, and tested. Second, to use a
commercial power system simulation platform, familiar to power system
operators, such as DIgSILENT Powerfactory. This will help reduce the barriers
to the industry for adopting such platforms, investigate and subsequently
deploy demand response strategies in their daily operation. VirGIL further
introduces the integration of the Quantized State System (QSS) methods for
simulation in this co-simulation platform. Results on how these systems
interact using a real network and consumption data are also presented.
</summary>
    <author>
      <name>Spyros Chatzivasileiadis</name>
    </author>
    <author>
      <name>Marco Bonvini</name>
    </author>
    <author>
      <name>Javier Matanza</name>
    </author>
    <author>
      <name>Rongxin Yin</name>
    </author>
    <author>
      <name>Zhenhua Liu</name>
    </author>
    <author>
      <name>Thierry Nouidui</name>
    </author>
    <author>
      <name>Emre C. Kara</name>
    </author>
    <author>
      <name>Rajiv Parmar</name>
    </author>
    <author>
      <name>David Lorenzetti</name>
    </author>
    <author>
      <name>Michael Wetter</name>
    </author>
    <author>
      <name>Sila Kiliccote</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04036v3</id>
    <updated>2017-09-26T07:26:13Z</updated>
    <published>2015-05-15T11:30:30Z</published>
    <title>Unified way for computing dynamics of Bose-Einstein condensates and
  degenerate Fermi gases</title>
    <summary>  In this work we present a very simple and efficient numerical scheme which
can be applied to study the dynamics of bosonic systems like, for instance,
spinor Bose-Einstein condensates with nonlocal interactions but equally well
works for Fermi gases. The method we use is a modification of well known Split
Operator Method (SOM). We carefully examine this algorithm in the case of $F=1$
spinor Bose-Einstein condensate without and with dipolar interactions and for
strongly interacting two-component Fermi gas. Our extension of the SOM method
has many advantages: it is fast, stable, and keeps constant all the physical
constraints (constants of motion) at high level.
</summary>
    <author>
      <name>Krzysztof Gawryluk</name>
    </author>
    <author>
      <name>Tomasz Karpiuk</name>
    </author>
    <author>
      <name>Mariusz Gajda</name>
    </author>
    <author>
      <name>Kazimierz Rzazewski</name>
    </author>
    <author>
      <name>Miroslaw Brewczyk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/00207160.2017.1370545</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/00207160.2017.1370545" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04036v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04036v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.quant-gas" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06282v1</id>
    <updated>2015-05-23T07:29:22Z</updated>
    <published>2015-05-23T07:29:22Z</published>
    <title>Are we far from correctly inferring gene interaction networks with
  Lasso?</title>
    <summary>  Detecting the interactions of genetic compounds like genes, SNPs, proteins,
metabolites, etc. can potentially unravel the mechanisms behind complex traits
and common genetic disorders. Several methods have been taken into
consideration for the analysis of different types of genetic data, regression
being one of the most widely adopted. Without any doubt, a common data type is
represented by gene expression profiles, from which gene regulatory networks
have been inferred with different approaches. In this work we review nine
penalised regression methods applied to microarray data to infer the topology
of the network of interactions. We evaluate each method with respect to the
complexity of biological data. We analyse the limitations of each of them in
order to suggest a number of precautions that should be considered to make
their predictions more significant and reliable.
</summary>
    <author>
      <name>Francesco Gadaleta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.06282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06607v2</id>
    <updated>2015-05-26T17:09:21Z</updated>
    <published>2015-05-25T12:28:03Z</published>
    <title>Stochastic Block Coordinate Frank-Wolfe Algorithm for Large-Scale
  Biological Network Alignment</title>
    <summary>  With increasingly "big" data available in biomedical research, deriving
accurate and reproducible biology knowledge from such big data imposes enormous
computational challenges. In this paper, motivated by recently developed
stochastic block coordinate algorithms, we propose a highly scalable randomized
block coordinate Frank-Wolfe algorithm for convex optimization with general
compact convex constraints, which has diverse applications in analyzing
biomedical data for better understanding cellular and disease mechanisms. We
focus on implementing the derived stochastic block coordinate algorithm to
align protein-protein interaction networks for identifying conserved functional
pathways based on the IsoRank framework. Our derived stochastic block
coordinate Frank-Wolfe (SBCFW) algorithm has the convergence guarantee and
naturally leads to the decreased computational cost (time and space) for each
iteration. Our experiments for querying conserved functional protein complexes
in yeast networks confirm the effectiveness of this technique for analyzing
large-scale biological networks.
</summary>
    <author>
      <name>Yijie Wang</name>
    </author>
    <author>
      <name>Xiaoning Qian</name>
    </author>
    <link href="http://arxiv.org/abs/1505.06607v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06607v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06751v1</id>
    <updated>2015-05-20T15:46:45Z</updated>
    <published>2015-05-20T15:46:45Z</published>
    <title>Novel Mining of Cancer via Mutation in Tumor Protein P53 using Quick
  Propagation Network</title>
    <summary>  There is multiple databases contain datasets of TP53 gene and its tumor
protein P53 which believed to be involved in over 50% of human cancers cases,
these databases are rich as datasets covered all mutations caused diseases
(cancers), but they haven't efficient mining method can classify and diagnosis
mutations patient's then predict the cancer of that patient. This paper
proposed a novel mining of cancer via mutations because there is no mining
method before offers friendly, effective and flexible predict or diagnosis of
cancers via using whole common database of TP53 gene (tumor protein P53) as
dataset and selecting a minimum number of fields in training and testing quick
propagation algorithm which supporting this miming method. Simulating quick
propagation network for the train dataset shows results the Correlation
(0.9999), R-squared (0.9998) and mean of Absolute Relative Error (0.0029),
while the training for the ALL datasets (train, test and validation dataset)
have results the Correlation (0.9993), R-squared (0.9987) and mean of Absolute
Relative Error (0.0057).
</summary>
    <author>
      <name>Ayad Ghany Ismaeel</name>
    </author>
    <author>
      <name>Raghad Zuhair Yousif</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages, 9 figures, 2 Table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Electronics
  Engineering IJCSEE, Volume 3, Issue 2, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.06751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00080v2</id>
    <updated>2015-07-03T12:08:25Z</updated>
    <published>2015-05-30T07:02:48Z</published>
    <title>Integration of Gene Expression Data and Methylation Reveals Genetic
  Networks for Glioblastoma</title>
    <summary>  Motivation: The consistent amount of different types of omics data requires
novel methods of analysis and data integration. In this work we describe
Regression2Net, a computational approach to analyse gene expression and
methylation profiles via regression analysis and network-based techniques.
  Results: We identified 284 and 447 unique candidate genes potentially
associated to the Glioblastoma pathology from two networks inferred from mixed
genetic datasets. In-depth biological analysis of these networks reveals genes
that are related to energy metabolism, cell cycle control (AATF), immune system
response and several types of cancer. Importantly, we observed significant
over- representation of cancer related pathways including glioma especially in
the methylation network. This confirms the strong link between methylation and
glioblastomas. Potential glioma suppressor genes ACCN3 and ACCN4 linked to
NBPF1 neuroblastoma breakpoint family have been identified in our expression
network. Numerous ABC transporter genes (ABCA1, ABCB1) present in the
expression network suggest drug resistance of glioblastoma tumors.
</summary>
    <author>
      <name>Francesco Gadaleta</name>
    </author>
    <author>
      <name>Kyrylo Bessonov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to submission to
  commercial journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.00080v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00080v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00571v6</id>
    <updated>2023-11-05T15:30:34Z</updated>
    <published>2015-06-01T17:04:23Z</published>
    <title>Calculation of the confidence bounds for the fraction nonconforming of
  normal populations of measurements in clinical laboratory medicine</title>
    <summary>  The fraction nonconforming is a key quality measure used in statistical
quality control design in clinical laboratory medicine. The confidence bounds
of normal populations of measurements for the fraction nonconforming each of
the lower and upper quality specification limits when both the random and the
systematic error are unknown can be calculated using the noncentral
t-distribution, as it is described in detail and illustrated with examples.
</summary>
    <author>
      <name>Aristides T. Hatjimihail</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 5 tables, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.00571v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00571v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="6804" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00716v1</id>
    <updated>2015-06-02T00:37:50Z</updated>
    <published>2015-06-02T00:37:50Z</published>
    <title>Tackling Exascale Software Challenges in Molecular Dynamics Simulations
  with GROMACS</title>
    <summary>  GROMACS is a widely used package for biomolecular simulation, and over the
last two decades it has evolved from small-scale efficiency to advanced
heterogeneous acceleration and multi-level parallelism targeting some of the
largest supercomputers in the world. Here, we describe some of the ways we have
been able to realize this through the use of parallelization on all levels,
combined with a constant focus on absolute performance. Release 4.6 of GROMACS
uses SIMD acceleration on a wide range of architectures, GPU offloading
acceleration, and both OpenMP and MPI parallelism within and between nodes,
respectively. The recent work on acceleration made it necessary to revisit the
fundamental algorithms of molecular simulation, including the concept of
neighborsearching, and we discuss the present and future challenges we see for
exascale simulation - in particular a very fine-grained task parallelism. We
also discuss the software management, code peer review and continuous
integration testing required for a project of this complexity.
</summary>
    <author>
      <name>Páll Szilárd</name>
    </author>
    <author>
      <name>Mark James Abraham</name>
    </author>
    <author>
      <name>Carsten Kutzner</name>
    </author>
    <author>
      <name>Berk Hess</name>
    </author>
    <author>
      <name>Erik Lindahl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-15976-8_1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-15976-8_1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EASC 2014 conference proceeding</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. EASC 2014, 8759 pp. 3-27, Springer LNCS</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.00716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2; I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03611v1</id>
    <updated>2015-06-11T10:18:17Z</updated>
    <published>2015-06-11T10:18:17Z</published>
    <title>A correction to the enhanced bottom drag parameterisation of tidal
  turbines</title>
    <summary>  Hydrodynamic modelling is an important tool for the development of tidal
stream energy projects. Many hydrodynamic models incorporate the effect of
tidal turbines through an enhanced bottom drag. In this paper we show that
although for coarse grid resolutions (kilometre scale) the resulting force
exerted on the flow agrees well with the theoretical value, the force starts
decreasing with decreasing grid sizes when these become smaller than the length
scale of the wake recovery. This is because the assumption that the upstream
velocity can be approximated by the local model velocity, is no longer valid.
Using linear momentum actuator disc theory however, we derive a relationship
between these two velocities and formulate a correction to the enhanced bottom
drag formulation that consistently applies a force that remains closed to the
theoretical value, for all grid sizes down to the turbine scale. In addition, a
better understanding of the relation between the model, upstream, and actual
turbine velocity, as predicted by actuator disc theory, leads to an improved
estimate of the usefully extractable energy. We show how the corrections can be
applied (demonstrated here for the models MIKE 21 and Fluidity) by a simple
modification of the drag coefficient.
</summary>
    <author>
      <name>Stephan C Kramer</name>
    </author>
    <author>
      <name>Matthew D Piggott</name>
    </author>
    <link href="http://arxiv.org/abs/1506.03611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05887v1</id>
    <updated>2015-06-19T06:37:46Z</updated>
    <published>2015-06-19T06:37:46Z</published>
    <title>A Genetically Modified Hoare Logic</title>
    <summary>  An important problem when modeling gene networks lies in the identification
of parameters, even if we consider a purely discrete framework as the one of
Ren\'e Thomas. Here we are interested in the exhaustive search of all parameter
values that are consistent with observed behaviors of the gene network. We
present in this article a new approach based on Hoare Logic and on a weakest
precondition calculus to generate constraints on possible parameter values.
Observed behaviors play the role of "programs" for the classical Hoare logic,
and computed weakest preconditions represent the sets of all compatible
parameterizations expressed as constraints on parameters. Finally we give a
proof of correctness of our Hoare logic for gene networks as well as a proof of
completeness based on the computation of the weakest precondition.
</summary>
    <author>
      <name>Gilles Bernot</name>
    </author>
    <author>
      <name>Jean-Paul Comet</name>
    </author>
    <author>
      <name>Zohra Khalis</name>
    </author>
    <author>
      <name>Adrien Richard</name>
    </author>
    <author>
      <name>Olivier Roux</name>
    </author>
    <link href="http://arxiv.org/abs/1506.05887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05905v2</id>
    <updated>2016-04-14T12:07:18Z</updated>
    <published>2015-06-19T08:25:29Z</published>
    <title>Quantum IsoRank: Efficient Alignment of Multiple PPI Networks</title>
    <summary>  Comparative analyses of protein-protein interaction networks play important
roles in the understanding of biological processes. However, the growing
enormity of available data on the networks becomes a computational challenge
for the conventional alignment algorithms. Quantum algorithms generally provide
greater efficiency over their classical counterparts in solving various
problems.
  One of such algorithms is the quantum phase estimation algorithm which
generates the principal eigenvector of a stochastic matrix with probability
one.
  Using the quantum phase estimation algorithm, we introduce a quantum
computing approach for the alignment of protein-protein interaction networks by
following the classical algorithm IsoRank which uses the principal eigenvector
of the stochastic matrix representing the Kronecker product of the normalized
adjacency matrices of networks for the pairwise alignment. We also present a
greedy quantum measurement scheme to efficiently procure the alignment from the
output state of the phase estimation algorithm where the eigenvector is encoded
as the amplitudes of this state. The complexity of the quantum approach
outperforms the classical running time.
</summary>
    <author>
      <name>Anmer Daskin</name>
    </author>
    <link href="http://arxiv.org/abs/1506.05905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06366v1</id>
    <updated>2015-06-21T14:03:42Z</updated>
    <published>2015-06-21T14:03:42Z</published>
    <title>A Novel Method for Stock Forecasting based on Fuzzy Time Series Combined
  with the Longest Common/Repeated Sub-sequence</title>
    <summary>  Stock price forecasting is an important issue for investors since extreme
accuracy in forecasting can bring about high profits. Fuzzy Time Series (FTS)
and Longest Common/Repeated Sub-sequence (LCS/LRS) are two important issues for
forecasting prices. However, to the best of our knowledge, there are no
significant studies using LCS/LRS to predict stock prices. It is impossible
that prices stay exactly the same as historic prices. Therefore, this paper
proposes a state-of-the-art method which combines FTS and LCS/LRS to predict
stock prices. This method is based on the principle that history will repeat
itself. It uses different interval lengths in FTS to fuzzify the prices, and
LCS/LRS to look for the same pattern in the historical prices to predict future
stock prices. In the experiment, we examine various intervals of fuzzy time
sets in order to achieve high prediction accuracy. The proposed method
outperforms traditional methods in terms of prediction accuracy and,
furthermore, it is easy to implement.
</summary>
    <author>
      <name>He-Wen Chen</name>
    </author>
    <author>
      <name>Zih-Ci Wang</name>
    </author>
    <author>
      <name>Shu-Yu Kuo</name>
    </author>
    <author>
      <name>Yao-Hsin Chou</name>
    </author>
    <link href="http://arxiv.org/abs/1506.06366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07214v1</id>
    <updated>2015-06-24T00:04:44Z</updated>
    <published>2015-06-24T00:04:44Z</published>
    <title>Convex Relaxations for Gas Expansion Planning</title>
    <summary>  Expansion of natural gas networks is a critical process involving substantial
capital expenditures with complex decision-support requirements. Given the
non-convex nature of gas transmission constraints, global optimality and
infeasibility guarantees can only be offered by global optimisation approaches.
Unfortunately, state-of-the-art global optimisation solvers are unable to scale
up to real-world size instances. In this study, we present a convex
mixed-integer second-order cone relaxation for the gas expansion planning
problem under steady-state conditions. The underlying model offers tight lower
bounds with high computational efficiency. In addition, the optimal solution of
the relaxation can often be used to derive high-quality solutions to the
original problem, leading to provably tight optimality gaps and, in some cases,
global optimal soluutions. The convex relaxation is based on a few key ideas,
including the introduction of flux direction variables, exact McCormick
relaxations, on/off constraints, and integer cuts. Numerical experiments are
conducted on the traditional Belgian gas network, as well as other real larger
networks. The results demonstrate both the accuracy and computational speed of
the relaxation and its ability to produce high-quality solutions.
</summary>
    <author>
      <name>Conrado Borraz-Sanchez</name>
    </author>
    <author>
      <name>Russell Bent</name>
    </author>
    <author>
      <name>Scott Backhaus</name>
    </author>
    <author>
      <name>Hassan Hijazi</name>
    </author>
    <author>
      <name>Pascal Van Hentenryck</name>
    </author>
    <link href="http://arxiv.org/abs/1506.07214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.09000v1</id>
    <updated>2015-06-30T09:13:13Z</updated>
    <published>2015-06-30T09:13:13Z</published>
    <title>Decision-level multi-method fusion of spatially scattered data from
  nondestructive inspection of ferromagnetic parts</title>
    <summary>  This article deals with the fusion of flaw detections from multi-sensor
nondestructive materials testing. Because each testing method makes use of
different physical effects for defect localization, a multi-method approach is
promising to effectively distinguish the many false alarms from actual material
defects. To this end, we propose a new fusion technique for scattered two- or
three-dimensional location data. Using a density-based approach, the proposed
method is able to explicitly address the localization uncertainties such as
registration errors. We provide guidelines on how to set all key parameters and
demonstrate the technique's robustness. Finally, we apply our fusion approach
to experimental data and demonstrate its ability to find small defects by
substantially reducing false alarms under conditions where no single-sensor
method is adequate.
</summary>
    <author>
      <name>René Heideklang</name>
    </author>
    <author>
      <name>Parisa Shokouhi</name>
    </author>
    <link href="http://arxiv.org/abs/1506.09000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.09000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.09163v1</id>
    <updated>2015-06-30T17:17:10Z</updated>
    <published>2015-06-30T17:17:10Z</published>
    <title>Comment partitionner automatiquement des marches aléatoires ? Avec
  application à la finance quantitative</title>
    <summary>  We present in this paper a novel non-parametric approach useful for
clustering Markov processes. We introduce a pre-processing step consisting in
mapping multivariate independent and identically distributed samples from
random variables to a generic non-parametric representation which factorizes
dependency and marginal distribution apart without losing any. An associated
metric is defined where the balance between random variables dependency and
distribution information is controlled by a single parameter. This mixing
parameter can be learned or played with by a practitioner, such use is
illustrated on the case of clustering financial time series. Experiments,
implementation and results obtained on public financial time series are online
on a web portal \url{http://www.datagrapple.com}.
</summary>
    <author>
      <name>Gautier Marti</name>
    </author>
    <author>
      <name>Frank Nielsen</name>
    </author>
    <author>
      <name>Philippe Very</name>
    </author>
    <author>
      <name>Philippe Donnat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.09163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.09163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00113v1</id>
    <updated>2015-07-01T05:51:56Z</updated>
    <published>2015-07-01T05:51:56Z</published>
    <title>Multiscale model reduction for shale gas transport in fractured media</title>
    <summary>  In this paper, we develop a multiscale model reduction technique that
describes shale gas transport in fractured media. Due to the pore-scale
heterogeneities and processes, we use upscaled models to describe the matrix.
We follow our previous work \cite{aes14}, where we derived an upscaled model in
the form of generalized nonlinear diffusion model to describe the effects of
kerogen. To model the interaction between the matrix and the fractures, we use
Generalized Multiscale Finite Element Method. In this approach, the matrix and
the fracture interaction is modeled via local multiscale basis functions. We
developed the GMsFEM and applied for linear flows with horizontal or vertical
fracture orientations on a Cartesian fine grid. In this paper, we consider
arbitrary fracture orientations and use triangular fine grid and developed
GMsFEM for nonlinear flows. Moreover, we develop online basis function
strategies to adaptively improve the convergence. The number of multiscale
basis functions in each coarse region represents the degrees of freedom needed
to achieve a certain error threshold. Our approach is adaptive in a sense that
the multiscale basis functions can be added in the regions of interest.
Numerical results for two-dimensional problem are presented to demonstrate the
efficiency of proposed approach.
</summary>
    <author>
      <name>I. Y. Akkutlu</name>
    </author>
    <author>
      <name>Yalchin Efendiev</name>
    </author>
    <author>
      <name>Maria Vasilyeva</name>
    </author>
    <link href="http://arxiv.org/abs/1507.00113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00219v1</id>
    <updated>2015-07-01T13:12:38Z</updated>
    <published>2015-07-01T13:12:38Z</published>
    <title>TurboMOR: an Efficient Model Order Reduction Technique for RC Networks
  with Many Ports</title>
    <summary>  Model order reduction (MOR) techniques play a crucial role in the
computer-aided design of modern integrated circuits, where they are used to
reduce the size of parasitic networks. Unfortunately, the efficient reduction
of passive networks with many ports is still an open problem. Existing
techniques do not scale well with the number of ports, and lead to dense
reduced models that burden subsequent simulations. In this paper, we propose
TurboMOR, a novel MOR technique for the efficient reduction of passive RC
networks. TurboMOR is based on moment-matching, achieved through efficient
congruence transformations based on Householder reflections. A novel feature of
TurboMOR is the block-diagonal structure of the reduced models, that makes them
more efficient than the dense models produced by existing techniques. Moreover,
the model structure allows for an insightful interpretation of the reduction
process in terms of system theory. Numerical results show that TurboMOR scales
more favourably than existing techniques in terms of reduction time, simulation
time and memory consumption.
</summary>
    <author>
      <name>Denis Oyaro</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCAD.2016.2531046</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCAD.2016.2531046" rel="related"/>
    <link href="http://arxiv.org/abs/1507.00219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01894v2</id>
    <updated>2015-07-08T12:17:16Z</updated>
    <published>2015-07-07T17:38:44Z</published>
    <title>On pore-scale modeling and simulation of reactive transport in 3D
  geometries</title>
    <summary>  Pore-scale modeling and simulation of reactive flow in porous media has a
range of diverse applications, and poses a number of research challenges. It is
known that the morphology of a porous medium has significant influence on the
local flow rate, which can have a substantial impact on the rate of chemical
reactions. While there are a large number of papers and software tools
dedicated to simulating either fluid flow in 3D computerized tomography (CT)
images or reactive flow using pore-network models, little attention to date has
been focused on the pore-scale simulation of sorptive transport in 3D CT
images, which is the specific focus of this paper. Here we first present an
algorithm for the simulation of such reactive flows directly on images, which
is implemented in a sophisticated software package. We then use this software
to present numerical results in two resolved geometries, illustrating the
importance of pore-scale simulation and the flexibility of our software
package.
</summary>
    <author>
      <name>Oleg Iliev</name>
    </author>
    <author>
      <name>Zahra Lakdawala</name>
    </author>
    <author>
      <name>Katherine Leonard</name>
    </author>
    <author>
      <name>Yavor Vutov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01894v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01894v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05272v1</id>
    <updated>2015-07-19T10:19:08Z</updated>
    <published>2015-07-19T10:19:08Z</published>
    <title>Optimizing Phylogenetic Supertrees Using Answer Set Programming</title>
    <summary>  The supertree construction problem is about combining several phylogenetic
trees with possibly conflicting information into a single tree that has all the
leaves of the source trees as its leaves and the relationships between the
leaves are as consistent with the source trees as possible. This leads to an
optimization problem that is computationally challenging and typically
heuristic methods, such as matrix representation with parsimony (MRP), are
used. In this paper we consider the use of answer set programming to solve the
supertree construction problem in terms of two alternative encodings. The first
is based on an existing encoding of trees using substructures known as
quartets, while the other novel encoding captures the relationships present in
trees through direct projections. We use these encodings to compute a
genus-level supertree for the family of cats (Felidae). Furthermore, we compare
our results to recent supertrees obtained by the MRP method.
</summary>
    <author>
      <name>Laura Koponen</name>
    </author>
    <author>
      <name>Emilia Oikarinen</name>
    </author>
    <author>
      <name>Tomi Janhunen</name>
    </author>
    <author>
      <name>Laura Säilä</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/S1471068415000265</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/S1471068415000265" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Theory and Practice of Logic Programming (TPLP),
  Proceedings of ICLP 2015</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Theory and Practice of Logic Programming 15 (2015) 604-619</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.05272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05795v2</id>
    <updated>2016-07-07T13:05:54Z</updated>
    <published>2015-07-21T11:55:18Z</published>
    <title>Design optimisation and resource assessment for tidal-stream renewable
  energy farms using a new continuous turbine approach</title>
    <summary>  This paper presents a new approach for optimising the design of tidal stream
turbine farms. In this approach, the turbine farm is represented by a turbine
density function that specifies the number of turbines per unit area and an
associated continuous locally-enhanced bottom friction field. The farm design
question is formulated as a mathematical optimisation problem constrained by
the shallow water equations and solved with efficient, gradient-based
optimisation methods. The resulting method is accurate, computationally
efficient, allows complex installation constraints, and supports different goal
quantities such as to maximise power or profit. The outputs of the optimisation
are the optimal number of turbines, their location within the farm, the overall
farm profit, the farm's power extraction, and the installation cost. We
demonstrate the capabilities of the method on a validated numerical model of
the Pentland Firth, Scotland. We optimise the design of four tidal farms
simultaneously, as well as individually, and study how farms in close proximity
may impact upon one another.
</summary>
    <author>
      <name>Simon W. Funke</name>
    </author>
    <author>
      <name>Stephan C. Kramer</name>
    </author>
    <author>
      <name>Matthew D. Piggott</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Renewable Energy, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.05795v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05795v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.1.8; G.4; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.06565v1</id>
    <updated>2015-07-23T17:03:20Z</updated>
    <published>2015-07-23T17:03:20Z</published>
    <title>Large scale lattice Boltzmann simulation for the coupling of free and
  porous media flow</title>
    <summary>  In this work, we investigate the interaction of free and porous media flow by
large scale lattice Boltzmann simulations. We study the transport phenomena at
the porous interface on multiple scales, i.e., we consider both,
computationally generated pore-scale geometries and homogenized models at a
macroscopic scale. The pore-scale results are compared to those obtained by
using different transmission models. Two-domain approaches with sharp interface
conditions, e.g., of Beavers--Joseph--Saffman type, as well as a single-domain
approach with a porosity depending viscosity are taken into account. For the
pore-scale simulations, we use a highly scalable communication-reducing scheme
with a robust second order boundary handling. We comment on computational
aspects of the pore-scale simulation and on how to generate pore-scale
geometries. The two-domain approaches depend sensitively on the choice of the
exact position of the interface, whereas a well-designed single-domain approach
can significantly better recover the averaged pore-scale results.
</summary>
    <author>
      <name>Ehsan Fattahi</name>
    </author>
    <author>
      <name>Christian Waluga</name>
    </author>
    <author>
      <name>Barbara Wohlmuth</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <link href="http://arxiv.org/abs/1507.06565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.06565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07548v1</id>
    <updated>2015-07-25T20:42:48Z</updated>
    <published>2015-07-25T20:42:48Z</published>
    <title>ms2: A molecular simulation tool for thermodynamic properties, new
  version release</title>
    <summary>  A new version release (2.0) of the molecular simulation tool ms2 [S. Deublein
et al., Comput. Phys. Commun. 182 (2011) 2350] is presented. Version 2.0 of ms2
features a hybrid parallelization based on MPI and OpenMP for molecular
dynamics simulation to achieve higher scalability. Furthermore, the formalism
by Lustig [R. Lustig, Mol. Phys. 110 (2012) 3041] is implemented, allowing for
a systematic sampling of Massieu potential derivatives in a single simulation
run. Moreover, the Green-Kubo formalism is extended for the sampling of the
electric conductivity and the residence time. To remove the restriction of the
preceding version to electro-neutral molecules, Ewald summation is implemented
to consider ionic long range interactions. Finally, the sampling of the radial
distribution function is added.
</summary>
    <author>
      <name>Colin W. Glass</name>
    </author>
    <author>
      <name>Steffen Reiser</name>
    </author>
    <author>
      <name>Gábor Rutkai</name>
    </author>
    <author>
      <name>Stephan Deublein</name>
    </author>
    <author>
      <name>Andreas Köster</name>
    </author>
    <author>
      <name>Gabriela Guevara Carrión</name>
    </author>
    <author>
      <name>Amer Wafai</name>
    </author>
    <author>
      <name>Martin Horsch</name>
    </author>
    <author>
      <name>Martin F. Bernreuther</name>
    </author>
    <author>
      <name>Thorsten Windmann</name>
    </author>
    <author>
      <name>Hans Hasse</name>
    </author>
    <author>
      <name>Jadran Vrabec</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cpc.2014.07.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cpc.2014.07.012" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Physics Communications 185 (12): 3302-3306 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.07548v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07548v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.01041v2</id>
    <updated>2016-04-20T15:15:31Z</updated>
    <published>2015-08-05T11:57:14Z</published>
    <title>Implementation of the Log-Conformation Formulation for Two-Dimensional
  Viscoelastic Flow</title>
    <summary>  We have implemented the log-conformation method for two-dimensional
viscoelastic flow in COMSOL, a commercial high-level finite element package.
The code is verified for an Oldroyd-B fluid flowing past a confined cylinder.
We are also able to describe the well-known bistability of the viscoelastic
flow in a cross-slot geometry for a FENE-CR fluid, and we describe the changes
required for performing simulations with the Phan-Thien-Tanner (PTT), Giesekus
and FENE-P models. Finally, we calculate the flow of a FENE-CR fluid in a
geometry with three in- and outlets. The implementation is included in the
supplementary material, and we hope that it can inspire new as well as
experienced researchers in the field of differential constitutive equations for
viscoelastic flow.
</summary>
    <author>
      <name>K. E. Jensen</name>
    </author>
    <author>
      <name>P. Szabo</name>
    </author>
    <author>
      <name>F. Okkels</name>
    </author>
    <link href="http://arxiv.org/abs/1508.01041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.01041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02489v1</id>
    <updated>2015-08-11T05:08:25Z</updated>
    <published>2015-08-11T05:08:25Z</published>
    <title>Probabilistic Power Flow Computation via Low-Rank and Sparse Tensor
  Recovery</title>
    <summary>  This paper presents a tensor-recovery method to solve probabilistic power
flow problems. Our approach generates a high-dimensional and sparse generalized
polynomial-chaos expansion that provides useful statistical information. The
result can also speed up other essential routines in power systems (e.g.,
stochastic planning, operations and controls).
  Instead of simulating a power flow equation at all quadrature points, our
approach only simulates an extremely small subset of samples. We suggest a
model to exploit the underlying low-rank and sparse structure of
high-dimensional simulation data arrays, making our technique applicable to
power systems with many random parameters. We also present a numerical method
to solve the resulting nonlinear optimization problem.
  Our algorithm is implemented in MATLAB and is verified by several benchmarks
in MATPOWER $5.1$. Accurate results are obtained for power systems with up to
$50$ independent random parameters, with a speedup factor up to $9\times
10^{20}$.
</summary>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Hung Dinh Nguyen</name>
    </author>
    <author>
      <name>Konstantin Turitsyn</name>
    </author>
    <author>
      <name>Luca Daniel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 10 figures, submitted to IEEE Trans. Power Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02506v1</id>
    <updated>2015-08-11T07:44:27Z</updated>
    <published>2015-08-11T07:44:27Z</published>
    <title>Finite Element Procedures for Enzyme, Chemical Reaction and 'In-Silico'
  Genome Scale Networks</title>
    <summary>  The capacity to predict and control bioprocesses is perhaps one of the most
important objectives of biotechnology. Computational simulation is an
established methodology for the design and optimization of bioprocesses, where
the finite elements method (FEM) is at the state-of-art engineering
multi-physics simulation system, with tools such as Finite Element Analysis
(FEA) and Computational Fluid Dynamics (CFD). Although FEA and CFD are
currently applied to bioreactor design, most simulations are restricted to the
multi-physics capabilities of the existing sofware packages. This manuscript is
a contribution for the consolidation of FEM in computational biotechnology, by
presenting a comprehensive review of finite element procedures of the most
common enzymatic mechanisms found in biotechnological processes, such as,
enzyme activation, Michaelis Menten, competitive inhibition, non-competitive
inhibition, anti-competitive inhibition, competition by substrate, sequential
random mechanism, ping-pong bi-bi and Theorel-Chance. Most importantly, the
manuscript opens the possibility for the use of FEM in conjunction with
{\guillemotleft}in-silico{\guillemotright} models of metabolic networks, as
well as, chemical networks in order to simulate complex bioprocesses in
biotechnology, putting emphasis into flux balance analysis, pheno-metabolomics
space exploration in time and space, overcoming the limitations of assuming
chemostat conditions in systems biology computations.
</summary>
    <author>
      <name>R. C. Martins</name>
    </author>
    <author>
      <name>N. Fachada</name>
    </author>
    <link href="http://arxiv.org/abs/1508.02506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03604v1</id>
    <updated>2015-08-14T18:49:36Z</updated>
    <published>2015-08-14T18:49:36Z</published>
    <title>MOLNs: A cloud platform for interactive, reproducible and scalable
  spatial stochastic computational experiments in systems biology using PyURDME</title>
    <summary>  Computational experiments using spatial stochastic simulations have led to
important new biological insights, but they require specialized tools, a
complex software stack, as well as large and scalable compute and data analysis
resources due to the large computational cost associated with Monte Carlo
computational workflows. The complexity of setting up and managing a
large-scale distributed computation environment to support productive and
reproducible modeling can be prohibitive for practitioners in systems biology.
This results in a barrier to the adoption of spatial stochastic simulation
tools, effectively limiting the type of biological questions addressed by
quantitative modeling. In this paper, we present PyURDME, a new, user-friendly
spatial modeling and simulation package, and MOLNs, a cloud computing appliance
for distributed simulation of stochastic reaction-diffusion models. MOLNs is
based on IPython and provides an interactive programming platform for
development of sharable and reproducible distributed parallel computational
experiments.
</summary>
    <author>
      <name>Brian Drawert</name>
    </author>
    <author>
      <name>Michael Trogdon</name>
    </author>
    <author>
      <name>Salman Toor</name>
    </author>
    <author>
      <name>Linda Petzold</name>
    </author>
    <author>
      <name>Andreas Hellander</name>
    </author>
    <link href="http://arxiv.org/abs/1508.03604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03993v1</id>
    <updated>2015-08-17T12:19:45Z</updated>
    <published>2015-08-17T12:19:45Z</published>
    <title>Simulating Viscous Fingering with a Timespace Method and Anisotropic
  Mesh Adaptation</title>
    <summary>  We report findings related to a two dimensional viscous fingering problem
solved with a timespace method and anisotropic elements. Timespace methods have
attracted interest for solution of time dependent partial differential
equations due to the implications of parallelism in the temporal dimension, but
there are also attractive features in the context of anisotropic mesh
adaptation; not only are heuristics and interpolation errors avoided, but
slanted elements in timespace also correspond to long and accurate timesteps,
i.e. the anisotropy in timespace can be exploited. We show that our timespace
method is restricted by a minimum timestep size, which is due to the growth of
numerical perturbations. The lower bound on the timestep is, however, quite
high, which is indicative that the number of timesteps can be reduced with
several orders of magnitude for practical applications.
</summary>
    <author>
      <name>Kristian E. Jensen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Rejected by Journal of Computational Physics</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05176v1</id>
    <updated>2015-08-21T04:49:34Z</updated>
    <published>2015-08-21T04:49:34Z</published>
    <title>Efficient Representation of Uncertainty for Stochastic Economic Dispatch</title>
    <summary>  Stochastic economic dispatch models address uncertainties in forecasts of
renewable generation output by considering a finite number of realizations
drawn from a stochastic process model, typically via Monte Carlo sampling.
Accurate evaluations of expectations or higher-order moments for quantities of
interest, e.g., generating cost, can require a prohibitively large number of
samples. We propose an alternative to Monte Carlo sampling based on Polynomial
Chaos expansions. These representations are based on sparse quadrature methods,
and enable accurate propagation of uncertainties in model parameters. We also
investigate a method based on Karhunen-Loeve expansions that enables us to
efficiently represent uncertainties in renewable energy generation. Considering
expected production cost, we demonstrate that the proposed approach can yield
several orders of magnitude reduction in computational cost for solving
stochastic economic dispatch relative to Monte Carlo sampling, for a given
target error threshold.
</summary>
    <author>
      <name>Cosmin Safta</name>
    </author>
    <author>
      <name>Richard L. -Y. Chen</name>
    </author>
    <author>
      <name>Habib N. Najm</name>
    </author>
    <author>
      <name>Ali Pinar</name>
    </author>
    <author>
      <name>Jean-Paul Watson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1407.2232</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.06561v1</id>
    <updated>2015-08-25T16:58:35Z</updated>
    <published>2015-08-25T16:58:35Z</published>
    <title>A Space-Efficient Approach towards Distantly Homologous Protein
  Similarity Searches</title>
    <summary>  Protein similarity searches are a routine job for molecular biologists where
a query sequence of amino acids needs to be compared and ranked against an
ever-growing database of proteins. All available algorithms in this field can
be grouped into two categories, either solving the problem using sequence
alignment through dynamic programming, or, employing certain heuristic measures
to perform an initial screening followed by applying an optimal sequence
alignment algorithm to the closest matching candidates. While the first
approach suffers from huge time and space demands, the latter approach might
miss some protein sequences which are distantly related to the query sequence.
In this paper, we propose a heuristic pair-wise sequence alignment algorithm
that can be efficiently employed for protein database searches for moderately
sized databases. The proposed algorithm is sufficiently fast to be applicable
to database searches for short query sequences, has constant auxiliary space
requirements, produces good alignments, and is sensitive enough to return even
distantly related protein chains that might be of interest.
</summary>
    <author>
      <name>Akash Nag</name>
    </author>
    <author>
      <name>Sunil Karforma</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Research in Computer Science
  (IJARCS). Vol.6(2). pp:19-22. 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1508.06561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.06561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07416v1</id>
    <updated>2015-08-29T08:18:14Z</updated>
    <published>2015-08-29T08:18:14Z</published>
    <title>Linked Component Analysis from Matrices to High Order Tensors:
  Applications to Biomedical Data</title>
    <summary>  With the increasing availability of various sensor technologies, we now have
access to large amounts of multi-block (also called multi-set,
multi-relational, or multi-view) data that need to be jointly analyzed to
explore their latent connections. Various component analysis methods have
played an increasingly important role for the analysis of such coupled data. In
this paper, we first provide a brief review of existing matrix-based (two-way)
component analysis methods for the joint analysis of such data with a focus on
biomedical applications. Then, we discuss their important extensions and
generalization to multi-block multiway (tensor) data. We show how constrained
multi-block tensor decomposition methods are able to extract similar or
statistically dependent common features that are shared by all blocks, by
incorporating the multiway nature of data. Special emphasis is given to the
flexible common and individual feature analysis of multi-block data with the
aim to simultaneously extract common and individual latent components with
desired properties and types of diversity. Illustrative examples are given to
demonstrate their effectiveness for biomedical data analysis.
</summary>
    <author>
      <name>Guoxu Zhou</name>
    </author>
    <author>
      <name>Qibin Zhao</name>
    </author>
    <author>
      <name>Yu Zhang</name>
    </author>
    <author>
      <name>Tülay Adalı</name>
    </author>
    <author>
      <name>Shengli Xie</name>
    </author>
    <author>
      <name>Andrzej Cichocki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JPROC.2015.2474704</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JPROC.2015.2474704" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 11 figures, Proceedings of the IEEE, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07435v3</id>
    <updated>2016-09-27T06:18:36Z</updated>
    <published>2015-08-29T11:11:40Z</published>
    <title>Subdifferential-based implicit return-mapping operators in Mohr-Coulomb
  plasticity</title>
    <summary>  The paper is devoted to a constitutive solution, limit load analysis and
Newton-like methods in elastoplastic problems containing the Mohr-Coulomb yield
criterion. Within the constitutive problem, we introduce a self-contained
derivation of the implicit return-mapping solution scheme using a recent
subdifferential-based treatment. Unlike conventional techniques based on
Koiter's rules, the presented scheme a priori detects a position of the unknown
stress tensor on the yield surface even if the constitutive solution cannot be
found in closed form. This fact eliminates blind guesswork from the scheme,
enables to analyze properties of the constitutive operator, and simplifies
construction of the consistent tangent operator which is important for the
semismooth Newton method applied on the incremental boundary value
elastoplastic problem. The incremental problem in Mohr-Coulomb plasticity is
combined with the limit load analysis. Beside a conventional direct method of
the incremental limit analysis, a recent indirect one is introduced and its
advantages are described. The paper contains 2D and 3D numerical experiments on
slope stability with publicly available Matlab implementations.
</summary>
    <author>
      <name>Stanislav Sysala</name>
    </author>
    <author>
      <name>Martin Cermak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/zamm.201600215</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/zamm.201600215" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07435v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07435v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01693v1</id>
    <updated>2015-09-05T11:24:36Z</updated>
    <published>2015-09-05T11:24:36Z</published>
    <title>The Economic Dispatch for Integrated Wind Power Systems Using Particle
  Swarm Optimization</title>
    <summary>  The economic dispatch of wind power units is quite different from that in
conventional thermal units, since the adopted model should take into
consideration the intermittency nature of wind speed as well. Therefore, this
paper uses a model that takes into account the aforementioned consideration in
addition to whether the utility owns wind turbines or not. The economic
dispatch is solved by using one of the modern optimization algorithms: the
particle swarm optimization algorithm. A 6-bus system is used and it includes
wind-powered generators besides to thermal generators. The thorough analysis of
the results is also provided.
</summary>
    <author>
      <name>Mohamed Abuella</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Southern Illinois University</arxiv:affiliation>
    </author>
    <author>
      <name>Constantine J. Hatziadoniu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Southern Illinois University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is a partial work of M.S.Thesis in Electrical and Computer
  Engineering at Southern Illinois University Carbondale</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01709v2</id>
    <updated>2015-11-18T14:40:56Z</updated>
    <published>2015-09-05T15:37:11Z</published>
    <title>Algorithm for estimating swirl angles in multi-intake hydraulic sumps</title>
    <summary>  The paper has been withdrawn effective November 18, 2015.
  Hydraulic Pump sumps are designed to provide a swirl free flow to the pump.
The degree of swirl is measured in physical model tests using a swirl meter and
a quantity known as swirl angle is generally measured. The present paper
presents a novel method to compute the bulk swirl angle using the local
velocity field obtained from computational fluid dynamics data. The basis for
the present method is the conservation of angular momentum conservation. By
carrying out both numerical and experimental studies the novel swirl angle
calculation method is validated. Further the effect of vortex suppression
devices in reducing the swirl angle is also demonstrated.
</summary>
    <author>
      <name>Peetak Mitra</name>
    </author>
    <author>
      <name>Niranjan Gudibande</name>
    </author>
    <author>
      <name>Kannan Iyer</name>
    </author>
    <author>
      <name>TI Eldho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper has been withdrawn by the author (Peetak Mitra) since it
  was felt the paper was sketchy in its concepts</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01709v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01709v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03198v1</id>
    <updated>2015-06-19T07:44:29Z</updated>
    <published>2015-06-19T07:44:29Z</published>
    <title>Agent enabled Mining of Distributed Protein Data Banks</title>
    <summary>  Mining biological data is an emergent area at the intersection between
bioinformatics and data mining (DM). The intelligent agent based model is a
popular approach in constructing Distributed Data Mining (DDM) systems to
address scalable mining over large scale distributed data. The nature of
associations between different amino acids in proteins has also been a subject
of great anxiety. There is a strong need to develop new models and exploit and
analyze the available distributed biological data sources. In this study, we
have designed and implemented a multi-agent system (MAS) called Agent enriched
Quantitative Association Rules Mining for Amino Acids in distributed Protein
Data Banks (AeQARM-AAPDB). Such globally strong association rules enhance
understanding of protein composition and are desirable for synthesis of
artificial proteins. A real protein data bank is used to validate the system.
</summary>
    <author>
      <name>G. S. Bhamra</name>
    </author>
    <author>
      <name>A. K. Verma</name>
    </author>
    <author>
      <name>R. B. Patel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijfcst.2015.5303</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijfcst.2015.5303" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal in Foundations of Computer Science &amp;
  Technology (IJFCST), Vol.5, No.3, May 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.03198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03530v1</id>
    <updated>2015-09-11T14:23:16Z</updated>
    <published>2015-09-11T14:23:16Z</published>
    <title>A comparative analysis of progressive multiple sequence alignment
  approaches using UPGMA and neighbor joining based guide trees</title>
    <summary>  Multiple sequence alignment is increasingly important to bioinformatics, with
several applications ranging from phylogenetic analyses to domain
identification. There are several ways to perform multiple sequence alignment,
an important way of which is the progressive alignment approach studied in this
work. Progressive alignment involves three steps: find the distance between
each pair of sequences; construct a guide tree based on the distance matrix;
finally based on the guide tree align sequences using the concept of aligned
profiles. Our contribution is in comparing two main methods of guide tree
construction in terms of both efficiency and accuracy of the overall alignment:
UPGMA and Neighbor Join methods. Our experimental results indicate that the
Neighbor Join method is both more efficient in terms of performance and more
accurate in terms of overall cost minimization.
</summary>
    <author>
      <name>Ravi Kumar Yadav Dega</name>
    </author>
    <author>
      <name>Gunes Ercal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol. 5,No.3/4, August 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.03530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.04250v1</id>
    <updated>2015-09-14T19:23:06Z</updated>
    <published>2015-09-14T19:23:06Z</published>
    <title>The response of grandstands driven by filtered Gaussian white noise
  processes</title>
    <summary>  This paper presents a semi-analytical estimate of the response of a
grandstand occupied by an active crowd and by a passive crowd. Filtered
Gaussian white noise processes are used to approximate the loading terms
representing an active crowd. Lumped biodynamic models with a single degree of
freedom are included to reflect passive spectators occupying the structure. The
response is described in terms of the first two moments, employing the It\^o
formula and the state augmentation method for the stationary time domain
solution. The quality of the approximation is compared on the basis of three
examples of varying complexity using Monte Carlo simulation based on a
synthetic generator available in the literature. For comparative purposes,
there is also a brief review of frequency domain estimates.
</summary>
    <author>
      <name>O. Rokoš</name>
    </author>
    <author>
      <name>J. Máca</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.advengsoft.2013.05.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.advengsoft.2013.05.008" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 12 figures, 4 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Engineering Software, Volume 72, June 2014, Pages
  85--94, Special Issue dedicated to Professor Zden\v{e}k Bittnar on the
  occasion of his Seventieth Birthday: Part 2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.04250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.04250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.08357v1</id>
    <updated>2015-09-28T15:23:48Z</updated>
    <published>2015-09-28T15:23:48Z</published>
    <title>Skin Effect Modeling in Conductors of Arbitrary Shape Through a Surface
  Admittance Operator and the Contour Integral Method</title>
    <summary>  An accurate modeling of skin effect inside conductors is of capital
importance to solve transmission line and scattering problems. This paper
presents a surface-based formulation to model skin effect in conductors of
arbitrary cross section, and compute the per-unit-length impedance of a
multiconductor transmission line. The proposed formulation is based on the
Dirichlet-Neumann operator that relates the longitudinal electric field to the
tangential magnetic field on the boundary of a conductor. We demonstrate how
the surface operator can be obtained through the contour integral method for
conductors of arbitrary shape. The proposed algorithm is simple to implement,
efficient, and can handle arbitrary cross-sections, which is a main advantage
over the existing approach based on eigenfunctions, which is available only for
canonical conductor's shapes. The versatility of the method is illustrated
through a diverse set of examples, which includes transmission lines with
trapezoidal, curved, and V-shaped conductors. Numerical results demonstrate the
accuracy, versatility, and efficiency of the proposed technique.
</summary>
    <author>
      <name>Utkarsh R. Patel</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMTT.2016.2593721</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMTT.2016.2593721" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been submitted for publication to the IEEE
  Transactions on Microwave Theory and Techniques on September 27, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.08357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.08357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01364v1</id>
    <updated>2015-09-30T12:34:41Z</updated>
    <published>2015-09-30T12:34:41Z</published>
    <title>An extension of the open-source porousMultiphaseFoam toolbox dedicated
  to groundwater flows solving the Richards' equation</title>
    <summary>  In this note, the existing porousMultiphaseFoam toolbox, developed initially
for any two-phase flow in porous media is extended to the specific case of the
Richards' equation which neglect the pressure gradient of the non-wetting
phase. This model is typically used for saturated and unsaturated groundwater
flows. A Picard's algorithm is implemented to linearize and solve the Richards'
equation developed in the pressure head based form. This new solver of the
porousMultiphaseFoam toolbox is named groundwaterFoam. The validation of
thesolver is achieved by a comparison between numerical simulations and results
obtained from the literature. Finally, a parallel efficiency test is performed
on a large unstructured mesh and exhibits a super-linear behavior as observed
for the other solvers of the toolbox.
</summary>
    <author>
      <name>Pierre Horgue</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMFT</arxiv:affiliation>
    </author>
    <author>
      <name>Jacques Franc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMFT</arxiv:affiliation>
    </author>
    <author>
      <name>Romain Guibert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMFT</arxiv:affiliation>
    </author>
    <author>
      <name>Gérald Debenest</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMFT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1510.01364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.class-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02775v1</id>
    <updated>2015-10-09T19:17:12Z</updated>
    <published>2015-10-09T19:17:12Z</published>
    <title>Protein preliminaries and structure prediction fundamentals for computer
  scientists</title>
    <summary>  Protein structure prediction is a challenging and unsolved problem in
computer science. Proteins are the sequence of amino acids connected together
by single peptide bond. The combinations of the twenty primary amino acids are
the constituents of all proteins. In-vitro laboratory methods used in this
problem are very time-consuming, cost-intensive, and failure-prone. Thus,
alternative computational methods come into play. The protein structure
prediction problem is to find the three-dimensional native structure of a
protein, from its amino acid sequence. The native structure of a protein has
the minimum free energy possible and arguably determines the function of the
protein. In this study, we present the preliminaries of proteins and their
structures, protein structure prediction problem, and protein models. We also
give a brief overview on experimental and computational methods used in protein
structure prediction. This study will provide a fundamental knowledge to the
computer scientists who are intending to pursue their future research on
protein structure prediction problem.
</summary>
    <author>
      <name>Mahmood A. Rashid</name>
    </author>
    <author>
      <name>Firas Khatib</name>
    </author>
    <author>
      <name>Abdul Sattar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.02775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03035v1</id>
    <updated>2015-10-11T11:01:30Z</updated>
    <published>2015-10-11T11:01:30Z</published>
    <title>Reliability Analysis of Processes with Moving Cracked Material</title>
    <summary>  The reliability of processes with moving elastic and isotropic material
containing initial cracks is considered in terms of fracture. The material is
modelled as a moving plate which is simply supported from two of its sides and
subjected to homogeneous tension acting in the travelling direction. For
tension, two models are studied: i) tension is constant with respect to time,
and ii) tension varies temporally according to an Ornstein-Uhlenbeck process.
Cracks of random length are assumed to occur in the material according to a
stochastic counting process. For a general counting process, a representation
of the nonfracture probability of the system is obtained that exploits
conditional Monte Carlo simulation. Explicit formulae are derived for special
cases. To study the reliability of the system with temporally varying tension,
a known explicit result for the first passage time of an Ornstein-Uhlenbeck
process to a constant boundary is utilized. Numerical examples are provided for
printing presses and paper material.
</summary>
    <author>
      <name>Maria Tirronen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.apm.2015.12.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.apm.2015.12.010" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematical Modelling 40 (2016) 4986-4999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.03035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05533v1</id>
    <updated>2015-10-19T15:31:58Z</updated>
    <published>2015-10-19T15:31:58Z</published>
    <title>Image-based Modelling of Organogenesis</title>
    <summary>  One of the major challenges in biology concerns the integration of data
across length and time scales into a consistent framework: how do macroscopic
properties and functionalities arise from the molecular regulatory networks -
and how can they change as a result of mutations? Morphogenesis provides an
excellent model system to study how simple molecular networks robustly control
complex processes on the macroscopic scale in spite of molecular noise, and how
important functional variants can emerge from small genetic changes. Recent
advancements in 3D imaging technologies, computer algorithms, and computer
power now allow us to develop and analyse increasingly realistic models of
biological control. Here we present our pipeline for image-based modeling that
includes the segmentation of images, the determination of displacement fields,
and the solution of systems of partial differential equations (PDEs) on the
growing, embryonic domains. The development of suitable mathematical models,
the data-based inference of parameter sets, and the evaluation of competing
models are still challenging, and current approaches are discussed.
</summary>
    <author>
      <name>Dagmar Iber</name>
    </author>
    <author>
      <name>Zahra Karimaddini</name>
    </author>
    <author>
      <name>Erkan Ünal</name>
    </author>
    <link href="http://arxiv.org/abs/1510.05533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05751v2</id>
    <updated>2016-04-14T18:21:50Z</updated>
    <published>2015-10-20T04:36:38Z</published>
    <title>Semi-Implicit Time Integration of Atmospheric Flows with
  Characteristic-Based Flux Partitioning</title>
    <summary>  This paper presents a characteristic-based flux partitioning for the
semi-implicit time integration of atmospheric flows. Nonhydrostatic models
require the solution of the compressible Euler equations. The acoustic
time-scale is significantly faster than the advective scale, yet it is
typically not relevant to atmospheric and weather phenomena. The acoustic and
advective components of the hyperbolic flux are separated in the characteristic
space. High-order, conservative additive Runge-Kutta methods are applied to the
partitioned equations so that the acoustic component is integrated in time
implicitly with an unconditionally stable method, while the advective component
is integrated explicitly. The time step of the overall algorithm is thus
determined by the advective scale. Benchmark flow problems are used to
demonstrate the accuracy, stability, and convergence of the proposed algorithm.
The computational cost of the partitioned semi-implicit approach is compared
with that of explicit time integration.
</summary>
    <author>
      <name>Debojyoti Ghosh</name>
    </author>
    <author>
      <name>Emil M. Constantinescu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/15M1044369</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/15M1044369" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing, 38 (3), 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.05751v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05751v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M06, 86A10, 76N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07020v2</id>
    <updated>2017-05-23T13:48:23Z</updated>
    <published>2015-10-22T12:54:40Z</published>
    <title>An Efficient Polyphase Filter Based Resampling Method for Unifying the
  PRFs in SAR Data</title>
    <summary>  Variable and higher pulse repetition frequencies (PRFs) are increasingly
being used to meet the stricter requirements and complexities of current
airborne and spaceborne synthetic aperture radar (SAR) systems associated with
higher resolution and wider area products. POLYPHASE, the proposed resampling
scheme, downsamples and unifies variable PRFs within a single look complex
(SLC) SAR acquisition and across a repeat pass sequence of acquisitions down to
an effective lower PRF. A sparsity condition of the received SAR data ensures
that the uniformly resampled data approximates the spectral properties of a
decimated densely sampled version of the received SAR data. While experiments
conducted with both synthetically generated and real airborne SAR data show
that POLYPHASE retains comparable performance to the state-of-the-art BLUI
scheme in image quality, a polyphase filter-based implementation of POLYPHASE
offers significant computational savings for arbitrary (not necessarily
periodic) input PRF variations, thus allowing fully on-board, in-place, and
real-time implementation.
</summary>
    <author>
      <name>Yoangel Torres</name>
    </author>
    <author>
      <name>Kamal Premaratne</name>
    </author>
    <author>
      <name>Falk Amelung</name>
    </author>
    <author>
      <name>Shimon Wdowinski</name>
    </author>
    <link href="http://arxiv.org/abs/1510.07020v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07020v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.01380v1</id>
    <updated>2015-11-04T16:06:46Z</updated>
    <published>2015-11-04T16:06:46Z</published>
    <title>Isogeometric approach for nonlinear bending and post-buckling analysis
  of functionally graded plates under thermal environment</title>
    <summary>  In this paper, equilibrium and stability equations of functionally graded
material (FGM) plate under thermal environment are formulated based on
isogeometric analysis (IGA) in combination with higher-order shear deformation
theory (HSDT). The FGM plate is made by a mixture of two distinct components,
for which material properties not only vary continuously through thickness
according to a power-law distribution but also are assumed to be a function of
temperature. Temperature field is assumed to be constant in any plane and
uniform, linear and nonlinear through plate thickness, respectively. The
governing equation is in nonlinear form based on von Karman assumption and
thermal effect. A NURBS-based isogeometric finite element formulation is
utilized to naturally fulfil the rigorous C1-continuity required by the present
plate model. Influences of gradient indices, boundary conditions, temperature
distributions, material properties, length-to-thickness ratios on the behaviour
of FGM plate are discussed in details. Numerical results demonstrate excellent
performance of the present approach.
</summary>
    <author>
      <name>Loc V. Tran</name>
    </author>
    <author>
      <name>Phuc Phung-Van</name>
    </author>
    <author>
      <name>Jaehong Lee</name>
    </author>
    <author>
      <name>H. Nguyen-Xuan</name>
    </author>
    <author>
      <name>M. Abdel Wahab</name>
    </author>
    <link href="http://arxiv.org/abs/1511.01380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.01380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04515v1</id>
    <updated>2015-11-14T05:57:35Z</updated>
    <published>2015-11-14T05:57:35Z</published>
    <title>An Algorithmic Framework for Efficient Large-Scale Circuit Simulation
  Using Exponential Integrators</title>
    <summary>  We propose an efficient algorithmic framework for time domain circuit
simulation using exponential integrator. This work addresses several critical
issues exposed by previous matrix exponential based circuit simulation
research, and makes it capable of simulating stiff nonlinear circuit system at
a large scale. In this framework, the system's nonlinearity is treated with
exponential Rosenbrock-Euler formulation. The matrix exponential and vector
product is computed using invert Krylov subspace method. Our proposed method
has several distinguished advantages over conventional formulations (e.g., the
well-known backward Euler with Newton-Raphson method). The matrix factorization
is performed only for the conductance/resistance matrix G, without being
performed for the combinations of the capacitance/inductance matrix C and
matrix G, which are used in traditional implicit formulations. Furthermore, due
to the explicit nature of our formulation, we do not need to repeat LU
decompositions when adjusting the length of time steps for error controls. Our
algorithm is better suited to solving tightly coupled post-layout circuits in
the pursuit for full-chip simulation. Our experimental results validate the
advantages of our framework.
</summary>
    <author>
      <name>Hao Zhuang</name>
    </author>
    <author>
      <name>Wenjian Yu</name>
    </author>
    <author>
      <name>Ilgweon Kang</name>
    </author>
    <author>
      <name>Xinan Wang</name>
    </author>
    <author>
      <name>Chung-Kuan Cheng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2744769.2744793</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2744769.2744793" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages; ACM/IEEE DAC 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.04515v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04515v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04519v1</id>
    <updated>2015-11-14T06:29:51Z</updated>
    <published>2015-11-14T06:29:51Z</published>
    <title>MATEX: A Distributed Framework for Transient Simulation of Power
  Distribution Networks</title>
    <summary>  We proposed MATEX, a distributed framework for transient simulation of power
distribution networks (PDNs). MATEX utilizes matrix exponential kernel with
Krylov subspace approximations to solve differential equations of linear
circuit. First, the whole simulation task is divided into subtasks based on
decompositions of current sources, in order to reduce the computational
overheads. Then these subtasks are distributed to different computing nodes and
processed in parallel. Within each node, after the matrix factorization at the
beginning of simulation, the adaptive time stepping solver is performed without
extra matrix re-factorizations. MATEX overcomes the stiff-ness hinder of
previous matrix exponential-based circuit simulator by rational Krylov subspace
method, which leads to larger step sizes with smaller dimensions of Krylov
subspace bases and highly accelerates the whole computation. MATEX outperforms
both traditional fixed and adaptive time stepping methods, e.g., achieving
around 13X over the trapezoidal framework with fixed time step for the IBM
power grid benchmarks.
</summary>
    <author>
      <name>Hao Zhuang</name>
    </author>
    <author>
      <name>Shih-Hung Weng</name>
    </author>
    <author>
      <name>Jeng-Hau Lin</name>
    </author>
    <author>
      <name>Chung-Kuan Cheng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2593069.2593160</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2593069.2593160" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM/IEEE DAC 2014. arXiv admin note: substantial text overlap with
  arXiv:1505.06699</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.04519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.02183v1</id>
    <updated>2015-12-07T19:34:58Z</updated>
    <published>2015-12-07T19:34:58Z</published>
    <title>Wavelet Based Load Models from AMI Data</title>
    <summary>  A major challenge of using AMI data in power system analysis is the large
size of the data sets. For rapid analysis that addresses historical behavior of
systems consisting of a few hundred feeders, all of the AMI load data can be
loaded into memory and used in a power flow analysis. However, if a system
contains thousands of feeders then the handling of the AMI data in the analysis
becomes more challenging. The work here seeks to demonstrate that the
information contained in large AMI data sets can be compressed into accurate
load models using wavelets. Two types of wavelet based load models are
considered, the multi-resolution wavelet load model for each individual
customer and the classified wavelet load model for customers that share similar
load patterns. The multi-resolution wavelet load model compresses the data, and
the classified wavelet load model further compresses the data. The method of
grouping customers into classes using the wavelet based classification
technique is illustrated.
</summary>
    <author>
      <name>Shiyin Zhong</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Senior Member, IEEE</arxiv:affiliation>
    </author>
    <author>
      <name>Robert Broadwater</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Senior Member, IEEE</arxiv:affiliation>
    </author>
    <author>
      <name>Steve Steffel</name>
    </author>
    <link href="http://arxiv.org/abs/1512.02183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.02183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05055v1</id>
    <updated>2015-12-16T05:23:03Z</updated>
    <published>2015-12-16T05:23:03Z</published>
    <title>Inferring Gene Regulatory Network Using An Evolutionary Multi-Objective
  Method</title>
    <summary>  Inference of gene regulatory networks (GRNs) based on experimental data is a
challenging task in bioinformatics. In this paper, we present a bi-objective
minimization model (BoMM) for inference of GRNs, where one objective is the
fitting error of derivatives, and the other is the number of connections in the
network. To solve the BoMM efficiently, we propose a multi-objective
evolutionary algorithm (MOEA), and utilize the separable parameter estimation
method (SPEM) decoupling the ordinary differential equation (ODE) system. Then,
the Akaike Information Criterion (AIC) is employed to select one inference
result from the obtained Pareto set. Taking the S-system as the investigated
GRN model, our method can properly identify the topologies and parameter values
of benchmark systems. There is no need to preset problem-dependent parameter
values to obtain appropriate results, and thus, our method could be applicable
to inference of various GRNs models.
</summary>
    <author>
      <name>Yu Chen</name>
    </author>
    <author>
      <name>Xiufen Zou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.05055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.07818v1</id>
    <updated>2015-12-24T14:07:40Z</updated>
    <published>2015-12-24T14:07:40Z</published>
    <title>Robust Simulation for Hybrid Systems: Chattering Path Avoidance</title>
    <summary>  The sliding mode approach is recognized as an efficient tool for treating the
chattering behavior in hybrid systems. However, the amplitude of chattering, by
its nature, is proportional to magnitude of discontinuous control. A possible
scenario is that the solution trajectories may successively enter and exit as
well as slide on switching mani-folds of different dimensions. Naturally, this
arises in dynamical systems and control applications whenever there are
multiple discontinuous control variables. The main contribution of this paper
is to provide a robust computational framework for the most general way to
extend a flow map on the intersection of p intersected (n--1)-dimensional
switching manifolds in at least p dimensions. We explore a new formulation to
which we can define unique solutions for such particular behavior in hybrid
systems and investigate its efficient computation/simulation. We illustrate the
concepts with examples throughout the paper.
</summary>
    <author>
      <name>Ayman Aljarbouh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">HYCOMES</arxiv:affiliation>
    </author>
    <author>
      <name>Benoit Caillaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">HYCOMES</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3384/ecp15119175</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3384/ecp15119175" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 56th Conference on Simulation and Modelling (SIMS 56), Oct 2015,
  Link\"oping, Sweden. 2015, Link\"oping University Press</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.07818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.07818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00323v1</id>
    <updated>2016-01-03T19:06:43Z</updated>
    <published>2016-01-03T19:06:43Z</published>
    <title>The Design of a Community Science Cloud: The Open Science Data Cloud
  Perspective</title>
    <summary>  In this paper we describe the design, and implementation of the Open Science
Data Cloud, or OSDC. The goal of the OSDC is to provide petabyte-scale data
cloud infrastructure and related services for scientists working with large
quantities of data. Currently, the OSDC consists of more than 2000 cores and 2
PB of storage distributed across four data centers connected by 10G networks.
We discuss some of the lessons learned during the past three years of operation
and describe the software stacks used in the OSDC. We also describe some of the
research projects in biology, the earth sciences, and social sciences enabled
by the OSDC.
</summary>
    <author>
      <name>Robert L. Grossman</name>
    </author>
    <author>
      <name>Matthew Greenway</name>
    </author>
    <author>
      <name>Allison P. Heath</name>
    </author>
    <author>
      <name>Ray Powell</name>
    </author>
    <author>
      <name>Rafael D. Suarez</name>
    </author>
    <author>
      <name>Walt Wells</name>
    </author>
    <author>
      <name>Kevin White</name>
    </author>
    <author>
      <name>Malcolm Atkinson</name>
    </author>
    <author>
      <name>Iraklis Klampanos</name>
    </author>
    <author>
      <name>Heidi L. Alvarez</name>
    </author>
    <author>
      <name>Christine Harvey</name>
    </author>
    <author>
      <name>Joe J. Mambretti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.00323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02241v1</id>
    <updated>2016-01-10T18:04:08Z</updated>
    <published>2016-01-10T18:04:08Z</published>
    <title>Extended Capability Models for Carbon Fiber Composite (CFC) Panels in
  the Unstructured Transmission Line Modelling (UTLM) Method</title>
    <summary>  An effective model of single and multilayered thin panels, including those
formed using carbon fiber composite (CFC) materials, is incorporated into the
Transmission Line Modeling (TLM) method. The thin panel model is a
one-dimensional (1D) one based on analytical expansions of cotangent and
cosecant functions that are used to describe the admittance matrix in the
frequency domain; these are then converted into the time domain by using
digital filter theory and an inverse Z transform. The model, which is extended
to allow for material anisotropy, is executed within 1D TLM codes. And, for the
first time, the two-dimensional (2D) thin surface model is embedded in
unstructured three-dimensional (3D) TLM codes. The approach is validated by
using it to study some canonical structures with analytic solutions, and
against results taken from the literature. It is then used to investigate
shielding effectiveness of carbon fiber composite materials in a practical
curved aerospace-related structure.
</summary>
    <author>
      <name>Xuesong Meng</name>
    </author>
    <author>
      <name>Ana Vukovic</name>
    </author>
    <author>
      <name>Trevor M. Benson</name>
    </author>
    <author>
      <name>Phillip Sewell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; submitted to IEEE Transactions on Electromagnetic
  Compatibility</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.02241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03907v2</id>
    <updated>2016-01-18T02:51:49Z</updated>
    <published>2016-01-15T13:24:53Z</published>
    <title>A stabilized finite element formulation for liquid shells and its
  application to lipid bilayers</title>
    <summary>  This paper presents a new finite element (FE) formulation for liquid shells
that is based on an explicit, 3D surface discretization using $C^1$-continuous
finite elements constructed from NURBS interpolation. Both displacement-based
and mixed FE formulations are proposed. The latter is needed for
area-incompressible material behavior, where penalty-type regularizations can
lead to misleading results. In order to obtain quasi-static solutions, several
numerical stabilization schemes are proposed based on either stiffness,
viscosity or projection. Several numerical examples are considered in order to
illustrate the accuracy and the capabilities of the proposed formulation, and
to compare the different stabilization schemes. The presented formulation is
capable of simulating non-trivial surface shapes associated with tube formation
and protein-induced budding of lipid bilayers. In the latter case, the
presented formulation yields non-axisymmetric solutions, which have not been
observed in previous simulations. It is shown that those non-axisymmetric
shapes are preferred over axisymmetric ones.
</summary>
    <author>
      <name>Roger A. Sauer</name>
    </author>
    <author>
      <name>Thang X. Duong</name>
    </author>
    <author>
      <name>Kranthi K. Mandadapu</name>
    </author>
    <author>
      <name>David J. Steigmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2016.11.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2016.11.004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected typo in axes of Fig.3, results unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.03907v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03907v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04150v1</id>
    <updated>2016-01-16T10:43:58Z</updated>
    <published>2016-01-16T10:43:58Z</published>
    <title>Selection of Most Effective Control Variables for Solving Optimal Power
  Flow Using Sensitivity Analysis in Particle Swarm Algorithm</title>
    <summary>  Solving the optimal power flow problem is one of the main objectives in
electrical power systems analysis and design. The modern optimization
algorithms such as the evolutionary algorithms are also adopted to solve this
problem, especially when the intermittency nature of generation resources are
included, as in wind and solar energy resources, where the models are
stochastic and non-linear. This paper uses the particle swarm optimization
algorithm for solving the optimal power flow for IEEE-30 bus system. In
addition to selection of the most effective control variables based on
sensitivity analysis to alleviate the violations and return the system back to
its normal state. This adopted strategy would decrease the optimal power flow
calculation burden by particle swarm optimization algorithm, especially with
large systems.
</summary>
    <author>
      <name>Mohamed Abuella</name>
    </author>
    <author>
      <name>Constantine Hatziadoniu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This article is a partial work of the author's M.Sc thesis at
  department of Electrical and Computer Engineering Southern Illinois
  University Carbondale, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04207v1</id>
    <updated>2016-01-16T20:21:41Z</updated>
    <published>2016-01-16T20:21:41Z</published>
    <title>The discrete analogue of the method of quickest descent for an inverse
  acoustic problem in case of a smooth source</title>
    <summary>  The article considers the discrete analogue of the method of quickest descent
for an inverse Acoustics problem in case of a smooth source. The authors
derived the gradient of functional in differential and discrete cases,
described the algorithm of solving a problem, and compared gradients of
functional in continuous and discrete cases. In the article the improved
estimates of the rates of convergence of gradient-based methods are obtained,
which are very important for practice because they provide with the possibility
to make input data errors consistent with the iteration number. There is a
practical application of the proposed new method of deriving the gradient of
functional for an Acoustics discrete problem, for it provides with calculations
that are more accurate. The theoretical importance of the method is the
developed technique of deriving estimates and gradients of functional at a
discrete level.
</summary>
    <author>
      <name>G. Tyulepberdinova</name>
    </author>
    <author>
      <name>G. Gaziz</name>
    </author>
    <author>
      <name>N. Kerimbayev</name>
    </author>
    <author>
      <name>S. Abdykarimova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04207v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04207v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06368v1</id>
    <updated>2016-01-24T11:32:51Z</updated>
    <published>2016-01-24T11:32:51Z</published>
    <title>Splitting schemes with respect to physical processes for double-porosity
  poroelasticity problems</title>
    <summary>  We consider unsteady poroelasticity problem in fractured porous medium within
the classical Barenblatt double-porosity model. For numerical solution of
double-porosity poroelasticity problems we construct splitting schemes with
respect to physical processes, where transition to a new time level is
associated with solving separate problem for the displacements and fluid
pressures in pores and fractures. The stability of schemes is achieved by
switching to three-level explicit-implicit difference scheme with some of the
terms in the system of equations taken from the lower time level and by
choosing a weight parameter used as a regularization parameter. The
computational algorithm is based on the finite element approximation in space.
The investigation of stability of splitting schemes is based on the general
stability (well-posedness) theory of operator-difference schemes. A priori
estimates for proposed splitting schemes and the standard two-level scheme are
provided. The accuracy and stability of considered schemes are demonstrated by
numerical experiments.
</summary>
    <author>
      <name>A. E. Kolesov</name>
    </author>
    <author>
      <name>P. N. Vabishchevich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.06368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34Q74, 65M12, 65M60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02847v2</id>
    <updated>2017-05-03T15:48:52Z</updated>
    <published>2016-02-09T03:17:07Z</published>
    <title>Refined Multiscale Fuzzy Entropy based on Standard Deviation for
  Biomedical Signal Analysis</title>
    <summary>  Multiscale entropy (MSE) has been a prevalent algorithm to quantify the
complexity of fluctuations in the local mean value of biomedical time series.
Recent developments in the field have tried to improve the MSE by reducing its
variability in large scale factors. On the other hand, there has been recent
interest in using other statistical moments than the mean, i.e. variance, in
the coarse-graining step of the MSE. Building on these trends, here we
introduce the so-called refined composite multiscale fuzzy entropy based on the
standard deviation (RCMFE{\sigma}) to quantify the dynamical properties of
spread over multiple time scales. We demonstrate the dependency of the
RCMFE{\sigma}, in comparison with other multiscale approaches, on several
straightforward signal processing concepts using a set of synthetic signals. We
also investigate the complementarity of using the standard deviation instead of
the mean in the coarse-graining process using magnetoencephalograms in
Alzheimer disease and publicly available electroencephalograms recorded from
focal and non-focal areas in epilepsy. Our results indicate that RCMFE{\sigma}
offers complementary information to that revealed by classical coarse-graining
approaches and that it has superior performance to distinguish different types
of physiological activity.
</summary>
    <author>
      <name>Hamed Azami</name>
    </author>
    <author>
      <name>Alberto Fernandez</name>
    </author>
    <author>
      <name>Javier Escudero</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11517-017-1647-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11517-017-1647-5" rel="related"/>
    <link href="http://arxiv.org/abs/1602.02847v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02847v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02982v1</id>
    <updated>2016-02-09T13:44:03Z</updated>
    <published>2016-02-09T13:44:03Z</published>
    <title>Variable Transmission Voltage for Loss Minimization in Long Offshore
  Wind Farm AC Export Cables</title>
    <summary>  Connection of offshore wind farms to shore requires the use of submarine
cables. In the case of long HVAC connections, the capacitive charging currents
limit the transfer capability and lead to high losses. This paper shows that
the losses can be substantially reduced by continuously adjusting the cable
operating voltage according to the instantaneous wind farm power
production.Calculations for a 320 MW windfarm connected to shore via a 200 km
cable at 220 kV nominal voltage shows that an annual loss reduction of 9
percent is achievable by simply using a 15 percent tap changer voltage
regulation on the two transformers. Allowing a larger voltage regulation range
leads to further loss reduction (13 percent for 0.4-1.0 p.u. voltage range). If
the windfarm has a low utilization factor, the loss reduction potential is
demonstrated to be as high as 21 percent . The methodology can be applied
without introducing new technology that needs to be developed or qualified.
</summary>
    <author>
      <name>Bjorn Gustavsen</name>
    </author>
    <author>
      <name>Olve Mo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be submitted to IEEE Transactions on Power Delivery</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.02982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.03854v1</id>
    <updated>2016-01-26T01:35:23Z</updated>
    <published>2016-01-26T01:35:23Z</published>
    <title>Estimating the unconfined compressive strength of carbonate rocks using
  gene expression programming</title>
    <summary>  Conventionally, many researchers have used both regression and black box
techniques to estimate the unconfined compressive strength (UCS) of different
rocks. The advantage of the regression approach is that it can be used to
render a functional relationship between the predictive rock indices and its
UCS. The advantage of the black box techniques is in rendering more accurate
predictions. Gene expression programming (GEP) is proposed, in this study, as a
robust mathematical alternative for predicting the UCS of carbonate rocks. The
two parameters of total porosity and P-wave speed were selected as predictive
indices. The proposed GEP model had the advantage of the both traditionally
used approaches by proposing a mathematical model, similar to a regression,
while keeping the prediction errors as low as the black box methods. The GEP
outperformed both artificial neural networks and support vector machines in
terms of yielding more accurate estimates of UCS. Both the porosity and the
P-wave velocity were sufficient predictive indices for estimating the UCS of
the carbonate rocks in this study. Nearly, 95% of the observed variation in the
UCS values was explained by these two parameters (i.e., R2 =95%).
</summary>
    <author>
      <name>Saeid R. Dindarloo</name>
    </author>
    <author>
      <name>Elnaz Siami-Irdemoosa</name>
    </author>
    <link href="http://arxiv.org/abs/1602.03854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.03854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07851v1</id>
    <updated>2016-02-25T09:07:19Z</updated>
    <published>2016-02-25T09:07:19Z</published>
    <title>Influence of morphological parameters in 3D composite materials on their
  effective thermal properties and comparison with effective mechanical
  properties</title>
    <summary>  In this paper we study the effective thermal behaviour of 3D representative
volume elements (RVEs) of two-phased composite materials constituted by a
matrix with cylindrical and spherical inclusions distributed randomly, with
periodic boundaries. Variations around the shape of inclusions have been taken
into account, by corrugating shapes, excavating and/or by removing pieces of
inclusions. The effective behaviour is computed with the help of homogenization
process based on an accelerated FFT-scheme giving the thermal conductivity
tensor. Several morphological parameters are also taken into account for
instance the number and the volume fraction of each type of inclusions,... in
order to analyse the behaviour of the composite for a large number of
geometries. We compare the results obtained for RVEs with and without
variations, and then with the mechanical results of such composite studied in
our previous paper.
</summary>
    <author>
      <name>Sophie Lemaitre</name>
    </author>
    <author>
      <name>Vladimir Salnikov</name>
    </author>
    <author>
      <name>Daniel Choi</name>
    </author>
    <author>
      <name>Philippe Karamian-Surville</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01866v2</id>
    <updated>2016-06-29T02:59:26Z</updated>
    <published>2016-03-06T20:10:15Z</published>
    <title>An efficient adaptive polygonal finite element method for plastic
  collapse analysis of solids</title>
    <summary>  We propose an adaptive polygonal finite element formulation for collapse
plastic analysis of solids. The article contributes into four crucial points:
1) Wachspress shape functions at vertex and bubble nodes handled at a
primal-mesh level; 2) plastic strain rates and dissipation performed over a
dual-mesh level; 3) a new adaptive primal-mesh strategy driven by the L^2
-norm-based indicator of strain rates; and 4) a spatial decomposition structure
obtained from a so-called polytree mesh scheme. We investigate both purely
cohesive and cohesive-frictional materials. We prove numerically that the
present method performs well for volumetric locking problem. In addition, the
optimization formulation of limit analysis is written by the form of
second-order cone programming (SOCP) in order to exploit the high efficiency of
interior-point solvers. The present method retains a low number of optimization
variables. This convenient approach allows us to design and solve the
large-scale optimization problems effectively. Numerical validations show the
excellent performance of the proposed method.
</summary>
    <author>
      <name>H. Nguyen-Xuan</name>
    </author>
    <author>
      <name>Son H. Nguyen</name>
    </author>
    <author>
      <name>Hyun-Gyu Kim</name>
    </author>
    <author>
      <name>Klaus Hackl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript needs to be improved furthermore</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01866v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01866v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02524v2</id>
    <updated>2016-12-21T09:22:21Z</updated>
    <published>2016-03-08T14:04:58Z</published>
    <title>Robust multigrid for high-order discontinuous Galerkin methods: A fast
  Poisson solver suitable for high-aspect ratio Cartesian grids</title>
    <summary>  We present a polynomial multigrid method for nodal interior penalty and local
discontinuous Galerkin formulations of the Poisson equation on Cartesian grids.
For smoothing we propose two classes of overlapping Schwarz methods. The first
class comprises element-centered and the second face-centered methods. Within
both classes we identify methods that achieve superior convergence rates, prove
robust with respect to the mesh spacing and the polynomial order, at least up
to ${P=32}$. Consequent structure exploitation yields a computational
complexity of $O(PN)$, where $N$ is the number of unknowns. Further we
demonstrate the suitability of the face-centered method for element aspect
ratios up to 32.
</summary>
    <author>
      <name>Jörg Stiller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2016.09.041</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2016.09.041" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Comput. Phys. 327 (2016) 317-336</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.02524v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02524v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03608v2</id>
    <updated>2016-04-28T13:51:18Z</updated>
    <published>2016-03-11T12:29:13Z</published>
    <title>Bragg-Williams approximation for the dynamics of prey-predator
  biological associations</title>
    <summary>  The dynamics of an association of interactive biological species is studied
theoretically. We explore a mean field approximation to describe the temporal
evolution of an ecological system with the basic prey-predator interspecies
relation, as well as an approximation to introduce time correlations in the
dynamics. We start by discussing the solution of the Volterra-Lotka model in a
mean field approximation based in an analogy with the Weiss solution to the
Ising model for ferromagnetic materials. In order to explore the effects of
long-range time correlations, we describe the time evolution of the system
within a kind of Bragg-Williams approximation. This approach allows us to
evaluate a characteristic life-time of the ecosystem. This quantity could be
very useful to discuss the time evolution of the system under a wide diversity
of environmental conditions of the ecosystem which is not usually considered.
We discuss the general trends of the temporal evolution of the association with
some data from real ecosystems.
</summary>
    <author>
      <name>E. M. De la Calleja</name>
    </author>
    <author>
      <name>J. L. Carrillo</name>
    </author>
    <author>
      <name>I. Santamaría-Holek</name>
    </author>
    <link href="http://arxiv.org/abs/1603.03608v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03608v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06119v1</id>
    <updated>2016-03-19T17:38:52Z</updated>
    <published>2016-03-19T17:38:52Z</published>
    <title>A Big-Data Approach to Handle Process Variations: Uncertainty
  Quantification by Tensor Recovery</title>
    <summary>  Stochastic spectral methods have become a popular technique to quantify the
uncertainties of nano-scale devices and circuits. They are much more efficient
than Monte Carlo for certain design cases with a small number of random
parameters. However, their computational cost significantly increases as the
number of random parameters increases. This paper presents a big-data approach
to solve high-dimensional uncertainty quantification problems. Specifically, we
simulate integrated circuits and MEMS at only a small number of quadrature
samples, then, a huge number of (e.g., $1.5 \times 10^{27}$) solution samples
are estimated from the available small-size (e.g., $500$) solution samples via
a low-rank and tensor-recovery method. Numerical results show that our
algorithm can easily extend the applicability of tensor-product stochastic
collocation to IC and MEMS problems with over 50 random parameters, whereas the
traditional algorithm can only handle several random parameters.
</summary>
    <author>
      <name>Zheng Zhang</name>
    </author>
    <author>
      <name>Tsui-Wei Weng</name>
    </author>
    <author>
      <name>Luca Daniel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2016 IEEE 20th Workshop on Signal and Power Integrity (SPI), 8-11 May
  2016, Turin, Italy</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08260v1</id>
    <updated>2016-03-27T21:21:39Z</updated>
    <published>2016-03-27T21:21:39Z</published>
    <title>Optimal design of a micro-tubular fuel cell</title>
    <summary>  We discuss the problem of the optimal design of a micro-tubular fuel cell
applying an inverse homogenization technique. Fuel cells are extremely clean
and efficient electrochemical power generation devices, made up of a
cathode/electrolyte/anode structure, whose energetic potential has not being
fully exploited in propulsion systems in aeronautics due to their low power
densities. Nevertheless, thanks to the recent development of additive layer
manufacturing techniques (3D printing), complex structures usually impossible
to design with conventional manufacturing techniques can be constructed with a
low cost, allowing notably to build porous or foam-type structures for fuel
cells. We seek thus to come up with the micro-structure of an arrangement of
micro-tubular cathodes which maximizes the contact surface subject to a
pressure drop and a permeability constraint. The optimal periodic design
(fluid/solid) emerges from the application of a shape gradient algorithm
coupled to a level-set method for the geometrical description of the
corresponding cell problem.
</summary>
    <author>
      <name>Gabriel Delgado</name>
    </author>
    <link href="http://arxiv.org/abs/1603.08260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05201v1</id>
    <updated>2016-04-18T15:15:01Z</updated>
    <published>2016-04-18T15:15:01Z</published>
    <title>Two-grid algorithms for singularly perturbed reaction-diffusion problems
  on layer adapted meshes</title>
    <summary>  We propose a new two-grid approach based on Bellman-Kalaba quasilinearization
and Axelsson-Xu finite element two-grid method for the solution of singularly
perturbed reaction-diffusion equations. The algorithms involve solving one
inexpensive problem on coarse grid and solving on fine grid one linear problem
obtained by quasilinearization of the differential equation about an
interpolant of the computed solution on the coarse grid. Different meshes (of
Bakhvalov, Shishkin and Vulanovi\'c types) are examined. All the schemes are
uniformly convergent with respect to the small parameter. We show theoretically
and numerically that the global error of the two-grid method is the same as of
the nonlinear problem solved directly on the fine layer-adapted mesh.
</summary>
    <author>
      <name>Ivanka Tr. Angelova</name>
    </author>
    <author>
      <name>Lubin G. Vulkov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.05201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00854v1</id>
    <updated>2016-04-28T16:29:39Z</updated>
    <published>2016-04-28T16:29:39Z</published>
    <title>Fast Simulation of Probabilistic Boolean Networks (Technical Report)</title>
    <summary>  Probabilistic Boolean networks (PBNs) is an important mathematical framework
widely used for modelling and analysing biological systems. PBNs are suited for
modelling large biological systems, which more and more often arise in systems
biology. However, the large system size poses a~significant challenge to the
analysis of PBNs, in particular, to the crucial analysis of their steady-state
behaviour. Numerical methods for performing steady-state analyses suffer from
the state-space explosion problem, which makes the utilisation of statistical
methods the only viable approach. However, such methods require long
simulations of PBNs, rendering the simulation speed a crucial efficiency
factor. For large PBNs and high estimation precision requirements, a slow
simulation speed becomes an obstacle. In this paper, we propose a
structure-based method for fast simulation of PBNs. This method first performs
a network reduction operation and then divides nodes into groups for parallel
simulation. Experimental results show that our method can lead to an
approximately 10 times speedup for computing steady-state probabilities of a
real-life biological network.
</summary>
    <author>
      <name>Andrzej Mizera</name>
    </author>
    <author>
      <name>Jun Pang</name>
    </author>
    <author>
      <name>Qixia Yuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures, for CMSB 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.00854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.06735v1</id>
    <updated>2016-05-22T04:43:10Z</updated>
    <published>2016-05-22T04:43:10Z</published>
    <title>Tensors in Power System Computation I: Distributed Computation for
  Optimal Power Flow, DC OPF</title>
    <summary>  Tensor decomposition plays a key role in identifying common features across a
collection of matrices in many areas of science. A fundamental need in big data
research is to process data tabulated as large-scale matrices using
eigenvectors. A higher order generalized singular value decomposition technique
successfully captures the common features of the same organ from multiple
animals in genomic signal processing. A recent semidefinite programming
approach to solve an AC optimal power flow was accompanied by the problem
formulation in the Cartesian coordinate system. The collection of nodal
Kirchhoff laws introduces a 3D tensor with a common feature of individual
matrices to maintain local power balance. In this paper, the mathematical
process is established and the common feature is identified. The common feature
is a key element to a fully decentralized and therefore scalable algorithm to
solve AC optimal power flow.
</summary>
    <author>
      <name>HyungSeon Oh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.06735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.06735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07091v1</id>
    <updated>2016-05-23T16:52:03Z</updated>
    <published>2016-05-23T16:52:03Z</published>
    <title>Stable and accurate interface capturing advection schemes</title>
    <summary>  In this paper, stable and "low-diffusive" multidimensional interface
capturing (IC) schemes using slope limiters are discussed. It is known that
direction-by-direction slope-limited MUSCL schemes create geometrical artifacts
and thus return a poor accuracy. We here focus on this particular issue and
show that the reconstruction of gradient directions are an important factor of
accuracy. The use of a multidimensional limiting process (MLP) added with an
adequate time integration scheme leads to an artifact-free and instability-free
interface capturing (IC) approach. Numerical experiments like the reference
Kothe-Rider forward-backward advection case show the accuracy of the approach.
We also show that the approach can be extended to the more complex compressible
multimaterial hydrodynamics case, with potentially an arbitrary number of
fluids. We also believe that this approach is appropriate for
multicore/manycore architecture because of its SIMD feature, which may be
another asset compared to interface reconstruction approaches.
</summary>
    <author>
      <name>Florian De Vuyst</name>
    </author>
    <author>
      <name>Marie Béchereau</name>
    </author>
    <author>
      <name>Thibault Gasc</name>
    </author>
    <author>
      <name>Renaud Motte</name>
    </author>
    <author>
      <name>Mathieu Peybernes</name>
    </author>
    <author>
      <name>Raphael Poncet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.07091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00556v2</id>
    <updated>2016-10-07T18:26:44Z</updated>
    <published>2016-06-02T06:51:10Z</published>
    <title>Numerical Simulation of Multi-phase Flow in Porous Media on Parallel
  Computers</title>
    <summary>  A parallel reservoir simulator has been developed, which is designed for
large-scale black oil simulations. It handles three phases, including water,
oil and gas, and three components, including water, oil and gas. This simulator
can calculate traditional reservoir models and naturally fractured models.
Various well operations are supported, such as water flooding, gas flooding and
polymer flooding. The operation constraints can be fixed bottom-hole pressure,
a fixed fluid rate, and combinations of them. The simulator is based on our
in-house platform, which provides grids, cell-centred data, linear solvers,
preconditioners and well modeling. The simulator and the platform use MPI for
communications among computation nodes. Our simulator is capable of simulating
giant reservoir models with hundreds of millions of grid cells. Numerical
simulations show that our simulator matches with commercial simulators and it
has excellent scalability.
</summary>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Lihua Shen</name>
    </author>
    <author>
      <name>Kun Wang</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00556v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00556v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.01243v1</id>
    <updated>2016-06-03T08:20:32Z</updated>
    <published>2016-06-03T08:20:32Z</published>
    <title>BES with FEM: Building Energy Simulation using Finite Element Methods</title>
    <summary>  An overall objective of energy efficiency in the built environment is to
improve building and systems performances in terms of durability, comfort and
economics. In order to predict, improve and meet a certain set of performance
requirements related to the indoor climate of buildings and the associated
energy demand, building energy simulation (BES) tools are indispensable. Due to
the rapid development of FEM software and the Multiphysics approaches, it
should possible to build and simulate full 3D models of buildings regarding the
energy demand. The paper presents a methodology for performing building energy
simulation with Comsol. The method was applied to an international test box
experiment. The results showed an almost perfect agreement between the used BES
model and Comsol. These preliminary results confirm the great opportunities to
use FEM related software for building energy performance simulation.
</summary>
    <author>
      <name>A. W. M. van Schijndel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 figures, Proceedings of the 2012 COMSOL Conference in
  Milan</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.01243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.01243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.01313v1</id>
    <updated>2016-06-04T00:44:35Z</updated>
    <published>2016-06-04T00:44:35Z</published>
    <title>Design of Robust Adaptive Beamforming Algorithms Based on Low-Rank and
  Cross-Correlation Techniques</title>
    <summary>  This work presents cost-effective low-rank techniques for designing robust
adaptive beamforming (RAB) algorithms. The proposed algorithms are based on the
exploitation of the cross-correlation between the array observation data and
the output of the beamformer. Firstly, we construct a general linear equation
considered in large dimensions whose solution yields the steering vector
mismatch. Then, we employ the idea of the full orthogonalization method (FOM),
an orthogonal Krylov subspace based method, to iteratively estimate the
steering vector mismatch in a reduced-dimensional subspace, resulting in the
proposed orthogonal Krylov subspace projection mismatch estimation (OKSPME)
method. We also devise adaptive algorithms based on stochastic gradient (SG)
and conjugate gradient (CG) techniques to update the beamforming weights with
low complexity and avoid any costly matrix inversion. The main advantages of
the proposed low-rank and mismatch estimation techniques are their
cost-effectiveness when dealing with high dimension subspaces or large sensor
arrays. Simulations results show excellent performance in terms of the output
signal-to-interference-plus-noise ratio (SINR) of the beamformer among all the
compared RAB methods.
</summary>
    <author>
      <name>H. Ruan</name>
    </author>
    <author>
      <name>R. C. de Lamare</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TSP.2016.2550006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TSP.2016.2550006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 figures, 12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.01313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.01313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02422v4</id>
    <updated>2017-01-15T21:18:24Z</updated>
    <published>2016-06-08T07:03:09Z</published>
    <title>Bayesian inference for the stochastic identification of elastoplastic
  material parameters: Introduction, misconceptions and insights</title>
    <summary>  We discuss Bayesian inference (BI) for the probabilistic identification of
material parameters. This contribution aims to shed light on the use of BI for
the identification of elastoplastic material parameters. For this purpose a
single spring is considered, for which the stress-strain curves are
artificially created. Besides offering a didactic introduction to BI, this
paper proposes an approach to incorporate statistical errors both in the
measured stresses, and in the measured strains. It is assumed that the
uncertainty is only due to measurement errors and the material is homogeneous.
Furthermore, a number of possible misconceptions on BI are highlighted based on
the purely elastic case.
</summary>
    <author>
      <name>Hussein Rappel</name>
    </author>
    <author>
      <name>Lars A. A. Beex</name>
    </author>
    <author>
      <name>Jack S. Hale</name>
    </author>
    <author>
      <name>Stephane P. A. Bordas</name>
    </author>
    <link href="http://arxiv.org/abs/1606.02422v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02422v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03855v2</id>
    <updated>2016-06-14T05:13:40Z</updated>
    <published>2016-06-13T08:27:21Z</published>
    <title>Mathematical Modeling of Dynamics for Partially Filled Shells of
  Revolution</title>
    <summary>  In this work we study the dynamic behaviour of compound shells of revolution
partially filled with an ideal incompressible fluid based on boundary-value
problems. New analytical mathematical model with corresponding discrete scheme
for the elastic displacements and the dynamic liquid pressure is developed. The
discrete scheme is based on the method of discrete singularities. A code to
perform the numerical analysis is developed. Comprehensive benchmarking of the
obtained results against other methods is done and good agreement is observed.
The convergence of the proposed numerical method is demonstrated. One of the
advantages of this new model is that the initial 3D problem is analytically
reduced to a 1D integral equation. Moreover, it can handle the behaviour of the
pressure in the vicinity of the nodes explicitly and the computational
technique used has a quick convergence requiring a negligible amount of CPU
time.
</summary>
    <author>
      <name>Iryna Kononenko</name>
    </author>
    <author>
      <name>Oleksiy Kononenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.03855v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03855v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04464v3</id>
    <updated>2017-07-13T01:04:40Z</updated>
    <published>2016-06-14T17:18:06Z</published>
    <title>Sequential geophysical and flow inversion to characterize fracture
  networks in subsurface systems</title>
    <summary>  Subsurface applications including geothermal, geological carbon
sequestration, oil and gas, etc., typically involve maximizing either the
extraction of energy or the storage of fluids. Characterizing the subsurface is
extremely complex due to heterogeneity and anisotropy. Due to this complexity,
there are uncertainties in the subsurface parameters, which need to be
estimated from multiple diverse as well as fragmented data streams. In this
paper, we present a non-intrusive sequential inversion framework, for
integrating data from geophysical and flow sources to constraint subsurface
Discrete Fracture Networks (DFN). In this approach, we first estimate bounds on
the statistics for the DFN fracture orientations using microseismic data. These
bounds are estimated through a combination of a focal mechanism (physics-based
approach) and clustering analysis (statistical approach) of seismic data. Then,
the fracture lengths are constrained based on the flow data. The efficacy of
this multi-physics based sequential inversion is demonstrated through a
representative synthetic example.
</summary>
    <author>
      <name>M. K. Mudunuru</name>
    </author>
    <author>
      <name>S. Karra</name>
    </author>
    <author>
      <name>N. Makedonska</name>
    </author>
    <author>
      <name>T. Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/sam.11356</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/sam.11356" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.04464v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04464v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06154v1</id>
    <updated>2016-06-07T07:01:50Z</updated>
    <published>2016-06-07T07:01:50Z</published>
    <title>Closed Form Fractional Integration and Differentiation via Real
  Exponentially Spaced Pole-Zero Pairs</title>
    <summary>  We derive closed-form expressions for the poles and zeros of approximate
fractional integrator/differentiator filters, which correspond to spectral
roll-off filters having any desired log-log slope to a controllable degree of
accuracy over any bandwidth. The filters can be described as a uniform
exponential distribution of poles along the negative-real axis of the s plane,
with zeros interleaving them. Arbitrary spectral slopes are obtained by sliding
the array of zeros relative to the array of poles, where each array maintains
periodic spacing on a log scale. The nature of the slope approximation is close
to Chebyshev optimal in the interior of the pole-zero array, approaching
conjectured Chebyshev optimality over all frequencies in the limit as the order
approaches infinity. Practical designs can arbitrarily approach the
equal-ripple approximation by enlarging the pole-zero array band beyond the
desired frequency band. The spectral roll-off slope can be robustly modulated
in real time by varying only the zeros controlled by one slope parameter.
Software implementations are provided in matlab and Faust.
</summary>
    <author>
      <name>Julius Orion Smith</name>
    </author>
    <author>
      <name>Harrison Freeman Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.06154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06975v1</id>
    <updated>2016-06-22T15:05:23Z</updated>
    <published>2016-06-22T15:05:23Z</published>
    <title>Bias Correction in Saupe Tensor Estimation</title>
    <summary>  Estimation of the Saupe tensor is central to the determination of molecular
structures from residual dipolar couplings (RDC) or chemical shift
anisotropies. Assuming a given template structure, the singular value
decomposition (SVD) method proposed in Losonczi et al. 1999 has been used
traditionally to estimate the Saupe tensor. Despite its simplicity, whenever
the template structure has large structural noise, the eigenvalues of the
estimated tensor have a magnitude systematically smaller than their actual
values. This leads to systematic error when calculating the eigenvalue
dependent parameters, magnitude and rhombicity. We propose here a Monte Carlo
simulation method to remove such bias. We further demonstrate the effectiveness
of our method in the setting when the eigenvalue estimates from multiple
template protein fragments are available and their average is used as an
improved eigenvalue estimator. For both synthetic and experimental RDC datasets
of ubiquitin, when using template fragments corrupted by large noise, the
magnitude of our proposed bias-reduced estimator generally reaches at least 90%
of the actual value, whereas the magnitude of SVD estimator can be shrunk below
80% of the true value.
</summary>
    <author>
      <name>Yuehaw Khoo</name>
    </author>
    <author>
      <name>Amit Singer</name>
    </author>
    <author>
      <name>David Cowburn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.06975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08761v1</id>
    <updated>2016-06-28T15:45:32Z</updated>
    <published>2016-06-28T15:45:32Z</published>
    <title>A Dissipative Systems Theory for FDTD with Application to Stability
  Analysis and Subgridding</title>
    <summary>  This paper establishes a far-reaching connection between the
Finite-Difference Time-Domain method (FDTD) and the theory of dissipative
systems. The FDTD equations for a rectangular region are written as a dynamical
system having the magnetic and electric fields on the boundary as inputs and
outputs. Suitable expressions for the energy stored in the region and the
energy absorbed from the boundaries are introduced, and used to show that the
FDTD system is dissipative under a generalized Courant-Friedrichs-Lewy
condition. Based on the concept of dissipation, a powerful theoretical
framework to investigate the stability of FDTD methods is devised. The new
method makes FDTD stability proofs simpler, more intuitive, and modular.
Stability conditions can indeed be given on the individual components (e.g.
boundary conditions, meshes, embedded models) instead of the whole coupled
setup. As an example of application, we derive a new subgridding method with
material traverse, arbitrary grid refinement, and guaranteed stability. The
method is easy to implement and has a straightforward stability proof.
Numerical results confirm its stability, low reflections, and ability to handle
material traverse.
</summary>
    <author>
      <name>Fadime Bekmambetova</name>
    </author>
    <author>
      <name>Xinyue Zhang</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAP.2016.2637867</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAP.2016.2637867" rel="related"/>
    <link href="http://arxiv.org/abs/1606.08761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02573v2</id>
    <updated>2020-03-19T18:44:32Z</updated>
    <published>2016-07-09T06:57:38Z</published>
    <title>Microwave Tomographic Imaging of Cerebrovascular Accidents by Using
  High-Performance Computing</title>
    <summary>  The motivation of this work is the detection of cerebrovascular accidents by
microwave tomographic imaging. This requires the solution of an inverse problem
relying on a minimization algorithm (for example, gradient-based), where
successive iterations consist in repeated solutions of a direct problem. The
reconstruction algorithm is extremely computationally intensive and makes use
of efficient parallel algorithms and high-performance computing. The
feasibility of this type of imaging is conditioned on one hand by an accurate
reconstruction of the material properties of the propagation medium and on the
other hand by a considerable reduction in simulation time. Fulfilling these two
requirements will enable a very rapid and accurate diagnosis. From the
mathematical and numerical point of view, this means solving Maxwell's
equations in time-harmonic regime by appropriate domain decomposition methods,
which are naturally adapted to parallel architectures.
</summary>
    <author>
      <name>P. -H. Tournier</name>
    </author>
    <author>
      <name>I. Aliferis</name>
    </author>
    <author>
      <name>M. Bonazzoli</name>
    </author>
    <author>
      <name>M. de Buhan</name>
    </author>
    <author>
      <name>M. Darbas</name>
    </author>
    <author>
      <name>V. Dolean</name>
    </author>
    <author>
      <name>F. Hecht</name>
    </author>
    <author>
      <name>P. Jolivet</name>
    </author>
    <author>
      <name>I. El Kanfoud</name>
    </author>
    <author>
      <name>C. Migliaccio</name>
    </author>
    <author>
      <name>F. Nataf</name>
    </author>
    <author>
      <name>C. Pichot</name>
    </author>
    <author>
      <name>S. Semenov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.parco.2019.02.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.parco.2019.02.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Parallel Computing, 85:88-97, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.02573v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02573v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02904v1</id>
    <updated>2016-07-11T11:23:04Z</updated>
    <published>2016-07-11T11:23:04Z</published>
    <title>The Vectorization of the Tersoff Multi-Body Potential: An Exercise in
  Performance Portability</title>
    <summary>  Molecular dynamics simulations, an indispensable research tool in
computational chemistry and materials science, consume a significant portion of
the supercomputing cycles around the world. We focus on multi-body potentials
and aim at achieving performance portability. Compared with well-studied pair
potentials, multibody potentials deliver increased simulation accuracy but are
too complex for effective compiler optimization. Because of this, achieving
cross-platform performance remains an open question. By abstracting from target
architecture and computing precision, we develop a vectorization scheme
applicable to both CPUs and accelerators. We present results for the Tersoff
potential within the molecular dynamics code LAMMPS on several architectures,
demonstrating efficiency gains not only for computational kernels, but also for
large-scale simulations. On a cluster of Intel Xeon Phi's, our optimized solver
is between 3 and 5 times faster than the pure MPI reference.
</summary>
    <author>
      <name>Markus Höhnerbach</name>
    </author>
    <author>
      <name>Ahmed E. Ismail</name>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05867v1</id>
    <updated>2016-07-20T09:02:00Z</updated>
    <published>2016-07-20T09:02:00Z</published>
    <title>Asymptotic bounds on the globally optimal positions of orthogonal
  stiffeners for rectangular plates in elastostatic bending</title>
    <summary>  The present paper treats the problem of finding the asymptotic bounds for the
globally optimal locations of orthogonal stiffeners minimizing the compliance
of a rectangular plate in elastostatic bending. The essence of the paper is the
utilization of a method of analysis of orthogonally stiffened rectangular
plates first presented by Mazurkiewicz in 1962, and obtained herein in a closed
form for several special cases in the approximation of stiffeners having zero
torsional rigidity. Asymptotic expansions of the expressions for the deflection
field of a stiffened plate are used to derive limit-case globally optimal
stiffening layouts for highly flexible and highly rigid stiffeners. A central
result obtained in this work is an analytical proof of the fact that an array
of flexible enough orthogonal stiffeners of any number, stiffening a
simply-supported rectangular plate subjected to any lateral loading, is best to
be put in the form of exactly two orthogonal stiffeners, one in each direction.
</summary>
    <author>
      <name>Nathan Perchikov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11081-011-9161-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11081-011-9161-3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Optim. Eng. 14 (2013) 119-153</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.05867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.06834v2</id>
    <updated>2017-09-30T21:06:33Z</updated>
    <published>2016-07-22T20:27:06Z</published>
    <title>A Numerical Investigation of Matrix-Free Implicit Time-Stepping Methods
  for Large CFD Simulations</title>
    <summary>  This paper is concerned with the development and testing of advanced
time-stepping methods suited for the integration of time-accurate, real-world
applications of computational fluid dynamics (CFD). The performance of several
time discretization methods is studied numerically with regards to
computational efficiency, order of accuracy, and stability, as well as the
ability to treat effectively stiff problems. We consider matrix-free
implementations, a popular approach for time-stepping methods applied to large
CFD applications due to its adherence to scalable matrix-vector operations and
a small memory footprint. We compare explicit methods with matrix-free
implementations of implicit, linearly-implicit, as well as Rosenbrock-Krylov
methods. We show that Rosenbrock-Krylov methods are competitive with existing
techniques excelling for a number of problem types and settings.
</summary>
    <author>
      <name>Arash Sarshar</name>
    </author>
    <author>
      <name>Paul Tranquilli</name>
    </author>
    <author>
      <name>Brent Pickering</name>
    </author>
    <author>
      <name>Andrew McCall</name>
    </author>
    <author>
      <name>Adrian Sandu</name>
    </author>
    <author>
      <name>Christopher J. Roy</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compfluid.2017.09.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compfluid.2017.09.014" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computers &amp; Fluids, Volume 159, 15 Dec. 2017, PP. 53-63</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.06834v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.06834v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L05, 65L06, 65L20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.08083v2</id>
    <updated>2017-05-11T07:43:33Z</updated>
    <published>2016-07-27T13:23:05Z</published>
    <title>An Energy stable Monolithic Eulerian Fluid-Structure Numerical Scheme *</title>
    <summary>  The conservation laws of continuum mechanic written in an Eulerian frame make
no difference between fluids and solids except in the expression of the stress
tensors, usually with Newton's hypothesis for the fluids and Helmholtz
potentials of energy for hyperelastic solids. By taking the velocities as
unknown , monolithic methods for fluid structure interactions (FSI) are built.
In this article such a formulation is analyzed when the fluid is compressible
and the fluid is incompressible. The idea is not new but the progress of mesh
generators and numerical schemes like the Characteristics-Galerkin method
render this approach feasible and reasonably robust. In this article the method
and its discretization are presented, stability is discussed by through an
energy estimate. A numerical section discusses implementation issues and
presents a few simple tests.
</summary>
    <author>
      <name>Olivier Pironneau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LJLL</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1607.08083v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.08083v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04550v1</id>
    <updated>2016-08-16T11:26:25Z</updated>
    <published>2016-08-16T11:26:25Z</published>
    <title>Fast Calculation of the Knowledge Gradient for Optimization of
  Deterministic Engineering Simulations</title>
    <summary>  A novel efficient method for computing the Knowledge-Gradient policy for
Continuous Parameters (KGCP) for deterministic optimization is derived. The
differences with Expected Improvement (EI), a popular choice for Bayesian
optimization of deterministic engineering simulations, are explored. Both
policies and the Upper Confidence Bound (UCB) policy are compared on a number
of benchmark functions including a problem from structural dynamics. It is
empirically shown that KGCP has similar performance as the EI policy for many
problems, but has better convergence properties for complex (multi-modal)
optimization problems as it emphasizes more on exploration when the model is
confident about the shape of optimal regions. In addition, the relationship
between Maximum Likelihood Estimation (MLE) and slice sampling for estimation
of the hyperparameters of the underlying models, and the complexity of the
problem at hand, is studied.
</summary>
    <author>
      <name>Joachim van der Herten</name>
    </author>
    <author>
      <name>Ivo Couckuyt</name>
    </author>
    <author>
      <name>Dirk Deschrijver</name>
    </author>
    <author>
      <name>Tom Dhaene</name>
    </author>
    <link href="http://arxiv.org/abs/1608.04550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04998v1</id>
    <updated>2016-08-15T22:56:50Z</updated>
    <published>2016-08-15T22:56:50Z</published>
    <title>A Unified Finite Element Method for Fluid-Structure Interaction</title>
    <summary>  In this article, we present a new unified finite element method (UFEM) for
simulation of general Fluid-Structure interaction (FSI) which has the same
generality and robustness as monolithic methods but is significantly more
computationally efficient and easier to implement. Our proposed approach has
similarities with classical immersed finite element methods (IFEMs), by
approximating a single velocity and pressure field in the entire domain (i.e.
occupied by fluid and solid) on a single mesh, but differs by treating the
corrections due to the solid deformation on the left-hand side of the modified
fluid flow equations (i.e. implicitly). The method is described in detail,
followed by the presentation of multiple computational examples in order to
validate it across a wide range of fluid and solid parameters and interactions.
</summary>
    <author>
      <name>Yongxing Wang</name>
    </author>
    <author>
      <name>Peter Jimack</name>
    </author>
    <author>
      <name>Mark Walkley</name>
    </author>
    <link href="http://arxiv.org/abs/1608.04998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06654v1</id>
    <updated>2016-08-23T21:06:28Z</updated>
    <published>2016-08-23T21:06:28Z</published>
    <title>Stress-constrained continuum topology optimization: a new approach based
  on elasto-plasticity</title>
    <summary>  A new approach for generating stress-constrained topological designs in
continua is presented. The main novelty is in the use of elasto-plastic
modeling and in optimizing the design such that it will exhibit a
linear-elastic response. This is achieved by imposing a single global
constraint on the total sum of equivalent plastic strains, providing accurate
control over all local stress violations. The single constraint essentially
replaces a large number of local stress constraints or an approximate
aggregation of them--two common approaches in the literature. A classical
rate-independent plasticity model is utilized, for which analytical adjoint
sensitivity analysis is derived and verified. Several examples demonstrate the
capability of the computational procedure to generate designs that challenge
results from the literature, in terms of the obtained stiffness-strength-weight
trade-offs. A full elasto-plastic analysis of the optimized designs shows that
prior to the initial yielding, these designs can sustain significantly higher
loads than minimum compliance topological layouts, with only a minor compromise
on stiffness.
</summary>
    <author>
      <name>Oded Amir</name>
    </author>
    <link href="http://arxiv.org/abs/1608.06654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04810v1</id>
    <updated>2016-09-15T07:43:44Z</updated>
    <published>2016-09-15T07:43:44Z</published>
    <title>From the Skin-Depth Equation to the Inverse RFEC Sensor Model</title>
    <summary>  In this paper, we tackle the direct and inverse problems for the Remote-Field
Eddy-Current (RFEC) technology. The direct problem is the sensor model, where
given the geometry the measurements are obtained. Conversely, the inverse
problem is where the geometry needs to be estimated given the field
measurements. These problems are particularly important in the field of
Non-Destructive Testing (NDT) because they allow assessing the quality of the
structure monitored. We solve the direct problem in a parametric fashion using
Least Absolute Shrinkage and Selection Operation (LASSO). The proposed inverse
model uses the parameters from the direct model to recover the thickness using
least squares producing the optimal solution given the direct model. This study
is restricted to the 2D axisymmetric scenario. Both, direct and inverse models,
are validated using a Finite Element Analysis (FEA) environment with realistic
pipe profiles.
</summary>
    <author>
      <name>Raphael Falque</name>
    </author>
    <author>
      <name>Teresa Vidal-Calleja</name>
    </author>
    <author>
      <name>Gamini Dissanayake</name>
    </author>
    <author>
      <name>Jaime Valls Miro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted and accepted to the 14th International Conference on
  Control, Automation, Robotics and Vision (ICARCV 2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.04810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06086v1</id>
    <updated>2016-09-20T10:36:01Z</updated>
    <published>2016-09-20T10:36:01Z</published>
    <title>Modelling Stock-market Investors as Reinforcement Learning Agents
  [Correction]</title>
    <summary>  Decision making in uncertain and risky environments is a prominent area of
research. Standard economic theories fail to fully explain human behaviour,
while a potentially promising alternative may lie in the direction of
Reinforcement Learning (RL) theory. We analyse data for 46 players extracted
from a financial market online game and test whether Reinforcement Learning
(Q-Learning) could capture these players behaviour using a risk measure based
on financial modeling. Moreover we test an earlier hypothesis that players are
"na\"ive" (short-sighted). Our results indicate that a simple Reinforcement
Learning model which considers only the selling component of the task captures
the decision-making process for a subset of players but this is not sufficient
to draw any conclusion on the population. We also find that there is not a
significant improvement of fitting of the players when using a full RL model
against a myopic version, where only immediate reward is valued by the players.
This indicates that players, if using a Reinforcement Learning approach, do so
na\"ively
</summary>
    <author>
      <name>Alvin Pastore</name>
    </author>
    <author>
      <name>Umberto Esposito</name>
    </author>
    <author>
      <name>Eleni Vasilaki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/EAIS.2015.7368789</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/EAIS.2015.7368789" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages (including bibliography and appendix), 5 figures (2 in main
  body, 3 in appendix). IEEE EAIS 2015 Conference paper erratum</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Evolving and Adaptive Intelligent Systems (EAIS), 2015 IEEE
  International Conference on, Douai, 2015, pp. 1-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.06086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06153v1</id>
    <updated>2016-09-19T12:48:52Z</updated>
    <published>2016-09-19T12:48:52Z</published>
    <title>Uncertainty Analysis of Simple Macroeconomic Models Using Angel-Daemon
  Games</title>
    <summary>  We propose the use of an angel-daemon framework to perform an uncertainty
analysis of short-term macroeconomic models with exogenous components. An
uncertainty profile $\mathcal U$ is a short and macroscopic description of a
potentially perturbed situation. The angel-daemon framework uses $\mathcal U$
to define a strategic game where two agents, the angel and the daemon, act
selfishly having different goals. The Nash equilibria of those games provide
the stable strategies in perturbed situations, giving a natural estimation of
uncertainty.
  In this initial work we apply the framework in order to get an uncertainty
analysis of linear versions of the IS-LM and the IS-MP models. In those models,
by considering uncertainty profiles, we can capture different economical
situations. Some of them can be described in terms of macroeconomic policy
coordination. In other cases we just analyse the results of the system under
some possible perturbation level. Besides providing examples of application we
analyse the structure of the Nash equilibria in some particular cases of
interest.
</summary>
    <author>
      <name>Joaquim Gabarro</name>
    </author>
    <author>
      <name>Maria Serna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.06153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91-08 91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06187v2</id>
    <updated>2017-01-02T14:02:48Z</updated>
    <published>2016-09-18T16:50:47Z</published>
    <title>Determination of Bond Wire Failure Probabilities in Microelectronic
  Packages</title>
    <summary>  This work deals with the computation of industry-relevant bond wire failure
probabilities in microelectronic packages. Under operating conditions, a
package is subject to Joule heating that can lead to electrothermally induced
failures. Manufacturing tolerances result, e.g., in uncertain bond wire
geometries that often induce very small failure probabilities requiring a high
number of Monte Carlo (MC) samples to be computed. Therefore, a hybrid MC
sampling scheme that combines the use of an expensive computer model with a
cheap surrogate is used. The fraction of surrogate evaluations is maximized
using an iterative procedure, yielding accurate results at reduced cost.
Moreover, the scheme is non-intrusive, i.e., existing code can be reused. The
algorithm is used to compute the failure probability for an example package and
the computational savings are assessed by performing a surrogate efficiency
study.
</summary>
    <author>
      <name>Thorben Casper</name>
    </author>
    <author>
      <name>Ulrich Römer</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/THERMINIC.2016.7748645</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/THERMINIC.2016.7748645" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Therminic 2016, available at
  http://ieeexplore.ieee.org/document/7748645/</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.06187v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06187v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H30, 60H35, 65M06, 78A30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; F.2.1; I.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07114v2</id>
    <updated>2021-06-29T15:45:32Z</updated>
    <published>2016-09-22T19:19:21Z</published>
    <title>A Stable FDTD Method with Embedded Reduced-Order Models</title>
    <summary>  The computational efficiency of the Finite-Difference Time-Domain (FDTD)
method can be significantly reduced by the presence of complex objects with
fine features. Small geometrical details impose a fine mesh and a reduced time
step, significantly increasing computational cost. Model order reduction has
been proposed as a systematic way to generate compact models for complex
objects, that one can then instantiate into a main FDTD mesh. However, the
stability of FDTD with embedded reduced models remains an open problem. We
propose a systematic method to generate reduced models for FDTD domains, and
embed them into a main FDTD mesh with guaranteed stability up to the
Courant-Friedrichs-Lewy (CFL) limit of the fine mesh. With a simple
perturbation technique, the CFL of the whole scheme can be further extended
beyond the fine grid's CFL limit. Reduced models can be created for arbitrary
domains containing inhomogeneous and lossy materials. Numerical tests confirm
the stability of the proposed method, and its potential to accelerate
multiscale FDTD simulations.
</summary>
    <author>
      <name>Xinyue Zhang</name>
    </author>
    <author>
      <name>Fadime Bekmambetova</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAP.2017.2784414</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAP.2017.2784414" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted and published in IEEE Transactions on Antennas and
  Propagation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in IEEE Transactions on Antennas and Propagation, vol. 66, no. 2,
  pp. 827-837, Feb. 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.07114v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07114v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.00004v1</id>
    <updated>2016-09-30T11:16:35Z</updated>
    <published>2016-09-30T11:16:35Z</published>
    <title>Energy consistent framework for continuously evolving 3D crack
  propagation</title>
    <summary>  This paper presents a formulation for brittle fracture in 3D elastic solids
within the context of configurational mechanics. The local form of the first
law of thermodynamics provides a condition for equilibrium of the crack front.
The direction of the crack propagation is shown to be given by the direction of
the configurational forces on the crack front that maximise the local
dissipation. The evolving crack front is continuously resolved by the finite
element mesh, without the need for face splitting or the use of enrichment
techniques. A monolithic solution strategy is adopted, solving simultaneously
for both the material displacements (i.e. crack extension) and the spatial
displacements, is adopted. In order to trace the dissipative loading path, an
arc-length procedure is developed that controls the incremental crack area
growth. In order to maintain mesh quality, smoothing of the mesh is undertaken
as a continuous process, together with face flipping, node merging and edge
splitting where necessary. Hierarchical basis functions of arbitrary polynomial
order are adopted to increase the order of approximation without the need to
change the finite element mesh. Performance of the formulation is demonstrated
by means of three representative numerical simulations, demonstrating both
accuracy and robustness.
</summary>
    <author>
      <name>Lukasz Kaczmarczyk</name>
    </author>
    <author>
      <name>Zahur Ullah</name>
    </author>
    <author>
      <name>Chris J. Pearce</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2017.06.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2017.06.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.00004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.00004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.00704v1</id>
    <updated>2016-10-03T04:42:06Z</updated>
    <published>2016-10-03T04:42:06Z</published>
    <title>A thermodynamic approach to nonlinear ultrasonics for material state
  awareness and prognosis</title>
    <summary>  We develop a thermodynamic framework for modeling nonlinear ultrasonic damage
sensing and prognosis in materials undergoing progressive damage. The framework
is based on the internal variable approach and relies on the construction of a
pseudo-elastic strain energy function that captures the energetics associated
with the damage progression. The pseudo-elastic strain energy function is
composed of two energy functions - one that describes how a material stores
energy in an elastic fashion and the other describes how material dissipates
energy or stores it in an inelastic fashion. Experimental motivation for the
choice of the above two functionals is discussed and some specific choices
pertaining to damage progression during fatigue and creep are presented. The
thermodynamic framework is employed to model the nonlinear response of material
undergoing stress relaxation and creep-like degradation. For each of the above
cases, evolution of the nonlinearity parameter with damage as well as with
macroscopic measurables like accumulated plastic strain are obtained.
</summary>
    <author>
      <name>Vamshi Krishna Chillara</name>
    </author>
    <link href="http://arxiv.org/abs/1610.00704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.00704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02277v2</id>
    <updated>2023-01-30T12:22:11Z</updated>
    <published>2016-10-07T13:33:50Z</published>
    <title>Multi-mesh multi-objective optimization with application to a model
  problem in urban design</title>
    <summary>  We present an application of multi-mesh finite element methods as part of a
methodology for optimizing settlement layouts. By formulating a multi-objective
optimization problem, we demonstrate how a given number of buildings may be
optimally placed on a given piece of land with respect to both wind conditions
and the view experienced from the buildings. The wind flow is modeled by a
multi-mesh (cut finite element) method. This allows each building to be
embedded in a boundary-fitted mesh which can be moved freely on top of a fixed
background mesh. This approach enables a multitude of settlement layouts to be
evaluated without the need for costly mesh generation when changing the
configuration of buildings. The view is modeled by a measure that takes into
account the totality of unobstructed view from the collection of buildings, and
is efficiently computed by rasterization.
</summary>
    <author>
      <name>Anders Logg</name>
    </author>
    <author>
      <name>Christian Valdemar Lorenzen</name>
    </author>
    <author>
      <name>Carl Lundholm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper III in C. Lundholm, "Cut Finite Element Methods on Overlapping
  Meshes: Analysis and Applications", PhD thesis, Chalmers University of
  Technology and University of Gothenburg, 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.02277v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02277v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; I.6.5; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03484v2</id>
    <updated>2016-10-13T07:57:56Z</updated>
    <published>2016-10-11T15:47:23Z</published>
    <title>Multi-scale computational homogenisation to predict the long-term
  durability of composite structures</title>
    <summary>  A coupled hygro-thermo-mechanical computational model is proposed for fibre
reinforced polymers, formulated within the framework of Computational
Homogenisation (CH). At each macrostructure Gauss point, constitutive matrices
for thermal, moisture transport and mechanical responses are calculated from CH
of the underlying representative volume element (RVE). A degradation model,
developed from experimental data relating evolution of mechanical properties
over time for a given exposure temperature and moisture concentration is also
developed and incorporated in the proposed computational model. A unified
approach is used to impose the RVE boundary conditions, which allows convenient
switching between linear Dirichlet, uniform Neumann and periodic boundary
conditions. A plain weave textile composite RVE consisting of yarns embedded in
a matrix is considered in this case. Matrix and yarns are considered as
isotropic and transversely isotropic materials respectively. Furthermore, the
computational framework utilises hierarchic basis functions and designed to
take advantage of distributed memory high-performance computing.
</summary>
    <author>
      <name>Zahur Ullah</name>
    </author>
    <author>
      <name>Lukasz Kaczmarczyk</name>
    </author>
    <author>
      <name>Sotirios Grammatikos</name>
    </author>
    <author>
      <name>Mark Evernden</name>
    </author>
    <author>
      <name>Chris Pearce</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted in revised form to Computer &amp; Structures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.03484v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03484v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03863v4</id>
    <updated>2016-12-09T08:34:46Z</updated>
    <published>2016-10-11T12:48:20Z</published>
    <title>High Dimensional Uncertainty Quantification for an Electrothermal Field
  Problem using Stochastic Collocation on Sparse Grids and Tensor Train
  Decompositions</title>
    <summary>  The temperature developed in bondwires of integrated circuits (ICs) is a
possible source of malfunction, and has to be taken into account during the
design phase of an IC. Due to manufacturing tolerances, a bondwire's
geometrical characteristics are uncertain parameters, and as such their impact
has to be examined with the use of uncertainty quantification (UQ) methods.
Sampling methods, like the Monte Carlo (MC), converge slowly, while efficient
alternatives scale badly with respect to the number of considered
uncertainties. Possible remedies to this, so-called, curse of dimensionality
are sought in the application of stochastic collocation (SC) on sparse grids
(SGs) and of the recently emerged low-rank tensor decomposition methods, with
emphasis on the tensor train (TT) decomposition.
</summary>
    <author>
      <name>D. Loukrezis</name>
    </author>
    <author>
      <name>U. Römer</name>
    </author>
    <author>
      <name>T. Casper</name>
    </author>
    <author>
      <name>S. Schöps</name>
    </author>
    <author>
      <name>H. De Gersem</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/jnm.2222</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/jnm.2222" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Numer. Model., 31(2), 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.03863v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03863v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03932v3</id>
    <updated>2017-06-11T05:06:42Z</updated>
    <published>2016-10-13T04:08:32Z</published>
    <title>The Curvature-Augmented Closest Point Method with Vesicle
  Inextensibility Application</title>
    <summary>  The Closest Point method, initially developed by Ruuth and Merriman, allows
for the numerical solution of surface partial differential equations without
the need for a parameterization of the surface itself. Surface quantities are
embedded into the surrounding domain by assigning each value at a given spatial
location to the corresponding value at the closest point on the surface. This
embedding allows for surface derivatives to be replaced by their Cartesian
counterparts (e.g. $\nabla_s = \nabla$). This equivalence is only valid on the
surface, and thus, interpolation is used to enforce what is known as the side
condition away from the surface. To improve upon the method, this work derives
an operator embedding that incorporates curvature information, making it valid
in a neighborhood of the surface. With this, direct enforcement of the side
condition is no longer needed. Comparisons in $\mathbb{R}^2$ and $\mathbb{R}^3$
show that the resulting Curvature-Augmented Closest Point method has better
accuracy and requires less memory, through increased matrix sparsity, than the
Closest Point method, while maintaining similar matrix condition numbers. To
demonstrate the utility of the method in a physical application, simulations of
inextensible, bi-lipid vesicles evolving toward equilibrium shapes are also
included.
</summary>
    <author>
      <name>Christopher J. Vogl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2017.06.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2017.06.004" rel="related"/>
    <link href="http://arxiv.org/abs/1610.03932v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03932v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04303v1</id>
    <updated>2016-10-14T00:46:08Z</updated>
    <published>2016-10-14T00:46:08Z</published>
    <title>Electrothermal Simulation of Bonding Wire Degradation under Uncertain
  Geometries</title>
    <summary>  In this paper, electrothermal field phenomena in electronic components are
considered. This coupling is tackled by multiphysical field simulations using
the Finite Integration Technique (FIT). In particular, the design of bonding
wires with respect to thermal degradation is investigated. Instead of resolving
the wires by the computational grid, lumped element representations are
introduced as point-to-point connections in the spatially distributed model.
Fabrication tolerances lead to uncertainties of the wires' parameters and
influence the operation and reliability of the final product. Based on
geometric measurements, the resulting variability of the wire temperatures is
determined using the stochastic electrothermal field-circuit model.
</summary>
    <author>
      <name>Thorben Casper</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Renaud Gillon</name>
    </author>
    <author>
      <name>Tomas Gotthans</name>
    </author>
    <author>
      <name>Tomas Kratochvil</name>
    </author>
    <author>
      <name>Peter Meuris</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to DATE, available at
  http://ieeexplore.ieee.org/document/7459510/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2016 Design, Automation &amp; Test in Europe Conference &amp; Exhibition
  (DATE), Dresden, 2016, pp. 1297-1302</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.04303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04304v1</id>
    <updated>2016-10-14T00:47:04Z</updated>
    <published>2016-10-14T00:47:04Z</published>
    <title>Automatic Generation of Equivalent Electrothermal SPICE Netlists from 3D
  Electrothermal Field Models</title>
    <summary>  Starting from a 3D electrothermal field problem discretized by the Finite
Integration Technique, the equivalence to a circuit description is shown by
exploiting the analogy to the Modified Nodal Analysis approach. Using this
analogy, an algorithm for the automatic generation of a monolithic SPICE
netlist is presented. Joule losses from the electrical circuit are included as
heat sources in the thermal circuit. The thermal simulation yields nodal
temperatures that influence the electrical conductivity. Apart from the used
field discretization, this approach applies no further simplifications. An
example 3D chip package is used to validate the algorithm.
</summary>
    <author>
      <name>Thorben Casper</name>
    </author>
    <author>
      <name>Herbert De Gersem</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/EuroSimE.2016.7463329</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/EuroSimE.2016.7463329" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to EuroSimE 2016, available at
  http://ieeexplore.ieee.org/document/7463329/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2016 17th International Conference on Thermal, Mechanical and
  Multi-Physics Simulation and Experiments in Microelectronics and Microsystems
  (EuroSimE), Montpellier, 2016, pp. 1-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.04304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05029v2</id>
    <updated>2017-12-19T17:43:44Z</updated>
    <published>2016-10-17T09:30:49Z</published>
    <title>An algorithmic comparison of the Hyper-Reduction and the Discrete
  Empirical Interpolation Method for a nonlinear thermal problem</title>
    <summary>  A novel algorithmic discussion of the methodological and numerical
differences of competing parametric model reduction techniques for nonlinear
problems are presented. First, the Galerkin reduced basis (RB) formulation is
presented which fails at providing significant gains with respect to the
computational efficiency for nonlinear problems. Renown methods for the
reduction of the computing time of nonlinear reduced order models are the
Hyper-Reduction and the (Discrete) Empirical Interpolation Method (EIM, DEIM).
An algorithmic description and a methodological comparison of both methods are
provided. The accuracy of the predictions of the hyper-reduced model and the
(D)EIM in comparison to the Galerkin RB is investigated. All three approaches
are applied to a simple uncertainty quantification of a planar nonlinear
thermal conduction problem. The results are compared to computationally intense
finite element simulations.
</summary>
    <author>
      <name>Felix Fritzen</name>
    </author>
    <author>
      <name>Bernhard Haasdonk</name>
    </author>
    <author>
      <name>David Ryckelynck</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05029v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05029v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="78M34, 65N30, 80M10, 34A05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; F.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05472v2</id>
    <updated>2016-10-22T10:09:36Z</updated>
    <published>2016-10-18T08:09:36Z</published>
    <title>Simulation of electrical machines - A FEM-BEM coupling scheme</title>
    <summary>  Electrical machines commonly consist of moving and stationary parts. The
field simulation of such devices can be very demanding if the underlying
numerical scheme is solely based on a domain discretization, such as in case of
the Finite Element Method (FEM). Here, a coupling scheme based on FEM together
with Boundary Element Methods (BEM) is presented that neither hinges on
re-meshing techniques nor deals with a special treatment of sliding interfaces.
While the numerics are certainly more involved the reward is obvious: The
modeling costs decrease and the application engineer is provided with an
easy-to-use, versatile, and accurate simulation tool.
</summary>
    <author>
      <name>Lars Kielhorn</name>
    </author>
    <author>
      <name>Thomas Rüberg</name>
    </author>
    <author>
      <name>Jürgen Zechner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1108/COMPEL-02-2017-0061</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1108/COMPEL-02-2017-0061" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05472v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05472v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.06958v1</id>
    <updated>2016-10-21T21:29:06Z</updated>
    <published>2016-10-21T21:29:06Z</published>
    <title>Scale-Dependent Pedotransfer Functions Reliability for Estimating
  Saturated Hydraulic Conductivity</title>
    <summary>  Saturated hydraulic conductivity Ksat is a fundamental characteristic in
modeling flow and contaminant transport in soils and sediments. Therefore, many
models have been developed to estimate Ksat from easily measureable parameters,
such as textural properties, bulk density, etc. However, Ksat is not only
affected by textural and structural characteristics, but also by scale e.g.,
internal diameter and height. Using the UNSODA database and the contrast
pattern aided regression (CPXR) method, we recently developed scale-dependent
pedotransfer functions to estimate Ksat from textural data, bulk density, and
sample dimensions. The main objectives of this study were evaluating the
proposed pedotransfer functions using a larger database, and comparing them
with seven other models. For this purpose, we selected more than nineteen
thousands soil samples from all around the United States. Results showed that
the scale-dependent pedotransfer functions estimated Ksat more accurately than
seven other models frequently used in the literature.
</summary>
    <author>
      <name>Behzad Ghanbarian</name>
    </author>
    <author>
      <name>Vahid Taslimitehrani</name>
    </author>
    <author>
      <name>Yakov A. Pachepsky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.catena.2016.10.015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.catena.2016.10.015" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Catena (2017) Vol. 149 pp. 374-380</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.06958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.06958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09902v2</id>
    <updated>2017-02-24T17:11:18Z</updated>
    <published>2016-10-31T12:57:21Z</published>
    <title>A Quadratic Manifold for Model Order Reduction of Nonlinear Structural
  Dynamics</title>
    <summary>  This paper describes the use of a quadratic manifold for the model order
reduction of structural dynamics problems featuring geometric nonlinearities.
The manifold is tangent to a subspace spanned by the most relevant vibration
modes, and its curvature is provided by modal derivatives obtained by
sensitivity analysis of the eigenvalue problem, or its static approximation,
along the vibration modes. The construction of the quadratic manifold requires
minimal computational effort once the vibration modes are known. The reduced
order model is then obtained by Galerkin projection, where the
configuration-dependent tangent space of the manifold is used to project the
discretized equations of motion.
</summary>
    <author>
      <name>Shobhit Jain</name>
    </author>
    <author>
      <name>Paolo Tiso</name>
    </author>
    <author>
      <name>Daniel J. Rixen</name>
    </author>
    <author>
      <name>Johannes B. Rutzmoser</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2017.04.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2017.04.005" rel="related"/>
    <link href="http://arxiv.org/abs/1610.09902v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09902v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09906v1</id>
    <updated>2016-10-31T13:13:52Z</updated>
    <published>2016-10-31T13:13:52Z</published>
    <title>Generalization of Quadratic Manifolds for Reduced Order Modeling of
  Nonlinear Structural Dynamics</title>
    <summary>  In this paper, a generalization of a quadratic manifold approach for the
reduction of geometrically nonlinear structural dynamics problems is presented.
This generalization is constructed by a linearization of the static force with
respect to the generalized coordinates, resulting in a shift of the quadratic
behavior from the force to the manifold. In this framework, static derivatives
emerge as natural extensions to modal derivatives for displacement fields other
than the vibration modes, such as the Krylov subspace vectors. Here the dynamic
problem is projected onto the tangent space of the quadratic manifold, allowing
for a much less number of generalized coordinates compared to linear basis
methods. The potential of the quadratic manifold approach is investigated in a
numerical study, where several variations of the approach are compared on
different examples, indicating a clear pattern where the proposed approach is
applicable.
</summary>
    <author>
      <name>J. B. Rutzmoser</name>
    </author>
    <author>
      <name>D. J. Rixen</name>
    </author>
    <author>
      <name>P. Tiso</name>
    </author>
    <author>
      <name>S. Jain</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compstruc.2017.06.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compstruc.2017.06.003" rel="related"/>
    <link href="http://arxiv.org/abs/1610.09906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09991v1</id>
    <updated>2016-10-31T16:05:23Z</updated>
    <published>2016-10-31T16:05:23Z</published>
    <title>Parallel adaptive integration in high-performance functional
  Renormalization Group computations</title>
    <summary>  The conceptual framework provided by the functional Renormalization Group
(fRG) has become a formidable tool to study correlated electron systems on
lattices which, in turn, provided great insights to our understanding of
complex many-body phenomena, such as high- temperature superconductivity or
topological states of matter. In this work we present one of the latest
realizations of fRG which makes use of an adaptive numerical quadrature scheme
specifically tailored to the described fRG scheme. The final result is an
increase in performance thanks to improved parallelism and scalability.
</summary>
    <author>
      <name>Julian Lichtenstein</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Jan Winkelmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>David Sánchez de la Peña</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Toni Vidović</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Zagreb</arxiv:affiliation>
    </author>
    <author>
      <name>Edoardo Di Napoli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JARA-HPC</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Forschungszentrum Jülich</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures, accepted for publication in the proceedings of
  the JHPCS'16</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.09991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00616v2</id>
    <updated>2018-03-13T15:49:09Z</updated>
    <published>2016-11-02T14:02:16Z</published>
    <title>Dual Quaternion Variational Integrator for Rigid Body Dynamic Simulation</title>
    <summary>  We introduce a symplectic dual quaternion variational integrator(DQVI) for
simulating single rigid body motion in all six degrees of freedom. Dual
quaternion is used to represent rigid body kinematics and one-step Lie group
variational integrator is used to conserve the geometric structure, energy and
momentum of the system during the simulation. The combination of these two
becomes the first Lie group variational integrator for rigid body simulation
without decoupling translations and rotations. Newton-Raphson method is used to
solve the recursive dynamic equation. This method is suitable for real-time
rigid body simulations with high precision under large time step. DQVI respects
the symplectic structure of the system with excellent long-term conservation of
geometry structure, momentum and energy. It also allows the reference point and
6-by-6 inertia matrix to be arbitrarily defined, which is very convenient for a
variety of engineering problems.
</summary>
    <author>
      <name>Jiafeng Xu</name>
    </author>
    <author>
      <name>Karl Henning Halse</name>
    </author>
    <link href="http://arxiv.org/abs/1611.00616v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00616v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03725v1</id>
    <updated>2016-11-10T07:23:43Z</updated>
    <published>2016-11-10T07:23:43Z</published>
    <title>Practical Interpolation for Spectrum Cartography through Local Path Loss
  Modeling</title>
    <summary>  A fundamental building block for supporting better utilization of radio
spectrum involves predicting the impact that an emitter will have at different
geographic locations. To this end, fixed sensors can be deployed to spatially
sample the RF environment over an area of interest, with interpolation methods
used to infer received power at locations between sensors. This paper describes
a radio map interpolation method that exploits the known properties of most
path loss models, with the aim of minimizing the RMS errors in predicted
dB-power. We show that the results come very close to those for ideal Simple
Kriging. Moreover, the method is simpler in terms of real-time computation by
the network and it requires no knowledge of the spatial correlation of shadow
fading. Our analysis of the method is general, but we exemplify it for a
specific network geometry, comprising a grid-like pattern of sensors. We also
provide comparisons to other widely used interpolation methods.
</summary>
    <author>
      <name>Shweta Sagari</name>
    </author>
    <author>
      <name>Larry Greenstein</name>
    </author>
    <author>
      <name>Wade Trappe</name>
    </author>
    <link href="http://arxiv.org/abs/1611.03725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06271v1</id>
    <updated>2016-11-18T23:02:35Z</updated>
    <published>2016-11-18T23:02:35Z</published>
    <title>A Novel Single-Source Surface Integral Method to Compute Scattering from
  Dielectric Objects</title>
    <summary>  Using the traditional surface integral methods, the computation of scattering
from a dielectric object requires two equivalent current densities on the
boundary of the dielectric. In this paper, we present an approach that requires
only a single current density. Our method is based on a surface admittance
operator and is applicable to dielectric bodies of arbitrary shape. The
formulation results in four times lower memory consumption and up to eight
times lower time to solve the linear system than the traditional PMCHWT
formulation. Numerical results demonstrate that the proposed technique is as
accurate as the PMCHWT formulation.
</summary>
    <author>
      <name>Utkarsh R. Patel</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <author>
      <name>Sean V. Hum</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LAWP.2017.2669183</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LAWP.2017.2669183" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Antennas and Wireless Propagation Letters on
  November 18, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.06271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06396v1</id>
    <updated>2016-11-19T16:17:12Z</updated>
    <published>2016-11-19T16:17:12Z</published>
    <title>Studying the influence of inclusion characteristics on the
  characteristic length involved in quasi-brittle materials using the lattice
  element method</title>
    <summary>  Unlike nonlocal models, there is no need to introduce an internal length in
the constitutive law for lattice model at the mesoscopic scale. Actually, the
internal length is not explicitly introduced but rather governed by the
mesostructure characteristics themselves. The influence of the mesostructure on
the width of the fracture process zone which is assumed to be correlated to the
characteristic length of the homogenized quasi-brittle material is studied. The
influence of the ligament size (a structural parameter) is also investigated.
This analysis provides recommendations/warnings when extracting an internal
length required for nonlocal damage models from the material mesostructure
</summary>
    <author>
      <name>Huu Phuoc Bui</name>
    </author>
    <author>
      <name>Vincent Richefeu</name>
    </author>
    <author>
      <name>Frédéric Dufour</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.06396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06721v2</id>
    <updated>2017-09-23T09:02:33Z</updated>
    <published>2016-11-21T11:04:26Z</published>
    <title>Multiple Right-Hand Side Techniques in Semi-Explicit Time Integration
  Methods for Transient Eddy Current Problems</title>
    <summary>  The spatially discretized magnetic vector potential formulation of
magnetoquasistatic field problems is transformed from an infinitely stiff
differential algebraic equation system into a finitely stiff ordinary
differential equation (ODE) system by application of a generalized Schur
complement for nonconducting parts. The ODE can be integrated in time using
explicit time integration schemes, e.g. the explicit Euler method. This
requires the repeated evaluation of a pseudo-inverse of the discrete curl-curl
matrix in nonconducting material by the preconditioned conjugate gradient (PCG)
method which forms a multiple right-hand side problem. The subspace projection
extrapolation method and proper orthogonal decomposition are compared for the
computation of suitable start vectors in each time step for the PCG method
which reduce the number of iterations and the overall computational costs.
</summary>
    <author>
      <name>Jennifer Dutiné</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2017.2682558</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2017.2682558" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Magn., Volume: 53, Issue: 6, June 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1611.06721v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06721v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L80, 65N30, 78M10, 78A30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06868v1</id>
    <updated>2016-11-17T14:27:39Z</updated>
    <published>2016-11-17T14:27:39Z</published>
    <title>High-Frequency Modeling and Simulation of a Single-Phase Three-Winding
  Transformer Including Taps in Regulating Winding</title>
    <summary>  Transformer terminal equivalents obtained via admittance measurements are
suitable for simulating high-frequency transient interaction between the
transformer and the network. This paper augments the terminal equivalent
approach with a measurement-based voltage transfer function model which permits
calculation of voltages at internal points in the regulating winding. The
approach is demonstrated for a single-phase three-winding transformer in tap
position Nom+ with inclusion of three internal points in the regulating winding
that represent the mid-point and the two extreme ends. The terminal equivalent
modeling makes use of additional common-mode measurements to avoid error
magnifications to result from the ungrounded tertiary winding. The final model
is used in a time domain simulation where ground-fault initiation results in a
resonant voltage build-up in the winding. It is shown that that the peak value
of the resonant overvoltage can be higher than during the lightning impulse
test, with unfavorable network conditions. Additional measurements show that
the selected tap position affects the terminal behavior of the transformer,
changing the frequency and peak value of the lower resonance point in the
voltage transfer between windings.
</summary>
    <author>
      <name>Bjorn Gustavsen</name>
    </author>
    <author>
      <name>Alvaro Portillo</name>
    </author>
    <author>
      <name>Rodrigo Ronchi</name>
    </author>
    <author>
      <name>Asgeir Mjelve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 21 figures, to be submitted to IEEE Transactions on Power
  Delivery</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.06868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.07368v1</id>
    <updated>2016-11-21T13:11:29Z</updated>
    <published>2016-11-21T13:11:29Z</published>
    <title>Discretization of Maxwell's Equations for Non-inertial Observers Using
  Space-Time Algebra</title>
    <summary>  We employ Maxwell's equations formulated in Space-Time Algebra to perform
discretization of moving geometries directly in space-time. All the derivations
are carried out without any non-relativistic assumptions, thus the application
area of the scheme is not restricted to low velocities. The 4D mesh
construction is based on a 3D mesh stemming from a conventional 3D mesh
generator. The movement of the system is encoded in the 4D mesh geometry,
enabling an easy extension of well-known 3D approaches to the space-time
setting. As a research example, we study a manifestation of Sagnac's effect in
a rotating ring resonator. In case of constant rotation, the space-time
approach enhances the efficiency of the scheme, as the material matrices are
constant for every time step, without abandoning the relativistic framework.
</summary>
    <author>
      <name>Mariusz Klimek</name>
    </author>
    <author>
      <name>Stefan Kurz</name>
    </author>
    <author>
      <name>Sebastian Schoeps</name>
    </author>
    <author>
      <name>Thomas Weiland</name>
    </author>
    <link href="http://arxiv.org/abs/1611.07368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.07368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.07403v2</id>
    <updated>2017-09-23T08:55:33Z</updated>
    <published>2016-11-22T16:38:28Z</published>
    <title>Low-Dimensional Stochastic Modeling of the Electrical Properties of
  Biological Tissues</title>
    <summary>  Uncertainty quantification plays an important role in biomedical engineering
as measurement data is often unavailable and literature data shows a wide
variability. Using state-of-the-art methods one encounters difficulties when
the number of random inputs is large. This is the case, e.g., when using
composite Cole-Cole equations to model random electrical properties. It is
shown how the number of parameters can be significantly reduced by the
Karhunen-Loeve expansion. The low-dimensional random model is used to quantify
uncertainties in the axon activation during deep brain stimulation. Numerical
results for a Medtronic 3387 electrode design are given.
</summary>
    <author>
      <name>Ulrich Römer</name>
    </author>
    <author>
      <name>Christian Schmidt</name>
    </author>
    <author>
      <name>Ursula van Rienen</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2017.2668841</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2017.2668841" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Magn, Volume: 53, Issue: 6, June 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1611.07403v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.07403v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H30, 60H35, 78M10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8; I.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.01357v1</id>
    <updated>2016-11-28T13:31:03Z</updated>
    <published>2016-11-28T13:31:03Z</published>
    <title>Geodesic equations and their numerical solutions in geodetic and
  Cartesian coordinates on an oblate spheroid</title>
    <summary>  The direct geodesic problem on an oblate spheroid is described as an initial
value problem and is solved numerically in geodetic and Cartesian coordinates.
The geodesic equations are formulated by means of the theory of differential
geometry. The initial value problem under consideration is reduced to a system
of first-order ordinary differential equations, which is solved using a
numerical method. The solution provides the coordinates and the azimuths at any
point along the geodesic. The Clairaut constant is not assumed known but it is
computed, allowing to check the precision of the method. An extended data set
of geodesics is used, in order to evaluate the performance of the method in
each coordinate system. The results for the direct geodesic problem are
validated by comparison to Karney's method. We conclude that a complete,
stable, precise, accurate and fast solution of the problem in Cartesian
coordinates is accomplished.
</summary>
    <author>
      <name>G. Panou</name>
    </author>
    <author>
      <name>R. Korakitis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to an academic Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.01357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.01357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.01586v1</id>
    <updated>2016-12-05T23:19:53Z</updated>
    <published>2016-12-05T23:19:53Z</published>
    <title>A One-Field Monolithic Fictitious Domain Method for Fluid-Structure
  Interactions</title>
    <summary>  In this article, we present a one-field monolithic fictitious domain (FD)
method for simulation of general fluid-structure interactions (FSI). One-field
means only one velocity field is solved in the whole domain, based upon the use
of an appropriate L2 projection. Monolithic means the fluid and solid equations
are solved synchronously (rather than sequentially). We argue that the proposed
method has the same generality and robustness as FD methods with distributed
Lagrange multiplier (DLM) but is significantly more computationally efficient
(because of one-field) whilst being very straightforward to implement. The
method is described in detail, followed by the presentation of multiple
computational examples in order to validate it across a wide range of fluid and
solid parameters and interactions.
</summary>
    <author>
      <name>Yongxing Wang</name>
    </author>
    <author>
      <name>Peter Jimack</name>
    </author>
    <author>
      <name>Mark Walkley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cma.2017.01.023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cma.2017.01.023" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1608.04998</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.01586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.01586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03247v1</id>
    <updated>2016-12-10T03:39:20Z</updated>
    <published>2016-12-10T03:39:20Z</published>
    <title>Parameter Estimation of a Nonlinear Burgers Model using Nanoindentation
  and Finite Element-based Inverse Analysis</title>
    <summary>  Nanoindentation involves probing a hard diamond tip into a material, where
the load and the displacement experienced by the tip is recorded continuously.
This load-displacement data is a direct function of material's innate
stress-strain behavior. Thus, theoretically it is possible to extract
mechanical properties of a material through nanoindentation. However, due to
various nonlinearities associated with nanoindentation the process of
interpreting load-displacement data into material properties is difficult.
Although, simple elastic behavior can be characterized easily, a method to
characterize complicated material behavior such as nonlinear viscoelasticity is
still lacking. In this study, a nanoindentation-based material characterization
technique is developed to characterize soft materials exhibiting nonlinear
viscoelasticity. Nanoindentation experiment was modeled in finite element
analysis software (ABAQUS), where a nonlinear viscoelastic behavior was
incorporated using user-defined subroutine (UMAT). The model parameters were
calibrated using a process called inverse analysis. In this study, a surrogate
model-based approach was used for the inverse analysis. The different factors
affecting the surrogate model performance are analyzed in order to optimize the
performance with respect to the computational cost.
</summary>
    <author>
      <name>Salah U. Hamim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Dissertation, Oklahoma State University, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.03247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.04451v1</id>
    <updated>2016-12-14T01:32:53Z</updated>
    <published>2016-12-14T01:32:53Z</published>
    <title>Preemptive Termination of Suggestions during Sequential Kriging
  Optimization of a Brain Activity Reconstruction Simulation</title>
    <summary>  Reconstructing brain activity through electroencephalography requires a
boundary value problem (BVP) solver to take a proposed distribution of current
dipoles within the brain and compute the resulting electrostatic potential on
the scalp. This article proposes the use of sequential kriging optimization to
identify different optimal BVP solver parameters for dipoles located in
isolated sections of the brain by considering the cumulative impact of randomly
oriented dipoles within a chosen isolated section. We attempt preemptive
termination of parametrizations suggested during the sequential kriging
optimization which, given the results to that point, seem unlikely to produce
high quality solutions. Numerical experiments on a simplification of the full
geometry for which an approximate solution is available show a benefit from
this preemptive termination.
</summary>
    <author>
      <name>Michael McCourt</name>
    </author>
    <author>
      <name>Ian Dewancker</name>
    </author>
    <author>
      <name>Salvatore Ganci</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages of text, 2 pages of citations, 1 figure, 1 algorithm, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.04451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.04451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N80, 90C26" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09087v2</id>
    <updated>2017-10-24T14:33:41Z</updated>
    <published>2016-12-29T10:02:43Z</published>
    <title>Efficient isogeometric thin shell formulations for soft biological
  materials</title>
    <summary>  This paper presents three different constitutive approaches to model thin
rotation-free shells based on the Kirchhoff-Love hypothesis. One approach is
based on numerical integration through the shell thickness while the other two
approaches do not need any numerical integration and so they are
computationally more efficient. The formulation is designed for large
deformations and allows for geometrical and material nonlinearities, which
makes it very suitable for the modeling of soft tissues. Furthermore, six
different isotropic and anisotropic material models, which are commonly used to
model soft biological materials, are examined for the three proposed
constitutive approaches. Following an isogeometric approach, NURBS-based finite
elements are used for the discretization of the shell surface. Several
numerical examples are investigated to demonstrate the capabilities of the
formulation. Those include the contact simulation during balloon angioplasty.
</summary>
    <author>
      <name>Farshad Roohbakhshan</name>
    </author>
    <author>
      <name>Roger A. Sauer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10237-017-0906-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10237-017-0906-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Typos are removed. Remark 3.4 is added. Eq. (18) in the previous
  version is removed. Thus, the equations get renumbered. Example 5.5 is
  updated. Minor typos in Eqs. (17), (80), (145) and (146), are corrected. They
  do not affect the results</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Biomech Model Mechanobiol (2017) 16:1569</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1612.09087v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09087v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09447v1</id>
    <updated>2016-12-30T10:37:05Z</updated>
    <published>2016-12-30T10:37:05Z</published>
    <title>GPU Accelerated Explicit Time Integration Methods for
  Electro-Quasistatic Fields</title>
    <summary>  Electro-quasistatic field problems involving nonlinear materials are commonly
discretized in space using finite elements. In this paper, it is proposed to
solve the resulting system of ordinary differential equations by an explicit
Runge-Kutta-Chebyshev time-integration scheme. This mitigates the need for
Newton-Raphson iterations, as they are necessary within fully implicit time
integration schemes. However, the electro-quasistatic system of ordinary
differential equations has a Laplace-type mass matrix such that parts of the
explicit time-integration scheme remain implicit. An iterative solver with
constant preconditioner is shown to efficiently solve the resulting multiple
right-hand side problem. This approach allows an efficient parallel
implementation on a system featuring multiple graphic processing units.
</summary>
    <author>
      <name>Christian Richter</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2017.2662234</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2017.2662234" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Magn., Volume: 53, Issue: 6, June 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1612.09447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M60, 78A30, 78M10, 65Y05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00435v1</id>
    <updated>2017-01-02T16:18:05Z</updated>
    <published>2017-01-02T16:18:05Z</published>
    <title>A Computational Approach to Finding RNA Tertiary Motifs in Genomic
  Sequences</title>
    <summary>  Motif finding in DNA, RNA and proteins plays an important role in life
science research. Recent patents concerning motif finding in the biomolecular
data are recorded in the DNA Patent Database which serves as a resource for
policy makers and members of the general public interested in fields like
genomics, genetics and biotechnology. In this paper we present a computational
approach to mining for RNA tertiary motifs in genomic sequences. Specifically
we describe a method, named CSminer, for finding RNA coaxial helical stackings
in genomes. A coaxial helical stacking occurs in an RNA tertiary structure
where two separate helical elements form a pseudocontiguous helix and provides
thermodynamic stability to the molecule as a whole. Experimental results
demonstrate the effectiveness of our approach.
</summary>
    <author>
      <name>Kevin Byron</name>
    </author>
    <author>
      <name>Jason T. L. Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 9 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.00435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00997v1</id>
    <updated>2017-01-04T13:23:04Z</updated>
    <published>2017-01-04T13:23:04Z</published>
    <title>Distributed Co-Simulation of Maritime Systems and Operations</title>
    <summary>  Here, we present the concept of an open virtual prototyping framework for
maritime systems and operations that enables its users to develop re-usable
component or subsystem models, and combine them in full-system simulations for
prototyping, verification, training, and performance studies. This framework
consists of a set of guidelines for model coupling, high-level and low-level
coupling interfaces to guarantee interoperability, a full-system simulation
software, and example models and demonstrators. We discuss the requirements for
such a framework, address the challenges and the possibilities in fulfilling
them, and aim to give a list of best practices for modular and efficient
virtual prototyping and full-system simulation. The context of our work is
within maritime systems and operations, but the issues and solutions we present
here are general enough to be of interest to a much broader audience, both
industrial and scientific.
</summary>
    <author>
      <name>Severin Sadjina</name>
    </author>
    <author>
      <name>Lars T. Kyllingstad</name>
    </author>
    <author>
      <name>Martin Rindarøy</name>
    </author>
    <author>
      <name>Stian Skjong</name>
    </author>
    <author>
      <name>Vilmar Æsøy</name>
    </author>
    <author>
      <name>Dariusz Eirik Fathi</name>
    </author>
    <author>
      <name>Vahid Hassani</name>
    </author>
    <author>
      <name>Trond Johnsen</name>
    </author>
    <author>
      <name>Jørgen Bremnes Nielsen</name>
    </author>
    <author>
      <name>Eilif Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.00997v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00997v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01430v2</id>
    <updated>2017-05-14T03:59:01Z</updated>
    <published>2017-01-05T03:14:07Z</published>
    <title>A High-Resolution Finite Volume Seismic Model to Generate Seafloor
  Deformation for Tsunami Modeling</title>
    <summary>  A high-resolution finite volume method approach to incorporating
time-dependent slip across rectangular subfaults when modeling general fault
geometry is presented. The fault slip is induced by a modification of the
Riemann problem to the linear elasticity equations across cell interfaces
aligned with the subfaults. This is illustrated in the context of the
high-resolution wave-propagation algorithms that are implemented in the open
source Clawpack software (www.clawpack.org), but this approach could be easily
incorporated into other Riemann solver based numerical methods. Surface
deformation results are obtained in both two and three dimensions and compared
to those given by the steady-state, homogeneous half-space Okada solution.
</summary>
    <author>
      <name>Christopher J. Vogl</name>
    </author>
    <author>
      <name>Randall J. LeVeque</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10915-017-0459-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10915-017-0459-y" rel="related"/>
    <link href="http://arxiv.org/abs/1701.01430v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01430v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.03009v1</id>
    <updated>2017-01-11T15:23:21Z</updated>
    <published>2017-01-11T15:23:21Z</published>
    <title>Explicit Time Integration of Transient Eddy Current Problems</title>
    <summary>  For time integration of transient eddy current problems commonly implicit
time integration methods are used, where in every time step one or several
nonlinear systems of equations have to be linearized with the Newton-Raphson
method due to ferromagnetic materials involved. In this paper, a generalized
Schur-complement is applied to the magnetic vector potential formulation, which
converts a differential-algebraic equation system of index 1 into a system of
ordinary differential equations (ODE) with reduced stiffness. For the time
integration of this ODE system of equations, the explicit Euler method is
applied. The Courant-Friedrich-Levy (CFL) stability criterion of explicit time
integration methods may result in small time steps. Applying a pseudo-inverse
of the discrete curl-curl operator in nonconducting regions of the problem is
required in every time step. For the computation of the pseudo-inverse, the
preconditioned conjugate gradient (PCG) method is used. The cascaded Subspace
Extrapolation method (CSPE) is presented to produce suitable start vectors for
these PCG iterations. The resulting scheme is validated using the TEAM 10
benchmark problem.
</summary>
    <author>
      <name>Jennifer Dutiné</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Georg Wimmer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/jnm.2227</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/jnm.2227" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Numer. Model., 2017, e2227</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.03009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.03009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.03978v1</id>
    <updated>2017-01-15T01:12:11Z</updated>
    <published>2017-01-15T01:12:11Z</published>
    <title>Computer-aided molecular design: An introduction and review of tools,
  applications, and solution techniques</title>
    <summary>  This article provides an introduction to and review of the field of
computer-aided molecular design (CAMD). It is intended to be approachable for
the absolute beginner as well as useful to the seasoned CAMD practitioner. We
begin by discussing various quantitative structure-property relationships
(QSPRs) which have been demonstrated to work well with CAMD problems. The
methods discussed in this article are (1) group contribution methods, (2)
topological indices, and (3) signature descriptors. Next, we present general
optimization formulations for various forms of the CAMD problem. Common design
constraints are discussed and structural feasibility constraints are provided
for the three types of QSPRs addressed. We then detail useful techniques for
approaching CAMD optimization problems, including decomposition methods,
heuristic approaches, and mathematical programming strategies. Finally, we
discuss many applications that have been addressed using CAMD.
</summary>
    <author>
      <name>Nick D. Austin</name>
    </author>
    <author>
      <name>Nikolaos V. Sahinidis</name>
    </author>
    <author>
      <name>Daniel W. Trahan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cherd.2016.10.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cherd.2016.10.014" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 13 figures, 3 tables, 173 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chemical Engineering Research and Design, 116, 2-26, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.03978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.03978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06182v1</id>
    <updated>2017-01-22T16:23:38Z</updated>
    <published>2017-01-22T16:23:38Z</published>
    <title>Pseudospectral methods for density functional theory in bounded and
  unbounded domains</title>
    <summary>  Classical Density Functional Theory (DFT) is a statistical-mechanical
framework to analyze fluids, which accounts for nanoscale fluid inhomogeneities
and non-local intermolecular interactions. DFT can be applied to a wide range
of interfacial phenomena, as well as problems in adsorption, colloidal science
and phase transitions in fluids. Typical DFT equations are highly non-linear,
stiff and contain several convolution terms. We propose a novel, efficient
pseudo-spectral collocation scheme for computing the non-local terms in real
space with the help of a specialized Gauss quadrature. Due to the exponential
accuracy of the quadrature and a convenient choice of collocation points near
interfaces, we can use grids with a significantly lower number of nodes than
most other reported methods. We demonstrate the capabilities of our numerical
methodology by studying equilibrium and dynamic two-dimensional test cases with
single- and multispecies hard-sphere and hard-disc particles modelled with
fundamental measure theory, with and without van der Waals attractive forces,
in bounded and unbounded physical domains. We show that our results satisfy
statistical mechanical sum rules.
</summary>
    <author>
      <name>Andreas Nold</name>
    </author>
    <author>
      <name>Benjamin D. Goddard</name>
    </author>
    <author>
      <name>Peter Yatsyshin</name>
    </author>
    <author>
      <name>Nikos Savva</name>
    </author>
    <author>
      <name>Serafim Kalliadasis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2016.12.023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2016.12.023" rel="related"/>
    <link href="http://arxiv.org/abs/1701.06182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06254v1</id>
    <updated>2017-01-23T02:35:21Z</updated>
    <published>2017-01-23T02:35:21Z</published>
    <title>A Parallel Simulator for Massive Reservoir Models Utilizing
  Distributed-Memory Parallel Systems</title>
    <summary>  This paper presents our work on developing parallel computational methods for
two-phase flow on modern parallel computers, where techniques for linear
solvers and nonlinear methods are studied and the standard and inexact Newton
methods are investigated. A multi-stage preconditioner for two-phase flow is
applied and advanced matrix processing strategies are studied. A local
reordering method is developed to speed the solution of linear systems.
Numerical experiments show that these computational methods are effective and
scalable, and are capable of computing large-scale reservoir simulation
problems using thousands of CPU cores on parallel computers. The nonlinear
techniques, preconditioner and matrix processing strategies can also be applied
to three-phase black oil, compositional and thermal models.
</summary>
    <author>
      <name>Hui Liu</name>
    </author>
    <author>
      <name>Lihua Shen</name>
    </author>
    <author>
      <name>Yan Chen</name>
    </author>
    <author>
      <name>Kun Wang</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <author>
      <name>Zhangxin Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1606.00556</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06432v2</id>
    <updated>2019-07-06T11:00:56Z</updated>
    <published>2017-01-14T08:39:00Z</published>
    <title>On profile reconstruction of Euler-Bernoulli beams by means of an energy
  based genetic algorithm</title>
    <summary>  This paper studies the inverse problem related to the identification of the
flexural stiffness of an Euler Bernoulli beam in order to reconstruct its
profile starting from available response data. The proposed identification
procedure makes use of energy measurements and is based on the application of a
closed form solution for the static displacements of multi-stepped beams. This
solution allows to easily calculate the energy related to beams modeled with
arbitrary multi-step shapes subjected to a transversal roving force, and to
compare it with the correspondent data obtained through direct measurements on
real beams. The optimal solution which minimizes the difference between
measured and calculated data is then sought by means of genetic algorithms. In
the paper several different stepped beams are investigated showing that the
proposed procedure allows in many cases to identify the exact beam profile.
However it is shown that in some other cases different multi-step profiles may
correspond to very similar static responses, and therefore to comparable minima
in the optimization problem, thus complicating the profile identification
problem.
</summary>
    <author>
      <name>A. Greco</name>
    </author>
    <author>
      <name>A. Pluchino</name>
    </author>
    <author>
      <name>S. Caddemi</name>
    </author>
    <author>
      <name>I. Caliò</name>
    </author>
    <author>
      <name>F. Cannizzaro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 7 figures, 6 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Engineering with Computers 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.06432v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06432v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08742v3</id>
    <updated>2017-09-18T15:58:09Z</updated>
    <published>2017-01-30T18:29:18Z</published>
    <title>Adaptive local surface refinement based on LR NURBS and its application
  to contact</title>
    <summary>  A novel adaptive local surface refinement technique based on Locally Refined
Non-Uniform Rational B-Splines (LR NURBS) is presented. LR NURBS can model
complex geometries exactly and are the rational extension of LR B-splines. The
local representation of the parameter space overcomes the drawback of
non-existent local refinement in standard NURBS-based isogeometric analysis.
For a convenient embedding into general finite element code, the B\'ezier
extraction operator for LR NURBS is formulated. An automatic remeshing
technique is presented that allows adaptive local refinement and coarsening of
LR NURBS. In this work, LR NURBS are applied to contact computations of 3D
solids and membranes. For solids, LR NURBS-enriched finite elements are used to
discretize the contact surfaces with LR NURBS finite elements, while the rest
of the body is discretized by linear Lagrange finite elements. For membranes,
the entire surface is discretized by LR NURBS. Various numerical examples are
shown, and they demonstrate the benefit of using LR NURBS: Compared to uniform
refinement, LR NURBS can achieve high accuracy at lower computational cost.
</summary>
    <author>
      <name>Christopher Zimmermann</name>
    </author>
    <author>
      <name>Roger A. Sauer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-017-1455-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-017-1455-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Mechanics (2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.08742v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08742v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.09079v1</id>
    <updated>2017-01-28T19:51:35Z</updated>
    <published>2017-01-28T19:51:35Z</published>
    <title>A one-dimensional model for water desalination by flow-through electrode
  capacitive deionization</title>
    <summary>  Capacitive deionization (CDI) is a fast-emerging water desalination
technology in which a small cell voltage of ~1 V across porous carbon
electrodes removes salt from feedwaters via electrosorption. In flow-through
electrode (FTE) CDI cell architecture, feedwater is pumped through macropores
or laser perforated channels in porous electrodes, enabling highly compact
cells with parallel flow and electric field, as well as rapid salt removal. We
here present a one-dimensional model describing water desalination by FTE CDI,
and a comparison to data from a custom-built experimental cell. The model
employs simple cell boundary conditions derived via scaling arguments. We show
good model-to-data fits with reasonable values for fitting parameters such as
the Stern layer capacitance, micropore volume, and attraction energy. Thus, we
demonstrate that from an engineering modeling perspective, an FTE CDI cell may
be described with simpler one-dimensional models, unlike more typical
flow-between electrodes architecture where 2D models are required.
</summary>
    <author>
      <name>Eric N. Guyes</name>
    </author>
    <author>
      <name>Amit N. Shocron</name>
    </author>
    <author>
      <name>Anastasia Simanovski</name>
    </author>
    <author>
      <name>P. M. Biesheuvel</name>
    </author>
    <author>
      <name>Matthew E. Suss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 4 figures. Engineering model</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.09079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.09079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.09131v1</id>
    <updated>2017-01-31T17:06:29Z</updated>
    <published>2017-01-31T17:06:29Z</published>
    <title>On the choice of homogenization method to achieve effective mechanical
  properties of composites reinforced by ellipsoidal and spherical particles</title>
    <summary>  In this paper, several rigorous numerical simulations were conducted to
examine the relevance of mean-field micromechanical models compared to the Fast
Fourier Transform full-field computation by considering spherical or
ellipsoidal inclusions. To be more general, the numerical study was extended to
a mixture of different kind of microstructures consisting of spheroidal shapes
within the same RVE. Although the Fast Fourier Transform full field calculation
is sensitive to high contrasts, calculation time, for a combination of complex
microstructures, remains reasonable compared with those obtained with
mean-field micromechanical models. Moreover, for low volume fractions of
inclusions, the results of the mean-field approximations and those of the Fast
Fourier Transform-based (FFTb) full-field computation are very close, whatever
the inclusions morphology is. For RVEs consisting of ellipsoidal or a mixture
of ellipsoidal and spherical inclusions, when the inclusions volume fraction
becomes higher, one observes that Lielens' model and the FFTb full-field
computation give similar estimates. The accuracy of the computational methods
depends on the shape of the inclusions' and their volume fraction.
</summary>
    <author>
      <name>Viwanou Hounkpati</name>
    </author>
    <author>
      <name>Vladimir Salnikov</name>
    </author>
    <author>
      <name>Alexandre Vivet</name>
    </author>
    <author>
      <name>Philippe Karamian-Surville</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.09131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.09131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.00695v1</id>
    <updated>2017-01-31T21:59:47Z</updated>
    <published>2017-01-31T21:59:47Z</published>
    <title>Adaptive Multiscale Homogenization of the Lattice Discrete Particle
  Model for the Analysis of Damage and Fracture in Concrete</title>
    <summary>  This paper presents a new adaptive multiscale homogenization scheme for the
simulation of damage and fracture in concrete structures. A two-scale
homogenization method, coupling meso-scale discrete particle models to macro-
scale finite element models, is formulated into an adaptive framework. A
continuum multiaxial failure criterion for concrete is calibrated on the basis
of fine-scale simulations, and it serves as the adaptive criterion in the
multiscale framework. Thus, in this approach, simulations start without
assigning any material Representative Volume Element (RVE) to the macro-scale
finite elements. The finite elements that meet the adaptive criterion and must
be entered into the multiscale homogenization framework are detected on the
fly. This leads to a substantial reduction of the computational cost especially
for loading conditions leading to damage localization in which only a small
portion of the FE mesh is enriched with the homogenized RVE. Several numerical
simulations are carried out to investigate the capability of the developed
adaptive homogenization method. In addition, a detailed study on the
computational cost is performed.
</summary>
    <author>
      <name>Roozbeh Rezakhani</name>
    </author>
    <author>
      <name>Xinwei Zhou</name>
    </author>
    <author>
      <name>Gianluca Cusatis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1509.05440</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.00695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.00695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01464v2</id>
    <updated>2017-06-20T18:41:14Z</updated>
    <published>2017-02-05T23:01:24Z</published>
    <title>Online Voltage Stability Assessment for Load Areas Based on the
  Holomorphic Embedding Method</title>
    <summary>  This paper proposes an online steady-state voltage stability assessment
scheme to evaluate the proximity to voltage collapse at each bus of a load
area. Using a non-iterative holomorphic embedding method (HEM) with a proposed
physical germ solution, an accurate loading limit at each load bus can be
calculated based on online state estimation on the entire load area and a
measurement-based equivalent for the external system. The HEM employs a power
series to calculate an accurate Power-Voltage (P-V) curve at each load bus and
accordingly evaluates the voltage stability margin considering load variations
in the next period. An adaptive two-stage Pade approximants method is proposed
to improve the convergence of the power series for accurate determination of
the nose point on the P-V curve with moderate computational burden. The
proposed method is illustrated in detail on a 4-bus test system and then
demonstrated on a load area of the Northeast Power Coordinating Council (NPCC)
48-geneartor, 140-bus power system.
</summary>
    <author>
      <name>Chengxi Liu</name>
    </author>
    <author>
      <name>Bin Wang</name>
    </author>
    <author>
      <name>Fengkai Hu</name>
    </author>
    <author>
      <name>Kai Sun</name>
    </author>
    <author>
      <name>Claus Leth Bak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised and Submitted to IEEE Transaction on Power Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01464v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01464v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02046v1</id>
    <updated>2017-02-06T06:58:22Z</updated>
    <published>2017-02-06T06:58:22Z</published>
    <title>TensorBeat: Tensor Decomposition for Monitoring Multi-Person Breathing
  Beats with Commodity WiFi</title>
    <summary>  Breathing signal monitoring can provide important clues for human's physical
health problems. Comparing to existing techniques that require wearable devices
and special equipment, a more desirable approach is to provide contact-free and
long-term breathing rate monitoring by exploiting wireless signals. In this
paper, we propose TensorBeat, a system to employ channel state information
(CSI) phase difference data to intelligently estimate breathing rates for
multiple persons with commodity WiFi devices. The main idea is to leverage the
tensor decomposition technique to handle the CSI phase difference data. The
proposed TensorBeat scheme first obtains CSI phase difference data between
pairs of antennas at the WiFi receiver to create CSI tensor data. Then
Canonical Polyadic (CP) decomposition is applied to obtain the desired
breathing signals. A stable signal matching algorithm is developed to find the
decomposed signal pairs, and a peak detection method is applied to estimate the
breathing rates for multiple persons. Our experimental study shows that
TensorBeat can achieve high accuracy under different environments for
multi-person breathing rate monitoring.
</summary>
    <author>
      <name>Xuyu Wang</name>
    </author>
    <author>
      <name>Chao Yang</name>
    </author>
    <author>
      <name>Shiwen Mao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Intelligent Systems and Technology,2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.02046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04250v1</id>
    <updated>2017-02-14T15:03:05Z</updated>
    <published>2017-02-14T15:03:05Z</published>
    <title>LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi</title>
    <summary>  Molecular Dynamics is an important tool for computational biologists,
chemists, and materials scientists, consuming a sizable amount of
supercomputing resources. Many of the investigated systems contain charged
particles, which can only be simulated accurately using a long-range solver,
such as PPPM. We extend the popular LAMMPS molecular dynamics code with an
implementation of PPPM particularly suitable for the second generation Intel
Xeon Phi. Our main target is the optimization of computational kernels by means
of vectorization, and we observe speedups in these kernels of up to 12x. These
improvements carry over to LAMMPS users, with overall speedups ranging between
2-3x, without requiring users to retune input parameters. Furthermore, our
optimizations make it easier for users to determine optimal input parameters
for attaining top performance.
</summary>
    <author>
      <name>William McDoniel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Markus Höhnerbach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Rodrigo Canales</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Ahmed E. Ismail</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">West Virginia University</arxiv:affiliation>
    </author>
    <author>
      <name>Paolo Bientinesi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">West Virginia University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures, submitted to ISC High Performance 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.04250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04910v1</id>
    <updated>2017-02-16T10:14:24Z</updated>
    <published>2017-02-16T10:14:24Z</published>
    <title>A comparative study of fluid-particle coupling methods for fully
  resolved lattice Boltzmann simulations</title>
    <summary>  The direct numerical simulation of particulate systems offers a unique
approach to study the dynamics of fluid-solid suspensions by fully resolving
the submerged particles and without introducing empirical models. For the
lattice Boltzmann method, different variants exist to incorporate the
fluid-particle interaction into the simulation. This paper provides a detailed
and systematic comparison of two different methods, namely the momentum
exchange method and the partially saturated cells method by Noble and
Torczynski. Three subvariants of each method are used in the benchmark scenario
of a single heavy sphere settling in ambient fluid to study their
characteristics and accuracy for particle Reynolds numbers from 185 up to 365.
The sphere must be resolved with at least 24 computational cells per diameter
to achieve velocity errors below 5%. The momentum exchange method is found to
be more accurate in predicting the streamwise velocity component whereas the
partially saturated cells method is more accurate in the spanwise components.
The study reveals that the resolution should be chosen with respect to the
coupling dynamics, and not only based on the flow properties, to avoid large
errors in the fluid-particle interaction.
</summary>
    <author>
      <name>Christoph Rettinger</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.compfluid.2017.05.033</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.compfluid.2017.05.033" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 13 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.04910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06074v1</id>
    <updated>2017-02-20T17:28:12Z</updated>
    <published>2017-02-20T17:28:12Z</published>
    <title>Heterogeneity Preserving Upscaling for Heat Transport in Fractured
  Geothermal Reservoirs</title>
    <summary>  In simulation of fluid injection in fractured geothermal reservoirs, the
characteristics of the physical processes are severely affected by the local
occurence of connected fractures. To resolve these structurally dominated
processes, there is a need to develop discretization strategies that also limit
computational effort. In this paper we present an upscaling methodology for
geothermal heat transport with fractures represented explicitly in the
computational grid. The heat transport is modeled by an advection-conduction
equation for the temperature, and solved on a highly irregular coarse grid that
preserves the fracture heterogeneity. The upscaling is based on different
strategies for the advective term and the conductive term, respectively. The
coarse scale advective term is constructed from sums of fine scale fluxes,
whereas the coarse scale conductive term is constructed based on numerically
computed basis functions. The method naturally incorporates a coupling between
the matrix and the fractures via the discretization, so that explicit transfer
terms that couple solution variables in the fractures and the matrix are
avoided. Numerical results show that the upscaling methodology performs well,
in particular for large upscaling ratios, and that it is applicable also to
highly complex fracture networks.
</summary>
    <author>
      <name>Anna Nissen</name>
    </author>
    <author>
      <name>Eirik Keilegavlen</name>
    </author>
    <author>
      <name>Tor Harald Sandve</name>
    </author>
    <author>
      <name>Inga Berre</name>
    </author>
    <author>
      <name>Jan Martin Nordbotten</name>
    </author>
    <link href="http://arxiv.org/abs/1702.06074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07320v1</id>
    <updated>2017-02-21T15:09:00Z</updated>
    <published>2017-02-21T15:09:00Z</published>
    <title>Simulation of detecting contact nonlinearity in carbon fibre polymer
  using ultrasonic nonlinear delayed time reversal</title>
    <summary>  A finite element method simulation of a carbon fibre reinforced polymer block
is used to analyse the nonlinearities arising from a contacting delamination
gap inside the material. The ultrasonic signal is amplified and nonlinearities
are analysed by delayed Time Reversal -- Nonlinear Elastic Wave Spectroscopy
signal processing method. This signal processing method allows to focus the
wave energy onto the receiving transducer and to modify the focused wave shape,
allowing to use several different methods, including pulse inversion, for
detecting the nonlinear signature of the damage. It is found that the small
crack with contacting acoustic nonlinearity produces a noticeable nonlinear
signature when using pulse inversion signal processing, and even higher
signature with delayed time reversal, without requiring any baseline
information from an undamaged medium.
</summary>
    <author>
      <name>Martin Lints</name>
    </author>
    <author>
      <name>Andrus Salupere</name>
    </author>
    <author>
      <name>Serge Dos Santos</name>
    </author>
    <link href="http://arxiv.org/abs/1702.07320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07779v1</id>
    <updated>2017-02-24T21:57:02Z</updated>
    <published>2017-02-24T21:57:02Z</published>
    <title>A Stochastic Operator Approach to Model Inadequacy with Applications to
  Contaminant Transport</title>
    <summary>  The mathematical models used to represent physical phenomena are generally
known to be imperfect representations of reality. Model inadequacies arise for
numerous reasons, such as incomplete knowledge of the phenomena or
computational intractability of more accurate models. In such situations it is
impractical or impossible to improve the model, but necessity requires its use
to make predictions. With this in mind, it is important to represent the
uncertainty that a model's inadequacy causes in its predictions, as neglecting
to do so can cause overconfidence in its accuracy. A powerful approach to
addressing model inadequacy leverages the composite nature of physical models
by enriching a flawed embedded closure model with a stochastic error
representation. This work outlines steps in the development of a stochastic
operator as an inadequacy representation by establishing the framework for
inferring an infinite-dimensional operator and by introducing a novel method
for interrogating available high-fidelity models to learn about modeling error.
</summary>
    <author>
      <name>Teresa Portone</name>
    </author>
    <author>
      <name>Damon McDougall</name>
    </author>
    <author>
      <name>Robert D. Moser</name>
    </author>
    <link href="http://arxiv.org/abs/1702.07779v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07779v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08880v2</id>
    <updated>2017-03-01T04:15:28Z</updated>
    <published>2017-02-27T15:06:53Z</published>
    <title>Landau Collision Integral Solver with Adaptive Mesh Refinement on
  Emerging Architectures</title>
    <summary>  The Landau collision integral is an accurate model for the small-angle
dominated Coulomb collisions in fusion plasmas. We investigate a high order
accurate, fully conservative, finite element discretization of the nonlinear
multi-species Landau integral with adaptive mesh refinement using the PETSc
library (www.mcs.anl.gov/petsc). We develop algorithms and techniques to
efficiently utilize emerging architectures with an approach that minimizes
memory usage and movement and is suitable for vector processing. The Landau
collision integral is vectorized with Intel AVX-512 intrinsics and the solver
sustains as much as 22% of the theoretical peak flop rate of the Second
Generation Intel Xeon Phi, Knights Landing, processor.
</summary>
    <author>
      <name>M. F. Adams</name>
    </author>
    <author>
      <name>E. Hirvijoki</name>
    </author>
    <author>
      <name>M. G. Knepley</name>
    </author>
    <author>
      <name>J. Brown</name>
    </author>
    <author>
      <name>T. Isaac</name>
    </author>
    <author>
      <name>R. Mills</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/17M1118828</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/17M1118828" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal on Scientific Computing, 39 (6), 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.08880v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08880v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00446v2</id>
    <updated>2017-05-08T16:56:04Z</updated>
    <published>2017-03-01T17:00:42Z</published>
    <title>A tool for ECG signal analysis using standard and optimized Hermite
  transform</title>
    <summary>  The development of a system that would ease the diagnosis of heart diseases
would also fasten the work of the cardiologic department in hospitals and
facilitate the monitoring of patients with portable devices. This paper
presents a tool for ECG signal analysis which is designed in Matlab. The
Hermite transform domain is exploited for the analysis. The proposed transform
domain is very convenient for ECG signal analysis and classification. Parts of
the ECG signals, i.e. QRS complexes, show shape similarity with the Hermite
basis functions, which is one of the reasons for choosing this domain. Also,
the information about the signal can be represented using a small set of
coefficients in this domain, which makes data transmission and analysis faster.
The signal concentration in the Hermite domain and consequently, the number of
samples required for signal representation, can additionally be reduced by
performing the parametization of the Hermite transform. For the comparison
purpose, the Fourier transform domain is also implemented within the software,
in order to compare the signal concentration in two transform domains.
</summary>
    <author>
      <name>Zoja Vulaj</name>
    </author>
    <author>
      <name>Andjela Draganic</name>
    </author>
    <author>
      <name>Milos Brajovic</name>
    </author>
    <author>
      <name>Irena Orovic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted for presentation at the MECO 2017 conference (6th
  Mediterranean Conference on Embedded Computing MECO 2017, Bar, Montenegro)</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.00446v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00446v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01202v1</id>
    <updated>2017-03-03T15:27:32Z</updated>
    <published>2017-03-03T15:27:32Z</published>
    <title>Parallel energy-stable phase field crystal simulations based on domain
  decomposition methods</title>
    <summary>  In this paper, we present a parallel numerical algorithm for solving the
phase field crystal equation. In the algorithm, a semi-implicit finite
difference scheme is derived based on the discrete variational derivative
method. Theoretical analysis is provided to show that the scheme is
unconditionally energy stable and can achieve second-order accuracy in both
space and time. An adaptive time step strategy is adopted such that the time
step size can be flexibly controlled based on the dynamical evolution of the
problem. At each time step, a nonlinear algebraic system is constructed from
the discretization of the phase field crystal equation and solved by a domain
decomposition based, parallel Newton--Krylov--Schwarz method with improved
boundary conditions for subdomain problems. Numerical experiments with several
two and three dimensional test cases show that the proposed algorithm is
second-order accurate in both space and time, energy stable with large time
steps, and highly scalable to over ten thousands processor cores on the Sunway
TaihuLight supercomputer.
</summary>
    <author>
      <name>Ying Wei</name>
    </author>
    <author>
      <name>Chao Yang</name>
    </author>
    <author>
      <name>Jizu Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05522v1</id>
    <updated>2017-03-16T09:16:32Z</updated>
    <published>2017-03-16T09:16:32Z</published>
    <title>Treating Smoothness and Balance during Data Exchange in Explicit
  Simulator Coupling or Cosimulation</title>
    <summary>  Cosimulation methods allow combination of simulation tools of physical
systems running in parallel to act as a single simulation environment for a big
system. As data is passed across subsystem boundaries instead of solving the
system as one single equation system, it is not ensured that systemwide
balances are fulfilled. If the exchanged data is a flow of a conserved
quantity, approximation errors can accumulate and make simulation results
inaccurate. The problem of approximation errors is typically addressed with
extrapolation of exchanged data. Nevertheless balance errors occur as
extrapolation is approximation. This problem can be handled with balance
correction methods which compensate these errors by adding corrections for the
balances to the signal in next coupling time step. This work aims at combining
extrapolation of exchanged data and balance correction in a way that the
exchanged signal not only remains smooth, meaning the existence of continuous
derivatives, but even in a way reducing the derivatives, in order to avoid
unphysical dynamics caused by the coupling. To this end, suitable switch and
hat functions are constructed and applied to the problem.
</summary>
    <author>
      <name>Dirk Scharff</name>
    </author>
    <author>
      <name>Thilo Moshagen</name>
    </author>
    <author>
      <name>Jaroslav Vondřejc</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages. This paper has been submitted as research paper and is
  currently under review</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.0; G.1.8; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07218v1</id>
    <updated>2017-03-20T01:47:28Z</updated>
    <published>2017-03-20T01:47:28Z</published>
    <title>DG-Embedded Radial Distribution System Planning Using Binary-Selective
  PSO</title>
    <summary>  With the increasing rate of power consumption, many new distribution systems
need to be constructed to accommodate connecting the new consumers to the power
grid. On the other hand, the increasing penetration of renewable distributed
generation (DG) resources into the distribution systems and the necessity of
optimally place them in the network can dramatically change the problem of
distribution system planning and design. In this paper, the problem of optimal
distribution system planning including conductor sizing, DG placement,
alongside with placement and sizing of shunt capacitors is studied. A new
Binary-Selective Particle Swarm Optimization (PSO) approach which is capable of
handling all types of continuous, binary and selective variables,
simultaneously, is proposed to solve the optimization problem of distribution
system planning. The objective of the problem is to minimize the system costs.
Load growth rate, cost of energy, cost of power, and inflation rate are all
taken into account. The efficacy of the proposed method is tested on a 26-bus
distribution system.
</summary>
    <author>
      <name>Ahvand Jalali</name>
    </author>
    <author>
      <name>S K. Mohammadi</name>
    </author>
    <author>
      <name>H. Sangrody</name>
    </author>
    <author>
      <name>A. Rahim-Zadegan</name>
    </author>
    <link href="http://arxiv.org/abs/1703.07218v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07218v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07231v1</id>
    <updated>2017-03-19T03:18:13Z</updated>
    <published>2017-03-19T03:18:13Z</published>
    <title>Control and Limit Enforcements for VSC Multi-Terminal HVDC in Newton
  Power Flow</title>
    <summary>  This paper proposes a novel method to automatically enforce controls and
limits for Voltage Source Converter (VSC) based multi-terminal HVDC in the
Newton power flow iteration process. A general VSC MT-HVDC model with primary
PQ or PV control and secondary voltage control is formulated. Both the
dependent and independent variables are included in the propose formulation so
that the algebraic variables of the VSC MT-HVDC are adjusted simultaneously.
The proposed method also maintains the number of equations and the dimension of
the Jacobian matrix unchanged so that, when a limit is reached and a control is
released, the Jacobian needs no re-factorization. Simulations on the IEEE
14-bus and Polish 9241-bus systems are performed to demonstrate the
effectiveness of the method.
</summary>
    <author>
      <name>Hantao Cui</name>
    </author>
    <author>
      <name>Fangxing Li</name>
    </author>
    <author>
      <name>Haoyu Yuan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/PESGM.2017.8274242</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/PESGM.2017.8274242" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE PES General Meeting 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.07231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07770v3</id>
    <updated>2017-09-26T13:10:24Z</updated>
    <published>2017-03-22T17:52:53Z</published>
    <title>A Probabilistic Design Method for Fatigue Life of Metallic Component</title>
    <summary>  In the present study, a general probabilistic design framework is developed
for cyclic fatigue life prediction of metallic hardware using methods that
address uncertainty in experimental data and computational model. The
methodology involves (i) fatigue test data conducted on coupons of Ti6Al4V
material (ii) continuum damage mechanics based material constitutive models to
simulate cyclic fatigue behavior of material (iii) variance-based global
sensitivity analysis (iv) Bayesian framework for model calibration and
uncertainty quantification and (v) computational life prediction and
probabilistic design decision making under uncertainty. The outcomes of
computational analyses using the experimental data prove the feasibility of the
probabilistic design methods for model calibration in presence of incomplete
and noisy data. Moreover, using probabilistic design methods result in
assessment of reliability of fatigue life predicted by computational models.
</summary>
    <author>
      <name>Danial Faghihi</name>
    </author>
    <author>
      <name>Subhasis Sarkar</name>
    </author>
    <author>
      <name>Mehdi Naderi</name>
    </author>
    <author>
      <name>Lloyd Hackel</name>
    </author>
    <author>
      <name>Nagaraja Iyyer</name>
    </author>
    <link href="http://arxiv.org/abs/1703.07770v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07770v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.08835v1</id>
    <updated>2017-03-26T16:14:34Z</updated>
    <published>2017-03-26T16:14:34Z</published>
    <title>A new dominance concept and its application to diversity-stability
  analysis</title>
    <summary>  We introduce a new dominance concept consisting of three new dominance
metrics based on Lloyd's (1967) mean crowding index. The new metrics link
communities and species, whereas existing ones are applicable only to
communities. Our community-level metric is a function of Simpson's diversity
index. For species, our metric quantifies the difference between community
dominance and the dominance of a virtual community whose mean population size
(per species) equals the population size of the focal species. The new metrics
have at least two immediate applications: (i) acting as proxies for diversity
in diversity-stability modeling (ii) replacing population abundance in
reconstructing species dominance networks. The first application is
demonstrated here using data from a longitudinal study of the human vaginal
microbiome, and provides new insights relevant for microbial community
stability and disease etiology.
</summary>
    <author>
      <name>Zhanshan Ma</name>
    </author>
    <author>
      <name>Aaron M. Ellison</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/ecm.1358</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/ecm.1358" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For all correspondence to Zhanshan Sam Ma (ma@vandals.uidaho.edu)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ecological Monographs 69, e01358 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.08835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.08835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.00568v1</id>
    <updated>2017-04-03T13:19:49Z</updated>
    <published>2017-04-03T13:19:49Z</published>
    <title>A parametric level-set method for partially discrete tomography</title>
    <summary>  This paper introduces a parametric level-set method for tomographic
reconstruction of partially discrete images. Such images consist of a
continuously varying background and an anomaly with a constant (known)
grey-value. We represent the geometry of the anomaly using a level-set
function, which we represent using radial basis functions. We pose the
reconstruction problem as a bi-level optimization problem in terms of the
background and coefficients for the level-set function. To constrain the
background reconstruction we impose smoothness through Tikhonov regularization.
The bi-level optimization problem is solved in an alternating fashion; in each
iteration we first reconstruct the background and consequently update the
level-set function. We test our method on numerical phantoms and show that we
can successfully reconstruct the geometry of the anomaly, even from limited
data. On these phantoms, our method outperforms Total Variation reconstruction,
DART and P-DART.
</summary>
    <author>
      <name>Ajinkya Kadu</name>
    </author>
    <author>
      <name>Tristan van Leeuwen</name>
    </author>
    <author>
      <name>K. Joost Batenburg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-66272-5_11</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-66272-5_11" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper submitted to 20th International Conference on Discrete Geometry
  for Computer Imagery</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ropatsch W., Artner N., Janusch I. (eds) Discrete Geometry for
  Computer Imagery. DGCI 2017. Lecture Notes in Computer Science, vol 10502.
  Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.00568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.00568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02445v1</id>
    <updated>2017-04-08T06:12:40Z</updated>
    <published>2017-04-08T06:12:40Z</published>
    <title>Exact 3D seismic data reconstruction using Tubal-Alt-Min algorithm</title>
    <summary>  Data missing is an common issue in seismic data, and many methods have been
proposed to solve it. In this paper, we present the low-tubal-rank tensor model
and a novel tensor completion algorithm to recover 3D seismic data. This is a
fast iterative algorithm, called Tubal-Alt-Min which completes our 3D seismic
data by exploiting the low-tubal-rank property expressed as the product of two
much smaller tensors. TubalAlt-Min alternates between estimating those two
tensor using least squares minimization. We evaluate its reconstruction
performance both on synthetic seismic data and land data survey. The
experimental results show that compared with the tensor nuclear norm
minimization algorithm, Tubal-Alt-Min improves the reconstruction error by
orders of magnitude.
</summary>
    <author>
      <name>Feng Qian</name>
    </author>
    <author>
      <name>Quan Chen</name>
    </author>
    <author>
      <name>Ming-Jun Su</name>
    </author>
    <author>
      <name>Guang-Min Hu</name>
    </author>
    <author>
      <name>Xiao-Yang Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1704.02445v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02445v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03255v2</id>
    <updated>2017-04-28T13:44:27Z</updated>
    <published>2017-04-11T12:02:21Z</published>
    <title>Non-Linear Least-Squares Optimization of Rational Filters for the
  Solution of Interior Eigenvalue Problems</title>
    <summary>  Rational filter functions can be used to improve convergence of contour-based
eigensolvers, a popular family of algorithms for the solution of the interior
eigenvalue problem. We present a framework for the optimization of rational
filters based on a non-convex weighted Least-Squares scheme. When used in
combination with the FEAST library, our filters out-perform existing ones on a
large and representative set of benchmark problems. This work provides a
detailed description of: (1) a set up of the optimization process that exploits
symmetries of the filter function for Hermitian eigenproblems, (2) a
formulation of the gradient descent and Levenberg-Marquardt algorithms that
exploits the symmetries, (3) a method to select the starting position for the
optimization algorithms that reliably produces effective filters, (4) a
constrained optimization scheme that produces filter functions with specific
properties that may be beneficial to the performance of the eigensolver that
employs them.
</summary>
    <author>
      <name>Jan Winkelmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen University</arxiv:affiliation>
    </author>
    <author>
      <name>Edoardo Di Napoli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AICES, RWTH Aachen University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JSC, Forschungszentrum Jülich</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1704.03255v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03255v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="15A18, 65F10, 65F15, 65F50, 90C26" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07636v2</id>
    <updated>2017-09-30T19:28:36Z</updated>
    <published>2017-04-25T11:23:51Z</published>
    <title>Controlling the Error on Target Motion through Real-time Mesh
  Adaptation: Applications to Deep Brain Stimulation</title>
    <summary>  We present an error-controlled mesh refinement procedure for needle insertion
simulation and apply it to the simulation of electrode implantation for deep
brain stimulation, including brain shift. Our approach enables to control the
error in the computation of the displacement and stress fields around the
needle tip and needle shaft by suitably refining the mesh, whilst maintaining a
coarser mesh in other parts of the domain. We demonstrate through academic and
practical examples that our approach increases the accuracy of the displacement
and stress fields around the needle without increasing the computational
expense. This enables real-time simulations. The proposed methodology has
direct implications to increase the accuracy and control the computational
expense of the simulation of percutaneous procedures such as biopsy,
brachytherapy, regional anesthesia, or cryotherapy and can be essential to the
development of robotic guidance.
</summary>
    <author>
      <name>Huu Phuoc Bui</name>
    </author>
    <author>
      <name>Satyendra Tomar</name>
    </author>
    <author>
      <name>Hadrien Courtecuisse</name>
    </author>
    <author>
      <name>Michel Audette</name>
    </author>
    <author>
      <name>Stéphane Cotin</name>
    </author>
    <author>
      <name>Stéphane P. A. Bordas</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/cnm.2958</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/cnm.2958" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.07636v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07636v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07727v2</id>
    <updated>2018-11-28T09:49:16Z</updated>
    <published>2017-04-25T15:01:13Z</published>
    <title>Low-Dimensional Spatial Embedding Method for Shape Uncertainty
  Quantification in Acoustic Scattering</title>
    <summary>  This paper introduces a novel boundary integral approach of shape uncertainty
quantification for the Helmholtz scattering problem in the framework of the
so-called parametric method. The key idea is to construct an integration grid
whose associated weight function encompasses the irregularities and
nonsmoothness imposed by the random boundary. Thus, the solution can be
evaluated accurately with relatively low number of grid points. The integration
grid is obtained by employing a low-dimensional spatial embedding using the
coarea formula. The proposed method can handle large variation as well as
non-smoothness of the random boundary. For the ease of presentation the theory
is restricted to star-shaped obstacles in low-dimensional setting. Higher
spatial and parametric dimensional cases are discussed, though, not extensively
explored in the current study.
</summary>
    <author>
      <name>Yuval Harness</name>
    </author>
    <link href="http://arxiv.org/abs/1704.07727v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07727v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00614v1</id>
    <updated>2017-05-01T09:10:03Z</updated>
    <published>2017-05-01T09:10:03Z</published>
    <title>Numerical Model of Shallow Water: the Use of NVIDIA CUDA Graphics
  Processors</title>
    <summary>  In the paper we discuss the main features of the software package for
numerical simulations of the surface water dynamics. We consider an
approximation of the shallow water equations together with the parallel
technologies for NVIDIA CUDA graphics processors. The numerical hydrodynamic
code is based on the combined Lagrangian-Euler method~(CSPH-TVD). We focused on
the features of the parallel implementation of Tesla line of graphics
processors: C2070, K20, K40, K80. By using hierarchical grid systems at
different spatial scales we increase the efficiency of the computing resources
usage and speed up our simulations of a various flooding problems.
</summary>
    <author>
      <name>Tatyana Dyakonova</name>
    </author>
    <author>
      <name>Alexander Khoperskov</name>
    </author>
    <author>
      <name>Sergey Khrapov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-55669-7_11</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-55669-7_11" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Communications in Computer and Information Science, 2017, v.687,
  pp. 132-145</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.00614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01671v1</id>
    <updated>2017-05-04T01:47:19Z</updated>
    <published>2017-05-04T01:47:19Z</published>
    <title>Towards Simulation and Risk Assessment of Weather-Related Cascading
  Outages</title>
    <summary>  Weather and environmental factors are verified to have played significant
roles in historical major cascading outages and blackouts. Therefore, in the
simulation and risk assessment of cascading outages in power systems, it is
necessary to consider the weather and environmental effects. This paper
proposes a method for the risk assessment of weather-related cascading outages.
Based on the analysis of historical outage records and temperature-dependent
physical outage mechanisms of transmission lines, an outage rate model
considering weather condition and conductor temperature is proposed, and the
analytical form of outage probability of lines are derived. With the
weather-dependent outage model, a two-stage risk assessment method based on
Markovian tree (MT) search is proposed, which consists of offline full
assessment, and online efficient update of risk assessment results and
continued MT search using updated NWP data. The test cases on NPCC 140-bus test
system model in winter and summer scenarios verify the advantages of the
proposed risk assessment method in both accuracy and efficiency.
</summary>
    <author>
      <name>Rui Yao</name>
    </author>
    <author>
      <name>Kai Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1705.01671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02274v2</id>
    <updated>2017-07-22T06:56:52Z</updated>
    <published>2017-05-05T15:44:14Z</published>
    <title>A Dissipation Theory for Three-Dimensional FDTD with Application to
  Stability Analysis and Subgridding</title>
    <summary>  The finite-difference time-domain (FDTD) algorithm is a popular numerical
method for solving electromagnetic problems. FDTD simulations can suffer from
instability due to the explicit nature of the method. Stability enforcement can
be particularly challenging in scenarios where a setup is composed of multiple
components, such as grids of different resolution, advanced boundary
conditions, reduced-order models, and lumped elements. We propose a dissipation
theory for 3-D FDTD inspired by the principle of energy conservation. We view
the FDTD update equations for a 3-D region as a dynamical system, and show
under which conditions the system is dissipative. By requiring each component
of an FDTD-like scheme to be dissipative, the stability of the overall coupled
scheme follows by construction. The proposed framework enables the creation of
provably stable schemes in an easy and modular fashion, since conditions are
imposed on the individual components, rather than on the overall coupled scheme
as in existing approaches. With the proposed framework, we derive a new
subgridding scheme with guaranteed stability, low reflections, support for
material traverse and arbitrary (odd) grid refinement ratio.
</summary>
    <author>
      <name>Fadime Bekmambetova</name>
    </author>
    <author>
      <name>Xinyue Zhang</name>
    </author>
    <author>
      <name>Piero Triverio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAP.2018.2869617</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAP.2018.2869617" rel="related"/>
    <link href="http://arxiv.org/abs/1705.02274v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02274v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.04374v1</id>
    <updated>2017-05-11T20:54:51Z</updated>
    <published>2017-05-11T20:54:51Z</published>
    <title>Optimal fidelity multi-level Monte Carlo for quantification of
  uncertainty in simulations of cloud cavitation collapse</title>
    <summary>  We quantify uncertainties in the location and magnitude of extreme pressure
spots revealed from large scale multi-phase flow simulations of cloud
cavitation collapse. We examine clouds containing 500 cavities and quantify
uncertainties related to their initial spatial arrangement. The resulting
2000-dimensional space is sampled using a non-intrusive and computationally
efficient Multi-Level Monte Carlo (MLMC) methodology. We introduce novel
optimal control variate coefficients to enhance the variance reduction in MLMC.
The proposed optimal fidelity MLMC leads to more than two orders of magnitude
speedup when compared to standard Monte Carlo methods. We identify large
uncertainties in the location and magnitude of the peak pressure pulse and
present its statistical correlations and joint probability density functions
with the geometrical characteristics of the cloud. Characteristic properties of
spatial cloud structure are identified as potential causes of significant
uncertainties in exerted collapse pressures.
</summary>
    <author>
      <name>Jonas Šukys</name>
    </author>
    <author>
      <name>Ursula Rasthofer</name>
    </author>
    <author>
      <name>Fabian Wermelinger</name>
    </author>
    <author>
      <name>Panagiotis Hadjidoukas</name>
    </author>
    <author>
      <name>Petros Koumoutsakos</name>
    </author>
    <link href="http://arxiv.org/abs/1705.04374v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.04374v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="76B10, 68W10, 65C05, 65C60, 68M15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06149v1</id>
    <updated>2017-05-17T13:34:22Z</updated>
    <published>2017-05-17T13:34:22Z</published>
    <title>Parallel-in-Space-and-Time Simulation of the Three-Dimensional, Unsteady
  Navier-Stokes Equations for Incompressible Flow</title>
    <summary>  In this paper we combine the Parareal parallel-in-time method together with
spatial parallelization and investigate this space-time parallel scheme by
means of solving the three-dimensional incompressible Navier-Stokes equations.
Parallelization of time stepping provides a new direction of parallelization
and allows to employ additional cores to further speed up simulations after
spatial parallelization has saturated. We report on numerical experiments
performed on a Cray XE6, simulating a driven cavity flow with and without
obstacles. Distributed memory parallelization is used in both space and time,
featuring up to 2,048 cores in total. It is confirmed that the
space-time-parallel method can provide speedup beyond the saturation of the
spatial parallelization.
</summary>
    <author>
      <name>Roberto Croce</name>
    </author>
    <author>
      <name>Daniel Ruprecht</name>
    </author>
    <author>
      <name>Rolf Krause</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-09063-4_2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-09063-4_2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Modeling, Simulation and Optimization of Complex Processes - HPSC
  2012, Springer International Publishing, pages 13-23, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.06149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07413v2</id>
    <updated>2017-06-19T18:58:39Z</updated>
    <published>2017-05-21T08:28:18Z</published>
    <title>On the impact of quantum computing technology on future developments in
  high-performance scientific computing</title>
    <summary>  Quantum computing technologies have become a hot topic in academia and
industry receiving much attention and financial support from all sides.
Building a quantum computer that can be used practically is in itself an
outstanding challenge that has become the 'new race to the moon'. Next to
researchers and vendors of future computing technologies, national authorities
are showing strong interest in maturing this technology due to its known
potential to break many of today's encryption techniques, which would have
significant impact on our society. It is however quite likely that quantum
computing has beneficial impact on many computational disciplines.
  In this article we describe our vision of future developments in scientific
computing that would be enabled by the advent of software-programmable quantum
computers. We thereby assume that quantum computers will form part of a hybrid
accelerated computing platform like GPUs and co-processor cards do today. In
particular, we address the potential of quantum algorithms to bring major
breakthroughs in applied mathematics and its applications. Finally, we give
several examples that demonstrate the possible impact of quantum-accelerated
scientific computing on society.
</summary>
    <author>
      <name>Matthias Möller</name>
    </author>
    <author>
      <name>Cornelis Vuik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10676-017-9438-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10676-017-9438-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.07413v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07413v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08229v1</id>
    <updated>2017-05-22T16:14:22Z</updated>
    <published>2017-05-22T16:14:22Z</published>
    <title>Tools for improving resilience of electric distribution systems with
  networked microgrids</title>
    <summary>  In the electrical grid, the distribution system is themost vulnerable to
severe weather events. Well-placed and coordinatedupgrades, such as the
combination of microgrids, systemhardening and additional line redundancy, can
greatly reduce thenumber of electrical outages during extreme events. Indeed,
ithas been suggested that resilience is one of the primary benefitsof networked
microgrids. We formulate a resilient distributiongrid design problem as a
two-stage stochastic program andmake use of decomposition-based heuristic
algorithms to scaleto problems of practical size. We demonstrate the
feasibilityof a resilient distribution design tool on a model of an
actualdistribution network. We vary the study parameters, i.e., thecapital cost
of microgrid generation relative to system hardeningand target system
resilience metrics, and find regions in thisparametric space corresponding to
different distribution systemarchitectures, such as individual microgrids,
hardened networks,and a transition region that suggests the benefits of
microgridsnetworked via hardened circuit segments.
</summary>
    <author>
      <name>Arthur Barnes</name>
    </author>
    <author>
      <name>Harsha Nagarajan</name>
    </author>
    <author>
      <name>Emre Yamangil</name>
    </author>
    <author>
      <name>Russell Bent</name>
    </author>
    <author>
      <name>Scott Backhaus</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08849v1</id>
    <updated>2017-05-23T16:45:20Z</updated>
    <published>2017-05-23T16:45:20Z</published>
    <title>Parallel Matrix-Free Implementation of Frequency-Domain Finite
  Difference Methods for Cluster Computing</title>
    <summary>  Full-wave 3D electromagnetic simulations of complex planar devices,
multilayer interconnects, and chip packages are presented for wide-band
frequency-domain analysis using the finite difference integration technique
developed in the PETSc software package. Initial reordering of the index
assignment to the unknowns makes the resulting system matrix diagonally
dominant. The rearrangement also facilitates the decomposition of large domain
into slices for passing the mesh information to different machines. Matrix-free
methods are then exploited to minimize the number of element-wise
multiplications and memory requirements in the construction of the system of
linear equations. Besides, the recipes provide extreme ease of modifications in
the kernel of the code. The applicability of different Krylov subspace solvers
is investigated. The accuracy is checked through comparisons with CST MICROWAVE
STUDIO transient solver results. The parallel execution of the compiled code on
specific number of processors in multi-core distributed-memory architectures
demonstrate high scalability of the computational algorithm.
</summary>
    <author>
      <name>Amir Geranmayeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 10 figures including: Matrix-free 3D finite-difference
  frequency-domain (FDFD) methods, Simultaneous reduction in memory usage and
  computational costs of FDFD, Broadband impedance calculation of electrically
  large interconnects, Ease of solver modification for mutual field coupling
  simulation between many ports, Domain decomposition for passing the mesh
  information to parallel machines</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.08849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00221v1</id>
    <updated>2017-06-01T09:15:54Z</updated>
    <published>2017-06-01T09:15:54Z</published>
    <title>The Maximum Dissipation Principle in Rigid-Body Dynamics with Purely
  Inelastic Impacts</title>
    <summary>  Formulating a consistent theory for rigid-body dynamics with impacts is an
intricate problem. Twenty years ago Stewart published the first consistent
theory with purely inelastic impacts and an impulsive friction model analogous
to Coulomb friction. In this paper we demonstrate that the consistent impact
model can exhibit multiple solutions with a varying degree of dissipation even
in the single-contact case. Replacing the impulsive friction model based on
Coulomb friction by a model based on the maximum dissipation principle resolves
the non-uniqueness in the single-contact impact problem. The paper constructs
the alternative impact model and presents integral equations describing
rigid-body dynamics with a non-impulsive and non-compliant contact model and an
associated purely inelastic impact model maximizing dissipation. An analytic
solution is derived for the single-contact impact problem. The models are then
embedded into a time-stepping scheme. The macroscopic behaviour is compared to
Coulomb friction in a large-scale granular flow problem.
</summary>
    <author>
      <name>Tobias Preclik</name>
    </author>
    <author>
      <name>Sebastian Eibl</name>
    </author>
    <author>
      <name>Ulrich Rüde</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-017-1486-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-017-1486-0" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Springer, Computational Mechanics, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.00221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02985v1</id>
    <updated>2017-05-25T13:24:22Z</updated>
    <published>2017-05-25T13:24:22Z</published>
    <title>Stock Trading Using PE ratio: A Dynamic Bayesian Network Modeling on
  Behavioral Finance and Fundamental Investment</title>
    <summary>  On a daily investment decision in a security market, the price earnings (PE)
ratio is one of the most widely applied methods being used as a firm valuation
tool by investment experts. Unfortunately, recent academic developments in
financial econometrics and machine learning rarely look at this tool. In
practice, fundamental PE ratios are often estimated only by subjective expert
opinions. The purpose of this research is to formalize a process of fundamental
PE estimation by employing advanced dynamic Bayesian network (DBN) methodology.
The estimated PE ratio from our model can be used either as a information
support for an expert to make investment decisions, or as an automatic trading
system illustrated in experiments. Forward-backward inference and EM parameter
estimation algorithms are derived with respect to the proposed DBN structure.
Unlike existing works in literatures, the economic interpretation of our DBN
model is well-justified by behavioral finance evidences of volatility. A simple
but practical trading strategy is invented based on the result of Bayesian
inference. Extensive experiments show that our trading strategy equipped with
the inferenced PE ratios consistently outperforms standard investment
benchmarks.
</summary>
    <author>
      <name>Haizhen Wang</name>
    </author>
    <author>
      <name>Ratthachat Chatpatanasiri</name>
    </author>
    <author>
      <name>Pairote Sattayatham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.02985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03189v1</id>
    <updated>2017-06-10T06:32:08Z</updated>
    <published>2017-06-10T06:32:08Z</published>
    <title>Two-Scale Topology Optimization with Microstructures</title>
    <summary>  In this paper we present a novel two-scale framework to optimize the
structure and the material distribution of an object given its functional
specifications. Our approach utilizes multi-material microstructures as
low-level building blocks of the object. We start by precomputing the material
property gamut -- the set of bulk material properties that can be achieved with
all material microstructures of a given size. We represent the boundary of this
material property gamut using a level set field. Next, we propose an efficient
and general topology optimization algorithm that simultaneously computes an
optimal object topology and spatially-varying material properties constrained
by the precomputed gamut. Finally, we map the optimal spatially-varying
material properties onto the microstructures with the corresponding properties
in order to generate a high-resolution printable structure. We demonstrate the
efficacy of our framework by designing, optimizing, and fabricating objects in
different material property spaces on the level of a trillion voxels, i.e
several orders of magnitude higher than what can be achieved with current
systems.
</summary>
    <author>
      <name>Bo Zhu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIT CSAIL</arxiv:affiliation>
    </author>
    <author>
      <name>Mélina Skouras</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIT CSAIL</arxiv:affiliation>
    </author>
    <author>
      <name>Desai Chen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIT CSAIL</arxiv:affiliation>
    </author>
    <author>
      <name>Wojciech Matusik</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIT CSAIL</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 25 figures, to appear in ACM Transactions on Graphics 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35Q74" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04906v1</id>
    <updated>2017-06-15T14:55:09Z</updated>
    <published>2017-06-15T14:55:09Z</published>
    <title>A softening-healing law for self-healing quasi-brittle materials:
  analyzing with Strong Discontinuity embedded Approach</title>
    <summary>  Quasi-brittle materials such as concrete suffer from cracks during their life
cycle, requiring great cost for conventional maintenance or replacement. In the
last decades, self-healing materials are developed which are capable of filling
and healing the cracks and regaining part of the stiffness and strength
automatically after getting damaged, bringing the possibility of
maintenance-free materials and structures.
  In this paper, a time dependent softening-healing law for self-healing
quasi-brittle materials is presented by introducing limited material parameters
with clear physical background. Strong Discontinuity embedded Approach (SDA) is
adopted for evaluating the reliability of the model. In the numerical studies,
values of healing parameters are firstly obtained by back analysis of
experimental results of self-healing beams. Then numerical models regarding
concrete members and structures built with self-healing and non-healing
materials are simulated and compared for showing the capability of the
self-healing material.
</summary>
    <author>
      <name>Yiming Zhang</name>
    </author>
    <author>
      <name>Xiaoying Zhuang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 18 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.04906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05226v1</id>
    <updated>2017-06-16T11:56:50Z</updated>
    <published>2017-06-16T11:56:50Z</published>
    <title>State change modal method for numerical simulation of dynamic processes
  in a nuclear reactor</title>
    <summary>  Modeling of dynamic processes in nuclear reactors is carried out, mainly, on
the basis of the multigroup diffusion approximation for the neutron flux. The
basic model includes a multidimensional set of coupled parabolic equations and
ordinary differential equations. Dynamic processes are modeled by a successive
change of the reactor states, which are characterized by given coefficients of
the equations. In the modal method, the approximate solution is represented as
an expansion on the first eigenfunctions of some spectral problem. The
numerical-analytical method is based on the use of dominant time-eigenvalues of
a multigroup diffusion model taking into account delayed neutrons. Numerical
simulations of the dynamic process were performed in the framework of the
two-group approximation for the VVER-1000 reactor test model. The last is
characterized by the fact that some eigenvalues are complex.
</summary>
    <author>
      <name>Alexander V. Avvakumov</name>
    </author>
    <author>
      <name>Valery F. Strizhov</name>
    </author>
    <author>
      <name>Petr N. Vabishchevich</name>
    </author>
    <author>
      <name>Alexander O. Vasilev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 18 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.05226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05663v1</id>
    <updated>2017-06-18T14:38:38Z</updated>
    <published>2017-06-18T14:38:38Z</published>
    <title>Single item stochastic lot sizing problem considering capital flow and
  business overdraft</title>
    <summary>  This paper introduces capital flow to the single item stochastic lot sizing
problem. A retailer can leverage business overdraft to deal with unexpected
capital shortage, but needs to pay interest if its available balance goes below
zero. A stochastic dynamic programming model maximizing expected final capital
increment is formulated to solve the problem to optimality. We then investigate
the performance of four controlling policies: ($R, Q$), ($R, S$), ($s, S$) and
($s$, $\overline{Q}$, $S$); for these policies, we adopt simulation-genetic
algorithm to obtain approximate values of the controlling parameters. Finally,
a simulation-optimization heuristic is also employed to solve this problem.
Computational comparisons among these approaches show that policy $(s, S)$ and
policy $(s, \overline{Q}, S)$ provide performance close to that of optimal
solutions obtained by stochastic dynamic programming, while
simulation-optimization heuristic offers advantages in terms of computational
efficiency. Our numerical tests also show that capital availability as well as
business overdraft interest rate can substantially affect the retailer's
optimal lot sizing decisions.
</summary>
    <author>
      <name>Zhen Chen</name>
    </author>
    <author>
      <name>Roberto Rossi</name>
    </author>
    <author>
      <name>Ren-qian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.05663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05750v3</id>
    <updated>2018-02-07T07:42:43Z</updated>
    <published>2017-06-19T00:20:59Z</published>
    <title>Parallel-In-Time Simulation of Eddy Current Problems Using Parareal</title>
    <summary>  In this contribution the usage of the Parareal method is proposed for the
time-parallel solution of the eddy current problem. The method is adapted to
the particular challenges of the problem that are related to the differential
algebraic character due to non-conducting regions. It is shown how the
necessary modification can be automatically incorporated by using a suitable
time stepping method. The paper closes with a first demonstration of a
simulation of a realistic four-pole induction machine model using Parareal.
</summary>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <author>
      <name>Innocent Niyonzima</name>
    </author>
    <author>
      <name>Markus Clemens</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMAG.2017.2763090</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMAG.2017.2763090" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Magn. 54.3, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.05750v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05750v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L80, 65M60, 65N30, 65Y05, 78M10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7; G.1.8; F.2.1; I.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06468v1</id>
    <updated>2017-06-18T18:21:49Z</updated>
    <published>2017-06-18T18:21:49Z</published>
    <title>A finite-strain hyperviscoplastic model and undrained triaxial tests of
  peat</title>
    <summary>  This paper presents a finite-strain hyperviscoplastic constitutive model
within a thermodynamically consistent framework for peat which was categorised
as a material with both rate-dependent and thermodynamic equilibrium hysteresis
based on the data reported in the literature. The model was implemented
numerically using implicit time integration and verified against analytical
solutions under simplified conditions. Experimental studies on the undrained
relaxation and loading-unloading-reloading behaviour of an undisturbed fibrous
peat were carried out to define the thermodynamic equilibrium state during
deviatoric loading as a prerequisite for further modelling, to fit particularly
those model parameters related to solid matrix properties, and to validate the
proposed model under undrained conditions. This validation performed by
comparison to experimental results showed that the hyperviscoplastic model
could simulate undrained triaxial compression tests carried out at five
different strain rates with loading/unloading relaxation steps.
</summary>
    <author>
      <name>L. Zhang</name>
    </author>
    <author>
      <name>B. C. O'Kelly</name>
    </author>
    <author>
      <name>T. Nagel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 16 figures, 4 tables. This is a pre-peer reviewed version
  of manuscript submitted to the International Journal of Numerical and
  Analytical Methods in Geomechanics</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.06468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09369v1</id>
    <updated>2017-06-28T17:19:40Z</updated>
    <published>2017-06-28T17:19:40Z</published>
    <title>Passive Polarimetric Multistatic Radar Detection of Moving Targets</title>
    <summary>  We study the exploitation of polarimetric diversity in passive multistatic
radar for detecting moving targets. We first derive a data model that takes
into account polarization and anisotropy of targets inherent in multistatic
configurations. Unlike conventional isotropic models in which targets are
modeled as a collection of uniform spheres, we model targets as a collection of
dipole antennas with unknown directions. We consider a multistatic
configuration in which each receiver is equipped with a pair of orthogonally
polarized antennas, one directed to a scene of interest collecting target-path
signal and another one having a direct line-of-sight to a
transmitter-of-opportunity collecting direct-path signal. We formulate the
detection of moving target problem in a generalized likelihood ratio test
framework under the assumption that direct-path signal is available. We show
that the result can be reduced to the case in which the direct-path signal is
absent. We present a method for estimating the dipole moments of targets.
Extensive numerical simulations show the performance of both the detection and
the dipole estimation tasks with and without polarimetric diversity.
</summary>
    <author>
      <name>Il-Young Son</name>
    </author>
    <author>
      <name>Birsen Yazici</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, submitted to IEEE Trans. Signal Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09661v2</id>
    <updated>2018-01-19T12:22:58Z</updated>
    <published>2017-06-29T10:21:15Z</published>
    <title>Dynamic coupling of a finite element solver to large-scale atomistic
  simulations</title>
    <summary>  We propose a method for efficiently coupling the finite element method with
atomistic simulations, while using molecular dynamics or kinetic Monte Carlo
techniques. Our method can dynamically build an optimized unstructured mesh
that follows the geometry defined by atomistic data. On this mesh, different
multiphysics problems can be solved to obtain distributions of physical
quantities of interest, which can be fed back to the atomistic system. The
simulation flow is optimized to maximize computational efficiency while
maintaining good accuracy. This is achieved by providing the modules for a)
optimization of the density of the generated mesh according to requirements of
a specific geometry and b) efficient extension of the finite element domain
without a need to extend the atomistic one. Our method is organized as an
open-source C++ code. In the current implementation, an efficient Laplace
equation solver for calculation of electric field distribution near rough
atomistic surface demonstrates the capability of the suggested approach.
</summary>
    <author>
      <name>Mihkel Veske</name>
    </author>
    <author>
      <name>Andreas Kyritsakis</name>
    </author>
    <author>
      <name>Kristjan Eimre</name>
    </author>
    <author>
      <name>Vahur Zadin</name>
    </author>
    <author>
      <name>Alvo Aabloo</name>
    </author>
    <author>
      <name>Flyura Djurabekova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jcp.2018.04.031</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jcp.2018.04.031" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09661v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09661v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01947v2</id>
    <updated>2018-04-17T19:38:17Z</updated>
    <published>2017-07-06T19:49:58Z</published>
    <title>Efficient simulation of DC-DC switch-mode power converters by multirate
  partial differential equations</title>
    <summary>  In this paper, Multirate Partial Differential Equations (MPDEs) are used for
the efficient simulation of problems with 2-level pulsed excitations as they
often occur in power electronics, e.g., DC-DC switch-mode converters. The
differential equations describing the problem are reformulated as MPDEs which
are solved by a Galerkin approach and time discretization. For the solution
expansion two types of basis functions are proposed, namely classical Finite
Element (FE) nodal functions and the recently introduced excitation-specific
pulse width modulation (PWM) basis functions. The new method is applied to the
example of a buck converter. Convergence, accuracy of the solution and
computational efficiency of the method are numerically analyzed.
</summary>
    <author>
      <name>Andreas Pels</name>
    </author>
    <author>
      <name>Johan Gyselinck</name>
    </author>
    <author>
      <name>Ruth V. Sabariego</name>
    </author>
    <author>
      <name>Sebastian Schöps</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JMMCT.2018.2888900</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JMMCT.2018.2888900" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Journal on Multiscale and Multiphysics Computational
  Techniques, vol. 4, pp. 64-75, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.01947v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01947v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65L05, 65L80, 65M60" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7; G.1.8; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03581v1</id>
    <updated>2017-07-12T07:48:46Z</updated>
    <published>2017-07-12T07:48:46Z</published>
    <title>Toward transient finite element simulation of thermal deformation of
  machine tools in real-time</title>
    <summary>  Finite element models without simplifying assumptions can accurately describe
the spatial and temporal distribution of heat in machine tools as well as the
resulting deformation. In principle, this allows to correct for displacements
of the Tool Centre Point and enables high precision manufacturing. However, the
computational cost of FEM models and restriction to generic algorithms in
commercial tools like ANSYS prevents their operational use since simulations
have to run faster than real-time. For the case where heat diffusion is slow
compared to machine movement, we introduce a tailored implicit-explicit
multi-rate time stepping method of higher order based on spectral deferred
corrections. Using the open-source FEM library DUNE, we show that fully coupled
simulations of the temperature field are possible in real-time for a machine
consisting of a stock sliding up and down on rails attached to a stand.
</summary>
    <author>
      <name>Andreas Naumann</name>
    </author>
    <author>
      <name>Daniel Ruprecht</name>
    </author>
    <author>
      <name>Joerg Wensch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00466-018-1540-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00466-018-1540-6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Mechanics 62(5), pp. 929 - 942, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.03581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04038v4</id>
    <updated>2019-01-14T19:11:07Z</updated>
    <published>2017-07-13T09:31:26Z</published>
    <title>An arbitrary order scheme on generic meshes for miscible displacements
  in porous media</title>
    <summary>  We design, analyse and implement an arbitrary order scheme applicable to
generic meshes for a coupled elliptic-parabolic PDE system describing miscible
displacement in porous media. The discretisation is based on several
adaptations of the Hybrid-High-Order (HHO) method due to Di Pietro et al.
[Computational Methods in Applied Mathematics, 14(4), (2014)]. The equation
governing the pressure is discretised using an adaptation of the HHO method for
variable diffusion, while the discrete concentration equation is based on the
HHO method for advection-diffusion-reaction problems combined with numerically
stable flux reconstructions for the advective velocity that we have derived
using the results of Cockburn et al. [ESAIM: Mathematical Modelling and
Numerical Analysis, 50(3), (2016)]. We perform some rigorous analysis of the
method to demonstrate its $L^2$ stability under the irregular data often
presented by reservoir engineering problems and present several numerical tests
to demonstrate the quality of the results that are produced by the proposed
scheme.
</summary>
    <author>
      <name>Daniel Anderson</name>
    </author>
    <author>
      <name>Jerome Droniou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/17M1138807</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/17M1138807" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM J. Sci. Comput. 40 (4), B1020-B1054, 2018</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.04038v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04038v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07823v1</id>
    <updated>2017-07-25T06:08:18Z</updated>
    <published>2017-07-25T06:08:18Z</published>
    <title>Mathematical Model for Detection of Leakage in Domestic Water Supply
  Systems by Reading Consumption from an Analogue Water Meter</title>
    <summary>  In this article we introduce the principles to detect leakage using a
mathematical model based on machine learning and domestic water consumption
monitoring in real time. The model uses data which is measured from a water
meter, analyzes the water consumption, and uses two criteria simultaneously:
deviation from the average consumption, and comparison of steady water
consumptions over a period of time. Simulation of the model on a regular
household consumer was implemented on Antileaks - device that we have built
that designed to transfer consumption information from an analogue water meter
to a digital form in real time.
</summary>
    <author>
      <name>Gal Oren</name>
    </author>
    <author>
      <name>Nerya Y. Stroh</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Environmental Science and Development
  (IJESD), Vol. 4, No. 4, International Association of Computer Science and
  Information Technology Press, ISSN: 2010-0264, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.07823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08247v1</id>
    <updated>2017-07-25T23:19:20Z</updated>
    <published>2017-07-25T23:19:20Z</published>
    <title>Kinetic Simulation of Collisional Magnetized Plasmas with Semi-Implicit
  Time Integration</title>
    <summary>  Plasmas with varying collisionalities occur in many applications, such as
tokamak edge regions, where the flows are characterized by significant
variations in density and temperature. While a kinetic model is necessary for
weakly-collisional high-temperature plasmas, high collisionality in colder
regions render the equations numerically stiff due to disparate time scales. In
this paper, we propose an implicit-explicit algorithm for such cases, where the
collisional term is integrated implicitly in time, while the advective term is
integrated explicitly in time, thus allowing time step sizes that are
comparable to the advective time scales. This partitioning results in a more
efficient algorithm than those using explicit time integrators, where the time
step sizes are constrained by the stiff collisional time scales. We implement
semi-implicit additive Runge-Kutta methods in COGENT, a finite-volume
gyrokinetic code for mapped, multiblock grids and test the accuracy,
convergence, and computational cost of these semi-implicit methods for test
cases with highly-collisional plasmas.
</summary>
    <author>
      <name>Debojyoti Ghosh</name>
    </author>
    <author>
      <name>Mikhail A. Dorf</name>
    </author>
    <author>
      <name>Milo R. Dorr</name>
    </author>
    <author>
      <name>Jeffrey A. F. Hittinger</name>
    </author>
    <link href="http://arxiv.org/abs/1707.08247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M06, 86A10, 76N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
