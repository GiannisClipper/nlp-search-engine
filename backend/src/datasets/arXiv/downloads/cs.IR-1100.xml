<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.IR%26id_list%3D%26start%3D0%26max_results%3D1100" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.IR&amp;id_list=&amp;start=0&amp;max_results=1100</title>
  <id>http://arxiv.org/api/4CVktmnSWpTTXkqNMWXJrBiDRZI</id>
  <updated>2025-03-29T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">19998</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1100</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/0710.1962v1</id>
    <updated>2007-10-10T10:03:03Z</updated>
    <published>2007-10-10T10:03:03Z</published>
    <title>Stanford Matrix Considered Harmful</title>
    <summary>  This note argues about the validity of web-graph data used in the literature.
</summary>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/0710.1962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.1962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1869v2</id>
    <updated>2009-10-27T07:09:51Z</updated>
    <published>2009-10-09T21:42:58Z</published>
    <title>Management Of Volatile Information In Incremental Web Crawler</title>
    <summary>  Paper has been withdrawn.
</summary>
    <author>
      <name>Ravita Chahar</name>
    </author>
    <author>
      <name>Komal Hooda</name>
    </author>
    <author>
      <name>Annu Dhankhar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.1869v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1869v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.03066v1</id>
    <updated>2017-11-08T17:45:46Z</updated>
    <published>2017-11-08T17:45:46Z</published>
    <title>A Simple Derivation of the Heap's Law from the Generalized Zipf's Law</title>
    <summary>  I reproduce a rather simple formal derivation of the Heaps' law from the
generalized Zipf's law, which I previously published in Russian.
</summary>
    <author>
      <name>Leonid Boytsov</name>
    </author>
    <link href="http://arxiv.org/abs/1711.03066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.03066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702067v1</id>
    <updated>2007-02-10T21:26:05Z</updated>
    <published>2007-02-10T21:26:05Z</published>
    <title>The Haar Wavelet Transform of a Dendrogram: Additional Notes</title>
    <summary>  We consider the wavelet transform of a finite, rooted, node-ranked, $p$-way
tree, focusing on the case of binary ($p = 2$) trees. We study a Haar wavelet
transform on this tree. Wavelet transforms allow for multiresolution analysis
through translation and dilation of a wavelet function. We explore how this
works in our tree context.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pp, 1 fig. Supplementary material to "The Haar Wavelet Transform
  of a Dendrogram", http://arxiv.org/abs/cs.IR/0608107</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3; H.3.1; I.1.m; I.7.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0402061v1</id>
    <updated>2004-02-27T14:13:01Z</updated>
    <published>2004-02-27T14:13:01Z</published>
    <title>A Correlation-Based Distance</title>
    <summary>  In this short technical report, we define on the sample space R^D a distance
between data points which depends on their correlation. We also derive an
expression for the center of mass of a set of points with respect to this
distance.
</summary>
    <author>
      <name>Jean-Luc Falcone</name>
    </author>
    <author>
      <name>Paul Albuquerque</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0402061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0402061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410055v1</id>
    <updated>2004-10-21T15:51:20Z</updated>
    <published>2004-10-21T15:51:20Z</published>
    <title>Mathematical knowledge management is needed</title>
    <summary>  In this lecture I discuss some aspects of MKM, Mathematical Knowledge
Management, with particuar emphasis on information storage and information
retrieval.
</summary>
    <author>
      <name>Michiel Hazewinkel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keynote speech at the November, 2003 MKM meeting ar Herriott-Watt,
  Edinburg, UK. Nine pages, one figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0410055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11060v3</id>
    <updated>2020-02-15T13:03:58Z</updated>
    <published>2019-11-21T17:23:31Z</published>
    <title>A Survey on Adversarial Information Retrieval on the Web</title>
    <summary>  This survey paper discusses different forms of malicious techniques that can
affect how an information retrieval model retrieves documents for a query and
their remedies.
</summary>
    <author>
      <name>Saad Farooq</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11060v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11060v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01649v1</id>
    <updated>2015-09-05T00:52:43Z</updated>
    <published>2015-09-05T00:52:43Z</published>
    <title>Using of Neuro-Indexes</title>
    <summary>  The article describes a new data structure called neuro-index. It is an
alternative to well-known file indexes. The neuro-index is fundamentally
different because it stores weight coefficients in neural network. It is not a
reference type like "keyword-position in a file".
</summary>
    <author>
      <name>Valerii Garnaga</name>
    </author>
    <link href="http://arxiv.org/abs/1509.01649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.10204v1</id>
    <updated>2018-07-26T15:41:35Z</updated>
    <published>2018-07-26T15:41:35Z</published>
    <title>Visual Display and Retrieval of Music Information</title>
    <summary>  This paper describes computational methods for the visual display and
analysis of music information. We provide a concise description of software,
music descriptors and data visualization techniques commonly used in music
information retrieval. Finally, we provide use cases where the described
software, descriptors and visualizations are showcased.
</summary>
    <author>
      <name>Rafael Valle</name>
    </author>
    <link href="http://arxiv.org/abs/1807.10204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.10204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0104v1</id>
    <updated>2014-08-30T11:39:32Z</updated>
    <published>2014-08-30T11:39:32Z</published>
    <title>Marginalizing over the PageRank Damping Factor</title>
    <summary>  In this note, we show how to marginalize over the damping parameter of the
PageRank equation so as to obtain a parameter-free version known as TotalRank.
Our discussion is meant as a reference and intended to provide a guided tour
towards an interesting result that has applications in information retrieval
and classification.
</summary>
    <author>
      <name>Christian Bauckhage</name>
    </author>
    <link href="http://arxiv.org/abs/1409.0104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.08965v1</id>
    <updated>2022-02-09T18:09:50Z</updated>
    <published>2022-02-09T18:09:50Z</published>
    <title>High-performance automatic categorization and attribution of inventory
  catalogs</title>
    <summary>  Techniques of machine learning for automatic text categorization are applied
and adapted for the problem of inventory catalog data attribution, with
different approaches explored and optimal solution addressing the tradeoff
between accuracy and performance is selected.
</summary>
    <author>
      <name>Anton Kolonin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.08965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.08965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.07666v1</id>
    <updated>2019-03-18T18:44:07Z</updated>
    <published>2019-03-18T18:44:07Z</published>
    <title>An Updated Duet Model for Passage Re-ranking</title>
    <summary>  We propose several small modifications to Duet---a deep neural ranking
model---and evaluate the updated model on the MS MARCO passage ranking task. We
report significant improvements from the proposed changes based on an ablation
study.
</summary>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/1903.07666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.07666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.05755v1</id>
    <updated>2019-07-12T14:08:56Z</updated>
    <published>2019-07-12T14:08:56Z</published>
    <title>Proceedings of FACTS-IR 2019</title>
    <summary>  The proceedings list for the program of FACTS-IR 2019, the Workshop on
Fairness, Accountability, Confidentiality, Transparency, and Safety in
Information Retrieval held at SIGIR 2019.
</summary>
    <author>
      <name>Alexandra Olteanu</name>
    </author>
    <author>
      <name>Jean Garcia-Gathright</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <author>
      <name>Michael D. Ekstrand</name>
    </author>
    <link href="http://arxiv.org/abs/1907.05755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.02346v1</id>
    <updated>2019-12-05T02:03:30Z</updated>
    <published>2019-12-05T02:03:30Z</published>
    <title>Information Retrieval and Its Sister Disciplines</title>
    <summary>  This article presents a summary graph to show the relationships between
Information Retrieval (IR) and other related disciplines. The figure tells the
key differences between them and the conditions under which one would
transition into another.
</summary>
    <author>
      <name>Grace Hui Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1912.02346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.02346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.16061v1</id>
    <updated>2023-03-28T15:41:20Z</updated>
    <published>2023-03-28T15:41:20Z</published>
    <title>A comment to "A General Theory of IR Evaluation Measures"</title>
    <summary>  The paper "A General Theory of IR Evaluation Measures" develops a formal
framework to determine whether IR evaluation measures are interval scales. This
comment shows some limitations about its conclusions.
</summary>
    <author>
      <name>Fernando Giner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.16061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.16061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.12330v1</id>
    <updated>2024-12-16T20:00:51Z</updated>
    <published>2024-12-16T20:00:51Z</published>
    <title>Searching Personal Collections</title>
    <summary>  This article describes the history of information retrieval on personal
document collections.
</summary>
    <author>
      <name>Michael Bendersky</name>
    </author>
    <author>
      <name>Donald Metzler</name>
    </author>
    <author>
      <name>Marc Najork</name>
    </author>
    <author>
      <name>Xuanhui Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3674127.3674142</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3674127.3674142" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chapter 14 in "Information Retrieval: Advanced Topics and
  Techniques", edited by Omar Alonso and Ricardo Baeza-Yates, ACM Press, 2025</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2412.12330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.12330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.07315v2</id>
    <updated>2025-02-23T09:44:00Z</updated>
    <published>2025-02-11T07:25:57Z</published>
    <title>White Hat Search Engine Optimization using Large Language Models</title>
    <summary>  We present novel white-hat search engine optimization techniques based on
genAI and demonstrate their empirical merits.
</summary>
    <author>
      <name>Niv Bardas</name>
    </author>
    <author>
      <name>Tommy Mordo</name>
    </author>
    <author>
      <name>Oren Kurland</name>
    </author>
    <author>
      <name>Moshe Tennenholtz</name>
    </author>
    <author>
      <name>Gal Zur</name>
    </author>
    <link href="http://arxiv.org/abs/2502.07315v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.07315v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003001v1</id>
    <updated>2000-03-01T18:11:08Z</updated>
    <published>2000-03-01T18:11:08Z</published>
    <title>Making news understandable to computers</title>
    <summary>  Computers and devices are largely unaware of events taking place in the
world. This could be changed if news were made available in a
computer-understandable form. In this paper we present XML documents called
NewsForms that represent the key points of 17 types of news events. We discuss
the benefits of computer-understandable news and present the NewsExtract
program for converting text news stories into NewsForms.
</summary>
    <author>
      <name>Erik T. Mueller</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0003001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0110026v1</id>
    <updated>2001-10-10T15:28:00Z</updated>
    <published>2001-10-10T15:28:00Z</published>
    <title>Information retrieval in Current Research Information Systems</title>
    <summary>  In this paper we describe the requirements for research information systems
and problems which arise in the development of such system. Here is shown which
problems could be solved by using of knowledge markup technologies. Ontology
for Research Information System offered. Architecture for collecting research
data and providing access to it is described.
</summary>
    <author>
      <name>Andrei Lopatenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, ontology description included, position paper at the
  Workshop on Knowledge Markup and Semantic Annotation at K-CAP'2001</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0110026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.4; H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601103v1</id>
    <updated>2006-01-24T10:23:15Z</updated>
    <published>2006-01-24T10:23:15Z</published>
    <title>Google Web APIs - an Instrument for Webometric Analyses?</title>
    <summary>  This paper introduces Google Web APIs (Google APIs) as an instrument and
playground for webometric studies. Several examples of Google APIs
implementations are given. Our examples show that this Google Web Service can
be used successfully for informetric Internet based studies albeit with some
restrictions.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Fabio Tosques</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, 10th International Conference of the
  International Society for Scientometrics and Informetrics</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0601103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0751v1</id>
    <updated>2007-05-05T17:27:42Z</updated>
    <published>2007-05-05T17:27:42Z</published>
    <title>Approximate textual retrieval</title>
    <summary>  An approximate textual retrieval algorithm for searching sources with high
levels of defects is presented. It considers splitting the words in a query
into two overlapping segments and subsequently building composite regular
expressions from interlacing subsets of the segments. This procedure reduces
the probability of missed occurrences due to source defects, yet diminishes the
retrieval of irrelevant, non-contextual occurrences.
</summary>
    <author>
      <name>Pere Constans</name>
    </author>
    <link href="http://arxiv.org/abs/0705.0751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.4542v3</id>
    <updated>2009-09-15T14:52:52Z</updated>
    <published>2008-12-24T15:41:48Z</published>
    <title>Assessing scientific research performance and impact with single indices</title>
    <summary>  We provide a comprehensive and critical review of the h-index and its most
important modifications proposed in the literature, as well as of other similar
indicators measuring research output and impact. Extensions of some of these
indices are presented and illustrated.
</summary>
    <author>
      <name>John Panaretos</name>
    </author>
    <author>
      <name>Chrisovaladis Malesios</name>
    </author>
    <link href="http://arxiv.org/abs/0812.4542v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.4542v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5378v1</id>
    <updated>2009-11-28T06:25:00Z</updated>
    <published>2009-11-28T06:25:00Z</published>
    <title>De la recherche sociale d'information à la recherche collaborative
  d'information</title>
    <summary>  In this paper, we explain social information retrieval (SIR) and
collaborative information retrieval (CIR). We see SIR as a way of knowing who
to collaborate with in resolving an information problem while CIR entails the
process of mutual understanding and solving of an information problem among
collaborators. We are interested in the transition from SIR to CIR hence we
developed a communication model to facilitate knowledge sharing during CIR.
</summary>
    <author>
      <name>Victor Odumuyiwa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">7\`eme colloque du chapitre fran\c{c}ais de l'ISKO, Lyon : France
  (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.5378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.4458v1</id>
    <updated>2010-06-23T09:50:06Z</updated>
    <published>2010-06-23T09:50:06Z</published>
    <title>Few Algorithms for ascertaining merit of a document and their
  applications</title>
    <summary>  Existing models for ranking documents(mostly in world wide web) are prestige
based. In this article, three algorithms to objectively judge the merit of a
document are proposed - 1) Citation graph maxflow 2) Recursive Gloss Overlap
based intrinsic merit scoring and 3) Interview algorithm. A short discussion on
generic judgement and its mathematical treatment is presented in introduction
to motivate these algorithms.
</summary>
    <author>
      <name>Ka. Shrinivaasan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.4458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.4458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0766v1</id>
    <updated>2011-01-04T16:59:24Z</updated>
    <published>2011-01-04T16:59:24Z</published>
    <title>Information Retrieval of Jumbled Words</title>
    <summary>  It is known that humans can easily read words where the letters have been
jumbled in a certain way. This paper examines this problem by associating a
distance measure with the jumbling process. Modifications to text were
generated according to the Damerau-Levenshtein distance and it was checked if
the users are able to read it. Graphical representations of the results are
provided.
</summary>
    <author>
      <name>Venkata Ravinder Paruchuri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1639v1</id>
    <updated>2011-01-09T14:42:04Z</updated>
    <published>2011-01-09T14:42:04Z</published>
    <title>Applying Science Models for Search</title>
    <summary>  The paper proposes three different kinds of science models as value-added
services that are integrated in the retrieval process to enhance retrieval
quality. The paper discusses the approaches Search Term Recommendation,
Bradfordizing and Author Centrality on a general level and addresses
implementation issues of the models within a real-life retrieval environment.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <author>
      <name>Vivien Petras</name>
    </author>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <author>
      <name>York Sure</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, ISI 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.1639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3400v1</id>
    <updated>2011-01-18T08:39:12Z</updated>
    <published>2011-01-18T08:39:12Z</published>
    <title>Behavioral On-Line Advertising</title>
    <summary>  We present a new algorithm for behavioral targeting of banner advertisements.
We record different user's actions such as clicks, search queries and page
views. We use the collected information on the user to estimate in real time
the probability of a click on a banner. A banner is displayed if it either has
the highest probability of being clicked or if it is the one that generates the
highest average profit.
</summary>
    <author>
      <name>Fabrizio Caruso</name>
    </author>
    <author>
      <name>Giovanni Giuffrida</name>
    </author>
    <author>
      <name>Calogero Zarba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.3400v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3400v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3306v1</id>
    <updated>2011-02-16T11:16:51Z</updated>
    <published>2011-02-16T11:16:51Z</published>
    <title>Efficient Error-Correcting Geocoding</title>
    <summary>  We study the problem of resolving a perhaps misspelled address of a location
into geographic coordinates of latitude and longitude. Our data structure
solves this problem within a few milliseconds even for misspelled and
fragmentary queries. Compared to major geographic search engines such as Google
or Bing we achieve results of significantly better quality.
</summary>
    <author>
      <name>Christian Jung</name>
    </author>
    <author>
      <name>Daniel Karch</name>
    </author>
    <author>
      <name>Sebastian Knopp</name>
    </author>
    <author>
      <name>Dennis Luxen</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <link href="http://arxiv.org/abs/1102.3306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; E.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3286v2</id>
    <updated>2012-09-17T18:53:14Z</updated>
    <published>2012-09-14T18:59:03Z</published>
    <title>Music Recommendation System for Million Song Dataset Challenge</title>
    <summary>  In this paper a system that took 8th place in Million Song Dataset challenge
is described. Given full listening history for 1 million of users and half of
listening history for 110000 users participatints should predict the missing
half. The system proposed here uses memory-based collaborative filtering
approach and user-based similarity. MAP@500 score of 0.15037 was achieved.
</summary>
    <author>
      <name>Nikolay Glazyrin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3286v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3286v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0320v1</id>
    <updated>2012-11-01T22:16:57Z</updated>
    <published>2012-11-01T22:16:57Z</published>
    <title>TrackMeNot-so-good-after-all</title>
    <summary>  TrackMeNot is a Firefox plugin with laudable intentions - protecting your
privacy. By issuing a customizable stream of random search queries on its
users' behalf, TrackMeNot surmises that enough search noise will prevent its
users' true query profiles from being discerned. However, we find that
clustering queries by semantic relatedness allows us to disentangle a
nontrivial subset of true user queries from TrackMeNot issued noise.
</summary>
    <author>
      <name>Rami Al-Rfou'</name>
    </author>
    <author>
      <name>William Jannen</name>
    </author>
    <author>
      <name>Nikhil Patwardhan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0074v1</id>
    <updated>2012-12-01T07:01:27Z</updated>
    <published>2012-12-01T07:01:27Z</published>
    <title>Challenges in Kurdish Text Processing</title>
    <summary>  Despite having a large number of speakers, the Kurdish language is among the
less-resourced languages. In this work we highlight the challenges and problems
in providing the required tools and techniques for processing texts written in
Kurdish. From a high-level perspective, the main challenges are: the inherent
diversity of the language, standardization and segmentation issues, and the
lack of language resources.
</summary>
    <author>
      <name>Kyumars Sheykh Esmaili</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3906v1</id>
    <updated>2012-12-17T07:13:50Z</updated>
    <published>2012-12-17T07:13:50Z</published>
    <title>Simple Search Engine Model: Adaptive Properties</title>
    <summary>  In this paper we study the relationship between query and search engine by
exploring the adaptive properties based on a simple search engine. We used set
theory and utilized the words and terms for defining singleton space of event
in a search engine model, and then provided the inclusion between one singleton
to another.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, noting, draf</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4702v1</id>
    <updated>2012-12-19T15:18:09Z</updated>
    <published>2012-12-19T15:18:09Z</published>
    <title>Simple Search Engine Model: Adaptive Properties for Doubleton</title>
    <summary>  In this paper we study the relationship between query and search engine by
exploring the adaptive properties for doubleton as a space of event based on a
simple search engine. We employ set theory for defining doubleton and generate
some properties.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, nothing, a draf</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.4702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5633v1</id>
    <updated>2012-12-21T23:20:24Z</updated>
    <published>2012-12-21T23:20:24Z</published>
    <title>Design, implementation and experiment of a YeSQL Web Crawler</title>
    <summary>  We describe a novel, "focusable", scalable, distributed web crawler based on
GNU/Linux and PostgreSQL that we designed to be easily extendible and which we
have released under a GNU public licence. We also report a first use case
related to an analysis of Twitter's streams about the french 2012 presidential
elections and the URL's it contains.
</summary>
    <author>
      <name>Pierre Joulin</name>
    </author>
    <author>
      <name>Romain Deveaud</name>
    </author>
    <author>
      <name>Eric SanJuan-Ibekwe</name>
    </author>
    <author>
      <name>Jean-Marc Francony</name>
    </author>
    <author>
      <name>Françoise Para</name>
    </author>
    <link href="http://arxiv.org/abs/1212.5633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.3964v1</id>
    <updated>2013-03-16T10:21:33Z</updated>
    <published>2013-03-16T10:21:33Z</published>
    <title>Simple Search Engine Model: Selective Properties</title>
    <summary>  In this paper we study the relationship between query and search engine by
exploring the selective properties based on a simple search engine. We used the
set theory and utilized the words and terms for defining singleton and
doubleton in the event spaces and then provided their implementation for
proving the existence of the shadow of micro-cluster.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.3964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.3964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3563v1</id>
    <updated>2013-04-12T08:04:31Z</updated>
    <published>2013-04-12T08:04:31Z</published>
    <title>Data, text and web mining for business intelligence: a survey</title>
    <summary>  The Information and Communication Technologies revolution brought a digital
world with huge amounts of data available. Enterprises use mining technologies
to search vast amounts of data for vital insight and knowledge. Mining tools
such as data mining, text mining, and web mining are used to find hidden
knowledge in large databases or the Internet.
</summary>
    <author>
      <name>Abdul-Aziz Rashid Al-Azmi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdkp.2013.3201</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdkp.2013.3201" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 page, journal paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.3, No.2, March 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.3563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1114v1</id>
    <updated>2013-05-06T08:42:19Z</updated>
    <published>2013-05-06T08:42:19Z</published>
    <title>Towards User Profile Modelling in Recommender System</title>
    <summary>  The notion of profile appeared in the 1970s decade, which was mainly due to
the need to create custom applications that could be adapted to the user. In
this paper, we treat the different aspects of the user's profile, defining it,
profile, its features and its indicators of interest, and then we describe the
different approaches of modelling and acquiring the user's interests.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1745v1</id>
    <updated>2013-05-08T08:38:04Z</updated>
    <published>2013-05-08T08:38:04Z</published>
    <title>Mobile Recommender Systems Methods: An Overview</title>
    <summary>  The information that mobiles can access becomes very wide nowadays, and the
user is faced with a dilemma: there is an unlimited pool of information
available to him but he is unable to find the exact information he is looking
for. This is why the current research aims to design Recommender Systems (RS)
able to continually send information that matches the user's interests in order
to reduce his navigation time. In this paper, we treat the different approaches
to recommend.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1787v1</id>
    <updated>2013-05-08T11:52:39Z</updated>
    <published>2013-05-08T11:52:39Z</published>
    <title>Evolution of the user's content: An Overview of the state of the art</title>
    <summary>  The evolution of the user's content still remains a problem for an accurate
recommendation.This is why the current research aims to design Recommender
Systems (RS) able to continually adapt information that matches the user's
interests. This paper aims to explain this problematic point in outlining the
proposals that have been made in research with their advantages and
disadvantages.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5330v1</id>
    <updated>2013-05-23T06:49:20Z</updated>
    <published>2013-05-23T06:49:20Z</published>
    <title>A toy model of information retrieval system based on quantum probability</title>
    <summary>  Recent numerical results show that non-Bayesian knowledge revision may be
helpful in search engine training and optimization. In order to demonstrate how
basic assumption about about the physical nature (and hence the observed
statistics) of retrieved documents can affect the performance of search engines
we suggest an idealized toy model with minimal number of parameters.
</summary>
    <author>
      <name>Roman Zapatrin</name>
    </author>
    <link href="http://arxiv.org/abs/1305.5330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.7014v1</id>
    <updated>2013-05-30T06:35:52Z</updated>
    <published>2013-05-30T06:35:52Z</published>
    <title>Tweets Miner for Stock Market Analysis</title>
    <summary>  In this paper, we present a software package for the data mining of Twitter
microblogs for the purpose of using them for the stock market analysis. The
package is written in R langauge using apropriate R packages. The model of
tweets has been considered. We have also compared stock market charts with
frequent sets of keywords in Twitter microblogs messages.
</summary>
    <author>
      <name>Bohdan Pavlyshenko</name>
    </author>
    <link href="http://arxiv.org/abs/1305.7014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.7014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3872v1</id>
    <updated>2013-12-13T16:52:07Z</updated>
    <published>2013-12-13T16:52:07Z</published>
    <title>Eugene Garfield, Francis Narin, and PageRank: The Theoretical Bases of
  the Google Search Engine</title>
    <summary>  This paper presents a test of the validity of using Google Scholar to
evaluate the publications of researchers by comparing the premises on which its
search engine, PageRank, is based, to those of Garfield's theory of citation
indexing. It finds that the premises are identical and that PageRank and
Garfield's theory of citation indexing validate each other.
</summary>
    <author>
      <name>Stephen J. Bensman</name>
    </author>
    <link href="http://arxiv.org/abs/1312.3872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1270v1</id>
    <updated>2014-02-06T08:29:19Z</updated>
    <published>2014-02-06T08:29:19Z</published>
    <title>Vers une interface pour l enrichissement des requetes en arabe dans un
  systeme de recherche d information</title>
    <summary>  This presentation focuses on the automatic expansion of Arabic request using
morphological analyzer and Arabic Wordnet. The expanded request is sent to
Google.
</summary>
    <author>
      <name>Abderrahim Mohammed El Amine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, in French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CIIA'2009 : 2eme Conference Internationale sur Informatique et ses
  Applications, Saida - Algerie, 03 -04 Mai 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.1270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1842v1</id>
    <updated>2014-05-08T09:00:25Z</updated>
    <published>2014-05-08T09:00:25Z</published>
    <title>SocRecM: A Scalable Social Recommender Engine for Online Marketplaces</title>
    <summary>  In this paper, we present work-in-progress on SocRecM, a novel social
recommendation framework for online marketplaces. We demonstrate that SocRecM
is not only easy to integrate with existing Web technologies through a RESTful,
scalable and easy-to-extend service-based architecture but also reveal the
extent to which various social features and recommendation approaches are
useful in an online social marketplace environment.
</summary>
    <author>
      <name>Emanuel Lacic</name>
    </author>
    <author>
      <name>Dominik Kowald</name>
    </author>
    <author>
      <name>Christoph Trattner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.1842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2584v1</id>
    <updated>2014-05-11T21:05:28Z</updated>
    <published>2014-05-11T21:05:28Z</published>
    <title>Sentiment Analysis: A Survey</title>
    <summary>  Sentiment analysis (also known as opinion mining) refers to the use of
natural language processing, text analysis and computational linguistics to
identify and extract subjective information in source materials. Mining
opinions expressed in the user generated content is a challenging yet
practically very useful problem. This survey would cover various approaches and
methodology used in Sentiment Analysis and Opinion Mining in general. The focus
would be on Internet text like, Product review, tweets and other social media.
</summary>
    <author>
      <name>Rahul Tejwani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University at Buffalo</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1405.2584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0296v1</id>
    <updated>2014-06-02T09:00:01Z</updated>
    <published>2014-06-02T09:00:01Z</published>
    <title>Using Mobile Agents for Information Retrival in B2B Systems</title>
    <summary>  This paper presents an architecture of an information retrieval system that
use the advantages offered by mobile agents to collect information from
different sources and bring the result to the calling user. Mobile agent
technology will be used for determine the traceability of a product and also
for searching information about a specific entity.
</summary>
    <author>
      <name>Felicia Florentina Giza</name>
    </author>
    <author>
      <name>Cristina Elena Turcu</name>
    </author>
    <author>
      <name>Ovidiu Andrei Schipor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, in Romanian</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2022v1</id>
    <updated>2014-06-08T20:05:36Z</updated>
    <published>2014-06-08T20:05:36Z</published>
    <title>Two-dimensional Sentiment Analysis of text</title>
    <summary>  Sentiment Analysis aims to get the underlying viewpoint of the text, which
could be anything that holds a subjective opinion, such as an online review,
Movie rating, Comments on Blog posts etc. This paper presents a novel approach
that classify text in two-dimensional Emotional space, based on the sentiments
of the author. The approach uses existing lexical resources to extract feature
set, which is trained using Supervised Learning techniques.
</summary>
    <author>
      <name>Rahul Tejwani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University at Buffalo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">sentiment analysis, two-dimensional</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.2022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7357v1</id>
    <updated>2014-07-28T09:00:57Z</updated>
    <published>2014-07-28T09:00:57Z</published>
    <title>Text Classification Using Association Rules, Dependency Pruning and
  Hyperonymization</title>
    <summary>  We present new methods for pruning and enhancing item- sets for text
classification via association rule mining. Pruning methods are based on
dependency syntax and enhancing methods are based on replacing words by their
hyperonyms of various orders. We discuss the impact of these methods, compared
to pruning based on tfidf rank of words.
</summary>
    <author>
      <name>Yannis Haralambous</name>
    </author>
    <author>
      <name>Philippe Lenca</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 2 figures, presented at DMNLP 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1260v1</id>
    <updated>2014-08-06T12:36:23Z</updated>
    <published>2014-08-06T12:36:23Z</published>
    <title>Unstable markup: A template-based information extraction from web sites
  with unstable markup</title>
    <summary>  This paper presents results of a work on crawling CEUR Workshop proceedings
web site to a Linked Open Data (LOD) dataset in the framework of ESWC 2014
Semantic Publishing Challenge 2014. Our approach is based on using an
extensible template-dependent crawler and DBpedia for linking extracted
entities, such as the names of universities and countries.
</summary>
    <author>
      <name>Maxim Kolchin</name>
    </author>
    <author>
      <name>Fedor Kozlov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ESWC 2014 Semantic Publishing Challenge, Task 1</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04920v1</id>
    <updated>2015-01-20T19:01:20Z</updated>
    <published>2015-01-20T19:01:20Z</published>
    <title>Regroupement sémantique de définitions en espagnol</title>
    <summary>  This article focuses on the description and evaluation of a new unsupervised
learning method of clustering of definitions in Spanish according to their
semantic. Textual Energy was used as a clustering measure, and we study an
adaptation of the Precision and Recall to evaluate our method.
</summary>
    <author>
      <name>Gerardo Sierra</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Alejandro Molina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, in French, 5 figures. Workshop Evaluation des m\'ethodes
  d'Extraction de Connaissances dans les Donn\'ees EvalECD EGC'10, 2010 Tunis</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.04920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07754v1</id>
    <updated>2016-01-28T13:43:30Z</updated>
    <published>2016-01-28T13:43:30Z</published>
    <title>Deep Learning Based Semantic Video Indexing and Retrieval</title>
    <summary>  We share the implementation details and testing results for video retrieval
system based exclusively on features extracted by convolutional neural
networks. We show that deep learned features might serve as universal signature
for semantic content of video useful in many search and retrieval tasks. We
further show that graph-based storage structure for video index allows to
efficiently retrieving the content with complicated spatial and temporal search
queries.
</summary>
    <author>
      <name>Anna Podlesnaya</name>
    </author>
    <author>
      <name>Sergey Podlesnyy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.07754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03176v1</id>
    <updated>2016-09-11T15:59:35Z</updated>
    <published>2016-09-11T15:59:35Z</published>
    <title>E3 : Keyphrase based News Event Exploration Engine</title>
    <summary>  This paper presents a novel system E3 for extracting keyphrases from news
content for the purpose of offering the news audience a broad overview of news
events, with especially high content volume. Given an input query, E3 extracts
keyphrases and enrich them by tagging, ranking and finding role for frequently
associated keyphrases. Also, E3 finds the novelty and activeness of keyphrases
using news publication date, to identify the most interesting and informative
keyphrases.
</summary>
    <author>
      <name>Nikita Jain</name>
    </author>
    <author>
      <name>Swati Gupta</name>
    </author>
    <author>
      <name>Dhaval Patel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2914586.2914611</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2914586.2914611" rel="related"/>
    <link href="http://arxiv.org/abs/1609.03176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04292v1</id>
    <updated>2017-01-16T14:02:19Z</updated>
    <published>2017-01-16T14:02:19Z</published>
    <title>Semantic classifier approach to document classification</title>
    <summary>  In this paper we propose a new document classification method, bridging
discrepancies (so-called semantic gap) between the training set and the
application sets of textual data. We demonstrate its superiority over classical
text classification approaches, including traditional classifier ensembles. The
method consists in combining a document categorization technique with a single
classifier or a classifier ensemble (SEMCOM algorithm - Committee with Semantic
Categorizer).
</summary>
    <author>
      <name>Piotr Borkowski</name>
    </author>
    <author>
      <name>Krzysztof Ciesielski</name>
    </author>
    <author>
      <name>Mieczysław A. Kłopotek</name>
    </author>
    <link href="http://arxiv.org/abs/1701.04292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01845v1</id>
    <updated>2017-04-06T13:56:31Z</updated>
    <published>2017-04-06T13:56:31Z</published>
    <title>Report on TBAS 2012: Workshop on Task-Based and Aggregated Search</title>
    <summary>  The ECIR half-day workshop on Task-Based and Aggregated Search (TBAS) was
held in Barcelona, Spain on 1 April 2012. The program included a keynote talk
by Professor Jarvelin, six full paper presentations, two poster presentations,
and an interactive discussion among the approximately 25 participants. This
report overviews the aims and contents of the workshop and outlines the major
outcomes.
</summary>
    <author>
      <name>Birger Larsen</name>
    </author>
    <author>
      <name>Christina Lioma</name>
    </author>
    <author>
      <name>Arjen de Vries</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07757v1</id>
    <updated>2017-04-25T16:01:50Z</updated>
    <published>2017-04-25T16:01:50Z</published>
    <title>User Profile Based Research Paper Recommendation</title>
    <summary>  We design a recommender system for research papers based on topic-modeling.
The users feedback to the results is used to make the results more relevant the
next time they fire a query. The user's needs are understood by observing the
change in the themes that the user shows a preference for over time.
</summary>
    <author>
      <name>Harshita Sahijwani</name>
    </author>
    <author>
      <name>Sourish Dasgupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress. arXiv admin note: text overlap with
  arXiv:1611.04822</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.07757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.10261v2</id>
    <updated>2018-10-24T18:40:54Z</updated>
    <published>2018-08-29T15:24:33Z</published>
    <title>Centroid estimation based on symmetric KL divergence for Multinomial
  text classification problem</title>
    <summary>  We define a new method to estimate centroid for text classification based on
the symmetric KL-divergence between the distribution of words in training
documents and their class centroids. Experiments on several standard data sets
indicate that the new method achieves substantial improvements over the
traditional classifiers.
</summary>
    <author>
      <name>Jiangning Chen</name>
    </author>
    <author>
      <name>Heinrich Matzinger</name>
    </author>
    <author>
      <name>Haoyan Zhai</name>
    </author>
    <author>
      <name>Mi Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1808.10261v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.10261v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.06313v1</id>
    <updated>2018-10-15T12:41:25Z</updated>
    <published>2018-10-15T12:41:25Z</published>
    <title>Regret vs. Bandwidth Trade-off for Recommendation Systems</title>
    <summary>  We consider recommendation systems that need to operate under wireless
bandwidth constraints, measured as number of broadcast transmissions, and
demonstrate a (tight for some instances) tradeoff between regret and bandwidth
for two scenarios: the case of multi-armed bandit with context, and the case
where there is a latent structure in the message space that we can exploit to
reduce the learning phase.
</summary>
    <author>
      <name>Linqi Song</name>
    </author>
    <author>
      <name>Christina Fragouli</name>
    </author>
    <author>
      <name>Devavrat Shah</name>
    </author>
    <link href="http://arxiv.org/abs/1810.06313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.06313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.07368v1</id>
    <updated>2019-09-16T20:42:57Z</updated>
    <published>2019-09-16T20:42:57Z</published>
    <title>Document classification methods</title>
    <summary>  Information on different fields which are collected by users requires
appropriate management and organization to be structured in a standard way and
retrieved fast and more easily. Document classification is a conventional
method to separate text based on their subjects among scientific text, web
pages and digital library. Different methods and techniques are proposed for
document classifications that have advantages and deficiencies. In this paper,
several unsupervised and supervised document classification methods are studied
and compared.
</summary>
    <author>
      <name>Madjid Khalilian</name>
    </author>
    <author>
      <name>Shiva Hassanzadeh</name>
    </author>
    <link href="http://arxiv.org/abs/1909.07368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04453v2</id>
    <updated>2017-08-16T06:58:38Z</updated>
    <published>2017-06-14T12:47:36Z</published>
    <title>Hybrid Collaborative Recommendation via Semi-AutoEncoder</title>
    <summary>  In this paper, we present a novel structure, Semi-AutoEncoder, based on
AutoEncoder. We generalize it into a hybrid collaborative filtering model for
rating prediction as well as personalized top-n recommendations. Experimental
results on two real-world datasets demonstrate its state-of-the-art
performances.
</summary>
    <author>
      <name>Shuai Zhang</name>
    </author>
    <author>
      <name>Lina Yao</name>
    </author>
    <author>
      <name>Xiwei Xu</name>
    </author>
    <author>
      <name>Sen Wang</name>
    </author>
    <author>
      <name>Liming Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, ICONIP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.04453v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04453v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08928v1</id>
    <updated>2017-06-27T16:25:00Z</updated>
    <published>2017-06-27T16:25:00Z</published>
    <title>Classical Music Clustering Based on Acoustic Features</title>
    <summary>  In this paper we cluster 330 classical music pieces collected from MusicNet
database based on their musical note sequence. We use shingling and chord
trajectory matrices to create signature for each music piece and performed
spectral clustering to find the clusters. Based on different resolution, the
output clusters distinctively indicate composition from different classical
music era and different composing style of the musicians.
</summary>
    <author>
      <name>Xindi Wang</name>
    </author>
    <author>
      <name>Syed Arefinul Haque</name>
    </author>
    <link href="http://arxiv.org/abs/1706.08928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03496v1</id>
    <updated>2017-09-10T23:19:41Z</updated>
    <published>2017-09-10T23:19:41Z</published>
    <title>SweetRS: Dataset for a recommender systems of sweets</title>
    <summary>  Benchmarking recommender system and matrix completion algorithms could be
greatly simplified if the entire matrix was known. We built a \url{sweetrs.org}
platform with $77$ candies and sweets to rank. Over $2000$ users submitted over
$44000$ grades resulting in a matrix with $28\%$ coverage. In this report, we
give the full description of the environment and we benchmark the
\textsc{Soft-Impute} algorithm on the dataset.
</summary>
    <author>
      <name>Łukasz Kidziński</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.03496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05193v1</id>
    <updated>2017-09-14T07:24:08Z</updated>
    <published>2017-09-14T07:24:08Z</published>
    <title>Clustering of Musical Pieces through Complex Networks: an Assessment
  over Guitar Solos</title>
    <summary>  Musical pieces can be modeled as complex networks. This fosters innovative
ways to categorize music, paving the way towards novel applications in
multimedia domains, such as music didactics, multimedia entertainment and
digital music generation. Clustering these networks through their main metrics
allows grouping similar musical tracks. To show the viability of the approach,
we provide results on a dataset of guitar solos.
</summary>
    <author>
      <name>Stefano Ferretti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in IEEE Multimedia magazine</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.05193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.11372v1</id>
    <updated>2019-01-31T14:27:52Z</updated>
    <published>2019-01-31T14:27:52Z</published>
    <title>An InfoVis Tool for Interactive Component-Based Evaluation</title>
    <summary>  In this paper, we present an InfoVis tool based on Sankey diagrams for the
exploration of large combinatorial combinations of IR components - the Grid of
Points (GoP). The goal of this tool is to ease the comprehension of the
behavior of single IR components within fully functioning off-the-shelf IR
systems without recurring to complex statistical tools.
</summary>
    <author>
      <name>Giacomo Rocco</name>
    </author>
    <author>
      <name>Gianmaria Silvello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.11372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.11372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04032v1</id>
    <updated>2015-02-12T10:56:10Z</updated>
    <published>2015-02-12T10:56:10Z</published>
    <title>On Projection Based Operators in Lp space for Exact Similarity Search</title>
    <summary>  We investigate exact indexing for high dimensional Lp norms based on the
1-Lipschitz property and projection operators. The orthogonal projection that
satisfies the 1-Lipschitz property for the Lp norm is described. The adaptive
projection defined by the first principal component is introduced.
</summary>
    <author>
      <name>Andreas Wichert</name>
    </author>
    <author>
      <name>Catarina Moreira</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3233/FI-2015-1166</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3233/FI-2015-1166" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fundamenta Informaticae: Annales Societatis Mathematicae Polonae,
  136: 1-14, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.04032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04163v1</id>
    <updated>2015-02-14T03:23:53Z</updated>
    <published>2015-02-14T03:23:53Z</published>
    <title>A Distributional Representation Model For Collaborative Filtering</title>
    <summary>  In this paper, we propose a very concise deep learning approach for
collaborative filtering that jointly models distributional representation for
users and items. The proposed framework obtains better performance when
compared against current state-of-art algorithms and that made the
distributional representation model a promising direction for further research
in the collaborative filtering.
</summary>
    <author>
      <name>Zhang Junlin</name>
    </author>
    <author>
      <name>Cai Heng</name>
    </author>
    <author>
      <name>Huang Tongwen</name>
    </author>
    <author>
      <name>Xue Huiping</name>
    </author>
    <link href="http://arxiv.org/abs/1502.04163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06646v3</id>
    <updated>2015-06-28T14:13:03Z</updated>
    <published>2015-05-25T14:39:09Z</published>
    <title>A Survey on Retrieval of Mathematical Knowledge</title>
    <summary>  We present a short survey of the literature on indexing and retrieval of
mathematical knowledge, with pointers to 72 papers and tentative taxonomies of
both retrieval problems and recurring techniques.
</summary>
    <author>
      <name>F. Guidi</name>
    </author>
    <author>
      <name>C. Sacerdoti Coen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CICM 2015, 20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.06646v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06646v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08420v1</id>
    <updated>2016-04-28T14:01:54Z</updated>
    <published>2016-04-28T14:01:54Z</published>
    <title>Matrix Factorization Method for Decentralized Recommender Systems</title>
    <summary>  Decentralized recommender system does not rely on the central service
provider, and the users can keep the ownership of their ratings. This article
brings the theoretically well-studied matrix factorization method into the
decentralized recommender system, where the formerly prevalent algorithms are
heuristic and hence lack of theoretical guarantee. Our preliminary simulation
results show that this method is promising.
</summary>
    <author>
      <name>Wenjie Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03066v1</id>
    <updated>2016-06-09T18:58:51Z</updated>
    <published>2016-06-09T18:58:51Z</published>
    <title>The Effects of Latency Penalties in Evaluating Push Notification Systems</title>
    <summary>  We examine the effects of different latency penalties in the evaluation of
push notification systems, as operationalized in the TREC 2015 Microblog track
evaluation. The purpose of this study is to inform the design of metrics for
the TREC 2016 Real-Time Summarization track, which is largely modeled after the
TREC 2015 evaluation design.
</summary>
    <author>
      <name>Luchen Tan</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <author>
      <name>Adam Roegiest</name>
    </author>
    <author>
      <name>Charles L. A. Clarke</name>
    </author>
    <link href="http://arxiv.org/abs/1606.03066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04223v1</id>
    <updated>2016-06-14T07:19:08Z</updated>
    <published>2016-06-14T07:19:08Z</published>
    <title>Learning Term Weights for Ad-hoc Retrieval</title>
    <summary>  Most Information Retrieval models compute the relevance score of a document
for a given query by summing term weights specific to a document or a query.
Heuristic approaches, like TF-IDF, or probabilistic models, like BM25, are used
to specify how a term weight is computed. In this paper, we propose to leverage
learning-to-rank principles to learn how to compute a term weight for a given
document based on the term occurrence pattern.
</summary>
    <author>
      <name>B. Piwowarski</name>
    </author>
    <link href="http://arxiv.org/abs/1606.04223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03316v1</id>
    <updated>2016-12-10T16:33:06Z</updated>
    <published>2016-12-10T16:33:06Z</published>
    <title>Label Visualization and Exploration in IR</title>
    <summary>  There is a renaissance in visual analytics systems for data analysis and
sharing, in particular, in the current wave of big data applications. We
introduce RAVE, a prototype that automates the generation of an interface that
uses facets and visualization techniques for exploring and analyzing relevance
assessments data sets collected via crowdsourcing. We present a technical
description of the main components and demonstrate its use.
</summary>
    <author>
      <name>Omar Alonso</name>
    </author>
    <link href="http://arxiv.org/abs/1612.03316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.05667v1</id>
    <updated>2018-03-15T10:04:27Z</updated>
    <published>2018-03-15T10:04:27Z</published>
    <title>A Study of Recent Contributions on Information Extraction</title>
    <summary>  This paper reports on modern approaches in Information Extraction (IE) and
its two main sub-tasks of Named Entity Recognition (NER) and Relation
Extraction (RE). Basic concepts and the most recent approaches in this area are
reviewed, which mainly include Machine Learning (ML) based approaches and the
more recent trend to Deep Learning (DL) based methods.
</summary>
    <author>
      <name>Parisa Naderi Golshan</name>
    </author>
    <author>
      <name>HosseinAli Rahmani Dashti</name>
    </author>
    <author>
      <name>Shahrzad Azizi</name>
    </author>
    <author>
      <name>Leila Safari</name>
    </author>
    <link href="http://arxiv.org/abs/1803.05667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.05667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.11814v1</id>
    <updated>2018-05-30T05:32:02Z</updated>
    <published>2018-05-30T05:32:02Z</published>
    <title>The VIREO KIS at VBS 2018</title>
    <summary>  This short paper presents the video browsing tool of VIREO team which has
been used in the Video Browser Showdown 2018. All added functions in the final
version are introduced and experiences gained from the benchmark are also
shared.
</summary>
    <author>
      <name>Phuong Anh Nguyen</name>
    </author>
    <author>
      <name>Yi-Jie Lu</name>
    </author>
    <author>
      <name>Hao Zhang</name>
    </author>
    <author>
      <name>Chong-Wah Ngo</name>
    </author>
    <link href="http://arxiv.org/abs/1805.11814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.11814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.03137v2</id>
    <updated>2020-08-10T13:13:56Z</updated>
    <published>2020-07-07T00:14:30Z</published>
    <title>Predicting Afrobeats Hit Songs Using Spotify Data</title>
    <summary>  This study approached the Hit Song Science problem with the aim of predicting
which songs in the Afrobeats genre will become popular among Spotify listeners.
A dataset of 2063 songs was generated through the Spotify Web API, with the
provided audio features. Random Forest and Gradient Boosting algorithms proved
to be successful with approximately F1 scores of 86%.
</summary>
    <author>
      <name>Adewale Adeagbo</name>
    </author>
    <link href="http://arxiv.org/abs/2007.03137v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.03137v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.05686v2</id>
    <updated>2021-10-25T09:54:03Z</updated>
    <published>2021-04-26T18:33:38Z</published>
    <title>Yes, BM25 is a Strong Baseline for Legal Case Retrieval</title>
    <summary>  We describe our single submission to task 1 of COLIEE 2021. Our vanilla BM25
got second place, well above the median of submissions. Code is available at
https://github.com/neuralmind-ai/coliee.
</summary>
    <author>
      <name>Guilherme Moraes Rosa</name>
    </author>
    <author>
      <name>Ruan Chaves Rodrigues</name>
    </author>
    <author>
      <name>Roberto Lotufo</name>
    </author>
    <author>
      <name>Rodrigo Nogueira</name>
    </author>
    <link href="http://arxiv.org/abs/2105.05686v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.05686v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.04009v1</id>
    <updated>2017-05-11T04:22:58Z</updated>
    <published>2017-05-11T04:22:58Z</published>
    <title>A survey of Community Question Answering</title>
    <summary>  With the advent of numerous community forums, tasks associated with the same
have gained importance in the recent past. With the influx of new questions
every day on these forums, the issues of identifying methods to find answers to
said questions, or even trying to detect duplicate questions, are of practical
importance and are challenging in their own right. This paper aims at surveying
some of the aforementioned issues, and methods proposed for tackling the same.
</summary>
    <author>
      <name>Barun Patra</name>
    </author>
    <link href="http://arxiv.org/abs/1705.04009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.04009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.03597v1</id>
    <updated>2018-02-10T14:18:51Z</updated>
    <published>2018-02-10T14:18:51Z</published>
    <title>Document Classification Using Distributed Machine Learning</title>
    <summary>  In this paper, we investigate the performance and success rates of Na\"ive
Bayes Classification Algorithm for automatic classification of Turkish news
into predetermined categories like economy, life, health etc. We use Apache Big
Data technologies such as Hadoop, HDFS, Spark and Mahout, and apply these
distributed technologies to Machine Learning.
</summary>
    <author>
      <name>Galip Aydin</name>
    </author>
    <author>
      <name>Ibrahim Riza Hallac</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.15224/978-1-63248-044-6-129</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.15224/978-1-63248-044-6-129" rel="related"/>
    <link href="http://arxiv.org/abs/1802.03597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.03597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.08988v1</id>
    <updated>2018-02-25T11:15:31Z</updated>
    <published>2018-02-25T11:15:31Z</published>
    <title>Deep Neural Network for Learning to Rank Query-Text Pairs</title>
    <summary>  This paper considers the problem of document ranking in information retrieval
systems by Learning to Rank. We propose ConvRankNet combining a Siamese
Convolutional Neural Network encoder and the RankNet ranking model which could
be trained in an end-to-end fashion. We prove a general result justifying the
linear test-time complexity of pairwise Learning to Rank approach. Experiments
on the OHSUMED dataset show that ConvRankNet outperforms systematically
existing feature-based models.
</summary>
    <author>
      <name>Baoyang Song</name>
    </author>
    <link href="http://arxiv.org/abs/1802.08988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.08988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.00257v1</id>
    <updated>2018-07-01T02:36:24Z</updated>
    <published>2018-07-01T02:36:24Z</published>
    <title>Information Retrieval in the Cloud</title>
    <summary>  There has been a recent trend to migrate IT infrastructure into the cloud. In
this paper, we discuss the impact of this trend on searching for textual and
other data, i.e. the distributed indexing and retrieval of information, from an
organizational context.
  Keywords: information retrieval (IR); federated search; cloud search.
</summary>
    <author>
      <name>Jochen L. Leidner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.00257v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.00257v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.0; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.03736v1</id>
    <updated>2020-03-08T07:15:48Z</updated>
    <published>2020-03-08T07:15:48Z</published>
    <title>DeepLENS: Deep Learning for Entity Summarization</title>
    <summary>  Entity summarization has been a prominent task over knowledge graphs. While
existing methods are mainly unsupervised, we present DeepLENS, a simple yet
effective deep learning model where we exploit textual semantics for encoding
triples and we score each candidate triple based on its interdependence on
other triples. DeepLENS significantly outperformed existing methods on a public
benchmark.
</summary>
    <author>
      <name>Qingxia Liu</name>
    </author>
    <author>
      <name>Gong Cheng</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, submitted to DL4KG 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.02620v1</id>
    <updated>2020-03-29T04:03:56Z</updated>
    <published>2020-03-29T04:03:56Z</published>
    <title>Grouping headlines</title>
    <summary>  In this work we deal with the problem of grouping in headlines of the
newspaper ABC (Australian Bro-adcasting Corporation) using unsupervised machine
learning techniques. We present and discuss the results on the clusters found
</summary>
    <author>
      <name>Ciro Javier Diaz Penedo</name>
    </author>
    <author>
      <name>Lucas Leonardo Silveira Costa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Portuguese</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.02620v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.02620v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.00468v1</id>
    <updated>2020-05-01T16:03:37Z</updated>
    <published>2020-05-01T16:03:37Z</published>
    <title>Automatic Discourse Segmentation: Review and Perspectives</title>
    <summary>  Multilingual discourse parsing is a very prominent research topic. The first
stage for discourse parsing is discourse segmentation. The study reported in
this article addresses a review of two on-line available discourse segmenters
(for English and Portuguese). We evaluate the possibility of developing similar
discourse segmenters for Spanish, French and African languages.
</summary>
    <author>
      <name>Iria da Cunha</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on African Human Language Technologies.
  17-20 Jan 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2005.00468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.00468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01263v1</id>
    <updated>2019-05-03T16:38:05Z</updated>
    <published>2019-05-03T16:38:05Z</published>
    <title>A Personalized Subreddit Recommendation Engine</title>
    <summary>  This paper aims to improve upon the generic recommendations that Reddit
provides for its users. We propose a novel personalized recommender system that
learns from both, the presence and the content of user-subreddit interaction,
using implicit and explicit signals to provide robust recommendations.
</summary>
    <author>
      <name>Abhishek K Das</name>
    </author>
    <author>
      <name>Nikhil Bhat</name>
    </author>
    <author>
      <name>Sukanto Guha</name>
    </author>
    <author>
      <name>Janvi Palan</name>
    </author>
    <link href="http://arxiv.org/abs/1905.01263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.00419v1</id>
    <updated>2019-07-31T09:07:13Z</updated>
    <published>2019-07-31T09:07:13Z</published>
    <title>Sudden Death: A New Way to Compare Recommendation Diversification</title>
    <summary>  This paper describes problems with the current way we compare the diversity
of different recommendation lists in offline experiments. We illustrate the
problems with a case study. We propose the Sudden Death score as a new and
better way of making these comparisons.
</summary>
    <author>
      <name>Derek Bridge</name>
    </author>
    <author>
      <name>Mesut Kaya</name>
    </author>
    <author>
      <name>Pablo Castells</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.00419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01447v1</id>
    <updated>2020-02-04T18:20:06Z</updated>
    <published>2020-02-04T18:20:06Z</published>
    <title>A Prototype of Serverless Lucene</title>
    <summary>  This paper describes a working prototype that adapts Lucene, the world's most
popular and most widely deployed open-source search library, to operate within
a serverless environment in the cloud. Although the serverless search concept
is not new, this work represents a substantial improvement over a previous
implementation in eliminating most custom code and in enabling interactive
search. While there remain limitations to the design, it nevertheless
challenges conventional thinking about search architectures for particular
operating points.
</summary>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.01447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.00811v1</id>
    <updated>2021-10-02T14:29:50Z</updated>
    <published>2021-10-02T14:29:50Z</published>
    <title>Multiversal Simulacra: Understanding Hypotheticals and Possible Worlds
  Through Simulation</title>
    <summary>  Recommender systems research is concerned with many aspects of recommender
system behavior and effects than simply its effectiveness, and simulation can
be a powerful tool for uncovering these effects. In this brief position paper,
I identify specific types of research that simulation is uniquely well-suited
to address along with a hierarchy of simulation types.
</summary>
    <author>
      <name>Michael D. Ekstrand</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contribution to the SimuRec Workshop at RecSys 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2110.00811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.00811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.03039v1</id>
    <updated>2021-10-06T19:54:55Z</updated>
    <published>2021-10-06T19:54:55Z</published>
    <title>Optimized Recommender Systems with Deep Reinforcement Learning</title>
    <summary>  Recommender Systems have been the cornerstone of online retailers.
Traditionally they were based on rules, relevance scores, ranking algorithms,
and supervised learning algorithms, but now it is feasible to use reinforcement
learning algorithms to generate meaningful recommendations. This work
investigates and develops means to setup a reproducible testbed, and evaluate
different state of the art algorithms in a realistic environment. It entails a
proposal, literature review, methodology, results, and comments.
</summary>
    <author>
      <name>Lucas Farris</name>
    </author>
    <link href="http://arxiv.org/abs/2110.03039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.03039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.04037v1</id>
    <updated>2021-10-08T11:14:44Z</updated>
    <published>2021-10-08T11:14:44Z</published>
    <title>Simulations for novel problems in recommendation: analyzing
  misinformation and data characteristics</title>
    <summary>  In this position paper, we discuss recent applications of simulation
approaches for recommender systems tasks. In particular, we describe how they
were used to analyze the problem of misinformation spreading and understand
which data characteristics affect the performance of recommendation algorithms
more significantly. We also present potential lines of future work where
simulation methods could advance the work in the recommendation community.
</summary>
    <author>
      <name>Alejandro Bellogín</name>
    </author>
    <author>
      <name>Yashar Deldjoo</name>
    </author>
    <link href="http://arxiv.org/abs/2110.04037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.04037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.6580v1</id>
    <updated>2013-02-26T20:55:42Z</updated>
    <published>2013-02-26T20:55:42Z</published>
    <title>Finding the Right Set of Users: Generalized Constraints for Group
  Recommendations</title>
    <summary>  Recently, group recommendations have attracted considerable attention. Rather
than recommending items to individual users, group recommenders recommend items
to groups of users. In this position paper, we introduce the problem of forming
an appropriate group of users to recommend an item when constraints apply to
the members of the group. We present a formal model of the problem and an
algorithm for its solution. Finally, we identify several directions for future
work.
</summary>
    <author>
      <name>Kostas Stefanidis</name>
    </author>
    <author>
      <name>Evaggelia Pitoura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PersDB 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.6580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.6580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05781v1</id>
    <updated>2015-03-19T14:31:28Z</updated>
    <published>2015-03-19T14:31:28Z</published>
    <title>Memantic: A Medical Knowledge Discovery Engine</title>
    <summary>  We present a system that constructs and maintains an up-to-date co-occurrence
network of medical concepts based on continuously mining the latest biomedical
literature. Users can explore this network visually via a concise online
interface to quickly discover important and novel relationships between medical
entities. This enables users to rapidly gain contextual understanding of their
medical topics of interest, and we believe this constitutes a significant user
experience improvement over contemporary search engines operating in the
biomedical literature domain.
</summary>
    <author>
      <name>Alexei Yavlinsky</name>
    </author>
    <link href="http://arxiv.org/abs/1503.05781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.01901v1</id>
    <updated>2016-10-06T15:04:10Z</updated>
    <published>2016-10-06T15:04:10Z</published>
    <title>Discriminative Information Retrieval for Knowledge Discovery</title>
    <summary>  We propose a framework for discriminative Information Retrieval (IR) atop
linguistic features, trained to improve the recall of tasks such as answer
candidate passage retrieval, the initial step in text-based Question Answering
(QA). We formalize this as an instance of linear feature-based IR (Metzler and
Croft, 2007), illustrating how a variety of knowledge discovery tasks are
captured under this approach, leading to a 44% improvement in recall for
candidate triage for QA.
</summary>
    <author>
      <name>Tongfei Chen</name>
    </author>
    <author>
      <name>Benjamin Van Durme</name>
    </author>
    <link href="http://arxiv.org/abs/1610.01901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.01901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.03846v1</id>
    <updated>2019-03-09T18:33:55Z</updated>
    <published>2019-03-09T18:33:55Z</published>
    <title>The Web is missing an essential part of infrastructure: an Open Web
  Index</title>
    <summary>  A proposal for building an index of the Web that separates the infrastructure
part of the search engine - the index - from the services part that will form
the basis for myriad search engines and other services utilizing Web data on
top of a public infrastructure open to everyone.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <link href="http://arxiv.org/abs/1903.03846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.03846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.04638v1</id>
    <updated>2019-03-11T22:38:59Z</updated>
    <published>2019-03-11T22:38:59Z</published>
    <title>Challenges in Search on Streaming Services: Netflix Case Study</title>
    <summary>  We discuss salient challenges of building a search experience for a streaming
media service such as Netflix. We provide an overview of the role of
recommendations within the search context to aid content discovery and support
searches for unavailable (out-of-catalog) entities. We also stress the
importance of keystroke-level instant search experience, and the technical
challenges associated with implementing it across different devices and
languages for a global audience.
</summary>
    <author>
      <name>Sudarshan Lamkhede</name>
    </author>
    <author>
      <name>Sudeep Das</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.04638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.04638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08010v1</id>
    <updated>2019-04-16T23:16:56Z</updated>
    <published>2019-04-16T23:16:56Z</published>
    <title>How to define co-occurrence in different domains of study?</title>
    <summary>  This position paper presents a comparative study of co-occurrences. Some
similarities and differences in the definition exist depending on the research
domain (e.g. linguistics, NLP, computer science). This paper discusses these
points, and deals with the methodological aspects in order to identify
co-occurrences in a multidisciplinary paradigm.
</summary>
    <author>
      <name>Mathieu Roche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CICLING'2018 (International Conference on Computational Linguistics
  and Intelligent Text Processing) - March 18 to 24, 2018 - Hanoi, Vietnam (not
  published in CICLING proceedings)</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.08010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.08754v1</id>
    <updated>2019-04-18T13:16:53Z</updated>
    <published>2019-04-18T13:16:53Z</published>
    <title>A Progressive Visual Analytics Tool for Incremental Experimental
  Evaluation</title>
    <summary>  This paper presents a visual tool, AVIATOR, that integrates the progressive
visual analytics paradigm in the IR evaluation process. This tool serves to
speed-up and facilitate the performance assessment of retrieval models enabling
a result analysis through visual facilities. AVIATOR goes one step beyond the
common "compute wait visualize" analytics paradigm, introducing a continuous
evaluation mechanism that minimizes human and computational resource
consumption.
</summary>
    <author>
      <name>Fabio Giachelle</name>
    </author>
    <author>
      <name>Gianmaria Silvello</name>
    </author>
    <link href="http://arxiv.org/abs/1904.08754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.05986v1</id>
    <updated>2019-06-14T02:28:55Z</updated>
    <published>2019-06-14T02:28:55Z</published>
    <title>Scalable Knowledge Graph Construction from Twitter</title>
    <summary>  We describe a knowledge graph derived from Twitter data with the goal of
discovering relationships between people, links, and topics. The goal is to
filter out noise from Twitter and surface an inside-out view that relies on
high quality content. The generated graph contains many relationships where the
user can query and traverse the structure from different angles allowing the
development of new applications.
</summary>
    <author>
      <name>Omar Alonso</name>
    </author>
    <author>
      <name>Vasileios Kandylas</name>
    </author>
    <author>
      <name>Serge-Eric Tremblay</name>
    </author>
    <link href="http://arxiv.org/abs/1906.05986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.08092v2</id>
    <updated>2019-08-20T13:23:17Z</updated>
    <published>2019-06-19T13:35:41Z</published>
    <title>A survey of OpenRefine reconciliation services</title>
    <summary>  We review the services implementing the OpenRefine reconciliation API,
comparing their design to the state of the art in record linkage. Due to the
design of the API, the matching scores returned by the services are of little
help to guide matching decisions. This suggests possible improvements to the
specifications of the API, which could improve user workflows by giving more
control over the scoring mechanism to the client.
</summary>
    <author>
      <name>Antonin Delpeuch</name>
    </author>
    <link href="http://arxiv.org/abs/1906.08092v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.08092v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.04919v1</id>
    <updated>2019-06-18T23:42:23Z</updated>
    <published>2019-06-18T23:42:23Z</published>
    <title>Interactive Topic Modeling with Anchor Words</title>
    <summary>  The formalism of anchor words has enabled the development of fast topic
modeling algorithms with provable guarantees. In this paper, we introduce a
protocol that allows users to interact with anchor words to build customized
and interpretable topic models. Experimental evidence validating the usefulness
of our approach is also presented.
</summary>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <author>
      <name>Stefanos Poulis</name>
    </author>
    <author>
      <name>Christopher Tosh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at 2019 ICML Workshop on Human in the Loop Learning (HILL
  2019), Long Beach, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.04919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.14005v1</id>
    <updated>2020-12-27T20:00:08Z</updated>
    <published>2020-12-27T20:00:08Z</published>
    <title>Neural document expansion for ad-hoc information retrieval</title>
    <summary>  Recently, Nogueira et al. [2019] proposed a new approach to document
expansion based on a neural Seq2Seq model, showing significant improvement on
short text retrieval task. However, this approach needs a large amount of
in-domain training data. In this paper, we show that this neural document
expansion approach can be effectively adapted to standard IR tasks, where
labels are scarce and many long documents are present.
</summary>
    <author>
      <name>Cheng Tang</name>
    </author>
    <author>
      <name>Andrew Arnold</name>
    </author>
    <link href="http://arxiv.org/abs/2012.14005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.14005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.05700v1</id>
    <updated>2021-02-10T19:14:01Z</updated>
    <published>2021-02-10T19:14:01Z</published>
    <title>ELSKE: Efficient Large-Scale Keyphrase Extraction</title>
    <summary>  Keyphrase extraction methods can provide insights into large collections of
documents such as social media posts. Existing methods, however, are less
suited for the real-time analysis of streaming data, because they are
computationally too expensive or require restrictive constraints regarding the
structure of keyphrases. We propose an efficient approach to extract keyphrases
from large document collections and show that the method also performs
competitively on individual documents.
</summary>
    <author>
      <name>Johannes Knittel</name>
    </author>
    <author>
      <name>Steffen Koch</name>
    </author>
    <author>
      <name>Thomas Ertl</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3469096.3474930</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3469096.3474930" rel="related"/>
    <link href="http://arxiv.org/abs/2102.05700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.05700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.11687v1</id>
    <updated>2022-06-23T13:26:00Z</updated>
    <published>2022-06-23T13:26:00Z</published>
    <title>Taking snapshots from a stream</title>
    <summary>  This work is devoted to a certain class of probabilistic snapshots for
elements of the observed data stream. We show you how one can control their
probabilistic properties and we show some potential applications. Our solution
can be used to store information from the observed history with limited memory.
It can be used for both web server applications and Ad hoc networks and, for
example, for automatic taking snapshots from video stream online of unknown
size.
</summary>
    <author>
      <name>Dominik Bojko</name>
    </author>
    <author>
      <name>Jacek Cichoń</name>
    </author>
    <link href="http://arxiv.org/abs/2206.11687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.11687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.11384v1</id>
    <updated>2022-08-24T09:02:33Z</updated>
    <published>2022-08-24T09:02:33Z</published>
    <title>Matching Theory-based Recommender Systems in Online Dating</title>
    <summary>  Online dating platforms provide people with the opportunity to find a
partner. Recommender systems in online dating platforms suggest one side of
users to the other side of users. We discuss the potential interactions between
reciprocal recommender systems (RRSs) and matching theory. We present our
ongoing project to deploy a matching theory-based recommender system (MTRS) in
a real-world online dating platform.
</summary>
    <author>
      <name>Yoji Tomita</name>
    </author>
    <author>
      <name>Riku Togashi</name>
    </author>
    <author>
      <name>Daisuke Moriwaki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3523227.3547406</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3523227.3547406" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as RecSys'22 Industrial Talk Poster</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.11384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.11384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.03941v1</id>
    <updated>2022-09-08T17:29:18Z</updated>
    <published>2022-09-08T17:29:18Z</published>
    <title>The Users Aren't Alright: Dangerous Mental Illness Behaviors and
  Recommendations</title>
    <summary>  In this paper, we argue that recommendation systems are in a unique position
to propagate dangerous and cruel behaviors to people with mental illnesses.
</summary>
    <author>
      <name>Ashlee Milton</name>
    </author>
    <author>
      <name>Stevie Chancellor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 5th FAccTRec Workshop: Responsible Recommendation
  (https://facctrec.github.io/facctrec2022/) -- Workshop co-located with the
  16th ACM Conference on Recommender Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.03941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.03941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.00767v1</id>
    <updated>2022-10-03T08:55:24Z</updated>
    <published>2022-10-03T08:55:24Z</published>
    <title>Unsupervised Search Algorithm Configuration using Query Performance
  Prediction</title>
    <summary>  Search engine configuration can be quite difficult for inexpert developers.
Instead, an auto-configuration approach can be used to speed up development
time. Yet, such an automatic process usually requires relevance labels to train
a supervised model. In this work, we suggest a simple solution based on query
performance prediction that requires no relevance labels but only a sample of
queries in a given domain. Using two example usecases we demonstrate the merits
of our solution.
</summary>
    <author>
      <name>Haggai Roitman</name>
    </author>
    <link href="http://arxiv.org/abs/2210.00767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.00767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.03404v1</id>
    <updated>2022-10-07T08:51:20Z</updated>
    <published>2022-10-07T08:51:20Z</published>
    <title>Quantifying Political Bias in News Articles</title>
    <summary>  Search bias analysis is getting more attention in recent years since search
results could affect In this work, we aim to establish an automated model for
evaluating ideological bias in online news articles. The dataset is composed of
news articles in search results as well as the newspaper articles. The current
automated model results show that model capability is not sufficient to be
exploited for annotating the documents automatically, thereby computing bias in
search results.
</summary>
    <author>
      <name>Gizem Gezici</name>
    </author>
    <link href="http://arxiv.org/abs/2210.03404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.03404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.07089v2</id>
    <updated>2023-02-03T21:07:10Z</updated>
    <published>2022-10-13T15:14:30Z</published>
    <title>Experimenting with Selected Automated Approaches for Bias Analysis</title>
    <summary>  This work first presents our attempts to establish an automated model using
state-of-the-art approaches for analysing bias in search results of Bing and
Google. Experimental results indicate that the current class-wise F1-scores of
our best model are not sufficient to establish an automated model for bias
analysis. Thus, we decided not to continue with this approach.
</summary>
    <author>
      <name>Gizem Gezici</name>
    </author>
    <link href="http://arxiv.org/abs/2210.07089v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.07089v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.15142v1</id>
    <updated>2022-10-27T03:03:12Z</updated>
    <published>2022-10-27T03:03:12Z</published>
    <title>Taxonomic Recommendations of Real Estate Properties with Textual
  Attribute Information</title>
    <summary>  In this extended abstract, we present an end to end approach for building a
taxonomy of home attribute terms that enables hierarchical recommendations of
real estate properties. We cover the methodology for building a real-estate
taxonomy, metrics for measuring this structure's quality, and then conclude
with a production use-case of making recommendations from search keywords at
different levels of topical similarity.
</summary>
    <author>
      <name>Zachary Harrison</name>
    </author>
    <author>
      <name>Anish Khazane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Sixteenth ACM Conference on Recommender Systems (RecSys 2022)</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.15142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.15142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.02894v1</id>
    <updated>2022-11-05T12:37:47Z</updated>
    <published>2022-11-05T12:37:47Z</published>
    <title>Deep Factorization Model for Robust Recommendation</title>
    <summary>  Recently, malevolent user hacking has become a huge problem for real-world
companies. In order to learn predictive models for recommender systems,
factorization techniques have been developed to deal with user-item ratings. In
this paper, we suggest a broad architecture of a factorization model with
adversarial training to get over these issues. The effectiveness of our systems
is demonstrated by experimental findings on real-world datasets.
</summary>
    <author>
      <name>Li Wang</name>
    </author>
    <author>
      <name>Qiang Zhao</name>
    </author>
    <author>
      <name>Wei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2211.02894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.02894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.16780v1</id>
    <updated>2023-03-25T23:56:23Z</updated>
    <published>2023-03-25T23:56:23Z</published>
    <title>Thistle: A Vector Database in Rust</title>
    <summary>  We present Thistle, a fully functional vector database. Thistle is an entry
into the domain of latent knowledge use in answering search queries, an ongoing
research topic at both start-ups and search engine companies. We implement
Thistle with several well-known algorithms, and benchmark results on the MS
MARCO dataset. Results help clarify the latent knowledge domain as well as the
growing Rust ML ecosystem.
</summary>
    <author>
      <name>Brad Windsor</name>
    </author>
    <author>
      <name>Kevin Choi</name>
    </author>
    <link href="http://arxiv.org/abs/2303.16780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.16780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.18305v1</id>
    <updated>2023-05-12T11:05:59Z</updated>
    <published>2023-05-12T11:05:59Z</published>
    <title>High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits</title>
    <summary>  We develop a novel latent-bandit algorithm for tackling the cold-start
problem for new users joining a recommender system. This new algorithm
significantly outperforms the state of the art, simultaneously achieving both
higher accuracy and lower regret.
</summary>
    <author>
      <name>David Young</name>
    </author>
    <author>
      <name>Douglas Leith</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14428/esann/2022.ES2022-79</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14428/esann/2022.ES2022-79" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, Esann 2022 conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">30th European Symposium on Artificial Neural Networks,
  Computational Intelligence and Machine Learning Proceedings (2022) 423 - 428</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2305.18305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.18305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.08636v1</id>
    <updated>2023-06-14T17:05:57Z</updated>
    <published>2023-06-14T17:05:57Z</published>
    <title>Using Wikipedia Editor Information to Build High-performance Recommender
  Systems</title>
    <summary>  Wikipedia has high-quality articles on a variety of topics and has been used
in diverse research areas. In this study, a method is presented for using
Wikipedia's editor information to build recommender systems in various domains
that outperform content-based systems.
</summary>
    <author>
      <name>Katsuhiko Hayashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Wiki Workshop2023 (withdrawn by the author)</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.08636v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.08636v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.10034v1</id>
    <updated>2023-06-07T20:19:25Z</updated>
    <published>2023-06-07T20:19:25Z</published>
    <title>Unlocking Insights into Business Trajectories with Transformer-based
  Spatio-temporal Data Analysis</title>
    <summary>  The world of business is constantly evolving and staying ahead of the curve
requires a deep understanding of market trends and performance. This article
addresses this requirement by modeling business trajectories using news
articles data.
</summary>
    <author>
      <name>Muhammad Arslan</name>
    </author>
    <author>
      <name>Christophe Cruz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented in the conference Spatial Analysis and GEOmatics 2023 SAGEO</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.10034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.10034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.13444v1</id>
    <updated>2024-02-21T00:37:16Z</updated>
    <published>2024-02-21T00:37:16Z</published>
    <title>The Effectiveness of Graph Contrastive Learning on Mathematical
  Information Retrieval</title>
    <summary>  This paper details an empirical investigation into using Graph Contrastive
Learning (GCL) to generate mathematical equation representations, a critical
aspect of Mathematical Information Retrieval (MIR). Our findings reveal that
this simple approach consistently exceeds the performance of the current
leading formula retrieval model, TangentCFT. To support ongoing research and
development in this field, we have made our source code accessible to the
public at https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/.
</summary>
    <author>
      <name>Pei-Syuan Wang</name>
    </author>
    <author>
      <name>Hung-Hsuan Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2402.13444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.13444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.12090v1</id>
    <updated>2024-03-13T20:28:08Z</updated>
    <published>2024-03-13T20:28:08Z</published>
    <title>Foundation Models and Information Retrieval in Digital Pathology</title>
    <summary>  The paper reviews the state-of-the-art of foundation models, LLMs, generative
AI, information retrieval and CBIR in digital pathology
</summary>
    <author>
      <name>H. R. Tizhoosh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint of a book chapter to appear in "Artificial
  Intelligence in Pathology" by Stanley Cohen and Chhavi Chauhan</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.12090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.12090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.15475v1</id>
    <updated>2024-04-23T19:26:28Z</updated>
    <published>2024-04-23T19:26:28Z</published>
    <title>An Annotated Glossary for Data Commons, Data Meshes, and Other Data
  Platforms</title>
    <summary>  Cloud-based data commons, data meshes, data hubs, and other data platforms
are important ways to manage, analyze and share data to accelerate research and
to support reproducible research. This is an annotated glossary of some of the
more common terms used in articles and discussions about these platforms.
</summary>
    <author>
      <name>Robert L. Grossman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.15475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.15475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.07923v1</id>
    <updated>2024-07-08T15:24:58Z</updated>
    <published>2024-07-08T15:24:58Z</published>
    <title>New Method for Keyword Extraction for Patent Claims</title>
    <summary>  The search for prior art is crucial in patent application processing, it
consists in retrieving other documents relevant to the invention of the
application. Most methods feed a search engine with keywords that are extracted
by frequency-analysis methods. We suggest and demonstrate a new method that
relies on the way information is provided in patent claims.
</summary>
    <author>
      <name>Julien Rossi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21942/uva.26207339</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21942/uva.26207339" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master's thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2407.07923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.07923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.07174v1</id>
    <updated>2024-08-13T19:37:20Z</updated>
    <published>2024-08-13T19:37:20Z</published>
    <title>On the Local Ultrametricity of Finite Metric Data</title>
    <summary>  New local ultrametricity measures for finite metric data are proposed through
the viewpoint that their Vietoris-Rips corners are samples from p-adic Mumford
curves endowed with a Radon measure coming from a regular differential 1-form.
This is experimentally applied to the iris dataset.
</summary>
    <author>
      <name>Patrick Erik Bradley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.07174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.07174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62-07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.10394v1</id>
    <updated>2024-08-19T20:26:45Z</updated>
    <published>2024-08-19T20:26:45Z</published>
    <title>Joint Modeling of Search and Recommendations Via an Unified Contextual
  Recommender (UniCoRn)</title>
    <summary>  Search and recommendation systems are essential in many services, and they
are often developed separately, leading to complex maintenance and technical
debt. In this paper, we present a unified deep learning model that efficiently
handles key aspects of both tasks.
</summary>
    <author>
      <name>Moumita Bhattacharya</name>
    </author>
    <author>
      <name>Vito Ostuni</name>
    </author>
    <author>
      <name>Sudarshan Lamkhede</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.10394v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.10394v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.00676v1</id>
    <updated>2024-11-01T15:35:56Z</updated>
    <published>2024-11-01T15:35:56Z</published>
    <title>Enhancing Semantic Interoperability Across Materials Science With
  HIVE4MAT</title>
    <summary>  HIVE4MAT is a linked data interactive application for navigating ontologies
of value to materials science. HIVE enables automatic indexing of textual
resources with standardized terminology. This article presents the motivation
underlying HIVE4MAT, explains the system architecture, reports on two
evaluations, and discusses future plans.
</summary>
    <author>
      <name>Jane Greenberg</name>
    </author>
    <author>
      <name>Kio Polson</name>
    </author>
    <author>
      <name>Scott McClellan</name>
    </author>
    <author>
      <name>Xintong Zhao</name>
    </author>
    <author>
      <name>Alex Kalinowski</name>
    </author>
    <author>
      <name>Yuan An</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 1 figures, 3 tables, to be published in SeMatS 2024
  workshop proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/2411.00676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.00676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.05339v1</id>
    <updated>2024-12-06T04:30:00Z</updated>
    <published>2024-12-06T04:30:00Z</published>
    <title>PyTerrier-GenRank: The PyTerrier Plugin for Reranking with Large
  Language Models</title>
    <summary>  Using LLMs as rerankers requires experimenting with various hyperparameters,
such as prompt formats, model choice, and reformulation strategies. We
introduce PyTerrier-GenRank, a PyTerrier plugin to facilitate seamless
reranking experiments with LLMs, supporting popular ranking strategies like
pointwise and listwise prompting. We validate our plugin through HuggingFace
and OpenAI hosted endpoints.
</summary>
    <author>
      <name>Kaustubh D. Dhole</name>
    </author>
    <link href="http://arxiv.org/abs/2412.05339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.05339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.18570v1</id>
    <updated>2025-03-24T11:26:40Z</updated>
    <published>2025-03-24T11:26:40Z</published>
    <title>Dense Retrieval for Low Resource Languages -- the Case of Amharic
  Language</title>
    <summary>  This paper reports some difficulties and some results when using dense
retrievers on Amharic, one of the low-resource languages spoken by 120 millions
populations. The efforts put and difficulties faced by University Addis Ababa
toward Amharic Information Retrieval will be developed during the presentation.
</summary>
    <author>
      <name>Tilahun Yeshambel</name>
    </author>
    <author>
      <name>Moncef Garouani</name>
    </author>
    <author>
      <name>Serge Molina</name>
    </author>
    <author>
      <name>Josiane Mothe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.18570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.18570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5863v1</id>
    <updated>2011-10-17T21:19:58Z</updated>
    <published>2011-10-17T21:19:58Z</published>
    <title>A Wikipedia Literature Review</title>
    <summary>  This paper was originally designed as a literature review for a doctoral
dissertation focusing on Wikipedia. This exposition gives the structure of
Wikipedia and the latest trends in Wikipedia research.
</summary>
    <author>
      <name>Owen S. Martin</name>
    </author>
    <link href="http://arxiv.org/abs/1110.5863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.00251v2</id>
    <updated>2017-01-26T15:53:55Z</updated>
    <published>2016-01-31T14:22:47Z</published>
    <title>Do we have privacy in the digital world?</title>
    <summary>  Not really.
</summary>
    <author>
      <name>Kaveh Bakhtiyari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.1.2492.5203/2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.1.2492.5203/2" rel="related"/>
    <link href="http://arxiv.org/abs/1602.00251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.00251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907042v1</id>
    <updated>1999-07-27T16:42:18Z</updated>
    <published>1999-07-27T16:42:18Z</published>
    <title>Raising Reliability of Web Search Tool Research through Replication and
  Chaos Theory</title>
    <summary>  Because the World Wide Web is a dynamic collection of information, the Web
search tools (or "search engines") that index the Web are dynamic. Traditional
information retrieval evaluation techniques may not provide reliable results
when applied to the Web search tools. This study is the result of ten
replications of the classic 1996 Ding and Marchionini Web search tool research.
It explores the effects that replication can have on transforming unreliable
results from one iteration into replicable and therefore reliable results after
multiple iterations.
</summary>
    <author>
      <name>Scott Nicholson</name>
    </author>
    <link href="http://arxiv.org/abs/cs/9907042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4; H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102002v1</id>
    <updated>2001-02-01T23:03:49Z</updated>
    <published>2001-02-01T23:03:49Z</published>
    <title>On the Automated Classification of Web Sites</title>
    <summary>  In this paper we discuss several issues related to automated text
classification of web sites. We analyze the nature of web content and metadata
in relation to requirements for text features. We find that HTML metatags are a
good source of text features, but are not in wide use despite their role in
search engine rankings. We present an approach for targeted spidering including
metadata extraction and opportunistic crawling of specific semantic hyperlinks.
We describe a system for automatically classifying web sites into industry
categories and present performance results based on different combinations of
text features and training data. This system can serve as the basis for a
generalized framework for automated metadata creation.
</summary>
    <author>
      <name>John M. Pierre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, etendu.sty</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0102002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.5.2; H.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204054v1</id>
    <updated>2002-04-26T22:45:30Z</updated>
    <published>2002-04-26T22:45:30Z</published>
    <title>Navigating the Small World Web by Textual Cues</title>
    <summary>  Can a Web crawler efficiently locate an unknown relevant page? While this
question is receiving much empirical attention due to its considerable
commercial value in the search engine community
[Cho98,Chakrabarti99,Menczer00,Menczer01], theoretical efforts to bound the
performance of focused navigation have only exploited the link structure of the
Web graph, neglecting other features [Kleinberg01,Adamic01,Kim02]. Here I
investigate the connection between linkage and a content-induced topology of
Web pages, suggesting that efficient paths can be discovered by decentralized
navigation algorithms based on textual cues.
</summary>
    <author>
      <name>Filippo Menczer</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0204054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.3; H.3.4; H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0209021v1</id>
    <updated>2002-09-19T06:53:51Z</updated>
    <published>2002-09-19T06:53:51Z</published>
    <title>Activities, Context and Ubiquitous Computing</title>
    <summary>  Context and context-awareness provides computing environments with the
ability to usefully adapt the services or information they provide. It is the
ability to implicitly sense and automatically derive the user needs that
separates context-aware applications from traditionally designed applications,
and this makes them more attentive, responsive, and aware of their user's
identity, and their user's environment. This paper argues that context-aware
applications capable of supporting complex, cognitive activities can be built
from a model of context called Activity-Centric Context. A conceptual model of
Activity-Centric context is presented. The model is illustrated via a detailed
example.
</summary>
    <author>
      <name>Paul Prekop</name>
    </author>
    <author>
      <name>Mark Burnett</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Communications 26 (2003) 1168-1176</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0209021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0209021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.M; H1; H4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306021v2</id>
    <updated>2003-08-30T06:35:35Z</updated>
    <published>2003-06-04T19:40:04Z</published>
    <title>Visualization for Periodic Population Movement between Distinct
  Localities</title>
    <summary>  We present a new visualization method to summarize and present periodic
population movement between distinct locations, such as floors, buildings,
cities, or the like. In the specific case of this paper, we have chosen to
focus on student movement between college dormitories on the Columbia
University campus. The visual information is presented to the information
analyst in the form of an interactive geographical map, in which specific
temporal periods as well as individual buildings can be singled out for
detailed data exploration. The navigational interface has been designed to
specifically meet a geographical setting.
</summary>
    <author>
      <name>Alexander Haubold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Poster Summary: 2 pages, 4 figures, InfoVis 2003 Symposium</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311015v2</id>
    <updated>2003-11-15T13:25:00Z</updated>
    <published>2003-11-14T09:53:51Z</published>
    <title>Make search become the internal function of Internet</title>
    <summary>  Domain Resource Integrated System (DRIS) is introduced in this paper. DRIS is
a distributed information retrieval system, which will solve problems like poor
coverage, long update interval in current web search system. The most distinct
character of DRIS is that it's a public opening system, and acts as an internal
component of Internet, but not the production of a company. The implementation
of DRIS is also represented.
</summary>
    <author>
      <name>Liang Wang</name>
    </author>
    <author>
      <name>Yiping Guo</name>
    </author>
    <author>
      <name>Ming Fang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0311015v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311015v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3;H.3.5;H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312018v1</id>
    <updated>2003-12-11T20:07:39Z</updated>
    <published>2003-12-11T20:07:39Z</published>
    <title>Mapping Subsets of Scholarly Information</title>
    <summary>  We illustrate the use of machine learning techniques to analyze, structure,
maintain, and evolve a large online corpus of academic literature. An emerging
field of research can be identified as part of an existing corpus, permitting
the implementation of a more coherent community structure for its
practitioners.
</summary>
    <author>
      <name>Paul Ginsparg</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cornell University</arxiv:affiliation>
    </author>
    <author>
      <name>Paul Houle</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cornell University</arxiv:affiliation>
    </author>
    <author>
      <name>Thorsten Joachims</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cornell University</arxiv:affiliation>
    </author>
    <author>
      <name>Jae-Hoon Sul</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cornell University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1073/pnas.0308253100</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1073/pnas.0308253100" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, presented at Arthur M. Sackler Colloquium on
  "Mapping Knowledge Domains", 9--11 May 2003, Beckman Center, Irvine, CA,
  proceedings to appear in PNAS</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.6; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312033v1</id>
    <updated>2003-12-17T11:30:56Z</updated>
    <published>2003-12-17T11:30:56Z</published>
    <title>Using sensors in the web crawling process</title>
    <summary>  This paper offers a short description of an Internet information field
monitoring system, which places a special module-sensor on the side of the
Web-server to detect changes in information resources and subsequently
reindexes only the resources signalized by the corresponding sensor. Concise
results of simulation research and an implementation attempt of the given
"sensors" concept are provided.
</summary>
    <author>
      <name>Ilya Zemskov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures. The article was accepted for the IADIS
  International WWW/Internet 2003 Conference but not published in the
  proceedings due to the lack of financial support</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4; I.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405044v1</id>
    <updated>2004-05-12T20:18:51Z</updated>
    <published>2004-05-12T20:18:51Z</published>
    <title>Corpus structure, language models, and ad hoc information retrieval</title>
    <summary>  Most previous work on the recently developed language-modeling approach to
information retrieval focuses on document-specific characteristics, and
therefore does not take into account the structure of the surrounding corpus.
We propose a novel algorithmic framework in which information provided by
document-based language models is enhanced by the incorporation of information
drawn from clusters of similar documents. Using this framework, we develop a
suite of new algorithms. Even the simplest typically outperforms the standard
language-modeling approach in precision and recall, and our new interpolation
algorithm posts statistically significant improvements for both metrics over
all three corpora tested.
</summary>
    <author>
      <name>Oren Kurland</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear, SIGIR 2004</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0411026v1</id>
    <updated>2004-11-08T20:49:42Z</updated>
    <published>2004-11-08T20:49:42Z</published>
    <title>A Search Relevancy Tuning Method Using Expert Results Content Evaluation</title>
    <summary>  The article presents an online relevancy tuning method using explicit user
feedback. The author developed and tested a method of words' weights
modification based on search result evaluation by user. User decides whether
the result is useful or not after inspecting the full result content. The
experiment proved that the constantly accumulated words weights base leads to
better search quality in a specified data domain. The author also suggested
future improvements of the method.
</summary>
    <author>
      <name>Boris Mark Tylevich</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Moscow Institute of Physics and Technology, Moscow, Russia</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0411026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0411026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503020v1</id>
    <updated>2005-03-08T22:26:07Z</updated>
    <published>2005-03-08T22:26:07Z</published>
    <title>Earlier Web Usage Statistics as Predictors of Later Citation Impact</title>
    <summary>  The use of citation counts to assess the impact of research articles is well
established. However, the citation impact of an article can only be measured
several years after it has been published. As research articles are
increasingly accessed through the Web, the number of times an article is
downloaded can be instantly recorded and counted. One would expect the number
of times an article is read to be related both to the number of times it is
cited and to how old the article is. This paper analyses how short-term Web
usage impact predicts medium-term citation impact. The physics e-print archive
(arXiv.org) is used to test this.
</summary>
    <author>
      <name>Tim Brody</name>
    </author>
    <author>
      <name>Stevan Harnad</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0503020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505039v1</id>
    <updated>2005-05-14T17:48:07Z</updated>
    <published>2005-05-14T17:48:07Z</published>
    <title>Methods for comparing rankings of search engine results</title>
    <summary>  In this paper we present a number of measures that compare rankings of search
engine results. We apply these measures to five queries that were monitored
daily for two periods of about 21 days each. Rankings of the different search
engines (Google, Yahoo and Teoma for text searches and Google, Yahoo and
Picsearch for image searches) are compared on a daily basis, in addition to
longitudinal comparisons of the same engine for the same query over time. The
results and rankings of the two periods are compared as well.
</summary>
    <author>
      <name>Judit Bar-Ilan</name>
    </author>
    <author>
      <name>Mazlita Mat-Hassan</name>
    </author>
    <author>
      <name>Mark Levene</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures, 8 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0505039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505051v1</id>
    <updated>2005-05-20T14:54:40Z</updated>
    <published>2005-05-20T14:54:40Z</published>
    <title>Sub-Optimum Signal Linear Detector Using Wavelets and Support Vector
  Machines</title>
    <summary>  The problem of known signal detection in Additive White Gaussian Noise is
considered. In previous work, a new detection scheme was introduced by the
authors, and it was demonstrated that optimum performance cannot be reached in
a real implementation. In this paper we analyse Support Vector Machines (SVM)
as an alternative, evaluating the results in terms of Probability of detection
curves for a fixed Probability of false alarm.
</summary>
    <author>
      <name>Jaime Gomez</name>
    </author>
    <author>
      <name>Ignacio Melgar</name>
    </author>
    <author>
      <name>Juan Seijas</name>
    </author>
    <author>
      <name>Diego Andina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WSEAS Transactions on Communications, ISSN 1109-2742, issue 4, vol
  2, p426-431, October-2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505052v1</id>
    <updated>2005-05-20T15:01:20Z</updated>
    <published>2005-05-20T15:01:20Z</published>
    <title>Upgrading Pulse Detection with Time Shift Properties Using Wavelets and
  Support Vector Machines</title>
    <summary>  Current approaches in pulse detection use domain transformations so as to
concentrate frequency related information that can be distinguishable from
noise. In real cases we do not know when the pulse will begin, so we need a
time search process in which time windows are scheduled and analysed. Each
window can contain the pulsed signal (either complete or incomplete) and / or
noise. In this paper a simple search process will be introduced, allowing the
algorithm to process more information, upgrading the capabilities in terms of
probability of detection (Pd) and probability of false alarm (Pfa).
</summary>
    <author>
      <name>Jaime Gomez</name>
    </author>
    <author>
      <name>Ignacio Melgar</name>
    </author>
    <author>
      <name>Juan Seijas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the World Automation Congress (WAC-04), Sevilla,
  Spain, June-2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505053v1</id>
    <updated>2005-05-20T15:06:40Z</updated>
    <published>2005-05-20T15:06:40Z</published>
    <title>Wavelet Time Shift Properties Integration with Support Vector Machines</title>
    <summary>  This paper presents a short evaluation about the integration of information
derived from wavelet non-linear-time-invariant (non-LTI) projection properties
using Support Vector Machines (SVM). These properties may give additional
information for a classifier trying to detect known patterns hidden by noise.
In the experiments we present a simple electromagnetic pulsed signal
recognition scheme, where some improvement is achieved with respect to previous
work. SVMs are used as a tool for information integration, exploiting some
unique properties not easily found in neural networks.
</summary>
    <author>
      <name>Jaime Gomez</name>
    </author>
    <author>
      <name>Ignacio Melgar</name>
    </author>
    <author>
      <name>Juan Seijas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNAI-3131 Modeling Decisions for Artificial Intelligence, ISSN
  0302-9743, p49-59, Barcelona, Spain, August-2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505056v1</id>
    <updated>2005-05-23T07:04:49Z</updated>
    <published>2005-05-23T07:04:49Z</published>
    <title>Text Compression and Superfast Searching</title>
    <summary>  In this paper, a new compression scheme for text is presented. The same is
efficient in giving high compression ratios and enables super fast searching
within the compressed text. Typical compression ratios of 70-80% and reducing
the search time by 80-85% are the features of this paper. Till now, a trade-off
between high ratios and searchability within compressed text has been seen. In
this paper, we show that greater the compression, faster the search. This finds
applicability in so many places where data as natural language text is present.
</summary>
    <author>
      <name>Udayan Khurana</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Thapar Institute of Engineering and Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Anirudh Koul</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Thapar Institute of Engineering and Technology</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0505056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509020v1</id>
    <updated>2005-09-07T12:16:22Z</updated>
    <published>2005-09-07T12:16:22Z</published>
    <title>Transitive Text Mining for Information Extraction and Hypothesis
  Generation</title>
    <summary>  Transitive text mining - also named Swanson Linking (SL) after its primary
and principal researcher - tries to establish meaningful links between
literature sets which are virtually disjoint in the sense that each does not
mention the main concept of the other. If successful, SL may give rise to the
development of new hypotheses. In this communication we describe our approach
to transitive text mining which employs co-occurrence analysis of the medical
subject headings (MeSH), the descriptors assigned to papers indexed in PubMed.
In addition, we will outline the current state of our web-based information
system which will enable our users to perform literature-driven hypothesis
building on their own.
</summary>
    <author>
      <name>Johannes Stegmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Charite, Berlin</arxiv:affiliation>
    </author>
    <author>
      <name>Guenter Grohmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Charite, Berlin</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0509020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509072v1</id>
    <updated>2005-09-23T13:27:18Z</updated>
    <published>2005-09-23T13:27:18Z</published>
    <title>Folksonomy as a Complex Network</title>
    <summary>  Folksonomy is an emerging technology that works to classify the information
over WWW through tagging the bookmarks, photos or other web-based contents. It
is understood to be organized by every user while not limited to the authors of
the contents and the professional editors. This study surveyed the folksonomy
as a complex network. The result indicates that the network, which is composed
of the tags from the folksonomy, displays both properties of small world and
scale-free. However, the statistics only shows a local and static slice of the
vast body of folksonomy which is still evolving.
</summary>
    <author>
      <name>Kaikai Shen</name>
    </author>
    <author>
      <name>Lide Wu</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0509072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512032v1</id>
    <updated>2005-12-08T09:37:49Z</updated>
    <published>2005-12-08T09:37:49Z</published>
    <title>A Software Framework for Vehicle-Infrastructure Cooperative Applications</title>
    <summary>  A growing category of vehicle-infrastructure cooperative (VIC) applications
requires telematics software components distributed between an
infrastructure-based management center and a number of vehicles. This article
presents an approach based on a software framework, focusing on a Telematic
Management System (TMS), a component suite aimed to run inside an
infrastructure-based operations center, in some cases interacting with legacy
systems like Advanced Traffic Management Systems or Vehicle Relationship
Management. The TMS framework provides support for modular, flexible,
prototyping and implementation of VIC applications. This work has received the
support of the European Commission in the context of the projects REACT and
CyberCars.
</summary>
    <author>
      <name>Sebastián Bengochea</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Angel Talamona</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Michel Parent</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0512032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604036v2</id>
    <updated>2006-04-27T00:41:01Z</updated>
    <published>2006-04-10T12:04:29Z</published>
    <title>Collaborative thesaurus tagging the Wikipedia way</title>
    <summary>  This paper explores the system of categories that is used to classify
articles in Wikipedia. It is compared to collaborative tagging systems like
del.icio.us and to hierarchical classification like the Dewey Decimal
Classification (DDC). Specifics and commonalitiess of these systems of subject
indexing are exposed. Analysis of structural and statistical properties
(descriptors per record, records per descriptor, descriptor levels) shows that
the category system of Wikimedia is a thesaurus that combines collaborative
tagging and hierarchical subject indexing in a special way.
</summary>
    <author>
      <name>Jakob Voss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, 7 tables; v2 with added appendix and fixed
  references</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0604036v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604036v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606097v2</id>
    <updated>2006-06-23T05:10:39Z</updated>
    <published>2006-06-22T14:17:26Z</published>
    <title>Synonym search in Wikipedia: Synarcher</title>
    <summary>  The program Synarcher for synonym (and related terms) search in the text
corpus of special structure (Wikipedia) was developed. The results of the
search are presented in the form of graph. It is possible to explore the graph
and search for graph elements interactively. Adapted HITS algorithm for synonym
search, program architecture, and program work evaluation with test examples
are presented in the paper. The proposed algorithm can be applied to a query
expansion by synonyms (in a search engine) and a synonym dictionary forming.
</summary>
    <author>
      <name>A. Krizhanovsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, Synarcher program is available at
  http://synarcher.sourceforge.net</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606097v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606097v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.3; H.4.3; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606105v1</id>
    <updated>2006-06-26T11:51:41Z</updated>
    <published>2006-06-26T11:51:41Z</published>
    <title>Iso9000 Based Advanced Quality Approach for Continuous Improvement of
  Manufacturing Processes</title>
    <summary>  The continuous improvement in TQM is considered as the core value by which
organisation could maintain a competitive edge. Several techniques and tools
are known to support this core value but most of the time these techniques are
informal and without modelling the interdependence between the core value and
tools. Thus, technique formalisation is one of TQM challenges for increasing
efficiency of quality process implementation. In that way, the paper proposes
and experiments an advanced quality modelling approach based on meta-modelling
the "process approach" as advocated by the standard ISO9000:2000. This
meta-model allows formalising the interdependence between technique, tools and
core value
</summary>
    <author>
      <name>Salah Deeb</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAN</arxiv:affiliation>
    </author>
    <author>
      <name>Benoît Iung</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">12th IFAC Symposium on Information Control Problems in
  Manufacturing, St-Etienne, France (17/05/2006) CDROM</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606128v1</id>
    <updated>2006-06-30T15:17:36Z</updated>
    <published>2006-06-30T15:17:36Z</published>
    <title>Automatic forming lists of semantically related terms based on texts
  rating in the corpus with hyperlinks and categories (In Russian)</title>
    <summary>  HITS adapted algorithm for synonym search, the program architecture, and the
program work evaluation with test examples are presented in the paper.
Synarcher program for synonym (and related terms) search in the text corpus of
special structure (Wikipedia) was developed. The results of search are
presented in the form of a graph. It is possible to explore the graph and
search graph elements interactively. The proposed algorithm could be applied to
the search request extending and for synonym dictionary forming.
</summary>
    <author>
      <name>A. Krizhanovsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, in Russian, PDF, for other formats see
  http://whinger.narod.ru/paper/index.html</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.3; H.4.3; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608043v1</id>
    <updated>2006-08-08T13:19:08Z</updated>
    <published>2006-08-08T13:19:08Z</published>
    <title>Using Users' Expectations to Adapt Business Intelligence Systems</title>
    <summary>  This paper takes a look at the general characteristics of business or
economic intelligence system. The role of the user within this type of system
is emphasized. We propose two models which we consider important in order to
adapt this system to the user. The first model is based on the definition of
decisional problem and the second on the four cognitive phases of human
learning. We also describe the application domain we are using to test these
models in this type of system.
</summary>
    <author>
      <name>Babajide Afolabi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Odile Thiery</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Knowledge Organization 10 (2006) 247-254</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0608043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608107v3</id>
    <updated>2007-02-19T20:33:37Z</updated>
    <published>2006-08-28T17:05:07Z</published>
    <title>The Haar Wavelet Transform of a Dendrogram</title>
    <summary>  We describe a new wavelet transform, for use on hierarchies or binary rooted
trees. The theoretical framework of this approach to data analysis is
described. Case studies are used to further exemplify this approach. A first
set of application studies deals with data array smoothing, or filtering. A
second set of application studies relates to hierarchical tree condensation.
Finally, a third study explores the wavelet decomposition, and the
reproducibility of data sets such as text, including a new perspective on the
generation or computability of such data objects.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00357-007-0007-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00357-007-0007-9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pp, 8 figures. Forthcoming in Journal of Classification</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Classification, 24, 3-32, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0608107v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608107v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3; H.3.1; I.1.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610091v4</id>
    <updated>2006-12-24T06:03:44Z</updated>
    <published>2006-10-14T17:03:46Z</published>
    <title>On the Behavior of Journal Impact Factor Rank-Order Distribution</title>
    <summary>  An empirical law for the rank-order behavior of journal impact factors is
found. Using an extensive data base on impact factors including journals on
Education, Agrosciences, Geosciences, Biosciences and Environ- mental,
Chemical, Computer, Engineering, Material, Mathematical, Medical and Physical
Sciences we have found extremely good fits out- performing other rank-order
models. Some extensions to other areas of knowledge are discussed.
</summary>
    <author>
      <name>R. Mansilla</name>
    </author>
    <author>
      <name>E. Köppen</name>
    </author>
    <author>
      <name>G. Cocho</name>
    </author>
    <author>
      <name>P. Miramontes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the Journal of Informetrics, redundat text cropped,
  bibliography corrected, new section added, typos corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0610091v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610091v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703095v1</id>
    <updated>2007-03-20T14:52:52Z</updated>
    <published>2007-03-20T14:52:52Z</published>
    <title>Copula Component Analysis</title>
    <summary>  A framework named Copula Component Analysis (CCA) for blind source separation
is proposed as a generalization of Independent Component Analysis (ICA). It
differs from ICA which assumes independence of sources that the underlying
components may be dependent with certain structure which is represented by
Copula. By incorporating dependency structure, much accurate estimation can be
made in principle in the case that the assumption of independence is
invalidated. A two phrase inference method is introduced for CCA which is based
on the notion of multidimensional ICA.
</summary>
    <author>
      <name>Jian Ma</name>
    </author>
    <author>
      <name>Zengqi Sun</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0703095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703101v1</id>
    <updated>2007-03-21T20:47:33Z</updated>
    <published>2007-03-21T20:47:33Z</published>
    <title>A Note on Approximate Nearest Neighbor Methods</title>
    <summary>  A number of authors have described randomized algorithms for solving the
epsilon-approximate nearest neighbor problem. In this note I point out that the
epsilon-approximate nearest neighbor property often fails to be a useful
approximation property, since epsilon-approximate solutions fail to satisfy the
necessary preconditions for using nearest neighbors for classification and
related tasks.
</summary>
    <author>
      <name>Thomas M. Breuel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The report was originally written in 2005 and does not reference
  information after that date</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0703101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.1161v1</id>
    <updated>2007-05-08T20:08:13Z</updated>
    <published>2007-05-08T20:08:13Z</published>
    <title>IDF revisited: A simple new derivation within the Robertson-Spärck
  Jones probabilistic model</title>
    <summary>  There have been a number of prior attempts to theoretically justify the
effectiveness of the inverse document frequency (IDF). Those that take as their
starting point Robertson and Sparck Jones's probabilistic model are based on
strong or complex assumptions. We show that a more intuitively plausible
assumption suffices. Moreover, the new assumption, while conceptually very
simple, provides a solution to an estimation problem that had been deemed
intractable by Robertson and Walker (1997).
</summary>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear, Proceedings of SIGIR 2007, poster paper (2 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.1161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.1161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.4669v1</id>
    <updated>2007-09-28T18:45:48Z</updated>
    <published>2007-09-28T18:45:48Z</published>
    <title>The Extended Edit Distance Metric</title>
    <summary>  Similarity search is an important problem in information retrieval. This
similarity is based on a distance. Symbolic representation of time series has
attracted many researchers recently, since it reduces the dimensionality of
these high dimensional data objects. We propose a new distance metric that is
applied to symbolic data objects and we test it on time series data bases in a
classification task. We compare it to other distances that are well known in
the literature for symbolic data objects. We also prove, mathematically, that
our distance is metric.
</summary>
    <author>
      <name>Muhammad Marwan Muhammad Fuad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VALORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre-François Marteau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VALORIA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CBMI.2008.4564953</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CBMI.2008.4564953" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Content-Based Multimedia Indexing, CBMI 2008, london : United
  Kingdom (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0709.4669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.4669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2832v1</id>
    <updated>2007-11-19T16:10:35Z</updated>
    <published>2007-11-19T16:10:35Z</published>
    <title>Première étape vers une navigation référentielle par l'image
  pour l'assistance à la conception des ambiances lumineuses</title>
    <summary>  In the first design stage, image reference plays a double role of means of
formulation and resolution of problems. In our approach, we consider image
reference as a support of creation activity to generate ideas and we propose a
tool for navigation in references by image in order to assist daylight ambience
design. Within this paper, we present, in a first part, the semantic indexation
method to be used for the indexation of our image database. In a second part we
propose a synthetic analysis of various modes of referential navigation in
order to propose a tool implementing all or a part of these modes.
</summary>
    <author>
      <name>Salma Chaabouni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / Crai</arxiv:affiliation>
    </author>
    <author>
      <name>Jc Bignon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / Crai</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Halin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / Crai</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0711.2832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2867v1</id>
    <updated>2007-11-19T09:43:22Z</updated>
    <published>2007-11-19T09:43:22Z</published>
    <title>Maximizing PageRank via outlinks</title>
    <summary>  We analyze linkage strategies for a set I of webpages for which the webmaster
wants to maximize the sum of Google's PageRank scores. The webmaster can only
choose the hyperlinks starting from the webpages of I and has no control on the
hyperlinks from other webpages. We provide an optimal linkage strategy under
some reasonable assumptions.
</summary>
    <author>
      <name>Cristobald de Kerchove</name>
    </author>
    <author>
      <name>Laure Ninove</name>
    </author>
    <author>
      <name>Paul Van Dooren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 14 figures, submitted to Linear Algebra Appl</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.2867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2917v1</id>
    <updated>2007-11-19T12:35:48Z</updated>
    <published>2007-11-19T12:35:48Z</published>
    <title>Use of Wikipedia Categories in Entity Ranking</title>
    <summary>  Wikipedia is a useful source of knowledge that has many applications in
language processing and knowledge representation. The Wikipedia category graph
can be compared with the class hierarchy in an ontology; it has some
characteristics in common as well as some differences. In this paper, we
present our approach for answering entity ranking queries from the Wikipedia.
In particular, we explore how to make use of Wikipedia categories to improve
entity ranking effectiveness. Our experiments show that using categories of
example entities works significantly better than using loosely defined target
categories.
</summary>
    <author>
      <name>James A. Thom</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RMIT</arxiv:affiliation>
    </author>
    <author>
      <name>Jovan Pehcevski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <author>
      <name>Anne-Marie Vercoustre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans The 12th Australasian Document Computing Symposium (ADCS'07)
  (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.2917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3908v1</id>
    <updated>2008-01-25T10:40:27Z</updated>
    <published>2008-01-25T10:40:27Z</published>
    <title>Encoding changing country codes for the Semantic Web with ISO 3166 and
  SKOS</title>
    <summary>  This paper shows how authority files can be encoded for the Semantic Web with
the Simple Knowledge Organisation System (SKOS). In particular the application
of SKOS for encoding the structure, management, and utilization of country
codes as defined in ISO 3166 is demonstrated. The proposed encoding gives a use
case for SKOS that includes features that have only been discussed little so
far, such as multiple notations, nested concept schemes, changes by versioning.
</summary>
    <author>
      <name>Jakob Voss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to appear in the proceedings of the 2nd International Con-
  ference on Metadata and Semantics Research (MTSR 2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.3908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3522v5</id>
    <updated>2008-06-23T04:45:59Z</updated>
    <published>2008-02-24T17:18:50Z</published>
    <title>Time Warp Edit Distance</title>
    <summary>  This technical report details a family of time warp distances on the set of
discrete time series. This family is constructed as an editing distance whose
elementary operations apply on linear segments. A specific parameter allows
controlling the stiffness of the elastic matching. It is well suited for the
processing of event data for which each data sample is associated with a
timestamp, not necessarily obtained according to a constant sampling rate. Some
properties verified by these distances are proposed and proved in this report.
</summary>
    <author>
      <name>Pierre-François Marteau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VALORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Recognition - Clustering - Algorithms - Similarity Measures</arxiv:comment>
    <link href="http://arxiv.org/abs/0802.3522v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3522v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.1560v1</id>
    <updated>2008-07-10T00:01:20Z</updated>
    <published>2008-07-10T00:01:20Z</published>
    <title>Scientific Paper Summarization Using Citation Summary Networks</title>
    <summary>  Quickly moving to a new area of research is painful for researchers due to
the vast amount of scientific literature in each field of study. One possible
way to overcome this problem is to summarize a scientific topic. In this paper,
we propose a model of summarizing a single article, which can be further used
to summarize an entire topic. Our model is based on analyzing others' viewpoint
of the target article's contributions and the study of its citation summary
network using a clustering approach.
</summary>
    <author>
      <name>Vahed Qazvinian</name>
    </author>
    <author>
      <name>Dragomir R. Radev</name>
    </author>
    <link href="http://arxiv.org/abs/0807.1560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.1560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.1; I.2.7; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4186v1</id>
    <updated>2008-11-25T23:11:55Z</updated>
    <published>2008-11-25T23:11:55Z</published>
    <title>Search Result Clustering via Randomized Partitioning of Query-Induced
  Subgraphs</title>
    <summary>  In this paper, we present an approach to search result clustering, using
partitioning of underlying link graph. We define the notion of "query-induced
subgraph" and formulate the problem of search result clustering as a problem of
efficient partitioning of given subgraph into topic-related clusters. Also, we
propose a novel algorithm for approximative partitioning of such graph, which
results in cluster quality comparable to the one obtained by deterministic
algorithms, while operating in more efficient computation time, suitable for
practical implementations. Finally, we present a practical clustering search
engine developed as a part of this research and use it to get results about
real-world performance of proposed concepts.
</summary>
    <author>
      <name>Aleksandar Bradic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16th Telecommunications Forum TELFOR 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.4186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.1.2; E.1; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.1911v1</id>
    <updated>2009-02-11T15:14:11Z</updated>
    <published>2009-02-11T15:14:11Z</published>
    <title>Topological Centrality and Its Applications</title>
    <summary>  Recent development of network structure analysis shows that it plays an
important role in characterizing complex system of many branches of sciences.
Different from previous network centrality measures, this paper proposes the
notion of topological centrality (TC) reflecting the topological positions of
nodes and edges in general networks, and proposes an approach to calculating
the topological centrality. The proposed topological centrality is then used to
discover communities and build the backbone network. Experiments and
applications on research network show the significance of the proposed
approach.
</summary>
    <author>
      <name>Hai Zhuge</name>
    </author>
    <author>
      <name>Junsheng Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.1911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.1911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.5172v1</id>
    <updated>2009-03-30T11:06:03Z</updated>
    <published>2009-03-30T11:06:03Z</published>
    <title>Delocalization transition for the Google matrix</title>
    <summary>  We study the localization properties of eigenvectors of the Google matrix,
generated both from the World Wide Web and from the Albert-Barabasi model of
networks. We establish the emergence of a delocalization phase for the PageRank
vector when network parameters are changed. In the phase of localized PageRank,
a delocalization takes place in the complex plane of eigenvalues of the matrix,
leading to delocalized relaxation modes. We argue that the efficiency of
information retrieval by Google-type search is strongly affected in the phase
of delocalized PageRank.
</summary>
    <author>
      <name>Olivier Giraud</name>
    </author>
    <author>
      <name>Bertrand Georgeot</name>
    </author>
    <author>
      <name>Dima L. Shepelyansky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.80.026107</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.80.026107" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures. Research done at
  http://www.quantware.ups-tlse.fr/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 80, 026107 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.5172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.5172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.1130v1</id>
    <updated>2009-05-07T20:21:45Z</updated>
    <published>2009-05-07T20:21:45Z</published>
    <title>Statistical Automatic Summarization in Organic Chemistry</title>
    <summary>  We present an oriented numerical summarizer algorithm, applied to producing
automatic summaries of scientific documents in Organic Chemistry. We present
its implementation named Yachs (Yet Another Chemistry Summarizer) that combines
a specific document pre-processing with a sentence scoring method relying on
the statistical properties of documents. We show that Yachs achieves the best
results among several other summarizers on a corpus of Organic Chemistry
articles.
</summary>
    <author>
      <name>Florian Boudin</name>
    </author>
    <author>
      <name>Patricia Velazquez-Morales</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.1130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.1130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0080v2</id>
    <updated>2009-08-06T17:36:09Z</updated>
    <published>2009-05-30T14:22:04Z</published>
    <title>Reverse method for labeling the information from semi-structured web
  pages</title>
    <summary>  We propose a new technique to infer the structure and extract the tokens of
data from the semi-structured web sources which are generated using a
consistent template or layout with some implicit regularities. The attributes
are extracted and labeled reversely from the region of interest of targeted
contents. This is in contrast with the existing techniques which always
generate the trees from the root. We argue and show that our technique is
simpler, more accurate and effective especially to detect the changes of the
templates of targeted web pages.
</summary>
    <author>
      <name>Z. Akbar</name>
    </author>
    <author>
      <name>L. T. Handoko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICSPS.2009.86</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICSPS.2009.86" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Proceeding of the 2009 International Conference on Signal
  Processing Systems pp. 551-555</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.0080v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0080v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5286v1</id>
    <updated>2009-06-29T15:00:43Z</updated>
    <published>2009-06-29T15:00:43Z</published>
    <title>Putting Recommendations on the Map -- Visualizing Clusters and Relations</title>
    <summary>  For users, recommendations can sometimes seem odd or counterintuitive.
Visualizing recommendations can remove some of this mystery, showing how a
recommendation is grouped with other choices. A drawing can also lead a user's
eye to other options. Traditional 2D-embeddings of points can be used to create
a basic layout, but these methods, by themselves, do not illustrate clusters
and neighborhoods very well. In this paper, we propose the use of geographic
maps to enhance the definition of clusters and neighborhoods, and consider the
effectiveness of this approach in visualizing similarities and recommendations
arising from TV shows and music selections. All the maps referenced in this
paper can be found in http://www.research.att.com/~volinsky/maps
</summary>
    <author>
      <name>Emden Gansner</name>
    </author>
    <author>
      <name>Yifan Hu</name>
    </author>
    <author>
      <name>Stephen Kobourov</name>
    </author>
    <author>
      <name>Chris Volinsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.5286v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5286v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5608v1</id>
    <updated>2009-06-30T18:42:59Z</updated>
    <published>2009-06-30T18:42:59Z</published>
    <title>Loading Arbitrary Knowledge Bases in Matrix Browser</title>
    <summary>  This paper describes the work done on Matrix Browser, which is a recently
developed graphical user interface to explore and navigate complex networked
information spaces. This approach presents a new way of navigating information
nets in windows explorer like widget. The problem on hand was how to export
arbitrary knowledge bases in Matrix Browser. This was achieved by identifying
the relationships present in knowledge bases and then by forming the
hierarchies from this data and these hierarchies are being exported to matrix
browser. This paper gives solution to this problem and informs about
implementation work.
</summary>
    <author>
      <name>Saqib Saeed</name>
    </author>
    <author>
      <name>Christoph Kunz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper was published in the proceedings of IEEE International
  Multi Topic Conference (INMIC 2004) Lahore, Pakistan 24th- 26th December 2004</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.5608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.3315v1</id>
    <updated>2009-07-19T18:56:37Z</updated>
    <published>2009-07-19T18:56:37Z</published>
    <title>Effective Personalized Recommendation in Collaborative Tagging Systems</title>
    <summary>  Recently, collaborative tagging systems have attracted more and more
attention and have been widely applied in web systems. Tags provide highly
abstracted information about personal preferences and item content, and are
therefore potential to help in improving better personalized recommendations.
In this paper, we propose a tag-based recommendation algorithm considering the
personal vocabulary and evaluate it in a real-world dataset: Del.icio.us.
Experimental results demonstrate that the usage of tag information can
significantly improve the accuracy of personalized recommendations.
</summary>
    <author>
      <name>Zi-Ke Zhang</name>
    </author>
    <author>
      <name>Tao Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/0907.3315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.3315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0595v1</id>
    <updated>2009-08-05T17:09:45Z</updated>
    <published>2009-08-05T17:09:45Z</published>
    <title>Towards a Model of Understanding Social Search</title>
    <summary>  Search engine researchers typically depict search as the solitary activity of
an individual searcher. In contrast, results from our critical-incident survey
of 150 users on Amazon's Mechanical Turk service suggest that social
interactions play an important role throughout the search process. Our main
contribution is that we have integrated models from previous work in
sensemaking and information seeking behavior to present a canonical social
model of user activities before, during, and after search, suggesting where in
the search process even implicitly shared information may be valuable to
individual searchers.
</summary>
    <author>
      <name>Brynn M. Evans</name>
    </author>
    <author>
      <name>Ed H. Chi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.0595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.5.2; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0704v1</id>
    <updated>2009-08-05T16:48:18Z</updated>
    <published>2009-08-05T16:48:18Z</published>
    <title>A Taxonomy of Collaboration in Online Information Seeking</title>
    <summary>  People can help other people find information in networked information
seeking environments. Recently, many such systems and algorithms have
proliferated in industry and in academia. Unfortunately, it is difficult to
compare the systems in meaningful ways because they often define collaboration
in different ways. In this paper, we propose a model of possible kinds of
collaboration, and illustrate it with examples from literature. The model
contains four dimensions: intent, depth, concurrency and location. This model
can be used to classify existing systems and to suggest possible opportunities
for design in this space.
</summary>
    <author>
      <name>Gene Golovchinsky</name>
    </author>
    <author>
      <name>Jeremy Pickens</name>
    </author>
    <author>
      <name>Maribeth Back</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.0704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.5.2; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0709v1</id>
    <updated>2009-08-05T17:33:03Z</updated>
    <published>2009-08-05T17:33:03Z</published>
    <title>Toward Collaborative Information Seeking (CIS)</title>
    <summary>  It is natural for humans to collaborate while dealing with complex problems.
In this article I consider this process of collaboration in the context of
information seeking. The study and discussion presented here are driven by two
dissatisfactions: (1) the majority of IR systems today do not facilitate
collaboration directly, and (2) the concept of collaboration itself is not
well-understood. I begin by probing the notion of collaboration and propose a
model that helps us understand the requirements for a successful collaboration.
A model of a Collaborative Information Seeking (CIS) environment is then
rendered based on an extended model of information seeking.
</summary>
    <author>
      <name>Chirag Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.0709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.5.2; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3472v2</id>
    <updated>2010-03-09T12:43:28Z</updated>
    <published>2009-09-18T15:54:51Z</published>
    <title>The Universal Recommender</title>
    <summary>  We describe the Universal Recommender, a recommender system for semantic
datasets that generalizes domain-specific recommenders such as content-based,
collaborative, social, bibliographic, lexicographic, hybrid and other
recommenders. In contrast to existing recommender systems, the Universal
Recommender applies to any dataset that allows a semantic representation. We
describe the scalable three-stage architecture of the Universal Recommender and
its application to Internet Protocol Television (IPTV). To achieve good
recommendation accuracy, several novel machine learning and optimization
problems are identified. We finally give a brief argument supporting the need
for machine learning recommenders.
</summary>
    <author>
      <name>Jérôme Kunegis</name>
    </author>
    <author>
      <name>Alan Said</name>
    </author>
    <author>
      <name>Winfried Umbrath</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; typo and references fixed</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.3472v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3472v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4416v2</id>
    <updated>2009-09-25T14:17:26Z</updated>
    <published>2009-09-24T12:27:02Z</published>
    <title>A baseline for content-based blog classification</title>
    <summary>  A content-based network representation of web logs (blogs) using a basic
word-overlap similarity measure is presented. Due to a strong signal in blog
data the approach is sufficient for accurately classifying blogs. Using Swedish
blog data we demonstrate that blogs that treat similar subjects are organized
in clusters that, in turn, are hierarchically organized in higher-order
clusters. The simplicity of the representation renders it both computationally
tractable and transparent. We therefore argue that the approach is suitable as
a baseline when developing and analyzing more advanced content-based
representations of the blogosphere.
</summary>
    <author>
      <name>Olof Gornerup</name>
    </author>
    <author>
      <name>Magnus Boman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures New version has higher resolution for figures 2
  and 3</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.4416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1938v1</id>
    <updated>2009-10-10T19:26:13Z</updated>
    <published>2009-10-10T19:26:13Z</published>
    <title>Information Retrieval via Truncated Hilbert-Space Expansions</title>
    <summary>  In addition to the frequency of terms in a document collection, the
distribution of terms plays an important role in determining the relevance of
documents. In this paper, a new approach for representing term positions in
documents is presented. The approach allows an efficient evaluation of
term-positional information at query evaluation time. Three applications are
investigated: a function-based ranking optimization representing a user-defined
document region, a query expansion technique based on overlapping the term
distributions in the top-ranked documents, and cluster analysis of terms in
documents. Experimental results demonstrate the effectiveness of the proposed
approach.
</summary>
    <author>
      <name>Patricio Galeas</name>
    </author>
    <author>
      <name>Ralph Kretschmer</name>
    </author>
    <author>
      <name>Bernd Freisleben</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, submitted to proceedings of ECIR-2010</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.1938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0050v1</id>
    <updated>2009-10-31T01:03:27Z</updated>
    <published>2009-10-31T01:03:27Z</published>
    <title>How to Compare the Scientific Contributions between Research Groups</title>
    <summary>  We present a method to analyse the scientific contributions between research
groups. Given multiple research groups, we construct their journal/proceeding
graphs and then compute the similarity/gap between them using network analysis.
This analysis can be used for measuring similarity/gap of the topics/qualities
between research groups' scientific contributions. We demonstrate the
practicality of our method by comparing the scientific contributions by Korean
researchers with those by the global researchers for information security in
2006 - 2008. The empirical analysis shows that the current security research in
South Korea has been isolated from the global research trend.
</summary>
    <author>
      <name>Hyoungshick Kim</name>
    </author>
    <author>
      <name>Ji Won Yoon</name>
    </author>
    <link href="http://arxiv.org/abs/0911.0050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4292v1</id>
    <updated>2009-11-22T21:35:51Z</updated>
    <published>2009-11-22T21:35:51Z</published>
    <title>Similarity Measures, Author Cocitation Analysis, and Information Theory</title>
    <summary>  The use of Pearson's correlation coefficient in Author Cocitation Analysis
was compared with Salton's cosine measure in a number of recent contributions.
Unlike the Pearson correlation, the cosine is insensitive to the number of
zeros. However, one has the option of applying a logarithmic transformation in
correlation analysis. Information calculus is based on both the logarithmic
transformation and provides a non-parametric statistics. Using this methodology
one can cluster a document set in a precise way and express the differences in
terms of bits of information. The algorithm is explained and used on the data
set which was made the subject of this discussion.
</summary>
    <author>
      <name>Loet Leydesdorff</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of the American Society for Information Science &amp;
  Technology, 56(7), 2005, 769-772</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.4292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5046v2</id>
    <updated>2009-12-01T13:41:05Z</updated>
    <published>2009-11-26T10:27:14Z</published>
    <title>Integrating the Probabilistic Models BM25/BM25F into Lucene</title>
    <summary>  This document describes the BM25 and BM25F implementation using the Lucene
Java Framework. Both models have stood out at TREC by their performance and are
considered as state-of-the-art in the IR community. BM25 is applied to
retrieval on plain text documents, that is for documents that do not contain
fields, while BM25F is applied to documents with structure.
</summary>
    <author>
      <name>Joaquín Pérez-Iglesias</name>
    </author>
    <author>
      <name>José R. Pérez-Agüera</name>
    </author>
    <author>
      <name>Víctor Fresno</name>
    </author>
    <author>
      <name>Yuval Z. Feinstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Software can be downloaded from:
  http://nlp.uned.es/~jperezi/Lucene-BM25/</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.5046v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5046v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1294v1</id>
    <updated>2009-12-07T19:43:08Z</updated>
    <published>2009-12-07T19:43:08Z</published>
    <title>Conception d'un outil d'aide à l'indexation de ressources
  pédagogiques - Extraction automatique des thématiques et des mots-clefs
  de documents UNIT</title>
    <summary>  Indexing learning documents using the Learning Object Metadata (LOM) is often
carried out manually by archivists. Filling out the LOM fields is a long and
difficult task, requiring a complete reading and a full knowledge on the topic
dealt within the document. In this paper, we present an innovative model and
method to assist the archivists in finding the important concepts and keywords
of a learning document. The application is performed using wikipedia's category
links.
</summary>
    <author>
      <name>Carlo Abi Chahine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Philippe Kotowicz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Nathalie Chaignaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Pierre Pécuchet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Environnements Informatiques pour l'Apprentissage Humain, Le Mans
  : France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0440v1</id>
    <updated>2010-01-04T05:24:31Z</updated>
    <published>2010-01-04T05:24:31Z</published>
    <title>Tutoring System for Dance Learning</title>
    <summary>  Recent advances in hardware sophistication related to graphics display, audio
and video devices made available a large number of multimedia and hypermedia
applications. These multimedia applications need to store and retrieve the
different forms of media like text, hypertext, graphics, still images,
animations, audio and video. Dance is one of the important cultural forms of a
nation and dance video is one such multimedia types. Archiving and retrieving
the required semantics from these dance media collections is a crucial and
demanding multimedia application. This paper summarizes the difference dance
video archival techniques and systems. Keywords: Multimedia, Culture Media,
Metadata archival and retrieval systems, MPEG-7, XML.
</summary>
    <author>
      <name>Rajkumar Kannan</name>
    </author>
    <author>
      <name>Frederic Andres</name>
    </author>
    <author>
      <name>Balakrishnan Ramadoss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Advance Computing Conference 2009, Patiala, India</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.5.4; H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0827v1</id>
    <updated>2010-01-06T07:51:23Z</updated>
    <published>2010-01-06T07:51:23Z</published>
    <title>Document Clustering with K-tree</title>
    <summary>  This paper describes the approach taken to the XML Mining track at INEX 2008
by a group at the Queensland University of Technology. We introduce the K-tree
clustering algorithm in an Information Retrieval context by adapting it for
document clustering. Many large scale problems exist in document clustering.
K-tree scales well with large inputs due to its low complexity. It offers
promising results both in terms of efficiency and quality. Document
classification was completed using Support Vector Machines.
</summary>
    <author>
      <name>Christopher M. De Vries</name>
    </author>
    <author>
      <name>Shlomo Geva</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-03761-0_43</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-03761-0_43" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, INEX 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0830v1</id>
    <updated>2010-01-06T07:43:31Z</updated>
    <published>2010-01-06T07:43:31Z</published>
    <title>K-tree: Large Scale Document Clustering</title>
    <summary>  We introduce K-tree in an information retrieval context. It is an efficient
approximation of the k-means clustering algorithm. Unlike k-means it forms a
hierarchy of clusters. It has been extended to address issues with sparse
representations. We compare performance and quality to CLUTO using document
collections. The K-tree has a low time complexity that is suitable for large
document collections. This tree structure allows for efficient disk based
implementations where space requirements exceed that of main memory.
</summary>
    <author>
      <name>Christopher M. De Vries</name>
    </author>
    <author>
      <name>Shlomo Geva</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1571941.1572094</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1571941.1572094" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, SIGIR 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0239v1</id>
    <updated>2010-02-01T13:09:52Z</updated>
    <published>2010-02-01T13:09:52Z</published>
    <title>Construction et enrichissement automatique d'ontologie à partir de
  ressources externes</title>
    <summary>  Automatic construction of ontologies from text is generally based on
retrieving text content. For a much more rich ontology we extend these
approaches by taking into account the document structure and some external
resources (like thesaurus of indexing terms of near domain). In this paper we
describe how these external resources are at first analyzed and then exploited.
This method has been applied on a geographical domain and the benefit has been
evaluated.
</summary>
    <author>
      <name>Eric Kergosien</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Mouna Kamel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Sallaberry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Marie-Noëlle Bessagnet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Nathalie Aussenac- Gilles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <author>
      <name>Mauro Gaio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JFO'09: 3es Journ\'ees Francophones sur les Ontologies, Poitiers :
  France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.0239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0577v1</id>
    <updated>2010-02-02T20:07:22Z</updated>
    <published>2010-02-02T20:07:22Z</published>
    <title>Recherche de relations spatio-temporelles : une méthode basée sur
  l'analyse de corpus textuels</title>
    <summary>  This paper presents a work package realized for the G\'eOnto project. A new
method is proposed for an enrichment of a first geographical ontology developed
beforehand. This method relies on text analysis by lexico-syntactic patterns.
  From the retrieve of n-ary relations the method automatically detect those
involved in a spatial and/or temporal relation in a context of a description of
journeys.
</summary>
    <author>
      <name>Tien Nguyen Van</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Mauro Gaio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Sallaberry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">TIA'09WS: Acquisition et mod\'elisation de relations
  s\'emantiques, Toulouse : France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.0577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2439v1</id>
    <updated>2010-02-11T21:45:48Z</updated>
    <published>2010-02-11T21:45:48Z</published>
    <title>Using Web Page Titles to Rediscover Lost Web Pages</title>
    <summary>  Titles are denoted by the TITLE element within a web page. We queried the
title against the the Yahoo search engine to determine the page's status
(found, not found). We conducted several tests based on elements of the title.
These tests were used to discern whether we could predict a pages status based
on the title. Our results increase our ability to determine bad titles but not
our ability to determine good titles.
</summary>
    <author>
      <name>Jeffery L. Shipman</name>
    </author>
    <author>
      <name>Martin Klein</name>
    </author>
    <author>
      <name>Michael L. Nelson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages, 18 figures, CS project report</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.2439v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2439v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2858v3</id>
    <updated>2010-08-14T15:14:13Z</updated>
    <published>2010-02-15T12:47:16Z</published>
    <title>PageRank: Standing on the shoulders of giants</title>
    <summary>  PageRank is a Web page ranking technique that has been a fundamental
ingredient in the development and success of the Google search engine. The
method is still one of the many signals that Google uses to determine which
pages are most important. The main idea behind PageRank is to determine the
importance of a Web page in terms of the importance assigned to the pages
hyperlinking to it. In fact, this thesis is not new, and has been previously
successfully exploited in different contexts. We review the PageRank method and
link it to some renowned previous techniques that we have found in the fields
of Web information retrieval, bibliometrics, sociometry, and econometrics.
</summary>
    <author>
      <name>Massimo Franceschet</name>
    </author>
    <link href="http://arxiv.org/abs/1002.2858v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2858v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.1048v1</id>
    <updated>2010-03-04T13:53:26Z</updated>
    <published>2010-03-04T13:53:26Z</published>
    <title>Tag Clusters as Information Retrieval Interfaces</title>
    <summary>  The paper presents our design of a next generation information retrieval
system based on tag co-occurrences and subsequent clustering. We help users
getting access to digital data through information visualization in the form of
tag clusters. Current problems like the absence of interactivity and semantics
between tags or the difficulty of adding additional search arguments are
solved. In the evaluation, based upon SERVQUAL and IT systems quality
indicators, we found out that tag clusters are perceived as more useful than
tag clouds, are much more trustworthy, and are more enjoyable to use.
</summary>
    <author>
      <name>Kathrin Knautz</name>
    </author>
    <author>
      <name>Simone Soubusta</name>
    </author>
    <author>
      <name>Wolfgang G. Stock</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 43th Annual Hawaii International Conference on
  System Sciences (HICSS-43), January 5-8, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.1048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.1048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3274v1</id>
    <updated>2010-04-19T18:24:02Z</updated>
    <published>2010-04-19T18:24:02Z</published>
    <title>A New Approach to Keyphrase Extraction Using Neural Networks</title>
    <summary>  Keyphrases provide a simple way of describing a document, giving the reader
some clues about its contents. Keyphrases can be useful in a various
applications such as retrieval engines, browsing interfaces, thesaurus
construction, text mining etc.. There are also other tasks for which keyphrases
are useful, as we discuss in this paper. This paper describes a neural network
based approach to keyphrase extraction from scientific articles. Our results
show that the proposed method performs better than some state-of-the art
keyphrase extraction approaches.
</summary>
    <author>
      <name>Kamal Sarkar</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Suranjan Ghose</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/A-New-Approach-to-Keyphrase-Extraction-Using-Neural-Networks.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI, Volume 7, Issue 2, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3371v1</id>
    <updated>2010-04-20T07:49:07Z</updated>
    <published>2010-04-20T07:49:07Z</published>
    <title>Improving Update Summarization by Revisiting the MMR Criterion</title>
    <summary>  This paper describes a method for multi-document update summarization that
relies on a double maximization criterion. A Maximal Marginal Relevance like
criterion, modified and so called Smmr, is used to select sentences that are
close to the topic and at the same time, distant from sentences used in already
read documents. Summaries are then generated by assembling the high ranked
material and applying some ruled-based linguistic post-processing in order to
obtain length reduction and maintain coherency. Through a participation to the
Text Analysis Conference (TAC) 2008 evaluation campaign, we have shown that our
method achieves promising results.
</summary>
    <author>
      <name>Florian Boudin</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Marc El-Bèze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 3 figures and 8 tables.</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4489v1</id>
    <updated>2010-04-26T11:36:38Z</updated>
    <published>2010-04-26T11:36:38Z</published>
    <title>MIREX: MapReduce Information Retrieval Experiments</title>
    <summary>  We propose to use MapReduce to quickly test new retrieval approaches on a
cluster of machines by sequentially scanning all documents. We present a small
case study in which we use a cluster of 15 low cost ma- chines to search a web
crawl of 0.5 billion pages showing that sequential scanning is a viable
approach to running large-scale information retrieval experiments with little
effort. The code is available to other researchers at:
http://mirex.sourceforge.net
</summary>
    <author>
      <name>Djoerd Hiemstra</name>
    </author>
    <author>
      <name>Claudia Hauff</name>
    </author>
    <link href="http://arxiv.org/abs/1004.4489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.4748v1</id>
    <updated>2010-07-27T15:16:36Z</updated>
    <published>2010-07-27T15:16:36Z</published>
    <title>Detecting influenza outbreaks by analyzing Twitter messages</title>
    <summary>  We analyze over 500 million Twitter messages from an eight month period and
find that tracking a small number of flu-related keywords allows us to forecast
future influenza rates with high accuracy, obtaining a 95% correlation with
national health statistics. We then analyze the robustness of this approach to
spurious keyword matches, and we propose a document classification component to
filter these misleading messages. We find that this document classifier can
reduce error rates by over half in simulated false alarm experiments, though
more research is needed to develop methods that are robust in cases of
extremely high noise.
</summary>
    <author>
      <name>Aron Culotta</name>
    </author>
    <link href="http://arxiv.org/abs/1007.4748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.4748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3795v1</id>
    <updated>2010-08-23T11:30:15Z</updated>
    <published>2010-08-23T11:30:15Z</published>
    <title>Machine Science in Biomedicine: Practicalities, Pitfalls and Potential</title>
    <summary>  Machine Science, or Data-driven Research, is a new and interesting scientific
methodology that uses advanced computational techniques to identify, retrieve,
classify and analyse data in order to generate hypotheses and develop models.
In this paper we describe three recent biomedical Machine Science studies, and
use these to assess the current state of the art with specific emphasis on data
mining, data assessment, costs, limitations, skills and tool support.
</summary>
    <author>
      <name>T W Kelsey</name>
    </author>
    <author>
      <name>W H B Wallace</name>
    </author>
    <link href="http://arxiv.org/abs/1008.3795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5003v1</id>
    <updated>2010-09-25T10:33:42Z</updated>
    <published>2010-09-25T10:33:42Z</published>
    <title>Demonstrating a Service-Enhanced Retrieval System</title>
    <summary>  This paper is a short description of an information retrieval system enhanced
by three model driven retrieval services: (1) co-word analysis based query
expansion, re-ranking via (2) Bradfordizing and (3) author centrality. The
different services each favor quite other - but still relevant - documents than
pure term-frequency based rankings. Each service can be interactively combined
with each other to allow an iterative retrieval refinement.
</summary>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/meet.14504701395</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/meet.14504701395" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, ASIST 2010 conference, Pittsburgh, PA, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.5003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.6242v1</id>
    <updated>2010-10-29T15:11:05Z</updated>
    <published>2010-10-29T15:11:05Z</published>
    <title>GraphDuplex: visualisation simultanée de N réseaux couplés 2 par 2</title>
    <summary>  While social network analysis often focuses on graph structure of social
actors, an increasing number of communication networks now provide textual
content within social activity (email, instant messaging, blogging,
collaboration networks). We present an open source visualization software,
GraphDuplex, which brings together social structure and textual content, adding
a semantic dimension to social analysis. GraphDuplex eventually connects any
number of social or semantic graphs together, and through dynamic queries
enables user interaction and exploration across multiple graphs of different
nature.
</summary>
    <author>
      <name>Martine Hurault-Plantet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <author>
      <name>Elie Naulleau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CREM-EA3476</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Jacquemin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CREM-EA3476</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Conf\'erence en Recherche d'Information et Applications (CORIA
  2009), Prequ'\^ile de Giens : France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1010.6242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.6242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5364v1</id>
    <updated>2010-11-24T13:06:18Z</updated>
    <published>2010-11-24T13:06:18Z</published>
    <title>Optimizing On-Line Advertising</title>
    <summary>  We want to find the optimal strategy for displaying advertisements e.g.
banners, videos, in given locations at given times under some realistic dynamic
constraints. Our primary goal is to maximize the expected revenue in a given
period of time, i.e. the total profit produced by the impressions, which
depends on profit-generating events such as the impressions themselves, the
ensuing clicks and registrations. Moreover we must take into consideration the
possibility that the constraints could change in time in a way that cannot
always be foreseen.
</summary>
    <author>
      <name>Fabrizio Caruso</name>
    </author>
    <author>
      <name>Giovanni Giuffrida</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.5364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.1609v1</id>
    <updated>2010-12-07T21:16:59Z</updated>
    <published>2010-12-07T21:16:59Z</published>
    <title>Building conceptual spaces for exploring and linking biomedical
  resources</title>
    <summary>  The establishment of links between data (e.g., patient records) and Web
resources (e.g., literature) and the proper visualization of such discovered
knowledge is still a challenge in most Life Science domains (e.g.,
biomedicine). In this paper we present our contribution to the community in the
form of an infrastructure to annotate information resources, to discover
relationships among them, and to represent and visualize the new discovered
knowledge. Furthermore, we have also implemented a Web-based prototype tool
which integrates the proposed infrastructure.
</summary>
    <author>
      <name>R. Berlanga</name>
    </author>
    <author>
      <name>E. Jimenez-Ruiz</name>
    </author>
    <author>
      <name>V. Nebot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.1609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.1609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.1666v1</id>
    <updated>2010-12-08T01:10:59Z</updated>
    <published>2010-12-08T01:10:59Z</published>
    <title>SPARQL Assist Language-Neutral Query Composer</title>
    <summary>  SPARQL query composition is difficult for the lay-person or even the
experienced bioinformatician in cases where the data model is unfamiliar.
Established best-practices and internationalization concerns dictate that
semantic web ontologies should use terms with opaque identifiers, further
complicating the task. We present SPARQL Assist: a web application that
addresses these issues by providing context-sensitive type-ahead completion to
existing web forms. Ontological terms are suggested using their labels and
descriptions, leveraging existing XML support for internationalization and
language-neutrality.
</summary>
    <author>
      <name>Luke McCarthy</name>
    </author>
    <author>
      <name>Ben Vandervalk</name>
    </author>
    <author>
      <name>Mark Wilkinson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.1666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.1666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3793v1</id>
    <updated>2010-12-17T00:58:02Z</updated>
    <published>2010-12-17T00:58:02Z</published>
    <title>A robust ranking algorithm to spamming</title>
    <summary>  Ranking problem of web-based rating system has attracted many attentions. A
good ranking algorithm should be robust against spammer attack. Here we
proposed a correlation based reputation algorithm to solve the ranking problem
of such rating systems where user votes some objects with ratings. In this
algorithm, reputation of user is iteratively determined by the correlation
coefficient between his/her rating vector and the corresponding objects'
weighted average rating vector. Comparing with iterative refinement (IR) and
mean score algorithm, results for both artificial and real data indicate that,
the present algorithm shows a higher robustness against spammer attack.
</summary>
    <author>
      <name>Yanbo Zhou</name>
    </author>
    <author>
      <name>Ting Lei</name>
    </author>
    <author>
      <name>Tao Zhou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/94/48002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/94/48002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, 3 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPL 94 (2011) 48002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1012.3793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4063v1</id>
    <updated>2011-04-20T15:51:50Z</updated>
    <published>2011-04-20T15:51:50Z</published>
    <title>Fast redshift clustering with the Baire (ultra) metric</title>
    <summary>  The Baire metric induces an ultrametric on a dataset and is of linear
computational complexity, contrasted with the standard quadratic time
agglomerative hierarchical clustering algorithm. We apply the Baire distance to
spectrometric and photometric redshifts from the Sloan Digital Sky Survey
using, in this work, about half a million astronomical objects. We want to know
how well the (more cos\ tly to determine) spectrometric redshifts can predict
the (more easily obtained) photometric redshifts, i.e. we seek to regress the
spectrometric on the photometric redshifts, and we develop a clusterwise
nearest neighbor regression procedure for this.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <author>
      <name>Pedro Contreras</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/9789814383295_0005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/9789814383295_0005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30, 85-08, 11S82" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.5; H.3; E.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0121v1</id>
    <updated>2011-04-30T21:29:08Z</updated>
    <published>2011-04-30T21:29:08Z</published>
    <title>Methods of Hierarchical Clustering</title>
    <summary>  We survey agglomerative hierarchical clustering algorithms and discuss
efficient implementations that are available in R and other software
environments. We look at hierarchical self-organizing maps, and mixture models.
We review grid-based clustering, focusing on hierarchical density-based
approaches. Finally we describe a recently developed very efficient (linear
time) hierarchical clustering algorithm, which can also be viewed as a
hierarchical grid-based algorithm.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <author>
      <name>Pedro Contreras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 2 figures, 1 table, 69 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.2.8; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1406v1</id>
    <updated>2011-05-07T01:28:09Z</updated>
    <published>2011-05-07T01:28:09Z</published>
    <title>Comparison Latent Semantic and WordNet Approach for Semantic Similarity
  Calculation</title>
    <summary>  Information exchange among many sources in Internet is more autonomous,
dynamic and free. The situation drive difference view of concepts among
sources. For example, word 'bank' has meaning as economic institution for
economy domain, but for ecology domain it will be defined as slope of river or
lake. In this aper, we will evaluate latent semantic and WordNet approach to
calculate semantic similarity. The evaluation will be run for some concepts
from different domain with reference by expert or human. Result of the
evaluation can provide a contribution for mapping of concept, query rewriting,
interoperability, etc.
</summary>
    <author>
      <name>I Wayan Simri Wicaksana</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Gunadarma University</arxiv:affiliation>
    </author>
    <author>
      <name>Bambang Wahyudi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Gunadarma University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: latent semantic, interoperability, WordNet</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.1406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4702v1</id>
    <updated>2011-05-24T08:01:15Z</updated>
    <published>2011-05-24T08:01:15Z</published>
    <title>Exploiting Conceptual Knowledge for Querying Information Systems</title>
    <summary>  Whereas today's information systems are well-equipped for efficient query
handling, their strict mathematical foundations hamper their use for everyday
tasks. In daily life, people expect information to be offered in a personalized
and focused way. But currently, personalization in digital systems still only
takes explicit knowledge into account and does not yet process conceptual
information often naturally implied by users. We discuss how to bridge the gap
between users and today's systems, building on results from cognitive
psychology.
</summary>
    <author>
      <name>Joachim Selke</name>
    </author>
    <author>
      <name>Wolf-Tilo Balke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Philosophy's Relevance in Information
  Science (PRIS), Paderborn, Germany, 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5789v1</id>
    <updated>2011-05-29T14:06:44Z</updated>
    <published>2011-05-29T14:06:44Z</published>
    <title>Clustering and Classification in Text Collections Using Graph Modularity</title>
    <summary>  A new fast algorithm for clustering and classification of large collections
of text documents is introduced. The new algorithm employs the bipartite graph
that realizes the word-document matrix of the collection. Namely, the
modularity of the bipartite graph is used as the optimization functional.
Experiments performed with the new algorithm on a number of text collections
had shown a competitive quality of the clustering (classification), and a
record-breaking speed.
</summary>
    <author>
      <name>Grigory Pivovarov</name>
    </author>
    <author>
      <name>Sergei Trunov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, submitted to JMLR</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.5789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0217v1</id>
    <updated>2011-06-01T16:13:18Z</updated>
    <published>2011-06-01T16:13:18Z</published>
    <title>Using Lotkaian Informetrics for Ranking in Digital Libraries</title>
    <summary>  The purpose of this paper is to propose the use of models, theories and laws
in bibliometrics and scientometrics to enhance information retrieval processes,
especially ranking. A common pattern in many man-made data sets is Lotka's Law
which follows the well-known power-law distributions. These informetric
distributions can be used to give an alternative order to large and scattered
result sets and can be applied as a new ranking mechanism. The
polyrepresentation of information in Digital Library systems is used to enhance
the retrieval quality, to overcome the drawbacks of the typical term-based
ranking approaches and to enable users to explore retrieved document sets from
a different perspective.
</summary>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages; Proceedings of the ASIS&amp;T European Workshop 2011 (AEW 2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.0217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5460v1</id>
    <updated>2011-08-27T15:49:28Z</updated>
    <published>2011-08-27T15:49:28Z</published>
    <title>Personalized Web Services for Web Information Extraction</title>
    <summary>  The field of information extraction from the Web emerged with the growth of
the Web and the multiplication of online data sources. This paper is an
analysis of information extraction methods. It presents a service oriented
approach for web information extraction considering both web data management
and extraction services. Then we propose an SOA based architecture to enhance
flexibility and on-the-fly modification of web extraction services. An
implementation of the proposed architecture is proposed on the middleware level
of Java Enterprise Edition (JEE) servers.
</summary>
    <author>
      <name>Zahi Jarir</name>
    </author>
    <author>
      <name>Mohamed Quafafou</name>
    </author>
    <author>
      <name>Mahammed Erradi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Web Services Practices, Vol. 5, No.1
  (2010), pp. 22-31</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.5460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5703v1</id>
    <updated>2011-08-26T07:02:35Z</updated>
    <published>2011-08-26T07:02:35Z</published>
    <title>Web Pages Clustering: A New Approach</title>
    <summary>  The rapid growth of web has resulted in vast volume of information.
Information availability at a rapid speed to the user is vital. English
language (or any for that matter) has lot of ambiguity in the usage of words.
So there is no guarantee that a keyword based search engine will provide the
required results. This paper introduces the use of dictionary (standardised) to
obtain the context with which a keyword is used and in turn cluster the results
based on this context. These ideas can be merged with a metasearch engine to
enhance the search efficiency.
</summary>
    <author>
      <name>Jeevan H E</name>
    </author>
    <author>
      <name>Prashanth P P</name>
    </author>
    <author>
      <name>Punith Kumar S N</name>
    </author>
    <author>
      <name>Vinay Hegde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Clustering, concept mining, information retrieval, metasearch engine</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5703v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5703v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5784v1</id>
    <updated>2011-08-30T00:31:44Z</updated>
    <published>2011-08-30T00:31:44Z</published>
    <title>Probability Ranking in Vector Spaces</title>
    <summary>  The Probability Ranking Principle states that the document set with the
highest values of probability of relevance optimizes information retrieval
effectiveness given the probabilities are estimated as accurately as possible.
The key point of the principle is the separation of the document set into two
subsets with a given level of fallout and with the highest recall. The paper
introduces the separation between two vector subspaces and shows that the
separation yields a more effective performance than the optimal separation into
subsets with the same available evidence, the performance being measured with
recall and fallout. The result is proved mathematically and exemplified
experimentally.
</summary>
    <author>
      <name>Massimo Melucci</name>
    </author>
    <link href="http://arxiv.org/abs/1108.5784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1088v1</id>
    <updated>2011-09-06T07:07:26Z</updated>
    <published>2011-09-06T07:07:26Z</published>
    <title>A Framework for Business Intelligence Application using Ontological
  Classification</title>
    <summary>  Every business needs knowledge about their competitors to survive better. One
of the information repositories is web. Retrieving Specific information from
the web is challenging. An Ontological model is developed to capture specific
information by using web semantics. From the Ontology model, the relations
between the data are mined using decision tree. From all these a new framework
is developed for Business Intelligence.
</summary>
    <author>
      <name>A. Martin</name>
    </author>
    <author>
      <name>D. Maladhy</name>
    </author>
    <author>
      <name>V. Prasanna Venkatesan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Classification, Ontology, Business Intelligence, Datamining, Inverted
  Index, Ontology Tree Index</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Engineering Science and Technology
  (IJEST) Vol. 3 No. 2, (2011) 1213-1221</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1989v1</id>
    <updated>2011-09-09T13:00:18Z</updated>
    <published>2011-09-09T13:00:18Z</published>
    <title>Efficient Personalized Web Mining: Utilizing The Most Utilized Data</title>
    <summary>  Looking into the growth of information in the web it is a very tedious
process of getting the exact information the user is looking for. Many search
engines generate user profile related data listing. This paper involves one
such process where the rating is given to the link that the user is clicking
on. Rather than avoiding the uninterested links both interested links and the
uninterested links are listed. But sorted according to the weightings given to
each link by the number of visit made by the particular user and the amount of
time spent on the particular link.
</summary>
    <author>
      <name>L. K. Joshila Grace</name>
    </author>
    <author>
      <name>V. Maheswari</name>
    </author>
    <author>
      <name>Dhinaharan Nagamalai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">conference paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.1989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1991v1</id>
    <updated>2011-09-09T13:01:49Z</updated>
    <published>2011-09-09T13:01:49Z</published>
    <title>Effective Personalized Web Mining by Utilizing The Most Utilized Data</title>
    <summary>  Looking into the growth of information in the web it is a very tedious
process of getting the exact information the user is looking for. Many search
engines generate user profile related data listing. This paper involves one
such process where the rating is given to the link that the user is clicking
on. Rather than avoiding the uninterested links both interested links and the
uninterested links are listed. But sorted according to the weightings given to
each link by the number of visit made by the particular user and the amount of
time spent on the particular link.
</summary>
    <author>
      <name>L. K. Joshila Grace</name>
    </author>
    <author>
      <name>V. Maheswari</name>
    </author>
    <author>
      <name>Dhinaharan Nagamalai</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdms.2011.3309</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdms.2011.3309" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, journal paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Database Management Systems ( IJDMS ),
  Vol.3, No.3, August 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6862v1</id>
    <updated>2011-09-30T15:51:12Z</updated>
    <published>2011-09-30T15:51:12Z</published>
    <title>Video OCR for Video Indexing</title>
    <summary>  Video OCR is a technique that can greatly help to locate the topics of
interest in video via the automatic extraction and reading of captions and
annotations. Text in video can provide key indexing information. Recognizing
such text for search application is critical. Major difficult problem for
character recognition for videos is degraded and deformated characters, low
resolution characters or very complex background. To tackle the problem
preprocessing on text image plays vital role. Most of the OCR engines are
working on the binary image so to find a better binarization procedure for
image to get a desired result is important.Accurate binarization process
minimizes the error rate of video OCR.
</summary>
    <author>
      <name>Sankirti S.</name>
    </author>
    <author>
      <name>P. M. Kamade</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IACSIT International Journal of Engineering and Technology, Vol.3,
  No.3, June 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.6862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6349v1</id>
    <updated>2011-11-28T05:45:43Z</updated>
    <published>2011-11-28T05:45:43Z</published>
    <title>XML Information Retrieval Systems: A Survey</title>
    <summary>  The continuous growth in the XML information repositories has been matched by
increasing efforts in development of XML retrieval systems, in large parts
aiming at supporting content-oriented XML retrieval. These systems exploit the
available structural information, as market up in XML documents, in order to
return documents components- the so called XML elements-instead of the
complement documents in repose to the user query. In this paper, we provide an
overview of the different XML information retrieval systems and classify them
according to their storage and query evaluation strategies.
</summary>
    <author>
      <name>Awny Sayed</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 25 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2031v1</id>
    <updated>2011-12-09T07:24:13Z</updated>
    <published>2011-12-09T07:24:13Z</published>
    <title>Learning Context for Text Categorization</title>
    <summary>  This paper describes our work which is based on discovering context for text
document categorization. The document categorization approach is derived from a
combination of a learning paradigm known as relation extraction and an
technique known as context discovery. We demonstrate the effectiveness of our
categorization approach using reuters 21578 dataset and synthetic real world
data from sports domain. Our experimental results indicate that the learned
context greatly improves the categorization performance as compared to
traditional categorization approaches.
</summary>
    <author>
      <name>Y. V. Haribhakta</name>
    </author>
    <author>
      <name>Dr. Parag Kulkarni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, selected in IJDKP (International Journal of Data Mining and
  Knowledge Management Process)</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2807v2</id>
    <updated>2012-02-09T00:10:38Z</updated>
    <published>2011-12-13T06:46:26Z</published>
    <title>Design and Implementation of a Simple Web Search Engine</title>
    <summary>  We present a simple web search engine for indexing and searching html
documents using python programming language. Because python is well known for
its simple syntax and strong support for main operating systems, we hope it
will be beneficial for learning information retrieval techniques, especially
web search engine technology.
</summary>
    <author>
      <name>Andri Mirzal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Multimedia and Ubiquitous Engineering
  International Journal of Multimedia and Ubiquitous Engineering International
  Journal of Multimedia and Ubiquitous Engineering, Vol. 7, No. 1, January,
  2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2807v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2807v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0040v1</id>
    <updated>2011-12-23T14:18:35Z</updated>
    <published>2011-12-23T14:18:35Z</published>
    <title>Spam filtering by quantitative profiles</title>
    <summary>  Instead of the 'bag-of-words' representation, in the quantitative profile
approach to spam filtering and email categorization, an email is represented by
an m-dimensional vector of numbers, with m fixed in advance. Inspired by Sroufe
et al. [Sroufe, P., Phithakkitnukoon, S., Dantu, R., and Cangussu, J. (2010).
Email shape analysis. In \emph{LNCS}, 5935, pp. 18-29] two instances of
quantitative profiles are considered: line profile and character profile.
Performance of these profiles is studied on the TREC 2007, CEAS 2008 and a
private corpuses. At low computational costs, the two quantitative profiles
achieve performance that is at least comparable to that of heuristic rules and
naive Bayes.
</summary>
    <author>
      <name>M. Grendár</name>
    </author>
    <author>
      <name>J. Škutová</name>
    </author>
    <author>
      <name>V. Špitalský</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">supplementary material including the commented R source code can be
  found at http://www.savbb.sk/~grendar/spam/Supplement.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2240v1</id>
    <updated>2012-01-11T04:56:59Z</updated>
    <published>2012-01-11T04:56:59Z</published>
    <title>Bengali text summarization by sentence extraction</title>
    <summary>  Text summarization is a process to produce an abstract or a summary by
selecting significant portion of the information from one or more texts. In an
automatic text summarization process, a text is given to the computer and the
computer returns a shorter less redundant extract or abstract of the original
text(s). Many techniques have been developed for summarizing English text(s).
But, a very few attempts have been made for Bengali text summarization. This
paper presents a method for Bengali text summarization which extracts important
sentences from a Bengali document to produce a summary.
</summary>
    <author>
      <name>Kamal Sarkar</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of International Conference on Business and
  Information Management(ICBIM-2012),NIT Durgapur, PP 233-245</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.2240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2187v1</id>
    <updated>2012-02-10T04:49:58Z</updated>
    <published>2012-02-10T04:49:58Z</published>
    <title>Museum: Multidimensional web page segment evaluation model</title>
    <summary>  The evaluation of a web page with respect to a query is a vital task in the
web information retrieval domain. This paper proposes the evaluation of a web
page as a bottom-up process from the segment level to the page level. A model
for evaluating the relevancy is proposed incorporating six different
dimensions. An algorithm for evaluating the segments of a web page, using the
above mentioned six dimensions is proposed. The benefits of fine-granining the
evaluation process to the segment level instead of the page level are explored.
The proposed model can be incorporated for various tasks like web page
personalization, result re-ranking, mobile device page rendering etc.
</summary>
    <author>
      <name>K. S. Kuppusamy</name>
    </author>
    <author>
      <name>G. Aghila</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISSN 2151-9617</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing Volume 3, Issue 3 (2011) 24-27</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2393v1</id>
    <updated>2012-02-11T00:12:58Z</updated>
    <published>2012-02-11T00:12:58Z</published>
    <title>Statistical reliability and path diversity based PageRank algorithm
  improvements</title>
    <summary>  In this paper we present new improvement ideas of the original PageRank
algorithm. The first idea is to introduce an evaluation of the statistical
reliability of the ranking score of each node based on the local graph property
and the second one is to introduce the notion of the path diversity. The path
diversity can be exploited to dynamically modify the increment value of each
node in the random surfer model or to dynamically adapt the damping factor. We
illustrate the impact of such modifications through examples and simple
simulations.
</summary>
    <author>
      <name>Dohy Hong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.2393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2; F.2.2; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2622v1</id>
    <updated>2012-02-13T04:21:15Z</updated>
    <published>2012-02-13T04:21:15Z</published>
    <title>A Model for Web Page Usage Mining Based on Segmentation</title>
    <summary>  The web page usage mining plays a vital role in enriching the page's content
and structure based on the feedbacks received from the user's interactions with
the page. This paper proposes a model for micro-managing the tracking
activities by fine-tuning the mining from the page level to the segment level.
The proposed model enables the web-master to identify the segments which
receives more focus from users comparing with others. The segment level
analytics of user actions provides an important metric to analyse the factors
which facilitate the increase in traffic for the page. The empirical validation
of the model is performed through prototype implementation.
</summary>
    <author>
      <name>K. S. Kuppusamy</name>
    </author>
    <author>
      <name>G. Aghila</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Technologies, Vol. 2, No 2 , 2011, 1144-1148</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0747v2</id>
    <updated>2012-06-19T10:19:26Z</updated>
    <published>2012-03-04T16:33:41Z</published>
    <title>A review of EO image information mining</title>
    <summary>  We analyze the state of the art of content-based retrieval in Earth
observation image archives focusing on complete systems showing promise for
operational implementation. The different paradigms at the basis of the main
system families are introduced. The approaches taken are analyzed, focusing in
particular on the phases after primitive feature extraction. The solutions
envisaged for the issues related to feature simplification and synthesis,
indexing, semantic labeling are reviewed. The methodologies for query
specification and execution are analyzed.
</summary>
    <author>
      <name>Marco Quartulli</name>
    </author>
    <author>
      <name>Igor G. Olaizola</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quartulli, Marco, and Igor G Olaizola. "A review of EO image
  information mining." ISPRS Journal of Photogrammetry and Remote Sensing 75:
  p11-28. 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0747v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0747v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1793v1</id>
    <updated>2012-03-08T13:28:47Z</updated>
    <published>2012-03-08T13:28:47Z</published>
    <title>Using Hausdorff Distance for New Medical Image Annotation</title>
    <summary>  Medical images annotation is most of the time a repetitive hard task.
Collecting old similar annotations and assigning them to new medical images may
not only enhance the annotation process, but also reduce ambiguity caused by
repetitive annotations. The goal of this work is to propose an approach based
on Hausdorff distance able to compute similarity between a new medical image
and old stored images. User has to choose then one of the similar images and
annotations related to the selected one are assigned to the new one.
</summary>
    <author>
      <name>Riadh Bouslimi</name>
    </author>
    <author>
      <name>Jalel Akaichi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, 2 tables; International Journal of Database
  Management Systems (IJDMS) Vol.4, No.1, February 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.1793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2569v1</id>
    <updated>2012-03-12T17:57:40Z</updated>
    <published>2012-03-12T17:57:40Z</published>
    <title>When Index Term Probability Violates the Classical Probability Axioms
  Quantum Probability can be a Necessary Theory for Information Retrieval</title>
    <summary>  Probabilistic models require the notion of event space for defining a
probability measure. An event space has a probability measure which ensues the
Kolmogorov axioms. However, the probabilities observed from distinct sources,
such as that of relevance of documents, may not admit a single event space thus
causing some issues. In this article, some results are introduced for ensuring
whether the observed prob- abilities of relevance of documents admit a single
event space. More- over, an alternative framework of probability is introduced,
thus chal- lenging the use of classical probability for ranking documents. Some
reflections on the convenience of extending the classical probabilis- tic
retrieval toward a more general framework which encompasses the issues are
made.
</summary>
    <author>
      <name>Massimo Melucci</name>
    </author>
    <link href="http://arxiv.org/abs/1203.2569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3764v1</id>
    <updated>2012-03-16T16:59:03Z</updated>
    <published>2012-03-16T16:59:03Z</published>
    <title>The Abzooba Smart Health Informatics Platform (SHIP) TM - From Patient
  Experiences to Big Data to Insights</title>
    <summary>  This paper describes a technology to connect patients to information in the
experiences of other patients by using the power of structured big data. The
approach, implemented in the Abzooba Smart Health Informatics Platform
(SHIP),is to distill concepts of facts and expressions from conversations and
discussions in health social media forums, and use those distilled concepts in
connecting patients to experiences and insights that are highly relevant to
them in particular. We envision our work, in progress, to provide new and
effective tools to exploit the richness of content in social media in health
for outcomes research.
</summary>
    <author>
      <name>Naveen Ashish</name>
    </author>
    <author>
      <name>Antarip Biswas</name>
    </author>
    <author>
      <name>Sumit Das</name>
    </author>
    <author>
      <name>Saurav Nag</name>
    </author>
    <author>
      <name>Rajiv Pratap</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2032v3</id>
    <updated>2012-10-16T07:00:44Z</updated>
    <published>2012-04-10T02:53:03Z</published>
    <title>Multi-Output Recommender: Items, Groups and Friends, and Their Mutual
  Contributing Effects</title>
    <summary>  Due to the development of social media technology, it becomes easier for
users to gather together to form groups. Take the Last.fm for example, users
can join groups they may be interested where they can share their loved songs
and discuss topics about songs and singers. However, the number of groups grows
over time, users need effective groups recommendations in order to meet more
like-minded users.
</summary>
    <author>
      <name>Wei Zeng</name>
    </author>
    <author>
      <name>Li Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">withdraw the article</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2032v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2032v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1615v1</id>
    <updated>2012-06-07T21:04:15Z</updated>
    <published>2012-06-07T21:04:15Z</published>
    <title>Objects and Goals Extraction from Semantic Networks : Applications of
  Fuzzy SetS Theory</title>
    <summary>  In this paper we present a short survey of fuzzy and Semantic approaches to
Knowledge Extraction. The goal of such approaches is to define flexible
Knowledge Extraction Systems able to deal with the inherent vagueness and
uncertainty of the Extraction process. In this survey we address if and how
some approaches met their goal.
</summary>
    <author>
      <name>Mohamed Nazih Omri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1206.1042, arXiv:1206.0925</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Conf\'erence Internationale : Science \'Electroniques,
  Technologies de l'Information et des T\'el\'ecommunications(SETIT), p.
  275-282, Mahdia, Tunisie, 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.1615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1624v1</id>
    <updated>2012-06-07T21:36:08Z</updated>
    <published>2012-06-07T21:36:08Z</published>
    <title>Measure of Similarity between Fuzzy Concepts for Optimization of Fuzzy
  Semantic Nets</title>
    <summary>  This paper presents a method to measure the similarity between different
fuzzy concepts in order to optimize Semantic networks. The problem approached
is the minimization of the time of research and identification of user's
Objects and Goals. Indeed, it concerns to determine to each instant the
totality of Objects (respectively Goals) among which one can identify rapidly
the most satisfactory for the user's Object and Goal. Alone Objects and most
similar Goals to Objects and researched Goals of the viewpoint of attribute
values will be processed, what will avoid the analysis of all Objects and
system Goals far of needs of the user.
</summary>
    <author>
      <name>Mohamed nazih Omri</name>
    </author>
    <author>
      <name>Noureddine Chouigui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14th International Conference on Systems Science. Wroclaw, Poland,
  2001</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3278v1</id>
    <updated>2012-06-13T15:42:17Z</updated>
    <published>2012-06-13T15:42:17Z</published>
    <title>Topic Models Conditioned on Arbitrary Features with
  Dirichlet-multinomial Regression</title>
    <summary>  Although fully generative models have been successfully used to model the
contents of text documents, they are often awkward to apply to combinations of
text data and document metadata. In this paper we propose a
Dirichlet-multinomial regression (DMR) topic model that includes a log-linear
prior on document-topic distributions that is a function of observed features
of the document, such as author, publication venue, references, and dates. We
show that by selecting appropriate features, DMR topic models can meet or
exceed the performance of several previously published topic models designed
for specific data.
</summary>
    <author>
      <name>David Mimno</name>
    </author>
    <author>
      <name>Andrew McCallum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3278v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3278v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5584v1</id>
    <updated>2012-06-25T06:07:20Z</updated>
    <published>2012-06-25T06:07:20Z</published>
    <title>Web-page Prediction for Domain Specific Web-search using Boolean Bit
  Mask</title>
    <summary>  Search Engine is a Web-page retrieval tool. Nowadays Web searchers utilize
their time using an efficient search engine. To improve the performance of the
search engine, we are introducing a unique mechanism which will give Web
searchers more prominent search results. In this paper, we are going to discuss
a domain specific Web search prototype which will generate the predicted
Web-page list for user given search string using Boolean bit mask.
</summary>
    <author>
      <name>Sukanta Sinha</name>
    </author>
    <author>
      <name>Rana Duttagupta</name>
    </author>
    <author>
      <name>Debajyoti Mukhopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Computer Science, Eng. &amp; Appl., AISC 167, pp. 211-220,
  Springerlink, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.5584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6858v1</id>
    <updated>2012-06-27T16:26:46Z</updated>
    <published>2012-06-27T16:26:46Z</published>
    <title>Sequential Document Representations and Simplicial Curves</title>
    <summary>  The popular bag of words assumption represents a document as a histogram of
word occurrences. While computationally efficient, such a representation is
unable to maintain any sequential information. We present a continuous and
differentiable sequential document representation that goes beyond the bag of
words assumption, and yet is efficient and effective. This representation
employs smooth curves in the multinomial simplex to account for sequential
information. We discuss the representation and its geometric properties and
demonstrate its applicability for the task of text classification.
</summary>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1414v1</id>
    <updated>2012-07-04T16:23:52Z</updated>
    <published>2012-07-04T16:23:52Z</published>
    <title>Two-Way Latent Grouping Model for User Preference Prediction</title>
    <summary>  We introduce a novel latent grouping model for predicting the relevance of a
new document to a user. The model assumes a latent group structure for both
users and documents. We compared the model against a state-of-the-art method,
the User Rating Profile model, where only users have a latent group structure.
We estimate both models by Gibbs sampling. The new method predicts relevance
more accurately for new documents that have few known ratings. The reason is
that generalization over documents then becomes necessary and hence the twoway
grouping is profitable.
</summary>
    <author>
      <name>Eerika Savia</name>
    </author>
    <author>
      <name>Kai Puolamaki</name>
    </author>
    <author>
      <name>Janne Sinkkonen</name>
    </author>
    <author>
      <name>Samuel Kaski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3583v1</id>
    <updated>2012-07-16T06:07:47Z</updated>
    <published>2012-07-16T06:07:47Z</published>
    <title>Information Retrieval Model: A Social Network Extraction Perspective</title>
    <summary>  Future Information Retrieval, especially in connection with the internet,
will incorporate the content descriptions that are generated with social
network extraction technologies and preferably incorporate the probability
theory for assigning the semantic. Although there is an increasing interest
about social network extraction, but a little of them has a significant impact
to infomation retrieval. Therefore this paper proposes a model of information
retrieval from the social network extraction.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <author>
      <name>Shahrul Azman Noah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4152v1</id>
    <updated>2012-07-11T14:59:15Z</updated>
    <published>2012-07-11T14:59:15Z</published>
    <title>Maximum Entropy for Collaborative Filtering</title>
    <summary>  Within the task of collaborative filtering two challenges for computing
conditional probabilities exist. First, the amount of training data available
is typically sparse with respect to the size of the domain. Thus, support for
higher-order interactions is generally not present. Second, the variables that
we are conditioning upon vary for each query. That is, users label different
variables during each query. For this reason, there is no consistent input to
output mapping. To address these problems we purpose a maximum entropy approach
using a non-standard measure of entropy. This approach can be simplified to
solving a set of linear equations that can be efficiently solved.
</summary>
    <author>
      <name>Lawrence Zitnick</name>
    </author>
    <author>
      <name>Takeo Kanade</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.4152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4259v1</id>
    <updated>2012-07-18T04:11:55Z</updated>
    <published>2012-07-18T04:11:55Z</published>
    <title>Content Based Multimedia Information Retrieval to Support Digital
  Libraries</title>
    <summary>  Content-based multimedia information retrieval is an interesting research
area since it allows retrieval based on inherent characteristic of multimedia
objects. For example retrieval based on visual characteristics such as colour,
shapes or textures of objects in images or retrieval based on spatial
relationships among objects in the media (images or video clips). This paper
reviews some work done in image and video retrieval and then proposes an
integrated model that can handle images and video clips uniformly. Using this
model retrieval on images or video clips can be done based on the same
framework.
</summary>
    <author>
      <name>Mohammad Nabil Almunawar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, conference paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on New Information Technologies, 23-26
  July, 2001, Brunei Darussalam</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.4259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6600v1</id>
    <updated>2012-07-27T17:16:59Z</updated>
    <published>2012-07-27T17:16:59Z</published>
    <title>Diversity in Ranking using Negative Reinforcement</title>
    <summary>  In this paper, we consider the problem of diversity in ranking of the nodes
in a graph. The task is to pick the top-k nodes in the graph which are both
'central' and 'diverse'. Many graph-based models of NLP like text
summarization, opinion summarization involve the concept of diversity in
generating the summaries. We develop a novel method which works in an iterative
fashion based on random walks to achieve diversity. Specifically, we use
negative reinforcement as a main tool to introduce diversity in the
Personalized PageRank framework. Experiments on two benchmark datasets show
that our algorithm is competitive to the existing methods.
</summary>
    <author>
      <name>Rama Badrinath</name>
    </author>
    <author>
      <name>C. E. Veni Madhavan</name>
    </author>
    <link href="http://arxiv.org/abs/1207.6600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.1011v1</id>
    <updated>2012-08-05T14:03:22Z</updated>
    <published>2012-08-05T14:03:22Z</published>
    <title>Credibility in Web Search Engines</title>
    <summary>  Web search engines apply a variety of ranking signals to achieve user
satisfaction, i.e., results pages that provide the best-possible results to the
user. While these ranking signals implicitly consider credibility (e.g., by
measuring popularity), explicit measures of credibility are not applied. In
this chapter, credibility in Web search engines is discussed in a broad
context: credibility as a measure for including documents in a search engine's
index, credibility as a ranking signal, credibility in the context of universal
search results, and the possibility of using credibility as an explicit measure
for ranking purposes. It is found that while search engines-at least to a
certain extent-show credible results to their users, there is no fully
integrated credibility framework for Web search engines.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <link href="http://arxiv.org/abs/1208.1011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.1011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4147v3</id>
    <updated>2015-11-27T22:55:51Z</updated>
    <published>2012-08-21T00:28:32Z</published>
    <title>Generating ordered list of Recommended Items: a Hybrid Recommender
  System of Microblog</title>
    <summary>  Precise recommendation of followers helps in improving the user experience
and maintaining the prosperity of twitter and microblog platforms. In this
paper, we design a hybrid recommender system of microblog as a solution of KDD
Cup 2012, track 1 task, which requires predicting users a user might follow in
Tencent Microblog. We describe the background of the problem and present the
algorithm consisting of keyword analysis, user taxonomy, (potential)interests
extraction and item recommendation. Experimental result shows the high
performance of our algorithm. Some possible improvements are discussed, which
leads to further study.
</summary>
    <author>
      <name>Yingzhen Li</name>
    </author>
    <author>
      <name>Ye Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.4147v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4147v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0126v1</id>
    <updated>2012-09-01T19:45:01Z</updated>
    <published>2012-09-01T19:45:01Z</published>
    <title>Evaluation of some Information Retrieval models for Gujarati Ad hoc
  Monolingual Tasks</title>
    <summary>  This paper describes the work towards Gujarati Ad hoc Monolingual Retrieval
task for widely used Information Retrieval (IR) models. We present an indexing
baseline for the Gujarati Language represented by Mean Average Precision (MAP)
values. Our objective is to obtain a relative picture of a better IR model for
Gujarati Language. Results show that Classical IR models like Term Frequency
Inverse Document Frequency (TF_IDF) performs better when compared to few recent
probabilistic IR models. The experiments helped to identify the outperforming
IR models for Gujarati Language.
</summary>
    <author>
      <name>Hardik J. Joshi</name>
    </author>
    <author>
      <name>Pareek Jyoti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, Some text in Gujarati Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">VNSGU Journal of Science and Technology,3,2,176-181,2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.0126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1125v1</id>
    <updated>2012-09-05T21:28:32Z</updated>
    <published>2012-09-05T21:28:32Z</published>
    <title>Video Data Visualization System: Semantic Classification And
  Personalization</title>
    <summary>  We present in this paper an intelligent video data visualization tool, based
on semantic classification, for retrieving and exploring a large scale corpus
of videos. Our work is based on semantic classification resulting from semantic
analysis of video. The obtained classes will be projected in the visualization
space. The graph is represented by nodes and edges, the nodes are the keyframes
of video documents and the edges are the relation between documents and the
classes of documents. Finally, we construct the user's profile, based on the
interaction with the system, to render the system more adequate to its
references.
</summary>
    <author>
      <name>Jamel Slimi</name>
    </author>
    <author>
      <name>Anis Ben Ammar</name>
    </author>
    <author>
      <name>Adel M. Alimi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcga.2012.2201</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcga.2012.2201" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">graphics</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.1125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1719v1</id>
    <updated>2012-09-08T14:02:12Z</updated>
    <published>2012-09-08T14:02:12Z</published>
    <title>Semi-metric networks for recommender systems</title>
    <summary>  Weighted graphs obtained from co-occurrence in user-item relations lead to
non-metric topologies. We use this semi-metric behavior to issue
recommendations, and discuss its relationship to transitive closure on fuzzy
graphs. Finally, we test the performance of this method against other item- and
user-based recommender systems on the Movielens benchmark. We show that
including highly semi-metric edges in our recommendation algorithms leads to
better recommendations.
</summary>
    <author>
      <name>Tiago Simas</name>
    </author>
    <author>
      <name>Luis M. Rocha</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2012 IEEE/WIC/ACM International Conference on Web Intelligence and
  Intelligent Agent Technology</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4479v1</id>
    <updated>2012-09-20T09:59:53Z</updated>
    <published>2012-09-20T09:59:53Z</published>
    <title>Beyond Cumulated Gain and Average Precision: Including Willingness and
  Expectation in the User Model</title>
    <summary>  In this paper, we define a new metric family based on two concepts: The
definition of the stopping criterion and the notion of satisfaction, where the
former depends on the willingness and expectation of a user exploring search
results. Both concepts have been discussed so far in the IR literature, but we
argue in this paper that defining a proper single valued metric depends on
merging them into a single conceptual framework.
</summary>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <author>
      <name>Georges Dupret</name>
    </author>
    <author>
      <name>Mounia Lalmas</name>
    </author>
    <link href="http://arxiv.org/abs/1209.4479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6492v1</id>
    <updated>2012-09-28T11:50:15Z</updated>
    <published>2012-09-28T11:50:15Z</published>
    <title>Information Retrieval on the web and its evaluation</title>
    <summary>  Internet is one of the main sources of information for millions of people.
One can find information related to practically all matters on internet.
Moreover if we want to retrieve information about some particular topic we may
find thousands of Web Pages related to that topic. But our main concern is to
find relevant Web Pages from among that collection. So in this paper I have
discussed that how information is retrieved from the web and the efforts
required for retrieving this information in terms of system and users efforts.
</summary>
    <author>
      <name>Deepika Sharma</name>
    </author>
    <author>
      <name>Deepak Garg</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 40(3):26-31, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.6492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3312v1</id>
    <updated>2012-10-11T18:21:01Z</updated>
    <published>2012-10-11T18:21:01Z</published>
    <title>Artex is AnotheR TEXt summarizer</title>
    <summary>  This paper describes Artex, another algorithm for Automatic Text
Summarization. In order to rank sentences, a simple inner product is calculated
between each sentence, a document vector (text topic) and a lexical vector
(vocabulary used by a sentence). Summaries are then generated by assembling the
highest ranked sentences. No ruled-based linguistic post-processing is
necessary in order to obtain summaries. Tests over several datasets (coming
from Document Understanding Conferences (DUC), Text Analysis Conferences (TAC),
evaluation campaigns, etc.) in French, English and Spanish have shown that
summarizer achieves interesting results.
</summary>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:1209.3126</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3312v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3312v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0689v1</id>
    <updated>2012-11-04T14:50:16Z</updated>
    <published>2012-11-04T14:50:16Z</published>
    <title>Enhancing Invenio Digital Library With An External Relevance Ranking
  Engine</title>
    <summary>  Invenio is a comprehensive web-based free digital library software suite
originally developed at CERN. In order to improve its information retrieval and
word similarity ranking capabilities, the goal of this thesis is to enhance
Invenio by bridging it with modern external information retrieval systems. In
the first part a comparison of various information retrieval systems such as
Solr and Xapian is made. In the second part a system-independent bridge for
word similarity ranking is designed and implemented. Subsequently, Solr and
Xapian are integrated in Invenio via adapters to the bridge. In the third part
scalability tests are performed. Finally, a future outlook is briefly
discussed.
</summary>
    <author>
      <name>Patrick O. Glauner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">70 pages, 34 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3402v1</id>
    <updated>2012-11-14T20:04:51Z</updated>
    <published>2012-11-14T20:04:51Z</published>
    <title>Genetic Optimization of Keywords Subset in the Classification Analysis
  of Texts Authorship</title>
    <summary>  The genetic selection of keywords set, the text frequencies of which are
considered as attributes in text classification analysis, has been analyzed.
The genetic optimization was performed on a set of words, which is the fraction
of the frequency dictionary with given frequency limits. The frequency
dictionary was formed on the basis of analyzed text array of texts of English
fiction. As the fitness function which is minimized by the genetic algorithm,
the error of nearest k neighbors classifier was used. The obtained results show
high precision and recall of texts classification by authorship categories on
the basis of attributes of keywords set which were selected by the genetic
algorithm from the frequency dictionary.
</summary>
    <author>
      <name>Bohdan Pavlyshenko</name>
    </author>
    <link href="http://arxiv.org/abs/1211.3402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1068v1</id>
    <updated>2012-12-05T15:58:19Z</updated>
    <published>2012-12-05T15:58:19Z</published>
    <title>Spectral properties of Google matrix of Wikipedia and other networks</title>
    <summary>  We study the properties of eigenvalues and eigenvectors of the Google matrix
of the Wikipedia articles hyperlink network and other real networks. With the
help of the Arnoldi method we analyze the distribution of eigenvalues in the
complex plane and show that eigenstates with significant eigenvalue modulus are
located on well defined network communities. We also show that the correlator
between PageRank and CheiRank vectors distinguishes different organizations of
information flow on BBC and Le Monde web sites.
</summary>
    <author>
      <name>Leonardo Ermann</name>
    </author>
    <author>
      <name>Klaus M. Frahm</name>
    </author>
    <author>
      <name>Dima L. Shepelyansky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2013-31090-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2013-31090-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B 86, 193 (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.1068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1918v1</id>
    <updated>2012-12-09T20:55:52Z</updated>
    <published>2012-12-09T20:55:52Z</published>
    <title>Condensés de textes par des méthodes numériques</title>
    <summary>  Since information in electronic form is already a standard, and that the
variety and the quantity of information become increasingly large, the methods
of summarizing or automatic condensation of texts is a critical phase of the
analysis of texts. This article describes CORTEX a system based on numerical
methods, which allows obtaining a condensation of a text, which is independent
of the topic and of the length of the text. The structure of the system enables
it to find the abstracts in French or Spanish in very short times.
</summary>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Patricia Velázquez-Morales</name>
    </author>
    <author>
      <name>Jean-Guy Meunier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conf\'erence JADT 2002, Saint-Malo/France. 12 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.1918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2065v1</id>
    <updated>2012-12-10T13:57:59Z</updated>
    <published>2012-12-10T13:57:59Z</published>
    <title>A Survey on Information Retrieval, Text Categorization, and Web Crawling</title>
    <summary>  This paper is a survey discussing Information Retrieval concepts, methods,
and applications. It goes deep into the document and query modelling involved
in IR systems, in addition to pre-processing operations such as removing stop
words and searching by synonym techniques. The paper also tackles text
categorization along with its application in neural networks and machine
learning. Finally, the architecture of web crawlers is to be discussed shedding
the light on how internet spiders index web documents and how they allow users
to search for items on the web.
</summary>
    <author>
      <name>Youssef Bassil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LACSC - Lebanese Association for Computational Sciences,
  http://www.lacsc.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computer Science &amp; Research (JCSCR), Vol. 1, No. 6, pp.
  1-11, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.2065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2145v1</id>
    <updated>2012-12-10T17:39:44Z</updated>
    <published>2012-12-10T17:39:44Z</published>
    <title>A Scale-Space Theory for Text</title>
    <summary>  Scale-space theory has been established primarily by the computer vision and
signal processing communities as a well-founded and promising framework for
multi-scale processing of signals (e.g., images). By embedding an original
signal into a family of gradually coarsen signals parameterized with a
continuous scale parameter, it provides a formal framework to capture the
structure of a signal at different scales in a consistent way. In this paper,
we present a scale space theory for text by integrating semantic and spatial
filters, and demonstrate how natural language documents can be understood,
processed and analyzed at multiple resolutions, and how this scale-space
representation can be used to facilitate a variety of NLP and text analysis
tasks.
</summary>
    <author>
      <name>Shuang-Hong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures; Nature language processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.2145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3013v1</id>
    <updated>2012-12-12T23:25:46Z</updated>
    <published>2012-12-12T23:25:46Z</published>
    <title>Product/Brand extraction from WikiPedia</title>
    <summary>  In this paper we describe the task of extracting product and brand pages from
wikipedia. We present an experimental environment and setup built on top of a
dataset of wikipedia pages we collected. We introduce a method for recognition
of product pages modelled as a boolean probabilistic classification task. We
show that this approach can lead to promising results and we discuss
alternative approaches we considered.
</summary>
    <author>
      <name>K. Massoudi</name>
    </author>
    <author>
      <name>G. Modena</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages. Manuscript first creation date: November 27, 2009. At the
  time of first creation both authors were affiliated with the University of
  Amsterdam (The Netherlands)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3023v1</id>
    <updated>2012-12-13T00:34:23Z</updated>
    <published>2012-12-13T00:34:23Z</published>
    <title>Keyword Extraction for Identifying Social Actors</title>
    <summary>  Identifying the social actor has become one of tasks in Artificial
Intelligence, whereby extracting keyword from Web snippets depend on the use of
web is steadily gaining ground in this research. We develop therefore an
approach based on overlap principle for utilizing a collection of features in
web snippets, where use of keyword will eliminate the un-relevant web pages.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <author>
      <name>Shahrul Azman Mohd Noah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, nothing, draft to ICOCSIM 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5442v1</id>
    <updated>2012-12-21T14:00:23Z</updated>
    <published>2012-12-21T14:00:23Z</published>
    <title>Étude comparée de quatre logiciels de gestion de références
  bibliographiques libres ou gratuits</title>
    <summary>  This article is the result of the analysis of various bibliographic reference
management tools, especially those that are free. The use of editorial tools by
bibliographic editors has evolved rapidly since 2007. But, until recently, free
software has fallen short when it comes to ergonomics or use. The functional
and technical panorama offered by free software is the result of the comparison
of JabRef, Mendeley Desktop, BibDesk and Zotero software undertaken in January
2012 by two research professors affiliated with the Institut national
fran\c{c}ais des techniques de la documentation (INTD).
</summary>
    <author>
      <name>Gérald Kembellec</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DICEN CNAM</arxiv:affiliation>
    </author>
    <author>
      <name>Claire Scopsi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DICEN CNAM</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Documentation et Bibliotheques 58, 4 (2012) 187-197</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2320v1</id>
    <updated>2013-01-10T16:27:15Z</updated>
    <published>2013-01-10T16:27:15Z</published>
    <title>Using Temporal Data for Making Recommendations</title>
    <summary>  We treat collaborative filtering as a univariate time series estimation
problem: given a user's previous votes, predict the next vote. We describe two
families of methods for transforming data to encode time order in ways amenable
to off-the-shelf classification and density estimation tools, and examine the
results of using these approaches on several real-world data sets. The
improvements in predictive accuracy we realize recommend the use of other
predictive algorithms that exploit the temporal order of data.
</summary>
    <author>
      <name>Andrew Zimdars</name>
    </author>
    <author>
      <name>David Maxwell Chickering</name>
    </author>
    <author>
      <name>Christopher Meek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Seventeenth Conference on Uncertainty
  in Artificial Intelligence (UAI2001)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4171v1</id>
    <updated>2013-01-17T17:46:27Z</updated>
    <published>2013-01-17T17:46:27Z</published>
    <title>Affinity Weighted Embedding</title>
    <summary>  Supervised (linear) embedding models like Wsabie and PSI have proven
successful at ranking, recommendation and annotation tasks. However, despite
being scalable to large datasets they do not take full advantage of the extra
data due to their linear nature, and typically underfit. We propose a new class
of models which aim to provide improved performance while retaining many of the
benefits of the existing class of embedding models. Our new approach works by
iteratively learning a linear embedding model where the next iteration's
features and labels are reweighted as a function of the previous iteration. We
describe several variants of the family, and give some initial results.
</summary>
    <author>
      <name>Jason Weston</name>
    </author>
    <author>
      <name>Ron Weiss</name>
    </author>
    <author>
      <name>Hector Yee</name>
    </author>
    <link href="http://arxiv.org/abs/1301.4171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0481v2</id>
    <updated>2014-03-30T08:09:43Z</updated>
    <published>2013-03-03T09:32:44Z</published>
    <title>Situation-Aware Approach to Improve Context-based Recommender System</title>
    <summary>  In this paper, we introduce a novel situation aware approach to improve a
context based recommender system. To build situation aware user profiles, we
rely on evidence issued from retrieval situations. A retrieval situation refers
to the social spatio temporal context of the user when he interacts with the
recommender system. A situation is represented as a combination of social
spatio temporal concepts inferred from ontological knowledge given social
group, location and time information. User's interests are inferred from past
user's interaction with the recommender system related to the identified
situations. They are represented using concepts issued from a domain ontology.
We also propose a method to dynamically adapt the system to the user's
interest's evolution.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1303.0481v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0481v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0485v2</id>
    <updated>2014-04-15T08:31:54Z</updated>
    <published>2013-03-03T10:23:38Z</published>
    <title>Optimizing an Utility Function for Exploration / Exploitation Trade-off
  in Context-Aware Recommender System</title>
    <summary>  In this paper, we develop a dynamic exploration/ exploitation (exr/exp)
strategy for contextual recommender systems (CRS). Specifically, our methods
can adaptively balance the two aspects of exr/exp by automatically learning the
optimal tradeoff. This consists of optimizing a utility function represented by
a linearized form of the probability distributions of the rewards of the
clicked and the non-clicked documents already recommended. Within an offline
simulation framework we apply our algorithms to a CRS and conduct an evaluation
with real event log data. The experimental results and detailed analysis
demonstrate that our algorithms outperform existing algorithms in terms of
click-through-rate (CTR).
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1303.0485v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0485v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2156v1</id>
    <updated>2013-03-09T02:01:04Z</updated>
    <published>2013-03-09T02:01:04Z</published>
    <title>The Powerful Model Adpredictor for Search Engine Switching Detection
  Challenge</title>
    <summary>  The purpose of the Switching Detection Challenge in the 2013 WSCD workshop
was to predict users' search engine swithcing actions given records about
search sessions and logs.Our solution adopted the powerful prediction model
Adpredictor and utilized the method of feature engineering. We successfully
applied the click through rate (CTR) prediction model Adpredicitor into our
solution framework, and then the discovery of effective features and the
multiple classification of different switching type make our model outperforms
many competitors. We achieved an AUC score of 0.84255 on the private
leaderboard and ranked the 5th among all the competitors in the competition.
</summary>
    <author>
      <name>Heng Gao</name>
    </author>
    <author>
      <name>Yongbao Li</name>
    </author>
    <author>
      <name>Qiudan Li</name>
    </author>
    <author>
      <name>Daniel Zeng</name>
    </author>
    <link href="http://arxiv.org/abs/1303.2156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6906v1</id>
    <updated>2013-03-26T16:33:00Z</updated>
    <published>2013-03-26T16:33:00Z</published>
    <title>Large scale citation matching using Apache Hadoop</title>
    <summary>  During the process of citation matching links from bibliography entries to
referenced publications are created. Such links are indicators of topical
similarity between linked texts, are used in assessing the impact of the
referenced document and improve navigation in the user interfaces of digital
libraries. In this paper we present a citation matching method and show how to
scale it up to handle great amounts of data using appropriate indexing and a
MapReduce paradigm in the Hadoop environment.
</summary>
    <author>
      <name>Mateusz Fedoryszak</name>
    </author>
    <author>
      <name>Dominika Tkaczyk</name>
    </author>
    <author>
      <name>Łukasz Bolikowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.6906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3845v2</id>
    <updated>2014-03-30T08:19:52Z</updated>
    <published>2013-04-13T20:35:56Z</published>
    <title>The Impact of Situation Clustering in Contextual-Bandit Algorithm for
  Context-Aware Recommender Systems</title>
    <summary>  Most existing approaches in Context-Aware Recommender Systems (CRS) focus on
recommending relevant items to users taking into account contextual
information, such as time, location, or social aspects. However, few of them
have considered the problem of user's content dynamicity. We introduce in this
paper an algorithm that tackles the user's content dynamicity by modeling the
CRS as a contextual bandit algorithm and by including a situation clustering
algorithm to improve the precision of the CRS. Within a deliberately designed
offline simulation framework, we conduct evaluations with real online event log
data. The experimental results and detailed analysis reveal several important
discoveries in context aware recommender system.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <link href="http://arxiv.org/abs/1304.3845v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3845v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6181v1</id>
    <updated>2013-04-23T06:42:55Z</updated>
    <published>2013-04-23T06:42:55Z</published>
    <title>Evaluating Web Content Quality via Multi-scale Features</title>
    <summary>  Web content quality measurement is crucial to various web content processing
applications. This paper will explore multi-scale features which may affect the
quality of a host, and develop automatic statistical methods to evaluate the
Web content quality. The extracted properties include statistical content
features, page and host level link features and TFIDF features. The experiments
on ECML/PKDD 2010 Discovery Challenge data set show that the algorithm is
effective and feasible for the quality tasks of multiple languages, and the
multi-scale features have different identification ability and provide good
complement to each other for most tasks.
</summary>
    <author>
      <name>Guang-Gang Geng</name>
    </author>
    <author>
      <name>Xiao-Bo Jin</name>
    </author>
    <author>
      <name>Xin-Chang Zhang</name>
    </author>
    <author>
      <name>De-Xian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figures, ecml/pkdd 2010 discovery challenge</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2831v1</id>
    <updated>2013-05-10T08:06:15Z</updated>
    <published>2013-05-10T08:06:15Z</published>
    <title>Test Model for Text Categorization and Text Summarization</title>
    <summary>  Text Categorization is the task of automatically sorting a set of documents
into categories from a predefined set and Text Summarization is a brief and
accurate representation of input text such that the output covers the most
important concepts of the source in a condensed manner. Document Summarization
is an emerging technique for understanding the main purpose of any kind of
documents. This paper presents a model that uses text categorization and text
summarization for searching a document based on user query.
</summary>
    <author>
      <name>Khushboo Thakkar</name>
    </author>
    <author>
      <name>Urmila Shrawankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pages: 07 Figures : 07</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal on Computer Science and Engineering (IJCSE),
  ISSN : 0975-3397, Vol. 3 No. 4 Apr 2011 pp 1539-1545</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.2831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5827v1</id>
    <updated>2013-05-24T19:02:59Z</updated>
    <published>2013-05-24T19:02:59Z</published>
    <title>Semantic Web Search based on Ontology Modeling using Protege Reasoner</title>
    <summary>  The Semantic Web works on the existing Web which presents the meaning of
information as well-defined vocabularies understood by the people. Semantic
Search, at the same time, works on improving the accuracy if a search by
understanding the intent of the search and providing contextually relevant
results. This paper describes a semantic approach toward web search through a
PHP application. The goal was to parse through a user's browsing history and
return semantically relevant web pages for the search query provided.
</summary>
    <author>
      <name>Monica Shekhar</name>
    </author>
    <author>
      <name>Saravanaguru RA. K</name>
    </author>
    <link href="http://arxiv.org/abs/1305.5827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2015v1</id>
    <updated>2013-07-08T10:12:01Z</updated>
    <published>2013-07-08T10:12:01Z</published>
    <title>Full-text Support for Publish/Subscribe Ontology Systems</title>
    <summary>  We envision a publish/subscribe ontology system that is able to index
millions of user subscriptions and filter them against ontology data that
arrive in a streaming fashion. In this work, we propose a SPARQL extension
appropriate for a publish/subscribe setting; our extension builds on the
natural semantic graph matching of the language and supports the creation of
full-text subscriptions. Subsequently, we propose a main-memory subscription
indexing algorithm which performs both semantic and full-text matching at low
complexity and minimal filtering time. Thus, when ontology data are published
matching subscriptions are identified and notifications are forwarded to users.
</summary>
    <author>
      <name>Lefteris Zervakis</name>
    </author>
    <author>
      <name>Christos Tryfonopoulos</name>
    </author>
    <author>
      <name>Antonios Papadakis-Pesaresi</name>
    </author>
    <author>
      <name>Manolis Koubarakis</name>
    </author>
    <author>
      <name>Spiros Skiadopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ESWC 2012 Demo</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.2015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6422v1</id>
    <updated>2013-07-24T13:59:48Z</updated>
    <published>2013-07-24T13:59:48Z</published>
    <title>Mesure de la similarité entre termes et labels de concepts
  ontologiques</title>
    <summary>  We propose in this paper a method for measuring the similarity between
ontological concepts and terms. Our metric can take into account not only the
common words of two strings to compare but also other features such as the
position of the words in these strings, or the number of deletion, insertion or
replacement of words required for the construction of one of the two strings
from each other. The proposed method was then used to determine the ontological
concepts which are equivalent to the terms that qualify toponymes. It aims to
find the topographical type of the toponyme.
</summary>
    <author>
      <name>Van Tien Nguyen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Sallaberry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Mauro Gaio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CORIA 2013, Neufch\^atel : Suisse (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.6422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8060v1</id>
    <updated>2013-07-30T17:36:53Z</updated>
    <published>2013-07-30T17:36:53Z</published>
    <title>Extracting Information-rich Part of Texts using Text Denoising</title>
    <summary>  The aim of this paper is to report on a novel text reduction technique,
called Text Denoising, that highlights information-rich content when processing
a large volume of text data, especially from the biomedical domain. The core
feature of the technique, the text readability index, embodies the hypothesis
that complex text is more information-rich than the rest. When applied on tasks
like biomedical relation bearing text extraction, keyphrase indexing and
extracting sentences describing protein interactions, it is evident that the
reduced set of text produced by text denoising is more information-rich than
the rest.
</summary>
    <author>
      <name>Rushdi Shams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26th Canadian Conference on Artificial Intelligence (CAI-2013),
  Regina, Canada, May 29-31, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.8060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3333v1</id>
    <updated>2013-10-12T03:48:38Z</updated>
    <published>2013-10-12T03:48:38Z</published>
    <title>Visualizing Bags of Vectors</title>
    <summary>  The motivation of this work is two-fold - a) to compare between two different
modes of visualizing data that exists in a bag of vectors format b) to propose
a theoretical model that supports a new mode of visualizing data. Visualizing
high dimensional data can be achieved using Minimum Volume Embedding, but the
data has to exist in a format suitable for computing similarities while
preserving local distances. This paper compares the visualization between two
methods of representing data and also proposes a new method providing sample
visualizations for that method.
</summary>
    <author>
      <name>Sriramkumar Balasubramanian</name>
    </author>
    <author>
      <name>Raghuram Reddy Nagireddy</name>
    </author>
    <link href="http://arxiv.org/abs/1310.3333v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3333v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6110v1</id>
    <updated>2013-10-23T04:41:18Z</updated>
    <published>2013-10-23T04:41:18Z</published>
    <title>A two-step model and the algorithm for recalling in recommender systems</title>
    <summary>  When a user finds an interesting recommendation in a recommender system, the
user may want to recall related items recommended in the past to reconsider or
to enjoy them again. If the system can pick up such "recalled" items at each
user's request, it must deepen the user experience.
  We propose a model and the algorithm for such personalized "recalling" in
conventional recommender systems, which is an application of neural networks
for associative memory. In our model, the "recalled" items can reflect each
user's personality beyond naive similarities between items.
</summary>
    <author>
      <name>Keisuke Hara</name>
    </author>
    <author>
      <name>Tomihisa Kamada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, No figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.8226v1</id>
    <updated>2013-10-30T16:38:03Z</updated>
    <published>2013-10-30T16:38:03Z</published>
    <title>Bibliometric-enhanced Information Retrieval</title>
    <summary>  Bibliometric techniques are not yet widely used to enhance retrieval
processes in digital libraries, although they offer value-added effects for
users. In this workshop we will explore how statistical modelling of
scholarship, such as Bradfordizing or network analysis of coauthorship network,
can improve retrieval services for specific communities, as well as for large,
cross-domain collections. This workshop aims to raise awareness of the missing
link between information retrieval (IR) and bibliometrics/scientometrics and to
create a common ground for the incorporation of bibliometric-enhanced services
into retrieval at the digital library interface.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Andrea Scharnhorst</name>
    </author>
    <author>
      <name>Birger Larsen</name>
    </author>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, accepted workshop proposal for ECIR 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.8226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.8226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0667v1</id>
    <updated>2013-11-04T12:13:50Z</updated>
    <published>2013-11-04T12:13:50Z</published>
    <title>Developing a Visual Interactive Search History Exploration System</title>
    <summary>  As users advance in their search within a system, different queries are
conducted and various results are examined by them. These objects form an
implicit individual library representing the acquired knowledge. In our
research we aim to supply the user with visualizations of the search history
and interaction methods to organize the history. The fundamental question is
what role search history exploration can play in the users search process. In
this paper we want to introduce Ideas of a prototypical system for search
history exploration and discuss methods to address the questions mentioned
above.
</summary>
    <author>
      <name>Wilko van Hoek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">KNOWeSCAPE 2013, 2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4151v1</id>
    <updated>2013-11-17T12:02:12Z</updated>
    <published>2013-11-17T12:02:12Z</published>
    <title>Lattice-cell : Hybrid approach for text categorization</title>
    <summary>  In this paper, we propose a new text categorization framework based on
Concepts Lattice and cellular automata. In this framework, concept structure
are modeled by a Cellular Automaton for Symbolic Induction (CASI). Our
objective is to reduce time categorization caused by the Concept Lattice. We
examine, by experiments the performance of the proposed approach and compare it
with other algorithms such as Naive Bayes and k nearest neighbors. The results
show performance improvement while reducing time categorization.
</summary>
    <author>
      <name>Hichem Benfriha</name>
    </author>
    <author>
      <name>Fatiha Barigou</name>
    </author>
    <author>
      <name>Baghdad Atmani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/csit.2013.3817</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/csit.2013.3817" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Science &amp; Information Technology (CS &amp; IT) 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.4151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4900v1</id>
    <updated>2013-11-16T06:25:40Z</updated>
    <published>2013-11-16T06:25:40Z</published>
    <title>Query Interface Integrator For Domain Specific Hidden Web</title>
    <summary>  Web is title admittance today mainly relies on search engines. A large amount
of data is hidden in the databases behind the search interfaces referred to as
Hidden web, which needs to be indexed so in order to serve user query. In this
paper database and data mining techniques are used for query interface
integration. The query interface must resemble the look and feel of local
interface as much as possible despite being automatically generated without
human support.This technique keeps the related documents in the same domain so
that searching of documents becomes more efficient in terms of time complexity.
</summary>
    <author>
      <name>Sudhakar Ranjan</name>
    </author>
    <author>
      <name>Komal K. Bhatia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages. International Journal of Computer Engineering and
  Applications, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.4900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6240v1</id>
    <updated>2013-11-25T09:12:15Z</updated>
    <published>2013-11-25T09:12:15Z</published>
    <title>A Decision Tree Approach to Classify Web Services using Quality
  Parameters</title>
    <summary>  With the increase in the number of web services, many web services are
available on internet providing the same functionality, making it difficult to
choose the best one, fulfilling users all requirements. This problem can be
solved by considering the quality of web services to distinguish functionally
similar web services. Nine different quality parameters are considered. Web
services can be classified and ranked using decision tree approach since they
do not require long training period and can be easily interpreted. Various
decision tree and rules approaches available are applied and tested to find the
optimal decision method to correctly classify functionally similar web services
considering their quality parameters.
</summary>
    <author>
      <name>Shilpa Sonawani</name>
    </author>
    <author>
      <name>Debajyoti Mukhopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 tables; ICWA 2013 International Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.6240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1448v1</id>
    <updated>2013-12-05T06:50:30Z</updated>
    <published>2013-12-05T06:50:30Z</published>
    <title>Food Recommendation using Ontology and Heuristics</title>
    <summary>  Recommender systems are needed to find food items of ones interest. We review
recommender systems and recommendation methods. We propose a food
personalization framework based on adaptive hypermedia. We extend Hermes
framework with food recommendation functionality. We combine TF-IDF term
extraction method with cosine similarity measure. Healthy heuristics and
standard food database are incorporated into the knowledgebase. Based on the
performed evaluation, we conclude that semantic recommender systems in general
outperform traditional recommenders systems with respect to accuracy,
precision, and recall, and that the proposed recommender has a better F-measure
than existing semantic recommenders.
</summary>
    <author>
      <name>M. A. El-Dosuky</name>
    </author>
    <author>
      <name>M. Z. Rashad</name>
    </author>
    <author>
      <name>T. T. Hamza</name>
    </author>
    <author>
      <name>A. H. EL-Bassiouny</name>
    </author>
    <link href="http://arxiv.org/abs/1312.1448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1913v1</id>
    <updated>2013-12-06T16:34:14Z</updated>
    <published>2013-12-06T16:34:14Z</published>
    <title>Adapting Binary Information Retrieval Evaluation Metrics for
  Segment-based Retrieval Tasks</title>
    <summary>  This report describes metrics for the evaluation of the effectiveness of
segment-based retrieval based on existing binary information retrieval metrics.
This metrics are described in the context of a task for the hyperlinking of
video segments. This evaluation approach re-uses existing evaluation measures
from the standard Cranfield evaluation paradigm. Our adaptation approach can in
principle be used with any kind of effectiveness measure that uses binary
relevance, and for other segment-baed retrieval tasks. In our video
hyperlinking setting, we use precision at a cut-off rank n and mean average
precision.
</summary>
    <author>
      <name>Robin Aly</name>
    </author>
    <author>
      <name>Maria Eskevich</name>
    </author>
    <author>
      <name>Roeland Ordelman</name>
    </author>
    <author>
      <name>Gareth J. F. Jones</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Explanation of evaluation measures for the linking task of the
  MediaEval Workshop 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.1913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4036v1</id>
    <updated>2013-12-14T12:13:58Z</updated>
    <published>2013-12-14T12:13:58Z</published>
    <title>Mind Your Language: Effects of Spoken Query Formulation on Retrieval
  Effectiveness</title>
    <summary>  Voice search is becoming a popular mode for interacting with search engines.
As a result, research has gone into building better voice transcription
engines, interfaces, and search engines that better handle inherent verbosity
of queries. However, when one considers its use by non- native speakers of
English, another aspect that becomes important is the formulation of the query
by users. In this paper, we present the results of a preliminary study that we
conducted with non-native English speakers who formulate queries for given
retrieval tasks. Our results show that the current search engines are sensitive
in their rankings to the query formulation, and thus highlights the need for
developing more robust ranking methods.
</summary>
    <author>
      <name>Apoorv Narang</name>
    </author>
    <author>
      <name>Srikanta Bedathur</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4425v1</id>
    <updated>2013-12-16T16:49:32Z</updated>
    <published>2013-12-16T16:49:32Z</published>
    <title>An Ontology-based Model for Indexing and Retrieval</title>
    <summary>  Starting from an unsolved problem of information retrieval this paper
presents an ontology-based model for indexing and retrieval. The model combines
the methods and experiences of cognitive-to-interpret indexing languages with
the strengths and possibilities of formal knowledge representation. The core
component of the model uses inferences along the paths of typed relations
between the entities of a knowledge representation for enabling the
determination of hit quantities in the context of retrieval processes. The
entities are arranged in aspect-oriented facets to ensure a consistent
hierarchical structure. The possible consequences for indexing and retrieval
are discussed.
</summary>
    <author>
      <name>Winfried Gödert</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4824v2</id>
    <updated>2014-01-16T04:05:36Z</updated>
    <published>2013-12-17T15:32:56Z</published>
    <title>Generation, Implementation and Appraisal of an N-gram based Stemming
  Algorithm</title>
    <summary>  A language independent stemmer has always been looked for. Single N-gram
tokenization technique works well, however, it often generates stems that start
with intermediate characters, rather than initial ones. We present a novel
technique that takes the concept of N gram stemming one step ahead and compare
our method with an established algorithm in the field, Porter's Stemmer.
Results indicate that our N gram stemmer is not inferior to Porter's linguistic
stemmer.
</summary>
    <author>
      <name>B. P. Pande</name>
    </author>
    <author>
      <name>Pawan Tamta</name>
    </author>
    <author>
      <name>H. S. Dhami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.4824v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4824v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6802v1</id>
    <updated>2013-12-24T12:06:48Z</updated>
    <published>2013-12-24T12:06:48Z</published>
    <title>Suffix Stripping Problem as an Optimization Problem</title>
    <summary>  Stemming or suffix stripping, an important part of the modern Information
Retrieval systems, is to find the root word (stem) out of a given cluster of
words. Existing algorithms targeting this problem have been developed in a
haphazard manner. In this work, we model this problem as an optimization
problem. An Integer Program is being developed to overcome the shortcomings of
the existing approaches. The sample results of the proposed method are also
being compared with an established technique in the field for English language.
An AMPL code for the same IP has also been given.
</summary>
    <author>
      <name>B. P. Pande</name>
    </author>
    <author>
      <name>Pawan Tamta</name>
    </author>
    <author>
      <name>H. S. Dhami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.6802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1947v1</id>
    <updated>2014-02-09T13:02:51Z</updated>
    <published>2014-02-09T13:02:51Z</published>
    <title>Classification Tree Diagrams in Health Informatics Applications</title>
    <summary>  Health informatics deal with the methods used to optimize the acquisition,
storage and retrieval of medical data, and classify information in healthcare
applications. Healthcare analysts are particularly interested in various
computer informatics areas such as; knowledge representation from data, anomaly
detection, outbreak detection methods and syndromic surveillance applications.
Although various parametric and non-parametric approaches are being proposed to
classify information from data, classification tree diagrams provide an
interactive visualization to analysts as compared to other methods. In this
work we discuss application of classification tree diagrams to classify
information from medical data in healthcare applications.
</summary>
    <author>
      <name>Farrukh Arslan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In the Proceedings of 7th International Conference on the Theory and
  Application of Diagrams 2012. 7th International Conference on the Theory and
  Application of Diagrams 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.1947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3070v1</id>
    <updated>2014-02-13T09:54:01Z</updated>
    <published>2014-02-13T09:54:01Z</published>
    <title>Squeezing bottlenecks: exploring the limits of autoencoder semantic
  representation capabilities</title>
    <summary>  We present a comprehensive study on the use of autoencoders for modelling
text data, in which (differently from previous studies) we focus our attention
on the following issues: i) we explore the suitability of two different models
bDA and rsDA for constructing deep autoencoders for text data at the sentence
level; ii) we propose and evaluate two novel metrics for better assessing the
text-reconstruction capabilities of autoencoders; and iii) we propose an
automatic method to find the critical bottleneck dimensionality for text
language representations (below which structural information is lost).
</summary>
    <author>
      <name>Parth Gupta</name>
    </author>
    <author>
      <name>Rafael E. Banchs</name>
    </author>
    <author>
      <name>Paolo Rosso</name>
    </author>
    <link href="http://arxiv.org/abs/1402.3070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3470v1</id>
    <updated>2014-02-14T14:12:17Z</updated>
    <published>2014-02-14T14:12:17Z</published>
    <title>Designing an Ontology for the Data Documentation Initiative</title>
    <summary>  An ontology of the DDI 3 data model will be designed by following the
ontology engineering methodology to be evolved based on state-of-the-art
methodologies. Hence DDI 3 data and metadata can be represented in form of a
standard web interchange format RDF and processed by highly available RDF
tools. As a consequence the DDI community has the possibility to publish and
link LOD data sets to become part of the LOD cloud.
</summary>
    <author>
      <name>Thomas Bosch</name>
    </author>
    <author>
      <name>Andias Wira-Alam</name>
    </author>
    <author>
      <name>Brigitte Mathiak</name>
    </author>
    <link href="http://arxiv.org/abs/1402.3470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.0091v1</id>
    <updated>2014-04-01T00:53:37Z</updated>
    <published>2014-04-01T00:53:37Z</published>
    <title>Interestingness a Unifying Paradigm Bipolar Function Composition</title>
    <summary>  Interestingness is an important criterion by which we judge knowledge
discovery. But, interestingness has escaped all attempts to capture its
intuitive meaning into a concise and comprehensive form. A unifying paradigm is
formulated by function composition. We claim that composition is bipolar, i.e.
composition of exactly two functions, whose two semantic poles are relevance
and unexpectedness. The paradigm generality is demonstrated by case studies of
new interestingness functions, examples of known functions that fit the
framework, and counter-examples for which the paradigm points out to the
lacking pole.
</summary>
    <author>
      <name>Iaakov Exman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures, 1 table; in Proceedings of KDIR 2009, 1st
  International Conference on Knowledge Discovery and Information Retrieval,
  Madeira, Portugal, pp. 196-201</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.0091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.0091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1514v1</id>
    <updated>2014-04-05T19:58:38Z</updated>
    <published>2014-04-05T19:58:38Z</published>
    <title>Text Based Approach For Indexing And Retrieval Of Image And Video: A
  Review</title>
    <summary>  Text data present in multimedia contain useful information for automatic
annotation, indexing. Extracted information used for recognition of the overlay
or scene text from a given video or image. The Extracted text can be used for
retrieving the videos and images. In this paper, firstly, we are discussed the
different techniques for text extraction from images and videos. Secondly, we
are reviewed the techniques for indexing and retrieval of image and videos by
using extracted text.
</summary>
    <author>
      <name>Avinash N Bhute</name>
    </author>
    <author>
      <name>B. B. Meshram</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Vision: An International Journal, Vol 1, no. 1, March
  2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.1514v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1514v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3435v1</id>
    <updated>2014-04-13T22:01:48Z</updated>
    <published>2014-04-13T22:01:48Z</published>
    <title>Web Search of New Linearized Medical Drug Leads</title>
    <summary>  The Web is a potentially huge source of medical drug leads. But despite the
significant amount of multi- dimensional information about drugs, currently
commercial search engines accept only linear keyword strings as inputs. This
work uses linearized fragments of molecular structures as knowledge
representation units to serve as inputs to search engines. It is shown that
quite arbitrary fragments are surprisingly free of ambiguity, obtaining
relatively small result sets, which are both manageable and rich in novel
potential drug leads.
</summary>
    <author>
      <name>Iaakov Exman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5220/0003705401080115</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5220/0003705401080115" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures, reprint of paper in SKY 2011 Workshop, Paris,
  France, October 2011, SciTePress Digital Library</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1740v1</id>
    <updated>2014-05-07T20:20:35Z</updated>
    <published>2014-05-07T20:20:35Z</published>
    <title>Turkish Text Retrieval Experiments Using Lemur Toolkit</title>
    <summary>  We used Lemur Toolkit, an open source toolkit designed for Information
Retrieval (IR) research, for our automated indexing and retrieval experiments
on a TREC-like test collection for Turkish. We study and compare three
retrieval models Lemur supports, especially Language modeling approach to IR,
combined with language specific preprocessing techniques. Our experiments show
that all retrieval models benefits from language specific preprocessing in
terms of retrieval quality. Also Language Modeling approach is the best
performing retrieval model when language specific preprocessing applied.
</summary>
    <author>
      <name>Kutlu Emre Yılmaz</name>
    </author>
    <author>
      <name>Ahmet Arslan</name>
    </author>
    <author>
      <name>Ozgur Yilmazel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IADIS AC 2009: Rome, Italy</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.1740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2212v1</id>
    <updated>2014-05-09T12:10:11Z</updated>
    <published>2014-05-09T12:10:11Z</published>
    <title>Why we need an independent index of the Web</title>
    <summary>  The path to greater diversity, as we have seen, cannot be achieved by merely
hoping for a new search engine nor will government support for a single
alternative achieve this goal. What is instead required is to create the
conditions that will make establishing such a search engine possible in the
first place. I describe how building and maintaining a proprietary index is the
greatest deterrent to such an undertaking. We must first overcome this
obstacle. Doing so will still not solve the problem of the lack of diversity in
the search engine marketplace. But it may establish the conditions necessary to
achieve that desired end.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <link href="http://arxiv.org/abs/1405.2212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2386v1</id>
    <updated>2014-05-10T03:43:14Z</updated>
    <published>2014-05-10T03:43:14Z</published>
    <title>Predicting Central Topics in a Blog Corpus from a Networks Perspective</title>
    <summary>  In today's content-centric Internet, blogs are becoming increasingly popular
and important from a data analysis perspective. According to Wikipedia, there
were over 156 million public blogs on the Internet as of February 2011. Blogs
are a reflection of our contemporary society. The contents of different blog
posts are important from social, psychological, economical and political
perspectives. Discovery of important topics in the blogosphere is an area which
still needs much exploring. We try to come up with a procedure using
probabilistic topic modeling and network centrality measures which identifies
the central topics in a blog corpus.
</summary>
    <author>
      <name>Srayan Datta</name>
    </author>
    <link href="http://arxiv.org/abs/1405.2386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3353v1</id>
    <updated>2014-05-14T03:44:32Z</updated>
    <published>2014-05-14T03:44:32Z</published>
    <title>Which one is better: presentation-based or content-based math search?</title>
    <summary>  Mathematical content is a valuable information source and retrieving this
content has become an important issue. This paper compares two searching
strategies for math expressions: presentation-based and content-based
approaches. Presentation-based search uses state-of-the-art math search system
while content-based search uses semantic enrichment of math expressions to
convert math expressions into their content forms and searching is done using
these content-based expressions. By considering the meaning of math
expressions, the quality of search system is improved over presentation-based
systems.
</summary>
    <author>
      <name>Minh-Quoc Nghiem</name>
    </author>
    <author>
      <name>Giovanni Yoko Kristianto</name>
    </author>
    <author>
      <name>Goran Topic</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <link href="http://arxiv.org/abs/1405.3353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6287v1</id>
    <updated>2014-05-24T10:16:11Z</updated>
    <published>2014-05-24T10:16:11Z</published>
    <title>Étude des dimensions spécifiques du contexte dans un système de
  filtrage d'informations</title>
    <summary>  In the context of business information systems, e-commerce and access to
knowledge, the relevance of the information provided to use is a key fact to
the success of information systems. Therefore the quality of access is
determined by access to the right information at the right time, at the right
place. In this context, it is important to consider the users needs when access
to information and his contextual situation in order to provide relevant
information, tailored to their needs and context use. In what follows we
describe the prelude to a project that tries to combine all of these needs to
improve information systems.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6287v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6287v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6667v1</id>
    <updated>2014-05-26T18:25:35Z</updated>
    <published>2014-05-26T18:25:35Z</published>
    <title>Inferring gender of a Twitter user using celebrities it follows</title>
    <summary>  This paper addresses the task of user gender classification in social media,
with an application to Twitter. The approach automatically predicts gender by
leveraging observable information such as the tweet behavior, linguistic
content of the user's Twitter feed and the celebrities followed by the user.
This paper first evaluates linguistic content based features using LIWC
dictionary and popular neighborhood features using Wikipedia and Freebase. Then
augments both features which yielded a significant increase in the accuracy for
gender prediction. Results show that rich linguistic features combined with
popular neighborhood prove valuables and promising for additional user
classification needs.
</summary>
    <author>
      <name>Puneet Singh Ludu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted at CSE department, SUNY Buffalo, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6886v1</id>
    <updated>2014-05-27T12:34:24Z</updated>
    <published>2014-05-27T12:34:24Z</published>
    <title>A Topic Model Approach to Multi-Modal Similarity</title>
    <summary>  Calculating similarities between objects defined by many heterogeneous data
modalities is an important challenge in many multimedia applications. We use a
multi-modal topic model as a basis for defining such a similarity between
objects. We propose to compare the resulting similarities from different model
realizations using the non-parametric Mantel test. The approach is evaluated on
a music dataset.
</summary>
    <author>
      <name>Rasmus Troelsgård</name>
    </author>
    <author>
      <name>Bjørn Sand Jensen</name>
    </author>
    <author>
      <name>Lars Kai Hansen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">topic modelling workshop at NIPS 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7869v1</id>
    <updated>2014-05-08T07:44:39Z</updated>
    <published>2014-05-08T07:44:39Z</published>
    <title>Integrating Vague Association Mining with Markov Model</title>
    <summary>  The increasing demand of world wide web raises the need of predicting the
user's web page request.The most widely used approach to predict the web pages
is the pattern discovery process of Web usage mining. This process involves
inevitability of many techniques like Markov model, association rules and
clustering. Fuzzy theory with different techniques has been introduced for the
better results. Our focus is on Markov models. This paper is introducing the
vague Rules with Markov models for more accuracy using the vague set theory.
</summary>
    <author>
      <name>Priya Bajaj</name>
    </author>
    <author>
      <name>Supriya Raheja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.7869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7975v1</id>
    <updated>2014-05-17T22:21:00Z</updated>
    <published>2014-05-17T22:21:00Z</published>
    <title>Multi-layered graph-based multi-document summarization model</title>
    <summary>  Multi-document summarization is a process of automatic generation of a
compressed version of the given collection of documents. Recently, the
graph-based models and ranking algorithms have been actively investigated by
the extractive document summarization community. While most work to date
focuses on homogeneous connecteness of sentences and heterogeneous connecteness
of documents and sentences (e.g. sentence similarity weighted by document
importance), in this paper we present a novel 3-layered graph model that
emphasizes not only sentence and document level relations but also the
influence of under sentence level relations (e.g. a part of sentence
similarity).
</summary>
    <author>
      <name>Ercan Canhasi</name>
    </author>
    <link href="http://arxiv.org/abs/1405.7975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1143v1</id>
    <updated>2014-06-04T18:59:00Z</updated>
    <published>2014-06-04T18:59:00Z</published>
    <title>Identifying Duplicate and Contradictory Information in Wikipedia</title>
    <summary>  Our study identifies sentences in Wikipedia articles that are either
identical or highly similar by applying techniques for near-duplicate detection
of web pages. This is accomplished with a MapReduce implementation of minhash
to identify clusters of sentences with high Jaccard similarity. We show that
these clusters can be categorized into six different types, two of which are
particularly interesting: identical sentences quantify the extent to which
content in Wikipedia is copied and pasted, and near-duplicate sentences that
state contradictory facts point to quality issues in Wikipedia.
</summary>
    <author>
      <name>Sarah Weissman</name>
    </author>
    <author>
      <name>Samet Ayhan</name>
    </author>
    <author>
      <name>Joshua Bradley</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1406.1143v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1143v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1583v1</id>
    <updated>2014-06-06T05:12:38Z</updated>
    <published>2014-06-06T05:12:38Z</published>
    <title>Fuzzy clustering of web documents using equivalence relations and fuzzy
  hierarchical clustering</title>
    <summary>  The conventional clustering algorithms have difficulties in handling the
challenges posed by the collection of natural data which is often vague and
uncertain. Fuzzy clustering methods have the potential to manage such
situations efficiently. Fuzzy clustering method is offered to construct
clusters with uncertain boundaries and allows that one object belongs to one or
more clusters with some membership degree. In this paper, an algorithm and
experimental results are presented for fuzzy clustering of web documents using
equivalence relations and fuzzy hierarchical clustering.
</summary>
    <author>
      <name>Satendra kumar</name>
    </author>
    <author>
      <name>Mamta kathuria</name>
    </author>
    <author>
      <name>Alok Kumar Gupta</name>
    </author>
    <author>
      <name>Monika Rani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Software Engineering (CONSEG), 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.1583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6840v1</id>
    <updated>2014-06-26T11:01:11Z</updated>
    <published>2014-06-26T11:01:11Z</published>
    <title>From Citation count to Argumentation count: a new metric to indicate the
  usefulness of an article</title>
    <summary>  Citation count is a quantifiable measure to indicate the number of times an
article is cited by other articles. It is believed that if an article is cited
often then it must be an important or influential article; however, there is no
guarantee that the most cited articles are good in quality. In this paper, the
author suggests argumentation count, a new metric for citation analysis. The
proposed metric, argumentation count is a triplet of quantities for each
concept of an article that helps in providing a quantifiable measure about the
usefulness of an article.
</summary>
    <author>
      <name>Hardik Joshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Conference cum Workshop on Digital Library Using DSpace
  hosted by Gujarat National Law University on 21-23 March, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.6840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1539v1</id>
    <updated>2014-07-06T20:14:08Z</updated>
    <published>2014-07-06T20:14:08Z</published>
    <title>A Framework for Specific Term Recommendation Systems</title>
    <summary>  In this paper we present the IRSA framework that enables the automatic
creation of search term suggestion or recommendation systems (TS). Such TS are
used to operationalize interactive query expansion and help users in refining
their information need in the query formulation phase. Our recent research has
shown TS to be more effective when specific to a certain domain. The presented
technical framework allows owners of Digital Libraries to create their own
specific TS constructed via OAI-harvested metadata with very little effort.
</summary>
    <author>
      <name>Thomas Lüke</name>
    </author>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2484028.2484207</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2484028.2484207" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, SIGIR 13, July 28-August 1, 2013, Dublin, Ireland</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.1539v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1539v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1540v1</id>
    <updated>2014-07-06T20:20:13Z</updated>
    <published>2014-07-06T20:20:13Z</published>
    <title>Establishing an Online Access Panel for Interactive Information
  Retrieval Research</title>
    <summary>  We propose an online access panel to support the evaluation process of
Interactive Information Retrieval (IIR) systems - called IIRpanel. By
maintaining an online access panel with users of IIR systems we assume that the
recurring effort to recruit participants for web-based as well as for lab
studies can be minimized. We target on using the online access panel not only
for our own development processes but to open it for other interested
researchers in the field of IIR. In this paper we present the concept of
IIRpanel as well as first implementation details.
</summary>
    <author>
      <name>Dagmar Kern</name>
    </author>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/JCDL.2014.6970231</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/JCDL.2014.6970231" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, 2014 IEEE/ACM Joint Conference on Digital
  Libraries (JCDL), London, 8th-12th September 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.1540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7072v1</id>
    <updated>2014-07-25T22:33:49Z</updated>
    <published>2014-07-25T22:33:49Z</published>
    <title>Fast Spammer Detection Using Structural Rank</title>
    <summary>  Comments for a product or a news article are rapidly growing and became a
medium of measuring quality products or services. Consequently, spammers have
been emerged in this area to bias them toward their favor. In this paper, we
propose an efficient spammer detection method using structural rank of author
specific term-document matrices. The use of structural rank was found effective
and far faster than similar methods.
</summary>
    <author>
      <name>Seungyeon Kim</name>
    </author>
    <author>
      <name>Haesun Park</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0096v1</id>
    <updated>2014-08-01T07:51:37Z</updated>
    <published>2014-08-01T07:51:37Z</published>
    <title>Conditional Restricted Boltzmann Machines for Cold Start Recommendations</title>
    <summary>  Restricted Boltzman Machines (RBMs) have been successfully used in
recommender systems. However, as with most of other collaborative filtering
techniques, it cannot solve cold start problems for there is no rating for a
new item. In this paper, we first apply conditional RBM (CRBM) which could take
extra information into account and show that CRBM could solve cold start
problem very well, especially for rating prediction task. CRBM naturally
combine the content and collaborative data under a single framework which could
be fitted effectively. Experiments show that CRBM can be compared favourably
with matrix factorization models, while hidden features learned from the former
models are more easy to be interpreted.
</summary>
    <author>
      <name>Jiankou Li</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.0096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.2430v1</id>
    <updated>2014-08-11T14:58:30Z</updated>
    <published>2014-08-11T14:58:30Z</published>
    <title>Optimizing Component Combination in a Multi-Indexing Paragraph Retrieval
  System</title>
    <summary>  We demonstrate a method to optimize the combination of distinct components in
a paragraph retrieval system. Our system makes use of several indices, query
generators and filters, each of them potentially contributing to the quality of
the returned list of results. The components are combined with a weighed sum,
and we optimize the weights using a heuristic optimization algorithm. This
allows us to maximize the quality of our results, but also to determine which
components are most valuable in our system. We evaluate our approach on the
paragraph selection task of a Question Answering dataset.
</summary>
    <author>
      <name>Boris Iolis</name>
    </author>
    <author>
      <name>Gianluca Bontempi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, unpublished</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.2430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.2430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00311v1</id>
    <updated>2015-01-01T20:51:25Z</updated>
    <published>2015-01-01T20:51:25Z</published>
    <title>QANUS: An Open-source Question-Answering Platform</title>
    <summary>  In this paper, we motivate the need for a publicly available, generic
software framework for question-answering (QA) systems. We present an
open-source QA framework QANUS which researchers can leverage on to build new
QA systems easily and rapidly. The framework implements much of the code that
will otherwise have been repeated across different QA systems. To demonstrate
the utility and practicality of the framework, we further present a fully
functioning factoid QA system QA-SYS built on top of QANUS.
</summary>
    <author>
      <name>Jun-Ping Ng</name>
    </author>
    <author>
      <name>Min-Yen Kan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, demo paper describing QANUS</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00744v1</id>
    <updated>2015-01-05T01:49:11Z</updated>
    <published>2015-01-05T01:49:11Z</published>
    <title>Identifying Relevant Document Facets for Keyword-Based Search Queries</title>
    <summary>  As structured documents with rich metadata (such as products, movies, etc.)
become increasingly prevalent, searching those documents has become an
important IR problem. Although advanced search interfaces are widely available,
most users still prefer to use keyword-based queries to search those documents.
Query keywords often imply some hidden restrictions on the desired documents,
which can be represented as document facet-value pairs. To achieve high
retrieval performance, it's important to be able to identify the relevant
facet-value pairs hidden in a query. In this paper, we study the problem of
identifying document facet-value pairs that are relevant to a keyword-based
search query. We propose a machine learning approach and a set of useful
features, and evaluate our approach using a movie data set from INEX.
</summary>
    <author>
      <name>Lanbo Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1501.00744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06380v1</id>
    <updated>2015-01-26T13:21:09Z</updated>
    <published>2015-01-26T13:21:09Z</published>
    <title>Document Distance for the Automated Expansion of Relevance Judgements
  for Information Retrieval Evaluation</title>
    <summary>  This paper reports the use of a document distance-based approach to
automatically expand the number of available relevance judgements when these
are limited and reduced to only positive judgements. This may happen, for
example, when the only available judgements are extracted from a list of
references in a published review paper. We compare the results on two document
sets: OHSUMED, based on medical research publications, and TREC-8, based on
news feeds. We show that evaluations based on these expanded relevance
judgements are more reliable than those using only the initially available
judgements, especially when the number of available judgements is very limited.
</summary>
    <author>
      <name>Diego Mollá</name>
    </author>
    <author>
      <name>Iman Amini</name>
    </author>
    <author>
      <name>David Martinez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2014 Workshop on Gathering Efficient Assessments of Relevance</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.4; H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07716v1</id>
    <updated>2015-01-30T09:55:24Z</updated>
    <published>2015-01-30T09:55:24Z</published>
    <title>Attention Please! A Hybrid Resource Recommender Mimicking
  Attention-Interpretation Dynamics</title>
    <summary>  Classic resource recommenders like Collaborative Filtering (CF) treat users
as being just another entity, neglecting non-linear user-resource dynamics
shaping attention and interpretation. In this paper, we propose a novel hybrid
recommendation strategy that refines CF by capturing these dynamics. The
evaluation results reveal that our approach substantially improves CF and,
depending on the dataset, successfully competes with a computationally much
more expensive Matrix Factorization variant.
</summary>
    <author>
      <name>Paul Seitlinger</name>
    </author>
    <author>
      <name>Dominik Kowald</name>
    </author>
    <author>
      <name>Simone Kopeinik</name>
    </author>
    <author>
      <name>Ilire Hasani-Mavriqi</name>
    </author>
    <author>
      <name>Tobias Ley</name>
    </author>
    <author>
      <name>Elisabeth Lex</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to WWW'15 WebScience Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.07716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.8; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00305v1</id>
    <updated>2015-04-01T17:24:52Z</updated>
    <published>2015-04-01T17:24:52Z</published>
    <title>Study the effectiveness of genetic algorithm for documentary subject
  search</title>
    <summary>  This article presents results of experimental studies the effectiveness of
the genetic algorithm that was applied to effective queries creation and
relevant document selection. Studies were carried out to the comparative
analysis of the semantic relevance and quality ranking of the documents found
on the Internet in various ways. Analysis of the results shows that the
greatest effect of presented technology is achieved by finding new documents
for skilled users in the initial stages of the study of the topic.
Additionally, the number of unique and relevant results is significantly
increased.
</summary>
    <author>
      <name>V. K. Ivanov</name>
    </author>
    <author>
      <name>B. V. Palyukh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">OSTIS-2015 1 (2015) 471-476</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.00305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01183v1</id>
    <updated>2015-04-06T01:19:25Z</updated>
    <published>2015-04-06T01:19:25Z</published>
    <title>Document Clustering using K-Medoids</title>
    <summary>  People are always in search of matters for which they are prone to use
internet, but again it has huge assemblage of data due to which it becomes
difficult for the reader to get the most accurate data. To make it easier for
people to gather accurate data, similar information has to be clustered at one
place. There are many algorithms used for clustering of relevant information in
one platform. In this paper, K-Medoids clustering algorithm has been employed
for formation of clusters which is further used for document summarization.
</summary>
    <author>
      <name>Monica Jha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal on Advanced Computer Theory and Engineering
  (IJACTE), ISSN (Print): 2319-2526, Volume-4, Issue-1, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.01183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01433v1</id>
    <updated>2015-04-06T22:55:38Z</updated>
    <published>2015-04-06T22:55:38Z</published>
    <title>Automated System for Improving RSS Feeds Data Quality</title>
    <summary>  Nowadays, the majority of RSS feeds provide incomplete information about
their news items. The lack of information leads to engagement loss in users. We
present a new automated system for improving the RSS feeds' data quality. RSS
feeds provide a list of the latest news items ordered by date. Therefore, it
makes it easy for a web crawler to precisely locate the item and extract its
raw content. Then it identifies where the main content is located and extracts:
main text corpus, relevant keywords, bigrams, best image and predicts the
category of the item. The output of the system is an enhanced RSS feed. The
proposed system showed an average item data quality improvement from 39.98% to
95.62%.
</summary>
    <author>
      <name>Joan Hurtado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02362v1</id>
    <updated>2015-04-09T16:22:32Z</updated>
    <published>2015-04-09T16:22:32Z</published>
    <title>Approaches to the Intelligent Subject Search</title>
    <summary>  This article presents main results of the pilot study of approaches to the
subject information search based on automated semantic processing of mass
scientific and technical data. The authors focus on technology of building and
qualification of search queries with the following filtering and ranking of
search data. Software architecture, specific features of subject search and
research results application are considered.
</summary>
    <author>
      <name>V. K. Ivanov</name>
    </author>
    <author>
      <name>B. V. Palyukh</name>
    </author>
    <author>
      <name>A. N. Sotnikov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.15439/2014F70 10.15439/978-83-60810-57-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.15439/2014F70" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.15439/978-83-60810-57-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">FedCSIS'2014 3 (2014) 13-20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.02362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.04216v1</id>
    <updated>2015-04-16T13:05:19Z</updated>
    <published>2015-04-16T13:05:19Z</published>
    <title>Genetic algorithm implementation for effective document subject search</title>
    <summary>  This paper describes the software implementation of genetic algorithm for
identifying and selecting most relevant results received during sequentially
executed subject search operations. Simulated evolutionary process generates
sustainable and effective population of search queries, forms search pattern of
documents or semantic core, creates relevant sets of required documents, allows
automatic classification of search results. The paper discusses the features of
subject search, justifies the use of a genetic algorithm, describes arguments
of the fitness function and describes basic steps and parameters of the
algorithm.
</summary>
    <author>
      <name>V. K. Ivanov</name>
    </author>
    <author>
      <name>P. I. Meskin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.15827/0236-235X.108.118-126</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.15827/0236-235X.108.118-126" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Programmnye produkty i sistemy 4 (2014) 118-126</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.04216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.04216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.05473v1</id>
    <updated>2015-04-21T15:38:23Z</updated>
    <published>2015-04-21T15:38:23Z</published>
    <title>Can FCA-based Recommender System Suggest a Proper Classifier?</title>
    <summary>  The paper briefly introduces multiple classifier systems and describes a new
algorithm, which improves classification accuracy by means of recommendation of
a proper algorithm to an object classification. This recommendation is done
assuming that a classifier is likely to predict the label of the object
correctly if it has correctly classified its neighbors. The process of
assigning a classifier to each object is based on Formal Concept Analysis. We
explain the idea of the algorithm with a toy example and describe our first
experiments with real-world datasets.
</summary>
    <author>
      <name>Yury Kashnitsky</name>
    </author>
    <author>
      <name>Dmitry I. Ignatov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, 4 tables, ECAI 2014, workshop "What FCA can do
  for "Artifficial Intelligence"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CEUR Workshop Proceedings, 1257, pp. 17-26 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.05473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.05473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62-07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06077v1</id>
    <updated>2015-04-23T08:27:29Z</updated>
    <published>2015-04-23T08:27:29Z</published>
    <title>Open Data Platform for Knowledge Access in Plant Health Domain : VESPA
  Mining</title>
    <summary>  Important data are locked in ancient literature. It would be uneconomic to
produce these data again and today or to extract them without the help of text
mining technologies. Vespa is a text mining project whose aim is to extract
data on pest and crops interactions, to model and predict attacks on crops, and
to reduce the use of pesticides. A few attempts proposed an agricultural
information access. Another originality of our work is to parse documents with
a dependency of the document architecture.
</summary>
    <author>
      <name>Nicolas Turenne</name>
    </author>
    <author>
      <name>Mathieu Andro</name>
    </author>
    <author>
      <name>Roselyne Corbière</name>
    </author>
    <author>
      <name>Tien T. Phan</name>
    </author>
    <link href="http://arxiv.org/abs/1504.06077v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06077v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01443v1</id>
    <updated>2015-07-06T13:26:02Z</updated>
    <published>2015-07-06T13:26:02Z</published>
    <title>Nonparametric Bayesian Modeling for Automated Database Schema Matching</title>
    <summary>  The problem of merging databases arises in many government and commercial
applications. Schema matching, a common first step, identifies equivalent
fields between databases. We introduce a schema matching framework that builds
nonparametric Bayesian models for each field and compares them by computing the
probability that a single model could have generated both fields. Our
experiments show that our method is more accurate and faster than the existing
instance-based matching algorithms in part because of the use of nonparametric
Bayesian models.
</summary>
    <author>
      <name>Erik M. Ferragut</name>
    </author>
    <author>
      <name>Jason Laska</name>
    </author>
    <link href="http://arxiv.org/abs/1507.01443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02907v1</id>
    <updated>2015-07-10T13:59:00Z</updated>
    <published>2015-07-10T13:59:00Z</published>
    <title>Extending a Single-Document Summarizer to Multi-Document: a Hierarchical
  Approach</title>
    <summary>  The increasing amount of online content motivated the development of
multi-document summarization methods. In this work, we explore straightforward
approaches to extend single-document summarization methods to multi-document
summarization. The proposed methods are based on the hierarchical combination
of single-document summaries, and achieves state of the art results.
</summary>
    <author>
      <name>Luís Marujo</name>
    </author>
    <author>
      <name>Ricardo Ribeiro</name>
    </author>
    <author>
      <name>David Martins de Matos</name>
    </author>
    <author>
      <name>João P. Neto</name>
    </author>
    <author>
      <name>Anatole Gershman</name>
    </author>
    <author>
      <name>Jaime Carbonell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, Please cite: Proceedings of *SEM: the 4th Joint Conference
  on Lexical and Computational Semantics (bibtex:
  http://aclweb.org/anthology/S/S15/S15-1020.bib)</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.02907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.03928v1</id>
    <updated>2015-07-14T17:06:51Z</updated>
    <published>2015-07-14T17:06:51Z</published>
    <title>Pseudo-Query Reformulation</title>
    <summary>  Automatic query reformulation refers to rewriting a user's original query in
order to improve the ranking of retrieval results compared to the original
query. We present a general framework for automatic query reformulation based
on discrete optimization. Our approach, referred to as pseudo-query
reformulation, treats automatic query reformulation as a search problem over
the graph of unweighted queries linked by minimal transformations (e.g. term
additions, deletions). This framework allows us to test existing performance
prediction methods as heuristics for the graph search process. We demonstrate
the effectiveness of the approach on several publicly available datasets.
</summary>
    <author>
      <name>Fernando Diaz</name>
    </author>
    <link href="http://arxiv.org/abs/1507.03928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.03928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05497v1</id>
    <updated>2015-07-20T13:58:30Z</updated>
    <published>2015-07-20T13:58:30Z</published>
    <title>RAPS: A Recommender Algorithm Based on Pattern Structures</title>
    <summary>  We propose a new algorithm for recommender systems with numeric ratings which
is based on Pattern Structures (RAPS). As the input the algorithm takes rating
matrix, e.g., such that it contains movies rated by users. For a target user,
the algorithm returns a rated list of items (movies) based on its previous
ratings and ratings of other users. We compare the results of the proposed
algorithm in terms of precision and recall measures with Slope One, one of the
state-of-the-art item-based algorithms, on Movie Lens dataset and RAPS
demonstrates the best or comparable quality.
</summary>
    <author>
      <name>Dmitry I. Ignatov</name>
    </author>
    <author>
      <name>Denis Kornilov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper presented at FCA4AI 2015 in conjunction with IJCAI 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="06F99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.2.8; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07382v1</id>
    <updated>2015-07-27T12:05:58Z</updated>
    <published>2015-07-27T12:05:58Z</published>
    <title>Application of Kullback-Leibler divergence for short-term user interest
  detection</title>
    <summary>  Classical approaches in recommender systems such as collaborative filtering
are concentrated mainly on static user preference extraction. This approach
works well as an example for music recommendations when a user behavior tends
to be stable over long period of time, however the most common situation in
e-commerce is different which requires reactive algorithms based on a
short-term user activity analysis. This paper introduces a small mathematical
framework for short-term user interest detection formulated in terms of item
properties and its application for recommender systems enhancing. The framework
is based on the fundamental concept of information theory --- Kullback-Leibler
divergence.
</summary>
    <author>
      <name>Maxim Borisyak</name>
    </author>
    <author>
      <name>Roman Zykov</name>
    </author>
    <author>
      <name>Artem Noskov</name>
    </author>
    <link href="http://arxiv.org/abs/1507.07382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.08439v1</id>
    <updated>2015-07-30T10:08:14Z</updated>
    <published>2015-07-30T10:08:14Z</published>
    <title>Metadata Embeddings for User and Item Cold-start Recommendations</title>
    <summary>  I present a hybrid matrix factorisation model representing users and items as
linear combinations of their content features' latent factors. The model
outperforms both collaborative and content-based models in cold-start or sparse
interaction data scenarios (using both user and item metadata), and performs at
least as well as a pure collaborative matrix factorisation model where
interaction data is abundant. Additionally, feature embeddings produced by the
model encode semantic information in a way reminiscent of word embedding
approaches, making them useful for a range of related tasks such as tag
recommendations.
</summary>
    <author>
      <name>Maciej Kula</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lyst.com</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1507.08439v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.08439v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.01929v1</id>
    <updated>2015-08-08T17:18:40Z</updated>
    <published>2015-08-08T17:18:40Z</published>
    <title>Combining Text and Formula Queries in Math Information Retrieval:
  Evaluation of Query Results Merging Strategies</title>
    <summary>  Specific to Math Information Retrieval is combining text with mathematical
formulae both in documents and in queries. Rigorous evaluation of query
expansion and merging strategies combining math and standard textual keyword
terms in a query are given. It is shown that techniques similar to those known
from textual query processing may be applied in math information retrieval as
well, and lead to a cutting edge performance. Striping and merging partial
results from subqueries is one technique that improves results measured by
information retrieval evaluation metrics like Bpref.
</summary>
    <author>
      <name>Martin Líška</name>
    </author>
    <author>
      <name>Petr Sojka</name>
    </author>
    <author>
      <name>Michal Růžička</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2810355.2810359</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2810355.2810359" rel="related"/>
    <link href="http://arxiv.org/abs/1508.01929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.01929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02127v1</id>
    <updated>2015-08-10T04:56:08Z</updated>
    <published>2015-08-10T04:56:08Z</published>
    <title>A novel design of hidden web crawler using ontology</title>
    <summary>  Deep Web is content hidden behind HTML forms. Since it represents a large
portion of the structured, unstructured and dynamic data on the Web, accessing
Deep-Web content has been a long challenge for the database community. This
paper describes a crawler for accessing Deep-Web using Ontologies. Performance
evaluation of the proposed work showed that this new approach has promising
results.
</summary>
    <author>
      <name> Manvi</name>
    </author>
    <author>
      <name>Komal Kumar Bhatia</name>
    </author>
    <author>
      <name>Ashutosh Dixit</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22315381/IJETT-V26P204</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22315381/IJETT-V26P204" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages,8 figures,2 tables, International Journal of Engineering
  Trends &amp; Technology (IJETT),August 2015, ISSN: 2231-5381</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03298v1</id>
    <updated>2015-08-13T18:35:06Z</updated>
    <published>2015-08-13T18:35:06Z</published>
    <title>Enabling Complex Wikipedia Queries - Technical Report</title>
    <summary>  In this technical report we present a database schema used to store Wikipedia
so it can be easily used in query-intensive applications. In addition to
storing the information in a way that makes it highly accessible, our schema
enables users to easily formulate complex queries using information such as the
anchor-text of links and their location in the page, the titles and number of
redirect pages for each page and the paragraph structure of entity pages. We
have successfully used the schema in domains such as recommender systems,
information retrieval and sentiment analysis. In order to assist other
researchers, we now make the schema and its content available online.
</summary>
    <author>
      <name>Gilad Katz</name>
    </author>
    <author>
      <name>Bracha Shapira</name>
    </author>
    <link href="http://arxiv.org/abs/1508.03298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03856v1</id>
    <updated>2015-08-16T19:27:35Z</updated>
    <published>2015-08-16T19:27:35Z</published>
    <title>Two-stage Cascaded Classifier for Purchase Prediction</title>
    <summary>  In this paper we describe our machine learning solution for the RecSys
Challenge, 2015. We have proposed a time efficient two-stage cascaded
classifier for the prediction of buy sessions and purchased items within such
sessions. Based on the model, several interesting features found, and formation
of our own test bed, we have achieved a reasonable score. Usage of Random
Forests helps us to cope with the effect of the multiplicity of good models
depending on varying subsets of features in the purchased items prediction and,
in its turn, boosting is used as a suitable technique to overcome severe class
imbalance of the buy-session prediction.
</summary>
    <author>
      <name>Sheikh Muhammad Sarwar</name>
    </author>
    <author>
      <name>Mahamudul Hasan</name>
    </author>
    <author>
      <name>Dmitry I. Ignatov</name>
    </author>
    <link href="http://arxiv.org/abs/1508.03856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00855v1</id>
    <updated>2016-01-05T15:18:10Z</updated>
    <published>2016-01-05T15:18:10Z</published>
    <title>TimeMachine: Entity-centric Search and Visualization of News Archives</title>
    <summary>  We present a dynamic web tool that allows interactive search and
visualization of large news archives using an entity-centric approach. Users
are able to search entities using keyword phrases expressing news stories or
events and the system retrieves the most relevant entities to the user query
based on automatically extracted and indexed entity profiles. From the
computational journalism perspective, TimeMachine allows users to explore media
content through time using automatic identification of entity names, jobs,
quotations and relations between entities from co-occurrences networks
extracted from the news articles. TimeMachine demo is available at
http://maquinadotempo.sapo.pt/
</summary>
    <author>
      <name>Pedro Saleiro</name>
    </author>
    <author>
      <name>Jorge Teixeira</name>
    </author>
    <author>
      <name>Carlos Soares</name>
    </author>
    <author>
      <name>Eugénio Oliveira</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Information Retrieval: 38th European Conference on IR
  Research, ECIR 2016, Padua, Italy, March 20-23, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.00855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02300v1</id>
    <updated>2016-01-11T02:06:36Z</updated>
    <published>2016-01-11T02:06:36Z</published>
    <title>Temporal Multinomial Mixture for Instance-Oriented Evolutionary
  Clustering</title>
    <summary>  Evolutionary clustering aims at capturing the temporal evolution of clusters.
This issue is particularly important in the context of social media data that
are naturally temporally driven. In this paper, we propose a new probabilistic
model-based evolutionary clustering technique. The Temporal Multinomial Mixture
(TMM) is an extension of classical mixture model that optimizes feature
co-occurrences in the trade-off with temporal smoothness. Our model is
evaluated for two recent case studies on opinion aggregation over time. We
compare four different probabilistic clustering models and we show the
superiority of our proposal in the task of instance-oriented clustering.
</summary>
    <author>
      <name>Young-Min Kim</name>
    </author>
    <author>
      <name>Julien Velcin</name>
    </author>
    <author>
      <name>Stéphane Bonnevay</name>
    </author>
    <author>
      <name>Marian-Andrei Rizoiu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-16354-3_66</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-16354-3_66" rel="related"/>
    <link href="http://arxiv.org/abs/1601.02300v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02300v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02904v1</id>
    <updated>2016-01-12T15:16:17Z</updated>
    <published>2016-01-12T15:16:17Z</published>
    <title>Social Network Extraction: Superficial Method and Information Retrieval</title>
    <summary>  Social network has become one of the themes of government issues, mainly
dealing with the chaos. The use of web is steadily gaining ground in these
issues. However, most of the web documents are unstructured and lack of
semantic. In this paper we proposed an Information Retrieval driven method for
dealing with heterogeneity of features in the web. The proposed solution is to
compare some approaches have shown the capacity to extract social relation:
strength relations and relations based on online academic database.
</summary>
    <author>
      <name>Mahyuddin K. M. Nasution</name>
    </author>
    <author>
      <name>Shahrul Azman Mohd. Noah</name>
    </author>
    <author>
      <name>Saidah Saad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 1 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceeding of International Conference on Informatics for
  Development (ICID'11), c2-110 - c2-115 (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.02904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04800v1</id>
    <updated>2016-01-19T04:48:42Z</updated>
    <published>2016-01-19T04:48:42Z</published>
    <title>Top-N Recommender System via Matrix Completion</title>
    <summary>  Top-N recommender systems have been investigated widely both in industry and
academia. However, the recommendation quality is far from satisfactory. In this
paper, we propose a simple yet promising algorithm. We fill the user-item
matrix based on a low-rank assumption and simultaneously keep the original
information. To do that, a nonconvex rank relaxation rather than the nuclear
norm is adopted to provide a better rank approximation and an efficient
optimization strategy is designed. A comprehensive set of experiments on real
datasets demonstrates that our method pushes the accuracy of Top-N
recommendation to a new level.
</summary>
    <author>
      <name>Zhao Kang</name>
    </author>
    <author>
      <name>Chong Peng</name>
    </author>
    <author>
      <name>Qiang Cheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01665v1</id>
    <updated>2016-02-04T13:19:31Z</updated>
    <published>2016-02-04T13:19:31Z</published>
    <title>Improved Query Topic Models via Pseudo-Relevant Pólya Document Models</title>
    <summary>  Query-expansion via pseudo-relevance feedback is a popular method of
overcoming the problem of vocabulary mismatch and of increasing average
retrieval effectiveness. In this paper, we develop a new method that estimates
a query topic model from a set of pseudo-relevant documents using a new
language modelling framework.
  We assume that documents are generated via a mixture of multivariate Polya
distributions, and we show that by identifying the topical terms in each
document, we can appropriately select terms that are likely to belong to the
query topic model. The results of experiments on several TREC collections show
that the new approach compares favourably to current state-of-the-art expansion
methods.
</summary>
    <author>
      <name>Ronan Cummins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.01665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02506v1</id>
    <updated>2016-02-08T09:40:43Z</updated>
    <published>2016-02-08T09:40:43Z</published>
    <title>Wikipedia Tools for Google Spreadsheets</title>
    <summary>  In this paper, we introduce the Wikipedia Tools for Google Spreadsheets.
Google Spreadsheets is part of a free, Web-based software office suite offered
by Google within its Google Docs service. It allows users to create and edit
spreadsheets online, while collaborating with other users in realtime.
Wikipedia is a free-access, free-content Internet encyclopedia, whose content
and data is available, among other means, through an API. With the Wikipedia
Tools for Google Spreadsheets, we have created a toolkit that facilitates
working with Wikipedia data from within a spreadsheet context. We make these
tools available as open-source on GitHub
[https://github.com/tomayac/wikipedia-tools-for-google-spreadsheets], released
under the permissive Apache 2.0 license.
</summary>
    <author>
      <name>Thomas Steiner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 Listings, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.02506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02911v1</id>
    <updated>2016-02-09T09:22:40Z</updated>
    <published>2016-02-09T09:22:40Z</published>
    <title>Searching PubMed for articles relevant to clinical interpretation of
  rare human genetic variants</title>
    <summary>  Numerous challenges persist that delay clinical interpretation of human
genetic variants, to name a few: (1) un- structured PubMed articles are the
most abundant source of evidence, yet their variant annotations are difficult
to query uniformly, (2) variants can be reported many different ways, for
example as DNA sequence change or protein modification, (3) historical drift in
annotations over time between various genome reference assemblies and
transcript alignments, (4) no single laboratory has sufficient numbers of human
samples, necessitating precompetitive efforts to share evidence for clinical
interpretation.
</summary>
    <author>
      <name>Andrew J. McMurry</name>
    </author>
    <link href="http://arxiv.org/abs/1602.02911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07799v1</id>
    <updated>2016-02-25T05:12:55Z</updated>
    <published>2016-02-25T05:12:55Z</published>
    <title>A Study on the usage of Data Structures in Information Retrieval</title>
    <summary>  This paper tries to throw light in the usage of data structures in the field
of information retrieval. Information retrieval is an area of study which is
gaining momentum as the need and urge for sharing and exploring information is
growing day by day. Data structures have been the area of research for a long
period in the arena of computer science. The need to have efficient data
structures has become even more important as the data grows in an exponential
nature.
</summary>
    <author>
      <name>V. R. Kanagavalli</name>
    </author>
    <author>
      <name>G. Maheeja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">National Conference on Innovations in Communication and Computing
  Technologies Feb 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00134v2</id>
    <updated>2017-02-22T15:22:14Z</updated>
    <published>2016-07-30T15:42:34Z</published>
    <title>A Graph Framework for Multimodal Medical Information Processing</title>
    <summary>  Multimodal medical information processing is currently the epicenter of
intense interdisciplinary research, as proper data fusion may lead to more
accurate diagnoses. Moreover, multimodality may disambiguate cases of
co-morbidity. This paper presents a framework for retrieving, analyzing, and
storing medical information as a multilayer graph, an abstract format suitable
for data fusion and further processing. At the same time, this paper addresses
the need for reliable medical information through co-author graph ranking. A
use case pertaining to frailty based on Python and Neo4j serves as an
illustration of the proposed framework.
</summary>
    <author>
      <name>Georgios Drakopoulos</name>
    </author>
    <author>
      <name>Vasileios Megalooikonomou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We need to correct certain errors both in the software description as
  well as in the algorithms</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.00134v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00134v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00147v1</id>
    <updated>2016-07-30T16:53:05Z</updated>
    <published>2016-07-30T16:53:05Z</published>
    <title>Attention Span For Personalisation</title>
    <summary>  A click on an item is arguably the most widely used feature in recommender
systems. However, a click is one out of 174 events a browser can trigger. This
paper presents a framework to effectively collect and store data from event
streams. A set of mining methods is provided to extract user engagement
features such as: attention span, scrolling depth and visible impressions. In
this work, we present an experiment where recommendations based on attention
span drove 340% higher click-through-rate than clicks.
</summary>
    <author>
      <name>Joan Figuerola Hurtado</name>
    </author>
    <link href="http://arxiv.org/abs/1608.00147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01068v1</id>
    <updated>2016-08-03T03:49:54Z</updated>
    <published>2016-08-03T03:49:54Z</published>
    <title>Ranking Entity Based on Both of Word Frequency and Word Sematic Features</title>
    <summary>  Entity search is a new application meeting either precise or vague
requirements from the search engines users. Baidu Cup 2016 Challenge just
provided such a chance to tackle the problem of the entity search. We achieved
the first place with the average MAP scores on 4 tasks including movie, tvShow,
celebrity and restaurant. In this paper, we propose a series of similarity
features based on both of the word frequency features and the word semantic
features and describe our ranking architecture and experiment details.
</summary>
    <author>
      <name>Xiao-Bo Jin</name>
    </author>
    <author>
      <name>Guang-Gang Geng</name>
    </author>
    <author>
      <name>Kaizhu Huang</name>
    </author>
    <author>
      <name>Zhi-Wei Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper decribes the apporoaches that help us to achieve the first
  place in Baidu Cup 2016 NLP Challenge</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01247v2</id>
    <updated>2016-11-05T04:59:48Z</updated>
    <published>2016-08-03T16:33:32Z</published>
    <title>Query Clustering using Segment Specific Context Embeddings</title>
    <summary>  This paper presents a novel query clustering approach to capture the broad
interest areas of users querying search engines. We make use of recent advances
in NLP - word2vec and extend it to get query2vec, vector representations of
queries, based on query contexts, obtained from the top search results for the
query and use a highly scalable Divide &amp; Merge clustering algorithm on top of
the query vectors, to get the clusters. We have tried this approach on a
variety of segments, including Retail, Travel, Health, Phones and found the
clusters to be effective in discovering user's interest areas which have high
monetization potential.
</summary>
    <author>
      <name>S. K Kolluru</name>
    </author>
    <author>
      <name>Prasenjit Mukherjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01247v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01247v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01573v1</id>
    <updated>2016-08-04T15:14:04Z</updated>
    <published>2016-08-04T15:14:04Z</published>
    <title>Local Term Weight Models from Power Transformations: Development of
  BM25IR: A Best Match Model based on Inverse Regression</title>
    <summary>  In this article we show how power transformations can be used as a common
framework for the derivation of local term weights. We found that under some
parametric conditions, BM25 and inverse regression produce equivalent results.
As a special case of inverse regression, we show that the largest increment in
term weight occurs when a term is mentioned for the second time. A model based
on inverse regression (BM25IR) is presented. Simulations suggest that BM25IR
works fairly well for different BM25 parametric conditions and document
lengths.
</summary>
    <author>
      <name>Edel Garcia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 2 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03905v1</id>
    <updated>2016-08-12T20:33:54Z</updated>
    <published>2016-08-12T20:33:54Z</published>
    <title>Using Centroids of Word Embeddings and Word Mover's Distance for
  Biomedical Document Retrieval in Question Answering</title>
    <summary>  We propose a document retrieval method for question answering that represents
documents and questions as weighted centroids of word embeddings and reranks
the retrieved documents with a relaxation of Word Mover's Distance. Using
biomedical questions and documents from BIOASQ, we show that our method is
competitive with PUBMED. With a top-k approximation, our method is fast, and
easily portable to other domains and languages.
</summary>
    <author>
      <name>Georgios-Ioannis Brokos</name>
    </author>
    <author>
      <name>Prodromos Malakasiotis</name>
    </author>
    <author>
      <name>Ion Androutsopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 images, presented at BioNLP 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.03905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06656v1</id>
    <updated>2016-08-23T21:07:50Z</updated>
    <published>2016-08-23T21:07:50Z</published>
    <title>Lexical Query Modeling in Session Search</title>
    <summary>  Lexical query modeling has been the leading paradigm for session search. In
this paper, we analyze TREC session query logs and compare the performance of
different lexical matching approaches for session search. Naive methods based
on term frequency weighing perform on par with specialized session models. In
addition, we investigate the viability of lexical query models in the setting
of session search. We give important insights into the potential and
limitations of lexical query modeling for session search and propose future
directions for the field of session search.
</summary>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <author>
      <name>Evangelos Kanoulas</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2970398.2970422</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2970398.2970422" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICTIR2016, Proceedings of the 2nd ACM International Conference on the
  Theory of Information Retrieval. 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.06656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.07400v2</id>
    <updated>2017-01-03T07:41:44Z</updated>
    <published>2016-08-26T09:20:21Z</published>
    <title>Collaborative Filtering with Recurrent Neural Networks</title>
    <summary>  We show that collaborative filtering can be viewed as a sequence prediction
problem, and that given this interpretation, recurrent neural networks offer
very competitive approach. In particular we study how the long short-term
memory (LSTM) can be applied to collaborative filtering, and how it compares to
standard nearest neighbors and matrix factorization methods on movie
recommendation. We show that the LSTM is competitive in all aspects, and
largely outperforms other methods in terms of item coverage and short term
predictions.
</summary>
    <author>
      <name>Robin Devooght</name>
    </author>
    <author>
      <name>Hugues Bersini</name>
    </author>
    <link href="http://arxiv.org/abs/1608.07400v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.07400v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00683v1</id>
    <updated>2016-09-02T17:50:53Z</updated>
    <published>2016-09-02T17:50:53Z</published>
    <title>Pairwise, Magnitude, or Stars: What's the Best Way for Crowds to Rate?</title>
    <summary>  We compare three popular techniques of rating content: the ubiquitous five
star rating, the less used pairwise comparison, and the recently introduced (in
crowdsourcing) magnitude estimation approach. Each system has specific
advantages and disadvantages, in terms of required user effort, achievable user
preference prediction accuracy and number of ratings required.
  We design an experiment where the three techniques are compared in an
unbiased way. We collected 39'000 ratings on a popular crowdsourcing platform,
allowing us to release a dataset that will be useful for many related studies
on user rating techniques.
</summary>
    <author>
      <name>Alessandro Checco</name>
    </author>
    <author>
      <name>Gianluca Demartini</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00689v1</id>
    <updated>2016-09-02T18:23:22Z</updated>
    <published>2016-09-02T18:23:22Z</published>
    <title>Ensemble Learned Vaccination Uptake Prediction using Web Search Queries</title>
    <summary>  We present a method that uses ensemble learning to combine clinical and
web-mined time-series data in order to predict future vaccination uptake. The
clinical data is official vaccination registries, and the web data is query
frequencies collected from Google Trends. Experiments with official vaccine
records show that our method predicts vaccination uptake effectively (4.7 Root
Mean Squared Error). Whereas performance is best when combining clinical and
web data, using solely web data yields comparative performance. To our
knowledge, this is the first study to predict vaccination uptake using web data
(with and without clinical data).
</summary>
    <author>
      <name>Niels Dalum Hansen</name>
    </author>
    <author>
      <name>Christina Lioma</name>
    </author>
    <author>
      <name>Kåre Mølbak</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02171v1</id>
    <updated>2016-09-04T12:07:57Z</updated>
    <published>2016-09-04T12:07:57Z</published>
    <title>The Effect of Class Imbalance and Order on Crowdsourced Relevance
  Judgments</title>
    <summary>  In this paper we study the effect on crowd worker efficiency and
effectiveness of the dominance of one class in the data they process. We aim at
understanding if there is any positive or negative bias in workers seeing many
negative examples in the identification of positive labels. To test our
hypothesis, we design an experiment where crowd workers are asked to judge the
relevance of documents presented in different orders. Our findings indicate
that there is a significant improvement in the quality of relevance judgements
when presenting relevant results before the non-relevant ones.
</summary>
    <author>
      <name>Rehab K. Qarout</name>
    </author>
    <author>
      <name>Alessandro Checco</name>
    </author>
    <author>
      <name>Gianluca Demartini</name>
    </author>
    <link href="http://arxiv.org/abs/1609.02171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.02815v1</id>
    <updated>2016-11-08T15:25:02Z</updated>
    <published>2016-11-08T15:25:02Z</published>
    <title>An Automated System for Essay Scoring of Online Exams in Arabic based on
  Stemming Techniques and Levenshtein Edit Operations</title>
    <summary>  In this article, an automated system is proposed for essay scoring in Arabic
language for online exams based on stemming techniques and Levenshtein edit
operations. An online exam has been developed on the proposed mechanisms,
exploiting the capabilities of light and heavy stemming. The implemented online
grading system has shown to be an efficient tool for automated scoring of essay
questions.
</summary>
    <author>
      <name>Emad Fawzi Al-Shalabi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Volume 13,
  Issue 5, September 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1611.02815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.02815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.09028v1</id>
    <updated>2016-11-28T08:56:04Z</updated>
    <published>2016-11-28T08:56:04Z</published>
    <title>Analyzing Features for the Detection of Happy Endings in German Novels</title>
    <summary>  With regard to a computational representation of literary plot, this paper
looks at the use of sentiment analysis for happy ending detection in German
novels. Its focus lies on the investigation of previously proposed sentiment
features in order to gain insight about the relevance of specific features on
the one hand and the implications of their performance on the other hand.
Therefore, we study various partitionings of novels, considering the highly
variable concept of "ending". We also show that our approach, even though still
rather simple, can potentially lead to substantial findings relevant to
literary studies.
</summary>
    <author>
      <name>Fotis Jannidis</name>
    </author>
    <author>
      <name>Isabella Reger</name>
    </author>
    <author>
      <name>Albin Zehe</name>
    </author>
    <author>
      <name>Martin Becker</name>
    </author>
    <author>
      <name>Lena Hettinger</name>
    </author>
    <author>
      <name>Andreas Hotho</name>
    </author>
    <link href="http://arxiv.org/abs/1611.09028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.09028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00749v1</id>
    <updated>2017-01-03T17:17:34Z</updated>
    <published>2017-01-03T17:17:34Z</published>
    <title>Pyndri: a Python Interface to the Indri Search Engine</title>
    <summary>  We introduce pyndri, a Python interface to the Indri search engine. Pyndri
allows to access Indri indexes from Python at two levels: (1) dictionary and
tokenized document collection, (2) evaluating queries on the index. We hope
that with the release of pyndri, we will stimulate reproducible, open and
fast-paced IR research.
</summary>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <author>
      <name>Evangelos Kanoulas</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR2017. Proceedings of the 39th European Conference on Information
  Retrieval. 2017. The final publication will be available at Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.00749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01250v1</id>
    <updated>2017-01-05T08:53:02Z</updated>
    <published>2017-01-05T08:53:02Z</published>
    <title>A Probabilistic View of Neighborhood-based Recommendation Methods</title>
    <summary>  Probabilistic graphic model is an elegant framework to compactly present
complex real-world observations by modeling uncertainty and logical flow
(conditionally independent factors). In this paper, we present a probabilistic
framework of neighborhood-based recommendation methods (PNBM) in which
similarity is regarded as an unobserved factor. Thus, PNBM leads the estimation
of user preference to maximizing a posterior over similarity. We further
introduce a novel multi-layer similarity descriptor which models and learns the
joint influence of various features under PNBM, and name the new framework
MPNBM. Empirical results on real-world datasets show that MPNBM allows very
accurate estimation of user preferences.
</summary>
    <author>
      <name>Jun Wang</name>
    </author>
    <author>
      <name>Qiang Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by: ICDM 2016 - IEEE International Conference on Data Mining
  series (ICDM) workshop CLOUDMINE, 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.01250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01417v1</id>
    <updated>2017-01-05T18:36:26Z</updated>
    <published>2017-01-05T18:36:26Z</published>
    <title>Exploration of Proximity Heuristics in Length Normalization</title>
    <summary>  Ranking functions used in information retrieval are primarily used in the
search engines and they are often adopted for various language processing
applications. However, features used in the construction of ranking functions
should be analyzed before applying it on a data set. This paper gives
guidelines on construction of generalized ranking functions with
application-dependent features. The paper prescribes a specific case of a
generalized function for recommendation system using feature engineering
guidelines on the given data set. The behavior of both generalized and specific
functions are studied and implemented on the unstructured textual data. The
proximity feature based ranking function has outperformed by 52% from regular
BM25.
</summary>
    <author>
      <name>Pranav Agrawal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.01417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01737v1</id>
    <updated>2017-01-06T19:04:34Z</updated>
    <published>2017-01-06T19:04:34Z</published>
    <title>Spotting Information biases in Chinese and Western Media</title>
    <summary>  Newswire and Social Media are the major sources of information in our time.
While the topical demographic of Western Media was subjects of studies in the
past, less is known about Chinese Media. In this paper, we apply event
detection and tracking technology to examine the information overlap and
differences between Chinese and Western - Traditional Media and Social Media.
Our experiments reveal a biased interest of China towards the West, which
becomes particularly apparent when comparing the interest in celebrities.
</summary>
    <author>
      <name>Dominik Wurzer</name>
    </author>
    <author>
      <name>Yumeng Qin</name>
    </author>
    <link href="http://arxiv.org/abs/1701.01737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02617v1</id>
    <updated>2017-01-10T14:46:17Z</updated>
    <published>2017-01-10T14:46:17Z</published>
    <title>On Low Overlap Among Search Results of Academic Search Engines</title>
    <summary>  Number of published scholarly articles is growing exponentially. To tackle
this information overload, researchers are increasingly depending on niche
academic search engines. Recent works have shown that two major general web
search engines: Google and Bing, have high level of agreement in their top
search results. In contrast, we show that various academic search engines have
low degree of agreement among themselves. We performed experiments using 2500
queries over four academic search engines. We observe that overlap in search
result sets of any pair of academic search engines is significantly low and in
most of the cases the search result sets are mutually exclusive. We also
discuss implications of this low overlap.
</summary>
    <author>
      <name>Anasua Mitra</name>
    </author>
    <author>
      <name>Amit Awekar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, submitted to ACM WWW Conference 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.02617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02552v1</id>
    <updated>2017-04-09T01:24:32Z</updated>
    <published>2017-04-09T01:24:32Z</published>
    <title>Embedded Collaborative Filtering for "Cold Start" Prediction</title>
    <summary>  Using only implicit data, many recommender systems fail in general to provide
a precise set of recommendations to users with limited interaction history.
This issue is regarded as the "Cold Start" problem and is typically resolved by
switching to content-based approaches where extra costly information is
required. In this paper, we use a dimensionality reduction algorithm, Word2Vec
(W2V), originally applied in Natural Language Processing problems under the
framework of Collaborative Filtering (CF) to tackle the "Cold Start" problem
using only implicit data. This combined method is named Embedded Collaborative
Filtering (ECF). An experiment is conducted to determine the performance of ECF
on two different implicit data sets. We show that the ECF approach outperforms
other popular and state-of-the-art approaches in "Cold Start" scenarios.
</summary>
    <author>
      <name>Yubo Zhou</name>
    </author>
    <author>
      <name>Ali Nadaf</name>
    </author>
    <link href="http://arxiv.org/abs/1704.02552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03624v1</id>
    <updated>2017-04-12T05:36:28Z</updated>
    <published>2017-04-12T05:36:28Z</published>
    <title>Loklak - A Distributed Crawler and Data Harvester for Overcoming Rate
  Limits</title>
    <summary>  Modern social networks have become sources for vast quantities of data.
Having access to such big data can be very useful for various researchers and
data scientists. In this paper we describe Loklak, an open source distributed
peer to peer crawler and scraper for supporting such research on platforms like
Twitter, Weibo and other social networks. Social networks such as Twitter and
Weibo pose various limitations to the user on the rate at which one could
freely collect such data for research. Our crawler enables researchers to
continuously collect data while overcoming the barriers of authentication and
rate limits imposed to provide a repository of open data as a service.
</summary>
    <author>
      <name>Sudheesh Singanamalla</name>
    </author>
    <author>
      <name>Michael Peter Christen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.03624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03367v1</id>
    <updated>2017-07-11T17:12:50Z</updated>
    <published>2017-07-11T17:12:50Z</published>
    <title>Wextractor: Follow-up of the evolution of prices in web pages</title>
    <summary>  In the e-commerce world, the follow-up of prices in detail web pages is of
great interest for things like buying a product when it falls below some
threshold. For doing this task, instead of bookmarking the pages and revisiting
them, in this paper we propose a novel web data extraction system, called
Wextractor. It consists of an extraction method and a web app for listing the
retrieved prices. As for the final user, the main feature of Wextractor is
usability because (s)he only has to signal the pages of interest and our system
automatically extracts the price from the page.
</summary>
    <author>
      <name>Jorge Lloret-Gazo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03569v1</id>
    <updated>2017-07-12T07:17:50Z</updated>
    <published>2017-07-12T07:17:50Z</published>
    <title>Multitask Learning for Fine-Grained Twitter Sentiment Analysis</title>
    <summary>  Traditional sentiment analysis approaches tackle problems like ternary
(3-category) and fine-grained (5-category) classification by learning the tasks
separately. We argue that such classification tasks are correlated and we
propose a multitask approach based on a recurrent neural network that benefits
by jointly learning them. Our study demonstrates the potential of multitask
models on this type of problems and improves the state-of-the-art results in
the fine-grained sentiment classification problem.
</summary>
    <author>
      <name>Georgios Balikas</name>
    </author>
    <author>
      <name>Simon Moura</name>
    </author>
    <author>
      <name>Massih-Reza Amini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3077136.3080702</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3077136.3080702" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International ACM SIGIR Conference on Research and Development in
  Information Retrieval 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05254v1</id>
    <updated>2017-07-12T23:18:58Z</updated>
    <published>2017-07-12T23:18:58Z</published>
    <title>Explainable Entity-based Recommendations with Knowledge Graphs</title>
    <summary>  Explainable recommendation is an important task. Many methods have been
proposed which generate explanations from the content and reviews written for
items. When review text is unavailable, generating explanations is still a hard
problem. In this paper, we illustrate how explanations can be generated in such
a scenario by leveraging external knowledge in the form of knowledge graphs.
Our method jointly ranks items and knowledge graph entities using a
Personalized PageRank procedure to produce recommendations together with their
explanations.
</summary>
    <author>
      <name>Rose Catherine</name>
    </author>
    <author>
      <name>Kathryn Mazaitis</name>
    </author>
    <author>
      <name>Maxine Eskenazi</name>
    </author>
    <author>
      <name>William Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the 11th ACM Conference on Recommender
  Systems (RecSys 2017) - Posters</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06562v1</id>
    <updated>2017-07-20T15:06:43Z</updated>
    <published>2017-07-20T15:06:43Z</published>
    <title>From Task Classification Towards Similarity Measures for Recommendation
  in Crowdsourcing Systems</title>
    <summary>  Task selection in micro-task markets can be supported by recommender systems
to help individuals to find appropriate tasks. Previous work showed that for
the selection process of a micro-task the semantic aspects, such as the
required action and the comprehensibility, are rated more important than
factual aspects, such as the payment or the required completion time. This work
gives a foundation to create such similarity measures. Therefore, we show that
an automatic classification based on task descriptions is possible.
Additionally, we propose similarity measures to cluster micro-tasks according
to semantic aspects.
</summary>
    <author>
      <name>Steffen Schnitzer</name>
    </author>
    <author>
      <name>Svenja Neitzel</name>
    </author>
    <author>
      <name>Christoph Rensing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in Progress Paper at HCOMP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.06562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08913v1</id>
    <updated>2017-07-27T15:52:18Z</updated>
    <published>2017-07-27T15:52:18Z</published>
    <title>Multi-Stakeholder Recommendation: Applications and Challenges</title>
    <summary>  Recommender systems have been successfully applied to assist decision making
by producing a list of item recommendations tailored to user preferences.
Traditional recommender systems only focus on optimizing the utility of the end
users who are the receiver of the recommendations. By contrast,
multi-stakeholder recommendation attempts to generate recommendations that
satisfy the needs of both the end users and other parties or stakeholders. This
paper provides an overview and discussion about the multi-stakeholder
recommendations from the perspective of practical applications, available data
sets, corresponding research challenges and potential solutions.
</summary>
    <author>
      <name>Yong Zheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.08913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09258v1</id>
    <updated>2017-07-28T14:42:34Z</updated>
    <published>2017-07-28T14:42:34Z</published>
    <title>Patterns of Multistakeholder Recommendation</title>
    <summary>  Recommender systems are personalized information systems. However, in many
settings, the end-user of the recommendations is not the only party whose needs
must be represented in recommendation generation. Incorporating this insight
gives rise to the notion of multistakeholder recommendation, in which the
interests of multiple parties are represented in recommendation algorithms and
evaluation. In this paper, we identify patterns of stakeholder utility that
characterize different multistakeholder recommendation applications, and
provide a taxonomy of the different possible systems, only some of which have
currently been implemented.
</summary>
    <author>
      <name>Robin Burke</name>
    </author>
    <author>
      <name>Himan Abdollahpouri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09823v1</id>
    <updated>2017-07-31T12:48:45Z</updated>
    <published>2017-07-31T12:48:45Z</published>
    <title>Familia: An Open-Source Toolkit for Industrial Topic Modeling</title>
    <summary>  Familia is an open-source toolkit for pragmatic topic modeling in industry.
Familia abstracts the utilities of topic modeling in industry as two paradigms:
semantic representation and semantic matching. Efficient implementations of the
two paradigms are made publicly available for the first time. Furthermore, we
provide off-the-shelf topic models trained on large-scale industrial corpora,
including Latent Dirichlet Allocation (LDA), SentenceLDA and Topical Word
Embedding (TWE). We further describe typical applications which are
successfully powered by topic modeling, in order to ease the confusions and
difficulties of software engineers during topic model selection and
utilization.
</summary>
    <author>
      <name>Di Jiang</name>
    </author>
    <author>
      <name>Zeyu Chen</name>
    </author>
    <author>
      <name>Rongzhong Lian</name>
    </author>
    <author>
      <name>Siqi Bao</name>
    </author>
    <author>
      <name>Chen Li</name>
    </author>
    <link href="http://arxiv.org/abs/1707.09823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02765v1</id>
    <updated>2017-08-09T09:00:03Z</updated>
    <published>2017-08-09T09:00:03Z</published>
    <title>Ephemeral Context to Support Robust and Diverse Music Recommendations</title>
    <summary>  While prior work on context-based music recommendation focused on fixed set
of contexts (e.g. walking, driving, jogging), we propose to use multiple
sensors and external data sources to describe momentary (ephemeral) context in
a rich way with a very large number of possible states (e.g. jogging fast along
in downtown of Sydney under a heavy rain at night being tired and angry). With
our approach, we address the problems which current approaches face: 1) a
limited ability to infer context from missing or faulty sensor data; 2) an
inability to use contextual information to support novel content discovery.
</summary>
    <author>
      <name>Pavel Kucherbaev</name>
    </author>
    <author>
      <name>Nava Tintarev</name>
    </author>
    <author>
      <name>Carlos Rodriguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, Machine Learning for Music Discovery workshop at
  ICML2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.02765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04326v1</id>
    <updated>2017-08-14T21:04:36Z</updated>
    <published>2017-08-14T21:04:36Z</published>
    <title>Improved Answer Selection with Pre-Trained Word Embeddings</title>
    <summary>  This paper evaluates existing and newly proposed answer selection methods
based on pre-trained word embeddings. Word embeddings are highly effective in
various natural language processing tasks and their integration into
traditional information retrieval (IR) systems allows for the capture of
semantic relatedness between questions and answers. Empirical results on three
publicly available data sets show significant gains over traditional term
frequency based approaches in both supervised and unsupervised settings. We
show that combining these word embedding features with traditional
learning-to-rank techniques can achieve similar performance to state-of-the-art
neural networks trained for the answer selection task.
</summary>
    <author>
      <name>Rishav Chakravarti</name>
    </author>
    <author>
      <name>Jiri Navratil</name>
    </author>
    <author>
      <name>Cicero Nogueira dos Santos</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06011v1</id>
    <updated>2017-08-20T19:41:58Z</updated>
    <published>2017-08-20T19:41:58Z</published>
    <title>Modelling Word Burstiness in Natural Language: A Generalised Polya
  Process for Document Language Models in Information Retrieval</title>
    <summary>  We introduce a generalised multivariate Polya process for document language
modelling. The framework outlined here generalises a number of statistical
language models used in information retrieval for modelling document
generation. In particular, we show that the choice of replacement matrix M
ultimately defines the type of random process and therefore defines a
particular type of document language model. We show that a particular variant
of the general model is useful for modelling term-specific burstiness.
Furthermore, via experimentation we show that this variant significantly
improves retrieval effectiveness over a strong baseline on a number of small
test collections.
</summary>
    <author>
      <name>Ronan Cummins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08289v1</id>
    <updated>2017-08-28T12:44:14Z</updated>
    <published>2017-08-28T12:44:14Z</published>
    <title>Generating Query Suggestions to Support Task-Based Search</title>
    <summary>  We address the problem of generating query suggestions to support users in
completing their underlying tasks (which motivated them to search in the first
place). Given an initial query, these query suggestions should provide a
coverage of possible subtasks the user might be looking for. We propose a
probabilistic modeling framework that obtains keyphrases from multiple sources
and generates query suggestions from these keyphrases. Using the test suites of
the TREC Tasks track, we evaluate and analyze each component of our model.
</summary>
    <author>
      <name>Darío Garigliotti</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3077136.3080745</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3077136.3080745" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 40th International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR '17), 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.08289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.00399v1</id>
    <updated>2017-10-01T19:42:53Z</updated>
    <published>2017-10-01T19:42:53Z</published>
    <title>Identifying Clickbait Posts on Social Media with an Ensemble of Linear
  Models</title>
    <summary>  The purpose of a clickbait is to make a link so appealing that people click
on it. However, the content of such articles is often not related to the title,
shows poor quality, and at the end leaves the reader unsatisfied.
  To help the readers, the organizers of the clickbait challenge
(http://www.clickbait-challenge.org/) asked the participants to build a machine
learning model for scoring articles with respect to their "clickbaitness".
  In this paper we propose to solve the clickbait problem with an ensemble of
Linear SVM models, and our approach was tested successfully in the challenge:
it showed great performance of 0.036 MSE and ranked 3rd among all the solutions
to the contest.
</summary>
    <author>
      <name>Alexey Grigorev</name>
    </author>
    <link href="http://arxiv.org/abs/1710.00399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.00399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.08389v1</id>
    <updated>2017-10-23T17:00:13Z</updated>
    <published>2017-10-23T17:00:13Z</published>
    <title>An Empirical Investigation On Search Engine Ad Disclosure</title>
    <summary>  This representative study of German search engine users (N=1,000) focuses on
the ability of users to distinguish between organic results and advertisements
on Google results pages. We combine questions about Google's business with
task-based studies in which users were asked to distinguish between ads and
organic results in screenshots of results pages. We find that only a small
percentage of users is able to reliably distinguish between ads and organic
results, and that user knowledge of Google's business model is very limited. We
conclude that ads are insufficiently labelled as such, and that many users may
click on ads assuming that they are selecting organic results.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <author>
      <name>Friederike Kerkmann</name>
    </author>
    <author>
      <name>Sandra Ruemmele</name>
    </author>
    <author>
      <name>Sebastian Suenkler</name>
    </author>
    <link href="http://arxiv.org/abs/1710.08389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.08389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.11231v1</id>
    <updated>2017-10-30T20:39:31Z</updated>
    <published>2017-10-30T20:39:31Z</published>
    <title>Bibliometric-Enhanced Information Retrieval: 5th International BIR
  Workshop</title>
    <summary>  Bibliometric-enhanced Information Retrieval (BIR) workshops serve as the
annual gathering of IR researchers who address various information-related
tasks on scientific corpora and bibliometrics. The workshop features original
approaches to search, browse, and discover value-added knowledge from
scientific documents and related information networks (e.g., terms, authors,
institutions, references). We welcome contributions elaborating on dedicated IR
systems, as well as studies revealing original characteristics on how
scientific knowledge is created, communicated, and used. In this paper we
introduce the BIR workshop series and discuss some selected papers presented at
previous BIR workshops.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Ingo Frommholz</name>
    </author>
    <author>
      <name>Guillaume Cabanac</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, workshop paper accepted at 39th European Conference on IR
  Research, ECIR 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.11231v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.11231v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.00715v1</id>
    <updated>2017-10-31T18:52:28Z</updated>
    <published>2017-10-31T18:52:28Z</published>
    <title>Related Fact Checks: a tool for combating fake news</title>
    <summary>  The emergence of "Fake News" and misinformation via online news and social
media has spurred an interest in computational tools to combat this phenomenon.
In this paper we present a new "Related Fact Checks" service, which can help a
reader critically evaluate an article and make a judgment on its veracity by
bringing up fact checks that are relevant to the article. We describe the core
technical problems that need to be solved in building a "Related Fact Checks"
service, and present results from an evaluation of an implementation.
</summary>
    <author>
      <name>Sreya Guha</name>
    </author>
    <link href="http://arxiv.org/abs/1711.00715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.00715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.01647v1</id>
    <updated>2017-11-05T19:29:21Z</updated>
    <published>2017-11-05T19:29:21Z</published>
    <title>Performance Comparison of Algorithms for Movie Rating Estimation</title>
    <summary>  In this paper, our goal is to compare performances of three different
algorithms to predict the ratings that will be given to movies by potential
users where we are given a user-movie rating matrix based on the past
observations. To this end, we evaluate User-Based Collaborative Filtering,
Iterative Matrix Factorization and Yehuda Koren's Integrated model using
neighborhood and factorization where we use root mean square error (RMSE) as
the performance evaluation metric. In short, we do not observe significant
differences between performances, especially when the complexity increase is
considered. We can conclude that Iterative Matrix Factorization performs fairly
well despite its simplicity.
</summary>
    <author>
      <name>Alper Kose</name>
    </author>
    <author>
      <name>Can Kanbak</name>
    </author>
    <author>
      <name>Noyan Evirgen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been accepted to the 2017 IEEE ICMLA</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.01647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.01647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.04101v1</id>
    <updated>2017-11-11T08:43:06Z</updated>
    <published>2017-11-11T08:43:06Z</published>
    <title>Recommender Systems with Random Walks: A Survey</title>
    <summary>  Recommender engines have become an integral component in today's e-commerce
systems. From recommending books in Amazon to finding friends in social
networks such as Facebook, they have become omnipresent.
  Generally, recommender systems can be classified into two main categories:
content based and collaborative filtering based models. Both these models build
relationships between users and items to provide recommendations. Content based
systems achieve this task by utilizing features extracted from the context
available, whereas collaborative systems use shared interests between user-item
subsets.
  There is another relatively unexplored approach for providing recommendations
that utilizes a stochastic process named random walks. This study is a survey
exploring use cases of random walks in recommender systems and an attempt at
classifying them.
</summary>
    <author>
      <name>Laknath Semage</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, a survey paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.04101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.04101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.08379v2</id>
    <updated>2018-01-29T03:32:21Z</updated>
    <published>2017-11-22T16:37:42Z</published>
    <title>Mixture-of-tastes Models for Representing Users with Diverse Interests</title>
    <summary>  Most existing recommendation approaches implicitly treat user tastes as
unimodal, resulting in an average-of-tastes representations when multiple
distinct interests are present. We show that appropriately modelling the
multi-faceted nature of user tastes through a mixture-of-tastes model leads to
large increases in recommendation quality. Our result holds both for deep
sequence-based and traditional factorization models, and is robust to careful
selection and tuning of baseline models. In sequence-based models, this
improvement is achieved at a very modest cost in model complexity, making
mixture-of-tastes models a straightforward improvement on existing baselines.
</summary>
    <author>
      <name>Maciej Kula</name>
    </author>
    <link href="http://arxiv.org/abs/1711.08379v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.08379v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.08521v1</id>
    <updated>2017-11-22T22:24:20Z</updated>
    <published>2017-11-22T22:24:20Z</published>
    <title>EMFET: E-mail Features Extraction Tool</title>
    <summary>  EMFET is an open source and flexible tool that can be used to extract a large
number of features from any email corpus with emails saved in EML format. The
extracted features can be categorized into three main groups: header features,
payload (body) features, and attachment features. The purpose of the tool is to
help practitioners and researchers to build datasets that can be used for
training machine learning models for spam detection. So far, 140 features can
be extracted using EMFET. EMFET is extensible and easy to use. The source code
of EMFET is publicly available at GitHub
(https://github.com/WadeaHijjawi/EmailFeaturesExtraction)
</summary>
    <author>
      <name>Wadi' Hijawi</name>
    </author>
    <author>
      <name>Hossam Faris</name>
    </author>
    <author>
      <name>Ja'far Alqatawna</name>
    </author>
    <author>
      <name>Ibrahim Aljarah</name>
    </author>
    <author>
      <name>Ala' M. Al-Zoubi</name>
    </author>
    <author>
      <name>Maria Habib</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.32995.45603</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.32995.45603" rel="related"/>
    <link href="http://arxiv.org/abs/1711.08521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.08521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.10307v2</id>
    <updated>2017-11-29T13:50:46Z</updated>
    <published>2017-11-28T14:28:54Z</published>
    <title>Semantic Technology-Assisted Review (STAR) Document analysis and
  monitoring using random vectors</title>
    <summary>  The review and analysis of large collections of documents and the periodic
monitoring of new additions thereto has greatly benefited from new developments
in computer software. This paper demonstrates how using random vectors to
construct a low-dimensional Euclidean space embedding words and documents
enables fast and accurate computation of semantic similarities between them.
With this technique of Semantic Technology-Assisted Review (STAR), documents
can be selected, compared, classified, summarized and evaluated very quickly
with minimal expert involvement and high-quality results.
</summary>
    <author>
      <name>Jean-François Delpech</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 9 tables, 21 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.10307v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.10307v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1711.10377v2</id>
    <updated>2017-12-16T03:51:43Z</updated>
    <published>2017-11-15T17:32:59Z</published>
    <title>Sentiment analysis of twitter data</title>
    <summary>  Social networks are the main resources to gather information about people's
opinion and sentiments towards different topics as they spend hours daily on
social media and share their opinion. In this technical paper, we show the
application of sentimental analysis and how to connect to Twitter and run
sentimental analysis queries. We run experiments on different queries from
politics to humanity and show the interesting results. We realized that the
neutral sentiments for tweets are significantly high which clearly shows the
limitations of the current works.
</summary>
    <author>
      <name>Hamid Bagheri</name>
    </author>
    <author>
      <name>Md Johirul Islam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1711.10377v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1711.10377v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.00004v1</id>
    <updated>2018-07-31T14:16:54Z</updated>
    <published>2018-07-31T14:16:54Z</published>
    <title>Graph-Based Recommendation System</title>
    <summary>  In this work, we study recommendation systems modelled as contextual
multi-armed bandit (MAB) problems. We propose a graph-based recommendation
system that learns and exploits the geometry of the user space to create
meaningful clusters in the user domain. This reduces the dimensionality of the
recommendation problem while preserving the accuracy of MAB. We then study the
effect of graph sparsity and clusters size on the MAB performance and provide
exhaustive simulation results both in synthetic and in real-case datasets.
Simulation results show improvements with respect to state-of-the-art MAB
algorithms.
</summary>
    <author>
      <name>Kaige Yang</name>
    </author>
    <author>
      <name>Laura Toni</name>
    </author>
    <link href="http://arxiv.org/abs/1808.00004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.00004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.03835v1</id>
    <updated>2018-08-11T16:47:58Z</updated>
    <published>2018-08-11T16:47:58Z</published>
    <title>jLDADMM: A Java package for the LDA and DMM topic models</title>
    <summary>  In this technical report, we present jLDADMM---an easy-to-use Java toolkit
for conventional topic models. jLDADMM is released to provide alternatives for
topic modeling on normal or short texts. It provides implementations of the
Latent Dirichlet Allocation topic model and the one-topic-per-document
Dirichlet Multinomial Mixture model (i.e. mixture of unigrams), using collapsed
Gibbs sampling. In addition, jLDADMM supplies a document clustering evaluation
to compare topic models. jLDADMM is open-source and available to download at:
https://github.com/datquocnguyen/jLDADMM
</summary>
    <author>
      <name>Dat Quoc Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1808.03835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.03835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.06012v1</id>
    <updated>2018-08-17T22:11:54Z</updated>
    <published>2018-08-17T22:11:54Z</published>
    <title>Heuristics for publishing dynamic content as structured data with
  schema.org</title>
    <summary>  Publishing fast changing dynamic data as open data on the web in a scalable
manner is not trivial. So far the only approaches describe publishing as much
data as possible, which then leads to problems, like server capacity overload,
network latency or unwanted knowledge disclosure. With this paper we show ways
how to publish dynamic data in a scalable, meaningful manner by applying
context-dependent publication heuristics. The outcome shows that the
application of the right publication heuristics in the right domain can improve
the publication performance significantly. Good knowledge about the domain help
choosing the right publication heuristic and hence lead to very good
publication results.
</summary>
    <author>
      <name>Elias Kärle</name>
    </author>
    <author>
      <name>Dieter Fensel</name>
    </author>
    <link href="http://arxiv.org/abs/1808.06012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.06012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.06414v2</id>
    <updated>2018-08-25T07:25:24Z</updated>
    <published>2018-08-20T12:21:23Z</published>
    <title>Next Item Recommendation with Self-Attention</title>
    <summary>  In this paper, we propose a novel sequence-aware recommendation model. Our
model utilizes self-attention mechanism to infer the item-item relationship
from user's historical interactions. With self-attention, it is able to
estimate the relative weights of each item in user interaction trajectories to
learn better representations for user's transient interests. The model is
finally trained in a metric learning framework, taking both short-term and
long-term intentions into consideration. Experiments on a wide range of
datasets on different domains demonstrate that our approach outperforms the
state-of-the-art by a wide margin.
</summary>
    <author>
      <name>Shuai Zhang</name>
    </author>
    <author>
      <name>Yi Tay</name>
    </author>
    <author>
      <name>Lina Yao</name>
    </author>
    <author>
      <name>Aixin Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.06414v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.06414v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.07025v1</id>
    <updated>2018-08-21T17:22:37Z</updated>
    <published>2018-08-21T17:22:37Z</published>
    <title>Who is Really Affected by Fraudulent Reviews? An analysis of shilling
  attacks on recommender systems in real-world scenarios</title>
    <summary>  We present the results of an initial analysis conducted on a real-life
setting to quantify the effect of shilling attacks on recommender systems. We
focus on both algorithm performance as well as the types of users who are most
affected by these attacks.
</summary>
    <author>
      <name>Anu Shrestha</name>
    </author>
    <author>
      <name>Francesca Spezzano</name>
    </author>
    <author>
      <name>Maria Soledad Pera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Late-Breaking Results track part of the Twelfth
  ACM Conference on Recommender Systems (RecSys'18)</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.07025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.07025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.07089v1</id>
    <updated>2018-08-21T19:14:16Z</updated>
    <published>2018-08-21T19:14:16Z</published>
    <title>CoBaR: Confidence-Based Recommender</title>
    <summary>  Neighborhood-based collaborative filtering algorithms usually adopt a fixed
neighborhood size for every user or item, although groups of users or items may
have different lengths depending on users' preferences. In this paper, we
propose an extension to a non-personalized recommender based on confidence
intervals and hierarchical clustering to generate groups of users with optimal
sizes. The evaluation shows that the proposed technique outperformed the
traditional recommender algorithms in four publicly available datasets.
</summary>
    <author>
      <name>Fernando S. Aguiar Neto</name>
    </author>
    <author>
      <name>Arthur F. da Costa</name>
    </author>
    <author>
      <name>Marcelo G. Manzato</name>
    </author>
    <link href="http://arxiv.org/abs/1808.07089v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.07089v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.08274v1</id>
    <updated>2018-08-24T19:27:31Z</updated>
    <published>2018-08-24T19:27:31Z</published>
    <title>Can we leverage rating patterns from traditional users to enhance
  recommendations for children?</title>
    <summary>  Recommender algorithms performance is often associated with the availability
of sufficient historical rating data. Unfortunately, when it comes to children,
this data is seldom available. In this paper, we report on an initial analysis
conducted to examine the degree to which data about traditional users, i.e.,
adults, can be leveraged to enhance the recommendation process for children.
</summary>
    <author>
      <name>Ion Madrazo Azpiazu</name>
    </author>
    <author>
      <name>Michael Green</name>
    </author>
    <author>
      <name>Oghenemaro Anuyah</name>
    </author>
    <author>
      <name>Maria Soledad Pera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM RecSys 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.08274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.08274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.08643v1</id>
    <updated>2018-08-26T23:31:02Z</updated>
    <published>2018-08-26T23:31:02Z</published>
    <title>Scientific Relation Extraction with Selectively Incorporated Concept
  Embeddings</title>
    <summary>  This paper describes our submission for the SemEval 2018 Task 7 shared task
on semantic relation extraction and classification in scientific papers. We
extend the end-to-end relation extraction model of (Miwa and Bansal) with
enhancements such as a character-level encoding attention mechanism on
selecting pretrained concept candidate embeddings. Our official submission
ranked the second in relation classification task (Subtask 1.1 and Subtask 2
Senerio 2), and the first in the relation extraction task (Subtask 2 Scenario
1).
</summary>
    <author>
      <name>Yi Luan</name>
    </author>
    <author>
      <name>Mari Ostendorf</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <link href="http://arxiv.org/abs/1808.08643v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.08643v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.10260v1</id>
    <updated>2018-08-29T11:04:07Z</updated>
    <published>2018-08-29T11:04:07Z</published>
    <title>Understanding Latent Factors Using a GWAP</title>
    <summary>  Recommender systems relying on latent factor models often appear as black
boxes to their users. Semantic descriptions for the factors might help to
mitigate this problem. Achieving this automatically is, however, a
non-straightforward task due to the models' statistical nature. We present an
output-agreement game that represents factors by means of sample items and
motivates players to create such descriptions. A user study shows that the
collected output actually reflects real-world characteristics of the factors.
</summary>
    <author>
      <name>Johannes Kunkel</name>
    </author>
    <author>
      <name>Benedikt Loepp</name>
    </author>
    <author>
      <name>Jürgen Ziegler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Late-Breaking Results track part of the Twelfth
  ACM Conference on Recommender Systems (RecSys '18), Vancouver, BC, Canada,
  October 2-7, 2018, 2 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1808.10260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.10260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.08747v1</id>
    <updated>2018-10-20T03:35:48Z</updated>
    <published>2018-10-20T03:35:48Z</published>
    <title>Temporal Proximity induces Attributes Similarity</title>
    <summary>  Users consume their favorite content in temporal proximity of consumption
bundles according to their preferences and tastes. Thus, the underlying
attributes of items implicitly match user preferences, however, current
recommender systems largely ignore this fundamental driver in identifying
matching items. In this work, we introduce a novel temporal proximity filtering
method to enable items-matching. First, we demonstrate that proximity
preferences exist. Second, we present an induced similarity metric in temporal
proximity driven by user tastes and third, we show that this induced similarity
can be used to learn items pairwise similarity in attribute space. The proposed
model does not rely on any knowledge outside users' consumption bundles and
provide a novel way to devise user preferences and tastes driven novel items
recommender.
</summary>
    <author>
      <name>Arun Kumar</name>
    </author>
    <author>
      <name>Karan Aggarwal</name>
    </author>
    <author>
      <name>Paul Schrater</name>
    </author>
    <link href="http://arxiv.org/abs/1810.08747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.08747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.10038v1</id>
    <updated>2018-10-23T18:35:38Z</updated>
    <published>2018-10-23T18:35:38Z</published>
    <title>A new approach of contextual recommendation based on the method of
  Hierarchical Analysis of Processes</title>
    <summary>  Recommender systems are able to estimate the user's interest for resource
given from some relative information to others similar users and to propriety
of the resource. In this Memory, we introduced a new contextual recommendation
approach based on the AHP Process Hierarchical Analysis method. This work
consisted in making a bibliographic study on the works having proposed systems
of recommendation based on the context of the users in the field of films. The
goal is to design and develop a new approach to recommending movies based on
user context. And we relied on methods of multi-criteria decision making (MCDM)
and more precisely the method of Hierarchical Process Analysis (AHP) for
context integration in the recommendation process.
</summary>
    <author>
      <name>Halima Nefzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master's thesis. in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.10038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.10038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.12085v1</id>
    <updated>2018-10-26T16:36:27Z</updated>
    <published>2018-10-26T16:36:27Z</published>
    <title>Extractive Summarization of EHR Discharge Notes</title>
    <summary>  Patient summarization is essential for clinicians to provide coordinated care
and practice effective communication. Automated summarization has the potential
to save time, standardize notes, aid clinical decision making, and reduce
medical errors. Here we provide an upper bound on extractive summarization of
discharge notes and develop an LSTM model to sequentially label topics of
history of present illness notes. We achieve an F1 score of 0.876, which
indicates that this model can be employed to create a dataset for evaluation of
extractive summarization methods.
</summary>
    <author>
      <name>Emily Alsentzer</name>
    </author>
    <author>
      <name>Anne Kim</name>
    </author>
    <link href="http://arxiv.org/abs/1810.12085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.12085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.00749v1</id>
    <updated>2019-09-02T14:55:07Z</updated>
    <published>2019-09-02T14:55:07Z</published>
    <title>Know2Look: Commonsense Knowledge for Visual Search</title>
    <summary>  With the rise in popularity of social media, images accompanied by contextual
text form a huge section of the web. However, search and retrieval of documents
are still largely dependent on solely textual cues. Although visual cues have
started to gain focus, the imperfection in object/scene detection do not lead
to significantly improved results. We hypothesize that the use of background
commonsense knowledge on query terms can significantly aid in retrieval of
documents with associated images. To this end we deploy three different
modalities - text, visual cues, and commonsense knowledge pertaining to the
query - as a recipe for efficient search and retrieval.
</summary>
    <author>
      <name>Sreyasi Nag Chowdhury</name>
    </author>
    <author>
      <name>Niket Tandon</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in AKBC 2016</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">5th Workshop on Automated Knowledge Base Construction (AKBC) 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.00749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.00749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01165v1</id>
    <updated>2019-09-03T13:29:48Z</updated>
    <published>2019-09-03T13:29:48Z</published>
    <title>Finding Salient Context based on Semantic Matching for Relevance Ranking</title>
    <summary>  In this paper, we propose a salient-context based semantic matching method to
improve relevance ranking in information retrieval. We first propose a new
notion of salient context and then define how to measure it. Then we show how
the most salient context can be located with a sliding window technique.
Finally, we use the semantic similarity between a query term and the most
salient context terms in a corpus of documents to rank those documents.
Experiments on various collections from TREC show the effectiveness of our
model compared to the state-of-the-art methods.
</summary>
    <author>
      <name>Yuanyuan Qi</name>
    </author>
    <author>
      <name>Jiayue Zhang</name>
    </author>
    <author>
      <name>Weiran Xu</name>
    </author>
    <author>
      <name>Jun Guo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE International Conference on Visual Communications and Image
  Processing (VCIP)</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.01165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01727v1</id>
    <updated>2019-08-31T07:56:58Z</updated>
    <published>2019-08-31T07:56:58Z</published>
    <title>Heterogeneous Collaborative Filtering</title>
    <summary>  Recommendation system is important to a content sharing/creating social
network. Collaborative filtering is a widely-adopted technology in conventional
recommenders, which is based on similarity between positively engaged content
items involving the same users. Conventional collaborative filtering (CCF)
suffers from cold start problem and narrow content diversity. We propose a new
recommendation approach, heterogeneous collaborative filtering (HCF) to tackle
these challenges at the root, while keeping the strength of collaborative
filtering. We present two implementation algorithms of HCF for content
recommendation and content dissemination. Experiment results demonstrate that
our approach improve the recommendation quality in a real world social network
for content creating and sharing.
</summary>
    <author>
      <name>Yifang Liu</name>
    </author>
    <author>
      <name>Zhentao Xu</name>
    </author>
    <author>
      <name>Cong Hui</name>
    </author>
    <author>
      <name>Yi Xuan</name>
    </author>
    <author>
      <name>Jessie Chen</name>
    </author>
    <author>
      <name>Yuanming Shan</name>
    </author>
    <link href="http://arxiv.org/abs/1909.01727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.01793v1</id>
    <updated>2019-09-01T11:29:37Z</updated>
    <published>2019-09-01T11:29:37Z</published>
    <title>Employ Multimodal Machine Learning for Content quality analysis</title>
    <summary>  The task of identifying high-quality content becomes increasingly important,
and it can improve overall reading time and CTR(click-through rate estimates).
Generalizes quality analysis only focused on single Modal,such as image or
text,but in today's mainstream media sites a lot of information is presented in
graphic form.In this paper we propose a MultiModal quality recognition approach
for the quality score. First we use two feature extractors,one for image and
another for the text. After that we use an Siamese Network with the rank loss
as the optimization objective.Compare with other approach,our approach get a
more accuracy result.
</summary>
    <author>
      <name>Eric Du</name>
    </author>
    <author>
      <name>Xiaoyong Li</name>
    </author>
    <link href="http://arxiv.org/abs/1909.01793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.01793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.02768v1</id>
    <updated>2019-09-06T08:42:58Z</updated>
    <published>2019-09-06T08:42:58Z</published>
    <title>Pairwise Learning to Rank by Neural Networks Revisited: Reconstruction,
  Theoretical Analysis and Practical Performance</title>
    <summary>  We present a pairwise learning to rank approach based on a neural net, called
DirectRanker, that generalizes the RankNet architecture. We show mathematically
that our model is reflexive, antisymmetric, and transitive allowing for
simplified training and improved performance. Experimental results on the LETOR
MSLR-WEB10K, MQ2007 and MQ2008 datasets show that our model outperforms
numerous state-of-the-art methods, while being inherently simpler in structure
and using a pairwise approach only.
</summary>
    <author>
      <name>Marius Köppel</name>
    </author>
    <author>
      <name>Alexander Segner</name>
    </author>
    <author>
      <name>Martin Wagener</name>
    </author>
    <author>
      <name>Lukas Pensel</name>
    </author>
    <author>
      <name>Andreas Karwath</name>
    </author>
    <author>
      <name>Stefan Kramer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.02768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.03653v1</id>
    <updated>2019-09-09T06:42:46Z</updated>
    <published>2019-09-09T06:42:46Z</published>
    <title>Open Data Chatbot</title>
    <summary>  Recently, chatbots received an increased attention from industry and diverse
research communities as a dialogue-based interface providing advanced
human-computer interactions. On the other hand, Open Data continues to be an
important trend and a potential enabler for government transparency and citizen
participation. This paper shows how these two paradigms can be combined to help
non-expert users find and discover open government datasets through dialogue.
</summary>
    <author>
      <name>Sophia Keyner</name>
    </author>
    <author>
      <name>Vadim Savenkov</name>
    </author>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Semantic Web - 16th International Conference, ESWC 2019,
  Portoroz, Slovenia, June 2-6, 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1909.03653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.03653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.04954v1</id>
    <updated>2019-09-11T10:07:59Z</updated>
    <published>2019-09-11T10:07:59Z</published>
    <title>Report on the 8th International Workshop on Bibliometric-enhanced
  Information Retrieval (BIR 2019)</title>
    <summary>  The Bibliometric-enhanced Information Retrieval workshop series (BIR) at ECIR
tackled issues related to academic search, at the crossroads between
Information Retrieval and Bibliometrics. BIR is a hot topic investigated by
both academia (e.g., ArnetMiner, CiteSeerx, DocEar) and the industry (e.g.,
Google Scholar, Microsoft Academic Search, Semantic Scholar). This report
presents the 8th iteration of the one-day BIR workshop held at ECIR 2019 in
Cologne, Germany.
</summary>
    <author>
      <name>Guillaume Cabanac</name>
    </author>
    <author>
      <name>Ingo Frommholz</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, report to appear in ACM SIGIR Forum</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.04954v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.04954v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06133v2</id>
    <updated>2019-09-16T09:57:55Z</updated>
    <published>2019-09-13T10:52:30Z</published>
    <title>Towards Sharing Task Environments to Support Reproducible Evaluations of
  Interactive Recommender Systems</title>
    <summary>  Beyond sharing datasets or simulations, we believe the Recommender Systems
(RS) community should share Task Environments. In this work, we propose a
high-level logical architecture that will help to reason about the core
components of a RS Task Environment, identify the differences between
Environments, datasets and simulations; and most importantly, understand what
needs to be shared about Environments to achieve reproducible experiments. The
work presents itself as valuable initial groundwork, open to discussion and
extensions.
</summary>
    <author>
      <name>Andrea Barraza-Urbina</name>
    </author>
    <author>
      <name>Mathieu d'Aquin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Included in the Offline Evaluation for Recommender Systems Workshop
  (REVEAL'19), collocated with ACM RecSys 2019. REVEAL'19, September 20th,
  2019, Copenhagen, Denmark</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06133v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06133v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06239v1</id>
    <updated>2019-09-13T14:05:04Z</updated>
    <published>2019-09-13T14:05:04Z</published>
    <title>Modelling Stopping Criteria for Search Results using Poisson Processes</title>
    <summary>  Text retrieval systems often return large sets of documents, particularly
when applied to large collections. Stopping criteria can reduce the number of
these documents that need to be manually evaluated for relevance by predicting
when a suitable level of recall has been achieved. In this work, a novel method
for determining a stopping criterion is proposed that models the rate at which
relevant documents occur using a Poisson process. This method allows a user to
specify both a minimum desired level of recall to achieve and a desired
probability of having achieved it. We evaluate our method on a public dataset
and compare it with previous techniques for determining stopping criteria.
</summary>
    <author>
      <name>Alison Sneyd</name>
    </author>
    <author>
      <name>Mark Stevenson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06362v1</id>
    <updated>2019-09-13T03:23:02Z</updated>
    <published>2019-09-13T03:23:02Z</published>
    <title>Crank up the volume: preference bias amplification in collaborative
  recommendation</title>
    <summary>  Recommender systems are personalized: we expect the results given to a
particular user to reflect that user's preferences. Some researchers have
studied the notion of calibration, how well recommendations match users' stated
preferences, and bias disparity the extent to which mis-calibration affects
different user groups. In this paper, we examine bias disparity over a range of
different algorithms and for different item categories and demonstrate
significant differences between model-based and memory-based algorithms.
</summary>
    <author>
      <name>Kun Lin</name>
    </author>
    <author>
      <name>Nasim Sonboli</name>
    </author>
    <author>
      <name>Bamshad Mobasher</name>
    </author>
    <author>
      <name>Robin Burke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the RMSE workshop held in conjunction with the 13th ACM
  Conference on Recommender Systems (RecSys), 2019, in Copenhagen, Denmark</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.06722v1</id>
    <updated>2019-09-15T03:23:49Z</updated>
    <published>2019-09-15T03:23:49Z</published>
    <title>Plackett-Luce model for learning-to-rank task</title>
    <summary>  List-wise based learning to rank methods are generally supposed to have
better performance than point- and pair-wise based. However, in real-world
applications, state-of-the-art systems are not from list-wise based camp. In
this paper, we propose a new non-linear algorithm in the list-wise based
framework called ListMLE, which uses the Plackett-Luce (PL) loss. Our
experiments are conducted on the two largest publicly available real-world
datasets, Yahoo challenge 2010 and Microsoft 30K. This is the first time in the
single model level for a list-wise based system to match or overpass
state-of-the-art systems in real-world datasets.
</summary>
    <author>
      <name>Tian Xia</name>
    </author>
    <author>
      <name>Shaodan Zhai</name>
    </author>
    <author>
      <name>Shaojun Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1909.06722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12749v1</id>
    <updated>2019-09-16T03:59:47Z</updated>
    <published>2019-09-16T03:59:47Z</published>
    <title>Movie Recommender Systems: Implementation and Performance Evaluation</title>
    <summary>  Over the years, explosive growth in the number of items in the catalog of
e-commerce businesses, such as Amazon, Netflix, Pandora, etc., have warranted
the development of recommender systems to guide consumers towards their desired
products based on their preferences and tastes. Some of the popular approaches
for building recommender systems, for mining user, derived input datasets, are:
content-based systems, collaborative filtering, latent-factor systems using
Singular Value Decomposition (SVD), and Restricted Boltzmann Machines (RBM). In
this project, user-user collaborative filtering, item-item collaborative
filtering, content-based recommendation, SVD, and neural networks were chosen
for implementation in Python to predict the user ratings of unwatched movies
for each user, and their performances were evaluated and compared.
</summary>
    <author>
      <name>Mojdeh Saadati</name>
    </author>
    <author>
      <name>Syed Shihab</name>
    </author>
    <author>
      <name>Mohammed Shaiqur Rahman</name>
    </author>
    <link href="http://arxiv.org/abs/1909.12749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1909.12799v1</id>
    <updated>2019-09-12T09:36:31Z</updated>
    <published>2019-09-12T09:36:31Z</published>
    <title>How robust is MovieLens? A dataset analysis for recommender systems</title>
    <summary>  Research publication requires public datasets. In recommender systems, some
datasets are largely used to compare algorithms against a --supposedly-- common
benchmark. Problem: for various reasons, these datasets are heavily
preprocessed, making the comparison of results across papers difficult. This
paper makes explicit the variety of preprocessing and evaluation protocols to
test the robustness of a dataset (or lack of flexibility). While robustness is
good to compare results across papers, for flexible datasets we propose a
method to select a preprocessing protocol and share results more transparently.
</summary>
    <author>
      <name>Anne-Marie Tousch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages ; accepted at REVEAL workshop, RecSys 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.12799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.12799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.02633v1</id>
    <updated>2020-06-04T03:52:59Z</updated>
    <published>2020-06-04T03:52:59Z</published>
    <title>Stopwords in Technical Language Processing</title>
    <summary>  There are increasingly applications of natural language processing techniques
for information retrieval, indexing and topic modelling in the engineering
contexts. A standard component of such tasks is the removal of stopwords, which
are uninformative components of the data. While researchers use readily
available stopword lists which are derived for general English language, the
technical jargon of engineering fields contains their own highly frequent and
uninformative words and there exists no standard stopword list for technical
language processing applications. Here we address this gap by rigorously
identifying generic, insignificant, uninformative stopwords in engineering
texts beyond the stopwords in general texts, based on the synthesis of
alternative data-driven approaches, and curating a stopword list ready for
technical language processing applications.
</summary>
    <author>
      <name>Serhad Sarica</name>
    </author>
    <author>
      <name>Jianxi Luo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0254937</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0254937" rel="related"/>
    <link href="http://arxiv.org/abs/2006.02633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.02633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.03292v1</id>
    <updated>2020-06-05T08:21:26Z</updated>
    <published>2020-06-05T08:21:26Z</published>
    <title>SEAL: Scientific Keyphrase Extraction and Classification</title>
    <summary>  Automatic scientific keyphrase extraction is a challenging problem
facilitating several downstream scholarly tasks like search, recommendation,
and ranking. In this paper, we introduce SEAL, a scholarly tool for automatic
keyphrase extraction and classification. The keyphrase extraction module
comprises two-stage neural architecture composed of Bidirectional Long
Short-Term Memory cells augmented with Conditional Random Fields. The
classification module comprises of a Random Forest classifier. We extensively
experiment to showcase the robustness of the system. We evaluate multiple
state-of-the-art baselines and show a significant improvement. The current
system is hosted at http://lingo.iitgn.ac.in:5000/.
</summary>
    <author>
      <name>Ayush Garg</name>
    </author>
    <author>
      <name>Sammed Shantinath Kagi</name>
    </author>
    <author>
      <name>Mayank Singh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3383583.3398625</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3383583.3398625" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at JCDL 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.03292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.03292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.11821v2</id>
    <updated>2020-08-29T19:38:22Z</updated>
    <published>2020-06-21T15:12:27Z</published>
    <title>An Improved Relevance Feedback in CBIR</title>
    <summary>  Relevance Feedback in Content-Based Image Retrieval is a method where the
feedback of the performance is being used to improve itself. Prior works use
feature re-weighting and classification techniques as the Relevance Feedback
methods. This paper shows a novel addition to the prior methods to further
improve the retrieval accuracy. In addition to all of these, the paper also
shows a novel idea to even improve the 0-th iteration retrieval accuracy from
the information of Relevance Feedback.
</summary>
    <author>
      <name>Subhadip Maji</name>
    </author>
    <author>
      <name>Smarajit Bose</name>
    </author>
    <link href="http://arxiv.org/abs/2006.11821v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.11821v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.12382v1</id>
    <updated>2020-06-17T17:08:52Z</updated>
    <published>2020-06-17T17:08:52Z</published>
    <title>Quick Lists: Enriched Playlist Embeddings for Future Playlist
  Recommendation</title>
    <summary>  Recommending playlists to users in the context of a digital music service is
a difficult task because a playlist is often more than the mere sum of its
parts. We present a novel method for generating playlist embeddings that are
invariant to playlist length and sensitive to local and global track ordering.
The embeddings also capture information about playlist sequencing, and are
enriched with side information about the playlist user. We show that these
embeddings are useful for generating next-best playlist recommendations, and
that side information can be used for the cold start problem.
</summary>
    <author>
      <name>Brett Vintch</name>
    </author>
    <link href="http://arxiv.org/abs/2006.12382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.12382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2006.15498v2</id>
    <updated>2020-07-20T12:51:00Z</updated>
    <published>2020-06-28T03:46:32Z</published>
    <title>RepBERT: Contextualized Text Embeddings for First-Stage Retrieval</title>
    <summary>  Although exact term match between queries and documents is the dominant
method to perform first-stage retrieval, we propose a different approach,
called RepBERT, to represent documents and queries with fixed-length
contextualized embeddings. The inner products of query and document embeddings
are regarded as relevance scores. On MS MARCO Passage Ranking task, RepBERT
achieves state-of-the-art results among all initial retrieval techniques. And
its efficiency is comparable to bag-of-words methods.
</summary>
    <author>
      <name>Jingtao Zhan</name>
    </author>
    <author>
      <name>Jiaxin Mao</name>
    </author>
    <author>
      <name>Yiqun Liu</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <author>
      <name>Shaoping Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For corresponding code and data, see
  https://github.com/jingtaozhan/RepBERT-Index</arxiv:comment>
    <link href="http://arxiv.org/abs/2006.15498v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2006.15498v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00695v1</id>
    <updated>2017-06-02T14:20:34Z</updated>
    <published>2017-06-02T14:20:34Z</published>
    <title>Hashtag-centric Immersive Search on Social Media</title>
    <summary>  Social media information distributes in different Online Social Networks
(OSNs). This paper addresses the problem integrating the cross-OSN information
to facilitate an immersive social media search experience. We exploit hashtag,
which is widely used to annotate and organize multi-modal items in different
OSNs, as the bridge for information aggregation and organization. A three-stage
solution framework is proposed for hashtag representation, clustering and
demonstration. Given an event query, the related items from three OSNs,
Twitter, Flickr and YouTube, are organized in cluster-hashtag-item hierarchy
for display. The effectiveness of the proposed solution is validated by
qualitative and quantitative experiments on hundreds of trending event queries.
</summary>
    <author>
      <name>Yuqi Gao</name>
    </author>
    <author>
      <name>Jitao Sang</name>
    </author>
    <author>
      <name>Tongwei Ren</name>
    </author>
    <author>
      <name>Changsheng Xu</name>
    </author>
    <link href="http://arxiv.org/abs/1706.00695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02061v1</id>
    <updated>2017-06-07T06:57:25Z</updated>
    <published>2017-06-07T06:57:25Z</published>
    <title>An Extended Relevance Model for Session Search</title>
    <summary>  The session search task aims at best serving the user's information need
given her previous search behavior during the session. We propose an extended
relevance model that captures the user's dynamic information need in the
session. Our relevance modelling approach is directly driven by the user's
query reformulation (change) decisions and the estimate of how much the user's
search behavior affects such decisions. Overall, we demonstrate that, the
proposed approach significantly boosts session search performance.
</summary>
    <author>
      <name>Nir Levine</name>
    </author>
    <author>
      <name>Haggai Roitman</name>
    </author>
    <author>
      <name>Doron Cohen</name>
    </author>
    <link href="http://arxiv.org/abs/1706.02061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03266v1</id>
    <updated>2017-06-10T18:29:19Z</updated>
    <published>2017-06-10T18:29:19Z</published>
    <title>An Empirical Study of Some Selected IR Models for Bengali Monolingual
  Information Retrieval</title>
    <summary>  This paper presents an evaluation and an analysis of some selected
information retrieval models for Bengali monolingual information retrieval
task. Two models, TF-IDF model and the Okapi BM25 model have been considered
for our study. The developed IR models are tested on FIRE ad hoc retrieval data
sets released for different years from 2008 to 2012 and the obtained results
have been reported in this paper.
</summary>
    <author>
      <name>Kamal Sarkar</name>
    </author>
    <author>
      <name>Avisek Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, In Proceedings of ICBIM 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07479v2</id>
    <updated>2017-09-02T11:13:43Z</updated>
    <published>2017-06-22T20:20:34Z</published>
    <title>Binary Latent Representations for Efficient Ranking: Empirical
  Assessment</title>
    <summary>  Large-scale recommender systems often face severe latency and storage
constraints at prediction time. These are particularly acute when the number of
items that could be recommended is large, and calculating predictions for the
full set is computationally intensive. In an attempt to relax these
constraints, we train recommendation models that use binary rather than
real-valued user and item representations, and show that while they are
substantially faster to evaluate, the gains in speed come at a large cost in
accuracy. In our Movielens 1M experiments, we show that reducing the latent
dimensionality of traditional models offers a more attractive accuracy/speed
trade-off than using binary representations.
</summary>
    <author>
      <name>Maciej Kula</name>
    </author>
    <link href="http://arxiv.org/abs/1706.07479v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07479v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08746v2</id>
    <updated>2017-07-24T16:03:03Z</updated>
    <published>2017-06-27T09:23:37Z</published>
    <title>DE-PACRR: Exploring Layers Inside the PACRR Model</title>
    <summary>  Recent neural IR models have demonstrated deep learning's utility in ad-hoc
information retrieval. However, deep models have a reputation for being black
boxes, and the roles of a neural IR model's components may not be obvious at
first glance. In this work, we attempt to shed light on the inner workings of a
recently proposed neural IR model, namely the PACRR model, by visualizing the
output of intermediate layers and by investigating the relationship between
intermediate weights and the ultimate relevance score produced. We highlight
several insights, hoping that such insights will be generally applicable.
</summary>
    <author>
      <name>Andrew Yates</name>
    </author>
    <author>
      <name>Kai Hui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Neu-IR 2017 SIGIR Workshop on Neural Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08746v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08746v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09200v1</id>
    <updated>2017-06-28T10:12:01Z</updated>
    <published>2017-06-28T10:12:01Z</published>
    <title>Energy-Based Sequence GANs for Recommendation and Their Connection to
  Imitation Learning</title>
    <summary>  Recommender systems aim to find an accurate and efficient mapping from
historic data of user-preferred items to a new item that is to be liked by a
user. Towards this goal, energy-based sequence generative adversarial nets
(EB-SeqGANs) are adopted for recommendation by learning a generative model for
the time series of user-preferred items. By recasting the energy function as
the feature function, the proposed EB-SeqGANs is interpreted as an instance of
maximum-entropy imitation learning.
</summary>
    <author>
      <name>Jaeyoon Yoo</name>
    </author>
    <author>
      <name>Heonseok Ha</name>
    </author>
    <author>
      <name>Jihun Yi</name>
    </author>
    <author>
      <name>Jongha Ryu</name>
    </author>
    <author>
      <name>Chanju Kim</name>
    </author>
    <author>
      <name>Jung-Woo Ha</name>
    </author>
    <author>
      <name>Young-Han Kim</name>
    </author>
    <author>
      <name>Sungroh Yoon</name>
    </author>
    <link href="http://arxiv.org/abs/1706.09200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01256v2</id>
    <updated>2017-11-22T03:36:40Z</updated>
    <published>2017-09-05T06:47:03Z</published>
    <title>Semantic Document Distance Measures and Unsupervised Document Revision
  Detection</title>
    <summary>  In this paper, we model the document revision detection problem as a minimum
cost branching problem that relies on computing document distances.
Furthermore, we propose two new document distance measures, word vector-based
Dynamic Time Warping (wDTW) and word vector-based Tree Edit Distance (wTED).
Our revision detection system is designed for a large scale corpus and
implemented in Apache Spark. We demonstrate that our system can more precisely
detect revisions than state-of-the-art methods by utilizing the Wikipedia
revision dumps https://snap.stanford.edu/data/wiki-meta.html and simulated data
sets.
</summary>
    <author>
      <name>Xiaofeng Zhu</name>
    </author>
    <author>
      <name>Diego Klabjan</name>
    </author>
    <author>
      <name>Patrick Bless</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCNLP 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.01256v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01256v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03260v1</id>
    <updated>2017-09-11T06:25:46Z</updated>
    <published>2017-09-11T06:25:46Z</published>
    <title>A Short Note on Proximity-based Scoring of Documents with Multiple
  Fields</title>
    <summary>  The BM25 ranking function is one of the most well known query relevance
document scoring functions and many variations of it are proposed. The BM25F
function is one of its adaptations designed for modeling documents with
multiple fields. The Expanded Span method extends a BM25-like function by
taking into considerations of the proximity between term occurrences. In this
note, we combine these two variations into one scoring method in view of
proximity-based scoring of documents with multiple fields.
</summary>
    <author>
      <name>Tomohiro Manabe</name>
    </author>
    <author>
      <name>Sumio Fujita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.03260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07654v2</id>
    <updated>2018-02-01T15:45:17Z</updated>
    <published>2017-09-22T09:39:08Z</published>
    <title>Annotation based automatic action processing</title>
    <summary>  With a strong motivational background in search engine optimization the
amount of structured data on the web is growing rapidly. The main search engine
providers are promising great increase in visibility through annotation of the
web page's content with the vocabulary of schema.org and thus providing it as
structured data. But besides the usage by search engines the data can be used
in various other ways, for example for automatic processing of annotated web
services or actions. In this work we present an approach to consume and process
schema.org annotated data on the web and give an idea how a best practice can
look like.
</summary>
    <author>
      <name>Elias Kärle</name>
    </author>
    <author>
      <name>Dieter Fensel</name>
    </author>
    <link href="http://arxiv.org/abs/1709.07654v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07654v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.09836v1</id>
    <updated>2017-09-28T07:56:26Z</updated>
    <published>2017-09-28T07:56:26Z</published>
    <title>Towards a Semantic Search Engine for Scientific Articles</title>
    <summary>  Because of the data deluge in scientific publication, finding relevant
information is getting harder and harder for researchers and readers. Building
an enhanced scientific search engine by taking semantic relations into account
poses a great challenge. As a starting point, semantic relations between
keywords from scientific articles could be extracted in order to classify
articles. This might help later in the process of browsing and searching for
content in a meaningful scientific way. Indeed, by connecting keywords, the
context of the article can be extracted. This paper aims to provide ideas to
build such a smart search engine and describes the initial contributions
towards achieving such an ambitious goal.
</summary>
    <author>
      <name>Bastien Latard</name>
    </author>
    <author>
      <name>Jonathan Weber</name>
    </author>
    <author>
      <name>Germain Forestier</name>
    </author>
    <author>
      <name>Michel Hassenforder</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-67008-9_54</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-67008-9_54" rel="related"/>
    <link href="http://arxiv.org/abs/1709.09836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.09836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.03491v2</id>
    <updated>2019-01-15T05:09:48Z</updated>
    <published>2019-01-11T06:02:22Z</published>
    <title>Answer Interaction in Non-factoid Question Answering Systems</title>
    <summary>  Information retrieval systems are evolving from document retrieval to answer
retrieval. Web search logs provide large amounts of data about how people
interact with ranked lists of documents, but very little is known about
interaction with answer texts. In this paper, we use Amazon Mechanical Turk to
investigate three answer presentation and interaction approaches in a
non-factoid question answering setting. We find that people perceive and react
to good and bad answers very differently, and can identify good answers
relatively quickly. Our results provide the basis for further investigation of
effective answer interaction and feedback methods.
</summary>
    <author>
      <name>Chen Qu</name>
    </author>
    <author>
      <name>Liu Yang</name>
    </author>
    <author>
      <name>Bruce Croft</name>
    </author>
    <author>
      <name>Falk Scholer</name>
    </author>
    <author>
      <name>Yongfeng Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3295750.3298946</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3295750.3298946" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to CHIIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.03491v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.03491v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.04216v1</id>
    <updated>2019-01-14T10:05:52Z</updated>
    <published>2019-01-14T10:05:52Z</published>
    <title>Albanian Language Identification in Text Documents</title>
    <summary>  In this work we investigate the accuracy of standard and state-of-the-art
language identification methods in identifying Albanian in written text
documents. A dataset consisting of news articles written in Albanian has been
constructed for this purpose. We noticed a considerable decrease of accuracy
when using test documents that miss the Albanian alphabet letters " \"E " and "
\c{C} " and created a custom training corpus that solved this problem by
achieving an accuracy of more than 99%. Based on our experiments, the most
performing language identification methods for Albanian use a na\"ive Bayes
classifier and n-gram based classification features.
</summary>
    <author>
      <name>Klesti Hoxha</name>
    </author>
    <author>
      <name>Artur Baxhaku</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Buletini i Shkencave te Natyres, Vol. 23, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1901.04216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.04216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.07773v1</id>
    <updated>2019-01-23T08:43:50Z</updated>
    <published>2019-01-23T08:43:50Z</published>
    <title>Boosting Frequent Itemset Mining via Early Stopping Intersections</title>
    <summary>  Mining frequent itemsets from a transaction database has emerged as a
fundamental problem in data mining and committed itself as a building block for
many pattern mining tasks. In this paper, we present a general technique to
reduce support checking time in existing depth-first search generate-and-test
schemes such as Eclat/dEclat and PrePost+. Our technique allows infrequent
candidate itemsets to be detected early. The technique is based on an
early-stopping criterion and is general enough to be applicable in many
frequent itemset mining algorithms. We have applied the technique to two
TID-list based schemes (Eclat/dEclat) and one N-list based scheme (PrePost+).
Our technique has been tested over a variety of datasets and confirmed its
effectiveness in runtime reduction.
</summary>
    <author>
      <name>Huu Hiep Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1901.07773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.07773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10133v1</id>
    <updated>2019-01-29T06:53:21Z</updated>
    <published>2019-01-29T06:53:21Z</published>
    <title>Structuring an unordered text document</title>
    <summary>  Segmenting an unordered text document into different sections is a very
useful task in many text processing applications like multiple document
summarization, question answering, etc. This paper proposes structuring of an
unordered text document based on the keywords in the document. We test our
approach on Wikipedia documents using both statistical and predictive methods
such as the TextRank algorithm and Google's USE (Universal Sentence Encoder).
From our experimental results, we show that the proposed model can effectively
structure an unordered document into sections.
</summary>
    <author>
      <name>Shashank Yadav</name>
    </author>
    <author>
      <name>Tejas Shimpi</name>
    </author>
    <author>
      <name>C. Ravindranath Chowdary</name>
    </author>
    <author>
      <name>Prashant Sharma</name>
    </author>
    <author>
      <name>Deepansh Agrawal</name>
    </author>
    <author>
      <name>Shivang Agarwal</name>
    </author>
    <link href="http://arxiv.org/abs/1901.10133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1901.10496v1</id>
    <updated>2019-01-29T19:00:21Z</updated>
    <published>2019-01-29T19:00:21Z</published>
    <title>Impact of Training Dataset Size on Neural Answer Selection Models</title>
    <summary>  It is held as a truism that deep neural networks require large datasets to
train effective models. However, large datasets, especially with high-quality
labels, can be expensive to obtain. This study sets out to investigate (i) how
large a dataset must be to train well-performing models, and (ii) what impact
can be shown from fractional changes to the dataset size. A practical method to
investigate these questions is to train a collection of deep neural answer
selection models using fractional subsets of varying sizes of an initial
dataset. We observe that dataset size has a conspicuous lack of effect on the
training of some of these models, bringing the underlying algorithms into
question.
</summary>
    <author>
      <name>Trond Linjordet</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1901.10496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1901.10496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.02989v1</id>
    <updated>2019-11-08T02:19:52Z</updated>
    <published>2019-11-08T02:19:52Z</published>
    <title>Cross-Lingual Relevance Transfer for Document Retrieval</title>
    <summary>  Recent work has shown the surprising ability of multi-lingual BERT to serve
as a zero-shot cross-lingual transfer model for a number of language processing
tasks. We combine this finding with a similarly-recently proposal on
sentence-level relevance modeling for document retrieval to demonstrate the
ability of multi-lingual BERT to transfer models of relevance across languages.
Experiments on test collections in five different languages from diverse
language families (Chinese, Arabic, French, Hindi, and Bengali) show that
models trained with English data improve ranking quality, without any special
processing, both for (non-English) mono-lingual retrieval as well as
cross-lingual retrieval.
</summary>
    <author>
      <name>Peng Shi</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07200v1</id>
    <updated>2019-11-17T09:41:30Z</updated>
    <published>2019-11-17T09:41:30Z</published>
    <title>Common Artist Music Assistance</title>
    <summary>  In today's world of growing number of songs, the need of finding apposite
music content according to a user's interest is crucial. Furthermore,
recommendations suitable to one user may be irrelevant to another. In this
paper, we propose a recommendation system for users with common-artist music
listening patterns. We use "random walk with restart" algorithm to get relevant
recommendations and conduct experiments to find the optimal values of multiple
parameters.
</summary>
    <author>
      <name>Manish Agnihotri</name>
    </author>
    <author>
      <name>Adiyta Rathod</name>
    </author>
    <author>
      <name>Aditya Jajodia</name>
    </author>
    <author>
      <name>Chethan Sharma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 11 figures, ICCSE 2018 Malaysia</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.07317v1</id>
    <updated>2019-11-17T19:05:46Z</updated>
    <published>2019-11-17T19:05:46Z</published>
    <title>Quels corpus d'entraînement pour l'expansion de requêtes par
  plongement de mots : application à la recherche de microblogs culturels</title>
    <summary>  We describe here an experimental framework and the results obtained on
microblogs retrieval. We study the contribution one popular approach, i.e.,
words embeddings, and investigate the impact of the training set on the learned
embedding. We focus on query expansion for the retrieval of tweets on the CLEF
CMC 2016 corpus. Our results show that using embeddings trained on a corpus in
the same domain as the indexed documents did not necessarily lead to better
retrieval results.
</summary>
    <author>
      <name>Philippe Mulhem</name>
    </author>
    <author>
      <name>Lorraine Goeuriot</name>
    </author>
    <author>
      <name>Massih-Reza Amini</name>
    </author>
    <author>
      <name>Nayanika Dogra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages. in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1911.11061v2</id>
    <updated>2019-11-26T03:07:01Z</updated>
    <published>2019-11-20T00:55:30Z</published>
    <title>A Coefficient of Determination for Probabilistic Topic Models</title>
    <summary>  This research proposes a new (old) metric for evaluating goodness of fit in
topic models, the coefficient of determination, or $R^2$. Within the context of
topic modeling, $R^2$ has the same interpretation that it does when used in a
broader class of statistical models. Reporting $R^2$ with topic models
addresses two current problems in topic modeling: a lack of standard
cross-contextual evaluation metrics for topic modeling and ease of
communication with lay audiences. The author proposes that $R^2$ should be
reported as a standard metric when constructing topic models.
</summary>
    <author>
      <name>Tommy Jones</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11061v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11061v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2886v1</id>
    <updated>2011-03-15T11:48:30Z</updated>
    <published>2011-03-15T11:48:30Z</published>
    <title>Predicting User Preferences</title>
    <summary>  The many metrics employed for the evaluation of search engine results have
not themselves been conclusively evaluated. We propose a new measure for a
metric's ability to identify user preference of result lists. Using this
measure, we evaluate the metrics Discounted Cumulated Gain, Mean Average
Precision and classical precision, finding that the former performs best. We
also show that considering more results for a given query can impair rather
than improve a metric's ability to predict user preferences.
</summary>
    <author>
      <name>Pavel Sirotkin</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information und Wissen: global, sozial und frei? Proceedings des
  12. Internationalen Symposiums f\"ur Informationswissenschaft. Joachim
  Griesbaum, Thomas Mandl, Christa Womser-Hacker (Editors). VWH, Boizenburg,
  2011. Pages 24-35</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.2886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4362v1</id>
    <updated>2014-03-18T07:18:39Z</updated>
    <published>2014-03-18T07:18:39Z</published>
    <title>Concept Based vs. Pseudo Relevance Feedback Performance Evaluation for
  Information Retrieval System</title>
    <summary>  This article evaluates the performance of two techniques for query
reformulation in a system for information retrieval, namely, the concept based
and the pseudo relevance feedback reformulation. The experiments performed on a
corpus of Arabic text have allowed us to compare the contribution of these two
reformulation techniques in improving the performance of an information
retrieval system for Arabic texts.
</summary>
    <author>
      <name>Mohammed El Amine Abderrahim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1306.3955 by
  other authors</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computational Linguistics Research, ISSN:
  0976-416X, Volume 4, Issue 4, December, 2013, Pages 149-158</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.4362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7162v1</id>
    <updated>2014-03-27T18:36:15Z</updated>
    <published>2014-03-27T18:36:15Z</published>
    <title>Information Retrieval (IR) through Semantic Web (SW): An Overview</title>
    <summary>  A large amount of data is present on the web. It contains huge number of web
pages and to find suitable information from them is very cumbersome task. There
is need to organize data in formal manner so that user can easily access and
use them. To retrieve information from documents, we have many Information
Retrieval (IR) techniques. Current IR techniques are not so advanced that they
can be able to exploit semantic knowledge within documents and give precise
results. IR technology is major factor responsible for handling annotations in
Semantic Web (SW) languages and in the present paper knowledgeable
representation languages used for retrieving information are discussed.
</summary>
    <author>
      <name>Gagandeep Singh</name>
    </author>
    <author>
      <name>Vishal Jain</name>
    </author>
    <link href="http://arxiv.org/abs/1403.7162v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7162v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1220v1</id>
    <updated>2014-11-05T10:42:29Z</updated>
    <published>2014-11-05T10:42:29Z</published>
    <title>Faster Exact Search using Document Clustering</title>
    <summary>  We show how full-text search based on inverted indices can be accelerated by
clustering the documents without losing results (SeCluD -- SEarch with
CLUstered Documents). We develop a fast multilevel clustering algorithm that
explicitly uses query cost for conjunctive queries as an objective function.
Depending on the inputs we get up to four times faster than non-clustered
search. The resulting clusters are also useful for data compression and for
distributing the work over many machines.
</summary>
    <author>
      <name>Jonathan Dimond</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <link href="http://arxiv.org/abs/1411.1220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1635v1</id>
    <updated>2014-11-06T15:26:37Z</updated>
    <published>2014-11-06T15:26:37Z</published>
    <title>Scientometrics and Information Retrieval - weak-links revitalized</title>
    <summary>  This special issue brings together eight papers from experts of communities
which often have been perceived as different once: bibliometrics,
scientometrics and informetrics on the one side and information retrieval on
the other. The idea of this special issue started at the workshop "Combining
Bibliometrics and Information Retrieval" held at the 14th International
Conference of Scientometrics and Informetrics, Vienna, July 14-19, 2013. Our
motivation as guest editors started from the observation that main discourses
in both fields are different, that communities are only partly overlapping and
from the belief that a knowledge transfer would be profitable for both sides.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Andrea Scharnhorst</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11192-014-1484-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11192-014-1484-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, editorial for a special issue to appear in
  Scientometrics</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3650v1</id>
    <updated>2014-11-13T18:27:10Z</updated>
    <published>2014-11-13T18:27:10Z</published>
    <title>DUM: Diversity-Weighted Utility Maximization for Recommendations</title>
    <summary>  The need for diversification of recommendation lists manifests in a number of
recommender systems use cases. However, an increase in diversity may undermine
the utility of the recommendations, as relevant items in the list may be
replaced by more diverse ones. In this work we propose a novel method for
maximizing the utility of the recommended items subject to the diversity of
user's tastes, and show that an optimal solution to this problem can be found
greedily. We evaluate the proposed method in two online user studies as well as
in an offline analysis incorporating a number of evaluation metrics. The
results of evaluations show the superiority of our method over a number of
baselines.
</summary>
    <author>
      <name>Azin Ashkan</name>
    </author>
    <author>
      <name>Branislav Kveton</name>
    </author>
    <author>
      <name>Shlomo Berkovsky</name>
    </author>
    <author>
      <name>Zheng Wen</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3843v1</id>
    <updated>2014-11-14T09:43:24Z</updated>
    <published>2014-11-14T09:43:24Z</published>
    <title>Quantum emulation of query extension in information retrieval</title>
    <summary>  An operationalistic scheme, called Melucci metaphor, is suggested
representing Information Retrieval as physical measurements with beam of
particles playing the role of the flow of retrieved documents. The
possibilities of query expansion by extra term are studied from this
perspective, when the particles-`docuscles' are assumed to be of classical or
quantum nature. It is shown that in both cases the choice of an extra term
based on Bayesian belief revision is still valid on the qualitative level for
boosting the relevance of the retrieved documents.
</summary>
    <author>
      <name>Romàn Zapatrin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Latex, 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.3843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.8281v1</id>
    <updated>2014-12-29T08:45:59Z</updated>
    <published>2014-12-29T08:45:59Z</published>
    <title>Interactive Retrieval Based on Wikipedia Concepts</title>
    <summary>  This paper presents a new user feedback mechanism based on Wikipedia concepts
for interactive retrieval. In this mechanism, the system presents to the user a
group of Wikipedia concepts, and the user can choose those relevant to refine
his/her query. To realize this mechanism, we propose methods to address two
problems: 1) how to select a small number of possibly relevant Wikipedia
concepts to show the user, and 2) how to re-rank retrieved documents given the
user-identified Wikipedia concepts. Our methods are evaluated on three TREC
data sets. The experiment results show that our methods can dramatically
improve retrieval performances.
</summary>
    <author>
      <name>Lanbo Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1412.8281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.8281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00094v1</id>
    <updated>2015-01-31T12:15:53Z</updated>
    <published>2015-01-31T12:15:53Z</published>
    <title>Twitter Hash Tag Recommendation</title>
    <summary>  The rise in popularity of microblogging services like Twitter has led to
increased use of content annotation strategies like the hashtag. Hashtags
provide users with a tagging mechanism to help organize, group, and create
visibility for their posts. This is a simple idea but can be challenging for
the user in practice which leads to infrequent usage. In this paper, we will
investigate various methods of recommending hashtags as new posts are created
to encourage more widespread adoption and usage. Hashtag recommendation comes
with numerous challenges including processing huge volumes of streaming data
and content which is small and noisy. We will investigate preprocessing methods
to reduce noise in the data and determine an effective method of hashtag
recommendation based on the popular classification algorithms.
</summary>
    <author>
      <name>Roman Dovgopol</name>
    </author>
    <author>
      <name>Matt Nohelty</name>
    </author>
    <link href="http://arxiv.org/abs/1502.00094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00527v1</id>
    <updated>2015-02-02T15:50:39Z</updated>
    <published>2015-02-02T15:50:39Z</published>
    <title>Context Models For Web Search Personalization</title>
    <summary>  We present our solution to the Yandex Personalized Web Search Challenge. The
aim of this challenge was to use the historical search logs to personalize
top-N document rankings for a set of test users. We used over 100 features
extracted from user- and query-depended contexts to train neural net and
tree-based learning-to-rank and regression models. Our final submission, which
was a blend of several different models, achieved an NDCG@10 of 0.80476 and
placed 4'th amongst the 194 teams winning 3'rd prize.
</summary>
    <author>
      <name>Maksims Volkovs</name>
    </author>
    <link href="http://arxiv.org/abs/1502.00527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01057v1</id>
    <updated>2015-02-03T22:37:37Z</updated>
    <published>2015-02-03T22:37:37Z</published>
    <title>Personalized Web Search</title>
    <summary>  Personalization is important for search engines to improve user experience.
Most of the existing work do pure feature engineering and extract a lot of
session-style features and then train a ranking model. Here we proposed a novel
way to model both long term and short term user behavior using Multi-armed
bandit algorithm. Our algorithm can generalize session information across users
well, and as an Explore-Exploit style algorithm, it can generalize to new urls
and new users well. Experiments show that our algorithm can improve performance
over the default ranking and outperforms several popular Multi-armed bandit
algorithms.
</summary>
    <author>
      <name>Li Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01963v1</id>
    <updated>2015-02-06T17:35:34Z</updated>
    <published>2015-02-06T17:35:34Z</published>
    <title>Editorial for the Proceedings of the Workshop Knowledge Maps and
  Information Retrieval (KMIR2014) at Digital Libraries 2014</title>
    <summary>  Knowledge maps are promising tools for visualizing the structure of
large-scale information spaces, but still far away from being applicable for
searching. The first international workshop on "Knowledge Maps and Information
Retrieval (KMIR)", held as part of the International Conference on Digital
Libraries 2014 in London, aimed at bringing together experts in Information
Retrieval (IR) and knowledge mapping in order to discuss the potential of
interactive knowledge maps for information seeking purposes.
</summary>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Andrea Scharnhorst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">URL workshop proceedings: http://ceur-ws.org/Vol-1311/</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.01963v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01963v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01965v1</id>
    <updated>2015-02-06T17:38:48Z</updated>
    <published>2015-02-06T17:38:48Z</published>
    <title>How can heat maps of indexing vocabularies be utilized for information
  seeking purposes?</title>
    <summary>  The ability to browse an information space in a structured way by exploiting
similarities and dissimilarities between information objects is crucial for
knowledge discovery. Knowledge maps use visualizations to gain insights into
the structure of large-scale information spaces, but are still far away from
being applicable for searching. The paper proposes a use case for enhancing
search term recommendations by heat map visualizations of co-word
relation-ships taken from indexing vocabulary. By contrasting areas of
different "heat" the user is enabled to indicate mainstream areas of the field
in question more easily.
</summary>
    <author>
      <name>Peter Mutschke</name>
    </author>
    <author>
      <name>Karima Haddou ou Moussa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">URL workshop proceedings: http://ceur-ws.org/Vol-1311/</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.01965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00168v1</id>
    <updated>2015-05-01T12:21:24Z</updated>
    <published>2015-05-01T12:21:24Z</published>
    <title>Comparison Clustering using Cosine and Fuzzy set based Similarity
  Measures of Text Documents</title>
    <summary>  Keeping in consideration the high demand for clustering, this paper focuses
on understanding and implementing K-means clustering using two different
similarity measures. We have tried to cluster the documents using two different
measures rather than clustering it with Euclidean distance. Also a comparison
is drawn based on accuracy of clustering between fuzzy and cosine similarity
measure. The start time and end time parameters for formation of clusters are
used in deciding optimum similarity measure.
</summary>
    <author>
      <name>Manan Mohan Goyal</name>
    </author>
    <author>
      <name>Neha Agrawal</name>
    </author>
    <author>
      <name>Manoj Kumar Sarma</name>
    </author>
    <author>
      <name>Nayan Jyoti Kalita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, International Conference on Computing and Communication
  Systems 2015 (I3CS'15), ISBM: 978-1-4799-5857-01, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.00168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00519v1</id>
    <updated>2015-05-04T03:38:04Z</updated>
    <published>2015-05-04T03:38:04Z</published>
    <title>Large Scale Discovery of Seasonal Music From User Data</title>
    <summary>  The consumption history of online media content such as music and video
offers a rich source of data from which to mine information. Trends in this
data are of particular interest because they reflect user preferences as well
as associated cultural contexts that can be exploited in systems such as
recommendation or search. This paper classifies songs as seasonal using a
large, real-world dataset of user listening data. Results show strong
performance of classification of Christmas music with Gaussian Mixture Models.
</summary>
    <author>
      <name>Cameron Summers</name>
    </author>
    <author>
      <name>Phillip Popp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.00519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00755v1</id>
    <updated>2015-05-04T19:04:19Z</updated>
    <published>2015-05-04T19:04:19Z</published>
    <title>Towards the Ontology Web Search Engine</title>
    <summary>  The project of the Ontology Web Search Engine is presented in this paper. The
main purpose of this paper is to develop such a project that can be easily
implemented. Ontology Web Search Engine is software to look for and index
ontologies in the Web. OWL (Web Ontology Languages) ontologies are meant, and
they are necessary for the functioning of the SWES (Semantic Web Expert
System). SWES is an expert system that will use found ontologies from the Web,
generating rules from them, and will supplement its knowledge base with these
generated rules. It is expected that the SWES will serve as a universal expert
system for the average user.
</summary>
    <author>
      <name>Olegs Verhodubs</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00863v1</id>
    <updated>2015-05-05T02:06:23Z</updated>
    <published>2015-05-05T02:06:23Z</published>
    <title>A Feature-based Classification Technique for Answering Multi-choice
  World History Questions</title>
    <summary>  Our FRDC_QA team participated in the QA-Lab English subtask of the NTCIR-11.
In this paper, we describe our system for solving real-world university
entrance exam questions, which are related to world history. Wikipedia is used
as the main external resource for our system. Since problems with choosing
right/wrong sentence from multiple sentence choices account for about
two-thirds of the total, we individually design a classification based model
for solving this type of questions. For other types of questions, we also
design some simple methods.
</summary>
    <author>
      <name>Shuangyong Song</name>
    </author>
    <author>
      <name>Yao Meng</name>
    </author>
    <author>
      <name>Zhongguang Zheng</name>
    </author>
    <author>
      <name>Jun Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, no figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.00863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02798v1</id>
    <updated>2015-05-11T20:39:48Z</updated>
    <published>2015-05-11T20:39:48Z</published>
    <title>Math Search for the Masses: Multimodal Search Interfaces and
  Appearance-Based Retrieval</title>
    <summary>  We summarize math search engines and search interfaces produced by the
Document and Pattern Recognition Lab in recent years, and in particular the min
math search interface and the Tangent search engine. Source code for both
systems are publicly available. "The Masses" refers to our emphasis on creating
systems for mathematical non-experts, who may be looking to define unfamiliar
notation, or browse documents based on the visual appearance of formulae rather
than their mathematical semantics.
</summary>
    <author>
      <name>Richard Zanibbi</name>
    </author>
    <author>
      <name>Awelemdy Orakwue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper for Invited Talk at 2015 Conference on Intelligent Computer
  Mathematics (July, Washington DC)</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.02798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03090v1</id>
    <updated>2015-05-12T17:17:28Z</updated>
    <published>2015-05-12T17:17:28Z</published>
    <title>Efficient Similarity Indexing and Searching in High Dimensions</title>
    <summary>  Efficient indexing and searching of high dimensional data has been an area of
active research due to the growing exploitation of high dimensional data and
the vulnerability of traditional search methods to the curse of dimensionality.
This paper presents a new approach for fast and effective searching and
indexing of high dimensional features using random partitions of the feature
space. Experiments on both handwritten digits and 3-D shape descriptors have
shown the proposed algorithm to be highly effective and efficient in indexing
and searching real data sets of several hundred dimensions. We also compare its
performance to that of the state-of-the-art locality sensitive hashing
algorithm.
</summary>
    <author>
      <name>Yu Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1505.03090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03934v1</id>
    <updated>2015-05-15T01:08:57Z</updated>
    <published>2015-05-15T01:08:57Z</published>
    <title>Textual Spatial Cosine Similarity</title>
    <summary>  When dealing with document similarity many methods exist today, like cosine
similarity. More complex methods are also available based on the semantic
analysis of textual information, which are computationally expensive and rarely
used in the real time feeding of content as in enterprise-wide search
environments. To address these real-time constraints, we developed a new
measure of document similarity called Textual Spatial Cosine Similarity, which
is able to detect similitude at the semantic level using word placement
information contained in the document. We will see in this paper that two
degenerate cases exist for this model, which coincide with Cosine Similarity on
one side and with a paraphrasing detection model to the other.
</summary>
    <author>
      <name>Giancarlo Crocetti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 tables. Proceedings of 12th Annual Research Day, 2014 -
  Pace University</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.08155v1</id>
    <updated>2015-05-29T19:17:03Z</updated>
    <published>2015-05-29T19:17:03Z</published>
    <title>Performance Evaluation and Optimization of Math-Similarity Search</title>
    <summary>  Similarity search in math is to find mathematical expressions that are
similar to a user's query. We conceptualized the similarity factors between
mathematical expressions, and proposed an approach to math similarity search
(MSS) by defining metrics based on those similarity factors [11]. Our
preliminary implementation indicated the advantage of MSS compared to
non-similarity based search. In order to more effectively and efficiently
search similar math expressions, MSS is further optimized. This paper focuses
on performance evaluation and optimization of MSS. Our results show that the
proposed optimization process significantly improved the performance of MSS
with respect to both relevance ranking and recall.
</summary>
    <author>
      <name>Qun Zhang</name>
    </author>
    <author>
      <name>Abdou Youssef</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.08155v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.08155v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.00198v2</id>
    <updated>2015-12-04T10:12:53Z</updated>
    <published>2015-12-01T09:57:03Z</published>
    <title>Efficient filtering of adult content using textual information</title>
    <summary>  Nowadays adult content represents a non negligible proportion of the Web
content. It is of the utmost importance to protect children from this content.
Search engines, as an entry point for Web navigation are ideally placed to deal
with this issue.
  In this paper, we propose a method that builds a safe index i.e.
adult-content free for search engines. This method is based on a filter that
uses only textual information from the web page and the associated URL.
</summary>
    <author>
      <name>Thomas Largillier</name>
    </author>
    <author>
      <name>Guillaume Peyronnet</name>
    </author>
    <author>
      <name>Sylvain Peyronnet</name>
    </author>
    <link href="http://arxiv.org/abs/1512.00198v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.00198v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05437v1</id>
    <updated>2015-12-17T01:48:37Z</updated>
    <published>2015-12-17T01:48:37Z</published>
    <title>A Method of Passage-Based Document Retrieval in Question Answering
  System</title>
    <summary>  We propose a method for using the scoring values of passages to effectively
retrieve documents in a Question Answering system.
  For this, we suggest evaluation function that considers proximity between
each question terms in passage. And using this evaluation function , we extract
a documents which involves scoring values in the highest collection, as a
suitable document for question.
  The proposed method is very effective in document retrieval of Korean
question answering system.
</summary>
    <author>
      <name>Man-Hung Jong</name>
    </author>
    <author>
      <name>Chong-Han Ri</name>
    </author>
    <author>
      <name>Hyok-Chol Choe</name>
    </author>
    <author>
      <name>Chol-Jun Hwang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.05437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00223v1</id>
    <updated>2016-04-01T12:55:35Z</updated>
    <published>2016-04-01T12:55:35Z</published>
    <title>Lower-Cost epsilon-Private Information Retrieval</title>
    <summary>  Private Information Retrieval (PIR), despite being well studied, is
computationally costly and arduous to scale. We explore lower-cost relaxations
of information-theoretic PIR, based on dummy queries, sparse vectors, and
compositions with an anonymity system. We prove the security of each scheme
using a flexible differentially private definition for private queries that can
capture notions of imperfect privacy. We show that basic schemes are weak, but
some of them can be made arbitrarily safe by composing them with large
anonymity systems.
</summary>
    <author>
      <name>Raphael R. Toledo</name>
    </author>
    <author>
      <name>George Danezis</name>
    </author>
    <author>
      <name>Ian Goldberg</name>
    </author>
    <link href="http://arxiv.org/abs/1604.00223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05462v1</id>
    <updated>2016-04-19T08:00:08Z</updated>
    <published>2016-04-19T08:00:08Z</published>
    <title>Ensemble Enabled Weighted PageRank</title>
    <summary>  This paper describes our solution for WSDM Cup 2016. Ranking the query
independent importance of scholarly articles is a critical and challenging
task, due to the heterogeneity and dynamism of entities involved. Our approach
is called Ensemble enabled Weighted PageRank (EWPR). To do this, we first
propose Time-Weighted PageRank that extends PageRank by introducing a time
decaying factor. We then develop an ensemble method to assemble the authorities
of the heterogeneous entities involved in scholarly articles. We finally
propose to use external data sources to further improve the ranking accuracy.
Our experimental study shows that our EWPR is a good choice for ranking
scholarly articles.
</summary>
    <author>
      <name>Dongsheng Luo</name>
    </author>
    <author>
      <name>Chen Gong</name>
    </author>
    <author>
      <name>Renjun Hu</name>
    </author>
    <author>
      <name>Liang Duan</name>
    </author>
    <author>
      <name>Shuai Ma</name>
    </author>
    <link href="http://arxiv.org/abs/1604.05462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06225v1</id>
    <updated>2016-04-21T09:25:11Z</updated>
    <published>2016-04-21T09:25:11Z</published>
    <title>OCR Error Correction Using Character Correction and Feature-Based Word
  Classification</title>
    <summary>  This paper explores the use of a learned classifier for post-OCR text
correction. Experiments with the Arabic language show that this approach, which
integrates a weighted confusion matrix and a shallow language model, improves
the vast majority of segmentation and recognition errors, the most frequent
types of error on our dataset.
</summary>
    <author>
      <name>Ido Kissos</name>
    </author>
    <author>
      <name>Nachum Dershowitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th IAPR International Workshop on Document
  Analysis Systems (DAS2016), Santorini, Greece, April 11-14, 2016</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th IAPR International Workshop on Document
  Analysis Systems (DAS 2016), Santorini, Greece, pp. 198-203 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1604.06225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07521v1</id>
    <updated>2016-04-26T05:08:13Z</updated>
    <published>2016-04-26T05:08:13Z</published>
    <title>Feedback-based Approach to Introduce Freshness in Recommendations</title>
    <summary>  Recommender systems usually face the problem of serving the same
recommendations across multiple sessions regardless of whether the user is
interested in them or not, thereby reducing their effectiveness. To add
freshness to the recommended products, we introduce a feedback loop where the
set of recommended products in the current session depend on the user's
interaction with the previously recommended sets. We also describe ways of
addressing freshness when there is little or even no direct user interaction.
We define a metric to quantify freshness by reducing the problem to measuring
temporal diversity.
</summary>
    <author>
      <name>Hari Krishna Malladi</name>
    </author>
    <author>
      <name>Saikiran Thunuguntla</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03048v2</id>
    <updated>2017-12-11T10:23:55Z</updated>
    <published>2016-06-07T06:38:32Z</published>
    <title>A Minimum Spanning Tree Representation of Anime Similarities</title>
    <summary>  In this work, a new way to represent Japanese animation (anime) is presented.
We applied a minimum spanning tree to show the relation between anime. The
distance between anime is calculated through three similarity measurements,
namely crew, score histogram, and topic similarities. Finally, the centralities
are also computed to reveal the most significance anime. The result shows that
the minimum spanning tree can be used to determine the similarity anime.
Furthermore, by using centralities calculation, we found some anime that are
significant to others.
</summary>
    <author>
      <name>Canggih Puspo Wibowo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.03048v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03048v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03783v1</id>
    <updated>2016-06-12T23:50:19Z</updated>
    <published>2016-06-12T23:50:19Z</published>
    <title>Retrieving and Ranking Similar Questions from Question-Answer Archives
  Using Topic Modelling and Topic Distribution Regression</title>
    <summary>  Presented herein is a novel model for similar question ranking within
collaborative question answer platforms. The presented approach integrates a
regression stage to relate topics derived from questions to those derived from
question-answer pairs. This helps to avoid problems caused by the differences
in vocabulary used within questions and answers, and the tendency for questions
to be shorter than answers. The performance of the model is shown to outperform
translation methods and topic modelling (without regression) on several
real-world datasets.
</summary>
    <author>
      <name>Pedro Chahuara</name>
    </author>
    <author>
      <name>Thomas Lampert</name>
    </author>
    <author>
      <name>Pierre Gancarski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-43997-6_4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-43997-6_4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Theory and Practice of Digital Libraries
  2016 (accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.03783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06991v1</id>
    <updated>2016-06-22T15:53:29Z</updated>
    <published>2016-06-22T15:53:29Z</published>
    <title>Toward Word Embedding for Personalized Information Retrieval</title>
    <summary>  This paper presents preliminary works on using Word Embedding (word2vec) for
query expansion in the context of Personalized Information Retrieval.
Traditionally, word embeddings are learned on a general corpus, like Wikipedia.
In this work we try to personalize the word embeddings learning, by achieving
the learning on the user's profile. The word embeddings are then in the same
context than the user interests. Our proposal is evaluated on the CLEF Social
Book Search 2016 collection. The results obtained show that some efforts should
be made in the way to apply Word Embedding in the context of Personalized
Information Retrieval.
</summary>
    <author>
      <name>Nawal Ould-Amer</name>
    </author>
    <author>
      <name>Philippe Mulhem</name>
    </author>
    <author>
      <name>Mathias Gery</name>
    </author>
    <link href="http://arxiv.org/abs/1606.06991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03597v1</id>
    <updated>2016-12-12T10:27:31Z</updated>
    <published>2016-12-12T10:27:31Z</published>
    <title>Search Personalization with Embeddings</title>
    <summary>  Recent research has shown that the performance of search personalization
depends on the richness of user profiles which normally represent the user's
topical interests. In this paper, we propose a new embedding approach to
learning user profiles, where users are embedded on a topical interest space.
We then directly utilize the user profiles for search personalization.
Experiments on query logs from a major commercial web search engine demonstrate
that our embedding approach improves the performance of the search engine and
also achieves better search performance than other strong baselines.
</summary>
    <author>
      <name>Thanh Vu</name>
    </author>
    <author>
      <name>Dat Quoc Nguyen</name>
    </author>
    <author>
      <name>Mark Johnson</name>
    </author>
    <author>
      <name>Dawei Song</name>
    </author>
    <author>
      <name>Alistair Willis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-56608-5_54</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-56608-5_54" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 39th European Conference on Information
  Retrieval, ECIR 2017, to appear</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.03597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07117v1</id>
    <updated>2016-12-20T15:02:41Z</updated>
    <published>2016-12-20T15:02:41Z</published>
    <title>Classification and Learning-to-rank Approaches for Cross-Device Matching
  at CIKM Cup 2016</title>
    <summary>  In this paper, we propose two methods for tackling the problem of
cross-device matching for online advertising at CIKM Cup 2016. The first method
considers the matching problem as a binary classification task and solve it by
utilizing ensemble learning techniques. The second method defines the matching
problem as a ranking task and effectively solve it with using learning-to-rank
algorithms. The results show that the proposed methods obtain promising
results, in which the ranking-based method outperforms the classification-based
method for the task.
</summary>
    <author>
      <name>Nam Khanh Tran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CIKM Cup 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08391v1</id>
    <updated>2016-12-26T14:35:51Z</updated>
    <published>2016-12-26T14:35:51Z</published>
    <title>Audio-based Distributional Semantic Models for Music Auto-tagging and
  Similarity Measurement</title>
    <summary>  The recent development of Audio-based Distributional Semantic Models (ADSMs)
enables the computation of audio and lexical vector representations in a joint
acoustic-semantic space. In this work, these joint representations are applied
to the problem of automatic tag generation. The predicted tags together with
their corresponding acoustic representation are exploited for the construction
of acoustic-semantic clip embeddings. The proposed algorithms are evaluated on
the task of similarity measurement between music clips. Acoustic-semantic
models are shown to outperform the state-of-the-art for this task and produce
high quality tags for audio/music clips.
</summary>
    <author>
      <name>Giannis Karamanolakis</name>
    </author>
    <author>
      <name>Elias Iosif</name>
    </author>
    <author>
      <name>Athanasia Zlatintsi</name>
    </author>
    <author>
      <name>Aggelos Pikrakis</name>
    </author>
    <author>
      <name>Alexandros Potamianos</name>
    </author>
    <link href="http://arxiv.org/abs/1612.08391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09062v1</id>
    <updated>2016-12-29T07:56:09Z</updated>
    <published>2016-12-29T07:56:09Z</published>
    <title>Condensedly: comprehending article contents through condensed texts</title>
    <summary>  Summary: Abstracts in biomedical articles can provide a quick overview of the
articles but detailed information cannot be obtained without reading full-text
contents. Full-text articles certainly generate more information and contents;
however, accessing full-text documents is usually time consuming. Condensedly
is a web-based application, which provides readers an easy and efficient way to
access full-text paragraphs using sentences in abstracts as fishing bait to
retrieve the big fish reside in full-text. Condensedly is based on the
paragraph ranking algorithm, which evaluates and ranks full-text paragraphs
based on their association scores with sentences in abstracts.
  Availability: http://140.116.247.185/~research/Condensedly
</summary>
    <author>
      <name>Chao-Hsuan Ke</name>
    </author>
    <author>
      <name>Tsung-Lu Michael Lee</name>
    </author>
    <author>
      <name>Jung-Hsien Chiang</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.02915v1</id>
    <updated>2017-03-06T21:05:42Z</updated>
    <published>2017-03-06T21:05:42Z</published>
    <title>Kaggle Competition: Expedia Hotel Recommendations</title>
    <summary>  With hundreds, even thousands, of hotels to choose from at every destination,
it's difficult to know which will suit your personal preferences. Expedia wants
to take the proverbial rabbit hole out of hotel search by providing
personalized hotel recommendations to their users. This is no small task for a
site with hundreds of millions of visitors every month! Currently, Expedia uses
search parameters to adjust their hotel recommendations, but there aren't
enough customer specific data to personalize them for each user. In this
project, we have taken up the challenge to contextualize customer data and
predict the likelihood a user will stay at 100 different hotel groups.
</summary>
    <author>
      <name>Gourav G. Shenoy</name>
    </author>
    <author>
      <name>Mangirish A. Wagle</name>
    </author>
    <author>
      <name>Anwar Shaikh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 tables, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.02915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.02915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03923v1</id>
    <updated>2017-03-11T07:35:28Z</updated>
    <published>2017-03-11T07:35:28Z</published>
    <title>A German Corpus for Text Similarity Detection Tasks</title>
    <summary>  Text similarity detection aims at measuring the degree of similarity between
a pair of texts. Corpora available for text similarity detection are designed
to evaluate the algorithms to assess the paraphrase level among documents. In
this paper we present a textual German corpus for similarity detection. The
purpose of this corpus is to automatically assess the similarity between a pair
of texts and to evaluate different similarity measures, both for whole
documents or for individual sentences. Therefore we have calculated several
simple measures on our corpus based on a library of similarity functions.
</summary>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Gerardo Sierra</name>
    </author>
    <author>
      <name>Peter Peinl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 figure; 13 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of International Journal of Computational Linguistics and
  Applications, vol. 5, no. 2, 2014, pp. 9-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.03923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.04336v1</id>
    <updated>2017-03-13T11:19:56Z</updated>
    <published>2017-03-13T11:19:56Z</published>
    <title>A Visual Representation of Wittgenstein's Tractatus Logico-Philosophicus</title>
    <summary>  In this paper we present a data visualization method together with its
potential usefulness in digital humanities and philosophy of language. We
compile a multilingual parallel corpus from different versions of
Wittgenstein's Tractatus Logico-Philosophicus, including the original in German
and translations into English, Spanish, French, and Russian. Using this corpus,
we compute a similarity measure between propositions and render a visual
network of relations for different languages.
</summary>
    <author>
      <name>Anca Bucur</name>
    </author>
    <author>
      <name>Sergiu Nisioi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Language Technology Resources and Tools for Digital
  Humanities (LT4DH)</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.04336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.04336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05123v2</id>
    <updated>2017-03-16T08:57:29Z</updated>
    <published>2017-03-15T12:37:22Z</published>
    <title>Character-based Neural Embeddings for Tweet Clustering</title>
    <summary>  In this paper we show how the performance of tweet clustering can be improved
by leveraging character-based neural networks. The proposed approach overcomes
the limitations related to the vocabulary explosion in the word-based models
and allows for the seamless processing of the multilingual content. Our
evaluation results and code are available on-line at
https://github.com/vendi12/tweet2vec_clustering
</summary>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <author>
      <name>Lyndon Nixon</name>
    </author>
    <author>
      <name>Mihai Lupu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the SocialNLP 2017 workshop held in conjunction with EACL
  2017, April 3, 2017, Valencia, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05123v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05123v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05851v2</id>
    <updated>2017-10-05T21:38:08Z</updated>
    <published>2017-03-17T00:02:42Z</published>
    <title>Temporal Information Extraction for Question Answering Using Syntactic
  Dependencies in an LSTM-based Architecture</title>
    <summary>  In this paper, we propose to use a set of simple, uniform in architecture
LSTM-based models to recover different kinds of temporal relations from text.
Using the shortest dependency path between entities as input, the same
architecture is used to extract intra-sentence, cross-sentence, and document
creation time relations. A "double-checking" technique reverses entity pairs in
classification, boosting the recall of positive cases and reducing
misclassifications between opposite classes. An efficient pruning algorithm
resolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our
proposed technique outperforms state-of-the-art methods by a large margin.
</summary>
    <author>
      <name>Yuanliang Meng</name>
    </author>
    <author>
      <name>Anna Rumshisky</name>
    </author>
    <author>
      <name>Alexey Romanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05851v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05851v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.06108v1</id>
    <updated>2017-03-17T17:16:02Z</updated>
    <published>2017-03-17T17:16:02Z</published>
    <title>Global Entity Ranking Across Multiple Languages</title>
    <summary>  We present work on building a global long-tailed ranking of entities across
multiple languages using Wikipedia and Freebase knowledge bases. We identify
multiple features and build a model to rank entities using a ground-truth
dataset of more than 10 thousand labels. The final system ranks 27 million
entities with 75% precision and 48% F1 score. We provide performance evaluation
and empirical evidence of the quality of ranking across languages, and open the
final ranked lists for future research.
</summary>
    <author>
      <name>Prantik Bhattacharyya</name>
    </author>
    <author>
      <name>Nemanja Spasojevic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3041021.3054213</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3041021.3054213" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 Pages, 1 Figure, 2 Tables, WWW2017 Companion, WWW 2017 Companion</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.06108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.06108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07381v1</id>
    <updated>2017-03-21T18:29:05Z</updated>
    <published>2017-03-21T18:29:05Z</published>
    <title>Improving Statistical Multimedia Information Retrieval Model by using
  Ontology</title>
    <summary>  A typical IR system that delivers and stores information is affected by
problem of matching between user query and available content on web. Use of
Ontology represents the extracted terms in form of network graph consisting of
nodes, edges, index terms etc. The above mentioned IR approaches provide
relevance thus satisfying users query. The paper also emphasis on analyzing
multimedia documents and performs calculation for extracted terms using
different statistical formulas. The proposed model developed reduces semantic
gap and satisfies user needs efficiently.
</summary>
    <author>
      <name>Gagandeep Singh Narula</name>
    </author>
    <author>
      <name>Vishal Jain</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications ISSN No 0975 8887
  Volume 94 No 2, May 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.07381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07384v1</id>
    <updated>2017-03-21T18:34:34Z</updated>
    <published>2017-03-21T18:34:34Z</published>
    <title>Ontology Based Pivoted normalization using Vector Based Approach for
  information Retrieval</title>
    <summary>  The proposed methodology is procedural i.e. it follows finite number of steps
that extracts relevant documents according to users query. It is based on
principles of Data Mining for analyzing web data. Data Mining first adapts
integration of data to generate warehouse. Then, it extracts useful information
with the help of algorithm. The task of representing extracted documents is
done by using Vector Based Statistical Approach that represents each document
in set of Terms.
</summary>
    <author>
      <name>Vishal Jain</name>
    </author>
    <author>
      <name>Dr. Mayank Singh</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">7th International Conference on Advanced Computing and
  Communication Technologies, 16th November, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.07384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.09108v2</id>
    <updated>2017-04-20T09:50:03Z</updated>
    <published>2017-03-27T14:35:37Z</published>
    <title>Mr. DLib: Recommendations-as-a-Service (RaaS) for Academia</title>
    <summary>  Only few digital libraries and reference managers offer recommender systems,
although such systems could assist users facing information overload. In this
paper, we introduce Mr. DLib's recommendations-as-a-service, which allows third
parties to easily integrate a recommender system into their products. We
explain the recommender approaches implemented in Mr. DLib (content-based
filtering among others), and present details on 57 million recommendations,
which Mr. DLib delivered to its partner GESIS Sowiport. Finally, we outline our
plans for future development, including integration into JabRef, establishing a
living lab, and providing personalized recommendations.
</summary>
    <author>
      <name>Joeran Beel</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <author>
      <name>Corinna Breitinger</name>
    </author>
    <author>
      <name>Bela Gipp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at the JCDL conference 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.09108v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.09108v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.7, H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.03185v1</id>
    <updated>2018-03-08T16:22:26Z</updated>
    <published>2018-03-08T16:22:26Z</published>
    <title>Drug Recommendation toward Safe Polypharmacy</title>
    <summary>  Adverse drug reactions (ADRs) induced from high-order drug-drug interactions
(DDIs) due to polypharmacy represent a significant public health problem. In
this paper, we formally formulate the to-avoid and safe (with respect to ADRs)
drug recommendation problems when multiple drugs have been taken
simultaneously. We develop a joint model with a recommendation component and an
ADR label prediction component to recommend for a prescription a set of
to-avoid drugs that will induce ADRs if taken together with the prescription.
We also develop real drug-drug interaction datasets and corresponding
evaluation protocols. Our experimental results on real datasets demonstrate the
strong performance of the joint model compared to other baseline methods.
</summary>
    <author>
      <name>Wen-Hao Chiang</name>
    </author>
    <author>
      <name>Li Shen</name>
    </author>
    <author>
      <name>Lang Li</name>
    </author>
    <author>
      <name>Xia Ning</name>
    </author>
    <link href="http://arxiv.org/abs/1803.03185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.03185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.08721v2</id>
    <updated>2018-04-16T08:49:00Z</updated>
    <published>2018-03-23T10:35:42Z</published>
    <title>Unsupervised Keyphrase Extraction with Multipartite Graphs</title>
    <summary>  We propose an unsupervised keyphrase extraction model that encodes topical
information within a multipartite graph structure. Our model represents
keyphrase candidates and topics in a single graph and exploits their mutually
reinforcing relationship to improve candidate ranking. We further introduce a
novel mechanism to incorporate keyphrase selection preferences into the model.
Experiments conducted on three widely used datasets show significant
improvements over state-of-the-art graph-based models.
</summary>
    <author>
      <name>Florian Boudin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NAACL 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.08721v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.08721v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.09799v1</id>
    <updated>2018-03-26T19:12:02Z</updated>
    <published>2018-03-26T19:12:02Z</published>
    <title>Demystifying Core Ranking in Pinterest Image Search</title>
    <summary>  Pinterest Image Search Engine helps hundreds of millions of users discover
interesting content everyday. This motivates us to improve the image search
quality by evolving our ranking techniques. In this work, we share how we
practically design and deploy various ranking pipelines into Pinterest image
search ecosystem. Specifically, we focus on introducing our novel research and
study on three aspects: training data, user/image featurization and ranking
models. Extensive offline and online studies compared the performance of
different models and demonstrated the efficiency and effectiveness of our final
launched ranking models.
</summary>
    <author>
      <name>Linhong Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/1803.09799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.09799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.09875v1</id>
    <updated>2018-03-27T03:23:19Z</updated>
    <published>2018-03-27T03:23:19Z</published>
    <title>A Web Scraping Methodology for Bypassing Twitter API Restrictions</title>
    <summary>  Retrieving information from social networks is the first and primordial step
many data analysis fields such as Natural Language Processing, Sentiment
Analysis and Machine Learning. Important data science tasks relay on historical
data gathering for further predictive results. Most of the recent works use
Twitter API, a public platform for collecting public streams of information,
which allows querying chronological tweets for no more than three weeks old. In
this paper, we present a new methodology for collecting historical tweets
within any date range using web scraping techniques bypassing for Twitter API
restrictions.
</summary>
    <author>
      <name>A. Hernandez-Suarez</name>
    </author>
    <author>
      <name>G. Sanchez-Perez</name>
    </author>
    <author>
      <name>K. Toscano-Medina</name>
    </author>
    <author>
      <name>V. Martinez-Hernandez</name>
    </author>
    <author>
      <name>V. Sanchez</name>
    </author>
    <author>
      <name>H. Perez-Meana</name>
    </author>
    <link href="http://arxiv.org/abs/1803.09875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.09875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.00356v1</id>
    <updated>2018-05-01T14:13:56Z</updated>
    <published>2018-05-01T14:13:56Z</published>
    <title>Deep Factorization Machines for Knowledge Tracing</title>
    <summary>  This paper introduces our solution to the 2018 Duolingo Shared Task on Second
Language Acquisition Modeling (SLAM). We used deep factorization machines, a
wide and deep learning model of pairwise relationships between users, items,
skills, and other entities considered. Our solution (AUC 0.815) hopefully
managed to beat the logistic regression baseline (AUC 0.774) but not the top
performing model (AUC 0.861) and reveals interesting strategies to build upon
item response theory models.
</summary>
    <author>
      <name>Jill-Jênn Vie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 table, accepted at the 13th BEA workshop, co-located with
  NAACL HLT 2018 conference in New Orleans on June 5, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.00356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.00356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.01359v2</id>
    <updated>2020-12-04T12:54:08Z</updated>
    <published>2018-05-03T15:12:35Z</published>
    <title>EventKG+TL: Creating Cross-Lingual Timelines from an Event-Centric
  Knowledge Graph</title>
    <summary>  The provision of multilingual event-centric temporal knowledge graphs such as
EventKG enables structured access to representations of a large number of
historical and contemporary events in a variety of language contexts. Timelines
provide an intuitive way to facilitate an overview of events related to a query
entity - i.e., an entity or an event of user interest - over a certain period
of time. In this paper, we present EventKG+TL - a novel system that generates
cross-lingual event timelines using EventKG and facilitates an overview of the
language-specific event relevance and popularity along with the cross-lingual
differences.
</summary>
    <author>
      <name>Simon Gottschalk</name>
    </author>
    <author>
      <name>Elena Demidova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-98192-5_31</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-98192-5_31" rel="related"/>
    <link href="http://arxiv.org/abs/1805.01359v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.01359v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.01597v2</id>
    <updated>2018-06-05T08:50:30Z</updated>
    <published>2018-05-04T03:37:03Z</published>
    <title>Pytrec_eval: An Extremely Fast Python Interface to trec_eval</title>
    <summary>  We introduce pytrec_eval, a Python interface to the tree_eval information
retrieval evaluation toolkit. pytrec_eval exposes the reference implementations
of trec_eval within Python as a native extension. We show that pytrec_eval is
around one order of magnitude faster than invoking trec_eval as a sub process
from within Python. Compared to a native Python implementation of NDCG,
pytrec_eval is twice as fast for practically-sized rankings. Finally, we
demonstrate its effectiveness in an application where pytrec_eval is combined
with Pyndri and the OpenAI Gym where query expansion is learned using
Q-learning.
</summary>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3209978.3210065</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3209978.3210065" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR '18. The 41st International ACM SIGIR Conference on Research &amp;
  Development in Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.01597v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.01597v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.03797v1</id>
    <updated>2018-05-10T03:14:42Z</updated>
    <published>2018-05-10T03:14:42Z</published>
    <title>WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer
  Passage Retrieval</title>
    <summary>  With the rise in mobile and voice search, answer passage retrieval acts as a
critical component of an effective information retrieval system for open domain
question answering. Currently, there are no comparable collections that address
non-factoid question answering within larger documents while simultaneously
providing enough examples sufficient to train a deep neural network. In this
paper, we introduce a new Wikipedia based collection specific for non-factoid
answer passage retrieval containing thousands of questions with annotated
answers and show benchmark results on a variety of state of the art neural
architectures and retrieval models. The experimental results demonstrate the
unique challenges presented by answer passage retrieval within topically
relevant documents for future research.
</summary>
    <author>
      <name>Daniel Cohen</name>
    </author>
    <author>
      <name>Liu Yang</name>
    </author>
    <author>
      <name>W. Bruce Croft</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by SIGIR18</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.03797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.03797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.06353v1</id>
    <updated>2018-05-16T14:54:00Z</updated>
    <published>2018-05-16T14:54:00Z</published>
    <title>SmartTable: A Spreadsheet Program with Intelligent Assistance</title>
    <summary>  We introduce SmartTable, an online spreadsheet application that is equipped
with intelligent assistance capabilities. With a focus on relational tables,
describing entities along with their attributes, we offer assistance in two
flavors: (i) for populating the table with additional entities (rows) and (ii)
for extending it with additional entity attributes (columns). We provide
details of our implementation, which is also released as open source. The
application is available at http://smarttable.cc.
</summary>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <author>
      <name>Vugar Abdul Zada</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3209978.3210171</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3209978.3210171" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 41st International ACM SIGIR Conference on Research and
  Development in Information Retrieval (SIGIR '18)</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.06353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.06353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.06745v1</id>
    <updated>2018-05-03T13:28:51Z</updated>
    <published>2018-05-03T13:28:51Z</published>
    <title>Web Resource for Storing Collective Experience</title>
    <summary>  Experience is what makes our life more effective that is why it is necessary
to share experience among people. The use of information technologies is the
most technological way to work with experience, and the use of the Web is the
best way for sharing it. This paper describes a web resource designed for
storing, sharing and using experience that is obtained from different people in
the Web. The main purpose of this paper is to present this web resource in
order to evaluate the interest in such a web resource.
</summary>
    <author>
      <name>Olegs Verhodubs</name>
    </author>
    <link href="http://arxiv.org/abs/1805.06745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.06745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1805.07851v1</id>
    <updated>2018-05-21T00:27:05Z</updated>
    <published>2018-05-21T00:27:05Z</published>
    <title>A Text Analysis of Federal Reserve meeting minutes</title>
    <summary>  Recent developments in monetary policy by the Federal Reserve has created a
need for an objective method of communication analysis.Using methods developed
for text analysis, we present a novel technique of analysis which creates a
semantic space defined by various policymakers public comments and places the
committee consensus in the appropriate location. Its then possible to determine
which member of the committee is most closely aligned with the committee
consensus over time and create a foundation for further actionable research.
</summary>
    <author>
      <name>Harish Gandhi Ramachandran</name>
    </author>
    <author>
      <name>Dan DeRose Jr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1805.07851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1805.07851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.02281v1</id>
    <updated>2018-06-06T16:20:24Z</updated>
    <published>2018-06-06T16:20:24Z</published>
    <title>Deploying Deep Ranking Models for Search Verticals</title>
    <summary>  In this paper, we present an architecture executing a complex machine
learning model such as a neural network capturing semantic similarity between a
query and a document; and deploy to a real-world production system serving
500M+users. We present the challenges that arise in a real-world system and how
we solve them. We demonstrate that our architecture provides competitive
modeling capability without any significant performance impact to the system in
terms of latency. Our modular solution and insights can be used by other
real-world search systems to realize and productionize recent gains in neural
networks.
</summary>
    <author>
      <name>Rohan Ramanath</name>
    </author>
    <author>
      <name>Gungor Polatkan</name>
    </author>
    <author>
      <name>Liqin Xu</name>
    </author>
    <author>
      <name>Harold Lee</name>
    </author>
    <author>
      <name>Bo Hu</name>
    </author>
    <author>
      <name>Shan Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at the SysML Conference - 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1806.02281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.02281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.03368v1</id>
    <updated>2018-06-08T22:46:08Z</updated>
    <published>2018-06-08T22:46:08Z</published>
    <title>An Exploration of H-1B Visa Applications in the United States</title>
    <summary>  The H-1B visa program is a very important tool for US-based businesses and
educational institutes to recruit foreign talent. While the ultimate decision
to certify an application lies with the United States Department of Labor,
there are signals that can be used to determine whether an application is
likely to be certified or denied. In this paper we first perform a data-driven
exploratory analysis. We then leverage the features to train several
classifiers and compare their performance. Finally, we discuss the implications
of this work and future work that can be done in this area.
</summary>
    <author>
      <name>Habeeb Hooshmand</name>
    </author>
    <author>
      <name>Joseph Martinsen</name>
    </author>
    <author>
      <name>Jonathan Arauco</name>
    </author>
    <author>
      <name>Alishah Dholasaniya</name>
    </author>
    <author>
      <name>Bhavik Bhatt</name>
    </author>
    <link href="http://arxiv.org/abs/1806.03368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.03368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.04735v1</id>
    <updated>2018-06-12T19:36:52Z</updated>
    <published>2018-06-12T19:36:52Z</published>
    <title>Information Retrieval in African Languages</title>
    <summary>  Developing Information Retrieval (IR) tools and techniques in African
languages suffers from the dual problems of a lack of algorithms and very small
test data collections. This affects the creation of practical IR systems and
limits the ability to apply IR to address human and socio-economic problems,
which is an urgent need in poor countries. This position paper presents an
overview of recent and current work conducted at the University of Cape Town in
this area. While many problems have been investigated at an early stage,
limited dataset sizes for local African languages still persists as a
significant limitation and stumbling block.
</summary>
    <author>
      <name>Hussein Suleman</name>
    </author>
    <link href="http://arxiv.org/abs/1806.04735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.04735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.06192v1</id>
    <updated>2018-06-16T05:58:00Z</updated>
    <published>2018-06-16T05:58:00Z</published>
    <title>Handling Cold-Start Collaborative Filtering with Reinforcement Learning</title>
    <summary>  A major challenge in recommender systems is handling new users, whom are also
called $\textit{cold-start}$ users. In this paper, we propose a novel approach
for learning an optimal series of questions with which to interview cold-start
users for movie recommender systems. We propose learning interview questions
using Deep Q Networks to create user profiles to make better recommendations to
cold-start users. While our proposed system is trained using a movie
recommender system, our Deep Q Network model should generalize across various
types of recommender systems.
</summary>
    <author>
      <name>Hima Varsha Dureddy</name>
    </author>
    <author>
      <name>Zachary Kaden</name>
    </author>
    <link href="http://arxiv.org/abs/1806.06192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.06192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.09317v1</id>
    <updated>2018-06-25T08:05:26Z</updated>
    <published>2018-06-25T08:05:26Z</published>
    <title>Evaluation of Information Retrieval Systems Using Structural Equation
  Modelling</title>
    <summary>  The interpretation of the experimental data collected by testing systems
across input datasets and model parameters is of strategic importance for
system design and implementation. In particular, finding relationships between
variables and detecting the latent variables affecting retrieval performance
can provide designers, engineers and experimenters with useful if not necessary
information about how a system is performing. This paper discusses the use of
Structural Equation Modelling (SEM) in providing an in-depth explanation of
evaluation results and an explanation of failures and successes of a system; in
particular, we focus on the case of Information Retrieval.
</summary>
    <author>
      <name>Massimo Melucci</name>
    </author>
    <link href="http://arxiv.org/abs/1806.09317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.09317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1806.11424v1</id>
    <updated>2018-06-28T17:09:58Z</updated>
    <published>2018-06-28T17:09:58Z</published>
    <title>Understanding Fashionability: What drives sales of a style?</title>
    <summary>  We use customer demand data for fashion articles on Myntra, and derive a
fashionability or style quotient, which represents customer demand for the
stylistic content of a fashion article, decoupled with its commercials (price,
offers, etc.). We demonstrate learning for assortment planning in fashion that
would aim to keep a healthy mix of breadth and depth across various styles, and
we show the relationship between a customer's perception of a style vs a
merchandiser's catalogue of styles. We also backtest our method to calculate
prediction errors in our style quotient and customer demand, and discuss
various implications and findings.
</summary>
    <author>
      <name>Aniket Jain</name>
    </author>
    <author>
      <name>Yadunath Gupta</name>
    </author>
    <author>
      <name>Pawan Kumar Singh</name>
    </author>
    <author>
      <name>Aruna Rajan</name>
    </author>
    <link href="http://arxiv.org/abs/1806.11424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1806.11424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.00927v1</id>
    <updated>2020-07-02T07:06:27Z</updated>
    <published>2020-07-02T07:06:27Z</published>
    <title>How circular economy and industrial ecology concepts are intertwined? A
  bibliometric and text mining analysis</title>
    <summary>  Combining new insights from both bibliometric and text mining analyses, with
prior relevant research conversations on circular economy (CE) and industrial
ecology (IE), this paper aims to clarify the recent development trends and
relations between these concepts, including their representations and
applications. On this basis, discussions are made and recommendations provided
on how CE and IE approaches, tools, and indicators can complement each other to
enable and catalyze a more circular and sustainable development, by supporting
sustainable policy-making and monitoring sound CE strategies in industrial
practices.
</summary>
    <author>
      <name>Michael Saidani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Yannou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>Yann Leroy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>François Cluzel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGI</arxiv:affiliation>
    </author>
    <author>
      <name>Harrison Kim</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Online Symposium on Circular Economy and Sustainability, Jul 2020,
  Alexandroupolis, Greece</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.00927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.00927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.01978v1</id>
    <updated>2020-07-04T01:16:49Z</updated>
    <published>2020-07-04T01:16:49Z</published>
    <title>Building benchmarking frameworks for supporting replicability and
  reproducibility: spatial and textual analysis as an example</title>
    <summary>  Replicability and reproducibility (R&amp;R) are critical for the long-term
prosperity of a scientific discipline. In GIScience, researchers have discussed
R&amp;R related to different research topics and problems, such as local spatial
statistics, digital earth, and metadata (Fotheringham, 2009; Goodchild, 2012;
Anselin et al., 2014). This position paper proposes to further support R&amp;R by
building benchmarking frameworks in order to facilitate the replication of
previous research for effective and effcient comparisons of methods and
software tools developed for addressing the same or similar problems.
Particularly, this paper will use geoparsing, an important research problem in
spatial and textual analysis, as an example to explain the values of such
benchmarking frameworks.
</summary>
    <author>
      <name>Yingjie Hu</name>
    </author>
    <link href="http://arxiv.org/abs/2007.01978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.01978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.02492v1</id>
    <updated>2020-07-06T01:34:25Z</updated>
    <published>2020-07-06T01:34:25Z</published>
    <title>Searching Scientific Literature for Answers on COVID-19 Questions</title>
    <summary>  Finding answers related to a pandemic of a novel disease raises new
challenges for information seeking and retrieval, as the new information
becomes available gradually. TREC COVID search track aims to assist in creating
search tools to aid scientists, clinicians, policy makers and others with
similar information needs in finding reliable answers from the scientific
literature. We experiment with different ranking algorithms as part of our
participation in this challenge. We propose a novel method for neural
retrieval, and demonstrate its effectiveness on the TREC COVID search.
</summary>
    <author>
      <name>Vincent Nguyen</name>
    </author>
    <author>
      <name>Maciek Rybinski</name>
    </author>
    <author>
      <name>Sarvnaz Karimi</name>
    </author>
    <author>
      <name>Zhenchang Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages + 1 page of references, submitted to ACL COVID-19 workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2007.02492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.02492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.06758v1</id>
    <updated>2020-07-14T01:24:44Z</updated>
    <published>2020-07-14T01:24:44Z</published>
    <title>Recommender Systems for the Internet of Things: A Survey</title>
    <summary>  Recommendation represents a vital stage in developing and promoting the
benefits of the Internet of Things (IoT). Traditional recommender systems fail
to exploit ever-growing, dynamic, and heterogeneous IoT data. This paper
presents a comprehensive review of the state-of-the-art recommender systems, as
well as related techniques and application in the vibrant field of IoT. We
discuss several limitations of applying recommendation systems to IoT and
propose a reference framework for comparing existing studies to guide future
research and practices.
</summary>
    <author>
      <name>May Altulyan</name>
    </author>
    <author>
      <name>Lina Yao</name>
    </author>
    <author>
      <name>Xianzhi Wang</name>
    </author>
    <author>
      <name>Chaoran Huang</name>
    </author>
    <author>
      <name>Salil S Kanhere</name>
    </author>
    <author>
      <name>Quan Z Sheng</name>
    </author>
    <link href="http://arxiv.org/abs/2007.06758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.06758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.09377v1</id>
    <updated>2020-07-18T09:30:52Z</updated>
    <published>2020-07-18T09:30:52Z</published>
    <title>About a structure of easily updatable full-text indexes</title>
    <summary>  We consider strategies to organize easily updatable associative arrays in
external memory. These arrays are used for full-text search. We study indexes
with different keys: single word form, two word forms, and sequences of word
forms. The storage structure depends on the size of the key's data. The results
of the experiments are given in the context of the proximity full-text search,
which is performed by means of additional indexes.
</summary>
    <author>
      <name>Alexander B. Veretennikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Indexing: Scopus. This is the English translation performed by the
  author of the original Russian paper. The original version is available
  online at: http://ceur-ws.org/Vol-1894/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CEUR Workshop Proceedings, vol. 1894, 2017, pp. 30-40. 48th
  International Youth School Conference "Modern Problems in Mathematics and its
  Applications", 06-Feb-2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2007.09377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.09377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.11088v1</id>
    <updated>2020-07-21T20:55:57Z</updated>
    <published>2020-07-21T20:55:57Z</published>
    <title>Understanding BERT Rankers Under Distillation</title>
    <summary>  Deep language models such as BERT pre-trained on large corpus have given a
huge performance boost to the state-of-the-art information retrieval ranking
systems. Knowledge embedded in such models allows them to pick up complex
matching signals between passages and queries. However, the high computation
cost during inference limits their deployment in real-world search scenarios.
In this paper, we study if and how the knowledge for search within BERT can be
transferred to a smaller ranker through distillation. Our experiments
demonstrate that it is crucial to use a proper distillation procedure, which
produces up to nine times speedup while preserving the state-of-the-art
performance.
</summary>
    <author>
      <name>Luyu Gao</name>
    </author>
    <author>
      <name>Zhuyun Dai</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3409256.3409838</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3409256.3409838" rel="related"/>
    <link href="http://arxiv.org/abs/2007.11088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.11088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2007.11659v1</id>
    <updated>2020-06-18T22:37:57Z</updated>
    <published>2020-06-18T22:37:57Z</published>
    <title>Proceedings of the KG-BIAS Workshop 2020 at AKBC 2020</title>
    <summary>  The KG-BIAS 2020 workshop touches on biases and how they surface in knowledge
graphs (KGs), biases in the source data that is used to create KGs, methods for
measuring or remediating bias in KGs, but also identifying other biases such as
how and which languages are represented in automatically constructed KGs or how
personal KGs might incur inherent biases. The goal of this workshop is to
uncover how various types of biases are introduced into KGs, investigate how to
measure, and propose methods to remediate them.
</summary>
    <author>
      <name>Edgar Meij</name>
    </author>
    <author>
      <name>Tara Safavi</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Gianluca Demartini</name>
    </author>
    <author>
      <name>Miriam Redi</name>
    </author>
    <author>
      <name>Fatma Özcan</name>
    </author>
    <link href="http://arxiv.org/abs/2007.11659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2007.11659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.01210v1</id>
    <updated>2020-09-02T17:32:37Z</updated>
    <published>2020-09-02T17:32:37Z</published>
    <title>CODO: An Ontology for Collection and Analysis of Covid-19 Data</title>
    <summary>  The COviD-19 Ontology for cases and patient information (CODO) provides a
model for the collection and analysis of data about the COVID-19 pandemic. The
ontology provides a standards-based open-source model that facilitates the
integration of data from heterogeneous data sources. The ontology was designed
by analysing disparate COVID-19 data sources such as datasets, literature,
services, etc. The ontology follows the best practices for vocabularies by
re-using concepts from other leading vocabularies and by using the W3C
standards RDF, OWL, SWRL, and SPARQL. The ontology already has one independent
user and has incorporated real-world data from the government of India.
</summary>
    <author>
      <name>B. Dutta</name>
    </author>
    <author>
      <name>M. DeBellis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5220/0010112500760085</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5220/0010112500760085" rel="related"/>
    <link href="http://arxiv.org/abs/2009.01210v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.01210v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.01860v1</id>
    <updated>2020-08-13T14:49:57Z</updated>
    <published>2020-08-13T14:49:57Z</published>
    <title>A Comprehensive Pipeline for Hotel Recommendation System</title>
    <summary>  This paper addresses a comprehensive pipeline to build a hotel recommendation
system with the raw data collected by Apps in users' smartphones. The pipeline
mainly consists of pre-processing of the raw data and training prediction
models. We use two methods, Support Vector Machine (SVM) and Recurrent Neural
Network (RNN). The results show that two methods achieved a reasonable accuracy
with the pre-processing of the raw data. Therefore, we conclude that this paper
provides a comprehensive pipeline, in which a hotel recommendation system was
successfully built from the raw data to specific applications.
</summary>
    <author>
      <name>J. Chen</name>
    </author>
    <author>
      <name>Z. Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.01860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.01860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.03668v1</id>
    <updated>2020-09-08T12:14:52Z</updated>
    <published>2020-09-08T12:14:52Z</published>
    <title>IAI MovieBot: A Conversational Movie Recommender System</title>
    <summary>  Conversational recommender systems support users in accomplishing
recommendation-related goals via multi-turn conversations. To better model
dynamically changing user preferences and provide the community with a reusable
development framework, we introduce IAI MovieBot, a conversational recommender
system for movies. It features a task-specific dialogue flow, a multi-modal
chat interface, and an effective way to deal with dynamically changing user
preferences. The system is made available open source and is operated as a
channel on Telegram.
</summary>
    <author>
      <name>Javeria Habib</name>
    </author>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3340531.3417433</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3340531.3417433" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 29th ACM International Conference on Information
  and Knowledge Management, Oct 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.03668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.03668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.07531v2</id>
    <updated>2021-03-11T09:07:44Z</updated>
    <published>2020-09-16T07:59:33Z</published>
    <title>Simplified TinyBERT: Knowledge Distillation for Document Retrieval</title>
    <summary>  Despite the effectiveness of utilizing the BERT model for document ranking,
the high computational cost of such approaches limits their uses. To this end,
this paper first empirically investigates the effectiveness of two knowledge
distillation models on the document ranking task. In addition, on top of the
recently proposed TinyBERT model, two simplifications are proposed. Evaluations
on two different and widely-used benchmarks demonstrate that Simplified
TinyBERT with the proposed simplifications not only boosts TinyBERT, but also
significantly outperforms BERT-Base when providing 15$\times$ speedup.
</summary>
    <author>
      <name>Xuanang Chen</name>
    </author>
    <author>
      <name>Ben He</name>
    </author>
    <author>
      <name>Kai Hui</name>
    </author>
    <author>
      <name>Le Sun</name>
    </author>
    <author>
      <name>Yingfei Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ECIR 2021 (short paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.07531v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.07531v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.08957v1</id>
    <updated>2020-08-30T16:05:53Z</updated>
    <published>2020-08-30T16:05:53Z</published>
    <title>Personalized TV Recommendation: Fusing User Behavior and Preferences</title>
    <summary>  In this paper, we propose a two-stage ranking approach for recommending
linear TV programs. The proposed approach first leverages user viewing patterns
regarding time and TV channels to identify potential candidates for
recommendation and then further leverages user preferences to rank these
candidates given textual information about programs. To evaluate the method, we
conduct empirical studies on a real-world TV dataset, the results of which
demonstrate the superior performance of our model in terms of both
recommendation accuracy and time efficiency.
</summary>
    <author>
      <name>Sheng-Chieh Lin</name>
    </author>
    <author>
      <name>Ting-Wei Lin</name>
    </author>
    <author>
      <name>Jing-Kai Lou</name>
    </author>
    <author>
      <name>Ming-Feng Tsai</name>
    </author>
    <author>
      <name>Chuan-Ju Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.08957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.08957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.08958v1</id>
    <updated>2020-08-28T20:23:23Z</updated>
    <published>2020-08-28T20:23:23Z</published>
    <title>Keyword Search Engine Enriched by Expert System Features</title>
    <summary>  Keyword search engines are essential elements of large information spaces.
The largest information space is the Web, and keyword search engines play
crucial role there. The advent of keyword search engines has provided a quantum
leap in the development of the Web. Since then, the Web has continued to
evolve, and keyword search systems have proven inadequate. A new quantum leap
in the development of keyword search engines is needed. This quantum leap can
be provided with more intellectual keyword search engines. The increased
intelligence of such keyword search engines can be achieved through a
combination of keyword search engines and expert systems. The paper reveals how
it can be done.
</summary>
    <author>
      <name>Olegs Verhodubs</name>
    </author>
    <link href="http://arxiv.org/abs/2009.08958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.08958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.09392v1</id>
    <updated>2020-09-20T09:22:24Z</updated>
    <published>2020-09-20T09:22:24Z</published>
    <title>Longformer for MS MARCO Document Re-ranking Task</title>
    <summary>  Two step document ranking, where the initial retrieval is done by a classical
information retrieval method, followed by neural re-ranking model, is the new
standard. The best performance is achieved by using transformer-based models as
re-rankers, e.g., BERT. We employ Longformer, a BERT-like model for long
documents, on the MS MARCO document re-ranking task. The complete code used for
training the model can be found on:
https://github.com/isekulic/longformer-marco
</summary>
    <author>
      <name>Ivan Sekulić</name>
    </author>
    <author>
      <name>Amir Soleimani</name>
    </author>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <link href="http://arxiv.org/abs/2009.09392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.09392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.10128v2</id>
    <updated>2024-04-15T14:22:57Z</updated>
    <published>2020-09-21T18:46:00Z</published>
    <title>Claraprint: a chord and melody based fingerprint for western classical
  music cover detection</title>
    <summary>  Cover song detection has been an active field in the Music Information
Retrieval (MIR) community during the past decades. Most of the research
community focused in solving it for a wide range of music genres with diverse
characteristics. Western classical music, a genre heavily based on the
recording of "cover songs", or musical works, represents a large heritage,
offering immediate application for an efficient fingerprint algorithm. We
propose an engineering approach for retrieving a cover song from a reference
database thanks to a fingerprint designed for classical musical works. We open
a new data set to encourage the scientific community to use it for further
researches regarding this genre.
</summary>
    <author>
      <name>Mickaël Arcos</name>
    </author>
    <link href="http://arxiv.org/abs/2009.10128v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.10128v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2009.11576v1</id>
    <updated>2020-09-24T09:53:25Z</updated>
    <published>2020-09-24T09:53:25Z</published>
    <title>ArXivDigest: A Living Lab for Personalized Scientific Literature
  Recommendation</title>
    <summary>  Providing personalized recommendations that are also accompanied by
explanations as to why an item is recommended is a research area of growing
importance. At the same time, progress is limited by the availability of open
evaluation resources. In this work, we address the task of scientific
literature recommendation. We present arXivDigest, which is an online service
providing personalized arXiv recommendations to end users and operates as a
living lab for researchers wishing to work on explainable scientific literature
recommendations.
</summary>
    <author>
      <name>Kristian Gingstad</name>
    </author>
    <author>
      <name>Øyvind Jekteberg</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3340531.3417417</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3340531.3417417" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 29th ACM International Conference on Information
  and Knowledge Management (CIKM'20), Oct 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2009.11576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2009.11576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.00532v1</id>
    <updated>2021-02-28T15:09:49Z</updated>
    <published>2021-02-28T15:09:49Z</published>
    <title>An Efficient Indexing and Searching Technique for Information Retrieval
  for Urdu Language</title>
    <summary>  Indexing techniques are used to improve retrieval of data in response to
certain search condition. Inverted files are mostly used for creating indexes.
This paper proposes indexing technique for Urdu language. Language processing
step in Index creation is different for a particular language. We discuss index
creation steps specifically for Urdu language. We explore morphological rules
for Urdu language and implement these rules to create Urdu stemmer. We
implement our proposed technique with different implementations and compare
results. We suggest that indexes should be created without stop words and also
index file should be an order index file.
</summary>
    <author>
      <name>Muhammad Mudassar Qureshi</name>
    </author>
    <author>
      <name>Muhammad Shoaib</name>
    </author>
    <author>
      <name> Kalsoom</name>
    </author>
    <link href="http://arxiv.org/abs/2103.00532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.00532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.00917v2</id>
    <updated>2021-03-11T22:30:50Z</updated>
    <published>2021-03-01T11:14:01Z</published>
    <title>An open-source framework for ExpFinder integrating $N$-gram Vector Space
  Model and $μ$CO-HITS</title>
    <summary>  Finding experts drives successful collaborations and high-quality product
development in academic and research domains. To contribute to the expert
finding research community, we have developed ExpFinder which is a novel
ensemble model for expert finding by integrating an $N$-gram vector space model
($n$VSM) and a graph-based model ($\mu$CO-HITS). This paper provides
descriptions of ExpFinder's architecture, key components, functionalities, and
illustrative examples. ExpFinder is an effective and competitive model for
expert finding, significantly outperforming a number of expert finding models.
</summary>
    <author>
      <name>Hung Du</name>
    </author>
    <author>
      <name>Yong-Bin Kang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, "Submitted to Software Impacts"</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.00917v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.00917v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.12420v1</id>
    <updated>2021-03-23T09:59:27Z</updated>
    <published>2021-03-23T09:59:27Z</published>
    <title>HSEarch: semantic search system for workplace accident reports</title>
    <summary>  Semantic search engines, which integrate the output of text mining (TM)
methods, can significantly increase the ease and efficiency of finding relevant
documents and locating important information within them. We present a novel
search engine for the construction industry, HSEarch
(http://www.nactem.ac.uk/hse/), which uses TM methods to provide
semantically-enhanced, faceted search over a repository of workplace accident
reports. Compared to previous TM-driven search engines for the construction
industry, HSEarch provides a more interactive means for users to explore the
contents of the repository, to review documents more systematically and to
locate relevant knowledge within them.
</summary>
    <author>
      <name>Emrah Inan</name>
    </author>
    <author>
      <name>Paul Thompson</name>
    </author>
    <author>
      <name>Tim Yates</name>
    </author>
    <author>
      <name>Sophia Ananiadou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to appear in ECIR 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.12420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.12420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.12982v1</id>
    <updated>2021-03-24T04:37:32Z</updated>
    <published>2021-03-24T04:37:32Z</published>
    <title>From Semantic Retrieval to Pairwise Ranking: Applying Deep Learning in
  E-commerce Search</title>
    <summary>  We introduce deep learning models to the two most important stages in product
search at JD.com, one of the largest e-commerce platforms in the world.
Specifically, we outline the design of a deep learning system that retrieves
semantically relevant items to a query within milliseconds, and a pairwise deep
re-ranking system, which learns subtle user preferences. Compared to
traditional search systems, the proposed approaches are better at semantic
retrieval and personalized ranking, achieving significant improvements.
</summary>
    <author>
      <name>Rui Li</name>
    </author>
    <author>
      <name>Yunjiang Jiang</name>
    </author>
    <author>
      <name>Wenyun Yang</name>
    </author>
    <author>
      <name>Guoyu Tang</name>
    </author>
    <author>
      <name>Songlin Wang</name>
    </author>
    <author>
      <name>Chaoyi Ma</name>
    </author>
    <author>
      <name>Wei He</name>
    </author>
    <author>
      <name>Xi Xiong</name>
    </author>
    <author>
      <name>Yun Xiao</name>
    </author>
    <author>
      <name>Eric Yihong Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in SIGIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2103.12982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.12982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.13235v1</id>
    <updated>2021-03-24T14:54:01Z</updated>
    <published>2021-03-24T14:54:01Z</published>
    <title>Web Mining for Estimating Regulatory Blockchain Readiness</title>
    <summary>  The regulatory framework of cryptocurrencies (and, in general, blockchain
tokens) is of paramount importance. This framework drives nearly all key
decisions in the respective business areas. In this work, a computational model
is proposed for quantitatively estimating the regulatory stance of countries
with respect to cryptocurrencies. This is conducted via web mining utilizing
web search engines. The proposed model is experimentally validated. In
addition, unsupervised learning (clustering) is applied for better analyzing
the automatically derived estimations. Overall, very good performance is
achieved by the proposed algorithmic approach.
</summary>
    <author>
      <name>Elias Iosif</name>
    </author>
    <author>
      <name>Klitos Christodoulou</name>
    </author>
    <author>
      <name>Andreas Vlachos</name>
    </author>
    <link href="http://arxiv.org/abs/2103.13235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.13235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2103.14934v1</id>
    <updated>2021-03-27T16:00:05Z</updated>
    <published>2021-03-27T16:00:05Z</published>
    <title>Community-based Cyberreading for Information Understanding</title>
    <summary>  Although the content in scientific publications is increasingly challenging,
it is necessary to investigate another important problem, that of scientific
information understanding. For this proposed problem, we investigate novel
methods to assist scholars (readers) to better understand scientific
publications by enabling physical and virtual collaboration. For physical
collaboration, an algorithm will group readers together based on their profiles
and reading behavior, and will enable the cyberreading collaboration within a
online reading group. For virtual collaboration, instead of pushing readers to
communicate with others, we cluster readers based on their estimated
information needs. For each cluster, a learning to rank model will be generated
to recommend readers' communitized resources (i.e., videos, slides, and wikis)
to help them understand the target publication.
</summary>
    <author>
      <name>Zhuoren Jiang</name>
    </author>
    <author>
      <name>Xiaozhong Liu</name>
    </author>
    <author>
      <name>Liangcai Gao</name>
    </author>
    <author>
      <name>Zhi Tang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2103.14934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2103.14934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2105.05389v1</id>
    <updated>2021-05-12T01:24:28Z</updated>
    <published>2021-05-12T01:24:28Z</published>
    <title>Co-Factorization Model for Collaborative Filtering with Session-based
  Data</title>
    <summary>  Matrix factorization (MF) is a common method for collaborative filtering. MF
represents user preferences and item attributes by latent factors. Despite that
MF is a powerful method, it suffers from not be able to identifying strong
associations of closely related items. In this work, we propose a method for
matrix factorization that can reflect the localized relationships between
strong related items into the latent representations of items. We do it by
combine two worlds: MF for collaborative filtering and item2vec for
item-embedding. The proposed method is able to exploit item-item relations. Our
experiments on several datasets demonstrates a better performance with the
previous work.
</summary>
    <author>
      <name>Binh Nguyen</name>
    </author>
    <author>
      <name>Atsuhiro Takasu</name>
    </author>
    <link href="http://arxiv.org/abs/2105.05389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2105.05389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.02010v2</id>
    <updated>2015-09-26T15:16:54Z</updated>
    <published>2015-09-07T12:36:19Z</published>
    <title>LocLinkVis: A Geographic Information Retrieval-Based System for
  Large-Scale Exploratory Search</title>
    <summary>  In this paper we present LocLinkVis (Locate-Link-Visualize); a system which
supports exploratory information access to a document collection based on
geo-referencing and visualization. It uses a gazetteer which contains
representations of places ranging from countries to buildings, and that is used
to recognize toponyms, disambiguate them into places, and to visualize the
resulting spatial footprints.
</summary>
    <author>
      <name>Alex Olieman</name>
    </author>
    <author>
      <name>Jaap Kamps</name>
    </author>
    <author>
      <name>Rosa Merino Claros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SEM'15</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. Posters and Demos Track of 11th Int. Conf. on Semantic
  Systems (2015) 30-33</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.02010v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.02010v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09522v1</id>
    <updated>2016-03-31T10:50:50Z</updated>
    <published>2016-03-31T10:50:50Z</published>
    <title>Image Retrieval with a Bayesian Model of Relevance Feedback</title>
    <summary>  A content-based image retrieval system based on multinomial relevance
feedback is proposed. The system relies on an interactive search paradigm where
at each round a user is presented with k images and selects the one closest to
their ideal target. Two approaches, one based on the Dirichlet distribution and
one based the Beta distribution, are used to model the problem motivating an
algorithm that trades exploration and exploitation in presenting the images in
each round. Experimental results show that the new approach compares favourably
with previous work.
</summary>
    <author>
      <name>Dorota Glowacka</name>
    </author>
    <author>
      <name>Yee Whye Teh</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <link href="http://arxiv.org/abs/1603.09522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04624v1</id>
    <updated>2016-05-16T00:59:07Z</updated>
    <published>2016-05-16T00:59:07Z</published>
    <title>Learning to Rank Personalized Search Results in Professional Networks</title>
    <summary>  LinkedIn search is deeply personalized - for the same queries, different
searchers expect completely different results. This paper presents our approach
to achieving this by mining various data sources available in LinkedIn to infer
searchers' intents (such as hiring, job seeking, etc.), as well as extending
the concept of homophily to capture the searcher-result similarities on many
aspects. Then, learning-to-rank (LTR) is applied to combine these signals with
standard search features.
</summary>
    <author>
      <name>Viet Ha-Thuc</name>
    </author>
    <author>
      <name>Shakti Sinha</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1605.04624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05369v1</id>
    <updated>2016-05-17T21:10:07Z</updated>
    <published>2016-05-17T21:10:07Z</published>
    <title>Audio Features Affected by Music Expressiveness</title>
    <summary>  Within a Music Information Retrieval perspective, the goal of the study
presented here is to investigate the impact on sound features of the musician's
affective intention, namely when trying to intentionally convey emotional
contents via expressiveness. A preliminary experiment has been performed
involving $10$ tuba players. The recordings have been analysed by extracting a
variety of features, which have been subsequently evaluated by combining both
classic and machine learning statistical techniques. Results are reported and
discussed.
</summary>
    <author>
      <name>Alberto Introini</name>
    </author>
    <author>
      <name>Giorgio Presti</name>
    </author>
    <author>
      <name>Giuseppe Boccignone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM SIGIR Conference on Research and Development in
  Information Retrieval (SIGIR 2016), Pisa, Italy, July 17-21, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07891v2</id>
    <updated>2016-06-23T00:46:06Z</updated>
    <published>2016-05-25T14:09:00Z</published>
    <title>Query Expansion with Locally-Trained Word Embeddings</title>
    <summary>  Continuous space word embeddings have received a great deal of attention in
the natural language processing and machine learning communities for their
ability to model term similarity and other relationships. We study the use of
term relatedness in the context of query expansion for ad hoc information
retrieval. We demonstrate that word embeddings such as word2vec and GloVe, when
trained globally, underperform corpus and query specific embeddings for
retrieval tasks. These results suggest that other tasks benefiting from global
embeddings may also benefit from local embeddings.
</summary>
    <author>
      <name>Fernando Diaz</name>
    </author>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/1605.07891v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07891v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00223v2</id>
    <updated>2024-11-18T07:36:40Z</updated>
    <published>2016-07-01T12:45:43Z</published>
    <title>Memory Based Collaborative Filtering with Lucene</title>
    <summary>  Memory Based Collaborative Filtering is a widely used approach to provide
recommendations. It exploits similarities between ratings across a population
of users by forming a weighted vote to predict unobserved ratings. Bespoke
solutions are frequently adopted to deal with the problem of high quality
recommendations on large data sets. A disadvantage of this approach, however,
is the loss of generality and flexibility of the general collaborative
filtering systems. In this paper, we have developed a methodology that allows
one to build a scalable and effective collaborative filtering system on top of
a conventional full-text search engine such as Apache Lucene.
</summary>
    <author>
      <name>Claudio Gennaro</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00223v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00223v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02641v1</id>
    <updated>2016-07-09T18:10:06Z</updated>
    <published>2016-07-09T18:10:06Z</published>
    <title>Randomised Relevance Model</title>
    <summary>  Relevance Models are well-known retrieval models and capable of producing
competitive results. However, because they use query expansion they can be very
slow. We address this slowness by incorporating two variants of locality
sensitive hashing (LSH) into the query expansion process. Results on two
document collections suggest that we can obtain large reductions in the amount
of work, with a small reduction in effectiveness. Our approach is shown to be
additive when pruning query terms.
</summary>
    <author>
      <name>Dominik Wurzer</name>
    </author>
    <author>
      <name>Miles Osborne</name>
    </author>
    <author>
      <name>Victor Lavrenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Information Retrieval, Query Expansion, Locality Sensitive Hashing,
  Randomized Algorithm, Relevance Model</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02754v1</id>
    <updated>2016-07-10T15:32:03Z</updated>
    <published>2016-07-10T15:32:03Z</published>
    <title>Hybrid Recommender System Based on Personal Behavior Mining</title>
    <summary>  Recommender systems are mostly well known for their applications in
e-commerce sites and are mostly static models. Classical personalized
recommender algorithm includes item-based collaborative filtering method
applied in Amazon, matrix factorization based collaborative filtering algorithm
from Netflix, etc. In this article, we hope to combine traditional model with
behavior pattern extraction method. We use desensitized mobile transaction
record provided by T-mall, Alibaba to build a hybrid dynamic recommender
system. The sequential pattern mining aims to find frequent sequential pattern
in sequence database and is applied in this hybrid model to predict customers'
payment behavior thus contributing to the accuracy of the model.
</summary>
    <author>
      <name>Zhiyuan Fang</name>
    </author>
    <author>
      <name>Lingqi Zhang</name>
    </author>
    <author>
      <name>Kun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03296v1</id>
    <updated>2016-07-12T10:15:15Z</updated>
    <published>2016-07-12T10:15:15Z</published>
    <title>Implicit Negative Feedback in Clinical Information Retrieval</title>
    <summary>  In this paper, we reflect on ways to improve the quality of bio-medical
information retrieval by drawing implicit negative feedback from negated
information in noisy natural language search queries. We begin by studying the
extent to which negations occur in clinical texts and quantify their
detrimental effect on retrieval performance. Subsequently, we present a number
of query reformulation and ranking approaches that remedy these shortcomings by
resolving natural language negations. Our experimental results are based on
data collected in the course of the TREC Clinical Decision Support Track and
show consistent improvements compared to state-of-the-art methods. Using our
novel algorithms, we are able to reduce the negative impact of negations on
early precision by up to 65%.
</summary>
    <author>
      <name>Lorenz Kuhn</name>
    </author>
    <author>
      <name>Carsten Eickhoff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2911451.2917761</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2911451.2917761" rel="related"/>
    <link href="http://arxiv.org/abs/1607.03296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07326v1</id>
    <updated>2016-07-25T15:54:07Z</updated>
    <published>2016-07-25T15:54:07Z</published>
    <title>Meta-Prod2Vec - Product Embeddings Using Side-Information for
  Recommendation</title>
    <summary>  We propose Meta-Prod2vec, a novel method to compute item similarities for
recommendation that leverages existing item metadata. Such scenarios are
frequently encountered in applications such as content recommendation, ad
targeting and web search. Our method leverages past user interactions with
items and their attributes to compute low-dimensional embeddings of items.
Specifically, the item metadata is in- jected into the model as side
information to regularize the item embeddings. We show that the new item
representa- tions lead to better performance on recommendation tasks on an open
music dataset.
</summary>
    <author>
      <name>Flavian Vasile</name>
    </author>
    <author>
      <name>Elena Smirnova</name>
    </author>
    <author>
      <name>Alexis Conneau</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2959100.2959160</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2959100.2959160" rel="related"/>
    <link href="http://arxiv.org/abs/1607.07326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00894v1</id>
    <updated>2017-05-02T10:35:12Z</updated>
    <published>2017-05-02T10:35:12Z</published>
    <title>Talking Open Data</title>
    <summary>  Enticing users into exploring Open Data remains an important challenge for
the whole Open Data paradigm. Standard stock interfaces often used by Open Data
portals are anything but inspiring even for tech-savvy users, let alone those
without an articulated interest in data science. To address a broader range of
citizens, we designed an open data search interface supporting natural language
interactions via popular platforms like Facebook and Skype. Our data-aware
chatbot answers search requests and suggests relevant open datasets, bringing
fun factor and a potential of viral dissemination into Open Data exploration.
The current system prototype is available for Facebook
(https://m.me/OpenDataAssistant) and Skype
(https://join.skype.com/bot/6db830ca-b365-44c4-9f4d-d423f728e741) users.
</summary>
    <author>
      <name>Sebastian Neumaier</name>
    </author>
    <author>
      <name>Vadim Savenkov</name>
    </author>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ESWC2017 demo track</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.00894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.04803v1</id>
    <updated>2017-05-13T09:06:52Z</updated>
    <published>2017-05-13T09:06:52Z</published>
    <title>Benchmark for Complex Answer Retrieval</title>
    <summary>  Retrieving paragraphs to populate a Wikipedia article is a challenging task.
The new TREC Complex Answer Retrieval (TREC CAR) track introduces a
comprehensive dataset that targets this retrieval scenario. We present early
results from a variety of approaches -- from standard information retrieval
methods (e.g., tf-idf) to complex systems that using query expansion using
knowledge bases and deep neural networks. The goal is to offer future
participants of this track an overview of some promising approaches to tackle
this problem.
</summary>
    <author>
      <name>Federico Nanni</name>
    </author>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Matt Magnusson</name>
    </author>
    <author>
      <name>Laura Dietz</name>
    </author>
    <link href="http://arxiv.org/abs/1705.04803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.04803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06056v2</id>
    <updated>2017-07-27T09:52:55Z</updated>
    <published>2017-05-17T09:06:42Z</published>
    <title>Target Type Identification for Entity-Bearing Queries</title>
    <summary>  Identifying the target types of entity-bearing queries can help improve
retrieval performance as well as the overall search experience. In this work,
we address the problem of automatically detecting the target types of a query
with respect to a type taxonomy. We propose a supervised learning approach with
a rich variety of features. Using a purpose-built test collection, we show that
our approach outperforms existing methods by a remarkable margin. This is an
extended version of the article published with the same title in the
Proceedings of SIGIR'17.
</summary>
    <author>
      <name>Darío Garigliotti</name>
    </author>
    <author>
      <name>Faegheh Hasibi</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3077136.3080659</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3077136.3080659" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of SIGIR'17 short paper, 5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.06056v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06056v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06504v2</id>
    <updated>2017-08-30T11:47:45Z</updated>
    <published>2017-05-18T10:08:38Z</published>
    <title>TableQA: Question Answering on Tabular Data</title>
    <summary>  Tabular data is difficult to analyze and to search through, yielding for new
tools and interfaces that would allow even non tech-savvy users to gain
insights from open datasets without resorting to specialized data analysis
tools or even without having to fully understand the dataset structure. The
goal of our demonstration is to showcase answering natural language questions
from tabular data, and to discuss related system configuration and model
training aspects. Our prototype is publicly available and open-sourced (see
https://svakulenko.ai.wu.ac.at/tableqa).
</summary>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <author>
      <name>Vadim Savenkov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version of the demo paper accepted at SEMANTiCS 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.06504v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06504v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07311v1</id>
    <updated>2017-05-20T14:21:02Z</updated>
    <published>2017-05-20T14:21:02Z</published>
    <title>Personalized Ranking for Context-Aware Venue Suggestion</title>
    <summary>  Making personalized and context-aware suggestions of venues to the users is
very crucial in venue recommendation. These suggestions are often based on
matching the venues' features with the users' preferences, which can be
collected from previously visited locations. In this paper we present a novel
user-modeling approach which relies on a set of scoring functions for making
personalized suggestions of venues based on venues content and reviews as well
as users context. Our experiments, conducted on the dataset of the TREC
Contextual Suggestion Track, prove that our methodology outperforms
state-of-the-art approaches by a significant margin.
</summary>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Ida Mele</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 32nd ACM SIGAPP Symposium On Applied Computing (SAC), Marrakech,
  Morocco, April 4-6, 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.07311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08154v1</id>
    <updated>2017-05-23T09:36:41Z</updated>
    <published>2017-05-23T09:36:41Z</published>
    <title>Reference String Extraction Using Line-Based Conditional Random Fields</title>
    <summary>  The extraction of individual reference strings from the reference section of
scientific publications is an important step in the citation extraction
pipeline. Current approaches divide this task into two steps by first detecting
the reference section areas and then grouping the text lines in such areas into
reference strings. We propose a classification model that considers every line
in a publication as a potential part of a reference string. By applying
line-based conditional random fields rather than constructing the graphical
model based on the individual words, dependencies and patterns that are typical
in reference sections provide strong features while the overall complexity of
the model is reduced.
</summary>
    <author>
      <name>Martin Körner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.08154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08321v1</id>
    <updated>2017-05-02T17:04:42Z</updated>
    <published>2017-05-02T17:04:42Z</published>
    <title>Increasing Papers' Discoverability with Precise Semantic Labeling: the
  sci.AI Platform</title>
    <summary>  The number of published findings in biomedicine increases continually. At the
same time, specifics of the domain's terminology complicates the task of
relevant publications retrieval. In the current research, we investigate
influence of terms' variability and ambiguity on a paper's likelihood of being
retrieved. We obtained statistics that demonstrate significance of the issue
and its challenges, followed by presenting the sci.AI platform, which allows
precise terms labeling as a resolution.
</summary>
    <author>
      <name>Roman Gurinovich</name>
    </author>
    <author>
      <name>Alexander Pashuk</name>
    </author>
    <author>
      <name>Yuriy Petrovskiy</name>
    </author>
    <author>
      <name>Alex Dmitrievskij</name>
    </author>
    <author>
      <name>Oleg Kuryan</name>
    </author>
    <author>
      <name>Alexei Scerbacov</name>
    </author>
    <author>
      <name>Antonia Tiggre</name>
    </author>
    <author>
      <name>Elena Moroz</name>
    </author>
    <author>
      <name>Yuri Nikolsky</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08804v2</id>
    <updated>2017-11-30T21:11:25Z</updated>
    <published>2017-05-24T14:52:06Z</published>
    <title>Beyond Parity: Fairness Objectives for Collaborative Filtering</title>
    <summary>  We study fairness in collaborative-filtering recommender systems, which are
sensitive to discrimination that exists in historical data. Biased data can
lead collaborative-filtering methods to make unfair predictions for users from
minority groups. We identify the insufficiency of existing fairness metrics and
propose four new metrics that address different forms of unfairness. These
fairness metrics can be optimized by adding fairness terms to the learning
objective. Experiments on synthetic and real data show that our new metrics can
better measure fairness than the baseline, and that the fairness objectives
effectively help reduce unfairness.
</summary>
    <author>
      <name>Sirui Yao</name>
    </author>
    <author>
      <name>Bert Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08804v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08804v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.01264v1</id>
    <updated>2017-12-02T22:34:25Z</updated>
    <published>2017-12-02T22:34:25Z</published>
    <title>A Context-aware Recommender System for Hyperlocal News: A Conceptual
  Framework</title>
    <summary>  Recommender systems (RSs) have been popular in variety of application domains
due to the increased demand for filtering and sorting items and information.
Today, there is a numerous approaches and algorithms of data filtering and
recommendations. This works presents a conceptual framework for constructing a
mobile RS in hyper-local news domain. The mobile RS is designed to deal with
specific requirements of news readers, such as spatial- temporal relevance,
recency, real-time update and validated news. The implementation of the RS in a
distributed file system is also discussed.
</summary>
    <author>
      <name>Anh Nguyen Duc</name>
    </author>
    <author>
      <name>Hilde Gudvangen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the author's version of the work, Norwegian Big Data
  Symposium (NOBIDS) 2016, Trondheim, Norway</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.01264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.01264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.04671v1</id>
    <updated>2017-12-13T09:25:50Z</updated>
    <published>2017-12-13T09:25:50Z</published>
    <title>Everything You Always Wanted to Know About TREC RTS* (*But Were Afraid
  to Ask)</title>
    <summary>  The TREC Real-Time Summarization (RTS) track provides a framework for
evaluating systems monitoring the Twitter stream and pushing tweets to users
according to given profiles. It includes metrics, files, settings and
hypothesis provided by the organizers. In this work, we perform a thorough
analysis of each component of the framework used in 2016 and 2017 and found
some limitations for the Scenario A of this track. Our main findings point out
the weakness of the metrics and give clear recommendations to fairly reuse the
collection.
</summary>
    <author>
      <name>Gilles Hubert</name>
    </author>
    <author>
      <name>Jose G. Moreno</name>
    </author>
    <author>
      <name>Karen Pinel-Sauvagnat</name>
    </author>
    <author>
      <name>Yoann Pitarch</name>
    </author>
    <link href="http://arxiv.org/abs/1712.04671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.04671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.06921v1</id>
    <updated>2017-12-19T13:39:52Z</updated>
    <published>2017-12-19T13:39:52Z</published>
    <title>Ensemble Models for Detecting Wikidata Vandalism with Stacking - Team
  Honeyberry Vandalism Detector at WSDM Cup 2017</title>
    <summary>  The WSDM Cup 2017 is a binary classification task for classifying Wikidata
revisions into vandalism and non-vandalism. This paper describes our method
using some machine learning techniques such as under-sampling, feature
selection, stacking and ensembles of models. We confirm the validity of each
technique by calculating AUC-ROC of models using such techniques and not using
them. Additionally, we analyze the results and gain useful insights into
improving models for the vandalism detection task. The AUC-ROC of our final
submission after the deadline resulted in 0.94412.
</summary>
    <author>
      <name>Tomoya Yamazaki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo Japan Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Mei Sasaki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo Japan Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Naoya Murakami</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo Japan Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Takuya Makabe</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo Japan Corporation</arxiv:affiliation>
    </author>
    <author>
      <name>Hiroki Iwasawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo Japan Corporation</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.06921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.06921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.08353v1</id>
    <updated>2017-12-22T09:05:32Z</updated>
    <published>2017-12-22T09:05:32Z</published>
    <title>Relevance Score of Triplets Using Knowledge Graph Embedding - The
  Pigweed Triple Scorer at WSDM Cup 2017</title>
    <summary>  Collaborative Knowledge Bases such as Freebase and Wikidata mention multiple
professions and nationalities for a particular entity. The goal of the WSDM Cup
2017 Triplet Scoring Challenge was to calculate relevance scores between an
entity and its professions/nationalities. Such scores are a fundamental
ingredient when ranking results in entity search. This paper proposes a novel
approach to ensemble an advanced Knowledge Graph Embedding Model with a simple
bag-of-words model. The former deals with hidden pragmatics and deep semantics
whereas the latter handles text-based retrieval and low-level semantics.
</summary>
    <author>
      <name>Vibhor Kanojia</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo! Japan</arxiv:affiliation>
    </author>
    <author>
      <name>Riku Togashi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo! Japan</arxiv:affiliation>
    </author>
    <author>
      <name>Hideyuki Maeda</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yahoo! Japan</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.08353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.08353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.08354v1</id>
    <updated>2017-12-22T09:06:04Z</updated>
    <published>2017-12-22T09:06:04Z</published>
    <title>Supervised Ranking of Triples for Type-Like Relations - The Cress Triple
  Scorer at the WSDM Cup 2017</title>
    <summary>  This paper describes our participation in the Triple Scoring task of WSDM Cup
2017, which aims at ranking triples from a knowledge base for two type-like
relations: profession and nationality. We introduce a supervised ranking method
along with the features we designed for this task. Our system has been top
ranked with respect to average score difference and 2nd best in terms of
Kendall's tau.
</summary>
    <author>
      <name>Faegheh Hasibi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTNU Trondheim</arxiv:affiliation>
    </author>
    <author>
      <name>Darío Garigliotti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Stavanger</arxiv:affiliation>
    </author>
    <author>
      <name>Shuo Zhang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Stavanger</arxiv:affiliation>
    </author>
    <author>
      <name>Krisztian Balog</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Stavanger</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.08354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.08354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1712.08356v1</id>
    <updated>2017-12-22T09:08:34Z</updated>
    <published>2017-12-22T09:08:34Z</published>
    <title>Leveraging Text and Knowledge Bases for Triple Scoring: An Ensemble
  Approach - The BOKCHOY Triple Scorer at WSDM Cup 2017</title>
    <summary>  We present our winning solution for the WSDM Cup 2017 triple scoring task. We
devise an ensemble of four base scorers, so as to leverage the power of both
text and knowledge bases for that task. Then we further refine the outputs of
the ensemble by trigger word detection, achieving even better predictive
accuracy. The code is available at https://github.com/wsdm-cup-2017/bokchoy.
</summary>
    <author>
      <name>Boyang Ding</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chinese Academy of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Quan Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chinese Academy of Sciences</arxiv:affiliation>
    </author>
    <author>
      <name>Bin Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chinese Academy of Sciences</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Triple Scorer at WSDM Cup 2017, see arXiv:1712.08081</arxiv:comment>
    <link href="http://arxiv.org/abs/1712.08356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1712.08356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.05382v3</id>
    <updated>2018-12-05T14:55:44Z</updated>
    <published>2018-02-15T01:53:59Z</published>
    <title>Popularity-Aware Item Weighting for Long-Tail Recommendation</title>
    <summary>  Many recommender systems suffer from the popularity bias problem: popular
items are being recommended frequently while less popular, niche products, are
recommended rarely if not at all. However, those ignored products are exactly
the products that businesses need to find customers for and their
recommendations would be more beneficial. In this paper, we examine an item
weighting approach to improve long-tail recommendation. Our approach works as a
simple yet powerful add-on to existing recommendation algorithms for making a
tunable trade-off between accuracy and long-tail coverage.
</summary>
    <author>
      <name>Himan Abdollahpouri</name>
    </author>
    <author>
      <name>Robin Burke</name>
    </author>
    <author>
      <name>Bamshad Mobasher</name>
    </author>
    <link href="http://arxiv.org/abs/1802.05382v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.05382v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1802.06892v1</id>
    <updated>2018-02-19T22:29:50Z</updated>
    <published>2018-02-19T22:29:50Z</published>
    <title>Real World Evaluation of Approaches to Research Paper Recommendation</title>
    <summary>  In this work, we have identified the need for choosing baseline approaches
for research-paper recommendation systems. Following a literature survey of all
research paper recommendation approaches described over the last four years, we
framed criteria that makes for a well-rounded set of baselines. These are
implemented on Mr. DLib a literature recommendation platform. User click data
was collected as part of an ongoing experiment in collaboration with our
partner Gesis. We reported the results from our evaluation for the experiments.
We will be able to draw clearer conclusions as time passes. We find that a term
based similarity search performs better than keyword based approaches. These
results are a good starting point in finding performance improvements for
related document searches.
</summary>
    <author>
      <name>Siddharth Dinesh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Combined BE/MSc Thesis - BITS Pilani Goa</arxiv:comment>
    <link href="http://arxiv.org/abs/1802.06892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1802.06892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.03713v1</id>
    <updated>2018-04-10T20:47:22Z</updated>
    <published>2018-04-10T20:47:22Z</published>
    <title>Report on the 7th International Workshop on Bibliometric-enhanced
  Information Retrieval (BIR 2018)</title>
    <summary>  The Bibliometric-enhanced Information Retrieval (BIR) workshop series has
started at ECIR in 2014 and serves as the annual gathering of IR researchers
who address various information-related tasks on scientific corpora and
bibliometrics. We welcome contributions elaborating on dedicated IR systems, as
well as studies revealing original characteristics on how scientific knowledge
is created, communicated, and used. This report presents all accepted papers at
the 7th BIR workshop at ECIR 2018 in Grenoble, France.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Ingo Frommholz</name>
    </author>
    <author>
      <name>Guillaume Cabanac</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.03713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.03713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.04410v2</id>
    <updated>2018-08-18T13:05:12Z</updated>
    <published>2018-04-12T10:22:28Z</published>
    <title>Optimizing Query Evaluations using Reinforcement Learning for Web Search</title>
    <summary>  In web search, typically a candidate generation step selects a small set of
documents---from collections containing as many as billions of web pages---that
are subsequently ranked and pruned before being presented to the user. In Bing,
the candidate generation involves scanning the index using statically designed
match plans that prescribe sequences of different match criteria and stopping
conditions. In this work, we pose match planning as a reinforcement learning
task and observe up to 20% reduction in index blocks accessed, with small or no
degradation in the quality of the candidate sets.
</summary>
    <author>
      <name>Corby Rosset</name>
    </author>
    <author>
      <name>Damien Jose</name>
    </author>
    <author>
      <name>Gargi Ghosh</name>
    </author>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Saurabh Tiwary</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM SIGIR 2018 short paper (pre-print)</arxiv:comment>
    <link href="http://arxiv.org/abs/1804.04410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.04410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.09943v1</id>
    <updated>2018-04-26T08:52:19Z</updated>
    <published>2018-04-26T08:52:19Z</published>
    <title>System Description of CITlab's Recognition &amp; Retrieval Engine for
  ICDAR2017 Competition on Information Extraction in Historical Handwritten
  Records</title>
    <summary>  We present a recognition and retrieval system for the ICDAR2017 Competition
on Information Extraction in Historical Handwritten Records which successfully
infers person names and other data from marriage records. The system extracts
information from the line images with a high accuracy and outperforms the
baseline. The optical model is based on Neural Networks. To infer the desired
information, regular expressions are used to describe the set of feasible words
sequences.
</summary>
    <author>
      <name>Tobias Strauß</name>
    </author>
    <author>
      <name>Max Weidemann</name>
    </author>
    <author>
      <name>Johannes Michael</name>
    </author>
    <author>
      <name>Gundram Leifert</name>
    </author>
    <author>
      <name>Tobias Grüning</name>
    </author>
    <author>
      <name>Roger Labahn</name>
    </author>
    <link href="http://arxiv.org/abs/1804.09943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.09943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1804.11335v1</id>
    <updated>2018-04-26T02:47:08Z</updated>
    <published>2018-04-26T02:47:08Z</published>
    <title>A Hybrid Recommendation Method Based on Feature for Offline Book
  Personalization</title>
    <summary>  Recommendation system has been widely used in different areas. Collaborative
filtering focuses on rating, ignoring the features of items itself. In order to
effectively evaluate customers preferences on books, taking into consideration
of the characteristics of offline book retail, we use LDA model to calculate
customers preference on book topics and use word2vec to calculate customers
preference on book types. When forecasting rating on books, we take two factors
into consideration: similarity of customers and correlation between customers
and books. The experiment shows that our hybrid recommendation method based on
features performances better than single recommendation method in offline book
retail data.
</summary>
    <author>
      <name>Xixi Li</name>
    </author>
    <author>
      <name>Jiahao Xing</name>
    </author>
    <author>
      <name>Haihui Wang</name>
    </author>
    <author>
      <name>Lingfang Zheng</name>
    </author>
    <author>
      <name>Suling Jia</name>
    </author>
    <author>
      <name>Qiang Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1804.11335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.11335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.00692v1</id>
    <updated>2018-06-29T13:55:44Z</updated>
    <published>2018-06-29T13:55:44Z</published>
    <title>Grapevine: A Wine Prediction Algorithm Using Multi-dimensional
  Clustering Methods</title>
    <summary>  We present a method for a wine recommendation system that employs
multidimensional clustering and unsupervised learning methods. Our algorithm
first performs clustering on a large corpus of wine reviews. It then uses the
resulting wine clusters as an approximation of the most common flavor palates,
recommending a user a wine by optimizing over a price-quality ratio within
clusters that they demonstrated a preference for.
</summary>
    <author>
      <name>Richard Diehl Martinez</name>
    </author>
    <author>
      <name>Geoffrey Angus</name>
    </author>
    <author>
      <name>Rooz Mahdavian</name>
    </author>
    <link href="http://arxiv.org/abs/1807.00692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.00692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.02039v1</id>
    <updated>2018-07-05T14:58:32Z</updated>
    <published>2018-07-05T14:58:32Z</published>
    <title>Towards a simplified ontology for better e-commerce search</title>
    <summary>  Query Understanding is a semantic search method that can classify tokens in a
customer's search query to entities such as Product, Brand, etc. This method
can overcome the limitations of bag-of-words methods but requires an ontology.
We show that current ontologies are not optimized for search and propose a
simplified ontology framework designed specifically for e-commerce search and
retrieval. We also present three methods for automatically extracting product
classes for the proposed ontology and compare their performance relative to
each other.
</summary>
    <author>
      <name>Aliasgar Kutiyanawala</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">John</arxiv:affiliation>
    </author>
    <author>
      <name>Prateek Verma</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">John</arxiv:affiliation>
    </author>
    <author>
      <name> Zheng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">John</arxiv:affiliation>
    </author>
    <author>
      <name> Yan</name>
    </author>
    <link href="http://arxiv.org/abs/1807.02039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.02039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.03719v1</id>
    <updated>2018-06-28T14:20:30Z</updated>
    <published>2018-06-28T14:20:30Z</published>
    <title>Peerus Review: a tool for scientific experts finding</title>
    <summary>  We propose a tool for experts finding applied to academic data generated by
the start-up DSRT in the context of its application Peerus. A user may submit
the title, the abstract and optionnally the authors and the journal of
publication of a scientific article and the application then returns a list of
experts, potential reviewers of the submitted article. The retrieval algorithm
is a voting system based on a language modeling technique trained on several
millions of scientific papers.
</summary>
    <author>
      <name>Robin Brochier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ERIC</arxiv:affiliation>
    </author>
    <author>
      <name>Adrien Guille</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ERIC</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Velcin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ERIC</arxiv:affiliation>
    </author>
    <author>
      <name>Benjamin Rothan</name>
    </author>
    <author>
      <name>Di Cioccio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EGC 2018, Jan 2018, Paris, France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1807.03719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.03719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.05576v1</id>
    <updated>2018-07-15T17:08:45Z</updated>
    <published>2018-07-15T17:08:45Z</published>
    <title>Semantic Search by Latent Ontological Features</title>
    <summary>  Both named entities and keywords are important in defining the content of a
text in which they occur. In particular, people often use named entities in
information search. However, named entities have ontological features, namely,
their aliases, classes, and identifiers, which are hidden from their textual
appearance. We propose ontology-based extensions of the traditional Vector
Space Model that explore different combinations of those latent ontological
features with keywords for text retrieval. Our experiments on benchmark
datasets show better search quality of the proposed models as compared to the
purely keyword-based model, and their advantages for both text retrieval and
representation of documents and queries.
</summary>
    <author>
      <name>Tru H. Cao</name>
    </author>
    <author>
      <name>Vuong M. Ngo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, Accept by New Generation Computing (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.05576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.05576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.05906v1</id>
    <updated>2018-07-16T15:02:38Z</updated>
    <published>2018-07-16T15:02:38Z</published>
    <title>Human Perception of Surprise: A User Study</title>
    <summary>  Understanding how to engage users is a critical question in many
applications. Previous research has shown that unexpected or astonishing events
can attract user attention, leading to positive outcomes such as engagement and
learning. In this work, we investigate the similarity and differences in how
people and algorithms rank the surprisingness of facts. Our crowdsourcing
study, involving 106 participants, shows that computational models of surprise
can be used to artificially induce surprise in humans.
</summary>
    <author>
      <name>Nalin Chhibber</name>
    </author>
    <author>
      <name>Rohail Syed</name>
    </author>
    <author>
      <name>Mengqiu Teng</name>
    </author>
    <author>
      <name>Joslin Goh</name>
    </author>
    <author>
      <name>Kevyn Collins-Thompson</name>
    </author>
    <author>
      <name>Edith Law</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages. Presented at Computational Surprise Workshop, SIGIR 2018
  (Michigan)</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.05906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.05906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.07966v1</id>
    <updated>2018-07-20T10:30:26Z</updated>
    <published>2018-07-20T10:30:26Z</published>
    <title>Exploring Combinations of Ontological Features and Keywords for Text
  Retrieval</title>
    <summary>  Named entities have been considered and combined with keywords to enhance
information retrieval performance. However, there is not yet a formal and
complete model that takes into account entity names, classes, and identifiers
together. Our work explores various adaptations of the traditional Vector Space
Model that combine different ontological features with keywords, and in
different ways. It shows better performance of the proposed models as compared
to the keyword-based Lucene, and their advantages for both text retrieval and
representation of documents and queries.
</summary>
    <author>
      <name>Tru H. Cao</name>
    </author>
    <author>
      <name>Khanh C. Le</name>
    </author>
    <author>
      <name>Vuong M. Ngo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, will be in PRICAI. arXiv admin note: substantial text
  overlap with arXiv:1807.05576</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.07966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.07966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1807.09754v1</id>
    <updated>2018-07-12T23:17:05Z</updated>
    <published>2018-07-12T23:17:05Z</published>
    <title>Data Infrastructure and Approaches for Ontology-Based Drug Repurposing</title>
    <summary>  We report development of a data infrastructure for drug repurposing that
takes advantage of two currently available chemical ontologies. The data
infrastructure includes a database of compound- target associations augmented
with molecular ontological labels. It also contains two computational tools for
prediction of new associations. We describe two drug-repurposing systems: one,
Nascent Ontological Information Retrieval for Drug Repurposing (NOIR-DR), based
on an information retrieval strategy, and another, based on non-negative matrix
factorization together with compound similarity, that was inspired by
recommender systems. We report the performance of both tools on a
drug-repurposing task.
</summary>
    <author>
      <name>Stephen Boyer</name>
    </author>
    <author>
      <name>Thomas Griffin</name>
    </author>
    <author>
      <name>Sarath Swaminathan</name>
    </author>
    <author>
      <name>Kenneth L. Clarkson</name>
    </author>
    <author>
      <name>Dmitry Zubarev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1807.09754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1807.09754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.02344v1</id>
    <updated>2020-01-08T02:48:23Z</updated>
    <published>2020-01-08T02:48:23Z</published>
    <title>Citation Recommendations Considering Content and Structural Context
  Embedding</title>
    <summary>  The number of academic papers being published is increasing exponentially in
recent years, and recommending adequate citations to assist researchers in
writing papers is a non-trivial task. Conventional approaches may not be
optimal, as the recommended papers may already be known to the users, or be
solely relevant to the surrounding context but not other ideas discussed in the
manuscript. In this work, we propose a novel embedding algorithm DocCit2Vec,
along with the new concept of ``structural context'', to tackle the
aforementioned issues. The proposed approach demonstrates superior performances
to baseline models in extensive experiments designed to simulate practical
usage scenarios.
</summary>
    <author>
      <name>Yang Zhang</name>
    </author>
    <author>
      <name>Qiang Ma</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2020 IEEE International Conference on Big Data and Smart Computing</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.02344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.03303v1</id>
    <updated>2020-01-10T04:39:44Z</updated>
    <published>2020-01-10T04:39:44Z</published>
    <title>Linking Social Media Posts to News with Siamese Transformers</title>
    <summary>  Many computational social science projects examine online discourse
surrounding a specific trending topic. These works often involve the
acquisition of large-scale corpora relevant to the event in question to analyze
aspects of the response to the event. Keyword searches present a
precision-recall trade-off and crowd-sourced annotations, while effective, are
costly. This work aims to enable automatic and accurate ad-hoc retrieval of
comments discussing a trending topic from a large corpus, using only a handful
of seed news articles.
</summary>
    <author>
      <name>Jacob Danovitch</name>
    </author>
    <link href="http://arxiv.org/abs/2001.03303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04348v1</id>
    <updated>2019-12-14T21:45:28Z</updated>
    <published>2019-12-14T21:45:28Z</published>
    <title>Leveraging Multi-Method Evaluation for Multi-Stakeholder Settings</title>
    <summary>  In this paper, we focus on recommendation settings with multiple stakeholders
with possibly varying goals and interests, and argue that a single evaluation
method or measure is not able to evaluate all relevant aspects in such a
complex setting. We reason that employing a multi-method evaluation, where
multiple evaluation methods or measures are combined and integrated, allows for
getting a richer picture and prevents blind spots in the evaluation outcome.
</summary>
    <author>
      <name>Christine Bauer</name>
    </author>
    <author>
      <name>Eva Zangerle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, ImpactRS 2019, Copenhagen, Denmark</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">1st Workshop on the Impact of Recommender Systems (ImpactRS 2019),
  co-located with 13th ACM Conference on Recommender Systems (ACM RecSys 2019),
  ceur-ws.org, Vol 2462, Short 3</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.04348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.06910v1</id>
    <updated>2020-01-19T22:08:57Z</updated>
    <published>2020-01-19T22:08:57Z</published>
    <title>Common Conversational Community Prototype: Scholarly Conversational
  Assistant</title>
    <summary>  This paper discusses the potential for creating academic resources (tools,
data, and evaluation approaches) to support research in conversational search,
by focusing on realistic information needs and conversational interactions.
Specifically, we propose to develop and operate a prototype conversational
search system for scholarly activities. This Scholarly Conversational Assistant
would serve as a useful tool, a means to create datasets, and a platform for
running evaluation challenges by groups across the community. This article
results from discussions of a working group at Dagstuhl Seminar 19461 on
Conversational Search.
</summary>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <author>
      <name>Lucie Flekova</name>
    </author>
    <author>
      <name>Matthias Hagen</name>
    </author>
    <author>
      <name>Rosie Jones</name>
    </author>
    <author>
      <name>Martin Potthast</name>
    </author>
    <author>
      <name>Filip Radlinski</name>
    </author>
    <author>
      <name>Mark Sanderson</name>
    </author>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <author>
      <name>Hamed Zamani</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.08085v1</id>
    <updated>2020-01-18T10:23:48Z</updated>
    <published>2020-01-18T10:23:48Z</published>
    <title>Experiments on Manual Thesaurus based Query Expansion for Ad-hoc
  Monolingual Gujarati Information Retrieval Tasks</title>
    <summary>  In this paper, we present the experimental work done on Query Expansion (QE)
for retrieval tasks of Gujarati text documents. In information retrieval, it is
very difficult to estimate the exact user need, query expansion adds terms to
the original query, which provides more information about the user need. There
are various approaches to query expansion. In our work, manual thesaurus based
query expansion was performed to evaluate the performance of widely used
information retrieval models for Gujarati text documents. Results show that
query expansion improves the recall of text documents.
</summary>
    <author>
      <name>Hardik Joshi</name>
    </author>
    <author>
      <name>Jyoti Pareek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1209.0126</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.10336v1</id>
    <updated>2020-01-20T13:16:12Z</updated>
    <published>2020-01-20T13:16:12Z</published>
    <title>Bibliometric-enhanced Information Retrieval 10th Anniversary Workshop
  Edition</title>
    <summary>  The Bibliometric-enhanced Information Retrieval workshop series (BIR) was
launched at ECIR in 2014 \cite{MayrEtAl2014} and it was held at ECIR each year
since then. This year we organize the 10th iteration of BIR. The workshop
series at ECIR and JCDL/SIGIR tackles issues related to academic search, at the
crossroads between Information Retrieval, Natural Language Processing and
Bibliometrics. In this overview paper, we summarize the past workshops, present
the workshop topics for 2020 and reflect on some future steps for this workshop
series.
</summary>
    <author>
      <name>Guillaume Cabanac</name>
    </author>
    <author>
      <name>Ingo Frommholz</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-45442-5_85</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-45442-5_85" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Overview paper submitted to ECIR 2020, Lisbon, PT. arXiv admin note:
  substantial text overlap with arXiv:1909.04954</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.10336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.10336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.04628v1</id>
    <updated>2020-03-10T10:46:12Z</updated>
    <published>2020-03-10T10:46:12Z</published>
    <title>Large-Scale Evaluation of Keyphrase Extraction Models</title>
    <summary>  Keyphrase extraction models are usually evaluated under different, not
directly comparable, experimental setups. As a result, it remains unclear how
well proposed models actually perform, and how they compare to each other. In
this work, we address this issue by presenting a systematic large-scale
analysis of state-of-the-art keyphrase extraction models involving multiple
benchmark datasets from various sources and domains. Our main results reveal
that state-of-the-art models are in fact still challenged by simple baselines
on some datasets. We also present new insights about the impact of using
author- or reader-assigned keyphrases as a proxy for gold standard, and give
recommendations for strong baselines and reliable benchmark datasets.
</summary>
    <author>
      <name>Ygor Gallina</name>
    </author>
    <author>
      <name>Florian Boudin</name>
    </author>
    <author>
      <name>Béatrice Daille</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2003.06461v2</id>
    <updated>2020-04-17T20:19:42Z</updated>
    <published>2020-03-13T19:44:26Z</published>
    <title>Exploring User Opinions of Fairness in Recommender Systems</title>
    <summary>  Algorithmic fairness for artificial intelligence has become increasingly
relevant as these systems become more pervasive in society. One realm of AI,
recommender systems, presents unique challenges for fairness due to trade offs
between optimizing accuracy for users and fairness to providers. But what is
fair in the context of recommendation--particularly when there are multiple
stakeholders? In an initial exploration of this problem, we ask users what
their ideas of fair treatment in recommendation might be, and why. We analyze
what might cause discrepancies or changes between user's opinions towards
fairness to eventually help inform the design of fairer and more transparent
recommendation algorithms.
</summary>
    <author>
      <name>Jessie Smith</name>
    </author>
    <author>
      <name>Nasim Sonboli</name>
    </author>
    <author>
      <name>Casey Fiesler</name>
    </author>
    <author>
      <name>Robin Burke</name>
    </author>
    <link href="http://arxiv.org/abs/2003.06461v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06461v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.05716v1</id>
    <updated>2020-04-12T23:16:14Z</updated>
    <published>2020-04-12T23:16:14Z</published>
    <title>Large-scale Real-time Personalized Similar Product Recommendations</title>
    <summary>  Similar product recommendation is one of the most common scenes in
e-commerce. Many recommendation algorithms such as item-to-item Collaborative
Filtering are working on measuring item similarities. In this paper, we
introduce our real-time personalized algorithm to model product similarity and
real-time user interests. We also introduce several other baseline algorithms
including an image-similarity-based method, item-to-item collaborative
filtering, and item2vec, and compare them on our large-scale real-world
e-commerce dataset. The algorithms which achieve good offline results are also
tested on the online e-commerce website. Our personalized method achieves a 10%
improvement on the add-cart number in the real-world e-commerce scenario.
</summary>
    <author>
      <name>Zhi Liu</name>
    </author>
    <author>
      <name>Yan Huang</name>
    </author>
    <author>
      <name>Jing Gao</name>
    </author>
    <author>
      <name>Li Chen</name>
    </author>
    <author>
      <name>Dong Li</name>
    </author>
    <link href="http://arxiv.org/abs/2004.05716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.05716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.12628v1</id>
    <updated>2020-04-27T08:11:00Z</updated>
    <published>2020-04-27T08:11:00Z</published>
    <title>Visual Analysis of Ontology Matching Results with the MELT Dashboard</title>
    <summary>  In this demo, we introduce MELT Dashboard, an interactive Web user interface
for ontology alignment evaluation which is created with the existing Matching
EvaLuation Toolkit (MELT). Compared to existing, static evaluation interfaces
in the ontology matching domain, our dashboard allows for interactive
self-service analyses such as a drill down into the matcher performance for
data type properties or into the performance of matchers within a certain
confidence threshold. In addition, the dashboard offers detailed group
evaluation capabilities that allow for the application in broad evaluation
campaigns such as the Ontology Alignment Evaluation Initiative (OAEI).
</summary>
    <author>
      <name>Jan Portisch</name>
    </author>
    <author>
      <name>Sven Hertling</name>
    </author>
    <author>
      <name>Heiko Paulheim</name>
    </author>
    <link href="http://arxiv.org/abs/2004.12628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.12628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.13313v3</id>
    <updated>2020-10-06T22:55:25Z</updated>
    <published>2020-04-28T05:55:42Z</published>
    <title>Modularized Transfomer-based Ranking Framework</title>
    <summary>  Recent innovations in Transformer-based ranking models have advanced the
state-of-the-art in information retrieval. However, these Transformers are
computationally expensive, and their opaque hidden states make it hard to
understand the ranking process. In this work, we modularize the Transformer
ranker into separate modules for text representation and interaction. We show
how this design enables substantially faster ranking using offline pre-computed
representations and light-weight online interactions. The modular design is
also easier to interpret and sheds light on the ranking process in Transformer
rankers.
</summary>
    <author>
      <name>Luyu Gao</name>
    </author>
    <author>
      <name>Zhuyun Dai</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <link href="http://arxiv.org/abs/2004.13313v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.13313v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.13969v3</id>
    <updated>2021-03-29T06:19:52Z</updated>
    <published>2020-04-29T06:10:02Z</published>
    <title>Complementing Lexical Retrieval with Semantic Residual Embedding</title>
    <summary>  This paper presents CLEAR, a retrieval model that seeks to complement
classical lexical exact-match models such as BM25 with semantic matching
signals from a neural embedding matching model. CLEAR explicitly trains the
neural embedding to encode language structures and semantics that lexical
retrieval fails to capture with a novel residual-based embedding learning
method. Empirical evaluations demonstrate the advantages of CLEAR over
state-of-the-art retrieval models, and that it can substantially improve the
end-to-end accuracy and efficiency of reranking pipelines.
</summary>
    <author>
      <name>Luyu Gao</name>
    </author>
    <author>
      <name>Zhuyun Dai</name>
    </author>
    <author>
      <name>Tongfei Chen</name>
    </author>
    <author>
      <name>Zhen Fan</name>
    </author>
    <author>
      <name>Benjamin Van Durme</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.13969v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.13969v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.01535v1</id>
    <updated>2020-05-04T14:48:53Z</updated>
    <published>2020-05-04T14:48:53Z</published>
    <title>Ten Questions in Lifelog Mining and Information Recall</title>
    <summary>  With the advance of science and technology, people are used to record their
daily life events via writing blogs, uploading social media posts, taking
photos, or filming videos. Such rich repository personal information is useful
for supporting human living assistance. The main challenge is how to store and
manage personal knowledge from various sources. In this position paper, we
propose a research agenda on mining personal knowledge from various sources of
lifelogs, personal knowledge base construction, and information recall for
assisting people to recall their experiences.
</summary>
    <author>
      <name>An-Zi Yen</name>
    </author>
    <author>
      <name>Hen-Hsen Huang</name>
    </author>
    <author>
      <name>Hsin-Hsi Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2005.01535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.01535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.03529v1</id>
    <updated>2020-05-07T14:53:11Z</updated>
    <published>2020-05-07T14:53:11Z</published>
    <title>CounQER: A System for Discovering and Linking Count Information in
  Knowledge Bases</title>
    <summary>  Predicate constraints of general-purpose knowledge bases (KBs) like Wikidata,
DBpedia and Freebase are often limited to subproperty, domain and range
constraints. In this demo we showcase CounQER, a system that illustrates the
alignment of counting predicates, like staffSize, and enumerating predicates,
like workInstitution^{-1} . In the demonstration session, attendees can inspect
these alignments, and will learn about the importance of these alignments for
KB question answering and curation. CounQER is available at
https://counqer.mpi-inf.mpg.de/spo.
</summary>
    <author>
      <name>Shrestha Ghosh</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ESWC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.03529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.03529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.07893v1</id>
    <updated>2020-05-16T07:39:29Z</updated>
    <published>2020-05-16T07:39:29Z</published>
    <title>Tiering as a Stochastic Submodular Optimization Problem</title>
    <summary>  Tiering is an essential technique for building large-scale information
retrieval systems. While the selection of documents for high priority tiers
critically impacts the efficiency of tiering, past work focuses on optimizing
it with respect to a static set of queries in the history, and generalizes
poorly to the future traffic. Instead, we formulate the optimal tiering as a
stochastic optimization problem, and follow the methodology of regularized
empirical risk minimization to maximize the \emph{generalization performance}
of the system. We also show that the optimization problem can be cast as a
stochastic submodular optimization problem with a submodular knapsack
constraint, and we develop efficient optimization algorithms by leveraging this
connection.
</summary>
    <author>
      <name>Hyokun Yun</name>
    </author>
    <author>
      <name>Michael Froh</name>
    </author>
    <author>
      <name>Roshan Makhijani</name>
    </author>
    <author>
      <name>Brian Luc</name>
    </author>
    <author>
      <name>Alex Smola</name>
    </author>
    <author>
      <name>Trishul Chilimbi</name>
    </author>
    <link href="http://arxiv.org/abs/2005.07893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.07893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.09252v1</id>
    <updated>2020-05-19T07:10:28Z</updated>
    <published>2020-05-19T07:10:28Z</published>
    <title>Multi-Modal Summary Generation using Multi-Objective Optimization</title>
    <summary>  Significant development of communication technology over the past few years
has motivated research in multi-modal summarization techniques. A majority of
the previous works on multi-modal summarization focus on text and images. In
this paper, we propose a novel extractive multi-objective optimization based
model to produce a multi-modal summary containing text, images, and videos.
Important objectives such as intra-modality salience, cross-modal redundancy
and cross-modal similarity are optimized simultaneously in a multi-objective
optimization framework to produce effective multi-modal output. The proposed
model has been evaluated separately for different modalities, and has been
found to perform better than state-of-the-art approaches.
</summary>
    <author>
      <name>Anubhav Jangra</name>
    </author>
    <author>
      <name>Sriparna Saha</name>
    </author>
    <author>
      <name>Adam Jatowt</name>
    </author>
    <author>
      <name>Mohammad Hasanuzzaman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.09252v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.09252v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.11992v1</id>
    <updated>2020-05-25T09:22:32Z</updated>
    <published>2020-05-25T09:22:32Z</published>
    <title>MPSUM: Entity Summarization with Predicate-based Matching</title>
    <summary>  With the development of Semantic Web, entity summarization has become an
emerging task to generate concrete summaries for real world entities. To solve
this problem, we propose an approach named MPSUM that extends a probabilistic
topic model by integrating the idea of predicate-uniqueness and
object-importance for ranking triples. The approach aims at generating brief
but representative summaries for entities. We compare our approach with the
state-of-the-art methods using DBpedia and LinkedMDB datasets.The experimental
results show that our work improves the quality of entity summarization.
</summary>
    <author>
      <name>Dongjun Wei</name>
    </author>
    <author>
      <name>Shiyuan Gao</name>
    </author>
    <author>
      <name>Yaxin Liu</name>
    </author>
    <author>
      <name>Zhibing Liu</name>
    </author>
    <author>
      <name>Longtao Hang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, accepted in EYRE@CIKM'2018</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.11992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.11992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.12816v1</id>
    <updated>2020-05-26T15:47:42Z</updated>
    <published>2020-05-26T15:47:42Z</published>
    <title>Predicting Entity Popularity to Improve Spoken Entity Recognition by
  Virtual Assistants</title>
    <summary>  We focus on improving the effectiveness of a Virtual Assistant (VA) in
recognizing emerging entities in spoken queries. We introduce a method that
uses historical user interactions to forecast which entities will gain in
popularity and become trending, and it subsequently integrates the predictions
within the Automated Speech Recognition (ASR) component of the VA. Experiments
show that our proposed approach results in a 20% relative reduction in errors
on emerging entity name utterances without degrading the overall recognition
quality of the system.
</summary>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <author>
      <name>Manos Tsagkias</name>
    </author>
    <author>
      <name>Ernest Pusateri</name>
    </author>
    <author>
      <name>Ilya Oparin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3397271.3401298</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3397271.3401298" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR '20. The 43rd International ACM SIGIR Conference on Research &amp;
  Development in Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.12816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.12816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.12978v1</id>
    <updated>2020-05-23T10:51:05Z</updated>
    <published>2020-05-23T10:51:05Z</published>
    <title>Devising Malware Characterstics using Transformers</title>
    <summary>  With the increasing number of cybersecurity threats, it becomes more
difficult for researchers to skim through the security reports for malware
analysis. There is a need to be able to extract highly relevant sentences
without having to read through the entire malware reports. In this paper, we
are finding relevant malware behavior mentions from Advanced Persistent Threat
Reports. This main contribution is an opening attempt to Transformer the
approach for malware behavior analysis.
</summary>
    <author>
      <name>Simra Shahid</name>
    </author>
    <author>
      <name>Tanmay Singh</name>
    </author>
    <author>
      <name>Yash Sharma</name>
    </author>
    <author>
      <name>Kapil Sharma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.12978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.12978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.12982v1</id>
    <updated>2020-05-14T14:57:12Z</updated>
    <published>2020-05-14T14:57:12Z</published>
    <title>Utilizing FastText for Venue Recommendation</title>
    <summary>  Venue recommendation systems model the past interactions (i.e., check-ins) of
the users and recommend venues. Traditional recommendation systems employ
collaborative filtering, content-based filtering or matrix factorization.
Recently, vector space embedding and deep learning algorithms are also used for
recommendation. In this work, I propose a method for recommending top-k venues
by utilizing the sequentiality feature of check-ins and a recent vector space
embedding method, namely the FastText. Our proposed method; forms groups of
check-ins, learns the vector space representations of the venues and utilizes
the learned embeddings to make venue recommendations. I measure the performance
of the proposed method using a Foursquare check-in dataset.The results show
that the proposed method performs better than the state-of-the-art methods.
</summary>
    <author>
      <name>Makbule Gulcin Ozsoy</name>
    </author>
    <link href="http://arxiv.org/abs/2005.12982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.12982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.12992v1</id>
    <updated>2020-05-21T18:10:21Z</updated>
    <published>2020-05-21T18:10:21Z</published>
    <title>Evaluating Information Retrieval Systems for Kids</title>
    <summary>  Evaluation of information retrieval systems (IRS) is a prominent topic among
information retrieval researchers--mainly directed at a general population.
Children require unique IRS and by extension different ways to evaluate these
systems, but as a large population that use IRS have largely been ignored on
the evaluation front. In this position paper, we explore many perspectives that
must be considered when evaluating IRS; we specially discuss problems faced by
researchers who work with children IRS, including lack of evaluation
frameworks, limitations of data, and lack of user judgment understanding.
</summary>
    <author>
      <name>Ashlee Milton</name>
    </author>
    <author>
      <name>Maria Soledad Pera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 4th International and Interdisciplinary Perspectives
  on Children &amp; Recommender and Information Retrieval Systems (KidRec '20),
  co-located with the 19th ACM International Conference on Interaction Design
  and Children (IDC '20), https://kidrec.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.12992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.12992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.12994v1</id>
    <updated>2020-05-26T19:21:57Z</updated>
    <published>2020-05-26T19:21:57Z</published>
    <title>A Study of Neural Matching Models for Cross-lingual IR</title>
    <summary>  In this study, we investigate interaction-based neural matching models for
ad-hoc cross-lingual information retrieval (CLIR) using cross-lingual word
embeddings (CLWEs). With experiments conducted on the CLEF collection over four
language pairs, we evaluate and provide insight into different neural model
architectures, different ways to represent query-document interactions and
word-pair similarity distributions in CLIR. This study paves the way for
learning an end-to-end CLIR system using CLWEs.
</summary>
    <author>
      <name>Puxuan Yu</name>
    </author>
    <author>
      <name>James Allan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3397271.3401322</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3397271.3401322" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, accepted at SIGIR'20</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.12994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.12994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.01018v1</id>
    <updated>2020-10-02T14:26:02Z</updated>
    <published>2020-10-02T14:26:02Z</published>
    <title>AVECL-UMONS database for audio-visual event classification and
  localization</title>
    <summary>  We introduce the AVECL-UMons dataset for audio-visual event classification
and localization in the context of office environments. The audio-visual
dataset is composed of 11 event classes recorded at several realistic positions
in two different rooms. Two types of sequences are recorded according to the
number of events in the sequence. The dataset comprises 2662 unilabel sequences
and 2724 multilabel sequences corresponding to a total of 5.24 hours. The
dataset is publicly accessible online :
https://zenodo.org/record/3965492#.X09wsobgrCI.
</summary>
    <author>
      <name>Mathilde Brousmiche</name>
    </author>
    <author>
      <name>Stéphane Dupont</name>
    </author>
    <author>
      <name>Jean Rouat</name>
    </author>
    <link href="http://arxiv.org/abs/2011.01018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.01018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.05614v1</id>
    <updated>2020-11-11T08:07:58Z</updated>
    <published>2020-11-11T08:07:58Z</published>
    <title>A Novel Privacy-Preserved Recommender System Framework based on
  Federated Learning</title>
    <summary>  Recommender System (RS) is currently an effective way to solve information
overload. To meet users' next click behavior, RS needs to collect users'
personal information and behavior to achieve a comprehensive and profound user
preference perception. However, these centrally collected data are
privacy-sensitive, and any leakage may cause severe problems to both users and
service providers. This paper proposed a novel privacy-preserved recommender
system framework (PPRSF), through the application of federated learning
paradigm, to enable the recommendation algorithm to be trained and carry out
inference without centrally collecting users' private data. The PPRSF not only
able to reduces the privacy leakage risk, satisfies legal and regulatory
requirements but also allows various recommendation algorithms to be applied.
</summary>
    <author>
      <name>Jiangcheng Qin</name>
    </author>
    <author>
      <name>Baisong Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3451471.3451485</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3451471.3451485" rel="related"/>
    <link href="http://arxiv.org/abs/2011.05614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.05614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; D.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.07368v2</id>
    <updated>2021-02-11T23:57:45Z</updated>
    <published>2020-11-14T19:03:24Z</published>
    <title>Conformer-Kernel with Query Term Independence at TREC 2020 Deep Learning
  Track</title>
    <summary>  We benchmark Conformer-Kernel models under the strict blind evaluation
setting of the TREC 2020 Deep Learning track. In particular, we study the
impact of incorporating: (i) Explicit term matching to complement matching
based on learned representations (i.e., the "Duet principle"), (ii) query term
independence (i.e., the "QTI assumption") to scale the model to the full
retrieval setting, and (iii) the ORCAS click data as an additional document
description field. We find evidence which supports that all three
aforementioned strategies can lead to improved retrieval quality.
</summary>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Sebastian Hofstatter</name>
    </author>
    <author>
      <name>Hamed Zamani</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/2011.07368v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.07368v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.09580v1</id>
    <updated>2020-11-18T23:13:33Z</updated>
    <published>2020-11-18T23:13:33Z</published>
    <title>Non-Linear Multiple Field Interactions Neural Document Ranking</title>
    <summary>  Ranking tasks are usually based on the text of the main body of the page and
the actions (clicks) of users on the page. There are other elements that could
be leveraged to better contextualise the ranking experience (e.g. text in other
fields, query made by the user, images, etc). We present one of the first
in-depth analyses of field interaction for multiple field ranking in two
separate datasets. While some works have taken advantage of full document
structure, some aspects remain unexplored. In this work we build on previous
analyses to show how query-field interactions, non-linear field interactions,
and the architecture of the underlying neural model affect performance.
</summary>
    <author>
      <name>Kentaro Takiguchi</name>
    </author>
    <author>
      <name>Niall Twomey</name>
    </author>
    <author>
      <name>Luis M. Vaquero</name>
    </author>
    <link href="http://arxiv.org/abs/2011.09580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.09580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2011.10919v1</id>
    <updated>2020-11-22T03:23:13Z</updated>
    <published>2020-11-22T03:23:13Z</published>
    <title>Applying Multi-armed Bandit Algorithms to Computational Advertising</title>
    <summary>  Over the last two decades, we have seen extensive industrial research in the
area of computational advertising. In this paper, our goal is to study the
performance of various online learning algorithms to identify and display the
best ads/offers with the highest conversion rates to web users. We formulate
our ad-selection problem as a Multi-Armed Bandit problem which is a classical
paradigm in Machine Learning. We have been applying machine learning, data
mining, probability, and statistics to analyze big data in the ad-tech space
and devise efficient ad selection strategies. This article highlights some of
our findings in the area of computational advertising from 2011 to 2015.
</summary>
    <author>
      <name>Kazem Jahanbakhsh</name>
    </author>
    <link href="http://arxiv.org/abs/2011.10919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2011.10919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.00350v1</id>
    <updated>2022-03-01T10:53:45Z</updated>
    <published>2022-03-01T10:53:45Z</published>
    <title>Results Merging in the Patent Domain</title>
    <summary>  In this paper, we test machine learning methods for results merging in patent
document retrieval. Specifically, we examine random forest, decision tree,
support vector machine (SVR), linear regression, polynomial regression, and
deep neural networks (DNNs). We use two different methods for results merging,
the multiple models (MM) method and the global model method (GM). Furthermore,
we examine whether the ranking of the document's scores is linearly
explainable. The CLEF-IP 2011 standard test collection was used in our
experiments. The random forest produces the best results in comparison to all
other models, and it fits the data better than linear and polynomial
approaches.
</summary>
    <author>
      <name>Vasileios Stamatis</name>
    </author>
    <author>
      <name>Michail Salampasis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3437120.3437313</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3437120.3437313" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICPS Series ; PCI-2020: 24th Pan-Hellenic Conference on
  Informatics ; Pages 229-232</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2203.00350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.00350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20 (Primary), 68U15 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.01769v2</id>
    <updated>2022-09-29T01:14:20Z</updated>
    <published>2022-03-03T15:27:02Z</published>
    <title>PeerSum: A Peer Review Dataset for Abstractive Multi-document
  Summarization</title>
    <summary>  We present PeerSum, a new MDS dataset using peer reviews of scientific
publications. Our dataset differs from the existing MDS datasets in that our
summaries (i.e., the meta-reviews) are highly abstractive and they are real
summaries of the source documents (i.e., the reviews) and it also features
disagreements among source documents. We found that current state-of-the-art
MDS models struggle to generate high-quality summaries for PeerSum, offering
new research opportunities.
</summary>
    <author>
      <name>Miao Li</name>
    </author>
    <author>
      <name>Jianzhong Qi</name>
    </author>
    <author>
      <name>Jey Han Lau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is because the paper has changed so much and the arxiv paper no
  longer represents the PeerSum</arxiv:comment>
    <link href="http://arxiv.org/abs/2203.01769v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.01769v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.04786v1</id>
    <updated>2022-03-09T15:10:12Z</updated>
    <published>2022-03-09T15:10:12Z</published>
    <title>Enhance Topics Analysis based on Keywords Properties</title>
    <summary>  Topic Modelling is one of the most prevalent text analysis technique used to
explore and retrieve collection of documents. The evaluation of the topic model
algorithms is still a very challenging tasks due to the absence of
gold-standard list of topics to compare against for every corpus. In this work,
we present a specificity score based on keywords properties that is able to
select the most informative topics. This approach helps the user to focus on
the most informative topics. In the experiments, we show that we are able to
compress the state-of-the-art topic modelling results of different factors with
an information loss that is much lower than the solution based on the recent
coherence score presented in literature.
</summary>
    <author>
      <name>Antonio Penta</name>
    </author>
    <link href="http://arxiv.org/abs/2203.04786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.04786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5; I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.04937v1</id>
    <updated>2022-03-09T18:36:46Z</updated>
    <published>2022-03-09T18:36:46Z</published>
    <title>Addressing Bias in Visualization Recommenders by Identifying Trends in
  Training Data: Improving VizML Through a Statistical Analysis of the Plotly
  Community Feed</title>
    <summary>  Machine learning is a promising approach to visualization recommendation due
to its high scalability and representational power. Researchers can create a
neural network to predict visualizations from input data by training it over a
corpus of datasets and visualization examples. However, these machine learning
models can reflect trends in their training data that may negatively affect
their performance. Our research project aims to address training bias in
machine learning visualization recommendation systems by identifying trends in
the training data through statistical analysis.
</summary>
    <author>
      <name>Allen Tu</name>
    </author>
    <author>
      <name>Priyanka Mehta</name>
    </author>
    <author>
      <name>Alexander Wu</name>
    </author>
    <author>
      <name>Nandhini Krishnan</name>
    </author>
    <author>
      <name>Amar Mujumdar</name>
    </author>
    <link href="http://arxiv.org/abs/2203.04937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.04937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.11026v1</id>
    <updated>2022-03-12T09:40:07Z</updated>
    <published>2022-03-12T09:40:07Z</published>
    <title>An Introduction to Matrix factorization and Factorization Machines in
  Recommendation System, and Beyond</title>
    <summary>  This paper aims at a better understanding of matrix factorization (MF),
factorization machines (FM), and their combination with deep algorithms'
application in recommendation systems. Specifically, this paper will focus on
Singular Value Decomposition (SVD) and its derivations, e.g Funk-SVD, SVD++,
etc. Step-by-step formula calculation and explainable pictures are displayed.
What's more, we explain the DeepFM model in which FM is assisted by deep
learning. Through numerical examples, we attempt to tie the theory to
real-world problems.
</summary>
    <author>
      <name>Yuefeng Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures. A notebook for better understanding MF, FM and
  their derivations in recommendation system</arxiv:comment>
    <link href="http://arxiv.org/abs/2203.11026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.11026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.11152v1</id>
    <updated>2022-03-17T15:53:47Z</updated>
    <published>2022-03-17T15:53:47Z</published>
    <title>Short Text Topic Modeling: Application to tweets about Bitcoin</title>
    <summary>  Understanding the semantic of a collection of texts is a challenging task.
Topic models are probabilistic models that aims at extracting "topics" from a
corpus of documents. This task is particularly difficult when the corpus is
composed of short texts, such as posts on social networks. Following several
previous research papers, we explore in this paper a set of collected tweets
about bitcoin. In this work, we train three topic models and evaluate their
output with several scores. We also propose a concrete application of the
extracted topics.
</summary>
    <author>
      <name>Hugo Schnoering</name>
    </author>
    <link href="http://arxiv.org/abs/2203.11152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.11152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.12465v1</id>
    <updated>2022-03-23T14:58:43Z</updated>
    <published>2022-03-23T14:58:43Z</published>
    <title>Multi-agent Searching System for Medical Information</title>
    <summary>  In the paper is proposed a model of multi-agent security system for searching
a medical information in Internet. The advantages when using mobile agent are
described, so that to perform searching in Internet. Nowadays, multi-agent
systems found their application into distribution of decisions. For modeling
the proposed multi-agent medical system is used JADE. Finally, the results when
using mobile agent are generated that could reflect performance when working
with BIG DATA. The proposed system is having also relatively high precision
96%.
</summary>
    <author>
      <name>Mariya Evtimova-Gardair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Volume 16, 2019, pp.140-145</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WSEAS Transactions on information science and applications,
  E-ISSN: 2224-3402, vol.16,2019, p.140-145</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2203.12465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.12465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.13561v1</id>
    <updated>2022-03-25T10:34:00Z</updated>
    <published>2022-03-25T10:34:00Z</published>
    <title>Personalize Web Searching Strategies Classification and Comparison</title>
    <summary>  Personalization is becoming very important direction in semantic web search
for the users that needs to find appropriate information. In this paper, a
classification of web personalization is proposed and semantic web search tools
are investigated. Building user interest profile is essential for
personalizing. Nowadays, semantic web tools use ontologies for personalization
because of their advantages. It is important to mention that most of the
semantic web search tools use agent technologies for implementation.
</summary>
    <author>
      <name>Mariya Evtimova-Gardair</name>
    </author>
    <author>
      <name>Ivan Momtchev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.17265/1548-7709/2016.01.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.17265/1548-7709/2016.01.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Communication and Computer, David Publishing, ISSN:
  1548-7709 (Print), 1930-1553 (Online), 2016, p.19-23</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2203.13561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.13561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.15328v1</id>
    <updated>2022-03-29T08:20:53Z</updated>
    <published>2022-03-29T08:20:53Z</published>
    <title>Compact Token Representations with Contextual Quantization for Efficient
  Document Re-ranking</title>
    <summary>  Transformer based re-ranking models can achieve high search relevance through
context-aware soft matching of query tokens with document tokens. To alleviate
runtime complexity of such inference, previous work has adopted a late
interaction architecture with pre-computed contextual token representations at
the cost of a large online storage. This paper proposes contextual quantization
of token embeddings by decoupling document-specific and document-independent
ranking contributions during codebook-based compression. This allows effective
online decompression and embedding composition for better search relevance.
This paper presents an evaluation of the above compact token representation
model in terms of relevance and space efficiency.
</summary>
    <author>
      <name>Yingrui Yang</name>
    </author>
    <author>
      <name>Yifan Qiao</name>
    </author>
    <author>
      <name>Tao Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2203.15328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.15328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.17042v1</id>
    <updated>2022-03-31T14:07:47Z</updated>
    <published>2022-03-31T14:07:47Z</published>
    <title>IITD-DBAI: Multi-Stage Retrieval with Pseudo-Relevance Feedback and
  Query Reformulation</title>
    <summary>  Resolving the contextual dependency is one of the most challenging tasks in
the Conversational system. Our submission to CAsT-2021 aimed to preserve the
key terms and the context in all subsequent turns and use classical Information
retrieval methods. It was aimed to pull as relevant documents as possible from
the corpus. We have participated in automatic track and submitted two runs in
the CAsT-2021. Our submission has produced a mean NDCG@3 performance better
than the median model.
</summary>
    <author>
      <name>Shivani Choudhary</name>
    </author>
    <link href="http://arxiv.org/abs/2203.17042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.17042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1602v1</id>
    <updated>2012-05-08T06:52:15Z</updated>
    <published>2012-05-08T06:52:15Z</published>
    <title>Indexing of Arabic documents automatically based on lexical analysis</title>
    <summary>  The continuous information explosion through the Internet and all information
sources makes it necessary to perform all information processing activities
automatically in quick and reliable manners. In this paper, we proposed and
implemented a method to automatically create and Index for books written in
Arabic language. The process depends largely on text summarization and
abstraction processes to collect main topics and statements in the book. The
process is developed in terms of accuracy and performance and results showed
that this process can effectively replace the effort of manually indexing books
and document, a process that can be very useful in all information processing
and retrieval applications.
</summary>
    <author>
      <name>Abdulrahman Al Molijy</name>
    </author>
    <author>
      <name>Ismail Hmeidi</name>
    </author>
    <author>
      <name>Izzat Alsmadi</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1638v1</id>
    <updated>2012-05-08T09:19:10Z</updated>
    <published>2012-05-08T09:19:10Z</published>
    <title>Document summarization using positive pointwise mutual information</title>
    <summary>  The degree of success in document summarization processes depends on the
performance of the method used in identifying significant sentences in the
documents. The collection of unique words characterizes the major signature of
the document, and forms the basis for Term-Sentence-Matrix (TSM). The Positive
Pointwise Mutual Information, which works well for measuring semantic
similarity in the Term-Sentence-Matrix, is used in our method to assign weights
for each entry in the Term-Sentence-Matrix. The Sentence-Rank-Matrix generated
from this weighted TSM, is then used to extract a summary from the document.
Our experiments show that such a method would outperform most of the existing
methods in producing summaries from large documents.
</summary>
    <author>
      <name>Aji S</name>
    </author>
    <author>
      <name>Ramachandra Kaimal</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3031v1</id>
    <updated>2012-05-14T14:01:56Z</updated>
    <published>2012-05-14T14:01:56Z</published>
    <title>The model of information retrieval based on the theory of hypercomplex
  numerical systems</title>
    <summary>  The paper provided a description of a new model of information retrieval,
which is an extension of vector-space model and is based on the principles of
the theory of hypercomplex numerical systems. The model allows to some extent
realize the idea of fuzzy search and allows you to apply in practice the model
of information retrieval practical developments in the field of hypercomplex
numerical systems.
</summary>
    <author>
      <name>D. V. Lande</name>
    </author>
    <author>
      <name>Ya. A. Kalinovskiy</name>
    </author>
    <author>
      <name>Yu. E. Boyarinova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.3031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3193v1</id>
    <updated>2012-05-14T21:08:05Z</updated>
    <published>2012-05-14T21:08:05Z</published>
    <title>A Comparative Study of Collaborative Filtering Algorithms</title>
    <summary>  Collaborative filtering is a rapidly advancing research area. Every year
several new techniques are proposed and yet it is not clear which of the
techniques work best and under what conditions. In this paper we conduct a
study comparing several collaborative filtering techniques -- both classic and
recent state-of-the-art -- in a variety of experimental contexts. Specifically,
we report conclusions controlling for number of items, number of users,
sparsity level, performance criteria, and computational complexity. Our
conclusions identify what algorithms work well and in what conditions, and
contribute to both industrial deployment collaborative filtering algorithms and
to the research community.
</summary>
    <author>
      <name>Joonseok Lee</name>
    </author>
    <author>
      <name>Mingxuan Sun</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.3193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; H.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.5632v1</id>
    <updated>2012-05-25T08:43:06Z</updated>
    <published>2012-05-25T08:43:06Z</published>
    <title>Quantum contextuality in classical information retrieval</title>
    <summary>  Document ranking based on probabilistic evaluations of relevance is known to
exhibit non-classical correlations, which may be explained by admitting a
complex structure of the event space, namely, by assuming the events to emerge
from multiple sample spaces. The structure of event space formed by overlapping
sample spaces is known in quantum mechanics, they may exhibit some
counter-intuitive features, called quantum contextuality. In this Note I
observe that from the structural point of view quantum contextuality looks
similar to personalization of information retrieval scenarios. Along these
lines, Knowledge Revision is treated as operationalistic measurement and a way
to quantify the rate of personalization of Information Retrieval scenarios is
suggested.
</summary>
    <author>
      <name>Roman Zapatrin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.5632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.5632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="81P13" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0491v1</id>
    <updated>2014-09-01T17:20:13Z</updated>
    <published>2014-09-01T17:20:13Z</published>
    <title>Facets and Typed Relations as Tools for Reasoning Processes in
  Information Retrieval</title>
    <summary>  Faceted arrangement of entities and typed relations for representing
different associations between the entities are established tools in knowledge
representation. In this paper, a proposal is being discussed combining both
tools to draw inferences along relational paths. This approach may yield new
benefit for information retrieval processes, especially when modeled for
heterogeneous environments in the Semantic Web. Faceted arrangement can be used
as a se-lection tool for the semantic knowledge modeled within the knowledge
repre-sentation. Typed relations between the entities of different facets can
be used as restrictions for selecting them across the facets.
</summary>
    <author>
      <name>Winfried Gödert</name>
    </author>
    <link href="http://arxiv.org/abs/1409.0491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0921v1</id>
    <updated>2014-09-02T23:41:58Z</updated>
    <published>2014-09-02T23:41:58Z</published>
    <title>A Generalized Framework for Ontology-Based Information Retrieval
  Application to a public-transportation system</title>
    <summary>  In this paper we present a generic framework for ontology-based information
retrieval. We focus on the recognition of semantic information extracted from
data sources and the mapping of this knowledge into ontology. In order to
achieve more scalability, we propose an approach for semantic indexing based on
entity retrieval model. In addition, we have used ontology of public
transportation domain in order to validate these proposals. Finally, we
evaluated our system using ontology mapping and real world data sources.
Experiments show that our framework can provide meaningful search results.
</summary>
    <author>
      <name>Amir Zidi</name>
    </author>
    <author>
      <name>Mourad Abed</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICAdLT.2013.6568453</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICAdLT.2013.6568453" rel="related"/>
    <link href="http://arxiv.org/abs/1409.0921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2762v1</id>
    <updated>2014-09-09T14:54:49Z</updated>
    <published>2014-09-09T14:54:49Z</published>
    <title>Parallel and Distributed Collaborative Filtering: A Survey</title>
    <summary>  Collaborative filtering is amongst the most preferred techniques when
implementing recommender systems. Recently, great interest has turned towards
parallel and distributed implementations of collaborative filtering algorithms.
This work is a survey of the parallel and distributed collaborative filtering
implementations, aiming not only to provide a comprehensive presentation of the
field's development, but also to offer future research orientation by
highlighting the issues that need to be further developed.
</summary>
    <author>
      <name>Efthalia Karydi</name>
    </author>
    <author>
      <name>Konstantinos G. Margaritis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4627v1</id>
    <updated>2014-09-16T13:24:44Z</updated>
    <published>2014-09-16T13:24:44Z</published>
    <title>DISA at ImageCLEF 2014 Revised: Search-based Image Annotation with DeCAF
  Features</title>
    <summary>  This paper constitutes an extension to the report on DISA-MU team
participation in the ImageCLEF 2014 Scalable Concept Image Annotation Task as
published in [3]. Specifically, we introduce a new similarity search component
that was implemented into the system, report on the results achieved by
utilizing this component, and analyze the influence of different similarity
search parameters on the annotation quality.
</summary>
    <author>
      <name>Petra Budikova</name>
    </author>
    <author>
      <name>Jan Botorek</name>
    </author>
    <author>
      <name>Michal Batko</name>
    </author>
    <author>
      <name>Pavel Zezula</name>
    </author>
    <link href="http://arxiv.org/abs/1409.4627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5443v2</id>
    <updated>2014-09-27T08:23:24Z</updated>
    <published>2014-09-18T20:00:52Z</published>
    <title>Exploratory Analysis of a Terabyte Scale Web Corpus</title>
    <summary>  In this paper we present a preliminary analysis over the largest publicly
accessible web dataset: the Common Crawl Corpus. We measure nine web
characteristics from two levels of granularity using MapReduce and we comment
on the initial observations over a fraction of it. To the best of our knowledge
two of the characteristics, the language distribution and the HTML version of
pages have not been analyzed in previous work, while the specific dataset has
been only analyzed on page level.
</summary>
    <author>
      <name>Vasilis Kolias</name>
    </author>
    <author>
      <name>Ioannis Anagnostopoulos</name>
    </author>
    <author>
      <name>Eleftherios Kayafas</name>
    </author>
    <link href="http://arxiv.org/abs/1409.5443v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5443v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.6805v1</id>
    <updated>2014-09-24T02:55:31Z</updated>
    <published>2014-09-24T02:55:31Z</published>
    <title>Improving Cross-domain Recommendation through Probabilistic
  Cluster-level Latent Factor Model--Extended Version</title>
    <summary>  Cross-domain recommendation has been proposed to transfer user behavior
pattern by pooling together the rating data from multiple domains to alleviate
the sparsity problem appearing in single rating domains. However, previous
models only assume that multiple domains share a latent common rating pattern
based on the user-item co-clustering. To capture diversities among different
domains, we propose a novel Probabilistic Cluster-level Latent Factor (PCLF)
model to improve the cross-domain recommendation performance. Experiments on
several real world datasets demonstrate that our proposed model outperforms the
state-of-the-art methods for the cross-domain recommendation task.
</summary>
    <author>
      <name>Siting Ren</name>
    </author>
    <author>
      <name>Sheng Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1409.6805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.6805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7729v1</id>
    <updated>2014-07-30T06:40:13Z</updated>
    <published>2014-07-30T06:40:13Z</published>
    <title>Context-Based Information Retrieval in Risky Environment</title>
    <summary>  Context-Based Information Retrieval is recently modelled as an exploration/
exploitation trade-off (exr/exp) problem, where the system has to choose
between maximizing its expected rewards dealing with its current knowledge
(exploitation) and learning more about the unknown user's preferences to
improve its knowledge (exploration). This problem has been addressed by the
reinforcement learning community but they do not consider the risk level of the
current user's situation, where it may be dangerous to explore the
non-top-ranked documents the user may not desire in his/her current situation
if the risk level is high. We introduce in this paper an algorithm named
CBIR-R-greedy that considers the risk level of the user's situation to
adaptively balance between exr and exp.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1408.2195</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.7729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.8572v1</id>
    <updated>2014-09-29T17:17:52Z</updated>
    <published>2014-09-29T17:17:52Z</published>
    <title>Freshness-Aware Thompson Sampling</title>
    <summary>  To follow the dynamicity of the user's content, researchers have recently
started to model interactions between users and the Context-Aware Recommender
Systems (CARS) as a bandit problem where the system needs to deal with
exploration and exploitation dilemma. In this sense, we propose to study the
freshness of the user's content in CARS through the bandit problem. We
introduce in this paper an algorithm named Freshness-Aware Thompson Sampling
(FA-TS) that manages the recommendation of fresh document according to the
user's risk of the situation. The intensive evaluation and the detailed
analysis of the experimental results reveals several important discoveries in
the exploration/exploitation (exr/exp) behaviour.
</summary>
    <author>
      <name>Djallel Bouneffouf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21st International Conference on Neural Information Processing. arXiv
  admin note: text overlap with arXiv:1409.7729</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.8572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.8572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01991v1</id>
    <updated>2015-10-07T15:39:39Z</updated>
    <published>2015-10-07T15:39:39Z</published>
    <title>HDIdx: High-Dimensional Indexing for Efficient Approximate Nearest
  Neighbor Search</title>
    <summary>  Fast Nearest Neighbor (NN) search is a fundamental challenge in large-scale
data processing and analytics, particularly for analyzing multimedia contents
which are often of high dimensionality. Instead of using exact NN search,
extensive research efforts have been focusing on approximate NN search
algorithms. In this work, we present "HDIdx", an efficient high-dimensional
indexing library for fast approximate NN search, which is open-source and
written in Python. It offers a family of state-of-the-art algorithms that
convert input high-dimensional vectors into compact binary codes, making them
very efficient and scalable for NN search with very low space complexity.
</summary>
    <author>
      <name>Ji Wan</name>
    </author>
    <author>
      <name>Sheng Tang</name>
    </author>
    <author>
      <name>Yongdong Zhang</name>
    </author>
    <author>
      <name>Jintao Li</name>
    </author>
    <author>
      <name>Pengcheng Wu</name>
    </author>
    <author>
      <name>Steven C. H. Hoi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neucom.2015.11.104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neucom.2015.11.104" rel="related"/>
    <link href="http://arxiv.org/abs/1510.01991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02755v2</id>
    <updated>2015-12-12T17:56:52Z</updated>
    <published>2015-10-04T09:24:27Z</published>
    <title>A Novel Approach to Document Classification using WordNet</title>
    <summary>  Content based Document Classification is one of the biggest challenges in the
context of free text mining. Current algorithms on document classifications
mostly rely on cluster analysis based on bag-of-words approach. However that
method is still being applied to many modern scientific dilemmas. It has
established a strong presence in fields like economics and social science to
merit serious attention from the researchers. In this paper we would like to
propose and explore an alternative grounded more securely on the dictionary
classification and correlatedness of words and phrases. It is expected that
application of our existing knowledge about the underlying classification
structure may lead to improvement of the classifier's performance.
</summary>
    <author>
      <name>Koushiki Sarkar</name>
    </author>
    <author>
      <name>Ritwika Law</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">(Working Paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.02755v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02755v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01713v1</id>
    <updated>2017-02-06T17:19:07Z</updated>
    <published>2017-02-06T17:19:07Z</published>
    <title>A dynamic multi-level collaborative filtering method for improved
  recommendations</title>
    <summary>  One of the most used approaches for providing recommendations in various
online environments such as e-commerce is collaborative filtering. Although,
this is a simple method for recommending items or services, accuracy and
quality problems still exist. Thus, we propose a dynamic multi-level
collaborative filtering method that improves the quality of the
recommendations. The proposed method is based on positive and negative
adjustments and can be used in different domains that utilize collaborative
filtering to increase the quality of the user experience. Furthermore, the
effectiveness of the proposed method is shown by providing an extensive
experimental evaluation based on three real datasets and by comparisons to
alternative methods.
</summary>
    <author>
      <name>Nikolaos Polatidis</name>
    </author>
    <author>
      <name>Christos K. Georgiadis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.csi.2016.10.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.csi.2016.10.014" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Standards &amp; Interfaces, 51, 14-21 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.01713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02107v1</id>
    <updated>2017-01-18T15:23:41Z</updated>
    <published>2017-01-18T15:23:41Z</published>
    <title>First Study on Data Readiness Level</title>
    <summary>  We introduce the idea of Data Readiness Level (DRL) to measure the relative
richness of data to answer specific questions often encountered by data
scientists. We first approach the problem in its full generality explaining its
desired mathematical properties and applications and then we propose and study
two DRL metrics. Specifically, we define DRL as a function of at least four
properties of data: Noisiness, Believability, Relevance, and Coherence. The
information-theoretic based metrics, Cosine Similarity and Document Disparity,
are proposed as indicators of Relevance and Coherence for a piece of data. The
proposed metrics are validated through a text-based experiment using Twitter
data.
</summary>
    <author>
      <name>Hui Guan</name>
    </author>
    <author>
      <name>Thanos Gentimis</name>
    </author>
    <author>
      <name>Hamid Krim</name>
    </author>
    <author>
      <name>James Keiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.02107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06510v1</id>
    <updated>2017-02-21T18:24:52Z</updated>
    <published>2017-02-21T18:24:52Z</published>
    <title>Algorithmes de classification et d'optimisation: participation du
  LIA/ADOC á DEFT'14</title>
    <summary>  This year, the DEFT campaign (D\'efi Fouilles de Textes) incorporates a task
which aims at identifying the session in which articles of previous TALN
conferences were presented. We describe the three statistical systems developed
at LIA/ADOC for this task. A fusion of these systems enables us to obtain
interesting results (micro-precision score of 0.76 measured on the test corpus)
</summary>
    <author>
      <name>Luis Adrián Cabrera-Diego</name>
    </author>
    <author>
      <name>Stéphane Huet</name>
    </author>
    <author>
      <name>Bassam Jabaian</name>
    </author>
    <author>
      <name>Alejandro Molina</name>
    </author>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Marc El-Bèze</name>
    </author>
    <author>
      <name>Barthélémy Durette</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 tables, Conference paper (in French)</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.06510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08070v1</id>
    <updated>2017-02-26T19:09:59Z</updated>
    <published>2017-02-26T19:09:59Z</published>
    <title>PubTree: A Hierarchical Search Tool for the MEDLINE Database</title>
    <summary>  Keeping track of the ever-increasing body of scientific literature is an
escalating challenge. We present PubTree a hierarchical search tool that
efficiently searches the PubMed/MEDLINE dataset based upon a decision tree
constructed using &gt;26 million abstracts. The tool is implemented as a webpage,
where users are asked a series of eighteen questions to locate pertinent
articles. The implementation of this hierarchical search tool highlights issues
endemic with document retrieval. However, the construction of this tree
indicates that with future developments hierarchical search could become an
effective tool (or adjunct) in the mining of biological literature.
</summary>
    <author>
      <name>William Rowe</name>
    </author>
    <author>
      <name>Paul D. Dobson</name>
    </author>
    <author>
      <name>Bede Constantinides</name>
    </author>
    <author>
      <name>Mark Platt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.00829v1</id>
    <updated>2019-05-02T16:04:21Z</updated>
    <published>2019-05-02T16:04:21Z</published>
    <title>Web data mining for public health purposes</title>
    <summary>  For a long time, public health events, such as disease incidence or
vaccination activity, have been monitored to keep track of the health status of
the population, allowing to evaluate the effect of public health initiatives
and to decide where resources for improving public health are best spent. This
thesis investigates the use of web data mining for public health monitoring,
and makes contributions in the following two areas: New approaches for
predicting public health events from web mined data, and novel applications of
web mined data for public health monitoring.
</summary>
    <author>
      <name>Niels Dalum Hansen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis (2017), Univ Copenhagen</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.00829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.00829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.01758v1</id>
    <updated>2019-05-05T22:16:08Z</updated>
    <published>2019-05-05T22:16:08Z</published>
    <title>Investigating the Successes and Failures of BERT for Passage Re-Ranking</title>
    <summary>  The bidirectional encoder representations from transformers (BERT) model has
recently advanced the state-of-the-art in passage re-ranking. In this paper, we
analyze the results produced by a fine-tuned BERT model to better understand
the reasons behind such substantial improvements. To this aim, we focus on the
MS MARCO passage re-ranking dataset and provide potential reasons for the
successes and failures of BERT for retrieval. In more detail, we empirically
study a set of hypotheses and provide additional analysis to explain the
successful performance of BERT.
</summary>
    <author>
      <name>Harshith Padigela</name>
    </author>
    <author>
      <name>Hamed Zamani</name>
    </author>
    <author>
      <name>W. Bruce Croft</name>
    </author>
    <link href="http://arxiv.org/abs/1905.01758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.01758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.03375v1</id>
    <updated>2019-05-08T22:16:59Z</updated>
    <published>2019-05-08T22:16:59Z</published>
    <title>Embarrassingly Shallow Autoencoders for Sparse Data</title>
    <summary>  Combining simple elements from the literature, we define a linear model that
is geared toward sparse data, in particular implicit feedback data for
recommender systems. We show that its training objective has a closed-form
solution, and discuss the resulting conceptual insights. Surprisingly, this
simple model achieves better ranking accuracy than various state-of-the-art
collaborative-filtering approaches, including deep non-linear models, on most
of the publicly available data-sets used in our experiments.
</summary>
    <author>
      <name>Harald Steck</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308558.3313710</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308558.3313710" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In the proceedings of the Web Conference (WWW) 2019 (7 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.03375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.03375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06114v1</id>
    <updated>2019-05-09T10:28:57Z</updated>
    <published>2019-05-09T10:28:57Z</published>
    <title>Semantic Search using Spreading Activation based on Ontology</title>
    <summary>  Currently, the text document retrieval systems have many challenges in
exploring the semantics of queries and documents. Each query implies
information which does not appear in the query but the documents related with
the information are also expected by user. The disadvantage of the previous
spreading activation algorithms could be many irrelevant concepts added to the
query. In this paper, a proposed novel algorithm is only activate and add to
the query named entities which are related with original entities in the query
and explicit relations in the query.
</summary>
    <author>
      <name>Ngo Minh Vuong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, in Vietnamese</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Science Journal, special issue E-Learning Architecture and
  Technology (ELATE), Vol.53, 2013, pp. 136-156</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.06114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06115v1</id>
    <updated>2019-05-08T20:27:00Z</updated>
    <published>2019-05-08T20:27:00Z</published>
    <title>Naive Bayes with Correlation Factor for Text Classification Problem</title>
    <summary>  Naive Bayes estimator is widely used in text classification problems.
However, it doesn't perform well with small-size training dataset. We propose a
new method based on Naive Bayes estimator to solve this problem. A correlation
factor is introduced to incorporate the correlation among different classes.
Experimental results show that our estimator achieves a better accuracy
compared with traditional Naive Bayes in real world data.
</summary>
    <author>
      <name>Jiangning Chen</name>
    </author>
    <author>
      <name>Zhibo Dai</name>
    </author>
    <author>
      <name>Juntao Duan</name>
    </author>
    <author>
      <name>Heinrich Matzinger</name>
    </author>
    <author>
      <name>Ionel Popescu</name>
    </author>
    <link href="http://arxiv.org/abs/1905.06115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.06874v1</id>
    <updated>2019-05-15T11:51:59Z</updated>
    <published>2019-05-15T11:51:59Z</published>
    <title>Behavior Sequence Transformer for E-commerce Recommendation in Alibaba</title>
    <summary>  Deep learning based methods have been widely used in industrial
recommendation systems (RSs). Previous works adopt an Embedding&amp;MLP paradigm:
raw features are embedded into low-dimensional vectors, which are then fed on
to MLP for final recommendations. However, most of these works just concatenate
different features, ignoring the sequential nature of users' behaviors. In this
paper, we propose to use the powerful Transformer model to capture the
sequential signals underlying users' behavior sequences for recommendation in
Alibaba. Experimental results demonstrate the superiority of the proposed
model, which is then deployed online at Taobao and obtain significant
improvements in online Click-Through-Rate (CTR) comparing to two baselines.
</summary>
    <author>
      <name>Qiwei Chen</name>
    </author>
    <author>
      <name>Huan Zhao</name>
    </author>
    <author>
      <name>Wei Li</name>
    </author>
    <author>
      <name>Pipei Huang</name>
    </author>
    <author>
      <name>Wenwu Ou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.06874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.06874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11518v1</id>
    <updated>2019-05-27T21:40:37Z</updated>
    <published>2019-05-27T21:40:37Z</published>
    <title>On a scalable problem transformation method for multi-label learning</title>
    <summary>  Binary relevance is a simple approach to solve multi-label learning problems
where an independent binary classifier is built per each label. A common
challenge with this in real-world applications is that the label space can be
very large, making it difficult to use binary relevance to larger scale
problems. In this paper, we propose a scalable alternative to this, via
transforming the multi-label problem into a single binary classification. We
experiment with a few variations of our method and show that our method
achieves higher precision than binary relevance and faster execution times on a
top-K recommender system task.
</summary>
    <author>
      <name>Dora Jambor</name>
    </author>
    <author>
      <name>Peng Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1905.11518v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11518v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11668v3</id>
    <updated>2021-09-11T10:24:36Z</updated>
    <published>2019-05-28T08:17:03Z</published>
    <title>A Framework for App Store Optimization</title>
    <summary>  In this paper a framework for app store optimization is proposed. The
framework is based on two main areas: developer dependent elements and user
dependent elements. Developer dependent elements are similar to factors in
search engine optimization. User dependent elements are similar to activities
in social media. The proposed framework is modelled after downloading sample
data from two leading app stores: Google Play and Apple iTunes. Results show
that developer dependent elements can be better optimized. Names and
descriptions of mobile apps are not fully utilized.
</summary>
    <author>
      <name>Artur Strzelecki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3991/ijim.v14i13.14143</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3991/ijim.v14i13.14143" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1903.07182</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Interactive Mobile Technologies (iJIM)
  2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1905.11668v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.11668v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.00831v1</id>
    <updated>2019-08-02T13:00:27Z</updated>
    <published>2019-08-02T13:00:27Z</published>
    <title>Bias Disparity in Collaborative Recommendation: Algorithmic Evaluation
  and Comparison</title>
    <summary>  Research on fairness in machine learning has been recently extended to
recommender systems. One of the factors that may impact fairness is bias
disparity, the degree to which a group's preferences on various item categories
fail to be reflected in the recommendations they receive. In some cases biases
in the original data may be amplified or reversed by the underlying
recommendation algorithm. In this paper, we explore how different
recommendation algorithms reflect the tradeoff between ranking quality and bias
disparity. Our experiments include neighborhood-based, model-based, and
trust-aware recommendation algorithms.
</summary>
    <author>
      <name>Masoud Mansoury</name>
    </author>
    <author>
      <name>Bamshad Mobasher</name>
    </author>
    <author>
      <name>Robin Burke</name>
    </author>
    <author>
      <name>Mykola Pechenizkiy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Recommendation in Multi-Stakeholder Environments (RMSE)
  at ACM RecSys 2019, Copenhagen, Denmark</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.00831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.01868v1</id>
    <updated>2019-08-05T21:31:10Z</updated>
    <published>2019-08-05T21:31:10Z</published>
    <title>Local versus Global Strategies in Social Query Expansion</title>
    <summary>  Link sharing in social media can be seen as a collaboratively retrieved set
of documents for a query or topic expressed by a hashtag. Temporal information
plays an important role for identifying the correct context for which such
annotations are valid for retrieval purposes. We investigate how social data as
temporal context can be used for query expansion and compare global versus
local strategies for computing such contextual information for a set of
hashtags.
</summary>
    <author>
      <name>Omar Alonso</name>
    </author>
    <author>
      <name>Vasileios Kandylas</name>
    </author>
    <author>
      <name>Serge-Eric Tremblay</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.02938v1</id>
    <updated>2019-08-08T05:45:57Z</updated>
    <published>2019-08-08T05:45:57Z</published>
    <title>Neural Document Expansion with User Feedback</title>
    <summary>  This paper presents a neural document expansion approach (NeuDEF) that
enriches document representations for neural ranking models. NeuDEF harvests
expansion terms from queries which lead to clicks on the document and weights
these expansion terms with learned attention. It is plugged into a standard
neural ranker and learned end-to-end. Experiments on a commercial search log
demonstrate that NeuDEF significantly improves the accuracy of state-of-the-art
neural rankers and expansion methods on queries with different frequencies.
Further studies show the contribution of click queries and learned expansion
weights, as well as the influence of document popularity of NeuDEF's
effectiveness.
</summary>
    <author>
      <name>Yue Yin</name>
    </author>
    <author>
      <name>Chenyan Xiong</name>
    </author>
    <author>
      <name>Cheng Luo</name>
    </author>
    <author>
      <name>Zhiyuan Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3341981.3344213</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3341981.3344213" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 2019 ACM SIGIR International Conference on the Theory of
  Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.02938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.03142v2</id>
    <updated>2019-08-27T12:41:30Z</updated>
    <published>2019-08-07T03:59:19Z</published>
    <title>The Hitchhiker's Guide to LDA</title>
    <summary>  Latent Dirichlet Allocation (LDA) model is a famous model in the topic model
field, it has been studied for years due to its extensive application value in
industry and academia. However, the mathematical derivation of LDA model is
challenging and difficult, which makes it difficult for the beginners to learn.
To help the beginners in learning LDA, this book analyzes the mathematical
derivation of LDA in detail, and it also introduces all the knowledge
background to make it easy for beginners to understand. Thus, this book
contains the author's unique insights. It should be noted that this book is
written in Chinese.
</summary>
    <author>
      <name>Chen Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">148 pages, in Chinese</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.03142v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.03142v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.03313v1</id>
    <updated>2019-08-09T04:44:12Z</updated>
    <published>2019-08-09T04:44:12Z</published>
    <title>Using Semantic Role Knowledge for Relevance Ranking of Key Phrases in
  Documents: An Unsupervised Approach</title>
    <summary>  In this paper, we investigate the integration of sentence position and
semantic role of words in a PageRank system to build a key phrase ranking
method. We present the evaluation results of our approach on three scientific
articles. We show that semantic role information, when integrated with a
PageRank system, can become a new lexical feature. Our approach had an overall
improvement on all the data sets over the state-of-art baseline approaches.
</summary>
    <author>
      <name>Prateeti Mohapatra</name>
    </author>
    <author>
      <name>Neelamadhav Gantayat</name>
    </author>
    <author>
      <name>Gargi B. Dasgupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.03313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.03313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.03738v1</id>
    <updated>2019-08-10T12:03:55Z</updated>
    <published>2019-08-10T12:03:55Z</published>
    <title>Personalized Music Recommendation with Triplet Network</title>
    <summary>  Since many online music services emerged in recent years so that effective
music recommendation systems are desirable. Some common problems in
recommendation system like feature representations, distance measure and cold
start problems are also challenges for music recommendation. In this paper, I
proposed a triplet neural network, exploiting both positive and negative
samples to learn the representation and distance measure between users and
items, to solve the recommendation task.
</summary>
    <author>
      <name>Haoting Liang</name>
    </author>
    <author>
      <name>Donghuo Zeng</name>
    </author>
    <author>
      <name>Yi Yu</name>
    </author>
    <author>
      <name>Keizo Oyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 figure; 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">DEIM 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1908.03738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.03738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.04045v1</id>
    <updated>2019-08-12T08:15:27Z</updated>
    <published>2019-08-12T08:15:27Z</published>
    <title>Automatic Fashion Knowledge Extraction from Social Media</title>
    <summary>  Fashion knowledge plays a pivotal role in helping people in their dressing.
In this paper, we present a novel system to automatically harvest fashion
knowledge from social media. It unifies three tasks of occasion, person and
clothing discovery from multiple modalities of images, texts and metadata. A
contextualized fashion concept learning model is applied to leverage the rich
contextual information for improving the fashion concept learning performance.
At the same time, to counter the label noise within training data, we employ a
weak label modeling method to further boost the performance. We build a website
to demonstrate the quality of fashion knowledge extracted by our system.
</summary>
    <author>
      <name>Yunshan Ma</name>
    </author>
    <author>
      <name>Lizi Liao</name>
    </author>
    <author>
      <name>Tat-Seng Chua</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3343031.3350607</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3343031.3350607" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 4 figures, ACMMM 2019 Demo</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06780v1</id>
    <updated>2019-08-19T13:14:02Z</updated>
    <published>2019-08-19T13:14:02Z</published>
    <title>A Study of BERT for Non-Factoid Question-Answering under Passage Length
  Constraints</title>
    <summary>  We study the use of BERT for non-factoid question-answering, focusing on the
passage re-ranking task under varying passage lengths. To this end, we explore
the fine-tuning of BERT in different learning-to-rank setups, comprising both
point-wise and pair-wise methods, resulting in substantial improvements over
the state-of-the-art. We then analyze the effectiveness of BERT for different
passage lengths and suggest how to cope with large passages.
</summary>
    <author>
      <name>Yosi Mass</name>
    </author>
    <author>
      <name>Haggai Roitman</name>
    </author>
    <author>
      <name>Shai Erera</name>
    </author>
    <author>
      <name>Or Rivlin</name>
    </author>
    <author>
      <name>Bar Weiner</name>
    </author>
    <author>
      <name>David Konopnicki</name>
    </author>
    <link href="http://arxiv.org/abs/1908.06780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07069v1</id>
    <updated>2019-08-16T13:01:30Z</updated>
    <published>2019-08-16T13:01:30Z</published>
    <title>CommentsRadar: Dive into Unique Data on All Comments on the Web</title>
    <summary>  We introduce an entity-centric search engineCommentsRadarthatpairs entity
queries with articles and user opinions covering a widerange of topics from top
commented sites. The engine aggregatesarticles and comments for these articles,
extracts named entities,links them together and with knowledge base entries,
performssentiment analysis, and aggregates the results, aiming to mine
fortemporal trends and other insights. In this work, we present thegeneral
engine, discuss the models used for all steps of this pipeline,and introduce
several case studies that discover important insightsfrom online commenting
data.
</summary>
    <author>
      <name>Sergey Nikolenko</name>
    </author>
    <author>
      <name>Elena Tutubalina</name>
    </author>
    <author>
      <name>Zulfat Miftahutdinov</name>
    </author>
    <author>
      <name>Eugene Beloded</name>
    </author>
    <link href="http://arxiv.org/abs/1908.07069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.07389v1</id>
    <updated>2019-08-19T03:39:41Z</updated>
    <published>2019-08-19T03:39:41Z</published>
    <title>The Design and Implementation of a Real Time Visual Search System on JD
  E-commerce Platform</title>
    <summary>  We present the design and implementation of a visual search system for real
time image retrieval on JD.com, the world's third largest and China's largest
e-commerce site. We demonstrate that our system can support real time visual
search with hundreds of billions of product images at sub-second timescales and
handle frequent image updates through distributed hierarchical architecture and
efficient indexing methods. We hope that sharing our practice with our real
production system will inspire the middleware community's interest and
appreciation for building practical large scale systems for emerging
applications, such as ecommerce visual search.
</summary>
    <author>
      <name>Jie Li</name>
    </author>
    <author>
      <name>Haifeng Liu</name>
    </author>
    <author>
      <name>Chuanghua Gui</name>
    </author>
    <author>
      <name>Jianyu Chen</name>
    </author>
    <author>
      <name>Zhenyun Ni</name>
    </author>
    <author>
      <name>Ning Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.07389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.07389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.08609v2</id>
    <updated>2019-09-18T18:39:45Z</updated>
    <published>2019-08-22T22:10:08Z</published>
    <title>Song Hit Prediction: Predicting Billboard Hits Using Spotify Data</title>
    <summary>  In this work, we attempt to solve the Hit Song Science problem, which aims to
predict which songs will become chart-topping hits. We constructed a dataset
with approximately 1.8 million hit and non-hit songs and extracted their audio
features using the Spotify Web API. We test four models on our dataset. Our
best model was random forest, which was able to predict Billboard song success
with 88% accuracy.
</summary>
    <author>
      <name>Kai Middlebrook</name>
    </author>
    <author>
      <name>Kian Sheik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.08609v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08609v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.11146v1</id>
    <updated>2019-08-29T10:48:26Z</updated>
    <published>2019-08-29T10:48:26Z</published>
    <title>Towards More Usable Dataset Search: From Query Characterization to
  Snippet Generation</title>
    <summary>  Reusing published datasets on the Web is of great interest to researchers and
developers. Their data needs may be met by submitting queries to a dataset
search engine to retrieve relevant datasets. In this ongoing work towards
developing a more usable dataset search engine, we characterize real data needs
by annotating the semantics of 1,947 queries using a novel fine-grained scheme,
to provide implications for enhancing dataset search. Based on the findings, we
present a query-centered framework for dataset search, and explore the
implementation of snippet generation and evaluate it with a preliminary user
study.
</summary>
    <author>
      <name>Jinchi Chen</name>
    </author>
    <author>
      <name>Xiaxia Wang</name>
    </author>
    <author>
      <name>Gong Cheng</name>
    </author>
    <author>
      <name>Evgeny Kharlamov</name>
    </author>
    <author>
      <name>Yuzhong Qu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3357384.3358096</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3357384.3358096" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, The 28th ACM International Conference on Information and
  Knowledge Management (CIKM 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11146v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11146v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.00207v2</id>
    <updated>2020-02-05T18:46:58Z</updated>
    <published>2020-02-01T13:25:43Z</published>
    <title>Web Table Extraction, Retrieval and Augmentation: A Survey</title>
    <summary>  Tables are a powerful and popular tool for organizing and manipulating data.
A vast number of tables can be found on the Web, which represents a valuable
knowledge resource. The objective of this survey is to synthesize and present
two decades of research on web tables. In particular, we organize existing
literature into six main categories of information access tasks: table
extraction, table interpretation, table search, question answering, knowledge
base augmentation, and table augmentation. For each of these tasks, we identify
and describe seminal approaches, present relevant resources, and point out
interdependencies among the different tasks.
</summary>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Intelligent Systems and Technology. 11(2):
  Article 13, January 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.00207v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.00207v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01071v1</id>
    <updated>2020-02-01T09:18:56Z</updated>
    <published>2020-02-01T09:18:56Z</published>
    <title>Concept Embedding for Information Retrieval</title>
    <summary>  Concepts are used to solve the term-mismatch problem. However, we need an
effective similarity measure between concepts. Word embedding presents a
promising solution. We present in this study three approaches to build concepts
vectors based on words vectors. We use a vector-based measure to estimate
inter-concepts similarity. Our experiments show promising results. Furthermore,
words and concepts become comparable. This could be used to improve conceptual
indexing process.
</summary>
    <author>
      <name>Karam Abdulahhad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-76941-7_45</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-76941-7_45" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68-XX, 68Pxx, 68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.01077v1</id>
    <updated>2020-02-04T01:21:46Z</updated>
    <published>2020-02-04T01:21:46Z</published>
    <title>Quantifying the Effects of Recommendation Systems</title>
    <summary>  Recommendation systems today exert a strong influence on consumer behavior
and individual perceptions of the world. By using collaborative filtering (CF)
methods to create recommendations, it generates a continuous feedback loop in
which user behavior becomes magnified in the algorithmic system. Popular items
get recommended more frequently, creating the bias that affects and alters user
preferences. In order to visualize and compare the different biases, we will
analyze the effects of recommendation systems and quantify the inequalities
resulting from them.
</summary>
    <author>
      <name>Sunshine Chong</name>
    </author>
    <author>
      <name>Andrés Abeliuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures, accepted into the National Symposium of IEEE Big
  Data 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.01077v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.01077v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.02070v1</id>
    <updated>2020-02-06T02:10:33Z</updated>
    <published>2020-02-06T02:10:33Z</published>
    <title>Understanding Car-Speak: Replacing Humans in Dealerships</title>
    <summary>  A large portion of the car-buying experience in the United States involves
interactions at a car dealership. At the dealership, the car-buyer relays their
needs to a sales representative. However, most car-buyers are only have an
abstract description of the vehicle they need. Therefore, they are only able to
describe their ideal car in "car-speak". Car-speak is abstract language that
pertains to a car's physical attributes. In this paper, we define car-speak. We
also aim to curate a reasonable data set of car-speak language. Finally, we
train several classifiers in order to classify car-speak.
</summary>
    <author>
      <name>Habeeb Hooshmand</name>
    </author>
    <author>
      <name>James Caverlee</name>
    </author>
    <link href="http://arxiv.org/abs/2002.02070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.02070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.03124v1</id>
    <updated>2020-02-08T09:04:32Z</updated>
    <published>2020-02-08T09:04:32Z</published>
    <title>Predict your Click-out: Modeling User-Item Interactions and Session
  Actions in an Ensemble Learning Fashion</title>
    <summary>  This paper describes the solution of the POLINKS team to the RecSys Challenge
2019 that focuses on the task of predicting the last click-out in a
session-based interaction. We propose an ensemble approach comprising a matrix
factorization for modeling the interaction user-item, and a session-aware
learning model implemented with a recurrent neural network. This method appears
to be effective in predicting the last click-out scoring a 0.60277 of Mean
Reciprocal Rank on the local test set.
</summary>
    <author>
      <name>Andrea Fiandro</name>
    </author>
    <author>
      <name>Giorgio Crepaldi</name>
    </author>
    <author>
      <name>Diego Monti</name>
    </author>
    <author>
      <name>Giuseppe Rizzo</name>
    </author>
    <author>
      <name>Maurizio Morisio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.05753v1</id>
    <updated>2020-02-13T19:30:32Z</updated>
    <published>2020-02-13T19:30:32Z</published>
    <title>Multi-objective Ranking via Constrained Optimization</title>
    <summary>  In this paper, we introduce an Augmented Lagrangian based method to
incorporate the multiple objectives (MO) in a search ranking algorithm.
Optimizing MOs is an essential and realistic requirement for building ranking
models in production. The proposed method formulates MO in constrained
optimization and solves the problem in the popular Boosting framework -- a
novel contribution of our work. Furthermore, we propose a procedure to set up
all optimization parameters in the problem. The experimental results show that
the method successfully achieves MO criteria much more efficiently than
existing methods.
</summary>
    <author>
      <name>Michinari Momma</name>
    </author>
    <author>
      <name>Alireza Bagheri Garakani</name>
    </author>
    <author>
      <name>Nanxun Ma</name>
    </author>
    <author>
      <name>Yi Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.06985v1</id>
    <updated>2020-09-30T16:53:49Z</updated>
    <published>2020-09-30T16:53:49Z</published>
    <title>Understanding Twitter Engagement with a Click-Through Rate-based Method</title>
    <summary>  This paper presents the POLINKS solution to the RecSys Challenge 2020 that
ranked 6th in the final leaderboard. We analyze the performance of our solution
that utilizes the click-through rate value to address the challenge task, we
compare it with a gradient boosting model, and we report the quality indicators
utilized for computing the final leaderboard.
</summary>
    <author>
      <name>Andrea Fiandro</name>
    </author>
    <author>
      <name>Jeanpierre Francois</name>
    </author>
    <author>
      <name>Isabeau Oliveri</name>
    </author>
    <author>
      <name>Simone Leonardi</name>
    </author>
    <author>
      <name>Matteo A. Senese</name>
    </author>
    <author>
      <name>Giorgio Crepaldi</name>
    </author>
    <author>
      <name>Alberto Benincasa</name>
    </author>
    <author>
      <name>Giuseppe Rizzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, 4 tables, Recsys2020 Challenge</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.06985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.06985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.08591v1</id>
    <updated>2020-10-16T18:56:25Z</updated>
    <published>2020-10-16T18:56:25Z</published>
    <title>A Conglomerate of Multiple OCR Table Detection and Extraction</title>
    <summary>  Information representation as tables are compact and concise method that
eases searching, indexing, and storage requirements. Extracting and cloning
tables from parsable documents is easier and widely used, however industry
still faces challenge in detecting and extracting tables from OCR documents or
images. This paper proposes an algorithm that detects and extracts multiple
tables from OCR document. The algorithm uses a combination of image processing
techniques, text recognition and procedural coding to identify distinct tables
in same image and map the text to appropriate corresponding cell in dataframe
which can be stored as Comma-separated values, Database, Excel and multiple
other usable formats.
</summary>
    <author>
      <name>Smita Pallavi</name>
    </author>
    <author>
      <name>Raj Ratn Pranesh</name>
    </author>
    <author>
      <name>Sumit Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For ICDAR proceedings, see https://panel.waset.org/abstracts/127575</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.08591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.08591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.12370v1</id>
    <updated>2020-10-23T12:59:19Z</updated>
    <published>2020-10-23T12:59:19Z</published>
    <title>EventKG+Click: A Dataset of Language-specific Event-centric User
  Interaction Traces</title>
    <summary>  An increasing need to analyse event-centric cross-lingual information calls
for innovative user interaction models that assist users in crossing the
language barrier. However, datasets that reflect user interaction traces in
cross-lingual settings required to train and evaluate the user interaction
models are mostly missing. In this paper, we present the EventKG+Click dataset
that aims to facilitate the creation and evaluation of such interaction models.
EventKG+Click builds upon the event-centric EventKG knowledge graph and
language-specific information on user interactions with events, entities, and
their relations derived from the Wikipedia clickstream.
</summary>
    <author>
      <name>Sara Abdollahi</name>
    </author>
    <author>
      <name>Simon Gottschalk</name>
    </author>
    <author>
      <name>Elena Demidova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 1st International Workshop on Cross-lingual
  Event-centric Open Analytics co-located with the 17th Extended Semantic Web
  Conference (ESWC 2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.12370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.12370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.12798v1</id>
    <updated>2020-10-24T06:25:13Z</updated>
    <published>2020-10-24T06:25:13Z</published>
    <title>Content-Based Personalized Recommender System Using Entity Embeddings</title>
    <summary>  Recommender systems are a class of machine learning algorithms that provide
relevant recommendations to a user based on the user's interaction with similar
items or based on the content of the item. In settings where the content of the
item is to be preserved, a content-based approach would be beneficial. This
paper aims to highlight the advantages of the content-based approach through
learned embeddings and leveraging these advantages to provide better and
personalised movie recommendations based on user preferences to various movie
features such as genre and keyword tags.
</summary>
    <author>
      <name>Xavier Thomas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 Pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.12798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.12798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.02061v1</id>
    <updated>2021-04-02T21:32:43Z</updated>
    <published>2021-04-02T21:32:43Z</published>
    <title>Query2Prod2Vec Grounded Word Embeddings for eCommerce</title>
    <summary>  We present Query2Prod2Vec, a model that grounds lexical representations for
product search in product embeddings: in our model, meaning is a mapping
between words and a latent space of products in a digital shop. We leverage
shopping sessions to learn the underlying space and use merchandising
annotations to build lexical analogies for evaluation: our experiments show
that our model is more accurate than known techniques from the NLP and IR
literature. Finally, we stress the importance of data efficiency for product
search outside of retail giants, and highlight how Query2Prod2Vec fits with
practical constraints faced by most practitioners.
</summary>
    <author>
      <name>Federico Bianchi</name>
    </author>
    <author>
      <name>Jacopo Tagliabue</name>
    </author>
    <author>
      <name>Bingqing Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at NAACL2021 - Industry Track</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.02061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.02061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.09439v2</id>
    <updated>2023-04-12T06:41:23Z</updated>
    <published>2021-04-15T12:52:30Z</published>
    <title>Vec2GC -- A Graph Based Clustering Method for Text Representations</title>
    <summary>  NLP pipelines with limited or no labeled data, rely on unsupervised methods
for document processing. Unsupervised approaches typically depend on clustering
of terms or documents. In this paper, we introduce a novel clustering
algorithm, Vec2GC (Vector to Graph Communities), an end-to-end pipeline to
cluster terms or documents for any given text corpus. Our method uses community
detection on a weighted graph of the terms or documents, created using text
representation learning. Vec2GC clustering algorithm is a density based
approach, that supports hierarchical clustering as well.
</summary>
    <author>
      <name>Rajesh N Rao</name>
    </author>
    <author>
      <name>Manojit Chakraborty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2104.09439v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2104.09439v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.07347v3</id>
    <updated>2021-08-06T01:25:28Z</updated>
    <published>2021-06-01T00:44:34Z</published>
    <title>Zipf Matrix Factorization : Matrix Factorization with Matthew Effect
  Reduction</title>
    <summary>  Recommender system recommends interesting items to users based on users' past
information history. Researchers have been paying attention to improvement of
algorithmic performance such as MAE and precision@K. Major techniques such as
matrix factorization and learning to rank are optimized based on such
evaluation metrics. However, the intrinsic Matthew Effect problem poses great
threat to the fairness of the recommender system, and the unfairness problem
cannot be resolved by optimization of traditional metrics. In this paper, we
propose a novel algorithm that incorporates Matthew Effect reduction with the
matrix factorization framework. We demonstrate that our approach can boost the
fairness of the algorithm and enhances performance evaluated by traditional
metrics.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICAIBD 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2106.07347v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.07347v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.10977v1</id>
    <updated>2021-06-21T10:53:47Z</updated>
    <published>2021-06-21T10:53:47Z</published>
    <title>Computational Pronunciation Analysis in Sung Utterances</title>
    <summary>  Recent automatic lyrics transcription (ALT) approaches focus on building
stronger acoustic models or in-domain language models, while the pronunciation
aspect is seldom touched upon. This paper applies a novel computational
analysis on the pronunciation variances in sung utterances and further proposes
a new pronunciation model adapted for singing. The singing-adapted model is
tested on multiple public datasets via word recognition experiments. It
performs better than the standard speech dictionary in all settings reporting
the best results on ALT in a capella recordings using n-gram language models.
For reproducibility, we share the sentence-level annotations used in testing,
providing a new benchmark evaluation set for ALT.
</summary>
    <author>
      <name>Emir Demirel</name>
    </author>
    <author>
      <name>Sven Ahlback</name>
    </author>
    <author>
      <name>Simon Dixon</name>
    </author>
    <link href="http://arxiv.org/abs/2106.10977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.10977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.11517v1</id>
    <updated>2021-06-22T03:17:59Z</updated>
    <published>2021-06-22T03:17:59Z</published>
    <title>Fine-tune the Entire RAG Architecture (including DPR retriever) for
  Question-Answering</title>
    <summary>  In this paper, we illustrate how to fine-tune the entire Retrieval Augment
Generation (RAG) architecture in an end-to-end manner. We highlighted the main
engineering challenges that needed to be addressed to achieve this objective.
We also compare how end-to-end RAG architecture outperforms the original RAG
architecture for the task of question answering. We have open-sourced our
implementation in the HuggingFace Transformers library.
</summary>
    <author>
      <name>Shamane Siriwardhana</name>
    </author>
    <author>
      <name>Rivindu Weerasekera</name>
    </author>
    <author>
      <name>Elliott Wen</name>
    </author>
    <author>
      <name>Suranga Nanayakkara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">for associated code, see
  https://github.com/huggingface/transformers/tree/master/examples/research_projects/rag-end2end-retriever</arxiv:comment>
    <link href="http://arxiv.org/abs/2106.11517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.11517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.14726v1</id>
    <updated>2021-06-28T13:55:49Z</updated>
    <published>2021-06-28T13:55:49Z</published>
    <title>Keyphrase Generation for Scientific Document Retrieval</title>
    <summary>  Sequence-to-sequence models have lead to significant progress in keyphrase
generation, but it remains unknown whether they are reliable enough to be
beneficial for document retrieval. This study provides empirical evidence that
such models can significantly improve retrieval performance, and introduces a
new extrinsic evaluation framework that allows for a better understanding of
the limitations of keyphrase generation models. Using this framework, we point
out and discuss the difficulties encountered with supplementing documents with
-- not present in text -- keyphrases, and generalizing models across domains.
Our code is available at https://github.com/boudinfl/ir-using-kg
</summary>
    <author>
      <name>Florian Boudin</name>
    </author>
    <author>
      <name>Ygor Gallina</name>
    </author>
    <author>
      <name>Akiko Aizawa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18653/v1/2020.acl-main.105</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18653/v1/2020.acl-main.105" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ACL 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2106.14726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.14726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.00462v1</id>
    <updated>2021-09-28T18:40:08Z</updated>
    <published>2021-09-28T18:40:08Z</published>
    <title>Explainable Point-Based Document Visualizations</title>
    <summary>  Two-dimensional data maps can visually reveal information about the relations
between data instances. Popular techniques to construct data maps are t-SNE and
UMAP. The resulting point-based visualizations, though, provide information
only through their interpretation. We here consider a set of abstracts from the
articles on longevity to argue for using keyword extraction methods to label
clusters of documents in the map. Among the considered approaches, the best
results were obtained by recently proposed YAKE!. Surprisingly, a classical
TF-IDF term ranking outperformed graph and embedding-based techniques.
</summary>
    <author>
      <name>Primož Godec</name>
    </author>
    <author>
      <name>Nikola Ðukić</name>
    </author>
    <author>
      <name>Ajda Pretnar</name>
    </author>
    <author>
      <name>Vesna Tanko</name>
    </author>
    <author>
      <name>Lan Žagar</name>
    </author>
    <author>
      <name>Blaž Zupan</name>
    </author>
    <link href="http://arxiv.org/abs/2110.00462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.00462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.00925v2</id>
    <updated>2022-04-21T21:27:39Z</updated>
    <published>2021-10-03T05:34:46Z</published>
    <title>Matching Models for Graph Retrieval</title>
    <summary>  Graph Retrieval has witnessed continued interest and progress in the past few
years. In thisreport, we focus on neural network based approaches for Graph
matching and retrieving similargraphs from a corpus of graphs. We explore
methods which can soft predict the similaritybetween two graphs. Later, we
gauge the power of a particular baseline (Shortest Path Kernel)and try to model
it in our product graph random walks setting while making it more generalised.
</summary>
    <author>
      <name>Chitrank Gupta</name>
    </author>
    <author>
      <name>Yash Jain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">BS Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2110.00925v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.00925v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.08835v1</id>
    <updated>2021-10-17T14:32:29Z</updated>
    <published>2021-10-17T14:32:29Z</published>
    <title>Towards More Accountable Search Engines: Online Evaluation of
  Representation Bias</title>
    <summary>  Information availability affects people's behavior and perception of the
world. Notably, people rely on search engines to satisfy their need for
information. Search engines deliver results relevant to user requests usually
without being or making themselves accountable for the information they
deliver, which may harm people's lives and, in turn, society. This potential
risk urges the development of evaluation mechanisms of bias in order to empower
the user in judging the results of search engines. In this paper, we give a
possible solution to measuring representation bias with respect to societal
features for search engines and apply it to evaluating the gender
representation bias for Google's Knowledge Graph Carousel for listing
occupations.
</summary>
    <author>
      <name>Aldo Lipani</name>
    </author>
    <author>
      <name>Florina Piroi</name>
    </author>
    <author>
      <name>Emine Yilmaz</name>
    </author>
    <link href="http://arxiv.org/abs/2110.08835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.08835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2110.13047v2</id>
    <updated>2021-10-29T07:26:37Z</updated>
    <published>2021-10-22T06:22:36Z</published>
    <title>Drug Similarity and Link Prediction Using Graph Embeddings on Medical
  Knowledge Graphs</title>
    <summary>  The paper utilizes the graph embeddings generated for entities of a large
biomedical database to perform link prediction to capture various new
relationships among different entities. A novel node similarity measure is
proposed that utilizes the graph embeddings and link prediction scores to find
similarity scores among various drugs which can be used by the medical experts
to recommend alternative drugs to avoid side effects from original one.
Utilizing machine learning on knowledge graph for drug similarity and
recommendation will be less costly and less time consuming with higher
scalability as compared to traditional biomedical methods due to the dependency
on costly medical equipment and experts of the latter ones.
</summary>
    <author>
      <name>Prakhar Gurawa</name>
    </author>
    <author>
      <name>Matthias Nickles</name>
    </author>
    <link href="http://arxiv.org/abs/2110.13047v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2110.13047v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00365v1</id>
    <updated>2022-01-02T15:03:19Z</updated>
    <published>2022-01-02T15:03:19Z</published>
    <title>Establishing Strong Baselines for TripClick Health Retrieval</title>
    <summary>  We present strong Transformer-based re-ranking and dense retrieval baselines
for the recently released TripClick health ad-hoc retrieval collection. We
improve the - originally too noisy - training data with a simple negative
sampling policy. We achieve large gains over BM25 in the re-ranking task of
TripClick, which were not achieved with the original baselines. Furthermore, we
study the impact of different domain-specific pre-trained models on TripClick.
Finally, we show that dense retrieval outperforms BM25 by considerable margins,
even with simple training procedures.
</summary>
    <author>
      <name>Sebastian Hofstätter</name>
    </author>
    <author>
      <name>Sophia Althammer</name>
    </author>
    <author>
      <name>Mete Sertkan</name>
    </author>
    <author>
      <name>Allan Hanbury</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ECIR 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.00365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.00688v1</id>
    <updated>2021-12-28T08:42:16Z</updated>
    <published>2021-12-28T08:42:16Z</published>
    <title>Automatic Pharma News Categorization</title>
    <summary>  We use a text dataset consisting of 23 news categories relevant to pharma
information science, in order to compare the fine-tuning performance of
multiple transformer models in a classification task. Using a well-balanced
dataset with multiple autoregressive and autocoding transformation models, we
compare their fine-tuning performance. To validate the winning approach, we
perform diagnostics of model behavior on mispredicted instances, including
inspection of category-wise metrics, evaluation of prediction certainty and
assessment of latent space representations. Lastly, we propose an ensemble
model consisting of the top performing individual predictors and demonstrate
that this approach offers a modest improvement in the F1 metric.
</summary>
    <author>
      <name>Stanislaw Adaszewski</name>
    </author>
    <author>
      <name>Pascal Kuner</name>
    </author>
    <author>
      <name>Ralf J. Jaeger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, 9 pages appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.00688v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.00688v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.07599v1</id>
    <updated>2022-01-19T14:00:30Z</updated>
    <published>2022-01-19T14:00:30Z</published>
    <title>repro_eval: A Python Interface to Reproducibility Measures of
  System-oriented IR Experiments</title>
    <summary>  In this work we introduce repro_eval - a tool for reactive reproducibility
studies of system-oriented information retrieval (IR) experiments. The
corresponding Python package provides IR researchers with measures for
different levels of reproduction when evaluating their systems' outputs. By
offering an easily extensible interface, we hope to stimulate common practices
when conducting a reproducibility study of system-oriented IR experiments.
</summary>
    <author>
      <name>Timo Breuer</name>
    </author>
    <author>
      <name>Nicola Ferro</name>
    </author>
    <author>
      <name>Maria Maistro</name>
    </author>
    <author>
      <name>Philipp Schaer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-72240-1_51</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-72240-1_51" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ECIR21. The final authenticated version is available
  online at https://doi.org/10.1007/978-3-030-72240-1_51</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.07599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.07599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.07917v1</id>
    <updated>2022-01-19T23:35:46Z</updated>
    <published>2022-01-19T23:35:46Z</published>
    <title>Similarity search on neighbor's graphs with automatic Pareto optimal
  performance and minimum expected quality setups based on hyperparameter
  optimization</title>
    <summary>  This manuscript introduces an autotuned algorithm for searching nearest
neighbors based on neighbor graphs and optimization metaheuristics to produce
Pareto-optimal searches for quality and search speed automatically; the same
strategy is also used to produce indexes that achieve a minimum quality. Our
approach is described and benchmarked with other state-of-the-art similarity
search methods, showing convenience and competitiveness.
</summary>
    <author>
      <name>Eric S. Tellez</name>
    </author>
    <author>
      <name>Guillermo Ruiz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to a peer reviewed journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.07917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.07917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.09996v1</id>
    <updated>2022-01-24T23:03:36Z</updated>
    <published>2022-01-24T23:03:36Z</published>
    <title>Patapasco: A Python Framework for Cross-Language Information Retrieval
  Experiments</title>
    <summary>  While there are high-quality software frameworks for information retrieval
experimentation, they do not explicitly support cross-language information
retrieval (CLIR). To fill this gap, we have created Patapsco, a Python CLIR
framework. This framework specifically addresses the complexity that comes with
running experiments in multiple languages. Patapsco is designed to be
extensible to many language pairs, to be scalable to large document
collections, and to support reproducible experiments driven by a configuration
file. We include Patapsco results on standard CLIR collections using multiple
settings.
</summary>
    <author>
      <name>Cash Costello</name>
    </author>
    <author>
      <name>Eugene Yang</name>
    </author>
    <author>
      <name>Dawn Lawrie</name>
    </author>
    <author>
      <name>James Mayfield</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, accepted at ECIR 2022 as a demo paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.09996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.09996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.12376v1</id>
    <updated>2022-01-28T19:13:32Z</updated>
    <published>2022-01-28T19:13:32Z</published>
    <title>Probably Reasonable Search in eDiscovery</title>
    <summary>  In eDiscovery, a party to a lawsuit or similar action must search through
available information to identify those documents and files that are relevant
to the suit. Search efforts tend to identify less than 100% of the relevant
documents and courts are frequently asked to adjudicate whether the search
effort has been reasonable, or whether additional effort to find more of the
relevant documents is justified. This article provides a method for estimating
the probability that significant additional information will be found from
extended effort. Modeling and two data sets indicate that the probability that
facts/topics exist among the so-far unidentified documents that have not been
observed in the identified documents is low for even moderate levels of Recall.
</summary>
    <author>
      <name>Herbert L. Roitblat</name>
    </author>
    <link href="http://arxiv.org/abs/2201.12376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.12376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.12544v1</id>
    <updated>2022-01-29T10:05:58Z</updated>
    <published>2022-01-29T10:05:58Z</published>
    <title>An Open Data and Geo-based Information Systems</title>
    <summary>  Barangay is the smallest type of government in the Philippines, and it is
driven and represented by its barangay authorities. The barangay officials are
accountable for keeping the records of citizens health and crime incidents. It
also the first-hand source of information of the national government to develop
government programs, community services, and maintain peace and order. This
paper presents a developed a web-based information system incorporating open
data and geo-based features for a pilot community in the Philippines. This
system serves as a platform for information collection and used for planning,
analysis, decision-making and increase effectiveness and efficiency of
government services in the community.
</summary>
    <author>
      <name>Dexter I. Mercurio</name>
    </author>
    <author>
      <name>Alexander A. Hernandez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">None</arxiv:comment>
    <link href="http://arxiv.org/abs/2201.12544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.12544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.08824v1</id>
    <updated>2022-02-17T18:46:36Z</updated>
    <published>2022-02-17T18:46:36Z</published>
    <title>Multi-stage Ensemble Model for Cross-market Recommendation</title>
    <summary>  This paper describes the solution of our team PolimiRank for the WSDM Cup
2022 on cross-market recommendation. The goal of the competition is to
effectively exploit the information extracted from different markets to improve
the ranking accuracy of recommendations on two target markets. Our model
consists in a multi-stage approach based on the combination of data belonging
to different markets. In the first stage, state-of-the-art recommenders are
used to predict scores for user-item couples, which are ensembled in the
following 2 stages, employing a simple linear combination and more powerful
Gradient Boosting Decision Tree techniques. Our team ranked 4th in the final
leaderboard.
</summary>
    <author>
      <name>Cesare Bernardis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2202.08824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.08824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4916v1</id>
    <updated>2013-02-20T14:38:38Z</updated>
    <published>2013-02-20T14:38:38Z</published>
    <title>Stacking from Tags: Clustering Bookmarks around a Theme</title>
    <summary>  Since very recently, users on the social bookmarking service Delicious can
stack web pages in addition to tagging them. Stacking enables users to group
web pages around specific themes with the aim of recommending to others.
However, users still stack a small subset of what they tag, and thus many web
pages remain unstacked. This paper presents early research towards
automatically clustering web pages from tags to find stacks and extend
recommendations.
</summary>
    <author>
      <name>Arkaitz Zubiaga</name>
    </author>
    <author>
      <name>Alberto Pérez García-Plaza</name>
    </author>
    <author>
      <name>Víctor Fresno</name>
    </author>
    <author>
      <name>Raquel Martínez</name>
    </author>
    <link href="http://arxiv.org/abs/1302.4916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.7039v1</id>
    <updated>2013-02-28T00:21:38Z</updated>
    <published>2013-02-28T00:21:38Z</published>
    <title>Content Based Image Retrieval System Using NOHIS-tree</title>
    <summary>  Content-based image retrieval (CBIR) has been one of the most important
research areas in computer vision. It is a widely used method for searching
images in huge databases. In this paper we present a CBIR system called
NOHIS-Search. The system is based on the indexing technique NOHIS-tree. The two
phases of the system are described and the performance of the system is
illustrated with the image database ImagEval. NOHIS-Search system was compared
to other two CBIR systems; the first that using PDDP indexing algorithm and the
second system is that using the sequential search. Results show that
NOHIS-Search system outperforms the two other systems.
</summary>
    <author>
      <name>Mounira Taileb</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 10th International Conference on Advances in Mobile
  Computing &amp; Multimedia (MoMM2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.7039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.7039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.4606v1</id>
    <updated>2013-06-19T16:37:23Z</updated>
    <published>2013-06-19T16:37:23Z</published>
    <title>Keyphrase Cloud Generation of Broadcast News</title>
    <summary>  This paper describes an enhanced automatic keyphrase extraction method
applied to Broadcast News. The keyphrase extraction process is used to create a
concept level for each news. On top of words resulting from a speech
recognition system output and news indexation and it contributes to the
generation of a tag/keyphrase cloud of the top news included in a Multimedia
Monitoring Solution system for TV and Radio news/programs, running daily, and
monitoring 12 TV channels and 4 Radios.
</summary>
    <author>
      <name>Luis Marujo</name>
    </author>
    <author>
      <name>Márcio Viveiros</name>
    </author>
    <author>
      <name>João Paulo da Silva Neto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceeding of Interspeech 2011: 12th Annual Conference of the
  International Speech Communication Association</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.4606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.4606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.4758v1</id>
    <updated>2013-06-20T05:42:58Z</updated>
    <published>2013-06-20T05:42:58Z</published>
    <title>Analysing Word Importance for Image Annotation</title>
    <summary>  Image annotation provides several keywords automatically for a given image
based on various tags to describe its contents which is useful in Image
retrieval. Various researchers are working on text based and content based
image annotations [7,9]. It is seen, in traditional Image annotation
approaches, annotation words are treated equally without considering the
importance of each word in real world. In context of this, in this work, images
are annotated with keywords based on their frequency count and word
correlation. Moreover this work proposes an approach to compute importance
score of candidate keywords, having same frequency count.
</summary>
    <author>
      <name>Payal Gulati</name>
    </author>
    <author>
      <name>A. K. Sharma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, Published in IJCSI (International Journal of
  Computer Science Issues) Journal, Volume 10, Issue 1, No 2, January 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.4758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.4758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1732v1</id>
    <updated>2014-01-08T15:46:35Z</updated>
    <published>2014-01-08T15:46:35Z</published>
    <title>Looking at Vector Space and Language Models for IR using Density
  Matrices</title>
    <summary>  In this work, we conduct a joint analysis of both Vector Space and Language
Models for IR using the mathematical framework of Quantum Theory. We shed light
on how both models allocate the space of density matrices. A density matrix is
shown to be a general representational tool capable of leveraging capabilities
of both VSM and LM representations thus paving the way for a new generation of
retrieval models. We analyze the possible implications suggested by our
findings.
</summary>
    <author>
      <name>Alessandro Sordoni</name>
    </author>
    <author>
      <name>Jian-Yun Nie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of Quantum Interaction 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.1732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2085v1</id>
    <updated>2014-10-08T12:46:34Z</updated>
    <published>2014-10-08T12:46:34Z</published>
    <title>Low cost page quality factors to detect web spam</title>
    <summary>  Web spam is a big challenge for quality of search engine results. It is very
important for search engines to detect web spam accurately. In this paper we
present 32 low cost quality factors to classify spam and ham pages on real time
basis. These features can be divided in to three categories: (i) URL features,
(ii) Content features, and (iii) Link features. We developed a classifier using
Resilient Back-propagation learning algorithm of neural network and obtained
good accuracy. This classifier can be applied to search engine results on real
time because calculation of these features require very little CPU resources.
</summary>
    <author>
      <name>Ashish Chandra</name>
    </author>
    <author>
      <name>Mohammad Suaib</name>
    </author>
    <author>
      <name>Dr. Rizwan Beg</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Informatics Engineering, an International Journal (IEIJ) ,Vol.2,
  No.3, September 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.2085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8068v1</id>
    <updated>2014-10-27T23:38:59Z</updated>
    <published>2014-10-27T23:38:59Z</published>
    <title>Health Information Search Behavior on the Web: A Pilot Study</title>
    <summary>  Searching health information on web has become an integral part of today's
world, and many people turn to the Web for healthcare information and
healthcare assessment. Our pilot study investigates users' preferences for the
type of search results (image, news, video, etc.), and investigates users'
ability to accurately interpret online health information for the purpose of
self diagnosis. The preliminary results reveal that blog and news articles are
most sought by users when searching online information and there exist
challenges in the use of online health information for self-diagnosis.
</summary>
    <author>
      <name>Shanu Sushmita</name>
    </author>
    <author>
      <name>Si-Chi Chin</name>
    </author>
    <link href="http://arxiv.org/abs/1410.8068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01647v1</id>
    <updated>2015-03-05T14:34:02Z</updated>
    <published>2015-03-05T14:34:02Z</published>
    <title>Decentralized Recommender Systems</title>
    <summary>  This paper proposes a decentralized recommender system by formulating the
popular collaborative filleting (CF) model into a decentralized matrix
completion form over a set of users. In such a way, data storages and
computations are fully distributed. Each user could exchange limited
information with its local neighborhood, and thus it avoids the centralized
fusion. Advantages of the proposed system include a protection on user privacy,
as well as better scalability and robustness. We compare our proposed algorithm
with several state-of-the-art algorithms on the FlickerUserFavor dataset, and
demonstrate that the decentralized algorithm can gain a competitive performance
to others.
</summary>
    <author>
      <name>Zhangyang Wang</name>
    </author>
    <author>
      <name>Xianming Liu</name>
    </author>
    <author>
      <name>Shiyu Chang</name>
    </author>
    <author>
      <name>Jiayu Zhou</name>
    </author>
    <author>
      <name>Guo-Jun Qi</name>
    </author>
    <author>
      <name>Thomas S. Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1503.01647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03168v1</id>
    <updated>2015-03-10T10:34:06Z</updated>
    <published>2015-03-10T10:34:06Z</published>
    <title>Experimental Estimation of Number of Clusters Based on Cluster Quality</title>
    <summary>  Text Clustering is a text mining technique which divides the given set of
text documents into significant clusters. It is used for organizing a huge
number of text documents into a well-organized form. In the majority of the
clustering algorithms, the number of clusters must be specified apriori, which
is a drawback of these algorithms. The aim of this paper is to show
experimentally how to determine the number of clusters based on cluster
quality. Since partitional clustering algorithms are well-suited for clustering
large document datasets, we have confined our analysis to a partitional
clustering algorithm.
</summary>
    <author>
      <name>G. Hannah Grace</name>
    </author>
    <author>
      <name>Kalyani Desikan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of mathematics and computer science, Vol12 (2014), 304-315</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.03168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03607v1</id>
    <updated>2015-03-12T06:51:06Z</updated>
    <published>2015-03-12T06:51:06Z</published>
    <title>A divisive hierarchical clustering-based method for indexing image
  information</title>
    <summary>  In most practical applications of image retrieval, high-dimensional feature
vectors are required, but current multi-dimensional indexing structures lose
their efficiency with growth of dimensions. Our goal is to propose a divisive
hierarchical clustering-based multi-dimensional indexing structure which is
efficient in high-dimensional feature spaces. A projection pursuit method has
been used for finding a component of the data, which data's projections onto it
maximizes the approximation of negentropy for preparing essential information
in order to partitioning of the data space. Various tests and experimental
results on high-dimensional datasets indicate the performance of proposed
method in comparison with others.
</summary>
    <author>
      <name>Najva Izadpanah</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.6, No.1, February 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.03607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06410v2</id>
    <updated>2019-09-12T05:42:44Z</updated>
    <published>2015-03-22T11:32:34Z</published>
    <title>What the F-measure doesn't measure: Features, Flaws, Fallacies and Fixes</title>
    <summary>  The F-measure or F-score is one of the most commonly used single number
measures in Information Retrieval, Natural Language Processing and Machine
Learning, but it is based on a mistake, and the flawed assumptions render it
unsuitable for use in most contexts! Fortunately, there are better
alternatives.
</summary>
    <author>
      <name>David M. W. Powers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.06410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05, 68Q32, 91E45" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.8; I.2.6; I.2.7; I.4.6; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07284v1</id>
    <updated>2015-03-25T05:35:05Z</updated>
    <published>2015-03-25T05:35:05Z</published>
    <title>A Rule-Based Short Query Intent Identification System</title>
    <summary>  Using SMS (Short Message System), cell phones can be used to query for
information about various topics. In an SMS based search system, one of the key
problems is to identify a domain (broad topic) associated with the user query;
so that a more comprehensive search can be carried out by the domain specific
search engine. In this paper we use a rule based approach, to identify the
domain, called Short Query Intent Identification System (SQIIS). We construct
two different rule-bases using different strategies to suit query intent
identification. We evaluate the two rule-bases experimentally.
</summary>
    <author>
      <name>Arijit De</name>
    </author>
    <author>
      <name>Sunil Kumar Kopparapu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICSIP.2010.5697471</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICSIP.2010.5697471" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2010 International Conference on Signal and Image Processing
  (ICSIP)</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.07284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07474v1</id>
    <updated>2015-03-25T17:52:21Z</updated>
    <published>2015-03-25T17:52:21Z</published>
    <title>User Profiling Trends, Techniques and Applications</title>
    <summary>  The Personalization of information has taken recommender systems at a very
high level. With personalization these systems can generate user specific
recommendations accurately and efficiently. User profiling helps
personalization, where information retrieval is done to personalize a scenario
which maintains a separate user profile for individual user. The main objective
of this paper is to explore this field of personalization in context of user
profiling, to help researchers make aware of the user profiling. Various
trends, techniques and Applications have been discussed in paper which will
fulfill this motto.
</summary>
    <author>
      <name>Sumitkumar Kanoje</name>
    </author>
    <author>
      <name>Sheetal Girase</name>
    </author>
    <author>
      <name>Debajyoti Mukhopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure in IJAFRC, Vol.1, Issue 11, November 2014, ISSN:
  2348-4853. arXiv admin note: text overlap with arXiv:1503.06555</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.07474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.00722v1</id>
    <updated>2015-11-02T21:49:25Z</updated>
    <published>2015-11-02T21:49:25Z</published>
    <title>Identifying Actionable Messages on Social Media</title>
    <summary>  Text actionability detection is the problem of classifying user authored
natural language text, according to whether it can be acted upon by a
responding agent. In this paper, we propose a supervised learning framework for
domain-aware, large-scale actionability classification of social media
messages. We derive lexicons, perform an in-depth analysis for over 25 text
based features, and explore strategies to handle domains that have limited
training data. We apply these methods to over 46 million messages spanning 75
companies and 35 languages, from both Facebook and Twitter. The models achieve
an aggregate population-weighted F measure of 0.78 and accuracy of 0.74, with
values of over 0.9 in some cases.
</summary>
    <author>
      <name>Nemanja Spasojevic</name>
    </author>
    <author>
      <name>Adithya Rao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2015 IEEE International Big Data Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.00722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.00722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02433v1</id>
    <updated>2015-11-08T03:25:28Z</updated>
    <published>2015-11-08T03:25:28Z</published>
    <title>Accelerating Recommender Systems using GPUs</title>
    <summary>  We describe GPU implementations of the matrix recommender algorithms CCD++
and ALS. We compare the processing time and predictive ability of the GPU
implementations with existing multi-core versions of the same algorithms.
Results on the GPU are better than the results of the multi-core versions
(maximum speedup of 14.8).
</summary>
    <author>
      <name>André Valente Rodrigues</name>
    </author>
    <author>
      <name>Alípio Jorge</name>
    </author>
    <author>
      <name>Inês Dutra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2695664.2695850</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2695664.2695850" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SAC '15 Proceedings of the 30th Annual ACM Symposium on Applied
  Computing Pages 879-884 ACM New York, NY, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.02433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03780v2</id>
    <updated>2019-02-18T23:46:26Z</updated>
    <published>2015-11-12T05:24:35Z</published>
    <title>A User's Guide to CARSKit</title>
    <summary>  Context-aware recommender systems extend traditional recommenders by adapting
their suggestions to users' contextual situations. CARSKit is a Java-based
open-source library specifically designed for the context-aware recommendation,
where the state-of-the-art context-aware recommendation algorithms have been
implemented. This report provides the basic user's guide to CARSKit, including
how to prepare the data set, how to configure the experimental settings, and
how to evaluate the algorithms, as well as interpreting the outputs. The
instructions in this guide are applicable for CARSKit v0.3.5 and above.
</summary>
    <author>
      <name>Yong Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/1511.03780v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03780v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05810v1</id>
    <updated>2015-11-18T14:43:22Z</updated>
    <published>2015-11-18T14:43:22Z</published>
    <title>The Influence of Commercial Intent of Search Results on Their Perceived
  Relevance</title>
    <summary>  We carried out a retrieval effectiveness test on the three major web search
engines (i.e., Google, Microsoft and Yahoo). In addition to relevance
judgments, we classified the results according to their commercial intent and
whether or not they carried any advertising. We found that all search engines
provide a large number of results with a commercial intent. Google provides
significantly more commercial results than the other search engines do.
However, the commercial intent of a result did not influence jurors in their
relevance judgments.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Measurement, Performance, Experimentation, Worldwide Web, search
  engines, commerciality, evaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05817v1</id>
    <updated>2015-11-18T14:54:10Z</updated>
    <published>2015-11-18T14:54:10Z</published>
    <title>A Framework for Evaluating the Retrieval Effectiveness of Search Engines</title>
    <summary>  This chapter presents a theoretical framework for evaluating next generation
search engines. We focus on search engines whose results presentation is
enriched with additional information and does not merely present the usual list
of 10 blue links, that is, of ten links to results, accompanied by a short
description. While Web search is used as an example here, the framework can
easily be applied to search engines in any other area. The framework not only
addresses the results presentation, but also takes into account an extension of
the general design of retrieval effectiveness tests. The chapter examines the
ways in which this design might influence the results of such studies and how a
reliable test is best designed.
</summary>
    <author>
      <name>Dirk Lewandowski</name>
    </author>
    <link href="http://arxiv.org/abs/1511.05817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04533v1</id>
    <updated>2016-02-17T19:33:47Z</updated>
    <published>2016-02-17T19:33:47Z</published>
    <title>A Comprehensive Comparative Study of Word and Sentence Similarity
  Measures</title>
    <summary>  Sentence similarity is considered the basis of many natural language tasks
such as information retrieval, question answering and text summarization. The
semantic meaning between compared text fragments is based on the words semantic
features and their relationships. This article reviews a set of word and
sentence similarity measures and compares them on benchmark datasets. On the
studied datasets, results showed that hybrid semantic measures perform better
than both knowledge and corpus based measures.
</summary>
    <author>
      <name>Issa Atoum</name>
    </author>
    <author>
      <name>Ahmed Otoom</name>
    </author>
    <author>
      <name>Narayanan Kulathuramaiyer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/ijca2016908259</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/ijca2016908259" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages,4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications,2016,135(1),
  Foundation of Computer Science (FCS), NY, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.04533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.02178v1</id>
    <updated>2018-01-07T12:20:56Z</updated>
    <published>2018-01-07T12:20:56Z</published>
    <title>Neural Networks for Information Retrieval</title>
    <summary>  Machine learning plays a role in many aspects of modern IR systems, and deep
learning is applied in all of them. The fast pace of modern-day research has
given rise to many approaches to many IR problems. The amount of information
available can be overwhelming both for junior students and for experienced
researchers looking for new research topics and directions. The aim of this
full-day tutorial is to give a clear overview of current tried-and-trusted
neural methods in IR and how they benefit IR.
</summary>
    <author>
      <name>Tom Kenter</name>
    </author>
    <author>
      <name>Alexey Borisov</name>
    </author>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <author>
      <name>Mostafa Dehghani</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Overview of full-day tutorial at WSDM 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.02178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.02178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.02832v1</id>
    <updated>2018-01-09T08:23:46Z</updated>
    <published>2018-01-09T08:23:46Z</published>
    <title>Biomedical Question Answering via Weighted Neural Network Passage
  Retrieval</title>
    <summary>  The amount of publicly available biomedical literature has been growing
rapidly in recent years, yet question answering systems still struggle to
exploit the full potential of this source of data. In a preliminary processing
step, many question answering systems rely on retrieval models for identifying
relevant documents and passages. This paper proposes a weighted cosine distance
retrieval scheme based on neural network word embeddings. Our experiments are
based on publicly available data and tasks from the BioASQ biomedical question
answering challenge and demonstrate significant performance gains over a wide
range of state-of-the-art models.
</summary>
    <author>
      <name>Ferenc Galkó</name>
    </author>
    <author>
      <name>Carsten Eickhoff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in ECIR 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.02832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.02832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.08573v1</id>
    <updated>2018-01-25T19:22:54Z</updated>
    <published>2018-01-25T19:22:54Z</published>
    <title>Etymo: A New Discovery Engine for AI Research</title>
    <summary>  We present Etymo (https://etymo.io), a discovery engine to facilitate
artificial intelligence (AI) research and development. It aims to help readers
navigate a large number of AI-related papers published every week by using a
novel form of search that finds relevant papers and displays related papers in
a graphical interface. Etymo constructs and maintains an adaptive
similarity-based network of research papers as an all-purpose knowledge graph
for ranking, recommendation, and visualisation. The network is constantly
evolving and can learn from user feedback to adjust itself.
</summary>
    <author>
      <name>Weijian Zhang</name>
    </author>
    <author>
      <name>Jonathan Deakin</name>
    </author>
    <author>
      <name>Nicholas J. Higham</name>
    </author>
    <author>
      <name>Shuaiqiang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1801.08573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.08573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.09079v2</id>
    <updated>2018-11-25T14:36:11Z</updated>
    <published>2018-01-27T12:02:03Z</published>
    <title>Using Additional Indexes for Fast Full-Text Search of Phrases That
  Contain Frequently Used Words</title>
    <summary>  Searches for phrases and word sets in large text arrays by means of
additional indexes are considered. Their use may reduce the query-processing
time by an order of magnitude in comparison with standard inverted files.
</summary>
    <author>
      <name>A. B. Veretennikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">These results were published in: Veretennikov A.B. Using Additional
  Indexes for Fast Full-Text Search of Phrases That Contain Frequently Used
  Words. Control Systems and Information Technologies. 2013. vol. 52, no. 2.
  pp. 61-66 (in Russian). This is an English translation of the text</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Control Systems and Information Technologies. 2013. vol. 52, no.
  2. pp. 61-66 (in Russian)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1801.09079v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1801.09079v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.00366v2</id>
    <updated>2020-03-16T15:07:38Z</updated>
    <published>2018-09-02T16:24:38Z</published>
    <title>Cold-start recommendations in Collective Matrix Factorization</title>
    <summary>  This work explores the ability of collective matrix factorization models in
recommender systems to make predictions about users and items for which there
is side information available but no feedback or interactions data, and
proposes a new formulation with a faster cold-start prediction formula that can
be used in real-time systems. While these cold-start recommendations are not as
good as warm-start ones, they were found to be of better quality than
non-personalized recommendations, and predictions about new users were found to
be more reliable than those about new items. The formulation proposed here
resulted in improved cold-start recommendations in many scenarios, at the
expense of worse warm-start ones.
</summary>
    <author>
      <name>David Cortes</name>
    </author>
    <link href="http://arxiv.org/abs/1809.00366v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.00366v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.00414v1</id>
    <updated>2018-09-03T00:04:49Z</updated>
    <published>2018-09-03T00:04:49Z</published>
    <title>Hypernyms Through Intra-Article Organization in Wikipedia</title>
    <summary>  We introduce a new measure for unsupervised hypernym detection and
directionality. The motivation is to keep the measure computationally light and
portatable across languages. We show that the relative physical location of
words in explanatory articles captures the directionality property. Further,
the phrases in section titles of articles about the word, capture the semantic
similarity needed for hypernym detection task. We experimentally show that the
combination of features coming from these two simple measures suffices to
produce results comparable with the best unsupervised measures in terms of the
average precision.
</summary>
    <author>
      <name>Disha Shrivastava</name>
    </author>
    <author>
      <name>Sreyash Kenkre</name>
    </author>
    <author>
      <name>Santosh Penubothula</name>
    </author>
    <link href="http://arxiv.org/abs/1809.00414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.00414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.00934v1</id>
    <updated>2018-08-31T14:45:33Z</updated>
    <published>2018-08-31T14:45:33Z</published>
    <title>A Deep Neural Network Sentence Level Classification Method with Context
  Information</title>
    <summary>  In the sentence classification task, context formed from sentences adjacent
to the sentence being classified can provide important information for
classification. This context is, however, often ignored. Where methods do make
use of context, only small amounts are considered, making it difficult to
scale. We present a new method for sentence classification, Context-LSTM-CNN,
that makes use of potentially large contexts. The method also utilizes
long-range dependencies within the sentence being classified, using an LSTM,
and short-span features, using a stacked CNN. Our experiments demonstrate that
this approach consistently improves over previous methods on two different
datasets.
</summary>
    <author>
      <name>Xingyi Song</name>
    </author>
    <author>
      <name>Johann Petrak</name>
    </author>
    <author>
      <name>Angus Roberts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.00934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.00934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.00999v3</id>
    <updated>2018-10-23T07:44:07Z</updated>
    <published>2018-08-30T22:34:29Z</published>
    <title>Towards Large Scale Training Of Autoencoders For Collaborative Filtering</title>
    <summary>  In this paper, we apply a mini-batch based negative sampling method to
efficiently train a latent factor autoencoder model on large scale and sparse
data for implicit feedback collaborative filtering. We compare our work against
a state-of-the-art baseline model on different experimental datasets and show
that this method can lead to a good and fast approximation of the baseline
model performance. The source code is available in
https://github.com/amoussawi/recoder .
</summary>
    <author>
      <name>Abdallah Moussawi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, ACM RecSys 2018 Late-breaking Results Track (Posters)</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.00999v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.00999v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.01477v1</id>
    <updated>2018-08-31T19:31:05Z</updated>
    <published>2018-08-31T19:31:05Z</published>
    <title>A Supervised Learning Approach For Heading Detection</title>
    <summary>  As the Portable Document Format (PDF) file format increases in popularity,
research in analysing its structure for text extraction and analysis is
necessary. Detecting headings can be a crucial component of classifying and
extracting meaningful data. This research involves training a supervised
learning model to detect headings with features carefully selected through
recursive feature elimination. The best performing classifier had an accuracy
of 96.95%, sensitivity of 0.986 and a specificity of 0.953. This research into
heading detection contributes to the field of PDF based text extraction and can
be applied to the automation of large scale PDF text analysis in a variety of
professional and policy based contexts.
</summary>
    <author>
      <name>Sahib Singh Budhiraja</name>
    </author>
    <author>
      <name>Vijay Mago</name>
    </author>
    <link href="http://arxiv.org/abs/1809.01477v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.01477v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.02130v1</id>
    <updated>2018-09-06T07:56:33Z</updated>
    <published>2018-09-06T07:56:33Z</published>
    <title>Deep neural network marketplace recommenders in online experiments</title>
    <summary>  Recommendations are broadly used in marketplaces to match users with items
relevant to their interests and needs. To understand user intent and tailor
recommendations to their needs, we use deep learning to explore various
heterogeneous data available in marketplaces. This paper focuses on the
challenge of measuring recommender performance and summarizes the online
experiment results with several promising types of deep neural network
recommenders - hybrid item representation models combining features from user
engagement and content, sequence-based models, and multi-armed bandit models
that optimize user engagement by re-ranking proposals from multiple submodels.
The recommenders are currently running in production at the leading Norwegian
marketplace FINN.no and serves over one million visitors everyday.
</summary>
    <author>
      <name>Simen Eide</name>
    </author>
    <author>
      <name>Ning Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1809.02130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.02130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.03040v2</id>
    <updated>2018-10-03T21:27:27Z</updated>
    <published>2018-09-09T20:32:48Z</published>
    <title>Fairness-Aware Recommendation of Information Curators</title>
    <summary>  This paper highlights our ongoing efforts to create effective information
curator recommendation models that can be personalized for individual users,
while maintaining important fairness properties. Concretely, we introduce the
problem of information curator recommendation, provide a high-level overview of
a fairness-aware recommender, and introduce some preliminary experimental
evidence over a real-world Twitter dataset. We conclude with some thoughts on
future directions.
</summary>
    <author>
      <name>Ziwei Zhu</name>
    </author>
    <author>
      <name>Jianling Wang</name>
    </author>
    <author>
      <name>Yin Zhang</name>
    </author>
    <author>
      <name>James Caverlee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, The 2nd FATREC Workshop on Responsible
  Recommendation at RecSys, 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.03040v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.03040v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.03901v1</id>
    <updated>2018-09-11T13:54:54Z</updated>
    <published>2018-09-11T13:54:54Z</published>
    <title>Mitigating Confirmation Bias on Twitter by Recommending Opposing Views</title>
    <summary>  In this work, we propose a content-based recommendation approach to increase
exposure to opposing beliefs and opinions. Our aim is to help provide users
with more diverse viewpoints on issues, which are discussed in partisan groups
from different perspectives. Since due to the backfire effect, people's
original beliefs tend to strengthen when challenged with counter evidence, we
need to expose them to opposing viewpoints at the right time. The preliminary
work presented here describes our first step into this direction. As
illustrative showcase, we take the political debate on Twitter around the
presidency of Donald Trump.
</summary>
    <author>
      <name>Elisabeth Lex</name>
    </author>
    <author>
      <name>Mario Wagner</name>
    </author>
    <author>
      <name>Dominik Kowald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">European Symposium on Computational Social Science, Cologne, Germany</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.03901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.03901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.04019v1</id>
    <updated>2018-09-11T16:43:52Z</updated>
    <published>2018-09-11T16:43:52Z</published>
    <title>Training and Prediction Data Discrepancies: Challenges of Text
  Classification with Noisy, Historical Data</title>
    <summary>  Industry datasets used for text classification are rarely created for that
purpose. In most cases, the data and target predictions are a by-product of
accumulated historical data, typically fraught with noise, present in both the
text-based document, as well as in the targeted labels. In this work, we
address the question of how well performance metrics computed on noisy,
historical data reflect the performance on the intended future machine learning
model input. The results demonstrate the utility of dirty training datasets
used to build prediction models for cleaner (and different) prediction inputs.
</summary>
    <author>
      <name>Emilia Apostolova</name>
    </author>
    <author>
      <name>R. Andrew Kreek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2018 The 4th Workshop on Noisy User-generated Text (W-NUT)</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.04019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.04019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.05685v1</id>
    <updated>2018-09-15T09:43:57Z</updated>
    <published>2018-09-15T09:43:57Z</published>
    <title>Commentary on Quantum-Inspired Information Retrieval</title>
    <summary>  There have been suggestions within the Information Retrieval (IR) community
that quantum mechanics (QM) can be used to help formalise the foundations of
IR. The invoked connection to QM is mathematical rather than physical. The
proposed ideas are concerned with information which is encoded, processed and
accessed in classical computers. However, some of the suggestions have been
thoroughly muddled with questions about applying techniques of quantum
information theory in IR, and it is often unclear whether or not the suggestion
is to perform actual quantum information processing on the information. This
paper is an attempt to provide some conceptual clarity on the emerging issues.
</summary>
    <author>
      <name>Elham Ashoori</name>
    </author>
    <author>
      <name>Terry Rudolph</name>
    </author>
    <link href="http://arxiv.org/abs/1809.05685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.05685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.06366v1</id>
    <updated>2018-09-15T22:11:03Z</updated>
    <published>2018-09-15T22:11:03Z</published>
    <title>AUEB at BioASQ 6: Document and Snippet Retrieval</title>
    <summary>  We present AUEB's submissions to the BioASQ 6 document and snippet retrieval
tasks (parts of Task 6b, Phase A). Our models use novel extensions to deep
learning architectures that operate solely over the text of the query and
candidate document/snippets. Our systems scored at the top or near the top for
all batches of the challenge, highlighting the effectiveness of deep learning
for these tasks.
</summary>
    <author>
      <name>Georgios-Ioannis Brokos</name>
    </author>
    <author>
      <name>Polyvios Liosis</name>
    </author>
    <author>
      <name>Ryan McDonald</name>
    </author>
    <author>
      <name>Dimitris Pappas</name>
    </author>
    <author>
      <name>Ion Androutsopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the workshop BioASQ: Large-scale Biomedical
  Semantic Indexing and Question Answering, at the Conference on Empirical
  Methods in Natural Language Processing (EMNLP 2018), Brussels, Belgium, 2018.
  arXiv admin note: text overlap with arXiv:1809.01682</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.06366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.06366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.06943v1</id>
    <updated>2018-09-18T21:35:37Z</updated>
    <published>2018-09-18T21:35:37Z</published>
    <title>Argumentation Mining: Exploiting Multiple Sources and Background
  Knowledge</title>
    <summary>  The field of Argumentation Mining has arisen from the need of determining the
underlying causes from an expressed opinion and the urgency to develop the
established fields of Opinion Mining and Sentiment Analysis. The recent
progress in the wider field of Artificial Intelligence in combination with the
available data through Social Web has create great potential for every
sub-field of Natural Language Process including Argumentation Mining.
</summary>
    <author>
      <name>Anastasios Lytos</name>
    </author>
    <author>
      <name>Thomas Lagkas</name>
    </author>
    <author>
      <name>Panagiotis Sarigiannidis</name>
    </author>
    <author>
      <name>Kalina Bontcheva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12th Annual South-East European Doctoral Student Conference
  (DSC2018), ISBN: 978-960-9416-20-7, pp. 66-74, Thessaloniki, Greece, May 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.06943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.06943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.07256v1</id>
    <updated>2018-09-19T15:49:12Z</updated>
    <published>2018-09-19T15:49:12Z</published>
    <title>Audio Based Disambiguation Of Music Genre Tags</title>
    <summary>  In this paper, we propose to infer music genre embeddings from audio datasets
carrying semantic information about genres. We show that such embeddings can be
used for disambiguating genre tags (identification of different labels for the
same genre, tag translation from a tag system to another, inference of
hierarchical taxonomies on these genre tags). These embeddings are built by
training a deep convolutional neural network genre classifier with large audio
datasets annotated with a flat tag system. We show empirically that they makes
it possible to retrieve the original taxonomy of a tag system, spot duplicates
tags and translate tags from a tag system to another.
</summary>
    <author>
      <name>Romain Hennequin</name>
    </author>
    <author>
      <name>Jimena Royo-Letelier</name>
    </author>
    <author>
      <name>Manuel Moussallam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in ISMIR 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.07256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.07256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.08711v1</id>
    <updated>2018-09-24T01:06:46Z</updated>
    <published>2018-09-24T01:06:46Z</published>
    <title>Recognizing Film Entities in Podcasts</title>
    <summary>  In this paper, we propose a Named Entity Recognition (NER) system to identify
film titles in podcast audio. Taking inspiration from NER systems for noisy
text in social media, we implement a two-stage approach that is robust to
computer transcription errors and does not require significant computational
expense to accommodate new film titles/releases. Evaluating on a diverse set of
podcasts, we demonstrate more than a 20% increase in F1 score across three
baseline approaches when combining fuzzy-matching with a linear model aware of
film-specific metadata.
</summary>
    <author>
      <name>Ahmet Salih Gundogdu</name>
    </author>
    <author>
      <name>Arjun Sanghvi</name>
    </author>
    <author>
      <name>Keith Harrigian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure. To appear in Proceedings of 2018 KDD Workshop on
  Machine Learning and Data Mining for Podcasts, August 2018, London, UK</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.08711v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.08711v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.09096v1</id>
    <updated>2018-09-24T11:00:57Z</updated>
    <published>2018-09-24T11:00:57Z</published>
    <title>Text Summarization as Tree Transduction by Top-Down TreeLSTM</title>
    <summary>  Extractive compression is a challenging natural language processing problem.
This work contributes by formulating neural extractive compression as a parse
tree transduction problem, rather than a sequence transduction task. Motivated
by this, we introduce a deep neural model for learning
structure-to-substructure tree transductions by extending the standard Long
Short-Term Memory, considering the parent-child relationships in the structural
recursion. The proposed model can achieve state of the art performance on
sentence compression benchmarks, both in terms of accuracy and compression
rate.
</summary>
    <author>
      <name>Davide Bacciu</name>
    </author>
    <author>
      <name>Antonio Bruno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in IEEE SCCI Deep Learning 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.09096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.09096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.09621v1</id>
    <updated>2018-09-25T08:38:05Z</updated>
    <published>2018-09-25T08:38:05Z</published>
    <title>Inferring Complementary Products from Baskets and Browsing Sessions</title>
    <summary>  Complementary products recommendation is an important problem in e-commerce.
Such recommendations increase the average order price and the number of
products in baskets. Complementary products are typically inferred from basket
data. In this study, we propose the BB2vec model. The BB2vec model learns
vector representations of products by analyzing jointly two types of data -
Baskets and Browsing sessions (visiting web pages of products). These vector
representations are used for making complementary products recommendation. The
proposed model alleviates the cold start problem by delivering better
recommendations for products having few or no purchases. We show that the
BB2vec model has better performance than other models which use only basket
data.
</summary>
    <author>
      <name>Ilya Trofimov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Intelligent Recommender Systems by Knowledge Transfer and
  Learning (RecSysKTL'18)</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.09621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.09621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1809.09955v1</id>
    <updated>2018-09-11T16:11:48Z</updated>
    <published>2018-09-11T16:11:48Z</published>
    <title>Knowledge extraction, modeling and formalization: EEG case study</title>
    <summary>  Formal Concept Analysis (FCA) is a well-established method for data analysis
which finds many applications in data mining. Its extension on complex data
representation formats brought a wave of new applications to the problems such
as gene expression mining, prediction of toxicity of chemical compounds or
clustering of sequences in process event logs. Insipired from this work our
research inherits their model and designs an experiment for mining
electroencephalographic recordings for patterns of sleep spindles. The
contribution of this paper lies in the specification of desritizition procedure
and the architecture of FCA experiment. We also provide some reflection on the
related research papers.
</summary>
    <author>
      <name>Dmitry Morozov</name>
    </author>
    <author>
      <name>Mario Lezoche</name>
    </author>
    <author>
      <name>Hervé Panetto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1506.05018 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1809.09955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1809.09955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.00854v1</id>
    <updated>2018-11-01T17:48:18Z</updated>
    <published>2018-11-01T17:48:18Z</published>
    <title>Improving Information Retrieval Results for Persian Documents using
  FarsNet</title>
    <summary>  In this paper, we propose a new method for query expansion, which uses
FarsNet (Persian WordNet) to find similar tokens related to the query and
expand the semantic meaning of the query. For this purpose, we use synonymy
relations in FarsNet and extract the related synonyms to query words. This
algorithm is used to enhance information retrieval systems and improve search
results. The overall evaluation of this system in comparison to the baseline
method (without using query expansion) shows an improvement of about 9 percent
in Mean Average Precision (MAP).
</summary>
    <author>
      <name>Adel Rahimi</name>
    </author>
    <author>
      <name>Mohammad Bahrani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.00854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.00854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.03275v1</id>
    <updated>2018-11-08T05:11:37Z</updated>
    <published>2018-11-08T05:11:37Z</published>
    <title>Quantum Semantic Correlations in Hate and Non-Hate Speeches</title>
    <summary>  This paper aims to apply the notions of quantum geometry and correlation to
the typification of semantic relations between couples of keywords in different
documents. In particular we analysed texts classified as hate / non hate
speeches, containing the keywords "women", "white", and "black". The paper
compares this approach to cosine similarity, a classical methodology, to cast
light on the notion of "similar meaning".
</summary>
    <author>
      <name>Francesco Galofaro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">POLIMI, UNIBZ</arxiv:affiliation>
    </author>
    <author>
      <name>Zeno Toffano</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Centralesupélec</arxiv:affiliation>
    </author>
    <author>
      <name>Bich-Liên Doan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Centralesupélec</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.283.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.283.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings CAPNS 2018, arXiv:1811.02701</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 283, 2018, pp. 62-74</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1811.03275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.03275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1811.11746v1</id>
    <updated>2018-11-29T15:20:32Z</updated>
    <published>2018-11-29T15:20:32Z</published>
    <title>Incremental Sparse TFIDF &amp; Incremental Similarity with Bipartite Graphs</title>
    <summary>  In this report, we experimented with several concepts regarding text streams
analysis.
  We tested an implementation of Incremental Sparse TF-IDF (IS-TFIDF) and
Incremental Cosine Similarity (ICS) with the use of bipartite graphs.
  We are using bipartite graphs - one type of node are documents, and the other
type of nodes are words - to know what documents are affected with a word
arrival at the stream (the neighbors of the word in the graph). Thus, with this
information, we leverage optimized algorithms used for graph-based
applications. The concept is similar to, for example, the use of hash tables or
other computer science concepts used for fast access to information in memory.
</summary>
    <author>
      <name>Rui Portocarrero Sarmento</name>
    </author>
    <author>
      <name>Pavel Brazdil</name>
    </author>
    <link href="http://arxiv.org/abs/1811.11746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.11746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.00427v1</id>
    <updated>2018-12-02T16:59:39Z</updated>
    <published>2018-12-02T16:59:39Z</published>
    <title>Report on the 3rd Joint Workshop on Bibliometric-enhanced Information
  Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2018)</title>
    <summary>  The $3^{rd}$ joint BIRNDL workshop was held at the 41st ACM SIGIR Conference
on Research and Development in Information Retrieval (SIGIR 2018) in Ann Arbor,
USA. BIRNDL 2018 intended to stimulate IR researchers and digital library
professionals to elaborate on new approaches in natural language processing,
information retrieval, scientometrics, and recommendation techniques that can
advance the state-of-the-art in scholarly document understanding, analysis, and
retrieval at scale. The workshop incorporated three paper sessions and the
$4^{th}$ edition of the CL-SciSumm Shared Task.
</summary>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <author>
      <name>Muthu Kumar Chandrasekaran</name>
    </author>
    <author>
      <name>Kokil Jaidka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, to appear in SIGIR Forum</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.00427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.00427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.01567v1</id>
    <updated>2018-12-04T18:15:33Z</updated>
    <published>2018-12-04T18:15:33Z</published>
    <title>Information Extraction Framework to Build Legislation Network</title>
    <summary>  This paper concerns an Information Extraction process for building a dynamic
Legislation Network from legal documents. Unlike supervised learning approaches
which require additional calculations, the idea here is to apply Information
Extraction methodologies by identifying distinct expressions in legal text and
extract quality network information. The study highlights the importance of
data accuracy in network analysis and improves approximate string matching
techniques for producing reliable network data-sets with more than 98 percent
precision and recall. The values, applications, and the complexity of the
created dynamic Legislation Network are also discussed and challenged.
</summary>
    <author>
      <name>Neda Sakhaee</name>
    </author>
    <author>
      <name>Mark C Wilson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10506-020-09263-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10506-020-09263-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Artif Intell Law (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.01567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.01567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.04265v1</id>
    <updated>2018-12-11T08:23:01Z</updated>
    <published>2018-12-11T08:23:01Z</published>
    <title>Proceedings of the 17th Dutch-Belgian Information Retrieval Workshop</title>
    <summary>  This volume contains the papers presented at DIR 2018: 17th Dutch-Belgian
Information Retrieval Workshop (DIR) held on November 23, 2018 in Leiden. DIR
aims to serve as an international platform (with a special focus on the
Netherlands and Belgium) for exchange and discussions on research &amp;
applications in the field of information retrieval and related fields.
  The committee accepted 4 short papers presenting novel work, 3 demo
proposals, and 8 compressed contributions (summaries of papers recently
published in international journals and conferences). Each submission was
reviewed by at least 3 programme committee members.
</summary>
    <author>
      <name>Alex Brandsen</name>
    </author>
    <author>
      <name>Anne Dirkson</name>
    </author>
    <author>
      <name>Wessel Kraaij</name>
    </author>
    <author>
      <name>Wout Lamers</name>
    </author>
    <author>
      <name>Suzan Verberne</name>
    </author>
    <author>
      <name>Hugo de Vos</name>
    </author>
    <author>
      <name>Gineke Wiggers</name>
    </author>
    <link href="http://arxiv.org/abs/1812.04265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.04265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10119v1</id>
    <updated>2018-12-25T15:24:04Z</updated>
    <published>2018-12-25T15:24:04Z</published>
    <title>Sequence to Sequence Learning for Query Expansion</title>
    <summary>  Using sequence to sequence algorithms for query expansion has not been
explored yet in Information Retrieval literature nor in Question-Answering's.
We tried to fill this gap in the literature with a custom Query Expansion
engine trained and tested on open datasets. Starting from open datasets, we
built a Query Expansion training set using sentence-embeddings-based Keyword
Extraction. We therefore assessed the ability of the Sequence to Sequence
neural networks to capture expanding relations in the words embeddings' space.
</summary>
    <author>
      <name>Salah Zaiem</name>
    </author>
    <author>
      <name>Fatiha Sadat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, AAAI-19 Student Abstract and Poster Program</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.10119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.10814v1</id>
    <updated>2018-12-27T20:09:51Z</updated>
    <published>2018-12-27T20:09:51Z</published>
    <title>Uni-DUE Student Team: Tackling fact checking through decomposable
  attention neural network</title>
    <summary>  In this paper we present our system for the FEVER Challenge. The task of this
challenge is to verify claims by extracting information from Wikipedia. Our
system has two parts. In the first part it performs a search for candidate
sentences by treating the claims as query. In the second part it filters out
noise from these candidates and uses the remaining ones to decide whether they
support or refute or entail not enough information to verify the claim. We show
that this system achieves a FEVER score of 0.3927 on the FEVER shared task
development data set which is a 25.5% improvement over the baseline score.
</summary>
    <author>
      <name>Jan Kowollik</name>
    </author>
    <author>
      <name>Ahmet Aker</name>
    </author>
    <link href="http://arxiv.org/abs/1812.10814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.10814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11321v1</id>
    <updated>2018-12-29T09:34:23Z</updated>
    <published>2018-12-29T09:34:23Z</published>
    <title>Attention-Based Capsule Networks with Dynamic Routing for Relation
  Extraction</title>
    <summary>  A capsule is a group of neurons, whose activity vector represents the
instantiation parameters of a specific type of entity. In this paper, we
explore the capsule networks used for relation extraction in a multi-instance
multi-label learning framework and propose a novel neural approach based on
capsule networks with attention mechanisms. We evaluate our method with
different benchmarks, and it is demonstrated that our method improves the
precision of the predicted relations. Particularly, we show that capsule
networks improve multiple entity pairs relation extraction.
</summary>
    <author>
      <name>Ningyu Zhang</name>
    </author>
    <author>
      <name>Shumin Deng</name>
    </author>
    <author>
      <name>Zhanlin Sun</name>
    </author>
    <author>
      <name>Xi Chen</name>
    </author>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Huajun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in EMNLP 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1812.11321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1812.11740v1</id>
    <updated>2018-12-31T09:51:37Z</updated>
    <published>2018-12-31T09:51:37Z</published>
    <title>A Neural Network Based Explainable Recommender System</title>
    <summary>  Recommendation system could help the companies to persuade users to visit or
consume at a particular place, which was based on many traditional methods such
as the set of collaborative filtering algorithms. Most research discusses the
model design or feature engineering methods to minimize the root mean square
error (RMSE) of rating prediction, but lacks exploring the ways to generate the
reasons for recommendations. This paper proposed an integrated neural network
based model which integrates rating scores prediction and explainable words
generation. Based on the experimental results, this model presented lower RMSE
compared with traditional methods, and generate the explanation of
recommendation to convince customers to visit the recommended place.
</summary>
    <author>
      <name>Jionghao Lin</name>
    </author>
    <author>
      <name>Yiren Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1812.11740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.11740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.02407v1</id>
    <updated>2019-02-06T21:54:45Z</updated>
    <published>2019-02-06T21:54:45Z</published>
    <title>A Comparison of Information Retrieval Techniques for Detecting Source
  Code Plagiarism</title>
    <summary>  Plagiarism is a commonly encountered problem in the academia. While there are
several tools and techniques to efficiently determine plagiarism in text, the
same cannot be said about source code plagiarism. To make the existing systems
more efficient, we use several information retrieval techniques to find the
similarity between source code files written in Java. We later use JPlag, which
is a string-based plagiarism detection tool used in academia to match the
plagiarized source codes. In this paper, we aim to generalize on the efficiency
and effectiveness of detecting plagiarism using different information retrieval
models rather than using just string manipulation algorithms.
</summary>
    <author>
      <name>Vasishtha Sriram Jayapati</name>
    </author>
    <author>
      <name>Ajay Venkitaraman</name>
    </author>
    <link href="http://arxiv.org/abs/1902.02407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.02407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.08251v2</id>
    <updated>2019-03-06T04:48:38Z</updated>
    <published>2019-02-21T20:25:46Z</published>
    <title>WebProtégé: A Cloud-Based Ontology Editor</title>
    <summary>  We present WebProt\'eg\'e, a tool to develop ontologies represented in the
Web Ontology Language (OWL). WebProt\'eg\'e is a cloud-based application that
allows users to collaboratively edit OWL ontologies, and it is available for
use at https://webprotege.stanford.edu. WebProt\'ege\'e currently hosts more
than 68,000 OWL ontology projects and has over 50,000 user accounts. In this
paper, we detail the main new features of the latest version of WebProt\'eg\'e.
</summary>
    <author>
      <name>Matthew Horridge</name>
    </author>
    <author>
      <name>Rafael S. Gonçalves</name>
    </author>
    <author>
      <name>Csongor I. Nyulas</name>
    </author>
    <author>
      <name>Tania Tudorache</name>
    </author>
    <author>
      <name>Mark A. Musen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308560.3317707</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308560.3317707" rel="related"/>
    <link href="http://arxiv.org/abs/1902.08251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.08251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1902.10371v1</id>
    <updated>2019-02-27T07:42:53Z</updated>
    <published>2019-02-27T07:42:53Z</published>
    <title>Query Term Weighting based on Query Performance Prediction</title>
    <summary>  This work presents a general query term weighting approach based on query
performance prediction (QPP). To this end, a given term is weighed according to
its predicted effect on query performance. Such an effect is assumed to be
manifested in the responses made by the underlying retrieval method for the
original query and its (simple) variants in the form of a single-term expanded
query. Focusing on search re-ranking as the underlying application, the
effectiveness of the proposed term weighting approach is demonstrated using
several state-of-the-art QPP methods evaluated over TREC corpora.
</summary>
    <author>
      <name>Haggai Roitman</name>
    </author>
    <link href="http://arxiv.org/abs/1902.10371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.10371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.04489v1</id>
    <updated>2019-03-11T14:18:43Z</updated>
    <published>2019-03-11T14:18:43Z</published>
    <title>SPMF: A Social Trust and Preference Segmentation-based Matrix
  Factorization Recommendation Algorithm</title>
    <summary>  The traditional social recommendation algorithm ignores the following fact:
the preferences of users with trust relationships are not necessarily similar,
and the consideration of user preference similarity should be limited to
specific areas. A social trust and preference segmentation-based matrix
factorization (SPMF) recommendation system is proposed to solve the
above-mentioned problems. Experimental results based on the Ciao and Epinions
datasets show that the accuracy of the SPMF algorithm is significantly higher
than that of some state-of-the-art recommendation algorithms. The proposed SPMF
algorithm is a more accurate and effective recommendation algorithm based on
distinguishing the difference of trust relations and preference domain, which
can support commercial activities such as product marketing.
</summary>
    <author>
      <name>Wei Peng</name>
    </author>
    <author>
      <name>Baogui Xin</name>
    </author>
    <link href="http://arxiv.org/abs/1903.04489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.04489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.04748v2</id>
    <updated>2019-05-10T07:46:39Z</updated>
    <published>2019-03-12T07:01:15Z</published>
    <title>Extracting localized information from a Twitter corpus for flood
  prevention</title>
    <summary>  In this paper, we discuss the collection of a corpus associated to tropical
storm Harvey, as well as its analysis from both spatial and topical
perspectives. From the spatial perspective, our goal here is to get a first
estimation of the quality and precision of the geographical information
featured in the collected corpus. From a topical perspective, we discuss the
representation of Twitter posts, and strategies to process an initially
unlabeled corpus of tweets.
</summary>
    <author>
      <name>Etienne Brangbour</name>
    </author>
    <author>
      <name>Pierrick Bruneau</name>
    </author>
    <author>
      <name>Stéphane Marchand-Maillet</name>
    </author>
    <author>
      <name>Renaud Hostache</name>
    </author>
    <author>
      <name>Patrick Matgen</name>
    </author>
    <author>
      <name>Marco Chini</name>
    </author>
    <author>
      <name>Thomas Tamisier</name>
    </author>
    <link href="http://arxiv.org/abs/1903.04748v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.04748v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.08756v1</id>
    <updated>2019-03-20T21:52:13Z</updated>
    <published>2019-03-20T21:52:13Z</published>
    <title>Distributed Vector Representations of Folksong Motifs</title>
    <summary>  This article presents a distributed vector representation model for learning
folksong motifs. A skip-gram version of word2vec with negative sampling is used
to represent high quality embeddings. Motifs from the Essen Folksong collection
are compared based on their cosine similarity. A new evaluation method for
testing the quality of the embeddings based on a melodic similarity task is
presented to show how the vector space can represent complex contextual
features, and how it can be utilized for the study of folksong variation.
</summary>
    <author>
      <name>Aitor Arronte-Alvarez</name>
    </author>
    <author>
      <name>Francisco Gómez-Martin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MCM 19</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.08756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.08756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10117v1</id>
    <updated>2019-03-25T03:33:06Z</updated>
    <published>2019-03-25T03:33:06Z</published>
    <title>Fiducia: A Personalized Food Recommender System for Zomato</title>
    <summary>  This paper presents Fiducia, a food review system involving a pipeline which
processes restaurant-related reviews obtained from Zomato (India's largest
restaurant search and discovery service). Fiducia is specific to popular cafe
food items and manages to identify relevant information pertaining to each item
separately in the reviews. It uses a sentiment check on these pieces of text
and accordingly suggests an appropriate restaurant for the particular item
depending on user-item and item-item similarity. Experimental results show that
the sentiment analyzer module of Fiducia achieves an accuracy of over 85% and
our final recommender system achieves an RMSE of about 1.01 beating other
baselines.
</summary>
    <author>
      <name>Mansi Goel</name>
    </author>
    <author>
      <name>Ayush Agarwal</name>
    </author>
    <author>
      <name>Deepak Thukral</name>
    </author>
    <author>
      <name>Tanmoy Chakraborty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1903.10117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1903.10972v1</id>
    <updated>2019-03-26T15:58:33Z</updated>
    <published>2019-03-26T15:58:33Z</published>
    <title>Simple Applications of BERT for Ad Hoc Document Retrieval</title>
    <summary>  Following recent successes in applying BERT to question answering, we explore
simple applications to ad hoc document retrieval. This required confronting the
challenge posed by documents that are typically longer than the length of input
BERT was designed to handle. We address this issue by applying inference on
sentences individually, and then aggregating sentence scores to produce
document scores. Experiments on TREC microblog and newswire test collections
show that our approach is simple yet effective, as we report the highest
average precision on these datasets by neural approaches that we are aware of.
</summary>
    <author>
      <name>Wei Yang</name>
    </author>
    <author>
      <name>Haotian Zhang</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1903.10972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.10972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.00289v1</id>
    <updated>2019-03-30T21:14:09Z</updated>
    <published>2019-03-30T21:14:09Z</published>
    <title>On the Estimation and Use of Statistical Modelling in Information
  Retrieval</title>
    <summary>  Several tasks in information retrieval (IR) rely on assumptions regarding the
distribution of some property (such as term frequency) in the data being
processed. This thesis argues that such distributional assumptions can lead to
incorrect conclusions and proposes a statistically principled method for
determining the "true" distribution. This thesis further applies this method to
derive a new family of ranking models that adapt their computations to the
statistics of the data being processed. Experimental evaluation shows results
on par or better than multiple strong baselines on several TREC collections.
Overall, this thesis concludes that distributional assumptions can be replaced
with an effective, efficient and principled method for determining the "true"
distribution and that using the "true" distribution can lead to improved
retrieval performance.
</summary>
    <author>
      <name>Casper Petersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Phd thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.00289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.00289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.01353v2</id>
    <updated>2019-05-20T11:16:54Z</updated>
    <published>2019-04-02T11:50:55Z</published>
    <title>Verification and Validation of Semantic Annotations</title>
    <summary>  In this paper, we propose a framework to perform verification and validation
of semantically annotated data. The annotations, extracted from websites, are
verified against the schema.org vocabulary and Domain Specifications to ensure
the syntactic correctness and completeness of the annotations. The Domain
Specifications allow checking the compliance of annotations against
corresponding domain-specific constraints. The validation mechanism will detect
errors and inconsistencies between the content of the analyzed schema.org
annotations and the content of the web pages where the annotations were found.
</summary>
    <author>
      <name>Oleksandra Panasiuk</name>
    </author>
    <author>
      <name>Omar Holzknecht</name>
    </author>
    <author>
      <name>Umutcan Şimşek</name>
    </author>
    <author>
      <name>Elias Kärle</name>
    </author>
    <author>
      <name>Dieter Fensel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for the A.P. Ershov Informatics Conference 2019(the PSI
  Conference Series, 12th edition) proceeding</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.01353v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.01353v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.03401v1</id>
    <updated>2019-04-06T09:44:30Z</updated>
    <published>2019-04-06T09:44:30Z</published>
    <title>Idealize - A Notion of Idea Strength</title>
    <summary>  Business Entrepreneurs frequently thrive on looking for ways to test business
ideas, without giving too much information. Recent techniques in startup
development promote the use of surveys to measure the potential client's
interest. In this preliminary report, we describe the concept behind Idealize,
a Shiny R application to measure the local trend strength of a potential idea.
Additionally, the system might provide a relative distance to the capital city
of the country. The tests were made for the United States of America, i.e.,
made available regarding native English language. This report shows some of the
tests results with this system.
</summary>
    <author>
      <name>Rui Portocarrero Sarmento</name>
    </author>
    <link href="http://arxiv.org/abs/1904.03401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.03401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.04995v1</id>
    <updated>2019-04-10T03:49:37Z</updated>
    <published>2019-04-10T03:49:37Z</published>
    <title>AMRec: An Intelligent System for Academic Method Recommendation</title>
    <summary>  Finding new academic Methods for research problems is the key task in a
researcher's research career. It is usually very difficult for new researchers
to find good Methods for their research problems since they lack of research
experiences. In order to help researchers carry out their researches in a more
convenient way, we describe a novel recommendation system called AMRec to
recommend new academic Methods for research problems in this paper. Our
proposed system first extracts academic concepts (Tasks and Methods) and their
relations from academic literatures, and then leverages the regularized matrix
factorization Method for academic Method recommendation. Preliminary evaluation
results verify the effectiveness of our proposed system.
</summary>
    <author>
      <name>Shanshan Huang</name>
    </author>
    <author>
      <name>Xiaojun Wan</name>
    </author>
    <author>
      <name>Xuewei Tang</name>
    </author>
    <link href="http://arxiv.org/abs/1904.04995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.04995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.05737v1</id>
    <updated>2019-04-11T14:50:58Z</updated>
    <published>2019-04-11T14:50:58Z</published>
    <title>Investigating Retrieval Method Selection with Axiomatic Features</title>
    <summary>  We consider algorithm selection in the context of ad-hoc information
retrieval. Given a query and a pair of retrieval methods, we propose a
meta-learner that predicts how to combine the methods' relevance scores into an
overall relevance score. Inspired by neural models' different properties with
regard to IR axioms, these predictions are based on features that quantify
axiom-related properties of the query and its top ranked documents. We conduct
an evaluation on TREC Web Track data and find that the meta-learner often
significantly improves over the individual methods. Finally, we conduct feature
and query weight analyses to investigate the meta-learner's behavior.
</summary>
    <author>
      <name>Siddhant Arora</name>
    </author>
    <author>
      <name>Andrew Yates</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Algorithm Selection and Meta-Learning in Information Retrieval
  (AMIR'19) workshop at ECIR'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.05737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.05737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.06672v1</id>
    <updated>2019-04-14T10:35:56Z</updated>
    <published>2019-04-14T10:35:56Z</published>
    <title>RelEmb: A relevance-based application embedding for Mobile App retrieval
  and categorization</title>
    <summary>  Information Retrieval Systems have revolutionized the organization and
extraction of Information. In recent years, mobile applications (apps) have
become primary tools of collecting and disseminating information. However,
limited research is available on how to retrieve and organize mobile apps on
users' devices. In this paper, authors propose a novel method to estimate
app-embeddings which are then applied to tasks like app clustering,
classification, and retrieval. Usage of app-embedding for query expansion,
nearest neighbor analysis enables unique and interesting use cases to enhance
end-user experience with mobile apps.
</summary>
    <author>
      <name>Ahsaas Bajaj</name>
    </author>
    <author>
      <name>Shubham Krishna</name>
    </author>
    <author>
      <name>Mukund Rungta</name>
    </author>
    <author>
      <name>Hemant Tiwari</name>
    </author>
    <author>
      <name>Vanraj Vala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages. Accepted at CICLing 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.06672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.06672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12162v2</id>
    <updated>2019-05-25T13:30:47Z</updated>
    <published>2019-04-27T14:46:34Z</published>
    <title>Sentiment Classification using N-gram IDF and Automated Machine Learning</title>
    <summary>  We propose a sentiment classification method with a general machine learning
framework. For feature representation, n-gram IDF is used to extract
software-engineering-related, dataset-specific, positive, neutral, and negative
n-gram expressions. For classifiers, an automated machine learning tool is
used. In the comparison using publicly available datasets, our method achieved
the highest F1 values in positive and negative sentences on all datasets.
</summary>
    <author>
      <name>Rungroj Maipradit</name>
    </author>
    <author>
      <name>Hideaki Hata</name>
    </author>
    <author>
      <name>Kenichi Matsumoto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, IEEE Software</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12162v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12162v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12578v1</id>
    <updated>2019-03-24T08:09:15Z</updated>
    <published>2019-03-24T08:09:15Z</published>
    <title>HAXMLNet: Hierarchical Attention Network for Extreme Multi-Label Text
  Classification</title>
    <summary>  Extreme multi-label text classification (XMTC) addresses the problem of
tagging each text with the most relevant labels from an extreme-scale label
set. Traditional methods use bag-of-words (BOW) representations without context
information as their features. The state-ot-the-art deep learning-based method,
AttentionXML, which uses a recurrent neural network (RNN) and the multi-label
attention, can hardly deal with extreme-scale (hundreds of thousands labels)
problem. To address this, we propose our HAXMLNet, which uses an efficient and
effective hierarchical structure with the multi-label attention. Experimental
results show that HAXMLNet reaches a competitive performance with other
state-of-the-art methods.
</summary>
    <author>
      <name>Ronghui You</name>
    </author>
    <author>
      <name>Zihan Zhang</name>
    </author>
    <author>
      <name>Suyang Dai</name>
    </author>
    <author>
      <name>Shanfeng Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12587v1</id>
    <updated>2019-04-04T15:41:26Z</updated>
    <published>2019-04-04T15:41:26Z</published>
    <title>Text Classification Components for Detecting Descriptions and Names of
  CAD models</title>
    <summary>  We apply text analysis approaches for a specialized search engine for 3D CAD
models and associated products. The main goals are to distinguish between
actual product descriptions and other text on a website, as well as to decide
whether a given text is or contains a product name.
  For this we use paragraph vectors for text classification, a character-level
long short-term memory network (LSTM) for a single word classification and an
LSTM tagger based on word embeddings for detecting product names within
sentences. Despite the need to collect bigger datasets in our specific problem
domain, the first results are promising and partially fit for production use.
</summary>
    <author>
      <name>Thomas Köllmer</name>
    </author>
    <author>
      <name>Jens Hasselbach</name>
    </author>
    <author>
      <name>Patrick Aichroth</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12587v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12587v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1904.12624v1</id>
    <updated>2019-04-18T13:38:57Z</updated>
    <published>2019-04-18T13:38:57Z</published>
    <title>BowTie - A deep learning feedforward neural network for sentiment
  analysis</title>
    <summary>  How to model and encode the semantics of human-written text and select the
type of neural network to process it are not settled issues in sentiment
analysis. Accuracy and transferability are critical issues in machine learning
in general. These properties are closely related to the loss estimates for the
trained model. I present a computationally-efficient and accurate feedforward
neural network for sentiment prediction capable of maintaining low losses. When
coupled with an effective semantics model of the text, it provides highly
accurate models with low losses. Experimental results on representative
benchmark datasets and comparisons to other methods show the advantages of the
new approach.
</summary>
    <author>
      <name>Apostol Vassilev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-37599-7_30</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-37599-7_30" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1904.12624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00041v1</id>
    <updated>2019-05-31T19:22:29Z</updated>
    <published>2019-05-31T19:22:29Z</published>
    <title>Table2Vec: Neural Word and Entity Embeddings for Table Population and
  Retrieval</title>
    <summary>  Tables contain valuable knowledge in a structured form. We employ neural
language modeling approaches to embed tabular data into vector spaces.
Specifically, we consider different table elements, such caption, column
headings, and cells, for training word and entity embeddings. These embeddings
are then utilized in three particular table-related tasks, row population,
column population, and table retrieval, by incorporating them into existing
retrieval models as additional semantic similarity signals. Evaluation results
show that table embeddings can significantly improve upon the performance of
state-of-the-art baselines.
</summary>
    <author>
      <name>Li Deng</name>
    </author>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3331184.3331333</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3331184.3331333" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 42nd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR '19), 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.00529v1</id>
    <updated>2019-06-03T02:22:35Z</updated>
    <published>2019-06-03T02:22:35Z</published>
    <title>Mining Data from the Congressional Record</title>
    <summary>  We propose a data storage and analysis method for using the US Congressional
record as a policy analysis tool. We use Amazon Web Services and the Solr
search engine to store and process Congressional record data from 1789 to the
present, and then query Solr to find how frequently language related to tax
increases and decreases appears. This frequency data is compared to six
economic indicators. Our preliminary results indicate potential relationships
between incidence of tax discussion and multiple indicators. We present our
data storage and analysis procedures, as well as results from comparisons to
all six indicators.
</summary>
    <author>
      <name>Zhengyu Ma</name>
    </author>
    <author>
      <name>Tianjiao Qi</name>
    </author>
    <author>
      <name>James Route</name>
    </author>
    <author>
      <name>Amir Ziai</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.01435v1</id>
    <updated>2019-05-31T23:20:01Z</updated>
    <published>2019-05-31T23:20:01Z</published>
    <title>Incorporating System-Level Objectives into Recommender Systems</title>
    <summary>  One of the most essential parts of any recommender system is
personalization-- how acceptable the recommendations are from the user's
perspective. However, in many real-world applications, there are other
stakeholders whose needs and interests should be taken into account. In this
work, we define the problem of multistakeholder recommendation and we focus on
finding algorithms for a special case where the recommender system itself is
also a stakeholder. In addition, we will explore the idea of incremental
incorporation of system-level objectives into recommender systems over time to
tackle the existing problems in the optimization techniques which only look for
optimizing the individual users' lists.
</summary>
    <author>
      <name>Himan Abdollahpouri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3308560.3314201</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3308560.3314201" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1901.07555</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02329v1</id>
    <updated>2019-06-05T22:05:36Z</updated>
    <published>2019-06-05T22:05:36Z</published>
    <title>Context Attentive Document Ranking and Query Suggestion</title>
    <summary>  We present a context-aware neural ranking model to exploit users' on-task
search activities and enhance retrieval performance. In particular, a two-level
hierarchical recurrent neural network is introduced to learn search context
representation of individual queries, search tasks, and corresponding
dependency structure by jointly optimizing two companion retrieval tasks:
document ranking and query suggestion. To identify the variable dependency
structure between search context and users' ongoing search activities,
attention at both levels of recurrent states are introduced. Extensive
experiment comparisons against a rich set of baseline methods and an in-depth
ablation analysis confirm the value of our proposed approach for modeling
search context buried in search tasks.
</summary>
    <author>
      <name>Wasi Uddin Ahmad</name>
    </author>
    <author>
      <name>Kai-Wei Chang</name>
    </author>
    <author>
      <name>Hongning Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to SIGIR 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.02408v1</id>
    <updated>2019-06-06T04:14:44Z</updated>
    <published>2019-06-06T04:14:44Z</published>
    <title>Comprehensive Personalized Ranking Using One-Bit Comparison Data</title>
    <summary>  The task of a personalization system is to recommend items or a set of items
according to the users' taste, and thus predicting their future needs. In this
paper, we address such personalized recommendation problems for which one-bit
comparison data of user preferences for different items as well as the
different user inclinations toward an item are available. We devise a
comprehensive personalized ranking (CPR) system by employing a Bayesian
treatment. We also provide a connection to the learning method with respect to
the CPR optimization criterion to learn the underlying low-rank structure of
the rating matrix based on the well-established matrix factorization method.
Numerical results are provided to verify the performance of our algorithm.
</summary>
    <author>
      <name>Aria Ameri</name>
    </author>
    <author>
      <name>Arindam Bose</name>
    </author>
    <author>
      <name>Mojtaba Soltanalian</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/DSW.2019.8755595</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/DSW.2019.8755595" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2019 IEEE Data Science Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.02408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.02408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.04497v2</id>
    <updated>2019-10-23T21:22:28Z</updated>
    <published>2019-06-11T11:06:26Z</published>
    <title>The Snippets Taxonomy in Web Search Engines</title>
    <summary>  In this paper authors analyzed 50 000 keywords results collected from
localized Polish Google search engine. We proposed a taxonomy for snippets
displayed in search results as regular, rich, news, featured and entity types
snippets. We observed some correlations between overlapping snippets in the
same keywords. Results show that commercial keywords do not cause results
having rich or entity types snippets, whereas keywords resulting with snippets
are not commercial nature. We found that significant number of snippets are
scholarly articles and rich cards carousel. We conclude our findings with
conclusion and research limitations.
</summary>
    <author>
      <name>Artur Strzelecki</name>
    </author>
    <author>
      <name>Paulina Rutecka</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-31143-8_13</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-31143-8_13" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Perspectives in Business Informatics Research 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.04497v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04497v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06437v1</id>
    <updated>2019-06-14T23:36:53Z</updated>
    <published>2019-06-14T23:36:53Z</published>
    <title>A Strategy for Expert Recommendation From Open Data Available on the
  Lattes Platform</title>
    <summary>  With the increasing volume of data and users of curriculum systems, the
difficulty of finding specialists is increasing.This work proposes an open data
extraction methodology of the Lattes Platform curricula, a treatment for this
data and investigates a Recommendation Agent approach based on deep neural
networks with autoencoder.
</summary>
    <author>
      <name>Sérgio José de Sousa</name>
    </author>
    <author>
      <name>Thiago Magela Rodrigues Dias</name>
    </author>
    <author>
      <name>Adilson Luiz Pinto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, in Portuguese, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.06492v1</id>
    <updated>2019-06-15T08:09:19Z</updated>
    <published>2019-06-15T08:09:19Z</published>
    <title>A formal approach for customization of schema.org based on SHACL</title>
    <summary>  Schema.org is a widely adopted vocabulary for semantic annotation of content
and data. However, its generic nature makes it complicated for data publishers
to pick right types and properties for a specific domain and task. In this
paper we propose a formal approach, a domain specification process that
generates domain specific patterns by applying operators implemented in SHACL
to the schema.org vocabulary. These patterns can support knowledge generation
and assessment processes for specific domains and tasks. We demonstrated our
approach with use cases in tourism domain.
</summary>
    <author>
      <name>Umutcan Şimşek</name>
    </author>
    <author>
      <name>Kevin Angele</name>
    </author>
    <author>
      <name>Elias Kärle</name>
    </author>
    <author>
      <name>Oleksandra Panasiuk</name>
    </author>
    <author>
      <name>Dieter Fensel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.07591v1</id>
    <updated>2019-06-18T14:03:14Z</updated>
    <published>2019-06-18T14:03:14Z</published>
    <title>Query Generation for Patent Retrieval with Keyword Extraction based on
  Syntactic Features</title>
    <summary>  This paper describes a new method to extract relevant keywords from patent
claims, as part of the task of retrieving other patents with similar claims
(search for prior art). The method combines a qualitative analysis of the
writing style of the claims with NLP methods to parse text, in order to
represent a legal text as a specialization arborescence of terms. In this
setting, the set of extracted keywords are yielding better search results than
keywords extracted with traditional methods such as tf-idf. The performance is
measured on the search results of a query consisting of the extracted keywords.
</summary>
    <author>
      <name>Julien Rossi</name>
    </author>
    <author>
      <name>Matthias Wirth</name>
    </author>
    <author>
      <name>Evangelos Kanoulas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented as short paper at JURIX 2018</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11285v1</id>
    <updated>2019-06-26T18:22:02Z</updated>
    <published>2019-06-26T18:22:02Z</published>
    <title>Re-ranking Based Diversification: A Unifying View</title>
    <summary>  We analyze different re-ranking algorithms for diversification and show that
majority of them are based on maximizing submodular/modular functions from the
class of parameterized concave/linear over modular functions. We study the
optimality of such algorithms in terms of the `total curvature'. We also show
that by adjusting the hyperparameter of the concave/linear composition to
trade-off relevance and diversity, if any, one is in fact tuning the `total
curvature' of the function for relevance-diversity trade-off.
</summary>
    <author>
      <name>Shameem A Puthiya Parambath</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539813.3545135</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539813.3545135" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2022 ACM SIGIR International Conference on
  Theory of Information Retrieval</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.11285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1906.11783v1</id>
    <updated>2019-06-27T16:42:40Z</updated>
    <published>2019-06-27T16:42:40Z</published>
    <title>Representation Learning of Music Using Artist, Album, and Track
  Information</title>
    <summary>  Supervised music representation learning has been performed mainly using
semantic labels such as music genres. However, annotating music with semantic
labels requires time and cost. In this work, we investigate the use of factual
metadata such as artist, album, and track information, which are naturally
annotated to songs, for supervised music representation learning. The results
show that each of the metadata has individual concept characteristics, and
using them jointly improves overall performance.
</summary>
    <author>
      <name>Jongpil Lee</name>
    </author>
    <author>
      <name>Jiyoung Park</name>
    </author>
    <author>
      <name>Juhan Nam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning (ICML) 2019, Machine
  Learning for Music Discovery Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.11783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.00635v1</id>
    <updated>2019-07-01T10:05:24Z</updated>
    <published>2019-07-01T10:05:24Z</published>
    <title>Dermtrainer: A Decision Support System for Dermatological Diseases</title>
    <summary>  Dermtrainer is a medical decision support system that assists general
practitioners in diagnosing skin diseases and serves as a training platform for
dermatologists. Its key components are a comprehensive dermatological knowledge
base, a clinical algorithm for diagnosing skin diseases, a reasoning component
for deducing the most likely differential diagnoses for a patient, and a
library of high-quality images. This report describes the technical components
of the system, in particular the ranking algorithm for retrieving appropriate
diseases as diagnoses.
</summary>
    <author>
      <name>Gernot Salzer</name>
    </author>
    <author>
      <name>Agata Ciabattoni</name>
    </author>
    <author>
      <name>Christian Fermüller</name>
    </author>
    <author>
      <name>Martin Haiduk</name>
    </author>
    <author>
      <name>Harald Kittler</name>
    </author>
    <author>
      <name>Arno Lukas</name>
    </author>
    <author>
      <name>Rosa María Rodríguez Domínguez</name>
    </author>
    <author>
      <name>Antonia Wesinger</name>
    </author>
    <author>
      <name>Elisabeth Riedl</name>
    </author>
    <link href="http://arxiv.org/abs/1907.00635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.01638v1</id>
    <updated>2019-06-22T02:42:44Z</updated>
    <published>2019-06-22T02:42:44Z</published>
    <title>An Online Topic Modeling Framework with Topics Automatically Labeled</title>
    <summary>  In this paper, we propose a novel online topic tracking framework, named
IEDL, for tracking the topic changes related to deep learning techniques on
Stack Exchange and automatically interpreting each identified topic. The
proposed framework combines the prior topic distributions in a time window
during inferring the topics in current time slice, and introduces a new ranking
scheme to select most representative phrases and sentences for the inferred
topics in each time slice. Experiments on 7,076 Stack Exchange posts show the
effectiveness of IEDL in tracking topic changes and labeling topics.
</summary>
    <author>
      <name>Fenglei Jin</name>
    </author>
    <author>
      <name>Cuiyun Gao</name>
    </author>
    <author>
      <name>Michael R. Lyu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, ICML</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.03718v1</id>
    <updated>2019-07-08T16:50:12Z</updated>
    <published>2019-07-08T16:50:12Z</published>
    <title>CobWeb: A Research Prototype for Exploring User Bias in Political
  Fact-Checking</title>
    <summary>  The effect of user bias in fact-checking has not been explored extensively
from a user-experience perspective. We estimate the user bias as a function of
the user's perceived reputation of the news sources (e.g., a user with liberal
beliefs may tend to trust liberal sources). We build an interface to
communicate the role of estimated user bias in the context of a fact-checking
task. We also explore the utility of helping users visualize their detected
level of bias. 80% of the users of our system find that the presence of an
indicator for user bias is useful in judging the veracity of a political claim.
</summary>
    <author>
      <name>Anubrata Das</name>
    </author>
    <author>
      <name>Kunjan Mehta</name>
    </author>
    <author>
      <name>Matthew Lease</name>
    </author>
    <link href="http://arxiv.org/abs/1907.03718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.09328v1</id>
    <updated>2019-07-22T14:09:20Z</updated>
    <published>2019-07-22T14:09:20Z</published>
    <title>A Conceptual Framework for Evaluating Fairness in Search</title>
    <summary>  While search efficacy has been evaluated traditionally on the basis of result
relevance, fairness of search has attracted recent attention. In this work, we
define a notion of distributional fairness and provide a conceptual framework
for evaluating search results based on it. As part of this, we formulate a set
of axioms which an ideal evaluation framework should satisfy for distributional
fairness. We show how existing TREC test collections can be repurposed to study
fairness, and we measure potential data bias to inform test collection design
for fair search. A set of analyses show metric divergence between relevance and
fairness, and we describe a simple but flexible interpolation strategy for
integrating relevance and fairness into a single metric for optimization and
evaluation.
</summary>
    <author>
      <name>Anubrata Das</name>
    </author>
    <author>
      <name>Matthew Lease</name>
    </author>
    <link href="http://arxiv.org/abs/1907.09328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.13158v1</id>
    <updated>2019-07-30T18:08:48Z</updated>
    <published>2019-07-30T18:08:48Z</published>
    <title>Multi-stakeholder Recommendation and its Connection to Multi-sided
  Fairness</title>
    <summary>  There is growing research interest in recommendation as a multi-stakeholder
problem, one where the interests of multiple parties should be taken into
account. This category subsumes some existing well-established areas of
recommendation research including reciprocal and group recommendation, but a
detailed taxonomy of different classes of multi-stakeholder recommender systems
is still lacking. Fairness-aware recommendation has also grown as a research
area, but its close connection with multi-stakeholder recommendation is not
always recognized. In this paper, we define the most commonly observed classes
of multi-stakeholder recommender systems and discuss how different fairness
concerns may come into play in such systems.
</summary>
    <author>
      <name>Himan Abdollahpouri</name>
    </author>
    <author>
      <name>Robin Burke</name>
    </author>
    <link href="http://arxiv.org/abs/1907.13158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.13158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1907.13561v1</id>
    <updated>2019-07-31T15:42:26Z</updated>
    <published>2019-07-31T15:42:26Z</published>
    <title>Attention-Wrapped Hierarchical BLSTMs for DDI Extraction</title>
    <summary>  Drug-Drug Interactions (DDIs) Extraction refers to the efforts to generate
hand-made or automatic tools to extract embedded information from text and
literature in the biomedical domain.
  Because of restrictions in hand-made efforts and their lower speed,
Machine-Learning, or Deep-Learning approaches have become more popular for
extracting DDIs. In this study, we propose a novel and generic Deep-Learning
model which wraps Hierarchical Bidirectional LSTMs with two Attention
Mechanisms that outperforms state-of-the-art models for DDIs Extraction, based
on the DDIExtraction-2013 corpora. This model has obtained the macro F1-score
of 0.785, and the precision of 0.80.
</summary>
    <author>
      <name>Vahab Mostafapour</name>
    </author>
    <author>
      <name>Oğuz Dikenelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.13561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.13561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03040v1</id>
    <updated>2019-10-03T19:35:27Z</updated>
    <published>2019-10-03T19:35:27Z</published>
    <title>IRF: Interactive Recommendation through Dialogue</title>
    <summary>  Recent research focuses beyond recommendation accuracy, towards human factors
that influence the acceptance of recommendations, such as user satisfaction,
trust, transparency and sense of control.We present a generic interactive
recommender framework that can add interaction functionalities to
non-interactive recommender systems.We take advantage of dialogue systems to
interact with the user and we design a middleware layer to provide the
interaction functions, such as providing explanations for the recommendations,
managing users preferences learnt from dialogue, preference elicitation and
refining recommendations based on learnt preferences.
</summary>
    <author>
      <name>Oznur Alkan</name>
    </author>
    <author>
      <name>Massimiliano Mattetti</name>
    </author>
    <author>
      <name>Elizabeth M. Daly</name>
    </author>
    <author>
      <name>Adi Botea</name>
    </author>
    <author>
      <name>Inge Vejsbjerg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, ACM RecSys Conference 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.03040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.03534v1</id>
    <updated>2019-10-08T16:45:20Z</updated>
    <published>2019-10-08T16:45:20Z</published>
    <title>Accurate and Fast Retrieval for Complex Non-metric Data via Neighborhood
  Graphs</title>
    <summary>  We demonstrate that a graph-based search algorithm-relying on the
construction of an approximate neighborhood graph-can directly work with
challenging non-metric and/or non-symmetric distances without resorting to
metric-space mapping and/or distance symmetrization, which, in turn, lead to
substantial performance degradation. Although the straightforward metrization
and symmetrization is usually ineffective, we find that constructing an index
using a modified, e.g., symmetrized, distance can improve performance. This
observation paves a way to a new line of research of designing index-specific
graph-construction distance functions.
</summary>
    <author>
      <name>Leonid Boytsov</name>
    </author>
    <author>
      <name>Eric Nyberg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32047-8_12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32047-8_12" rel="related"/>
    <link href="http://arxiv.org/abs/1910.03534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1910.10037v1</id>
    <updated>2019-10-22T15:15:27Z</updated>
    <published>2019-10-22T15:15:27Z</published>
    <title>One-Shot Template Matching for Automatic Document Data Capture</title>
    <summary>  In this paper, we propose a novel one-shot template-matching algorithm to
automatically capture data from business documents with an aim to minimize
manual data entry. Given one annotated document, our algorithm can
automatically extract similar data from other documents having the same format.
Based on a set of engineered visual and textual features, our method is
invariant to changes in position and value. Experiments on a dataset of 595
real invoices demonstrate 86.4% accuracy.
</summary>
    <author>
      <name>Pranjal Dhakal</name>
    </author>
    <author>
      <name>Manish Munikar</name>
    </author>
    <author>
      <name>Bikram Dahal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in International Conference on AI for Transforming Business
  (AITB2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.00180v1</id>
    <updated>2019-11-30T10:32:52Z</updated>
    <published>2019-11-30T10:32:52Z</published>
    <title>Latent Semantic Search and Information Extraction Architecture</title>
    <summary>  The motivation, concept, design and implementation of latent semantic search
for search engines have limited semantic search, entity extraction and property
attribution features, have insufficient accuracy and response time of latent
search, may impose privacy concerns and the search results are unavailable in
offline mode for robotic search operations. The alternative suggestion involves
autonomous search engine with adaptive storage consumption, configurable search
scope and latent search response time with built-in options for entity
extraction and property attribution available as open source platform for
mobile, desktop and server solutions. The suggested architecture attempts to
implement artificial general intelligence (AGI) principles as long as
autonomous behaviour constrained by limited resources is concerned, and it is
applied for specific task of enabling Web search for artificial agents
implementing the AGI.
</summary>
    <author>
      <name>Anton Kolonin</name>
    </author>
    <link href="http://arxiv.org/abs/1912.00180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.02263v1</id>
    <updated>2019-12-04T21:48:42Z</updated>
    <published>2019-12-04T21:48:42Z</published>
    <title>Evaluation Metrics for Item Recommendation under Sampling</title>
    <summary>  The task of item recommendation requires ranking a large catalogue of items
given a context. Item recommendation algorithms are evaluated using ranking
metrics that depend on the positions of relevant items. To speed up the
computation of metrics, recent work often uses sampled metrics where only a
smaller set of random items and the relevant items are ranked. This paper
investigates sampled metrics in more detail and shows that sampled metrics are
inconsistent with their exact version. Sampled metrics do not persist relative
statements, e.g., 'algorithm A is better than B', not even in expectation.
Moreover the smaller the sampling size, the less difference between metrics,
and for very small sampling size, all metrics collapse to the AUC metric.
</summary>
    <author>
      <name>Steffen Rendle</name>
    </author>
    <link href="http://arxiv.org/abs/1912.02263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.02263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04115v1</id>
    <updated>2019-12-09T15:19:27Z</updated>
    <published>2019-12-09T15:19:27Z</published>
    <title>Query Auto Completion for Math Formula Search</title>
    <summary>  Query Auto Completion (QAC) is among the most appealing features of a web
search engine. It helps users formulate queries quickly with less effort.
Although there has been much effort in this area for text, to the best of our
knowledge there is few work on mathematical formula auto completion. In this
paper, we implement 5 existing QAC methods on mathematical formula and evaluate
them on the NTCIR-12 MathIR task dataset. We report the efficiency of retrieved
results using Mean Reciprocal Rank (MRR) and Mean Average Precision(MAP). Our
study indicates that the Finite State Transducer outperforms other QAC models
with a MRR score of $0.642$.
</summary>
    <author>
      <name>Shaurya Rohatgi</name>
    </author>
    <author>
      <name>Wei Zhong</name>
    </author>
    <author>
      <name>Richard Zanibbi</name>
    </author>
    <author>
      <name>Jian Wu</name>
    </author>
    <author>
      <name>C. Lee Giles</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04471v1</id>
    <updated>2019-12-10T03:23:05Z</updated>
    <published>2019-12-10T03:23:05Z</published>
    <title>Duet at TREC 2019 Deep Learning Track</title>
    <summary>  This report discusses three submissions based on the Duet architecture to the
Deep Learning track at TREC 2019. For the document retrieval task, we adapt the
Duet model to ingest a "multiple field" view of documents---we refer to the new
architecture as Duet with Multiple Fields (DuetMF). A second submission
combines the DuetMF model with other neural and traditional relevance
estimators in a learning-to-rank framework and achieves improved performance
over the DuetMF baseline. For the passage retrieval task, we submit a single
run based on an ensemble of eight Duet models.
</summary>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Nick Craswell</name>
    </author>
    <link href="http://arxiv.org/abs/1912.04471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.04713v1</id>
    <updated>2019-12-10T14:41:02Z</updated>
    <published>2019-12-10T14:41:02Z</published>
    <title>Neural-IR-Explorer: A Content-Focused Tool to Explore Neural Re-Ranking
  Results</title>
    <summary>  In this paper we look beyond metrics-based evaluation of Information
Retrieval systems, to explore the reasons behind ranking results. We present
the content-focused Neural-IR-Explorer, which empowers users to browse through
retrieval results and inspect the inner workings and fine-grained results of
neural re-ranking models. The explorer includes a categorized overview of the
available queries, as well as an individual query result view with various
options to highlight semantic connections between query-document pairs. The
Neural-IR-Explorer is available at: https://neural-ir-explorer.ec.tuwien.ac.at/
</summary>
    <author>
      <name>Sebastian Hofstätter</name>
    </author>
    <author>
      <name>Markus Zlabinger</name>
    </author>
    <author>
      <name>Allan Hanbury</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ECIR 2020 (demo paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.04713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.04713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08422v1</id>
    <updated>2019-12-18T07:43:52Z</updated>
    <published>2019-12-18T07:43:52Z</published>
    <title>Distilling Structured Knowledge into Embeddings for Explainable and
  Accurate Recommendation</title>
    <summary>  Recently, the embedding-based recommendation models (e.g., matrix
factorization and deep models) have been prevalent in both academia and
industry due to their effectiveness and flexibility. However, they also have
such intrinsic limitations as lacking explainability and suffering from data
sparsity. In this paper, we propose an end-to-end joint learning framework to
get around these limitations without introducing any extra overhead by
distilling structured knowledge from a differentiable path-based recommendation
model. Through extensive experiments, we show that our proposed framework can
achieve state-of-the-art recommendation performance and meanwhile provide
interpretable recommendation reasons.
</summary>
    <author>
      <name>Yuan Zhang</name>
    </author>
    <author>
      <name>Xiaoran Xu</name>
    </author>
    <author>
      <name>Hanning Zhou</name>
    </author>
    <author>
      <name>Yan Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by WSDM'2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08932v1</id>
    <updated>2019-12-18T22:28:39Z</updated>
    <published>2019-12-18T22:28:39Z</published>
    <title>Collaborative Filtering vs. Content-Based Filtering: differences and
  similarities</title>
    <summary>  Recommendation Systems (SR) suggest items exploring user preferences, helping
them with the information overload problem. Two approaches to SR have received
more prominence, Collaborative Filtering, and Content-Based Filtering.
Moreover, even though studies are indicating their advantages and
disadvantages, few results empirically prove their characteristics,
similarities, and differences. In this work, an experimental methodology is
proposed to perform comparisons between recommendation algorithms for different
approaches going beyond the "precision of the predictions". For the
experiments, three algorithms of recommendation were tested: a baseline for
Collaborative Filtration and two algorithms for Content-based Filtering that
were developed for this evaluation. The experiments demonstrate the behavior of
these systems in different data sets, its main characteristics and especially
the complementary aspect of the two main approaches.
</summary>
    <author>
      <name>Rafael Glauber</name>
    </author>
    <author>
      <name>Angelo Loula</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1912.08976v1</id>
    <updated>2019-12-19T01:31:28Z</updated>
    <published>2019-12-19T01:31:28Z</published>
    <title>A multi-label classification method using a hierarchical and transparent
  representation for paper-reviewer recommendation</title>
    <summary>  Paper-reviewer recommendation task is of significant academic importance for
conference chairs and journal editors. How to effectively and accurately
recommend reviewers for the submitted papers is a meaningful and still tough
task. In this paper, we propose a Multi-Label Classification method using a
hierarchical and transparent Representation named Hiepar-MLC. Further, we
propose a simple multi-label-based reviewer assignment MLBRA strategy to select
the appropriate reviewers. It is interesting that we also explore the
paper-reviewer recommendation in the coarse-grained granularity.
</summary>
    <author>
      <name>Dong Zhang</name>
    </author>
    <author>
      <name>Shu Zhao</name>
    </author>
    <author>
      <name>Zhen Duan</name>
    </author>
    <author>
      <name>Jie Chen</name>
    </author>
    <author>
      <name>Yangping Zhang</name>
    </author>
    <author>
      <name>Jie Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.08976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.01190v1</id>
    <updated>2020-07-23T06:42:45Z</updated>
    <published>2020-07-23T06:42:45Z</published>
    <title>Musical Word Embedding: Bridging the Gap between Listening Contexts and
  Music</title>
    <summary>  Word embedding pioneered by Mikolov et al. is a staple technique for word
representations in natural language processing (NLP) research which has also
found popularity in music information retrieval tasks. Depending on the type of
text data for word embedding, however, vocabulary size and the degree of
musical pertinence can significantly vary. In this work, we (1) train the
distributed representation of words using combinations of both general text
data and music-specific data and (2) evaluate the system in terms of how they
associate listening contexts with musical compositions.
</summary>
    <author>
      <name>Seungheon Doh</name>
    </author>
    <author>
      <name>Jongpil Lee</name>
    </author>
    <author>
      <name>Tae Hong Park</name>
    </author>
    <author>
      <name>Juhan Nam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning for Media Discovery Workshop, International
  Conference on Machine Learning (ICML), 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2008.01190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.01190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.01194v1</id>
    <updated>2020-07-16T16:14:08Z</updated>
    <published>2020-07-16T16:14:08Z</published>
    <title>Facets of Fairness in Search and Recommendation</title>
    <summary>  Several recent works have highlighted how search and recommender systems
exhibit bias along different dimensions. Counteracting this bias and bringing a
certain amount of fairness in search is crucial to not only creating a more
balanced environment that considers relevance and diversity but also providing
a more sustainable way forward for both content consumers and content
producers. This short paper examines some of the recent works to define
relevance, diversity, and related concepts. Then, it focuses on explaining the
emerging concept of fairness in various recommendation settings. In doing so,
this paper presents comparisons and highlights contracts among various
measures, and gaps in our conceptual and evaluative frameworks.
</summary>
    <author>
      <name>Sahil Verma</name>
    </author>
    <author>
      <name>Ruoyuan Gao</name>
    </author>
    <author>
      <name>Chirag Shah</name>
    </author>
    <link href="http://arxiv.org/abs/2008.01194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.01194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.03917v1</id>
    <updated>2020-08-10T06:37:47Z</updated>
    <published>2020-08-10T06:37:47Z</published>
    <title>Beyond Lexical: A Semantic Retrieval Framework for Textual SearchEngine</title>
    <summary>  Search engine has become a fundamental component in various web and mobile
applications. Retrieving relevant documents from the massive datasets is
challenging for a search engine system, especially when faced with verbose or
tail queries. In this paper, we explore a vector space search framework for
document retrieval. Specifically, we trained a deep semantic matching model so
that each query and document can be encoded as a low dimensional embedding. Our
model was trained based on BERT architecture. We deployed a fast
k-nearest-neighbor index service for online serving. Both offline and online
metrics demonstrate that our method improved retrieval performance and search
quality considerably, particularly for tail
</summary>
    <author>
      <name>Kuan Fang</name>
    </author>
    <author>
      <name>Long Zhao</name>
    </author>
    <author>
      <name>Zhan Shen</name>
    </author>
    <author>
      <name>RuiXing Wang</name>
    </author>
    <author>
      <name>RiKang Zhour</name>
    </author>
    <author>
      <name>LiWen Fan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2008.03917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.03917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.06716v1</id>
    <updated>2020-08-15T13:21:10Z</updated>
    <published>2020-08-15T13:21:10Z</published>
    <title>Performance of Hyperbolic Geometry Models on Top-N Recommendation Tasks</title>
    <summary>  We introduce a simple autoencoder based on hyperbolic geometry for solving
standard collaborative filtering problem. In contrast to many modern deep
learning techniques, we build our solution using only a single hidden layer.
Remarkably, even with such a minimalistic approach, we not only outperform the
Euclidean counterpart but also achieve a competitive performance with respect
to the current state-of-the-art. We additionally explore the effects of space
curvature on the quality of hyperbolic models and propose an efficient
data-driven method for estimating its optimal value.
</summary>
    <author>
      <name>Leyla Mirvakhabova</name>
    </author>
    <author>
      <name>Evgeny Frolov</name>
    </author>
    <author>
      <name>Valentin Khrulkov</name>
    </author>
    <author>
      <name>Ivan Oseledets</name>
    </author>
    <author>
      <name>Alexander Tuzhilin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3383313.3412219</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3383313.3412219" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ACM RecSys 2020; 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2008.06716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.06716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.09237v1</id>
    <updated>2020-08-21T00:11:31Z</updated>
    <published>2020-08-21T00:11:31Z</published>
    <title>COOKIE: A Dataset for Conversational Recommendation over Knowledge
  Graphs in E-commerce</title>
    <summary>  In this work, we present a new dataset for conversational recommendation over
knowledge graphs in e-commerce platforms called COOKIE. The dataset is
constructed from an Amazon review corpus by integrating both user-agent
dialogue and custom knowledge graphs for recommendation. Specifically, we first
construct a unified knowledge graph and extract key entities between
user--product pairs, which serve as the skeleton of a conversation. Then we
simulate conversations mirroring the human coarse-to-fine process of choosing
preferred items. The proposed baselines and experiments demonstrate that our
dataset is able to provide innovative opportunities for conversational
recommendation.
</summary>
    <author>
      <name>Zuohui Fu</name>
    </author>
    <author>
      <name>Yikun Xian</name>
    </author>
    <author>
      <name>Yaxin Zhu</name>
    </author>
    <author>
      <name>Yongfeng Zhang</name>
    </author>
    <author>
      <name>Gerard de Melo</name>
    </author>
    <link href="http://arxiv.org/abs/2008.09237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.09237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.13528v1</id>
    <updated>2020-08-27T00:25:19Z</updated>
    <published>2020-08-27T00:25:19Z</published>
    <title>Microsoft Recommenders: Tools to Accelerate Developing Recommender
  Systems</title>
    <summary>  The purpose of this work is to highlight the content of the Microsoft
Recommenders repository and show how it can be used to reduce the time involved
in developing recommender systems. The open source repository provides python
utilities to simplify common recommender-related data science work as well as
example Jupyter notebooks that demonstrate use of the algorithms and tools
under various environments.
</summary>
    <author>
      <name>Scott Graham</name>
    </author>
    <author>
      <name>Jun-Ki Min</name>
    </author>
    <author>
      <name>Tao Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3298689.3346967</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3298689.3346967" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pages: 2; submitted to: RecSys '19</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 13th ACM Conference on Recommender Systems
  (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2008.13528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.13528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.4; I.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.13532v1</id>
    <updated>2020-08-19T08:29:27Z</updated>
    <published>2020-08-19T08:29:27Z</published>
    <title>Auto-Surprise: An Automated Recommender-System (AutoRecSys) Library with
  Tree of Parzens Estimator (TPE) Optimization</title>
    <summary>  We introduce Auto-Surprise, an Automated Recommender System library.
Auto-Surprise is an extension of the Surprise recommender system library and
eases the algorithm selection and configuration process. Compared to
out-of-the-box Surprise library, Auto-Surprise performs better when evaluated
with MovieLens, Book Crossing and Jester Datasets. It may also result in the
selection of an algorithm with significantly lower runtime. Compared to
Surprise's grid search, Auto-Surprise performs equally well or slightly better
in terms of RMSE, and is notably faster in finding the optimum hyperparameters.
</summary>
    <author>
      <name>Rohan Anand</name>
    </author>
    <author>
      <name>Joeran Beel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3383313.3411467</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3383313.3411467" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented at RecSys '20 Fourteenth ACM Conference on
  Recommender Systems, September 21-26, 2020, Virtual Event</arxiv:comment>
    <link href="http://arxiv.org/abs/2008.13532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.13532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2008.13541v1</id>
    <updated>2020-08-05T15:23:42Z</updated>
    <published>2020-08-05T15:23:42Z</published>
    <title>Introductory review to quantum information retrieval</title>
    <summary>  Recently people started to understand that applications of the mathematical
formalism of quantum theory are not reduced to physics. Nowadays, this
formalism is widely used outside of quantum physics, in particular, in
cognition, psychology, decision making, information processing, especially
information retrieval. The latter is very promising. The aim of this brief
introductory review is to stimulate research in this exciting area of
information science. This paper is not aimed to present a complete review on
the state of art in quantum information retrieval.
</summary>
    <author>
      <name>Alexander Lebedev</name>
    </author>
    <author>
      <name>Andrei Khrennikov</name>
    </author>
    <link href="http://arxiv.org/abs/2008.13541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2008.13541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.00501v1</id>
    <updated>2020-12-01T14:16:50Z</updated>
    <published>2020-12-01T14:16:50Z</published>
    <title>A Statistical Real-Time Prediction Model for Recommender System</title>
    <summary>  Recommender system has become an inseparable part of online shopping and its
usability is increasing with the advancement of these e-commerce sites. An
effective and efficient recommender system benefits both the seller and the
buyer significantly. We considered user activities and product information for
the filtering process in our proposed recommender system. Our model has
achieved inspiring result (approximately 58% true-positive and 13%
false-positive) for the data set provided by RecSys Challenge 2015. This paper
aims to describe a statistical model that will help to predict the buying
behavior of a user in real-time during a session.
</summary>
    <author>
      <name>Md Rifat Arefin</name>
    </author>
    <author>
      <name>Minhas Kamal</name>
    </author>
    <author>
      <name>Kishan Kumar Ganguly</name>
    </author>
    <author>
      <name>Tarek Salah Uddin Mahmud</name>
    </author>
    <link href="http://arxiv.org/abs/2012.00501v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.00501v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.09263v1</id>
    <updated>2020-12-16T21:00:24Z</updated>
    <published>2020-12-16T21:00:24Z</published>
    <title>Checking Fact Worthiness using Sentence Embeddings</title>
    <summary>  Checking and confirming factual information in texts and speeches is vital to
determine the veracity and correctness of the factual statements. This work was
previously done by journalists and other manual means but it is a
time-consuming task. With the advancements in Information Retrieval and NLP,
research in the area of Fact-checking is getting attention for automating it.
CLEF-2018 and 2019 organised tasks related to Fact-checking and invited
participants. This project focuses on CLEF-2019 Task-1 Check-Worthiness and
experiments using the latest Sentence-BERT pre-trained embeddings, topic
Modeling and sentiment score are performed. Evaluation metrics such as MAP,
Mean Reciprocal Rank, Mean R-Precision and Mean Precision@N present the
improvement in the results using the techniques.
</summary>
    <author>
      <name>Sidharth Singla</name>
    </author>
    <link href="http://arxiv.org/abs/2012.09263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.09263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.09650v1</id>
    <updated>2020-12-17T14:59:01Z</updated>
    <published>2020-12-17T14:59:01Z</published>
    <title>A White Box Analysis of ColBERT</title>
    <summary>  Transformer-based models are nowadays state-of-the-art in ad-hoc Information
Retrieval, but their behavior is far from being understood. Recent work has
claimed that BERT does not satisfy the classical IR axioms. However, we propose
to dissect the matching process of ColBERT, through the analysis of term
importance and exact/soft matching patterns. Even if the traditional axioms are
not formally verified, our analysis reveals that ColBERT: (i) is able to
capture a notion of term importance; (ii) relies on exact matches for important
terms.
</summary>
    <author>
      <name>Thibault Formal</name>
    </author>
    <author>
      <name>Benjamin Piwowarski</name>
    </author>
    <author>
      <name>Stéphane Clinchant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in ECIR'21</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.09650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.09650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.12065v1</id>
    <updated>2020-12-22T14:56:54Z</updated>
    <published>2020-12-22T14:56:54Z</published>
    <title>Event-Driven Query Expansion</title>
    <summary>  A significant number of event-related queries are issued in Web search. In
this paper, we seek to improve retrieval performance by leveraging events and
specifically target the classic task of query expansion. We propose a method to
expand an event-related query by first detecting the events related to it.
Then, we derive the candidates for expansion as terms semantically related to
both the query and the events. To identify the candidates, we utilize a novel
mechanism to simultaneously embed words and events in the same vector space. We
show that our proposed method of leveraging events improves query expansion
performance significantly compared with state-of-the-art methods on various
newswire TREC datasets.
</summary>
    <author>
      <name>Guy D. Rosin</name>
    </author>
    <author>
      <name>Ido Guy</name>
    </author>
    <author>
      <name>Kira Radinsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, WSDM 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.12065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.12065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.12795v1</id>
    <updated>2020-12-23T16:56:38Z</updated>
    <published>2020-12-23T16:56:38Z</published>
    <title>A Note on the Significance Adjustment for FA*IR with Two Protected
  Groups</title>
    <summary>  In this report we provide an improvement of the significance adjustment from
the FA*IR algorithm of Zehlike et al., which did not work for very short
rankings in combination with a low minimum proportion $p$ for the protected
group. We show how the minimum number of protected candidates per ranking
position can be calculated exactly and provide a mapping from the continuous
space of significance levels ($\alpha$) to a discrete space of tables, which
allows us to find $\alpha_c$ using a binary search heuristic.
</summary>
    <author>
      <name>Meike Zehlike</name>
    </author>
    <author>
      <name>Tom Sühr</name>
    </author>
    <author>
      <name>Carlos Castillo</name>
    </author>
    <link href="http://arxiv.org/abs/2012.12795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.12795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.12862v1</id>
    <updated>2020-12-20T19:28:57Z</updated>
    <published>2020-12-20T19:28:57Z</published>
    <title>Towards Fair Personalization by Avoiding Feedback Loops</title>
    <summary>  Self-reinforcing feedback loops are both cause and effect of over and/or
under-presentation of some content in interactive recommender systems. This
leads to erroneous user preference estimates, namely, overestimation of
over-presented content while violating the right to be presented of each
alternative, contrary of which we define as a fair system. We consider two
models that explicitly incorporate, or ignore the systematic and limited
exposure to alternatives. By simulations, we demonstrate that ignoring the
systematic presentations overestimates promoted options and underestimates
censored alternatives. Simply conditioning on the limited exposure is a remedy
for these biases.
</summary>
    <author>
      <name>Gökhan Çapan</name>
    </author>
    <author>
      <name>Özge Bozal</name>
    </author>
    <author>
      <name>İlker Gündoğdu</name>
    </author>
    <author>
      <name>Ali Taylan Cemgil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2019 Workshop on Human-Centric Machine Learning</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.12862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.12862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2012.14210v2</id>
    <updated>2021-06-09T07:25:23Z</updated>
    <published>2020-12-28T12:25:25Z</published>
    <title>The Curse of Dense Low-Dimensional Information Retrieval for Large Index
  Sizes</title>
    <summary>  Information Retrieval using dense low-dimensional representations recently
became popular and showed out-performance to traditional sparse-representations
like BM25. However, no previous work investigated how dense representations
perform with large index sizes. We show theoretically and empirically that the
performance for dense representations decreases quicker than sparse
representations for increasing index sizes. In extreme cases, this can even
lead to a tipping point where at a certain index size sparse representations
outperform dense representations. We show that this behavior is tightly
connected to the number of dimensions of the representations: The lower the
dimension, the higher the chance for false positives, i.e. returning irrelevant
documents.
</summary>
    <author>
      <name>Nils Reimers</name>
    </author>
    <author>
      <name>Iryna Gurevych</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at ACL 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2012.14210v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2012.14210v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.02017v1</id>
    <updated>2021-01-05T08:40:04Z</updated>
    <published>2021-01-05T08:40:04Z</published>
    <title>COVID-19: Comparative Analysis of Methods for Identifying Articles
  Related to Therapeutics and Vaccines without Using Labeled Data</title>
    <summary>  Here we proposed an approach to analyze text classification methods based on
the presence or absence of task-specific terms (and their synonyms) in the
text. We applied this approach to study six different transfer-learning and
unsupervised methods for screening articles relevant to COVID-19 vaccines and
therapeutics. The analysis revealed that while a BERT model trained on
search-engine results generally performed well, it miss-classified relevant
abstracts that did not contain task-specific terms. We used this insight to
create a more effective unsupervised ensemble.
</summary>
    <author>
      <name>Mihir Parmar</name>
    </author>
    <author>
      <name>Ashwin Karthik Ambalavanan</name>
    </author>
    <author>
      <name>Hong Guan</name>
    </author>
    <author>
      <name>Rishab Banerjee</name>
    </author>
    <author>
      <name>Jitesh Pabla</name>
    </author>
    <author>
      <name>Murthy Devarakonda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 Tables, Appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.02017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.02017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.02028v1</id>
    <updated>2021-01-02T21:50:36Z</updated>
    <published>2021-01-02T21:50:36Z</published>
    <title>A Multilayer Correlated Topic Model</title>
    <summary>  We proposed a novel multilayer correlated topic model (MCTM) to analyze how
the main ideas inherit and vary between a document and its different segments,
which helps understand an article's structure. The variational
expectation-maximization (EM) algorithm was derived to estimate the posterior
and parameters in MCTM. We introduced two potential applications of MCTM,
including the paragraph-level document analysis and market basket data
analysis. The effectiveness of MCTM in understanding the document structure has
been verified by the great predictive performance on held-out documents and
intuitive visualization. We also showed that MCTM could successfully capture
customers' popular shopping patterns in the market basket analysis.
</summary>
    <author>
      <name>Ye Tian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.02028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.02028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.02655v1</id>
    <updated>2021-01-07T17:51:04Z</updated>
    <published>2021-01-07T17:51:04Z</published>
    <title>Metric Learning for Session-based Recommendations</title>
    <summary>  Session-based recommenders, used for making predictions out of users'
uninterrupted sequences of actions, are attractive for many applications. Here,
for this task we propose using metric learning, where a common embedding space
for sessions and items is created, and distance measures dissimilarity between
the provided sequence of users' events and the next action. We discuss and
compare metric learning approaches to commonly used learning-to-rank methods,
where some synergies exist. We propose a simple architecture for problem
analysis and demonstrate that neither extensively big nor deep architectures
are necessary in order to outperform existing methods. The experimental results
against strong baselines on four datasets are provided with an ablation study.
</summary>
    <author>
      <name>Bartłomiej Twardowski</name>
    </author>
    <author>
      <name>Paweł Zawistowski</name>
    </author>
    <author>
      <name>Szymon Zaborowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at European Conference On Information Retrieval (ECIR) 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.02655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.02655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.03617v1</id>
    <updated>2021-01-10T19:56:39Z</updated>
    <published>2021-01-10T19:56:39Z</published>
    <title>Transfer Learning and Augmentation for Word Sense Disambiguation</title>
    <summary>  Many downstream NLP tasks have shown significant improvement through
continual pre-training, transfer learning and multi-task learning.
State-of-the-art approaches in Word Sense Disambiguation today benefit from
some of these approaches in conjunction with information sources such as
semantic relationships and gloss definitions contained within WordNet. Our work
builds upon these systems and uses data augmentation along with extensive
pre-training on various different NLP tasks and datasets. Our transfer learning
and augmentation pipeline achieves state-of-the-art single model performance in
WSD and is at par with the best ensemble results.
</summary>
    <author>
      <name>Harsh Kohli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-72240-1_29</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-72240-1_29" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures. Accepted at the 43rd European Conference on
  Information Retrieval (ECIR) 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.03617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.03617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.06150v1</id>
    <updated>2021-01-15T14:48:01Z</updated>
    <published>2021-01-15T14:48:01Z</published>
    <title>Annotation of epidemiological information in animal disease-related news
  articles: guidelines</title>
    <summary>  This paper describes a method for annotation of epidemiological information
in animal disease-related news articles. The annotation guidelines are generic
and aim to embrace all animal or zoonotic infectious diseases, regardless of
the pathogen involved or its way of transmission (e.g. vector-borne, airborne,
by contact). The framework relies on the successive annotation of all the
sentences from a news article. The annotator evaluates the sentences in a
specific epidemiological context, corresponding to the publication of the news
article.
</summary>
    <author>
      <name>Sarah Valentin</name>
    </author>
    <author>
      <name>Elena Arsevska</name>
    </author>
    <author>
      <name>Aline Vilain</name>
    </author>
    <author>
      <name>Valérie De Waele</name>
    </author>
    <author>
      <name>Renaud Lancelot</name>
    </author>
    <author>
      <name>Mathieu Roche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.06150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.06150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.07382v1</id>
    <updated>2021-01-19T00:17:52Z</updated>
    <published>2021-01-19T00:17:52Z</published>
    <title>A Comparison of Question Rewriting Methods for Conversational Passage
  Retrieval</title>
    <summary>  Conversational passage retrieval relies on question rewriting to modify the
original question so that it no longer depends on the conversation history.
Several methods for question rewriting have recently been proposed, but they
were compared under different retrieval pipelines. We bridge this gap by
thoroughly evaluating those question rewriting methods on the TREC CAsT 2019
and 2020 datasets under the same retrieval pipeline. We analyze the effect of
different types of question rewriting methods on retrieval performance and show
that by combining question rewriting methods of different types we can achieve
state-of-the-art performance on both datasets.
</summary>
    <author>
      <name>Svitlana Vakulenko</name>
    </author>
    <author>
      <name>Nikos Voskarides</name>
    </author>
    <author>
      <name>Zhucheng Tu</name>
    </author>
    <author>
      <name>Shayne Longpre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2021 short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.07382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.07382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.07918v1</id>
    <updated>2021-01-20T01:07:47Z</updated>
    <published>2021-01-20T01:07:47Z</published>
    <title>PGT: Pseudo Relevance Feedback Using a Graph-Based Transformer</title>
    <summary>  Most research on pseudo relevance feedback (PRF) has been done in vector
space and probabilistic retrieval models. This paper shows that
Transformer-based rerankers can also benefit from the extra context that PRF
provides. It presents PGT, a graph-based Transformer that sparsifies attention
between graph nodes to enable PRF while avoiding the high computational
complexity of most Transformer architectures. Experiments show that PGT
improves upon non-PRF Transformer reranker, and it is at least as accurate as
Transformer PRF models that use full attention, but with lower computational
costs.
</summary>
    <author>
      <name>HongChien Yu</name>
    </author>
    <author>
      <name>Zhuyun Dai</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ECIR 2021 (short paper track)</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.07918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.07918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.08705v1</id>
    <updated>2021-01-21T16:33:18Z</updated>
    <published>2021-01-21T16:33:18Z</published>
    <title>Assessing the Benefits of Model Ensembles in Neural Re-Ranking for
  Passage Retrieval</title>
    <summary>  Our work aimed at experimentally assessing the benefits of model ensembling
within the context of neural methods for passage reranking. Starting from
relatively standard neural models, we use a previous technique named Fast
Geometric Ensembling to generate multiple model instances from particular
training schedules, then focusing or attention on different types of approaches
for combining the results from the multiple model instances (e.g., averaging
the ranking scores, using fusion methods from the IR literature, or using
supervised learning-to-rank). Tests with the MS-MARCO dataset show that model
ensembling can indeed benefit the ranking quality, particularly with supervised
learning-to-rank although also with unsupervised rank aggregation.
</summary>
    <author>
      <name>Luís Borges</name>
    </author>
    <author>
      <name>Bruno Martins</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2021 short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.08705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.08705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.08751v1</id>
    <updated>2021-01-21T18:04:58Z</updated>
    <published>2021-01-21T18:04:58Z</published>
    <title>Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline</title>
    <summary>  Pre-trained deep language models~(LM) have advanced the state-of-the-art of
text retrieval. Rerankers fine-tuned from deep LM estimates candidate relevance
based on rich contextualized matching signals. Meanwhile, deep LMs can also be
leveraged to improve search index, building retrievers with better recall. One
would expect a straightforward combination of both in a pipeline to have
additive performance gain. In this paper, we discover otherwise and that
popular reranker cannot fully exploit the improved retrieval result. We,
therefore, propose a Localized Contrastive Estimation (LCE) for training
rerankers and demonstrate it significantly improves deep two-stage models.
</summary>
    <author>
      <name>Luyu Gao</name>
    </author>
    <author>
      <name>Zhuyun Dai</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.08751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.08751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.08769v1</id>
    <updated>2021-01-21T18:50:21Z</updated>
    <published>2021-01-21T18:50:21Z</published>
    <title>Item Recommendation from Implicit Feedback</title>
    <summary>  The task of item recommendation is to select the best items for a user from a
large catalogue of items. Item recommenders are commonly trained from implicit
feedback which consists of past actions that are positive only. Core challenges
of item recommendation are (1) how to formulate a training objective from
implicit feedback and (2) how to efficiently train models over a large item
catalogue. This article provides an overview of item recommendation, its unique
characteristics and some common approaches. It starts with an introduction to
the problem and discusses different training objectives. The main body deals
with learning algorithms and presents sampling based algorithms for general
recommenders and more efficient algorithms for dot product models. Finally, the
application of item recommenders for retrieval tasks is discussed.
</summary>
    <author>
      <name>Steffen Rendle</name>
    </author>
    <link href="http://arxiv.org/abs/2101.08769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.08769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.10219v1</id>
    <updated>2021-01-25T16:31:40Z</updated>
    <published>2021-01-25T16:31:40Z</published>
    <title>MICROS: Mixed-Initiative ConveRsatiOnal Systems Workshop</title>
    <summary>  The 1st edition of the workshop on Mixed-Initiative ConveRsatiOnal Systems
(MICROS@ECIR2021) aims at investigating and collecting novel ideas and
contributions in the field of conversational systems. Oftentimes, the users
fulfill their information need using smartphones and home assistants. This has
revolutionized the way users access online information, thus posing new
challenges compared to traditional search and recommendation. The first edition
of MICROS will have a particular focus on mixed-initiative conversational
systems. Indeed, conversational systems need to be proactive, proposing not
only answers but also possible interpretations for ambiguous or vague requests.
</summary>
    <author>
      <name>Ida Mele</name>
    </author>
    <author>
      <name>Cristina Ioana Muntean</name>
    </author>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Nikos Voskarides</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2021 workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2101.10219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.10219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2101.12339v1</id>
    <updated>2021-01-23T20:01:36Z</updated>
    <published>2021-01-23T20:01:36Z</published>
    <title>Are Top School Students More Critical of Their Professors? Mining
  Comments on RateMyProfessor.com</title>
    <summary>  Student reviews and comments on RateMyProfessor.com reflect realistic
learning experiences of students. Such information provides a large-scale data
source to examine the teaching quality of the lecturers. In this paper, we
propose an in-depth analysis of these comments. First, we partition our data
into different comparison groups. Next, we perform exploratory data analysis to
delve into the data. Furthermore, we employ Latent Dirichlet Allocation and
sentiment analysis to extract topics and understand the sentiments associated
with the comments. We uncover interesting insights about the characteristics of
both college students and professors. Our study proves that student reviews and
comments contain crucial information and can serve as essential references for
enrollment in courses and universities.
</summary>
    <author>
      <name>Ziqi Tang</name>
    </author>
    <author>
      <name>Yutong Wang</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2101.12339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2101.12339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.01922v1</id>
    <updated>2021-02-03T07:50:34Z</updated>
    <published>2021-02-03T07:50:34Z</published>
    <title>Session-based Recommendation with Self-Attention Networks</title>
    <summary>  Session-based recommendation aims to predict user's next behavior from
current session and previous anonymous sessions. Capturing long-range
dependencies between items is a vital challenge in session-based
recommendation. A novel approach is proposed for session-based recommendation
with self-attention networks (SR-SAN) as a remedy. The self-attention networks
(SAN) allow SR-SAN capture the global dependencies among all items of a session
regardless of their distance. In SR-SAN, a single item latent vector is used to
capture both current interest and global interest instead of session embedding
which is composed of current interest embedding and global interest embedding.
Some experiments have been performed on some open benchmark datasets.
Experimental results show that the proposed method outperforms some
state-of-the-arts by comparisons.
</summary>
    <author>
      <name>Jun Fang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages,5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2102.01922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.01922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.04205v2</id>
    <updated>2021-02-19T08:37:06Z</updated>
    <published>2021-02-05T08:33:45Z</published>
    <title>How Pandemic Spread in News: Text Analysis Using Topic Model</title>
    <summary>  Researches about COVID-19 has increased largely, no matter in the biology
field or the others. This research conducted a text analysis using LDA topic
model. We firstly scraped totally 1127 articles and 5563 comments on SCMP
covering COVID-19 from Jan 20 to May 19, then we trained the LDA model and
tuned parameters based on the Cv coherence as the model evaluation method. With
the optimal model, dominant topics, representative documents of each topic and
the inconsistence between articles and comments are analyzed. 3 possible
improvements are discussed at last.
</summary>
    <author>
      <name>Minghao Wang</name>
    </author>
    <author>
      <name>Paolo Mengoni</name>
    </author>
    <link href="http://arxiv.org/abs/2102.04205v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.04205v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.06687v2</id>
    <updated>2021-02-18T15:36:36Z</updated>
    <published>2021-02-12T18:45:23Z</published>
    <title>Destination similarity based on implicit user interest</title>
    <summary>  With the digitization of travel industry, it is more and more important to
understand users from their online behaviors. However, online travel industry
data are more challenging to analyze due to extra sparseness, dispersed user
history actions, fast change of user interest and lack of direct or indirect
feedbacks. In this work, a new similarity method is proposed to measure the
destination similarity in terms of implicit user interest. By comparing the
proposed method to several other widely used similarity measures in recommender
systems, the proposed method achieves a significant improvement on travel data.
Key words: Destination similarity, Travel industry, Recommender System,
Implicit user interest
</summary>
    <author>
      <name>Hongliu Cao</name>
    </author>
    <author>
      <name>Eoin Thomas</name>
    </author>
    <link href="http://arxiv.org/abs/2102.06687v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.06687v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.08113v1</id>
    <updated>2021-02-16T12:29:54Z</updated>
    <published>2021-02-16T12:29:54Z</published>
    <title>Recommender Systems for Configuration Knowledge Engineering</title>
    <summary>  The knowledge engineering bottleneck is still a major challenge in
configurator projects. In this paper we show how recommender systems can
support knowledge base development and maintenance processes. We discuss a
couple of scenarios for the application of recommender systems in knowledge
engineering and report the results of empirical studies which show the
importance of user-centered configuration knowledge organization.
</summary>
    <author>
      <name>Alexander Felfernig</name>
    </author>
    <author>
      <name>Stefan Reiterer</name>
    </author>
    <author>
      <name>Martin Stettinger</name>
    </author>
    <author>
      <name>Florian Reinfrank</name>
    </author>
    <author>
      <name>Michael Jeran</name>
    </author>
    <author>
      <name>Gerald Ninaus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A. Felfernig S, Reiterer, M. Stettinger, F. Reinfrank, M. Jeran, and
  G. Ninaus. Recommender Systems for Configuration Knowledge Engineering,
  Workshop on Configuration, Vienna, Austria, pp. 51-54, ISBN:
  979-10-91526-02-9, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/2102.08113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.08113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.09389v1</id>
    <updated>2021-02-15T12:09:46Z</updated>
    <published>2021-02-15T12:09:46Z</published>
    <title>HSR: Hyperbolic Social Recommender</title>
    <summary>  With the prevalence of online social media, users' social connections have
been widely studied and utilized to enhance the performance of recommender
systems. In this paper, we explore the use of hyperbolic geometry for social
recommendation. We present Hyperbolic Social Recommender (HSR), a novel social
recommendation framework that utilizes hyperbolic geometry to boost the
performance. With the help of hyperbolic spaces, HSR can learn high-quality
user and item representations for better modeling user-item interaction and
user-user social relations. Via a series of extensive experiments, we show that
our proposed HSR outperforms its Euclidean counterpart and state-of-the-art
social recommenders in click-through rate prediction and top-K recommendation,
demonstrating the effectiveness of social recommendation in the hyperbolic
space.
</summary>
    <author>
      <name>Anchen Li</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2102.09389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.09389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2102.12327v1</id>
    <updated>2021-02-24T15:02:50Z</updated>
    <published>2021-02-24T15:02:50Z</published>
    <title>An Overview of Direct Diagnosis and Repair Techniques in the WeeVis
  Recommendation Environment</title>
    <summary>  Constraint-based recommenders support users in the identification of items
(products) fitting their wishes and needs. Example domains are financial
services and electronic equipment. In this paper we show how divide-and-conquer
based (direct) diagnosis algorithms (no conflict detection is needed) can be
exploited in constraint-based recommendation scenarios. In this context, we
provide an overview of the MediaWiki-based recommendation environment WeeVis.
</summary>
    <author>
      <name>Alexander Felfernig</name>
    </author>
    <author>
      <name>Stefan Reiterer</name>
    </author>
    <author>
      <name>Martin Stettinger</name>
    </author>
    <author>
      <name>Michael Jeran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A. Felfernig, S. Reiterer, M. Stettinger, and M. Jeran. An Overview
  of Direct Diagnosis and Repair Techniques in the WeeVis Recommendation
  Environment. In the 25th International Workshop on Principles of Diagnosis,
  Graz, Austria, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/2102.12327v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2102.12327v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.00161v1</id>
    <updated>2021-07-01T00:43:05Z</updated>
    <published>2021-07-01T00:43:05Z</published>
    <title>The Use of Bandit Algorithms in Intelligent Interactive Recommender
  Systems</title>
    <summary>  In today's business marketplace, many high-tech Internet enterprises
constantly explore innovative ways to provide optimal online user experiences
for gaining competitive advantages. The great needs of developing intelligent
interactive recommendation systems are indicated, which could sequentially
suggest users the most proper items by accurately predicting their preferences,
while receiving the up-to-date feedback to refine the recommendation results,
continuously. Multi-armed bandit algorithms, which have been widely applied
into various online systems, are quite capable of delivering such efficient
recommendation services. However, few existing bandit models are able to adapt
to new changes introduced by the modern recommender systems.
</summary>
    <author>
      <name>Qing Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.00161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.00161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2107.00873v1</id>
    <updated>2021-07-02T07:15:27Z</updated>
    <published>2021-07-02T07:15:27Z</published>
    <title>On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration
  with DBpedia</title>
    <summary>  Modern large-scale knowledge graphs, such as DBpedia, are datasets which
require large computational resources to serve and process. Moreover, they
often have longer release cycles, which leads to outdated information in those
graphs. In this paper, we present DBpedia on Demand -- a system which serves
DBpedia resources on demand without the need to materialize and store the
entire graph, and which even provides limited querying functionality.
</summary>
    <author>
      <name>Malte Brockmeier</name>
    </author>
    <author>
      <name>Yawen Liu</name>
    </author>
    <author>
      <name>Sunita Pateer</name>
    </author>
    <author>
      <name>Sven Hertling</name>
    </author>
    <author>
      <name>Heiko Paulheim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Semantics 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2107.00873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2107.00873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.01542v1</id>
    <updated>2021-08-03T14:51:28Z</updated>
    <published>2021-08-03T14:51:28Z</published>
    <title>iART: A Search Engine for Art-Historical Images to Support Research in
  the Humanities</title>
    <summary>  In this paper, we introduce iART: an open Web platform for art-historical
research that facilitates the process of comparative vision. The system
integrates various machine learning techniques for keyword- and content-based
image retrieval as well as category formation via clustering. An intuitive GUI
supports users to define queries and explore results. By using a
state-of-the-art cross-modal deep learning approach, it is possible to search
for concepts that were not previously detected by trained classification
models. Art-historical objects from large, openly licensed collections such as
Amsterdam Rijksmuseum and Wikidata are made available to users.
</summary>
    <author>
      <name>Matthias Springstein</name>
    </author>
    <author>
      <name>Stefanie Schneider</name>
    </author>
    <author>
      <name>Javad Rahnama</name>
    </author>
    <author>
      <name>Eyke Hüllermeier</name>
    </author>
    <author>
      <name>Hubertus Kohle</name>
    </author>
    <author>
      <name>Ralph Ewerth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3474085.3478564</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3474085.3478564" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Multimedia Conference 2021</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2108.01542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.01542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.04976v2</id>
    <updated>2021-12-22T21:06:15Z</updated>
    <published>2021-08-11T00:33:18Z</published>
    <title>Deep Pairwise Learning To Rank For Search Autocomplete</title>
    <summary>  Autocomplete (a.k.a "Query Auto-Completion", "AC") suggests full queries
based on a prefix typed by customer. Autocomplete has been a core feature of
commercial search engine. In this paper, we propose a novel context-aware
neural network based pairwise ranker (DeepPLTR) to improve AC ranking, DeepPLTR
leverages contextual and behavioral features to rank queries by minimizing a
pairwise loss, based on a fully-connected neural network structure. Compared to
LambdaMART ranker, DeepPLTR shows +3.90% MeanReciprocalRank (MRR) lift in
offline evaluation, and yielded +0.06% (p &lt; 0.1) Gross Merchandise Value (GMV)
lift in an Amazon's online A/B experiment.
</summary>
    <author>
      <name>Kai Yuan</name>
    </author>
    <author>
      <name>Da Kuang</name>
    </author>
    <link href="http://arxiv.org/abs/2108.04976v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.04976v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.06014v1</id>
    <updated>2021-08-13T01:16:55Z</updated>
    <published>2021-08-13T01:16:55Z</published>
    <title>TPRM: A Topic-based Personalized Ranking Model for Web Search</title>
    <summary>  Ranking models have achieved promising results, but it remains challenging to
design personalized ranking systems to leverage user profiles and semantic
representations between queries and documents. In this paper, we propose a
topic-based personalized ranking model (TPRM) that integrates user topical
profile with pretrained contextualized term representations to tailor the
general document ranking list. Experiments on the real-world dataset
demonstrate that TPRM outperforms state-of-the-art ad-hoc ranking models and
personalized ranking models significantly.
</summary>
    <author>
      <name>Minghui Huang</name>
    </author>
    <author>
      <name>Wei Peng</name>
    </author>
    <author>
      <name>Dong Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2108.06014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.06014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.06215v1</id>
    <updated>2021-07-28T15:47:26Z</updated>
    <published>2021-07-28T15:47:26Z</published>
    <title>Sentiment Analysis of the COVID-related r/Depression Posts</title>
    <summary>  Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?
  Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT
</summary>
    <author>
      <name>Zihan Chen</name>
    </author>
    <author>
      <name>Marina Sokolova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures, 5 tables, 1 appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.06215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.06215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.06367v2</id>
    <updated>2023-06-11T14:40:04Z</updated>
    <published>2021-08-13T19:14:24Z</published>
    <title>Multi-Objective Recommendations: A Tutorial</title>
    <summary>  Recommender systems (RecSys) have been well developed to assist user decision
making. Traditional RecSys usually optimize a single objective (e.g., rating
prediction errors or ranking quality) in the model. There is an emerging demand
in multi-objective optimization recently in RecSys, especially in the area of
multi-stakeholder and multi-task recommender systems. This article provides an
overview of multi-objective recommendations, followed by the discussions with
case studies. The document is considered as a supplementary material for our
tutorial on multi-objective recommendations at ACM SIGKDD 2021.
</summary>
    <author>
      <name>Yong Zheng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Xuejun</arxiv:affiliation>
    </author>
    <author>
      <name> David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Xuejun</arxiv:affiliation>
    </author>
    <author>
      <name> Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2108.06367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.06367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.07571v1</id>
    <updated>2021-08-17T11:51:51Z</updated>
    <published>2021-08-17T11:51:51Z</published>
    <title>ACM-CR: A Manually Annotated Test Collection for Citation Recommendation</title>
    <summary>  Citation recommendation is intended to assist researchers in the process of
searching for relevant papers to cite by recommending appropriate citations for
a given input text. Existing test collections for this task are noisy and
unreliable since they are built automatically from parsed PDF papers. In this
paper, we present our ongoing effort at creating a publicly available, manually
annotated test collection for citation recommendation. We also conduct a series
of experiments to evaluate the effectiveness of content-based baseline models
on the test collection, providing results for future work to improve upon. Our
test collection and code to replicate experiments are available at
https://github.com/boudinfl/acm-cr
</summary>
    <author>
      <name>Florian Boudin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at JCDL 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.07571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.07571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2108.13302v1</id>
    <updated>2021-08-20T02:47:07Z</updated>
    <published>2021-08-20T02:47:07Z</published>
    <title>A Theoretical Framework for Online Information Search</title>
    <summary>  A significant part of human activity today consists of searching for a piece
of information online, utilizing knowledge repositories. This endeavor may be
time-consuming if the individual searching for the information is unfamiliar
with the subject matter of that information. However, experts can aid
individuals find relevant information by searching online. This paper describes
a theoretical framework to model the dynamic process by which requests for
information come to a system of experts, who then answer the requests by
searching for those pieces of information.
</summary>
    <author>
      <name>Rohit Negi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2108.13302v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2108.13302v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.02022v1</id>
    <updated>2021-09-05T08:16:10Z</updated>
    <published>2021-09-05T08:16:10Z</published>
    <title>Recommending Researchers in Machine Learning based on Author-Topic Model</title>
    <summary>  The aim of this paper is to uncover the researchers in machine learning using
the author-topic model (ATM). We collect 16,855 scientific papers from six top
journals in the field of machine learning published from 1997 to 2016 and
analyze them using ATM. The dataset is broken down into 4 intervals to identify
the top researchers and find similar researchers using their similarity score.
The similarity score is calculated using Hellinger distance. The researchers
are plotted using t-SNE, which reduces the dimensionality of the data while
keeping the same distance between the points. The analysis of our study helps
the upcoming researchers to find the top researchers in their area of interest.
</summary>
    <author>
      <name>Deepak Sharma</name>
    </author>
    <author>
      <name>Bijendra Kumar</name>
    </author>
    <author>
      <name>Satish Chand</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages,6 Figures, Presented in conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.02022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.02022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4, I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.02475v1</id>
    <updated>2021-08-25T15:11:38Z</updated>
    <published>2021-08-25T15:11:38Z</published>
    <title>Recommendation System Simulations: A Discussion of Two Key Challenges</title>
    <summary>  As recommendation systems become increasingly standard for online platforms,
simulations provide an avenue for understanding the impacts of these systems on
individuals and society. When constructing a recommendation system simulation,
there are two key challenges: first, defining a model for users selecting or
engaging with recommended items and second, defining a mechanism for users
encountering items that are not recommended to the user directly by the
platform, such as by a friend sharing specific content. This paper will delve
into both of these challenges, reviewing simulation assumptions from existing
research and proposing alternative assumptions. We also include a broader
discussion of the limitations of simulations and outline of open questions in
this area.
</summary>
    <author>
      <name>Allison J. B. Chaney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.02475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.02475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.04713v1</id>
    <updated>2021-09-10T07:39:52Z</updated>
    <published>2021-09-10T07:39:52Z</published>
    <title>Personalized Entity Search by Sparse and Scrutable User Profiles</title>
    <summary>  Prior work on personalizing web search results has focused on considering
query-and-click logs to capture users individual interests. For product search,
extensive user histories about purchases and ratings have been exploited.
However, for general entity search, such as for books on specific topics or
travel destinations with certain features, personalization is largely
underexplored. In this paper, we address personalization of book search, as an
exemplary case of entity search, by exploiting sparse user profiles obtained
through online questionnaires. We devise and compare a variety of re-ranking
methods based on language models or neural learning. Our experiments show that
even very sparse information about individuals can enhance the effectiveness of
the search results.
</summary>
    <author>
      <name>Ghazaleh Haratinezhad Torbati</name>
    </author>
    <author>
      <name>Andrew Yates</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <link href="http://arxiv.org/abs/2109.04713v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.04713v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.07692v1</id>
    <updated>2021-09-16T03:23:37Z</updated>
    <published>2021-09-16T03:23:37Z</published>
    <title>Evaluating Music Recommendations with Binary Feedback for Multiple
  Stakeholders</title>
    <summary>  High quality user feedback data is essential to training and evaluating a
successful music recommendation system, particularly one that has to balance
the needs of multiple stakeholders. Most existing music datasets suffer from
noisy feedback and self-selection biases inherent in the data collected by
music platforms. Using the Piki Music dataset of 500k ratings collected over a
two-year time period, we evaluate the performance of classic recommendation
algorithms on three important stakeholders: consumers, well-known artists and
lesser-known artists. We show that a matrix factorization algorithm trained on
both likes and dislikes performs significantly better compared to one trained
only on likes for all three stakeholders.
</summary>
    <author>
      <name>Sasha Stoikov</name>
    </author>
    <author>
      <name>Hongyi Wen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the MORS workshop at RecSys 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.07692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.07692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.13908v1</id>
    <updated>2021-09-28T17:55:48Z</updated>
    <published>2021-09-28T17:55:48Z</published>
    <title>The eDiscovery Medicine Show</title>
    <summary>  The practice of bloodletting gradually fell into disfavor as a growing body
of scientific evidence showed its ineffectiveness and demonstrated the
effectiveness of various pharmaceuticals for the prevention and treatment of
certain diseases. At the same time, the patent medicine industry promoted
ineffective remedies at medicine shows featuring entertainment, testimonials,
and pseudo-scientific claims with all the trappings--but none of the
methodology--of science. Today, many producing parties and eDiscovery vendors
similarly promote obsolete technology as well as unvetted tools labeled
"artificial intelligence" or "technology-assisted review," along with unsound
validation protocols. This situation will end only when eDiscovery technologies
and tools are subject to testing using the methods of information retrieval.
</summary>
    <author>
      <name>Maura R. Grossman</name>
    </author>
    <author>
      <name>Gordon V. Cormack</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Ohio State Technology Law Journal 18:1 (2021)</arxiv:comment>
    <link href="http://arxiv.org/abs/2109.13908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2109.13908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.00123v1</id>
    <updated>2021-10-29T23:43:19Z</updated>
    <published>2021-10-29T23:43:19Z</published>
    <title>Learning Representations for Zero-Shot Retrieval over Structured Data</title>
    <summary>  Large Scale Question-Answering systems today are widely used in downstream
applications such as chatbots and conversational dialogue agents. Typically,
such systems consist of an Answer Passage retrieval layer coupled with Machine
Comprehension models trained on natural language query-passage pairs. Recent
studies have explored Question Answering over structured data sources such as
web-tables and relational databases. However, architectures such as Seq2SQL
assume the correct table a priori which is input to the model along with the
free text question. Our proposed method, analogues to a passage retrieval model
in traditional Question-Answering systems, describes an architecture to discern
the correct table pertaining to a given query from amongst a large pool of
candidate tables.
</summary>
    <author>
      <name>Harsh Kohli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.00123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.00123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.02239v1</id>
    <updated>2021-11-03T13:59:45Z</updated>
    <published>2021-11-03T13:59:45Z</published>
    <title>Order Matters: Matching Multiple Knowledge Graphs</title>
    <summary>  Knowledge graphs (KGs) provide information in machine interpretable form. In
cases where multiple KGs are used in the same system, that information needs to
be integrated. This is usually done by automated matching systems. Most of
those systems consider only 1:1 (binary) matching tasks. Thus, matching a
larger number of knowledge graphs with such systems would lead to quadratic
efforts. In this paper, we empirically analyze different approaches to reduce
the task of multi-source matching to a linear number of executions of binary
matching systems. We show that the matching order of KGs and the multi-source
strategy actually matter and that near-optimal results can be achieved with
linear efforts.
</summary>
    <author>
      <name>Sven Hertling</name>
    </author>
    <author>
      <name>Heiko Paulheim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3460210.3493556</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3460210.3493556" rel="related"/>
    <link href="http://arxiv.org/abs/2111.02239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.02239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.05988v2</id>
    <updated>2022-06-08T14:42:48Z</updated>
    <published>2021-11-10T23:37:23Z</published>
    <title>Cross-language Information Retrieval</title>
    <summary>  Two key assumptions shape the usual view of ranked retrieval: (1) that the
searcher can choose words for their query that might appear in the documents
that they wish to see, and (2) that ranking retrieved documents will suffice
because the searcher will be able to recognize those which they wished to find.
When the documents to be searched are in a language not known by the searcher,
neither assumption is true. In such cases, Cross-Language Information Retrieval
(CLIR) is needed. This chapter reviews the state of the art for CLIR and
outlines some open research questions.
</summary>
    <author>
      <name>Petra Galuščáková</name>
    </author>
    <author>
      <name>Douglas W. Oard</name>
    </author>
    <author>
      <name>Suraj Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages, 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.05988v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.05988v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.07154v1</id>
    <updated>2021-11-13T17:20:49Z</updated>
    <published>2021-11-13T17:20:49Z</published>
    <title>Session-aware Item-combination Recommendation with Transformer Network</title>
    <summary>  In this paper, we detailedly describe our solution for the IEEE BigData Cup
2021: RL-based RecSys (Track 1: Item Combination Prediction). We first conduct
an exploratory data analysis on the dataset and then utilize the findings to
design our framework. Specifically, we use a two-headed transformer-based
network to predict user feedback and unlocked sessions, along with the proposed
session-aware reweighted loss, multi-tasking with click behavior prediction,
and randomness-in-session augmentation. In the final private leaderboard on
Kaggle, our method ranked 2nd with a categorization accuracy of 0.39224.
</summary>
    <author>
      <name>Tzu-Heng Lin</name>
    </author>
    <author>
      <name>Chen Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd place solution in IEEE Bigdata Cup 2021 (Track 1: Item
  Combination Prediction). Our code is available at
  https://github.com/lzhbrian/bigdatacup2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.07154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.07154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.10504v1</id>
    <updated>2021-11-20T03:14:01Z</updated>
    <published>2021-11-20T03:14:01Z</published>
    <title>Effects of context, complexity, and clustering on evaluation for math
  formula retrieval</title>
    <summary>  There are now several test collections for the formula retrieval task, in
which a system's goal is to identify useful mathematical formulae to show in
response to a query posed as a formula. These test collections differ in query
format, query complexity, number of queries, content source, and relevance
definition. Comparisons among six formula retrieval test collections illustrate
that defining relevance based on query and/or document context can be
consequential, that system results vary markedly with formula complexity, and
that judging relevance after clustering formulas with identical symbol layouts
(i.e., Symbol Layout Trees) can affect system preference ordering.
</summary>
    <author>
      <name>Behrooz Mansouri</name>
    </author>
    <author>
      <name>Douglas W. Oard</name>
    </author>
    <author>
      <name>Anurag Agarwal</name>
    </author>
    <author>
      <name>Richard Zanibbi</name>
    </author>
    <link href="http://arxiv.org/abs/2111.10504v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.10504v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.13466v1</id>
    <updated>2021-11-26T12:29:26Z</updated>
    <published>2021-11-26T12:29:26Z</published>
    <title>Streamlining Evaluation with ir-measures</title>
    <summary>  We present ir-measures, a new tool that makes it convenient to calculate a
diverse set of evaluation measures used in information retrieval. Rather than
implementing its own measure calculations, ir-measures provides a common
interface to a handful of evaluation tools. The necessary tools are
automatically invoked (potentially multiple times) to calculate all the desired
metrics, simplifying the evaluation process for the user. The tool also makes
it easier for researchers to use recently-proposed measures (such as those from
the C/W/L framework) alongside traditional measures, potentially encouraging
their adoption.
</summary>
    <author>
      <name>Sean MacAvaney</name>
    </author>
    <author>
      <name>Craig Macdonald</name>
    </author>
    <author>
      <name>Iadh Ounis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2022 (demo)</arxiv:comment>
    <link href="http://arxiv.org/abs/2111.13466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.13466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2111.13957v1</id>
    <updated>2021-11-27T18:35:44Z</updated>
    <published>2021-11-27T18:35:44Z</published>
    <title>Interpreting Dense Retrieval as Mixture of Topics</title>
    <summary>  Dense Retrieval (DR) reaches state-of-the-art results in first-stage
retrieval, but little is known about the mechanisms that contribute to its
success. Therefore, in this work, we conduct an interpretation study of
recently proposed DR models. Specifically, we first discretize the embeddings
output by the document and query encoders. Based on the discrete
representations, we analyze the attribution of input tokens. Both qualitative
and quantitative experiments are carried out on public test collections.
Results suggest that DR models pay attention to different aspects of input and
extract various high-level topic representations. Therefore, we can regard the
representations learned by DR models as a mixture of high-level topics.
</summary>
    <author>
      <name>Jingtao Zhan</name>
    </author>
    <author>
      <name>Jiaxin Mao</name>
    </author>
    <author>
      <name>Yiqun Liu</name>
    </author>
    <author>
      <name>Jiafeng Guo</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <author>
      <name>Shaoping Ma</name>
    </author>
    <link href="http://arxiv.org/abs/2111.13957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2111.13957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.03105v1</id>
    <updated>2021-11-22T18:29:44Z</updated>
    <published>2021-11-22T18:29:44Z</published>
    <title>Active Learning Meets Optimized Item Selection</title>
    <summary>  Designing recommendation systems with limited or no available training data
remains a challenge. To that end, a new combinatorial optimization problem is
formulated to generate optimized item selection for experimentation with the
goal to shorten the time for collecting randomized training data. We first
present an overview of the optimized item selection problem and a multi-level
optimization framework to solve it. The approach integrates techniques from
discrete optimization, unsupervised clustering, and latent text embeddings. We
then discuss how to incorporate optimized item selection with active learning
as part of randomized exploration in an ongoing fashion.
</summary>
    <author>
      <name>Bernard Kleynhans</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Serdar Kadıoğlu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCAI 2021 Data Science Meets Optimization Workshop (DSO@IJCAI 2021)</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.03105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.03105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.04666v1</id>
    <updated>2021-12-09T02:51:15Z</updated>
    <published>2021-12-09T02:51:15Z</published>
    <title>Densifying Sparse Representations for Passage Retrieval by
  Representational Slicing</title>
    <summary>  Learned sparse and dense representations capture different successful
approaches to text retrieval and the fusion of their results has proven to be
more effective and robust. Prior work combines dense and sparse retrievers by
fusing their model scores. As an alternative, this paper presents a simple
approach to densifying sparse representations for text retrieval that does not
involve any training. Our densified sparse representations (DSRs) are
interpretable and can be easily combined with dense representations for
end-to-end retrieval. We demonstrate that our approach can jointly learn sparse
and dense representations within a single model and then combine them for dense
retrieval. Experimental results suggest that combining our DSRs and dense
representations yields a balanced tradeoff between effectiveness and
efficiency.
</summary>
    <author>
      <name>Sheng-Chieh Lin</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <link href="http://arxiv.org/abs/2112.04666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.04666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.08632v2</id>
    <updated>2022-01-14T23:37:46Z</updated>
    <published>2021-12-16T05:17:31Z</published>
    <title>CDRec: Cayley-Dickson Recommender</title>
    <summary>  In this paper, we propose a recommendation framework named Cayley-Dickson
Recommender. We introduce Cayley-Dickson construction which uses a recursive
process to define hypercomplex algebras and their mathematical operations. We
also design a graph convolution operator to learn representations in the
hypercomplex space. To the best of our knowledge, it is the first time that
Cayley-Dickson construction and graph convolution techniques have been used in
hypercomplex recommendation. Compared with the state-of-the-art recommendation
methods, our method achieves superior performance on real-world datasets.
</summary>
    <author>
      <name>Anchen Li</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <author>
      <name>Huan Huo</name>
    </author>
    <author>
      <name>Farookh Hussain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1. The Preliminary Section is not sufficient. 2. Figure 2 is not
  clear enough. 3. The Experiment Section are not sufficient</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.08632v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.08632v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.09628v1</id>
    <updated>2021-12-17T16:59:40Z</updated>
    <published>2021-12-17T16:59:40Z</published>
    <title>Sparsifying Sparse Representations for Passage Retrieval by Top-$k$
  Masking</title>
    <summary>  Sparse lexical representation learning has demonstrated much progress in
improving passage retrieval effectiveness in recent models such as DeepImpact,
uniCOIL, and SPLADE. This paper describes a straightforward yet effective
approach for sparsifying lexical representations for passage retrieval,
building on SPLADE by introducing a top-$k$ masking scheme to control sparsity
and a self-learning method to coax masked representations to mimic unmasked
representations. A basic implementation of our model is competitive with more
sophisticated approaches and achieves a good balance between effectiveness and
efficiency. The simplicity of our methods opens the door for future
explorations in lexical representation learning for passage retrieval.
</summary>
    <author>
      <name>Jheng-Hong Yang</name>
    </author>
    <author>
      <name>Xueguang Ma</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2112.09628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.09628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.10085v2</id>
    <updated>2023-09-19T09:29:28Z</updated>
    <published>2021-12-19T08:11:57Z</published>
    <title>D-HAN: Dynamic News Recommendation with Hierarchical Attention Network</title>
    <summary>  News recommendation models often fall short in capturing users' preferences
due to their static approach to user-news interactions. To address this
limitation, we present a novel dynamic news recommender model that seamlessly
integrates continuous time information to a hierarchical attention network that
effectively represents news information at the sentence, element, and sequence
levels. Moreover, we introduce a dynamic negative sampling method to optimize
users' implicit feedback. To validate our model's effectiveness, we conduct
extensive experiments on three real-world datasets. The results demonstrate the
effectiveness of our proposed approach.
</summary>
    <author>
      <name>Qinghua Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2112.10085v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.10085v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.12773v1</id>
    <updated>2021-12-23T18:48:35Z</updated>
    <published>2021-12-23T18:48:35Z</published>
    <title>Customising Ranking Models for Enterprise Search on Bilingual
  Click-Through Dataset</title>
    <summary>  In this work, we provide the details about the process of establishing an
end-to-end system for enterprise search on bilingual click-through dataset. The
first part of the paper will be about the high-level workflow of the system.
Then, in the second part we will elaborately mention about the ranking models
to improve the search results in the vertical search of the technical documents
in enterprise domain. Throughout the paper, we will mention the way which we
combine the methods in IR literature. Finally, in the last part of the paper we
will report our results using different ranking algorithms with $NDCG@k$ where
k is the cut-off value.
</summary>
    <author>
      <name>Gizem Gezici</name>
    </author>
    <link href="http://arxiv.org/abs/2112.12773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.12773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.14958v1</id>
    <updated>2021-12-30T08:22:03Z</updated>
    <published>2021-12-30T08:22:03Z</published>
    <title>A Benchmark Dataset for Micro-video Thumbnail Selection</title>
    <summary>  The thumbnail, as the first sight of a micro-video, plays a pivotal role in
attracting users to click and watch. Although several pioneer efforts have been
dedicated to jointly considering the quality and representativeness for
selecting the thumbnail, they are limited in exploring the influence of users`
interests. While in the real scenario, the more the thumbnails satisfy the
users, the more likely the micro-videos will be clicked. In this paper, we aim
to select the thumbnail of a given micro-video that meets most users`
interests. Towards this end, we construct a large-scale dataset for the
micro-video thumbnails. Ultimately, we conduct several baselines on the dataset
and demonstrate the effectiveness of our dataset.
</summary>
    <author>
      <name>Liu Bo</name>
    </author>
    <link href="http://arxiv.org/abs/2112.14958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2112.14958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.08235v1</id>
    <updated>2022-04-18T09:48:15Z</updated>
    <published>2022-04-18T09:48:15Z</published>
    <title>Table Enrichment System for Machine Learning</title>
    <summary>  Data scientists are constantly facing the problem of how to improve
prediction accuracy with insufficient tabular data. We propose a table
enrichment system that enriches a query table by adding external attributes
(columns) from data lakes and improves the accuracy of machine learning
predictive models. Our system has four stages, join row search, task-related
table selection, row and column alignment, and feature selection and
evaluation, to efficiently create an enriched table for a given query table and
a specified machine learning task. We demonstrate our system with a web UI to
show the use cases of table enrichment.
</summary>
    <author>
      <name>Yuyang Dong</name>
    </author>
    <author>
      <name>Masafumi Oyamada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">demo paper at SIGIR2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.08235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.08235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.11154v1</id>
    <updated>2022-04-23T23:57:34Z</updated>
    <published>2022-04-23T23:57:34Z</published>
    <title>Dual Skipping Guidance for Document Retrieval with Learned Sparse
  Representations</title>
    <summary>  This paper proposes a dual skipping guidance scheme with hybrid scoring to
accelerate document retrieval that uses learned sparse representations while
still delivering a good relevance. This scheme uses both lexical BM25 and
learned neural term weights to bound and compose the rank score of a candidate
document separately for skipping and final ranking, and maintains two top-k
thresholds during inverted index traversal. This paper evaluates time
efficiency and ranking relevance of the proposed scheme in searching MS MARCO
TREC datasets.
</summary>
    <author>
      <name>Yifan Qiao</name>
    </author>
    <author>
      <name>Yingrui Yang</name>
    </author>
    <author>
      <name>Haixin Lin</name>
    </author>
    <author>
      <name>Tianbo Xiong</name>
    </author>
    <author>
      <name>Xiyue Wang</name>
    </author>
    <author>
      <name>Tao Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2204.11154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.11154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.11428v1</id>
    <updated>2022-04-25T04:31:33Z</updated>
    <published>2022-04-25T04:31:33Z</published>
    <title>Personal Research Knowledge Graphs</title>
    <summary>  Maintaining research-related information in an organized manner can be
challenging for a researcher. In this paper, we envision personal research
knowledge graphs (PRKGs) as a means to represent structured information about
the research activities of a researcher. PRKGs can be used to power intelligent
personal assistants, and personalize various applications. We explore what
entities and relations could be potentially included in a PRKG, how to extract
them from various sources, and how to share a PRKG within a research group.
</summary>
    <author>
      <name>Prantika Chakraborty</name>
    </author>
    <author>
      <name>Sudakshina Dutta</name>
    </author>
    <author>
      <name>Debarshi Kumar Sanyal</name>
    </author>
    <link href="http://arxiv.org/abs/2204.11428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.11428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.11593v1</id>
    <updated>2022-04-13T16:41:42Z</updated>
    <published>2022-04-13T16:41:42Z</published>
    <title>Scaling Cross-Domain Content-Based Image Retrieval for E-commerce Snap
  and Search Application</title>
    <summary>  In this industry talk at ECIR 2022, we illustrate how we approach the main
challenges from large scale cross-domain content-based image retrieval using a
cascade method and a combination of our visual search and classification
capabilities. Specifically, we present a system that is able to handle the
scale of the data for e-commerce usage and the cross-domain nature of the query
and gallery image pools. We showcase the approach applied in real-world
e-commerce snap and search use case and its impact on ranking and latency
performance.
</summary>
    <author>
      <name>Isaac Kwan Yin Chung</name>
    </author>
    <author>
      <name>Minh Tran</name>
    </author>
    <author>
      <name>Eran Nussinovitch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2022 Industry Day</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.11593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.11593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2204.13583v1</id>
    <updated>2022-04-27T15:10:30Z</updated>
    <published>2022-04-27T15:10:30Z</published>
    <title>KL-Mat : Fair Recommender System via Information Geometry</title>
    <summary>  Recommender system has intrinsic problems such as sparsity and fairness.
Although it has been widely adopted for the past decades, research on fairness
of recommendation algorithms has been largely neglected until recently. One
important paradigm for resolving the issue is regularization. However,
researchers have not been able to come up with a consensusly agreed
regularization term like regularization framework in other fields such as Lasso
or Ridge Regression. In this paper, we borrow concepts from information
geometry and propose a new regularization-based fair algorithm called KL-Mat.
The algorithmic technique leads to a more robust performance in accuracy
performance such as MAE. More importantly, the algorithm produces much fairer
results than vanilla matrix factorization approach. KL-Mat is fast,
easy-to-implement and explainable.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3514105.3514107</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3514105.3514107" rel="related"/>
    <link href="http://arxiv.org/abs/2204.13583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.13583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.00456v1</id>
    <updated>2022-05-01T12:11:17Z</updated>
    <published>2022-05-01T12:11:17Z</published>
    <title>An Analysis of the Features Considerable for NFT Recommendations</title>
    <summary>  This research explores the methods that NFTs can be recommended to people who
interact with NFT-marketplaces to explore NFTs of preference and similarity to
what they have been searching for. While exploring past methods that can be
adopted for recommendations, the use of NFT traits for recommendations has been
explored. The outcome of the research highlights the necessity of using
multiple Recommender Systems to present the user with the best possible NFTs
when interacting with decentralized systems.
</summary>
    <author>
      <name>Dinuka Piyadigama</name>
    </author>
    <author>
      <name>Guhanathan Poravi</name>
    </author>
    <link href="http://arxiv.org/abs/2205.00456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.00456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.09083v1</id>
    <updated>2022-05-18T17:19:16Z</updated>
    <published>2022-05-18T17:19:16Z</published>
    <title>Health Information Retrieval -- State of the art report</title>
    <summary>  This report provides an overview of the field of Information Retrieval (IR)
in healthcare. It does not aim to introduce general concepts and theories of IR
but to present and describe specific aspects of Health Information Retrieval
(HIR). After a brief introduction to the more broader field of IR, the
significance of HIR at current times is discussed. Specific characteristics of
Health Information, its classification and the main existing representations
for health concepts are described together with the main products and services
in the area (e.g.: databases of health bibliographic content, health specific
search engines and others). Recent research work is discussed and the most
active researchers, projects and research groups are also presented. Main
organizations and journals are also identified.
</summary>
    <author>
      <name>Carla Teixeira Lopes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2205.09083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.09083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.12371v1</id>
    <updated>2022-05-24T21:27:15Z</updated>
    <published>2022-05-24T21:27:15Z</published>
    <title>recommenderlab: An R Framework for Developing and Testing Recommendation
  Algorithms</title>
    <summary>  Algorithms that create recommendations based on observed data have
significant commercial value for online retailers and many other industries.
Recommender systems have a significant research community, and studying such
systems is part of most modern data science curricula. While there is an
abundance of software that implements recommendation algorithms, there is
little in terms of supporting recommender system research and education. This
paper describes the open-source software recommenderlab which was created with
supporting research and education in mind. The package can be directly
installed in R or downloaded from https://github.com/mhahsler/recommenderlab.
</summary>
    <author>
      <name>Michael Hahsler</name>
    </author>
    <link href="http://arxiv.org/abs/2205.12371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.12371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2205.15918v1</id>
    <updated>2022-05-31T16:08:41Z</updated>
    <published>2022-05-31T16:08:41Z</published>
    <title>Interactive Query Clarification and Refinement via User Simulation</title>
    <summary>  When users initiate search sessions, their queries are often unclear or might
lack of context; this resulting in inefficient document ranking. Multiple
approaches have been proposed by the Information Retrieval community to add
context and retrieve documents aligned with users' intents. While some work
focus on query disambiguation using users' browsing history, a recent line of
work proposes to interact with users by asking clarification questions or/and
proposing clarification panels. However, these approaches count either a
limited number (i.e., 1) of interactions with user or log-based interactions.
In this paper, we propose and evaluate a fully simulated query clarification
framework allowing multi-turn interactions between IR systems and user agents.
</summary>
    <author>
      <name>Pierre Erbacher</name>
    </author>
    <author>
      <name>Ludovic Denoyer</name>
    </author>
    <author>
      <name>Laure Soulier</name>
    </author>
    <link href="http://arxiv.org/abs/2205.15918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2205.15918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.00151v1</id>
    <updated>2022-05-31T23:48:12Z</updated>
    <published>2022-05-31T23:48:12Z</published>
    <title>DotMat: Solving Cold-start Problem and Alleviating Sparsity Problem for
  Recommender Systems</title>
    <summary>  Cold-start and sparsity problem are two key intrinsic problems to recommender
systems. During the past two decades, researchers and industrial practitioners
have spent considerable amount of efforts trying to solve the problems.
However, for cold-start problem, most research relies on importing side
information to transfer knowledge. A notable exception is ZeroMat, which uses
no extra input data. Sparsity is a lesser noticed problem. In this paper, we
propose a new algorithm named DotMat that relies on no extra input data, but is
capable of solving cold-start and sparsity problems. In experiments, we prove
that like ZeroMat, DotMat can achieve competitive results with recommender
systems with full data, such as the classic matrix factorization algorithm.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2022 IEEE 5th International Conference on Electronics Technology
  (ICET 2022)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2206.00151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.00151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.02254v1</id>
    <updated>2022-06-05T20:09:46Z</updated>
    <published>2022-06-05T20:09:46Z</published>
    <title>Augmenting Netflix Search with In-Session Adapted Recommendations</title>
    <summary>  We motivate the need for recommendation systems that can cater to the members
in-the-moment intent by leveraging their interactions from the current session.
We provide an overview of an end-to-end in-session adaptive recommendations
system in the context of Netflix Search. We discuss the challenges and
potential solutions when developing such a system at production scale.
</summary>
    <author>
      <name>Moumita Bhattacharya</name>
    </author>
    <author>
      <name>Sudarshan Lamkhede</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2206.02254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.02254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2 ARTIFICIAL INTELLIGENCE, H.3 INFORMATION STORAGE AND RETRIEVAL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.02630v1</id>
    <updated>2022-05-31T08:02:30Z</updated>
    <published>2022-05-31T08:02:30Z</published>
    <title>Improving Ads-Profitability Using Traffic-Fingerprints</title>
    <summary>  This paper introduces the concept of traffic-fingerprints, i.e., normalized
24-dimensional vectors representing a distribution of daily traffic on a web
page. Using k-means clustering we show that similarity of traffic-fingerprints
is related to the similarity of profitability time patterns for ads shown on
these pages. In other words, these fingerprints are correlated with the
conversions rates, thus allowing us to argue about conversion rates on pages
with negligible traffic. By blocking or unblocking whole clusters of pages we
were able to increase the revenue of online campaigns by more than 50%.
</summary>
    <author>
      <name>Adam Gabriel Dobrakowski</name>
    </author>
    <author>
      <name>Andrzej Pacuk</name>
    </author>
    <author>
      <name>Piotr Sankowski</name>
    </author>
    <author>
      <name>Marcin Mucha</name>
    </author>
    <author>
      <name>Paweł Brach</name>
    </author>
    <link href="http://arxiv.org/abs/2206.02630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.02630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.05554v1</id>
    <updated>2022-06-11T15:54:48Z</updated>
    <published>2022-06-11T15:54:48Z</published>
    <title>Incremental Information Gain Mining Of Temporal Relational Streams</title>
    <summary>  This paper studies the problem of mining for data values with high
information gain in relational tables. High information gain can help data
analysts and secondary data mining algorithms gain insights into strong
statistical dependencies and causality relationship between key metrics. In
this paper, we will study the problem of high information gain identification
for scenarios involving temporal relations where new records are added
continuously to the relations. We show that information gain can be efficiently
maintained in an incremental fashion, making it possible to monitor
continuously high information gain values.
</summary>
    <author>
      <name>Ken Pu</name>
    </author>
    <author>
      <name>Limin Ma</name>
    </author>
    <link href="http://arxiv.org/abs/2206.05554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.05554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2206.12291v1</id>
    <updated>2022-06-23T03:08:11Z</updated>
    <published>2022-06-23T03:08:11Z</published>
    <title>A Design of A Simple Yet Effective Exercise Recommendation System in
  K-12 Online Learning</title>
    <summary>  We propose a simple but effective method to recommend exercises with high
quality and diversity for students. Our method is made up of three key
components: (1) candidate generation module; (2) diversity-promoting module;
and (3) scope restriction module. The proposed method improves the overall
recommendation performance in terms of recall, and increases the diversity of
the recommended candidates by 0.81\% compared to the baselines.
</summary>
    <author>
      <name>Shuyan Huang</name>
    </author>
    <author>
      <name>Qiongqiong Liu</name>
    </author>
    <author>
      <name>Jiahao Chen</name>
    </author>
    <author>
      <name>Xiangen Hu</name>
    </author>
    <author>
      <name>Zitao Liu</name>
    </author>
    <author>
      <name>Weiqi Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AIED 2022: The 23rd International Conference on Artificial
  Intelligence in Education (accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/2206.12291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2206.12291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.11497v1</id>
    <updated>2022-07-23T11:46:13Z</updated>
    <published>2022-07-23T11:46:13Z</published>
    <title>Patent Search Using Triplet Networks Based Fine-Tuned SciBERT</title>
    <summary>  In this paper, we propose a novel method for the prior-art search task. We
fine-tune SciBERT transformer model using Triplet Network approach, allowing us
to represent each patent with a fixed-size vector. This also enables us to
conduct efficient vector similarity computations to rank patents in query time.
In our experiments, we show that our proposed method outperforms baseline
methods.
</summary>
    <author>
      <name>Utku Umur Acikalin</name>
    </author>
    <author>
      <name>Mucahid Kutlu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is accepted at the 3rd Workshop on Patent Text Mining and
  Semantic Technologies (PatentSemTech) 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2207.11497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.11497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.13443v2</id>
    <updated>2022-09-12T07:54:26Z</updated>
    <published>2022-07-27T10:43:27Z</published>
    <title>Lecture Notes on Neural Information Retrieval</title>
    <summary>  These lecture notes focus on the recent advancements in neural information
retrieval, with particular emphasis on the systems and models exploiting
transformer networks. These networks, originally proposed by Google in 2017,
have seen a large success in many natural language processing and information
retrieval tasks. While there are many fantastic textbook on information
retrieval and natural language processing as well as specialised books for a
more advanced audience, these lecture notes target people aiming at developing
a basic understanding of the main information retrieval techniques and
approaches based on deep learning. These notes have been prepared for a IR
graduate course of the MSc program in Artificial Intelligence and Data
Engineering at the University of Pisa, Italy.
</summary>
    <author>
      <name>Nicola Tonellotto</name>
    </author>
    <link href="http://arxiv.org/abs/2207.13443v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.13443v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.00108v1</id>
    <updated>2022-07-30T00:44:54Z</updated>
    <published>2022-07-30T00:44:54Z</published>
    <title>Some Practice for Improving the Search Results of E-commerce</title>
    <summary>  In the Amazon KDD Cup 2022, we aim to apply natural language processing
methods to improve the quality of search results that can significantly enhance
user experience and engagement with search engines for e-commerce. We discuss
our practical solution for this competition, ranking 6th in task one, 2nd in
task two, and 2nd in task 3. The code is available at
https://github.com/wufanyou/KDD-Cup-2022-Amazon.
</summary>
    <author>
      <name>Fanyou Wu</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Rado Gazo</name>
    </author>
    <author>
      <name>Benes Bedrich</name>
    </author>
    <author>
      <name>Xiaobo Qu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Amazon KDD Cup 2022 workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.00108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.00108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.03242v2</id>
    <updated>2022-09-09T13:07:58Z</updated>
    <published>2022-08-05T15:55:02Z</published>
    <title>Minimizing Mindless Mentions: Recommendation with Minimal Necessary User
  Reviews</title>
    <summary>  Recently, researchers have turned their attention to recommender systems that
use only minimal necessary data. This trend is informed by the idea that
recommender systems should use no more user interactions than are needed in
order to provide users with useful recommendations. In this position paper, we
make the case for applying the idea of minimal necessary data to recommender
systems that use user reviews. We argue that the content of individual user
reviews should be subject to minimization. Specifically, reviews used as
training data to generate recommendations or reviews used to help users decide
on purchases or consumption should be automatically edited to contain only the
information that is needed.
</summary>
    <author>
      <name>Danny Stax</name>
    </author>
    <author>
      <name>Manel Slokom</name>
    </author>
    <author>
      <name>Martha Larson</name>
    </author>
    <link href="http://arxiv.org/abs/2208.03242v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.03242v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.03854v2</id>
    <updated>2022-08-20T00:19:32Z</updated>
    <published>2022-08-08T00:42:42Z</published>
    <title>Towards Fair Conversational Recommender Systems</title>
    <summary>  Conversational recommender systems have demonstrated great success. They can
accurately capture a user's current detailed preference -- through a
multi-round interaction cycle -- to effectively guide users to a more
personalized recommendation. Alas, conversational recommender systems can be
plagued by the adverse effects of bias, much like traditional recommenders. In
this work, we argue for increased attention on the presence of and methods for
counteracting bias in these emerging systems. As a starting point, we propose
three fundamental questions that should be deeply examined to enable fairness
in conversational recommender systems.
</summary>
    <author>
      <name>Allen Lin</name>
    </author>
    <author>
      <name>Ziwei Zhu</name>
    </author>
    <author>
      <name>Jianling Wang</name>
    </author>
    <author>
      <name>James Caverlee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:2208.03298</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.03854v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.03854v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.04223v1</id>
    <updated>2022-08-04T13:33:23Z</updated>
    <published>2022-08-04T13:33:23Z</published>
    <title>Beer2Vec : Extracting Flavors from Reviews for Thirst-Quenching
  Recommandations</title>
    <summary>  This paper introduces the Beer2Vec model that allows the most popular
alcoholic beverage in the world to be encoded into vectors enabling flavorful
recommendations. We present our algorithm using a unique dataset focused on the
analysis of craft beers. We thoroughly explain how we encode the flavors and
how useful, from an empirical point of view, the beer vectors are to generate
meaningful recommendations. We also present three different ways to use
Beer2Vec in a real-world environment to enlighten the pool of craft beer
consumers. Finally, we make our model and functionalities available to
everybody through a web application.
</summary>
    <author>
      <name>Jean-Thomas Baillargeon</name>
    </author>
    <author>
      <name>Nicolas Garneau</name>
    </author>
    <link href="http://arxiv.org/abs/2208.04223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.04223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.04232v1</id>
    <updated>2022-08-08T16:00:55Z</updated>
    <published>2022-08-08T16:00:55Z</published>
    <title>Learning Diverse Document Representations with Deep Query Interactions
  for Dense Retrieval</title>
    <summary>  In this paper, we propose a new dense retrieval model which learns diverse
document representations with deep query interactions. Our model encodes each
document with a set of generated pseudo-queries to get query-informed,
multi-view document representations. It not only enjoys high inference
efficiency like the vanilla dual-encoder models, but also enables deep
query-document interactions in document encoding and provides multi-faceted
representations to better match different queries. Experiments on several
benchmarks demonstrate the effectiveness of the proposed method, out-performing
strong dual encoder baselines.The code is available at
\url{https://github.com/jordane95/dual-cross-encoder
</summary>
    <author>
      <name>Zehan Li</name>
    </author>
    <author>
      <name>Nan Yang</name>
    </author>
    <author>
      <name>Liang Wang</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <link href="http://arxiv.org/abs/2208.04232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.04232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.06264v1</id>
    <updated>2022-08-09T18:18:20Z</updated>
    <published>2022-08-09T18:18:20Z</published>
    <title>A Boring-yet-effective Approach for the Product Ranking Task of the
  Amazon KDD Cup 2022</title>
    <summary>  In this work we describe our submission to the product ranking task of the
Amazon KDD Cup 2022. We rely on a receipt that showed to be effective in
previous competitions: we focus our efforts towards efficiently training and
deploying large language odels, such as mT5, while reducing to a minimum the
number of task-specific adaptations. Despite the simplicity of our approach,
our best model was less than 0.004 nDCG@20 below the top submission. As the top
20 teams achieved an nDCG@20 close to .90, we argue that we need more difficult
e-Commerce evaluation datasets to discriminate retrieval methods.
</summary>
    <author>
      <name>Vitor Jeronymo</name>
    </author>
    <author>
      <name>Guilherme Rosa</name>
    </author>
    <author>
      <name>Surya Kallumadi</name>
    </author>
    <author>
      <name>Roberto Lotufo</name>
    </author>
    <author>
      <name>Rodrigo Nogueira</name>
    </author>
    <link href="http://arxiv.org/abs/2208.06264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.06264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.06955v1</id>
    <updated>2022-08-15T01:09:19Z</updated>
    <published>2022-08-15T01:09:19Z</published>
    <title>Continuous Active Learning Using Pretrained Transformers</title>
    <summary>  Pre-trained and fine-tuned transformer models like BERT and T5 have improved
the state of the art in ad-hoc retrieval and question-answering, but not as yet
in high-recall information retrieval, where the objective is to retrieve
substantially all relevant documents. We investigate whether the use of
transformer-based models for reranking and/or featurization can improve the
Baseline Model Implementation of the TREC Total Recall Track, which represents
the current state of the art for high-recall information retrieval. We also
introduce CALBERT, a model that can be used to continuously fine-tune a
BERT-based model based on relevance feedback.
</summary>
    <author>
      <name>Nima Sadri</name>
    </author>
    <author>
      <name>Gordon V. Cormack</name>
    </author>
    <link href="http://arxiv.org/abs/2208.06955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.06955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.08581v1</id>
    <updated>2022-08-18T00:58:50Z</updated>
    <published>2022-08-18T00:58:50Z</published>
    <title>Merchandise Recommendation for Retail Events with Word Embedding
  Weighted Tf-idf and Dynamic Query Expansion</title>
    <summary>  To recommend relevant merchandises for seasonal retail events, we rely on
item retrieval from marketplace inventory. With feedback to expand query scope,
we discuss keyword expansion candidate selection using word embedding
similarity, and an enhanced tf-idf formula for expanded words in search
ranking.
</summary>
    <author>
      <name>Ted Tao Yuan</name>
    </author>
    <author>
      <name>Zezhong Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3209978.3210202</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3209978.3210202" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The work is oral presented on the SIGIR Symposium on IR in Practice
  (SIRIP) 2018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 41st International ACM SIGIR Conference on
  Research &amp; Development in Information Retrieval (SIGIR '18), July 8--12,
  2018, Ann Arbor, MI, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2208.08581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.08581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.10751v1</id>
    <updated>2022-08-23T06:10:06Z</updated>
    <published>2022-08-23T06:10:06Z</published>
    <title>Predicting Query-Item Relationship using Adversarial Training and Robust
  Modeling Techniques</title>
    <summary>  We present an effective way to predict search query-item relationship. We
combine pre-trained transformer and LSTM models, and increase model robustness
using adversarial training, exponential moving average, multi-sampled dropout,
and diversity based ensemble, to tackle an extremely difficult problem of
predicting against queries not seen before. All of our strategies focus on
increasing robustness of deep learning models and are applicable in any task
where deep learning models are used. Applying our strategies, we achieved 10th
place in KDD Cup 2022 Product Substitution Classification task.
</summary>
    <author>
      <name>Min Seok Kim</name>
    </author>
    <link href="http://arxiv.org/abs/2208.10751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.10751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.12356v2</id>
    <updated>2023-08-11T16:15:52Z</updated>
    <published>2022-08-25T22:10:18Z</published>
    <title>Lib-SibGMU -- A University Library Circulation Dataset for Recommender
  Systems Developmen</title>
    <summary>  We opensource under CC BY 4.0 license Lib-SibGMU - a university library
circulation dataset - for a wide research community, and benchmark major
algorithms for recommender systems on this dataset. For a recommender
architecture that consists of a vectorizer that turns the history of the books
borrowed into a vector, and a neighborhood-based recommender, trained
separately, we show that using the fastText model as a vectorizer delivers
competitive results.
</summary>
    <author>
      <name>Eduard Zubchuk</name>
    </author>
    <author>
      <name>Mikhail Arhipkin</name>
    </author>
    <author>
      <name>Dmitry Menshikov</name>
    </author>
    <author>
      <name>Aleksandr Karaush</name>
    </author>
    <author>
      <name>Nikolay Mikhaylovskiy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Dataset copyright discussion</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.12356v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.12356v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.14980v1</id>
    <updated>2022-08-31T17:32:04Z</updated>
    <published>2022-08-31T17:32:04Z</published>
    <title>Inverse Propensity Score based offline estimator for deterministic
  ranking lists using position bias</title>
    <summary>  In this work, we present a novel way of computing IPS using a position-bias
model for deterministic logging policies. This technique significantly widens
the policies on which OPE can be used. We validate this technique using two
different experiments on industry-scale data. The OPE results are clearly
strongly correlated with the online results, with some constant bias. The
estimator requires the examination model to be a reasonably accurate
approximation of real user behaviour.
</summary>
    <author>
      <name>Nick Wood</name>
    </author>
    <author>
      <name>Sumit Sidana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 2 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2208.14980v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2208.14980v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.07333v1</id>
    <updated>2022-09-11T17:24:37Z</updated>
    <published>2022-09-11T17:24:37Z</published>
    <title>Public Reaction to Scientific Research via Twitter Sentiment Prediction</title>
    <summary>  Social media users share their ideas, thoughts, and emotions with other
users. However, it is not clear how online users would respond to new research
outcomes. This study aims to predict the nature of the emotions expressed by
Twitter users toward scientific publications. Additionally, we investigate what
features of the research articles help in such prediction. Identifying the
sentiments of research articles on social media will help scientists gauge a
new societal impact of their research articles.
</summary>
    <author>
      <name>Murtuza Shahzad</name>
    </author>
    <author>
      <name>Hamed Alhoori</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2478/jdis-2022-0003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2478/jdis-2022-0003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Data and Information Sciences</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Data and Information Science (2022), Volume 7, Issue 1,
  97-124</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2209.07333v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.07333v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.12766v1</id>
    <updated>2022-09-26T15:16:18Z</updated>
    <published>2022-09-26T15:16:18Z</published>
    <title>EasyRec: An easy-to-use, extendable and efficient framework for building
  industrial recommendation systems</title>
    <summary>  We present EasyRec, an easy-to-use, extendable and efficient recommendation
framework for building industrial recommendation systems. Our EasyRec framework
is superior in the following aspects: first, EasyRec adopts a modular and
pluggable design pattern to reduce the efforts to build custom models; second,
EasyRec implements hyper-parameter optimization and feature selection
algorithms to improve model performance automatically; third, EasyRec applies
online learning to fast adapt to the ever-changing data distribution. The code
is released: https://github.com/alibaba/EasyRec.
</summary>
    <author>
      <name>Mengli Cheng</name>
    </author>
    <author>
      <name>Yue Gao</name>
    </author>
    <author>
      <name>Guoqiang Liu</name>
    </author>
    <author>
      <name>HongSheng Jin</name>
    </author>
    <author>
      <name>Xiaowen Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.12766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.12766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.13011v1</id>
    <updated>2022-09-16T13:11:27Z</updated>
    <published>2022-09-16T13:11:27Z</published>
    <title>The effectiveness of factorization and similarity blending</title>
    <summary>  Collaborative Filtering (CF) is a widely used technique which allows to
leverage past users' preferences data to identify behavioural patterns and
exploit them to predict custom recommendations. In this work, we illustrate our
review of different CF techniques in the context of the Computational
Intelligence Lab (CIL) CF project at ETH Z\"urich. After evaluating the
performances of the individual models, we show that blending
factorization-based and similarity-based approaches can lead to a significant
error decrease (-9.4%) on the best-performing stand-alone model. Moreover, we
propose a novel stochastic extension of a similarity model, SCSR, which
consistently reduce the asymptotic complexity of the original algorithm.
</summary>
    <author>
      <name>Andrea Pinto</name>
    </author>
    <author>
      <name>Giacomo Camposampiero</name>
    </author>
    <author>
      <name>Loïc Houmard</name>
    </author>
    <author>
      <name>Marc Lundwall</name>
    </author>
    <link href="http://arxiv.org/abs/2209.13011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.13011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.13021v1</id>
    <updated>2022-09-13T20:38:39Z</updated>
    <published>2022-09-13T20:38:39Z</published>
    <title>Inclusive Ethical Design for Recommender Systems</title>
    <summary>  Recommender systems are becoming increasingly central as mediators of
information with the potential to profoundly influence societal opinion. While
approaches are being developed to ensure these systems are designed in a
responsible way, adolescents in particular, represent a potentially vulnerable
user group requiring explicit consideration. This is especially important given
the nature of their access and use of recommender systems but also their role
as providers of content. This paper proposes core principles for the ethical
design of recommender systems and evaluates whether current approaches to
ensuring adherence to these principles are sufficiently inclusive of the
particular needs and potential vulnerabilities of adolescent users.
</summary>
    <author>
      <name>Susan Leavy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2209.13021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2209.13021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.02640v1</id>
    <updated>2022-10-06T02:14:23Z</updated>
    <published>2022-10-06T02:14:23Z</published>
    <title>ForestQB: An Adaptive Query Builder to Support Wildlife Research</title>
    <summary>  This paper presents ForestQB, a SPARQL query builder, to assist Bioscience
and Wildlife Researchers in accessing Linked-Data. As they are unfamiliar with
the Semantic Web and the data ontologies, ForestQB aims to empower them to
benefit from using Linked-Data to extract valuable information without having
to grasp the nature of the data and its underlying technologies. ForestQB is
integrating Form-Based Query builders with Natural Language to simplify query
construction to match the user requirements. Demo available at
https://iotgarage.net/demo/forestQB
</summary>
    <author>
      <name>Omar Mussa</name>
    </author>
    <author>
      <name>Omer Rana</name>
    </author>
    <author>
      <name>Benoît Goossens</name>
    </author>
    <author>
      <name>Pablo Orozco-terWengel</name>
    </author>
    <author>
      <name>Charith Perera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 12th International Semantic Web Conference
  (Posters &amp; Demonstrations Track), 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.02640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.02640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.02864v1</id>
    <updated>2022-10-06T12:31:08Z</updated>
    <published>2022-10-06T12:31:08Z</published>
    <title>DBkWik++ -- Multi Source Matching of Knowledge Graphs</title>
    <summary>  Large knowledge graphs like DBpedia and YAGO are always based on the same
source, i.e., Wikipedia. But there are more wikis that contain information
about long-tail entities such as wiki hosting platforms like Fandom. In this
paper, we present the approach and analysis of DBkWik++, a fused Knowledge
Graph from thousands of wikis. A modified version of the DBpedia framework is
applied to each wiki which results in many isolated Knowledge Graphs. With an
incremental merge based approach, we reuse one-to-one matching systems to solve
the multi source KG matching task. Based on this alignment we create a
consolidated knowledge graph with more than 15 million instances.
</summary>
    <author>
      <name>Sven Hertling</name>
    </author>
    <author>
      <name>Heiko Paulheim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at KGSWC 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2210.02864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.02864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.04716v1</id>
    <updated>2022-10-10T14:17:03Z</updated>
    <published>2022-10-10T14:17:03Z</published>
    <title>A two-stage approach for table extraction in invoices</title>
    <summary>  The automated analysis of administrative documents is an important field in
document recognition that is studied for decades. Invoices are key documents
among these huge amounts of documents available in companies and public
services. Invoices contain most of the time data that are presented in tables
that should be clearly identified to extract suitable information. In this
paper, we propose an approach that combines an image processing based
estimation of the shape of the tables with a graph-based representation of the
document, which is used to identify complex tables precisely. We propose an
experimental evaluation using a real case application.
</summary>
    <author>
      <name>Thomas Saout</name>
    </author>
    <author>
      <name>Frédéric Lardeux</name>
    </author>
    <author>
      <name>Frédéric Saubion</name>
    </author>
    <link href="http://arxiv.org/abs/2210.04716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.04716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.05145v1</id>
    <updated>2022-10-11T04:54:19Z</updated>
    <published>2022-10-11T04:54:19Z</published>
    <title>Retrieval Augmentation for T5 Re-ranker using External Sources</title>
    <summary>  Retrieval augmentation has shown promising improvements in different tasks.
However, whether such augmentation can assist a large language model based
re-ranker remains unclear. We investigate how to augment T5-based re-rankers
using high-quality information retrieved from two external corpora -- a
commercial web search engine and Wikipedia. We empirically demonstrate how
retrieval augmentation can substantially improve the effectiveness of T5-based
re-rankers for both in-domain and zero-shot out-of-domain re-ranking tasks.
</summary>
    <author>
      <name>Kai Hui</name>
    </author>
    <author>
      <name>Tao Chen</name>
    </author>
    <author>
      <name>Zhen Qin</name>
    </author>
    <author>
      <name>Honglei Zhuang</name>
    </author>
    <author>
      <name>Fernando Diaz</name>
    </author>
    <author>
      <name>Mike Bendersky</name>
    </author>
    <author>
      <name>Don Metzler</name>
    </author>
    <link href="http://arxiv.org/abs/2210.05145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.05145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.10631v2</id>
    <updated>2022-12-17T16:24:33Z</updated>
    <published>2022-10-12T21:53:15Z</published>
    <title>Simulated Contextual Bandits for Personalization Tasks from
  Recommendation Datasets</title>
    <summary>  We propose a method for generating simulated contextual bandit environments
for personalization tasks from recommendation datasets like MovieLens, Netflix,
Last.fm, Million Song, etc. This allows for personalization environments to be
developed based on real-life data to reflect the nuanced nature of real-world
user interactions. The obtained environments can be used to develop methods for
solving personalization tasks, algorithm benchmarking, model simulation, and
more. We demonstrate our approach with numerical examples on MovieLens and IMDb
datasets.
</summary>
    <author>
      <name>Anton Dereventsov</name>
    </author>
    <author>
      <name>Anton Bibin</name>
    </author>
    <link href="http://arxiv.org/abs/2210.10631v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.10631v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.12098v1</id>
    <updated>2022-10-21T16:44:59Z</updated>
    <published>2022-10-21T16:44:59Z</published>
    <title>Triplet Losses-based Matrix Factorization for Robust Recommendations</title>
    <summary>  Much like other learning-based models, recommender systems can be affected by
biases in the training data. While typical evaluation metrics (e.g. hit rate)
are not concerned with them, some categories of final users are heavily
affected by these biases. In this work, we propose using multiple triplet
losses terms to extract meaningful and robust representations of users and
items. We empirically evaluate the soundness of such representations through
several "bias-aware" evaluation metrics, as well as in terms of stability to
changes in the training set and agreement of the predictions variance w.r.t.
that of each user.
</summary>
    <author>
      <name>Flavio Giobergia</name>
    </author>
    <link href="http://arxiv.org/abs/2210.12098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.12098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.12648v2</id>
    <updated>2022-12-29T08:38:28Z</updated>
    <published>2022-10-23T08:09:12Z</published>
    <title>Clarinet: A Music Retrieval System</title>
    <summary>  A MIDI based approach for music recognition is proposed and implemented in
this paper. Our Clarinet music retrieval system is designed to search piano
MIDI files with high recall and speed. We design a novel melody extraction
algorithm that improves recall results by more than 10%. We also implement 3
algorithms for retrieval-two self designed (RSA Note and RSA Time), and a
modified version of the Mongeau Sankoff Algorithm. Algorithms to achieve tempo
and scale invariance are also discussed in this paper. The paper also contains
detailed experimentation and benchmarks with four different metrics. Clarinet
achieves recall scores of more than 94%.
</summary>
    <author>
      <name>Kshitij Alwadhi</name>
    </author>
    <author>
      <name>Rohan Sharma</name>
    </author>
    <author>
      <name>Siddhant Sharma</name>
    </author>
    <link href="http://arxiv.org/abs/2210.12648v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.12648v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.15112v1</id>
    <updated>2022-10-27T01:45:59Z</updated>
    <published>2022-10-27T01:45:59Z</published>
    <title>Deep Latent Mixture Model for Recommendation</title>
    <summary>  Recent advances in neural networks have been successfully applied to many
tasks in online recommendation applications. We propose a new framework called
cone latent mixture model which makes use of hand-crafted state being able to
factor distinct dependencies among multiple related documents. Specifically, it
uses discriminative optimization techniques in order to generate effective
multi-level knowledge bases, and uses online discriminative learning techniques
in order to leverage these features. And for this joint model which uses
confidence estimates for each topic and is able to learn a discriminatively
trained jointly to automatically extracted salient features where
discriminative training is only uses features and then is able to accurately
trained.
</summary>
    <author>
      <name>Jun Zhang</name>
    </author>
    <author>
      <name>Ping Li</name>
    </author>
    <author>
      <name>Wei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2210.15112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2210.15112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.01332v1</id>
    <updated>2022-10-23T06:19:51Z</updated>
    <published>2022-10-23T06:19:51Z</published>
    <title>A Health Focused Text Classification Tool (HFTCT)</title>
    <summary>  Due to the high number of users on social media and the massive amounts of
queries requested every second to share a new video, picture, or message,
social platforms struggle to manage this humungous amount of data that is
endlessly coming in. HFTCT relies on wordlists to classify opinions. It can
carry out its tasks reasonably well; however, sometimes, the wordlists
themselves fail to be reliable as they are a limited source of positive and
negative words.
</summary>
    <author>
      <name>Baadr Suleman M Alwheepy</name>
    </author>
    <author>
      <name>Leandros Maglaras</name>
    </author>
    <author>
      <name>Nick Ayres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2211.01332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.01332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.02405v1</id>
    <updated>2022-11-04T12:26:25Z</updated>
    <published>2022-11-04T12:26:25Z</published>
    <title>Explainable Information Retrieval: A Survey</title>
    <summary>  Explainable information retrieval is an emerging research area aiming to make
transparent and trustworthy information retrieval systems. Given the increasing
use of complex machine learning models in search systems, explainability is
essential in building and auditing responsible information retrieval models.
This survey fills a vital gap in the otherwise topically diverse literature of
explainable information retrieval. It categorizes and discusses recent
explainability methods developed for different application domains in
information retrieval, providing a common framework and unifying perspectives.
In addition, it reflects on the common concern of evaluating explanations and
highlights open challenges and opportunities.
</summary>
    <author>
      <name>Avishek Anand</name>
    </author>
    <author>
      <name>Lijun Lyu</name>
    </author>
    <author>
      <name>Maximilian Idahl</name>
    </author>
    <author>
      <name>Yumeng Wang</name>
    </author>
    <author>
      <name>Jonas Wallat</name>
    </author>
    <author>
      <name>Zijian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 10 figures. Under review</arxiv:comment>
    <link href="http://arxiv.org/abs/2211.02405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.02405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.07610v1</id>
    <updated>2022-11-14T18:31:41Z</updated>
    <published>2022-11-14T18:31:41Z</published>
    <title>Pied Piper: Meta Search for Music</title>
    <summary>  Internet search engines have become an integral part of life, but for pop
music, people still rely on textual search engines like Google. We propose Pied
piper, a meta search engine for music. It can search for music lyrics, song
metadata and song audio or a combination of any of these as the input query and
efficiently return the relevant results.
</summary>
    <author>
      <name>Pulak Malhotra</name>
    </author>
    <author>
      <name>Ashwin Rao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures. To be published in conference proceedings of
  International Conference on Innovations in Computational Intelligence and
  Computer Vision (ICICV) 2022</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Innovations in Computational
  Intelligence and Computer Vision (ICICV) 2022</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2211.07610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.07610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.11535v1</id>
    <updated>2022-11-07T09:19:45Z</updated>
    <published>2022-11-07T09:19:45Z</published>
    <title>Preliminary Bias Results in Search Engines</title>
    <summary>  This report aims to report my thesis progress so far. My work attempts to
show the differences in the perspectives of two search engines, Bing and Google
on several selected controversial topics. In this work, we try to make a
distinction on the viewpoints of Bing \&amp; Google by using sentiment as well as
the ranking of the document returned from these two search engines on the same
queries, these queries are related mainly to controversial topics. You can find
the methods we used with experimental results below.
</summary>
    <author>
      <name>Gizem Gezici</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2112.12802</arxiv:comment>
    <link href="http://arxiv.org/abs/2211.11535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.11535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.11548v2</id>
    <updated>2024-10-06T23:54:24Z</updated>
    <published>2022-09-17T05:34:32Z</published>
    <title>Survey of Query-based Text Summarization</title>
    <summary>  Query-based text summarization is an important real world problem that
requires to condense the prolix text data into a summary under the guidance of
the query information provided by users. The topic has been studied for a long
time and there are many existing interesting research related to query-based
text summarization. Yet much of the work is not systematically surveyed. This
survey aims at summarizing some interesting work in query-based text
summarization methods as well as related generic text summarization methods.
Not all taxonomies in this paper exist the related work to the best of our
knowledge and some analysis will be presented.
</summary>
    <author>
      <name>Hang Yu</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <link href="http://arxiv.org/abs/2211.11548v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2211.11548v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.07126v1</id>
    <updated>2022-12-14T09:25:49Z</updated>
    <published>2022-12-14T09:25:49Z</published>
    <title>Explainability of Text Processing and Retrieval Methods: A Critical
  Survey</title>
    <summary>  Deep Learning and Machine Learning based models have become extremely popular
in text processing and information retrieval. However, the non-linear
structures present inside the networks make these models largely inscrutable. A
significant body of research has focused on increasing the transparency of
these models. This article provides a broad overview of research on the
explainability and interpretability of natural language processing and
information retrieval methods. More specifically, we survey approaches that
have been applied to explain word embeddings, sequence modeling, attention
modules, transformers, BERT, and document ranking. The concluding section
suggests some possible directions for future research on this topic.
</summary>
    <author>
      <name>Sourav Saha</name>
    </author>
    <author>
      <name>Debapriyo Majumdar</name>
    </author>
    <author>
      <name>Mandar Mitra</name>
    </author>
    <link href="http://arxiv.org/abs/2212.07126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.07126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.10460v1</id>
    <updated>2022-12-06T01:20:26Z</updated>
    <published>2022-12-06T01:20:26Z</published>
    <title>PoissonMat: Remodeling Matrix Factorization using Poisson Distribution
  and Solving the Cold Start Problem without Input Data</title>
    <summary>  Matrix Factorization is one of the most successful recommender system
techniques over the past decade. However, the classic probabilistic theory
framework for matrix factorization is modeled using normal distributions. To
find better probabilistic models, algorithms such as RankMat, ZeroMat and
DotMat have been invented in recent years. In this paper, we model the user
rating behavior in recommender system as a Poisson process, and design an
algorithm that relies on no input data to solve the recommendation problem and
the cold start issue at the same time. We prove the superiority of our
algorithm in comparison with matrix factorization, random placement, Zipf
placement, ZeroMat, DotMat, etc.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MLISE57402.2022.00055</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MLISE57402.2022.00055" rel="related"/>
    <link href="http://arxiv.org/abs/2212.10460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.10460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.13892v1</id>
    <updated>2022-12-22T03:04:14Z</updated>
    <published>2022-12-22T03:04:14Z</published>
    <title>Cross-Dataset Propensity Estimation for Debiasing Recommender Systems</title>
    <summary>  Datasets for training recommender systems are often subject to distribution
shift induced by users' and recommenders' selection biases. In this paper, we
study the impact of selection bias on datasets with different quantization. We
then leverage two differently quantized datasets from different source
distributions to mitigate distribution shift by applying the inverse
probability scoring method from causal inference. Empirically, our approach
gains significant performance improvement over single-dataset methods and
alternative ways of combining two datasets.
</summary>
    <author>
      <name>Fengyu Li</name>
    </author>
    <author>
      <name>Sarah Dean</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Workshop on Distribution Shifts, 36th Conference on Neural
  Information Processing Systems (NeurIPS 2022)</arxiv:comment>
    <link href="http://arxiv.org/abs/2212.13892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.13892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.13910v1</id>
    <updated>2022-12-13T12:51:27Z</updated>
    <published>2022-12-13T12:51:27Z</published>
    <title>Recommender Systems in E-commerce</title>
    <summary>  E-commerce recommender systems are becoming increasingly important in the
current digital world. They are used to personalize user experience, help
customers find what they need quickly and efficiently, and increase revenue for
the business. However, there are several challenges associated with big
data-based e-commerce recommender systems. These challenges include limited
resources, data validity period, cold start, long tail problem, scalability. In
this paper, we discuss the challenges and potential solutions to overcome these
challenges. We also discuss the different types of e-commerce recommender
systems, their advantages, and disadvantages. We conclude with some future
research directions to improve the performance of e-commerce recommender
systems.
</summary>
    <author>
      <name>Tanmayee Salunke</name>
    </author>
    <author>
      <name>Unnati Nichite</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.10194.43202</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.10194.43202" rel="related"/>
    <link href="http://arxiv.org/abs/2212.13910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.13910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.13916v1</id>
    <updated>2022-12-23T18:16:09Z</updated>
    <published>2022-12-23T18:16:09Z</published>
    <title>Cross-Domain Consumer Review Analysis</title>
    <summary>  The paper presents a cross-domain review analysis on four popular review
datasets: Amazon, Yelp, Steam, IMDb. The analysis is performed using Hadoop and
Spark, which allows for efficient and scalable processing of large datasets. By
examining close to 12 million reviews from these four online forums, we hope to
uncover interesting trends in sales and customer sentiment over the years. Our
analysis will include a study of the number of reviews and their distribution
over time, as well as an examination of the relationship between various review
attributes such as upvotes, creation time, rating, and sentiment. By comparing
the reviews across different domains, we hope to gain insight into the factors
that drive customer satisfaction and engagement in different product
categories.
</summary>
    <author>
      <name>Aditya Pandey</name>
    </author>
    <author>
      <name>Kunal Joshi</name>
    </author>
    <link href="http://arxiv.org/abs/2212.13916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.13916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2212.13923v1</id>
    <updated>2022-12-26T08:32:41Z</updated>
    <published>2022-12-26T08:32:41Z</published>
    <title>Do not Waste Money on Advertising Spend: Bid Recommendation via
  Concavity Changes</title>
    <summary>  In computational advertising, a challenging problem is how to recommend the
bid for advertisers to achieve the best return on investment (ROI) given budget
constraint. This paper presents a bid recommendation scenario that discovers
the concavity changes in click prediction curves. The recommended bid is
derived based on the turning point from significant increase (i.e. concave
downward) to slow increase (convex upward). Parametric learning based method is
applied by solving the corresponding constraint optimization problem. Empirical
studies on real-world advertising scenarios clearly demonstrate the performance
gains for business metrics (including revenue increase, click increase and
advertiser ROI increase).
</summary>
    <author>
      <name>Deguang Kong</name>
    </author>
    <author>
      <name>Konstantin Shmakov</name>
    </author>
    <author>
      <name>Jian Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2212.13923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2212.13923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.05544v3</id>
    <updated>2023-01-24T10:39:05Z</updated>
    <published>2023-01-13T13:41:20Z</published>
    <title>UserSimCRS: A User Simulation Toolkit for Evaluating Conversational
  Recommender Systems</title>
    <summary>  We present an extensible user simulation toolkit to facilitate automatic
evaluation of conversational recommender systems. It builds on an established
agenda-based approach and extends it with several novel elements, including
user satisfaction prediction, persona and context modeling, and conditional
natural language generation. We showcase the toolkit with a pre-existing movie
recommender system and demonstrate its ability to simulate dialogues that mimic
real conversations, while requiring only a handful of manually annotated
dialogues as training data.
</summary>
    <author>
      <name>Jafar Afzali</name>
    </author>
    <author>
      <name>Aleksander Mark Drzewiecki</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <author>
      <name>Shuo Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539597.3573029</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539597.3573029" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Sixteenth ACM International Conference on Web
  Search and Data Mining</arxiv:comment>
    <link href="http://arxiv.org/abs/2301.05544v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.05544v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.08801v1</id>
    <updated>2023-01-20T21:00:39Z</updated>
    <published>2023-01-20T21:00:39Z</published>
    <title>Information Retrieval: Recent Advances and Beyond</title>
    <summary>  In this paper, we provide a detailed overview of the models used for
information retrieval in the first and second stages of the typical processing
chain. We discuss the current state-of-the-art models, including methods based
on terms, semantic retrieval, and neural. Additionally, we delve into the key
topics related to the learning process of these models. This way, this survey
offers a comprehensive understanding of the field and is of interest for for
researchers and practitioners entering/working in the information retrieval
domain.
</summary>
    <author>
      <name>Kailash A. Hambarde</name>
    </author>
    <author>
      <name>Hugo Proenca</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACCESS.2023.3295776</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACCESS.2023.3295776" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Access 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2301.08801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2301.08801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.03497v2</id>
    <updated>2024-02-08T08:59:34Z</updated>
    <published>2023-02-02T02:59:00Z</published>
    <title>MMRec: Simplifying Multimodal Recommendation</title>
    <summary>  This paper presents an open-source toolbox, MMRec for multimodal
recommendation. MMRec simplifies and canonicalizes the process of implementing
and comparing multimodal recommendation models. The objective of MMRec is to
provide a unified and configurable arena that can minimize the effort in
implementing and testing multimodal recommendation models. It enables
multimodal models, ranging from traditional matrix factorization to modern
graph-based algorithms, capable of fusing information from multiple modalities
simultaneously. Our documentation, examples, and source code are available at
\url{https://github.com/enoche/MMRec}.
</summary>
    <author>
      <name>Xin Zhou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3611380.3628561</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3611380.3628561" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at MMAsia'23 Workshops</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.03497v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.03497v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.04983v1</id>
    <updated>2023-02-10T00:01:00Z</updated>
    <published>2023-02-10T00:01:00Z</published>
    <title>CREDENCE: Counterfactual Explanations for Document Ranking</title>
    <summary>  Towards better explainability in the field of information retrieval, we
present CREDENCE, an interactive tool capable of generating counterfactual
explanations for document rankers. Embracing the unique properties of the
ranking problem, we present counterfactual explanations in terms of document
perturbations, query perturbations, and even other documents. Additionally,
users may build and test their own perturbations, and extract insights about
their query, documents, and ranker.
</summary>
    <author>
      <name>Joel Rorseth</name>
    </author>
    <author>
      <name>Parke Godfrey</name>
    </author>
    <author>
      <name>Lukasz Golab</name>
    </author>
    <author>
      <name>Mehdi Kargar</name>
    </author>
    <author>
      <name>Divesh Srivastava</name>
    </author>
    <author>
      <name>Jaroslaw Szlichta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICDE55515.2023.00285</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICDE55515.2023.00285" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ICDE 2023 (Demonstration Track)</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.04983v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.04983v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.12139v1</id>
    <updated>2023-02-23T16:26:11Z</updated>
    <published>2023-02-23T16:26:11Z</published>
    <title>Automated Extraction of Fine-Grained Standardized Product Information
  from Unstructured Multilingual Web Data</title>
    <summary>  Extracting structured information from unstructured data is one of the key
challenges in modern information retrieval applications, including e-commerce.
Here, we demonstrate how recent advances in machine learning, combined with a
recently published multilingual data set with standardized fine-grained product
category information, enable robust product attribute extraction in challenging
transfer learning settings. Our models can reliably predict product attributes
across online shops, languages, or both. Furthermore, we show that our models
can be used to match product taxonomies between online retailers.
</summary>
    <author>
      <name>Alexander Flick</name>
    </author>
    <author>
      <name>Sebastian Jäger</name>
    </author>
    <author>
      <name>Ivana Trajanovska</name>
    </author>
    <author>
      <name>Felix Biessmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECIR 2023 Demo Track</arxiv:comment>
    <link href="http://arxiv.org/abs/2302.12139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.12139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2302.12574v1</id>
    <updated>2023-02-24T10:58:31Z</updated>
    <published>2023-02-24T10:58:31Z</published>
    <title>Naver Labs Europe (SPLADE) @ TREC Deep Learning 2022</title>
    <summary>  This paper describes our participation to the 2022 TREC Deep Learning
challenge. We submitted runs to all four tasks, with a focus on the full
retrieval passage task. The strategy is almost the same as 2021, with first
stage retrieval being based around SPLADE, with some added ensembling with
ColBERTv2 and DocT5. We also use the same strategy of last year for the second
stage, with an ensemble of re-rankers trained using hard negatives selected by
SPLADE. Initial result analysis show that the strategy is still strong, but is
still unclear to us what next steps should we take.
</summary>
    <author>
      <name>Carlos Lassance</name>
    </author>
    <author>
      <name>Stéphane Clinchant</name>
    </author>
    <link href="http://arxiv.org/abs/2302.12574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2302.12574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.04532v1</id>
    <updated>2023-03-08T12:04:16Z</updated>
    <published>2023-03-08T12:04:16Z</published>
    <title>Class Cardinality Comparison as a Fermi Problem</title>
    <summary>  Questions on class cardinality comparisons are quite tricky to answer and
come with its own challenges. They require some kind of reasoning since web
documents and knowledge bases, indispensable sources of information, rarely
store direct answers to questions, such as, ``Are there more astronauts or
Physics Nobel Laureates?'' We tackle questions on class cardinality comparison
by tapping into three sources for absolute cardinalities as well as the
cardinalities of orthogonal subgroups of the classes. We propose novel
techniques for aggregating signals with partial coverage for more reliable
estimates and evaluate them on a dataset of 4005 class pairs, achieving an
accuracy of 83.7%.
</summary>
    <author>
      <name>Shrestha Ghosh</name>
    </author>
    <author>
      <name>Simon Razniewski</name>
    </author>
    <author>
      <name>Gerhard Weikum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the Web Conference 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.04532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.04532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.04561v1</id>
    <updated>2023-03-08T13:20:53Z</updated>
    <published>2023-03-08T13:20:53Z</published>
    <title>Kernel-CF: Collaborative filtering done right with social network
  analysis and kernel smoothing</title>
    <summary>  Collaborative filtering is the simplest but oldest machine learning algorithm
in the field of recommender systems. In spite of its long history, it remains a
discussion topic in research venues. Usually people use users/items whose
similarity scores with the target customer greater than 0 to compute the
algorithms. However, this might not be the optimal solution after careful
scrutiny. In this paper, we transform the recommender system input data into a
2-D social network, and apply kernel smoothing to compute preferences for
unknown values in the user item rating matrix. We unifies the theoretical
framework of recommender system and non-parametric statistics and provides an
algorithmic procedure with optimal parameter selection method to achieve the
goal.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2303.04561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.04561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.04710v1</id>
    <updated>2023-02-28T13:47:55Z</updated>
    <published>2023-02-28T13:47:55Z</published>
    <title>Towards Better Web Search Performance: Pre-training, Fine-tuning and
  Learning to Rank</title>
    <summary>  This paper describes the approach of the THUIR team at the WSDM Cup 2023
Pre-training for Web Search task. This task requires the participant to rank
the relevant documents for each query. We propose a new data pre-processing
method and conduct pre-training and fine-tuning with the processed data.
Moreover, we extract statistical, axiomatic, and semantic features to enhance
the ranking performance. After the feature extraction, diverse learning-to-rank
models are employed to merge those features. The experimental results show the
superiority of our proposal. We finally achieve second place in this
competition.
</summary>
    <author>
      <name>Haitao Li</name>
    </author>
    <author>
      <name>Jia Chen</name>
    </author>
    <author>
      <name>Weihang Su</name>
    </author>
    <author>
      <name>Qingyao Ai</name>
    </author>
    <author>
      <name>Yiqun Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, WSDM Cup 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2303.04710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.04710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.10230v1</id>
    <updated>2023-03-17T20:08:59Z</updated>
    <published>2023-03-17T20:08:59Z</published>
    <title>ITM-Rec: An Open Data Set for Educational Recommender Systems</title>
    <summary>  With the development of recommender systems (RS), several promising systems
have emerged, such as context-aware RS, multi-criteria RS, and group RS.
However, the education domain may not benefit from these developments due to
missing information, such as contexts and multiple criteria, in educational
data sets. In this paper, we announce and release an open data set for
educational recommender systems. This data set includes not only traditional
rating entries, but also enriched information, e.g., contexts, user preferences
in multiple criteria, group compositions and preferences, etc. It provides a
testbed and enables more opportunities to develop and examine various
educational recommender systems.
</summary>
    <author>
      <name>Yong Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2303.10230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.10230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2303.14419v1</id>
    <updated>2023-03-25T10:07:59Z</updated>
    <published>2023-03-25T10:07:59Z</published>
    <title>Evolution of the Online Rating Platform Data Structures and its
  Implications for Recommender Systems</title>
    <summary>  Online rating platform represents the new trend of online cultural and
commercial goods consumption. The user rating data on such platforms are foods
for recommender system algorithms. Understanding the evolution pattern and its
underlying mechanism is the key to understand the structures of input data for
recommender systems. Prior research on input data analysis for recommender
systems is quite limited, with a notable exception in 2018 [6]. In this paper,
we take advantage of Poisson Process to analyze the evolution mechanism of the
input data structures. We discover that homogeneous Poisson Process could not
capture the mechanism of user rating behavior on online rating platforms, and
inhomogeneous Poisson Process is compatible with the formation process.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2303.14419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2303.14419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.01446v1</id>
    <updated>2023-04-04T01:43:58Z</updated>
    <published>2023-04-04T01:43:58Z</published>
    <title>Integrating Commercial and Social Determinants of Health: A Unified
  Ontology for Non-Clinical Determinants of Health</title>
    <summary>  The objectives of this research are 1) to develop an ontology for CDoH by
utilizing PubMed articles and ChatGPT; 2) to foster ontology reuse by
integrating CDoH with an existing SDoH ontology into a unified structure; 3) to
devise an overarching conception for all non-clinical determinants of health
and to create an initial ontology, called N-CODH, for them; 4) and to validate
the degree of correspondence between concepts provided by ChatGPT with the
existing SDoH ontology
</summary>
    <author>
      <name>Navya Martin Kollapally</name>
    </author>
    <author>
      <name>Vipina Kuttichi Keloth</name>
    </author>
    <author>
      <name>Julia Xu</name>
    </author>
    <author>
      <name>James Geller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review AMIA 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.01446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.01446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.08158v2</id>
    <updated>2023-07-03T08:52:37Z</updated>
    <published>2023-04-17T11:11:19Z</published>
    <title>Attention Mixtures for Time-Aware Sequential Recommendation</title>
    <summary>  Transformers emerged as powerful methods for sequential recommendation.
However, existing architectures often overlook the complex dependencies between
user preferences and the temporal context. In this short paper, we introduce
MOJITO, an improved Transformer sequential recommender system that addresses
this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal
context and item embedding representations for sequential modeling. Such an
approach permits to accurately predict which items should be recommended next
to users depending on past actions and the temporal context. We demonstrate the
relevance of our approach, by empirically outperforming existing Transformers
for sequential recommendation on several real-world datasets.
</summary>
    <author>
      <name>Viet-Anh Tran</name>
    </author>
    <author>
      <name>Guillaume Salha-Galvan</name>
    </author>
    <author>
      <name>Bruno Sguerra</name>
    </author>
    <author>
      <name>Romain Hennequin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.08158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.08158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.08188v1</id>
    <updated>2023-04-17T11:59:52Z</updated>
    <published>2023-04-17T11:59:52Z</published>
    <title>Statute-enhanced lexical retrieval of court cases for COLIEE 2022</title>
    <summary>  We discuss our experiments for COLIEE Task 1, a court case retrieval
competition using cases from the Federal Court of Canada. During experiments on
the training data we observe that passage level retrieval with rank fusion
outperforms document level retrieval. By explicitly adding extracted statute
information to the queries and documents we can further improve the results. We
submit two passage level runs to the competition, which achieve high recall but
low precision.
</summary>
    <author>
      <name>Tobias Fink</name>
    </author>
    <author>
      <name>Gabor Recski</name>
    </author>
    <author>
      <name>Wojciech Kusa</name>
    </author>
    <author>
      <name>Allan Hanbury</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Sixteenth International Workshop on Juris-informatics (JURISIN). 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.08188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.08188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.08253v2</id>
    <updated>2023-05-03T14:13:52Z</updated>
    <published>2023-04-17T13:14:24Z</published>
    <title>Do you MIND? Reflections on the MIND dataset for research on diversity
  in news recommendations</title>
    <summary>  The MIND dataset is at the moment of writing the most extensive dataset
available for the research and development of news recommender systems. This
work analyzes the suitability of the dataset for research on diverse news
recommendations. On the one hand we analyze the effect the different steps in
the recommendation pipeline have on the distribution of article categories, and
on the other hand we check whether the supplied data would be sufficient for
more sophisticated diversity analysis. We conclude that while MIND is a great
step forward, there is still a lot of room for improvement.
</summary>
    <author>
      <name>Sanne Vrijenhoek</name>
    </author>
    <link href="http://arxiv.org/abs/2304.08253v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.08253v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.11473v2</id>
    <updated>2023-06-11T17:35:02Z</updated>
    <published>2023-04-22T20:00:06Z</published>
    <title>(Vector) Space is Not the Final Frontier: Product Search as Program
  Synthesis</title>
    <summary>  As ecommerce continues growing, huge investments in ML and NLP for
Information Retrieval are following. While the vector space model dominated
retrieval modelling in product search - even as vectorization itself greatly
changed with the advent of deep learning -, our position paper argues in a
contrarian fashion that program synthesis provides significant advantages for
many queries and a significant number of players in the market. We detail the
industry significance of the proposed approach, sketch implementation details,
and address common objections drawing from our experience building a similar
system at Tooso.
</summary>
    <author>
      <name>Jacopo Tagliabue</name>
    </author>
    <author>
      <name>Ciro Greco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at SIGIR eCom 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.11473v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.11473v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.12650v1</id>
    <updated>2023-04-25T08:32:27Z</updated>
    <published>2023-04-25T08:32:27Z</published>
    <title>THUIR at WSDM Cup 2023 Task 1: Unbiased Learning to Rank</title>
    <summary>  This paper introduces the approaches we have used to participate in the WSDM
Cup 2023 Task 1: Unbiased Learning to Rank. In brief, we have attempted a
combination of both traditional IR models and transformer-based cross-encoder
architectures. To further enhance the ranking performance, we also considered a
series of features for learning to rank. As a result, we won 2nd place on the
final leaderboard.
</summary>
    <author>
      <name>Jia Chen</name>
    </author>
    <author>
      <name>Haitao Li</name>
    </author>
    <author>
      <name>Weihang Su</name>
    </author>
    <author>
      <name>Qingyao Ai</name>
    </author>
    <author>
      <name>Yiqun Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.12650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.12650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.13149v1</id>
    <updated>2023-04-25T20:52:40Z</updated>
    <published>2023-04-25T20:52:40Z</published>
    <title>Modeling Spoken Information Queries for Virtual Assistants: Open
  Problems, Challenges and Opportunities</title>
    <summary>  Virtual assistants are becoming increasingly important speech-driven
Information Retrieval platforms that assist users with various tasks.
  We discuss open problems and challenges with respect to modeling spoken
information queries for virtual assistants, and list opportunities where
Information Retrieval methods and research can be applied to improve the
quality of virtual assistant speech recognition.
  We discuss how query domain classification, knowledge graphs and user
interaction data, and query personalization can be helpful to improve the
accurate recognition of spoken information domain queries. Finally, we also
provide a brief overview of current problems and challenges in speech
recognition.
</summary>
    <author>
      <name>Christophe Van Gysel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539618.3591849</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539618.3591849" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR '23. The 46th International ACM SIGIR Conference on Research &amp;
  Development in Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.13149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.13149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.13290v1</id>
    <updated>2023-04-26T05:06:22Z</updated>
    <published>2023-04-26T05:06:22Z</published>
    <title>Improving Conversational Passage Re-ranking with View Ensemble</title>
    <summary>  This paper presents ConvRerank, a conversational passage re-ranker that
employs a newly developed pseudo-labeling approach. Our proposed view-ensemble
method enhances the quality of pseudo-labeled data, thus improving the
fine-tuning of ConvRerank. Our experimental evaluation on benchmark datasets
shows that combining ConvRerank with a conversational dense retriever in a
cascaded manner achieves a good balance between effectiveness and efficiency.
Compared to baseline methods, our cascaded pipeline demonstrates lower latency
and higher top-ranking effectiveness. Furthermore, the in-depth analysis
confirms the potential of our approach to improving the effectiveness of
conversational search.
</summary>
    <author>
      <name>Jia-Huei Ju</name>
    </author>
    <author>
      <name>Sheng-Chieh Lin</name>
    </author>
    <author>
      <name>Ming-Feng Tsai</name>
    </author>
    <author>
      <name>Chuan-Ju Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539618.3592002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539618.3592002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGIR 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2304.13290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.13290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2304.13579v1</id>
    <updated>2023-04-26T14:13:46Z</updated>
    <published>2023-04-26T14:13:46Z</published>
    <title>Improvements on Recommender System based on Mathematical Principles</title>
    <summary>  In this article, we will research the Recommender System's implementation
about how it works and the algorithms used. We will explain the Recommender
System's algorithms based on mathematical principles, and find feasible methods
for improvements. The algorithms based on probability have its significance in
Recommender System, we will describe how they help to increase the accuracy and
speed of the algorithms. Both the weakness and the strength of two different
mathematical distance used to describe the similarity will be detailed
illustrated in this article.
</summary>
    <author>
      <name>Fu Chen</name>
    </author>
    <author>
      <name>Junkang Zou</name>
    </author>
    <author>
      <name>Lingfeng Zhou</name>
    </author>
    <author>
      <name>Zekai Xu</name>
    </author>
    <author>
      <name>Zhenyu Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2304.13579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2304.13579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.04237v1</id>
    <updated>2023-05-07T10:01:42Z</updated>
    <published>2023-05-07T10:01:42Z</published>
    <title>Opening the TAR Black Box: Developing an Interpretable System for
  eDiscovery Using the Fuzzy ARTMAP Neural Network</title>
    <summary>  This foundational research provides additional support for using the Fuzzy
ARTMAP neural network as a classification algorithm in the TAR domain. While
research opportunities exist to improve recall performance and explanation, the
robust recall results from this study and the proof-of-concept demonstration of
If-Then rules for tf-idf vectorization strongly substantiate that a Fuzzy
ARTMAP-based TAR system is a potentially viable explainable alternative to
"black box" TAR systems.
</summary>
    <author>
      <name>Charles Courchaine</name>
    </author>
    <author>
      <name>Ricky J. Sethi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM ECIR 2023 in Legal Information Retrieval</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.04237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.04237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.04518v1</id>
    <updated>2023-05-08T07:28:16Z</updated>
    <published>2023-05-08T07:28:16Z</published>
    <title>Sparks of Artificial General Recommender (AGR): Early Experiments with
  ChatGPT</title>
    <summary>  This study investigates the feasibility of developing an Artificial General
Recommender (AGR), facilitated by recent advancements in Large Language Models
(LLMs). An AGR comprises both conversationality and universality to engage in
natural dialogues and generate recommendations across various domains. We
propose ten fundamental principles that an AGR should adhere to, each with its
corresponding testing protocols. We proceed to assess whether ChatGPT, a
sophisticated LLM, can comply with the proposed principles by engaging in
recommendation-oriented dialogues with the model while observing its behavior.
Our findings demonstrate the potential for ChatGPT to serve as an AGR, though
several limitations and areas for improvement are identified.
</summary>
    <author>
      <name>Guo Lin</name>
    </author>
    <author>
      <name>Yongfeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2305.04518v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.04518v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.04890v1</id>
    <updated>2023-05-03T16:06:49Z</updated>
    <published>2023-05-03T16:06:49Z</published>
    <title>Steam Recommendation System</title>
    <summary>  We aim to leverage the interactions between users and items in the Steam
community to build a game recommendation system that makes personalized
suggestions to players in order to boost Steam's revenue as well as improve the
users' gaming experience. The whole project is built on Apache Spark and deals
with Big Data. The final output of the project is a recommendation system that
gives a list of the top 5 items that the users will possibly like.6
</summary>
    <author>
      <name>Samin Batra</name>
    </author>
    <author>
      <name>Varun Sharma</name>
    </author>
    <author>
      <name>Yurou Sun</name>
    </author>
    <author>
      <name>Xinyao Wang</name>
    </author>
    <author>
      <name>Yinyu Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 7 figures, 8 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.04890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.04890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.06047v1</id>
    <updated>2023-05-10T10:57:26Z</updated>
    <published>2023-05-10T10:57:26Z</published>
    <title>Piloting topic-aware research impact assessment features in BIP!
  Services</title>
    <summary>  Various research activities rely on citation-based impact indicators. However
these indicators are usually globally computed, hindering their proper
interpretation in applications like research assessment and knowledge
discovery. In this work, we advocate for the use of topic-aware categorical
impact indicators, to alleviate the aforementioned problem. In addition, we
extend BIP! Services to support those indicators and showcase their benefits in
real-world research activities.
</summary>
    <author>
      <name>Serafeim Chatzopoulos</name>
    </author>
    <author>
      <name>Kleanthis Vichos</name>
    </author>
    <author>
      <name>Ilias Kanellos</name>
    </author>
    <author>
      <name>Thanasis Vergoulis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-43458-7_15</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-43458-7_15" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.06047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.06047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.07335v1</id>
    <updated>2023-05-12T09:27:04Z</updated>
    <published>2023-05-12T09:27:04Z</published>
    <title>Methods and Tools to Advance the Retrieval of Mathematical Knowledge
  from Digital Libraries for Search-, Recommendation-, and Assistance-Systems</title>
    <summary>  This project investigated new approaches and technologies to enhance the
accessibility of mathematical content and its semantic information for a broad
range of information retrieval applications. To achieve this goal, the project
addressed three main research challenges: (1) syntactic analysis of
mathematical expressions, (2) semantic enrichment of mathematical expressions,
and (3) evaluation using quality metrics and demonstrators. To make our
research useful for the research community, we published tools that enable
researchers to process mathematical expressions more effectively and
efficiently.
</summary>
    <author>
      <name>Bela Gipp</name>
    </author>
    <author>
      <name>André Greiner-Petter</name>
    </author>
    <author>
      <name>Moritz Schubotz</name>
    </author>
    <author>
      <name>Norman Meuschke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5281/zenodo.7924634</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5281/zenodo.7924634" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The final report for the DFG-Project MathIR - July 1st, 2018 -
  December 31st, 2022</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.07335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.07335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.07516v1</id>
    <updated>2023-05-12T14:31:09Z</updated>
    <published>2023-05-12T14:31:09Z</published>
    <title>Eye Tracking as a Source of Implicit Feedback in Recommender Systems: A
  Preliminary Analysis</title>
    <summary>  Eye tracking in recommender systems can provide an additional source of
implicit feedback, while helping to evaluate other sources of feedback. In this
study, we use eye tracking data to inform a collaborative filtering model for
movie recommendation providing an improvement over the click-based
implementations and additionally analyze the area of interest (AOI) duration as
related to the known information of click data and movies seen previously,
showing AOI information consistently coincides with these items of interest.
</summary>
    <author>
      <name>Santiago de Leon-Martinez</name>
    </author>
    <author>
      <name>Robert Moro</name>
    </author>
    <author>
      <name>Maria Bielikova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3588015.3589511</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3588015.3589511" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted to Eyes4ICU workshop at ETRA 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.07516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.07516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.10408v1</id>
    <updated>2023-05-07T00:16:30Z</updated>
    <published>2023-05-07T00:16:30Z</published>
    <title>Extracting Blockchain Concepts from Text</title>
    <summary>  Blockchains provide a mechanism through which mutually distrustful remote
parties can reach consensus on the state of a ledger of information. With the
great acceleration with which this space is developed, the demand for those
seeking to learn about blockchain also grows. Being a technical subject, it can
be quite intimidating to start learning. For this reason, the main objective of
this project was to apply machine learning models to extract information from
whitepapers and academic articles focused on the blockchain area to organize
this information and aid users to navigate the space.
</summary>
    <author>
      <name>Rodrigo Veiga</name>
    </author>
    <author>
      <name>Markus Endler</name>
    </author>
    <author>
      <name>Valeria de Paiva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2305.10408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.10408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2305.12190v1</id>
    <updated>2023-05-20T13:28:22Z</updated>
    <published>2023-05-20T13:28:22Z</published>
    <title>Paragraph-level Citation Recommendation based on Topic Sentences as
  Queries</title>
    <summary>  Citation recommendation (CR) models may help authors find relevant articles
at various stages of the paper writing process. Most research has dealt with
either global CR, which produces general recommendations suitable for the
initial writing stage, or local CR, which produces specific recommendations
more fitting for the final writing stages. We propose the task of
paragraph-level CR as a middle ground between the two approaches, where the
paragraph's topic sentence is taken as input and recommendations for citing
within the paragraph are produced at the output. We propose a model for this
task, fine-tune it using the quadruplet loss on the dataset of ACL papers, and
show improvements over the baselines.
</summary>
    <author>
      <name>Zoran Medić</name>
    </author>
    <author>
      <name>Jan Šnajder</name>
    </author>
    <link href="http://arxiv.org/abs/2305.12190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.12190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.02221v1</id>
    <updated>2023-06-04T00:32:45Z</updated>
    <published>2023-06-04T00:32:45Z</published>
    <title>ATEM: A Topic Evolution Model for the Detection of Emerging Topics in
  Scientific Archives</title>
    <summary>  This paper presents ATEM, a novel framework for studying topic evolution in
scientific archives. ATEM is based on dynamic topic modeling and dynamic graph
embedding techniques that explore the dynamics of content and citations of
documents within a scientific corpus. ATEM explores a new notion of contextual
emergence for the discovery of emerging interdisciplinary research topics based
on the dynamics of citation links in topic clusters. Our experiments show that
ATEM can efficiently detect emerging cross-disciplinary topics within the DBLP
archive of over five million computer science articles.
</summary>
    <author>
      <name>Hamed Rahimi</name>
    </author>
    <author>
      <name>Hubert Naacke</name>
    </author>
    <author>
      <name>Camelia Constantin</name>
    </author>
    <author>
      <name>Bernd Amann</name>
    </author>
    <link href="http://arxiv.org/abs/2306.02221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.02221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.03247v1</id>
    <updated>2023-06-05T21:02:02Z</updated>
    <published>2023-06-05T21:02:02Z</published>
    <title>Construction d'un système de recommandation basé sur des contraintes
  via des graphes de connaissances</title>
    <summary>  Knowledge graphs in RDF model entities and their relations using ontologies,
and have gained popularity for information modeling. In recommender systems,
knowledge graphs help represent more links and relationships between users and
items. Constraint-based recommender systems leverage deep recommendation
knowledge to identify relevant suggestions. When combined with knowledge
graphs, they offer benefits in constraint sets. This paper explores a
constraint-based recommender system using RDF knowledge graphs for the vehicle
purchase/sale domain. Our experiments demonstrate that the proposed approach
efficiently identifies recommendations based on user preferences.
</summary>
    <author>
      <name>Ngoc Luyen Le</name>
    </author>
    <author>
      <name>Marie-Hélène Abel</name>
    </author>
    <author>
      <name>Philippe Gouspillou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French language</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.03247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.03247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.03378v2</id>
    <updated>2023-06-09T05:43:17Z</updated>
    <published>2023-06-06T03:40:00Z</published>
    <title>Towards Alleviating the Object Bias in Prompt Tuning-based Factual
  Knowledge Extraction</title>
    <summary>  Many works employed prompt tuning methods to automatically optimize prompt
queries and extract the factual knowledge stored in Pretrained Language Models.
In this paper, we observe that the optimized prompts, including discrete
prompts and continuous prompts, exhibit undesirable object bias. To handle this
problem, we propose a novel prompt tuning method called MeCoD. consisting of
three modules: Prompt Encoder, Object Equalization and Biased Object
Obstruction. Experimental results show that MeCoD can significantly reduce the
object bias and at the same time improve accuracy of factual knowledge
extraction.
</summary>
    <author>
      <name>Yuhang Wang</name>
    </author>
    <author>
      <name>Dongyuan Lu</name>
    </author>
    <author>
      <name>Chao Kong</name>
    </author>
    <author>
      <name>Jitao Sang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2023 Findings</arxiv:comment>
    <link href="http://arxiv.org/abs/2306.03378v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.03378v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.06607v1</id>
    <updated>2023-06-11T07:03:23Z</updated>
    <published>2023-06-11T07:03:23Z</published>
    <title>Skellam Rank: Fair Learning to Rank Algorithm Based on Poisson Process
  and Skellam Distribution for Recommender Systems</title>
    <summary>  Recommender system is a widely adopted technology in a diversified class of
product lines. Modern day recommender system approaches include matrix
factorization, learning to rank and deep learning paradigms, etc. Unlike many
other approaches, learning to rank builds recommendation results based on
maximization of the probability of ranking orders. There are intrinsic issues
related to recommender systems such as selection bias, exposure bias and
popularity bias. In this paper, we propose a fair recommender system algorithm
that uses Poisson process and Skellam distribution. We demonstrate in our
experiments that our algorithm is competitive in accuracy metrics and far more
superior than other modern algorithms in fairness metrics.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2306.06607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.06607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.08236v1</id>
    <updated>2023-06-14T04:19:06Z</updated>
    <published>2023-06-14T04:19:06Z</published>
    <title>Extracting Information from Twitter Screenshots</title>
    <summary>  Screenshots are prevalent on social media as a common approach for
information sharing. Users rarely verify before sharing a screenshot whether
the post it contains is fake or real. Information sharing through fake
screenshots can be highly responsible for misinformation and disinformation
spread on social media. Our ultimate goal is to develop a tool that could take
a screenshot of a tweet and provide a probability that the tweet is real, using
resources found on the live web and in web archives. This paper provides
methods for extracting the tweet text, timestamp, and Twitter handle from a
screenshot of a tweet.
</summary>
    <author>
      <name>Tarannum Zaki</name>
    </author>
    <author>
      <name>Michael L. Nelson</name>
    </author>
    <author>
      <name>Michele C. Weigle</name>
    </author>
    <link href="http://arxiv.org/abs/2306.08236v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.08236v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.08915v2</id>
    <updated>2024-01-31T11:53:57Z</updated>
    <published>2023-06-15T07:38:25Z</published>
    <title>Prompt Performance Prediction for Image Generation</title>
    <summary>  The ability to predict the performance of a query before results are returned
has been a longstanding challenge in Information Retrieval (IR) systems.
Inspired by this task, we introduce, in this paper, a novel task called "Prompt
Performance Prediction" (PPP) that aims to predict the performance of a prompt,
before obtaining the actual generated images. We demonstrate the plausibility
of our task by measuring the correlation coefficient between predicted and
actual performance scores across: three datasets containing pairs of prompts
and generated images AND three art domain datasets of real images and real user
appreciation ratings. Our results show promising performance prediction
capabilities, suggesting potential applications for optimizing user prompts.
</summary>
    <author>
      <name>Nicolas Bizzozzero</name>
    </author>
    <author>
      <name>Ihab Bendidi</name>
    </author>
    <author>
      <name>Olivier Risser-Maroix</name>
    </author>
    <link href="http://arxiv.org/abs/2306.08915v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.08915v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.09938v1</id>
    <updated>2023-06-16T16:18:11Z</updated>
    <published>2023-06-16T16:18:11Z</published>
    <title>GRM: Generative Relevance Modeling Using Relevance-Aware Sample
  Estimation for Document Retrieval</title>
    <summary>  Recent studies show that Generative Relevance Feedback (GRF), using text
generated by Large Language Models (LLMs), can enhance the effectiveness of
query expansion. However, LLMs can generate irrelevant information that harms
retrieval effectiveness. To address this, we propose Generative Relevance
Modeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more
accurate weighting of expansion terms. Specifically, we identify similar real
documents for each generated document and use a neural re-ranker to estimate
their relevance. Experiments on three standard document ranking benchmarks show
that GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods.
</summary>
    <author>
      <name>Iain Mackie</name>
    </author>
    <author>
      <name>Ivan Sekulic</name>
    </author>
    <author>
      <name>Shubham Chatterjee</name>
    </author>
    <author>
      <name>Jeffrey Dalton</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <link href="http://arxiv.org/abs/2306.09938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.09938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.11293v1</id>
    <updated>2023-06-20T05:18:55Z</updated>
    <published>2023-06-20T05:18:55Z</published>
    <title>Representation Sparsification with Hybrid Thresholding for Fast
  SPLADE-based Document Retrieval</title>
    <summary>  Learned sparse document representations using a transformer-based neural
model has been found to be attractive in both relevance effectiveness and time
efficiency. This paper describes a representation sparsification scheme based
on hard and soft thresholding with an inverted index approximation for faster
SPLADE-based document retrieval. It provides analytical and experimental
results on the impact of this learnable hybrid thresholding scheme.
</summary>
    <author>
      <name>Yifan Qiao</name>
    </author>
    <author>
      <name>Yingrui Yang</name>
    </author>
    <author>
      <name>Shanxiu He</name>
    </author>
    <author>
      <name>Tao Yang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3539618.3592051</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3539618.3592051" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is published in SIGIR'23</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 46th International ACM SIGIR Conference on
  Research and Development in Information Retrieval 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2306.11293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.11293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2306.16668v1</id>
    <updated>2023-06-29T03:57:14Z</updated>
    <published>2023-06-29T03:57:14Z</published>
    <title>Beyond CO2 Emissions: The Overlooked Impact of Water Consumption of
  Information Retrieval Models</title>
    <summary>  As in other fields of artificial intelligence, the information retrieval
community has grown interested in investigating the power consumption
associated with neural models, particularly models of search. This interest has
become particularly relevant as the energy consumption of information retrieval
models has risen with new neural models based on large language models, leading
to an associated increase of CO2 emissions, albeit relatively low compared to
fields such as natural language processing.
</summary>
    <author>
      <name>Guido Zuccon</name>
    </author>
    <author>
      <name>Harrisen Scells</name>
    </author>
    <author>
      <name>Shengyao Zhuang</name>
    </author>
    <link href="http://arxiv.org/abs/2306.16668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2306.16668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.01212v1</id>
    <updated>2023-06-30T15:19:33Z</updated>
    <published>2023-06-30T15:19:33Z</published>
    <title>Of Spiky SVDs and Music Recommendation</title>
    <summary>  The truncated singular value decomposition is a widely used methodology in
music recommendation for direct similar-item retrieval or embedding musical
items for downstream tasks. This paper investigates a curious effect that we
show naturally occurring on many recommendation datasets: spiking formations in
the embedding space. We first propose a metric to quantify this spiking
organization's strength, then mathematically prove its origin tied to
underlying communities of items of varying internal popularity. With this
new-found theoretical understanding, we finally open the topic with an
industrial use case of estimating how music embeddings' top-k similar items
will change over time under the addition of data.
</summary>
    <author>
      <name>Darius Afchar</name>
    </author>
    <author>
      <name>Romain Hennequin</name>
    </author>
    <author>
      <name>Vincent Guigue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for RecSys 2023 (Singapour, 18-22 September)</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.01212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.01212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.02865v1</id>
    <updated>2023-07-06T09:04:58Z</updated>
    <published>2023-07-06T09:04:58Z</published>
    <title>PLIERS: a Popularity-Based Recommender System for Content Dissemination
  in Online Social Networks</title>
    <summary>  In this paper, we propose a novel tag-based recommender system called PLIERS,
which relies on the assumption that users are mainly interested in items and
tags with similar popularity to those they already own. PLIERS is aimed at
reaching a good tradeoff between algorithmic complexity and the level of
personalization of recommended items. To evaluate PLIERS, we performed a set of
experiments on real OSN datasets, demonstrating that it outperforms
state-of-the-art solutions in terms of personalization, relevance, and novelty
of recommendations.
</summary>
    <author>
      <name>Valerio Arnaboldi</name>
    </author>
    <author>
      <name>Mattia Giovanni Campana</name>
    </author>
    <author>
      <name>Franca Delmastro</name>
    </author>
    <author>
      <name>Elena Pagani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2851613.2851940</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2851613.2851940" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in SAC '16: Proceedings of the 31st Annual ACM Symposium on
  Applied Computing</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.02865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.02865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.05469v1</id>
    <updated>2023-07-07T06:48:58Z</updated>
    <published>2023-07-07T06:48:58Z</published>
    <title>AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in
  Sequential Recommendation</title>
    <summary>  This paper presents a solution to the challenges faced by contrastive
learning in sequential recommendation systems. In particular, it addresses the
issue of false negative, which limits the effectiveness of recommendation
algorithms. By introducing an advanced approach to contrastive learning, the
proposed method improves the quality of item embeddings and mitigates the
problem of falsely categorizing similar instances as dissimilar. Experimental
results demonstrate performance enhancements compared to existing systems. The
flexibility and applicability of the proposed approach across various
recommendation scenarios further highlight its value in enhancing sequential
recommendation systems.
</summary>
    <author>
      <name>Jaeheyoung Jeon</name>
    </author>
    <author>
      <name>Jung Hyun Ryu</name>
    </author>
    <author>
      <name>Jewoong Cho</name>
    </author>
    <author>
      <name>Myungjoo Kang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.05469v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.05469v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.07321v2</id>
    <updated>2023-10-01T13:12:29Z</updated>
    <published>2023-07-13T13:17:19Z</published>
    <title>NS4AR: A new, focused on sampling areas sampling method in graphical
  recommendation Systems</title>
    <summary>  The effectiveness of graphical recommender system depends on the quantity and
quality of negative sampling. This paper selects some typical recommender
system models, as well as some latest negative sampling strategies on the
models as baseline. Based on typical graphical recommender model, we divide
sample region into assigned-n areas and use AdaSim to give different weight to
these areas to form positive set and negative set. Because of the volume and
significance of negative items, we also proposed a subset selection model to
narrow the core negative samples.
</summary>
    <author>
      <name>Xiangqi Wang</name>
    </author>
    <author>
      <name>Dilinuer Aishan</name>
    </author>
    <author>
      <name>Qi Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">None</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.07321v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.07321v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="ACM-class: F.2.2, I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.08760v1</id>
    <updated>2023-07-17T18:07:26Z</updated>
    <published>2023-07-17T18:07:26Z</published>
    <title>Imposing Consistency Properties on Blackbox Systems with Applications to
  SVD-Based Recommender Systems</title>
    <summary>  In this paper we discuss pre- and post-processing methods to induce desired
consistency and/or invariance properties in blackbox systems, e.g., AI-based.
We demonstrate our approach in the context of blackbox SVD-based
matrix-completion methods commonly used in recommender system (RS)
applications. We provide empirical results showing that enforcement of
unit-consistency and shift-consistency, which have provable RS-relevant
properties relating to robustness and fairness, also lead to improved
performance according to generic RMSE and MAE performance metrics, irrespective
of the initial chosen hyperparameter.
</summary>
    <author>
      <name>Tung Nguyen</name>
    </author>
    <author>
      <name>Jeffrey Uhlmann</name>
    </author>
    <link href="http://arxiv.org/abs/2307.08760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.08760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.09172v1</id>
    <updated>2023-07-18T11:49:40Z</updated>
    <published>2023-07-18T11:49:40Z</published>
    <title>Jean-Luc Picard at Touché 2023: Comparing Image Generation, Stance
  Detection and Feature Matching for Image Retrieval for Arguments</title>
    <summary>  Participating in the shared task "Image Retrieval for arguments", we used
different pipelines for image retrieval containing Image Generation, Stance
Detection, Preselection and Feature Matching. We submitted four different runs
with different pipeline layout and compare them to given baseline. Our
pipelines perform similarly to the baseline.
</summary>
    <author>
      <name>Max Moebius</name>
    </author>
    <author>
      <name>Maximilian Enderling</name>
    </author>
    <author>
      <name>Sarah T. Bachinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure, 1 table, conference: CLEF</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.09172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.09172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.13427v1</id>
    <updated>2023-07-25T11:49:25Z</updated>
    <published>2023-07-25T11:49:25Z</published>
    <title>Comprehensive Review on Semantic Information Retrieval and Ontology
  Engineering</title>
    <summary>  Situation awareness is a crucial cognitive skill that enables individuals to
perceive, comprehend, and project the current state of their environment
accurately. It involves being conscious of relevant information, understanding
its meaning, and using that understanding to make well-informed decisions.
Awareness systems often need to integrate new knowledge and adapt to changing
environments. Ontology reasoning facilitates knowledge integration and
evolution, allowing for seamless updates and expansions of the ontology. With
the consideration of above, we are providing a quick review on semantic
information retrieval and ontology engineering to understand the emerging
challenges and future research. In the review we have found that the ontology
reasoning addresses the limitations of traditional systems by providing a
formal, flexible, and scalable framework for knowledge representation,
reasoning, and inference.
</summary>
    <author>
      <name>Sumit Sharma</name>
    </author>
    <author>
      <name>Sarika Jain</name>
    </author>
    <link href="http://arxiv.org/abs/2307.13427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.13427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.14401v1</id>
    <updated>2023-07-26T16:25:17Z</updated>
    <published>2023-07-26T16:25:17Z</published>
    <title>Measuring Americanization: A Global Quantitative Study of Interest in
  American Topics on Wikipedia</title>
    <summary>  We conducted a global comparative analysis of the coverage of American topics
in different language versions of Wikipedia, using over 90 million Wikidata
items and 40 million Wikipedia articles in 58 languages. Our study aimed to
investigate whether Americanization is more or less dominant in different
regions and cultures and to determine whether interest in American topics is
universal.
</summary>
    <author>
      <name>Piotr Konieczny</name>
    </author>
    <author>
      <name>Włodzimierz Lewoniewski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended and interactive version of bubble chart with Wikipedia
  languages: https://data.lewoniewski.info/americanwiki</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.14401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.14401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.16297v1</id>
    <updated>2023-07-30T18:30:23Z</updated>
    <published>2023-07-30T18:30:23Z</published>
    <title>Time-Aware Item Weighting for the Next Basket Recommendations</title>
    <summary>  In this paper we study the next basket recommendation problem. Recent methods
use different approaches to achieve better performance. However, many of them
do not use information about the time of prediction and time intervals between
baskets. To fill this gap, we propose a novel method, Time-Aware Item-based
Weighting (TAIW), which takes timestamps and intervals into account. We provide
experiments on three real-world datasets, and TAIW outperforms well-tuned
state-of-the-art baselines for next-basket recommendations. In addition, we
show the results of an ablation study and a case study of a few items.
</summary>
    <author>
      <name>Aleksey Romanov</name>
    </author>
    <author>
      <name>Oleg Lashinin</name>
    </author>
    <author>
      <name>Marina Ananyeva</name>
    </author>
    <author>
      <name>Sergey Kolesnikov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3604915.3608859</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3604915.3608859" rel="related"/>
    <link href="http://arxiv.org/abs/2307.16297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.16297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2307.16832v1</id>
    <updated>2023-07-31T16:56:08Z</updated>
    <published>2023-07-31T16:56:08Z</published>
    <title>Metric@CustomerN: Evaluating Metrics at a Customer Level in E-Commerce</title>
    <summary>  Accuracy measures such as Recall, Precision, and Hit Rate have been a
standard way of evaluating Recommendation Systems. The assumption is to use a
fixed Top-N to represent them. We propose that median impressions viewed from
historical sessions per diner be used as a personalized value for N. We present
preliminary exploratory results and list future steps to improve upon and
evaluate the efficacy of these personalized metrics.
</summary>
    <author>
      <name>Mayank Singh</name>
    </author>
    <author>
      <name>Emily Ray</name>
    </author>
    <author>
      <name>Marc Ferradou</name>
    </author>
    <author>
      <name>Andrea Barraza-Urbina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to evalRS 2023@KDD</arxiv:comment>
    <link href="http://arxiv.org/abs/2307.16832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2307.16832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.01204v1</id>
    <updated>2023-07-21T03:33:07Z</updated>
    <published>2023-07-21T03:33:07Z</published>
    <title>Methodologies for Improving Modern Industrial Recommender Systems</title>
    <summary>  Recommender system (RS) is an established technology with successful
applications in social media, e-commerce, entertainment, and more. RSs are
indeed key to the success of many popular APPs, such as YouTube, Tik Tok,
Xiaohongshu, Bilibili, and others. This paper explores the methodology for
improving modern industrial RSs. It is written for experienced RS engineers who
are diligently working to improve their key performance indicators, such as
retention and duration. The experiences shared in this paper have been tested
in some real industrial RSs and are likely to be generalized to other RSs as
well. Most contents in this paper are industry experience without publicly
available references.
</summary>
    <author>
      <name>Shusen Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2308.01204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.01204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.08406v1</id>
    <updated>2023-08-16T14:50:51Z</updated>
    <published>2023-08-16T14:50:51Z</published>
    <title>Content-based Recommendation Engine for Video Streaming Platform</title>
    <summary>  Recommendation engine suggest content, product or services to the user by
using machine learning algorithm. This paper proposed a content-based
recommendation engine for providing video suggestion to the user based on their
previous interests and choices. We will use TF-IDF text vectorization method to
determine the relevance of words in a document. Then we will find out the
similarity between each content by calculating cosine similarity between them.
Finally, engine will recommend videos to the users based on the obtained
similarity score value. In addition, we will measure the engine's performance
by computing precision, recall, and F1 core of the proposed system.
</summary>
    <author>
      <name>Puskal Khadka</name>
    </author>
    <author>
      <name>Prabhav Lamichhane</name>
    </author>
    <link href="http://arxiv.org/abs/2308.08406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.08406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.08650v1</id>
    <updated>2023-08-08T16:32:23Z</updated>
    <published>2023-08-08T16:32:23Z</published>
    <title>AdaptEx: A Self-Service Contextual Bandit Platform</title>
    <summary>  This paper presents AdaptEx, a self-service contextual bandit platform widely
used at Expedia Group, that leverages multi-armed bandit algorithms to
personalize user experiences at scale. AdaptEx considers the unique context of
each visitor to select the optimal variants and learns quickly from every
interaction they make. It offers a powerful solution to improve user
experiences while minimizing the costs and time associated with traditional
testing methods. The platform unlocks the ability to iterate towards optimal
product solutions quickly, even in ever-changing content and continuous "cold
start" situations gracefully.
</summary>
    <author>
      <name>William Black</name>
    </author>
    <author>
      <name>Ercument Ilhan</name>
    </author>
    <author>
      <name>Andrea Marchini</name>
    </author>
    <author>
      <name>Vilda Markeviciute</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3604915.3608870</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3604915.3608870" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 17th ACM Conference on Recommender Systems,
  2023, pp. 426-429</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2308.08650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.08650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.13536v1</id>
    <updated>2023-08-15T07:58:22Z</updated>
    <published>2023-08-15T07:58:22Z</published>
    <title>Implicit ZCA Whitening Effects of Linear Autoencoders for Recommendation</title>
    <summary>  Recently, in the field of recommendation systems, linear regression
(autoencoder) models have been investigated as a way to learn item similarity.
In this paper, we show a connection between a linear autoencoder model and ZCA
whitening for recommendation data. In particular, we show that the dual form
solution of a linear autoencoder model actually has ZCA whitening effects on
feature vectors of items, while items are considered as input features in the
primal problem of the autoencoder/regression model. We also show the
correctness of applying a linear autoencoder to low-dimensional item vectors
obtained using embedding methods such as Item2vec to estimate item-item
similarities. Our experiments provide preliminary results indicating the
effectiveness of whitening low-dimensional item embeddings.
</summary>
    <author>
      <name>Katsuhiko Hayashi</name>
    </author>
    <author>
      <name>Kazuma Onishi</name>
    </author>
    <link href="http://arxiv.org/abs/2308.13536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.13536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.15230v1</id>
    <updated>2023-08-29T11:37:33Z</updated>
    <published>2023-08-29T11:37:33Z</published>
    <title>Providing Previously Unseen Users Fair Recommendations Using Variational
  Autoencoders</title>
    <summary>  An emerging definition of fairness in machine learning requires that models
are oblivious to demographic user information, e.g., a user's gender or age
should not influence the model. Personalized recommender systems are
particularly prone to violating this definition through their explicit user
focus and user modelling. Explicit user modelling is also an aspect that makes
many recommender systems incapable of providing hitherto unseen users with
recommendations. We propose novel approaches for mitigating discrimination in
Variational Autoencoder-based recommender systems by limiting the encoding of
demographic information. The approaches are capable of, and evaluated on,
providing users that are not represented in the training data with fair
recommendations.
</summary>
    <author>
      <name>Bjørnar Vassøy</name>
    </author>
    <author>
      <name>Helge Langseth</name>
    </author>
    <author>
      <name>Benjamin Kille</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appearing in RecSys 2023 proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.15230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.15230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.15498v1</id>
    <updated>2023-08-29T02:42:52Z</updated>
    <published>2023-08-29T02:42:52Z</published>
    <title>Chunked Lists versus Extensible Arrays for Text Inversion</title>
    <summary>  In our 2017 work on in-memory list-based text inversion [Hawking and
Billerbeck. Efficient In-Memory, List-Based Text Inversion. ADCS 2017] we
compared memory use and indexing speed of a considerable number of variants of
chunked linked lists. In the present work we compare the best performing of
those variants (FBB - dynamic Fibonacci chunking) with the extensible SQ array
technique (SQA) presented in [Moffat and Mackenzie. Immediate-Access Indexing
Using Space-Efficient Extensible Arrays. ADCS 2023].
</summary>
    <author>
      <name>David Hawking</name>
    </author>
    <author>
      <name>Bodo Billerbeck</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2308.15498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2308.15498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.05113v1</id>
    <updated>2023-09-10T19:01:12Z</updated>
    <published>2023-09-10T19:01:12Z</published>
    <title>Personalized Search Via Neural Contextual Semantic Relevance Ranking</title>
    <summary>  Existing neural relevance models do not give enough consideration for query
and item context information which diversifies the search results to adapt for
personal preference. To bridge this gap, this paper presents a neural learning
framework to personalize document ranking results by leveraging the signals to
capture how the document fits into users' context. In particular, it models the
relationships between document content and user query context using both
lexical representations and semantic embeddings such that the user's intent can
be better understood by data enrichment of personalized query context
information. Extensive experiments performed on the search dataset, demonstrate
the effectiveness of the proposed method.
</summary>
    <author>
      <name>Deguang Kong</name>
    </author>
    <author>
      <name>Daniel Zhou</name>
    </author>
    <author>
      <name>Zhiheng Huang</name>
    </author>
    <author>
      <name>Steph Sigalas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contextual, Personalization, Search, Semantics, LLM, embedding</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.05113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.05113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.08622v2</id>
    <updated>2023-09-19T03:05:32Z</updated>
    <published>2023-09-10T21:40:51Z</published>
    <title>Representation Learning in Low-rank Slate-based Recommender Systems</title>
    <summary>  Reinforcement learning (RL) in recommendation systems offers the potential to
optimize recommendations for long-term user engagement. However, the
environment often involves large state and action spaces, which makes it hard
to efficiently learn and explore. In this work, we propose a sample-efficient
representation learning algorithm, using the standard slate recommendation
setup, to treat this as an online RL problem with low-rank Markov decision
processes (MDPs). We also construct the recommender simulation environment with
the proposed setup and sampling method.
</summary>
    <author>
      <name>Yijia Dai</name>
    </author>
    <author>
      <name>Wen Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in MFPL, ICML 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.08622v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.08622v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.11503v1</id>
    <updated>2023-09-05T18:19:57Z</updated>
    <published>2023-09-05T18:19:57Z</published>
    <title>Fairness Vs. Personalization: Towards Equity in Epistemic Utility</title>
    <summary>  The applications of personalized recommender systems are rapidly expanding:
encompassing social media, online shopping, search engine results, and more.
These systems offer a more efficient way to navigate the vast array of items
available. However, alongside this growth, there has been increased recognition
of the potential for algorithmic systems to exhibit and perpetuate biases,
risking unfairness in personalized domains. In this work, we explicate the
inherent tension between personalization and conventional implementations of
fairness. As an alternative, we propose equity to achieve fairness in the
context of epistemic utility. We provide a mapping between goals and practical
implementations and detail policy recommendations across key stakeholders to
forge a path towards achieving fairness in personalized systems.
</summary>
    <author>
      <name>Jennifer Chien</name>
    </author>
    <author>
      <name>David Danks</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 tables, FAccTRec '23 (Singapore)</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.11503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.11503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.11671v1</id>
    <updated>2023-09-20T22:36:33Z</updated>
    <published>2023-09-20T22:36:33Z</published>
    <title>Popularity Degradation Bias in Local Music Recommendation</title>
    <summary>  In this paper, we study the effect of popularity degradation bias in the
context of local music recommendations. Specifically, we examine how accurate
two top-performing recommendation algorithms, Weight Relevance Matrix
Factorization (WRMF) and Multinomial Variational Autoencoder (Mult-VAE), are at
recommending artists as a function of artist popularity. We find that both
algorithms improve recommendation performance for more popular artists and, as
such, exhibit popularity degradation bias. While both algorithms produce a
similar level of performance for more popular artists, Mult-VAE shows better
relative performance for less popular artists. This suggests that this
algorithm should be preferred for local (long-tail) music artist
recommendation.
</summary>
    <author>
      <name>April Trainor</name>
    </author>
    <author>
      <name>Douglas Turnbull</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at MuRS Workshop, RecSys '23</arxiv:comment>
    <link href="http://arxiv.org/abs/2309.11671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.11671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.13259v1</id>
    <updated>2023-09-23T04:46:28Z</updated>
    <published>2023-09-23T04:46:28Z</published>
    <title>WikiMT++ Dataset Card</title>
    <summary>  WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT),
featuring 1010 curated lead sheets in ABC notation. To expand application
scenarios of WikiMT, we add both objective (album, lyrics, video) and
subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes,
enhancing its usability for music information retrieval, conditional music
generation, automatic composition, and emotion classification, etc.
Additionally, CLaMP is implemented to correct the attributes inherited from
WikiMT to reduce errors introduced during original data collection and enhance
the accuracy and completeness of our dataset.
</summary>
    <author>
      <name>Monan Zhou</name>
    </author>
    <author>
      <name>Shangda Wu</name>
    </author>
    <author>
      <name>Yuan Wang</name>
    </author>
    <author>
      <name>Wei Li</name>
    </author>
    <link href="http://arxiv.org/abs/2309.13259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2309.13259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2310.07281v1</id>
    <updated>2023-10-11T08:15:10Z</updated>
    <published>2023-10-11T08:15:10Z</published>
    <title>A Completely Locale-independent Session-based Recommender System by
  Leveraging Trained Model</title>
    <summary>  In this paper, we propose a solution that won the 10th prize in the KDD Cup
2023 Challenge Task 2 (Next Product Recommendation for Underrepresented
Languages/Locales). Our approach involves two steps: (i) Identify candidate
item sets based on co-visitation, and (ii) Re-ranking the items using LightGBM
with locale-independent features, including session-based features and product
similarity. The experiment demonstrated that the locale-independent model
performed consistently well across different test locales, and performed even
better when incorporating data from other locales into the training.
</summary>
    <author>
      <name>Yu Tokutake</name>
    </author>
    <author>
      <name>Chihiro Yamasaki</name>
    </author>
    <author>
      <name>Yongzhi Jin</name>
    </author>
    <author>
      <name>Ayuka Inoue</name>
    </author>
    <author>
      <name>Kei Harada</name>
    </author>
    <link href="http://arxiv.org/abs/2310.07281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2310.07281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.03316v1</id>
    <updated>2023-11-06T18:08:37Z</updated>
    <published>2023-11-06T18:08:37Z</published>
    <title>Improving Collaborative Filtering Recommendation via Graph Learning</title>
    <summary>  Recommendation systems are designed to provide personalized predictions for
items that are most appealing to individual customers. Among various types of
recommendation algorithms, k-nearest neighbor based collaborative filtering
algorithm attracts tremendous attention and are widely used in practice.
However, the k-nearest neighbor scheme can only capture the local relationship
among users and the uniform neighborhood size is also not suitable to represent
the underlying data structure. In this paper, we leverage emerging graph signal
processing (GSP) theory to construct sparse yet high quality graph to enhance
the solution quality and efficiency of collaborative filtering algorithm.
Experimental results show that our method outperforms k-NN based collaborative
filtering algorithm by a large margin on the benchmark data set.
</summary>
    <author>
      <name>Yongyu Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2311.03316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.03316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.06592v1</id>
    <updated>2023-11-11T15:25:49Z</updated>
    <published>2023-11-11T15:25:49Z</published>
    <title>An Empirical Study of Using ChatGPT for Fact Verification Task</title>
    <summary>  ChatGPT has recently emerged as a powerful tool for performing diverse NLP
tasks. However, ChatGPT has been criticized for generating nonfactual
responses, raising concerns about its usability for sensitive tasks like fact
verification. This study investigates three key research questions: (1) Can
ChatGPT be used for fact verification tasks? (2) What are different prompts
performance using ChatGPT for fact verification tasks? (3) For the
best-performing prompt, what common mistakes does ChatGPT make? Specifically,
this study focuses on conducting a comprehensive and systematic analysis by
designing and comparing the performance of three different prompts for fact
verification tasks on the benchmark FEVER dataset using ChatGPT.
</summary>
    <author>
      <name>Mohna Chakraborty</name>
    </author>
    <author>
      <name>Adithya Kulkarni</name>
    </author>
    <author>
      <name>Qi Li</name>
    </author>
    <link href="http://arxiv.org/abs/2311.06592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.06592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.07947v2</id>
    <updated>2023-12-11T15:46:59Z</updated>
    <published>2023-11-14T06:57:20Z</published>
    <title>Towards a Technical Debt for Recommender System</title>
    <summary>  Balancing the management of technical debt within recommender systems
requires effectively juggling the introduction of new features with the ongoing
maintenance and enhancement of the current system. Within the realm of
recommender systems, technical debt encompasses the trade-offs and expedient
choices made during the development and upkeep of the recommendation system,
which could potentially have adverse effects on its long-term performance,
scalability, and maintainability. In this vision paper, our objective is to
kickstart a research direction regarding Technical Debt in Recommender Systems.
We identified 15 potential factors, along with detailed explanations outlining
why it is advisable to consider them.
</summary>
    <author>
      <name>Sergio Moreschini</name>
    </author>
    <author>
      <name>Ludovik Coba</name>
    </author>
    <author>
      <name>Valentina Lenarduzzi</name>
    </author>
    <link href="http://arxiv.org/abs/2311.07947v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.07947v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.08682v1</id>
    <updated>2023-11-15T04:15:58Z</updated>
    <published>2023-11-15T04:15:58Z</published>
    <title>Enhancing Recommender System Performance by Histogram Equalization</title>
    <summary>  Recommender system has been researched for decades with millions of different
versions of algorithms created in the industry. In spite of the huge amount of
work spent on the field, there are many basic questions to be answered in the
field. The most fundamental question to be answered is the accuracy problem,
and in recent years, fairness becomes the new buzz word for researchers. In
this paper, we borrow an idea from image processing, namely, histogram
equalization. As a preprocessing step to recommender system algorithms,
histogram equalization could enhance both the accuracy and fairness metrics of
the recommender system algorithms. In the experiment section, we prove that our
new approach could improve vanilla algorithms by a large margin in accuracy
metric and stay competitive on fairness metrics.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2311.08682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.08682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.11701v1</id>
    <updated>2023-11-20T12:08:32Z</updated>
    <published>2023-11-20T12:08:32Z</published>
    <title>Control in Hybrid Chatbots</title>
    <summary>  Customer data typically is held in database systems, which can be seen as
rule-based knowledge base, whereas businesses increasingly want to benefit from
the capabilities of large, pre-trained language models.
  In this technical report, we describe a case study of how a commercial rule
engine and an integrated neural chatbot may be integrated, and what level of
control that particular integration mode leads to. We also discuss alternative
ways (including past ways realized in other systems) how researchers strive to
maintain control and avoid what has recently been called model "hallucination".
</summary>
    <author>
      <name>Thomas Rüdel</name>
    </author>
    <author>
      <name>Jochen L. Leidner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2311.11701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.11701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50, 68T07" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.12338v1</id>
    <updated>2023-11-21T04:14:09Z</updated>
    <published>2023-11-21T04:14:09Z</published>
    <title>A Survey on Large Language Models for Personalized and Explainable
  Recommendations</title>
    <summary>  In recent years, Recommender Systems(RS) have witnessed a transformative
shift with the advent of Large Language Models(LLMs) in the field of Natural
Language Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from
Meta, have demonstrated unprecedented capabilities in understanding and
generating human-like text. This has led to a paradigm shift in the realm of
personalized and explainable recommendations, as LLMs offer a versatile toolset
for processing vast amounts of textual data to enhance user experiences. To
provide a comprehensive understanding of the existing LLM-based recommendation
systems, this survey aims to analyze how RS can benefit from LLM-based
methodologies. Furthermore, we describe major challenges in Personalized
Explanation Generating(PEG) tasks, which are cold-start problems, unfairness
and bias problems in RS.
</summary>
    <author>
      <name>Junyi Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2311.12338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2311.12338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.00512v1</id>
    <updated>2023-12-01T11:34:01Z</updated>
    <published>2023-12-01T11:34:01Z</published>
    <title>Attack Detection Using Item Vector Shift in Matrix Factorisation
  Recommenders</title>
    <summary>  This paper proposes a novel method for detecting shilling attacks in Matrix
Factorization (MF)-based Recommender Systems (RS), in which attackers use false
user-item feedback to promote a specific item. Unlike existing methods that use
either use supervised learning to distinguish between attack and genuine
profiles or analyse target item rating distributions to detect false ratings,
our method uses an unsupervised technique to detect false ratings by examining
shifts in item preference vectors that exploit rating deviations and user
characteristics, making it a promising new direction. The experimental results
demonstrate the effectiveness of our approach in various attack scenarios,
including those involving obfuscation techniques.
</summary>
    <author>
      <name>Sulthana Shams</name>
    </author>
    <author>
      <name>Douglas Leith</name>
    </author>
    <link href="http://arxiv.org/abs/2312.00512v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.00512v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.01556v1</id>
    <updated>2023-12-04T00:56:50Z</updated>
    <published>2023-12-04T00:56:50Z</published>
    <title>Searching Dense Representations with Inverted Indexes</title>
    <summary>  Nearly all implementations of top-$k$ retrieval with dense vector
representations today take advantage of hierarchical navigable small-world
network (HNSW) indexes. However, the generation of vector representations and
efficiently searching large collections of vectors are distinct challenges that
can be decoupled. In this work, we explore the contrarian approach of
performing top-$k$ retrieval on dense vector representations using inverted
indexes. We present experiments on the MS MARCO passage ranking dataset,
evaluating three dimensions of interest: output quality, speed, and index size.
Results show that searching dense representations using inverted indexes is
possible. Our approach exhibits reasonable effectiveness with compact indexes,
but is impractically slow. Thus, while workable, our solution does not provide
a compelling tradeoff and is perhaps best characterized today as a "technical
curiosity".
</summary>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <author>
      <name>Tommaso Teofili</name>
    </author>
    <link href="http://arxiv.org/abs/2312.01556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.01556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.03171v1</id>
    <updated>2023-12-05T22:28:42Z</updated>
    <published>2023-12-05T22:28:42Z</published>
    <title>Combining Counting Processes and Classification Improves a Stopping Rule
  for Technology Assisted Review</title>
    <summary>  Technology Assisted Review (TAR) stopping rules aim to reduce the cost of
manually assessing documents for relevance by minimising the number of
documents that need to be examined to ensure a desired level of recall. This
paper extends an effective stopping rule using information derived from a text
classifier that can be trained without the need for any additional annotation.
Experiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal
and RCV1) showed that the proposed approach consistently improves performance
and outperforms several alternative methods.
</summary>
    <author>
      <name>Reem Bin-Hezam</name>
    </author>
    <author>
      <name>Mark Stevenson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EMNLP 2023 Findings</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.03171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.03171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.07796v1</id>
    <updated>2023-12-12T23:22:57Z</updated>
    <published>2023-12-12T23:22:57Z</published>
    <title>Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge
  Gaps</title>
    <summary>  The paper presents a methodology for uncovering knowledge gaps on the
internet using the Retrieval Augmented Generation (RAG) model. By simulating
user search behaviour, the RAG system identifies and addresses gaps in
information retrieval systems. The study demonstrates the effectiveness of the
RAG system in generating relevant suggestions with a consistent accuracy of
93%. The methodology can be applied in various fields such as scientific
discovery, educational enhancement, research development, market analysis,
search engine optimisation, and content development. The results highlight the
value of identifying and understanding knowledge gaps to guide future
endeavours.
</summary>
    <author>
      <name>Joan Figuerola Hurtado</name>
    </author>
    <link href="http://arxiv.org/abs/2312.07796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.07796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.08995v1</id>
    <updated>2023-12-14T14:41:37Z</updated>
    <published>2023-12-14T14:41:37Z</published>
    <title>FrameFinder: Explorative Multi-Perspective Framing Extraction from News
  Headlines</title>
    <summary>  Revealing the framing of news articles is an important yet neglected task in
information seeking and retrieval. In the present work, we present FrameFinder,
an open tool for extracting and analyzing frames in textual data. FrameFinder
visually represents the frames of text from three perspectives, i.e., (i) frame
labels, (ii) frame dimensions, and (iii) frame structure. By analyzing the
well-established gun violence frame corpus, we demonstrate the merits of our
proposed solution to support social science research and call for subsequent
integration into information interactions.
</summary>
    <author>
      <name>Markus Reiter-Haas</name>
    </author>
    <author>
      <name>Beate Klösch</name>
    </author>
    <author>
      <name>Markus Hadler</name>
    </author>
    <author>
      <name>Elisabeth Lex</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3627508.3638308</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3627508.3638308" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at CHIIR'24</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2024 ACM SIGIR Conference on Human Information
  Interaction and Retrieval</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2312.08995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.08995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.09684v1</id>
    <updated>2023-12-15T10:58:45Z</updated>
    <published>2023-12-15T10:58:45Z</published>
    <title>Context-Aware Sequential Model for Multi-Behaviour Recommendation</title>
    <summary>  Sequential recommendation models are crucial for next-item recommendations in
online platforms, capturing complex patterns in user interactions. However,
many focus on a single behavior, overlooking valuable implicit interactions
like clicks and favorites. Existing multi-behavioral models often fail to
simultaneously capture sequential patterns. We propose CASM, a Context-Aware
Sequential Model, leveraging sequential models to seamlessly handle multiple
behaviors. CASM employs context-aware multi-head self-attention for
heterogeneous historical interactions and a weighted binary cross-entropy loss
for precise control over behavior contributions. Experimental results on four
datasets demonstrate CASM's superiority over state-of-the-art approaches.
</summary>
    <author>
      <name>Shereen Elsayed</name>
    </author>
    <author>
      <name>Ahmed Rashed</name>
    </author>
    <author>
      <name>Lars Schmidt-Thieme</name>
    </author>
    <link href="http://arxiv.org/abs/2312.09684v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.09684v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.10079v1</id>
    <updated>2023-12-10T07:35:17Z</updated>
    <published>2023-12-10T07:35:17Z</published>
    <title>Music Recommendation on Spotify using Deep Learning</title>
    <summary>  Hosting about 50 million songs and 4 billion playlists, there is an enormous
amount of data generated at Spotify every single day - upwards of 600 gigabytes
of data (harvard.edu). Since the algorithms that Spotify uses in recommendation
systems is proprietary and confidential, code for big data analytics and
recommendation can only be speculated. However, it is widely theorized that
Spotify uses two main strategies to target users' playlists and personalized
mixes that are infamous for their retention - exploration and exploitation
(kaggle.com). This paper aims to appropriate filtering using the approach of
deep learning for maximum user likeability. The architecture achieves 98.57%
and 80% training and validation accuracy respectively.
</summary>
    <author>
      <name>Chhavi Maheshwari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 images, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.10079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.10079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2312.16183v1</id>
    <updated>2023-12-17T15:18:18Z</updated>
    <published>2023-12-17T15:18:18Z</published>
    <title>LightGCN: Evaluated and Enhanced</title>
    <summary>  This paper analyses LightGCN in the context of graph recommendation
algorithms. Despite the initial design of Graph Convolutional Networks for
graph classification, the non-linear operations are not always essential.
LightGCN enables linear propagation of embeddings, enhancing performance. We
reproduce the original findings, assess LightGCN's robustness on diverse
datasets and metrics, and explore Graph Diffusion as an augmentation of signal
propagation in LightGCN.
</summary>
    <author>
      <name>Milena Kapralova</name>
    </author>
    <author>
      <name>Luca Pantea</name>
    </author>
    <author>
      <name>Andrei Blahovici</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NeurIPS'23 Workshop on New in ML; 3 pages, 2 figures, 3
  tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2312.16183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2312.16183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.00353v1</id>
    <updated>2023-12-30T23:56:35Z</updated>
    <published>2023-12-30T23:56:35Z</published>
    <title>EXPLORE -- Explainable Song Recommendation</title>
    <summary>  This study explores the development of an explainable music recommendation
system with enhanced user control. Leveraging a hybrid of collaborative
filtering and content-based filtering, we address the challenges of opaque
recommendation logic and lack of user influence on results. We present a novel
approach combining advanced algorithms and an interactive user interface. Our
methodology integrates Spotify data with user preference analytics to tailor
music suggestions. Evaluation through RMSE and user studies underscores the
efficacy and user satisfaction with our system. The paper concludes with
potential directions for future enhancements in group recommendations and
dynamic feedback integration.
</summary>
    <author>
      <name>Abhinav Arun</name>
    </author>
    <author>
      <name>Mehul Soni</name>
    </author>
    <author>
      <name>Palash Choudhary</name>
    </author>
    <author>
      <name>Saksham Arora</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.00353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.00353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.02827v1</id>
    <updated>2024-01-05T14:21:10Z</updated>
    <published>2024-01-05T14:21:10Z</published>
    <title>Let's Get It Started: Fostering the Discoverability of New Releases on
  Deezer</title>
    <summary>  This paper presents our recent initiatives to foster the discoverability of
new releases on the music streaming service Deezer. After introducing our
search and recommendation features dedicated to new releases, we outline our
shift from editorial to personalized release suggestions using cold start
embeddings and contextual bandits. Backed by online experiments, we discuss the
advantages of this shift in terms of recommendation quality and exposure of new
releases on the service.
</summary>
    <author>
      <name>Léa Briand</name>
    </author>
    <author>
      <name>Théo Bontempelli</name>
    </author>
    <author>
      <name>Walid Bendada</name>
    </author>
    <author>
      <name>Mathieu Morlon</name>
    </author>
    <author>
      <name>François Rigaud</name>
    </author>
    <author>
      <name>Benjamin Chapus</name>
    </author>
    <author>
      <name>Thomas Bouabça</name>
    </author>
    <author>
      <name>Guillaume Salha-Galvan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for presentation as an "Industry Talk" at the 46th European
  Conference on Information Retrieval (ECIR 2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.02827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.02827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.04053v1</id>
    <updated>2024-01-08T17:45:38Z</updated>
    <published>2024-01-08T17:45:38Z</published>
    <title>Learning-to-Rank with Nested Feedback</title>
    <summary>  Many platforms on the web present ranked lists of content to users, typically
optimized for engagement-, satisfaction- or retention- driven metrics. Advances
in the Learning-to-Rank (LTR) research literature have enabled rapid growth in
this application area. Several popular interfaces now include nested lists,
where users can enter a 2nd-level feed via any given 1st-level item. Naturally,
this has implications for evaluation metrics, objective functions, and the
ranking policies we wish to learn. We propose a theoretically grounded method
to incorporate 2nd-level feedback into any 1st-level ranking model. Online
experiments on a large-scale recommendation system confirm our theoretical
findings.
</summary>
    <author>
      <name>Hitesh Sagtani</name>
    </author>
    <author>
      <name>Olivier Jeunen</name>
    </author>
    <author>
      <name>Aleksei Ustimenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the European Conference on Information Retrieval (ECIR
  '24)</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.04053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.04053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.04055v1</id>
    <updated>2024-01-08T17:53:06Z</updated>
    <published>2024-01-08T17:53:06Z</published>
    <title>Sparse Meets Dense: A Hybrid Approach to Enhance Scientific Document
  Retrieval</title>
    <summary>  Traditional information retrieval is based on sparse bag-of-words vector
representations of documents and queries. More recent deep-learning approaches
have used dense embeddings learned using a transformer-based large language
model. We show that on a classic benchmark on scientific document retrieval in
the medical domain of cystic fibrosis, that both of these models perform
roughly equivalently. Notably, dense vectors from the state-of-the-art SPECTER2
model do not significantly enhance performance. However, a hybrid model that we
propose combining these methods yields significantly better results,
underscoring the merits of integrating classical and contemporary deep learning
techniques in information retrieval in the domain of specialized scientific
documents.
</summary>
    <author>
      <name>Priyanka Mandikal</name>
    </author>
    <author>
      <name>Raymond Mooney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at SDU-AAAI 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.04055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.04055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.04524v1</id>
    <updated>2024-01-09T12:34:13Z</updated>
    <published>2024-01-09T12:34:13Z</published>
    <title>Analyzing Coherency in Facet-based Clarification Prompt Generation for
  Search</title>
    <summary>  Clarifying user's information needs is an essential component of modern
search systems. While most of the approaches for constructing clarifying
prompts rely on query facets, the impact of the quality of the facets is
relatively unexplored. In this work, we concentrate on facet quality through
the notion of facet coherency and assess its importance for overall usefulness
for clarification in search. We find that existing evaluation procedures do not
account for facet coherency, as evident by the poor correlation of coherency
with automated metrics. Moreover, we propose a coherency classifier and assess
the prevalence of incoherent facets in a well-established dataset on
clarification. Our findings can serve as motivation for future work on the
topic.
</summary>
    <author>
      <name>Oleg Litvinov</name>
    </author>
    <author>
      <name>Ivan Sekulić</name>
    </author>
    <author>
      <name>Mohammad Aliannejadi</name>
    </author>
    <author>
      <name>Fabio Crestani</name>
    </author>
    <link href="http://arxiv.org/abs/2401.04524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.04524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.06830v1</id>
    <updated>2024-01-12T10:14:10Z</updated>
    <published>2024-01-12T10:14:10Z</published>
    <title>RecSys Challenge 2023: From data preparation to prediction, a simple,
  efficient, robust and scalable solution</title>
    <summary>  The RecSys Challenge 2023, presented by ShareChat, consists to predict if an
user will install an application on his smartphone after having seen
advertising impressions in ShareChat &amp; Moj apps. This paper presents the
solution of 'Team UMONS' to this challenge, giving accurate results (our best
score is 6.622686) with a relatively small model that can be easily implemented
in different production configurations. Our solution scales well when
increasing the dataset size and can be used with datasets containing missing
values.
</summary>
    <author>
      <name>Maxime Manderlier</name>
    </author>
    <author>
      <name>Fabian Lecron</name>
    </author>
    <link href="http://arxiv.org/abs/2401.06830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.06830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.09572v1</id>
    <updated>2024-01-17T19:49:11Z</updated>
    <published>2024-01-17T19:49:11Z</published>
    <title>Handling Large-scale Cardinality in building recommendation systems</title>
    <summary>  Effective recommendation systems rely on capturing user preferences, often
requiring incorporating numerous features such as universally unique
identifiers (UUIDs) of entities. However, the exceptionally high cardinality of
UUIDs poses a significant challenge in terms of model degradation and increased
model size due to sparsity. This paper presents two innovative techniques to
address the challenge of high cardinality in recommendation systems.
Specifically, we propose a bag-of-words approach, combined with layer sharing,
to substantially decrease the model size while improving performance. Our
techniques were evaluated through offline and online experiments on Uber use
cases, resulting in promising results demonstrating our approach's
effectiveness in optimizing recommendation systems and enhancing their overall
performance.
</summary>
    <author>
      <name>Dhruva Dixith Kurra</name>
    </author>
    <author>
      <name>Bo Ling</name>
    </author>
    <author>
      <name>Chun Zh</name>
    </author>
    <author>
      <name>Seyedshahin Ashrafzadeh</name>
    </author>
    <link href="http://arxiv.org/abs/2401.09572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.09572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.09725v1</id>
    <updated>2024-01-18T05:00:18Z</updated>
    <published>2024-01-18T05:00:18Z</published>
    <title>Enhancing Image-Text Matching with Adaptive Feature Aggregation</title>
    <summary>  Image-text matching aims to find matched cross-modal pairs accurately. While
current methods often rely on projecting cross-modal features into a common
embedding space, they frequently suffer from imbalanced feature representations
across different modalities, leading to unreliable retrieval results. To
address these limitations, we introduce a novel Feature Enhancement Module that
adaptively aggregates single-modal features for more balanced and robust
image-text retrieval. Additionally, we propose a new loss function that
overcomes the shortcomings of original triplet ranking loss, thereby
significantly improving retrieval performance. The proposed model has been
evaluated on two public datasets and achieves competitive retrieval performance
when compared with several state-of-the-art models. Implementation codes can be
found here.
</summary>
    <author>
      <name>Zuhui Wang</name>
    </author>
    <author>
      <name>Yunting Yin</name>
    </author>
    <author>
      <name>I. V. Ramakrishnan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ICASSP 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2401.09725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.09725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.10607v1</id>
    <updated>2024-01-19T10:32:28Z</updated>
    <published>2024-01-19T10:32:28Z</published>
    <title>Use of topical and temporal profiles and their hybridisation for
  content-based recommendation</title>
    <summary>  In the context of content-based recommender systems, the aim of this paper is
to determine how better profiles can be built and how these affect the
recommendation process based on the incorporation of temporality, i.e. the
inclusion of time in the recommendation process, and topicality, i.e. the
representation of texts associated with users and items using topics and their
combination. The main contribution of the paper is to present two different
ways of hybridising these two dimensions and to evaluate and compare them with
other alternatives.
</summary>
    <author>
      <name>Luis M. de Campos</name>
    </author>
    <author>
      <name>Juan M. Fernández-Luna</name>
    </author>
    <author>
      <name>Juan F. Huete</name>
    </author>
    <link href="http://arxiv.org/abs/2401.10607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.10607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.10611v1</id>
    <updated>2024-01-19T10:42:29Z</updated>
    <published>2024-01-19T10:42:29Z</published>
    <title>Publication venue recommendation using profiles based on clustering</title>
    <summary>  In this paper we study the venue recommendation problem in order to help
researchers to identify a journal or conference to submit a given paper. A
common approach to tackle this problem is to build profiles defining the scope
of each venue. Then, these profiles are compared against the target paper. In
our approach we will study how clustering techniques can be used to construct
topic-based profiles and use an Information Retrieval based approach to obtain
the final recommendations. Additionally, we will explore how the use of
authorship, representing a complementary piece of information, helps to improve
the recommendations.
</summary>
    <author>
      <name>Luis M. de Campos</name>
    </author>
    <author>
      <name>Juan M. Fernández-Luna</name>
    </author>
    <author>
      <name>Juan F. Huete</name>
    </author>
    <link href="http://arxiv.org/abs/2401.10611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.10611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.16427v1</id>
    <updated>2024-01-18T05:24:02Z</updated>
    <published>2024-01-18T05:24:02Z</published>
    <title>Mitigating Position Bias with Regularization for Recommender Systems</title>
    <summary>  Fairness is a popular research topic in recent years. A research topic
closely related to fairness is bias and debiasing. Among different types of
bias problems, position bias is one of the most widely encountered symptoms.
Position bias means that recommended items on top of the recommendation list
has a higher likelihood to be clicked than items on bottom of the same list. To
mitigate this problem, we propose to use regularization technique to reduce the
bias effect. In the experiment section, we prove that our method is superior to
other modern algorithms.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3233/FAIA231230</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3233/FAIA231230" rel="related"/>
    <link href="http://arxiv.org/abs/2401.16427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2401.16427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.02932v1</id>
    <updated>2024-02-05T11:55:30Z</updated>
    <published>2024-02-05T11:55:30Z</published>
    <title>Domain Adaptation of Multilingual Semantic Search -- Literature Review</title>
    <summary>  This literature review gives an overview of current approaches to perform
domain adaptation in a low-resource and approaches to perform multilingual
semantic search in a low-resource setting. We developed a new typology to
cluster domain adaptation approaches based on the part of dense textual
information retrieval systems, which they adapt, focusing on how to combine
them efficiently. We also explore the possibilities of combining multilingual
semantic search with domain adaptation approaches for dense retrievers in a
low-resource setting.
</summary>
    <author>
      <name>Anna Bringmann</name>
    </author>
    <author>
      <name>Anastasia Zhukova</name>
    </author>
    <link href="http://arxiv.org/abs/2402.02932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.02932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.04357v1</id>
    <updated>2024-02-06T19:43:52Z</updated>
    <published>2024-02-06T19:43:52Z</published>
    <title>Building Retrieval Systems for the ClueWeb22-B Corpus</title>
    <summary>  The ClueWeb22 dataset containing nearly 10 billion documents was released in
2022 to support academic and industry research. The goal of this project was to
build retrieval baselines for the English section of the "super head" part
(category B) of this dataset. These baselines can then be used by the research
community to compare their systems and also to generate data to train/evaluate
new retrieval and ranking algorithms. The report covers sparse and dense first
stage retrievals as well as neural rerankers that were implemented for this
dataset. These systems are available as a service on a Carnegie Mellon
University cluster.
</summary>
    <author>
      <name>Harshit Mehrotra</name>
    </author>
    <author>
      <name>Jamie Callan</name>
    </author>
    <author>
      <name>Zhen Fan</name>
    </author>
    <link href="http://arxiv.org/abs/2402.04357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.04357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.07466v1</id>
    <updated>2024-02-12T07:59:28Z</updated>
    <published>2024-02-12T07:59:28Z</published>
    <title>VCR: Video representation for Contextual Retrieval</title>
    <summary>  Streamlining content discovery within media archives requires integrating
advanced data representations and effective visualization techniques for clear
communication of video topics to users. The proposed system addresses the
challenge of efficiently navigating large video collections by exploiting a
fusion of visual, audio, and textual features to accurately index and
categorize video content through a text-based method. Additionally, semantic
embeddings are employed to provide contextually relevant information and
recommendations to users, resulting in an intuitive and engaging exploratory
experience over our topics ontology map using OpenAI GPT-4.
</summary>
    <author>
      <name>Oron Nir</name>
    </author>
    <author>
      <name>Idan Vidra</name>
    </author>
    <author>
      <name>Avi Neeman</name>
    </author>
    <author>
      <name>Barak Kinarti</name>
    </author>
    <author>
      <name>Ariel Shamir</name>
    </author>
    <link href="http://arxiv.org/abs/2402.07466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.07466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.09130v1</id>
    <updated>2024-02-14T12:28:14Z</updated>
    <published>2024-02-14T12:28:14Z</published>
    <title>Recommendation Algorithm Based on Recommendation Sessions</title>
    <summary>  The enormous development of the Internet, both in the geographical scale and
in the area of using its possibilities in everyday life, determines the
creation and collection of huge amounts of data. Due to the scale, it is not
possible to analyse them using traditional methods, therefore it makes a
necessary to use modern methods and techniques. Such methods are provided,
among others, by the area of recommendations. The aim of this study is to
present a new algorithm in the area of recommendation systems, the algorithm
based on data from various sets of information, both static (categories of
objects, features of objects) and dynamic (user behaviour).
</summary>
    <author>
      <name>Michał Malinowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6084/m9.figshare.13634717</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6084/m9.figshare.13634717" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2402.08275</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 36th International Business Information
  Management Association (IBIMA) (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2402.09130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.09130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.15591v1</id>
    <updated>2024-02-23T20:16:13Z</updated>
    <published>2024-02-23T20:16:13Z</published>
    <title>RecWizard: A Toolkit for Conversational Recommendation with Modular,
  Portable Models and Interactive User Interface</title>
    <summary>  We present a new Python toolkit called RecWizard for Conversational
Recommender Systems (CRS). RecWizard offers support for development of models
and interactive user interface, drawing from the best practices of the
Huggingface ecosystems. CRS with RecWizard are modular, portable, interactive
and Large Language Models (LLMs)-friendly, to streamline the learning process
and reduce the additional effort for CRS research. For more comprehensive
information about RecWizard, please check our GitHub
https://github.com/McAuley-Lab/RecWizard.
</summary>
    <author>
      <name>Zeyuan Zhang</name>
    </author>
    <author>
      <name>Tanmay Laud</name>
    </author>
    <author>
      <name>Zihang He</name>
    </author>
    <author>
      <name>Xiaojie Chen</name>
    </author>
    <author>
      <name>Xinshuang Liu</name>
    </author>
    <author>
      <name>Zhouhang Xie</name>
    </author>
    <author>
      <name>Julian McAuley</name>
    </author>
    <author>
      <name>Zhankui He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI'24 Demo Track</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.15591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.15591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2402.16325v1</id>
    <updated>2024-02-26T06:13:24Z</updated>
    <published>2024-02-26T06:13:24Z</published>
    <title>Confidence Calibration for Recommender Systems and Its Applications</title>
    <summary>  Despite the importance of having a measure of confidence in recommendation
results, it has been surprisingly overlooked in the literature compared to the
accuracy of the recommendation. In this dissertation, I propose a model
calibration framework for recommender systems for estimating accurate
confidence in recommendation results based on the learned ranking scores.
Moreover, I subsequently introduce two real-world applications of confidence on
recommendations: (1) Training a small student model by treating the confidence
of a big teacher model as additional learning guidance, (2) Adjusting the
number of presented items based on the expected user utility estimated with
calibrated probability.
</summary>
    <author>
      <name>Wonbin Kweon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Doctoral Dissertation</arxiv:comment>
    <link href="http://arxiv.org/abs/2402.16325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2402.16325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.00520v1</id>
    <updated>2024-03-01T13:30:34Z</updated>
    <published>2024-03-01T13:30:34Z</published>
    <title>IAI MovieBot 2.0: An Enhanced Research Platform with Trainable Neural
  Components and Transparent User Modeling</title>
    <summary>  While interest in conversational recommender systems has been on the rise,
operational systems suitable for serving as research platforms for
comprehensive studies are currently lacking. This paper introduces an enhanced
version of the IAI MovieBot conversational movie recommender system, aiming to
evolve it into a robust and adaptable platform for conducting user-facing
experiments. The key highlights of this enhancement include the addition of
trainable neural components for natural language understanding and dialogue
policy, transparent and explainable modeling of user preferences, along with
improvements in the user interface and research infrastructure.
</summary>
    <author>
      <name>Nolwenn Bernard</name>
    </author>
    <author>
      <name>Ivica Kostric</name>
    </author>
    <author>
      <name>Krisztian Balog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3616855.3635699</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3616855.3635699" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 17th ACM International Conference on Web Search
  and Data Mining (WSDM '24), March 4--8, 2024, Merida, Mexico</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.00520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.00520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.01301v1</id>
    <updated>2024-03-02T19:55:38Z</updated>
    <published>2024-03-02T19:55:38Z</published>
    <title>Supplier Recommendation in Online Procurement</title>
    <summary>  Supply chain optimization is key to a healthy and profitable business. Many
companies use online procurement systems to agree contracts with suppliers. It
is vital that the most competitive suppliers are invited to bid for such
contracts. In this work, we propose a recommender system to assist with
supplier discovery in road freight online procurement. Our system is able to
provide personalized supplier recommendations, taking into account customer
needs and preferences. This is a novel application of recommender systems,
calling for design choices that fit the unique requirements of online
procurement. Our preliminary results, using real-world data, are promising.
</summary>
    <author>
      <name>Victor Coscrato</name>
    </author>
    <author>
      <name>Derek Bridge</name>
    </author>
    <link href="http://arxiv.org/abs/2403.01301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.01301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.02609v1</id>
    <updated>2024-03-05T02:53:24Z</updated>
    <published>2024-03-05T02:53:24Z</published>
    <title>Search Intenion Network for Personalized Query Auto-Completion in
  E-Commerce</title>
    <summary>  Query Auto-Completion(QAC), as an important part of the modern search engine,
plays a key role in complementing user queries and helping them refine their
search intentions.Today's QAC systems in real-world scenarios face two major
challenges:1)intention equivocality(IE): during the user's typing process,the
prefix often contains a combination of characters and subwords, which makes the
current intention ambiguous and difficult to model.2)intention transfer
(IT):previous works make personalized recommendations based on users'
historical sequences, but ignore the search intention transfer.However, the
current intention extracted from prefix may be contrary to the historical
preferences.
</summary>
    <author>
      <name>Wei Bao</name>
    </author>
    <author>
      <name>Mi Zhang</name>
    </author>
    <author>
      <name>Tao Zhang</name>
    </author>
    <author>
      <name>Chengfu Huo</name>
    </author>
    <link href="http://arxiv.org/abs/2403.02609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.02609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.06789v1</id>
    <updated>2024-03-11T15:04:55Z</updated>
    <published>2024-03-11T15:04:55Z</published>
    <title>SPLADE-v3: New baselines for SPLADE</title>
    <summary>  A companion to the release of the latest version of the SPLADE library. We
describe changes to the training structure and present our latest series of
models -- SPLADE-v3. We compare this new version to BM25, SPLADE++, as well as
re-rankers, and showcase its effectiveness via a meta-analysis over more than
40 query sets. SPLADE-v3 further pushes the limit of SPLADE models: it is
statistically significantly more effective than both BM25 and SPLADE++, while
comparing well to cross-encoder re-rankers. Specifically, it gets more than 40
MRR@10 on the MS MARCO dev set, and improves by 2% the out-of-domain results on
the BEIR benchmark.
</summary>
    <author>
      <name>Carlos Lassance</name>
    </author>
    <author>
      <name>Hervé Déjean</name>
    </author>
    <author>
      <name>Thibault Formal</name>
    </author>
    <author>
      <name>Stéphane Clinchant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.06789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.06789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.07732v1</id>
    <updated>2024-03-12T15:11:50Z</updated>
    <published>2024-03-12T15:11:50Z</published>
    <title>DESERE: The 1st Workshop on Decentralised Search and Recommendation</title>
    <summary>  The DESERE Workshop, our First Workshop on Decentralised Search and
Recommendation, offers a platform for researchers to explore and share
innovative ideas on decentralised web services, mainly focusing on three major
topics: (i) societal impact of decentralised systems: their effect on privacy,
policy, and regulation; (ii) decentralising applications: algorithmic and
performance challenges that arise from decentralisation; and (iii)
infrastructure to support decentralised systems and services: peer-to-peer
networks, routing, and performance evaluation tools
</summary>
    <author>
      <name>Mohamed Ragab</name>
    </author>
    <author>
      <name>Yury Savateev</name>
    </author>
    <author>
      <name>Wenjie Wang</name>
    </author>
    <author>
      <name>Reza Moosaei</name>
    </author>
    <author>
      <name>Thanassis Tiropanis</name>
    </author>
    <author>
      <name>Alexandra Poulovassilis</name>
    </author>
    <author>
      <name>Adriane Chapman</name>
    </author>
    <author>
      <name>Helen Oliver</name>
    </author>
    <author>
      <name>George Roussos</name>
    </author>
    <link href="http://arxiv.org/abs/2403.07732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.07732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.12092v1</id>
    <updated>2024-03-14T10:39:14Z</updated>
    <published>2024-03-14T10:39:14Z</published>
    <title>Methods for Matching English Language Addresses</title>
    <summary>  Addresses occupy a niche location within the landscape of textual data, due
to the positional importance carried by every word, and the geographical scope
it refers to. The task of matching addresses happens everyday and is present in
various fields like mail redirection, entity resolution, etc. Our work defines,
and formalizes a framework to generate matching and mismatching pairs of
addresses in the English language, and use it to evaluate various methods to
automatically perform address matching. These methods vary widely from distance
based approaches to deep learning models. By studying the Precision, Recall and
Accuracy metrics of these approaches, we obtain an understanding of the best
suited method for this setting of the address matching task.
</summary>
    <author>
      <name>Keshav Ramani</name>
    </author>
    <author>
      <name>Daniel Borrajo</name>
    </author>
    <link href="http://arxiv.org/abs/2403.12092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.12092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2403.15757v1</id>
    <updated>2024-03-23T08:03:50Z</updated>
    <published>2024-03-23T08:03:50Z</published>
    <title>User-Side Realization</title>
    <summary>  Users are dissatisfied with services. Since the service is not tailor-made
for a user, it is natural for dissatisfaction to arise. The problem is, that
even if users are dissatisfied, they often do not have the means to resolve
their dissatisfaction. The user cannot alter the source code of the service,
nor can they force the service provider to change. The user has no choice but
to remain dissatisfied or quit the service. User-side realization offers
proactive solutions to this problem by providing general algorithms to deal
with common problems on the user's side. These algorithms run on the user's
side and solve the problems without having the service provider change the
service itself.
</summary>
    <author>
      <name>Ryoma Sato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Doctoral Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2403.15757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2403.15757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.00903v1</id>
    <updated>2024-04-01T04:13:42Z</updated>
    <published>2024-04-01T04:13:42Z</published>
    <title>Maximizing User Experience with LLMOps-Driven Personalized
  Recommendation Systems</title>
    <summary>  The integration of LLMOps into personalized recommendation systems marks a
significant advancement in managing LLM-driven applications. This innovation
presents both opportunities and challenges for enterprises, requiring
specialized teams to navigate the complexity of engineering technology while
prioritizing data security and model interpretability. By leveraging LLMOps,
enterprises can enhance the efficiency and reliability of large-scale machine
learning models, driving personalized recommendations aligned with user
preferences. Despite ethical considerations, LLMOps is poised for widespread
adoption, promising more efficient and secure machine learning services that
elevate user experience and shape the future of personalized recommendation
systems.
</summary>
    <author>
      <name>Chenxi Shi</name>
    </author>
    <author>
      <name>Penghao Liang</name>
    </author>
    <author>
      <name>Yichao Wu</name>
    </author>
    <author>
      <name>Tong Zhan</name>
    </author>
    <author>
      <name>Zhengyu Jin</name>
    </author>
    <link href="http://arxiv.org/abs/2404.00903v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.00903v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.05825v1</id>
    <updated>2024-04-08T19:29:07Z</updated>
    <published>2024-04-08T19:29:07Z</published>
    <title>LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language
  Models and Doc-Level Embedding</title>
    <summary>  Recently embedding-based retrieval or dense retrieval have shown state of the
art results, compared with traditional sparse or bag-of-words based approaches.
This paper introduces a model-agnostic doc-level embedding framework through
large language model (LLM) augmentation. In addition, it also improves some
important components in the retrieval model training process, such as negative
sampling, loss function, etc. By implementing this LLM-augmented retrieval
framework, we have been able to significantly improve the effectiveness of
widely-used retriever models such as Bi-encoders (Contriever, DRAGON) and
late-interaction models (ColBERTv2), thereby achieving state-of-the-art results
on LoTTE datasets and BEIR datasets.
</summary>
    <author>
      <name>Mingrui Wu</name>
    </author>
    <author>
      <name>Sheng Cao</name>
    </author>
    <link href="http://arxiv.org/abs/2404.05825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.05825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.08134v1</id>
    <updated>2024-04-11T21:31:02Z</updated>
    <published>2024-04-11T21:31:02Z</published>
    <title>Extending Translate-Train for ColBERT-X to African Language CLIR</title>
    <summary>  This paper describes the submission runs from the HLTCOE team at the CIRAL
CLIR tasks for African languages at FIRE 2023. Our submissions use machine
translation models to translate the documents and the training passages, and
ColBERT-X as the retrieval model. Additionally, we present a set of unofficial
runs that use an alternative training procedure with a similar training
setting.
</summary>
    <author>
      <name>Eugene Yang</name>
    </author>
    <author>
      <name>Dawn J. Lawrie</name>
    </author>
    <author>
      <name>Paul McNamee</name>
    </author>
    <author>
      <name>James Mayfield</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures. System description paper for HLTCOE's
  participation in CIRAL@FIRE 2023</arxiv:comment>
    <link href="http://arxiv.org/abs/2404.08134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.08134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.08628v1</id>
    <updated>2024-04-12T17:46:13Z</updated>
    <published>2024-04-12T17:46:13Z</published>
    <title>Accessibility in Information Retrieval</title>
    <summary>  This paper introduces the concept of accessibility from the field of
transportation planning and adopts it within the context of Information
Retrieval (IR). An analogy is drawn between the fields, which motivates the
development of document accessibility measures for IR systems. Considering the
accessibility of documents within a collection given an IR System provides a
different perspective on the analysis and evaluation of such systems which
could be used to inform the design, tuning and management of current and future
IR systems.
</summary>
    <author>
      <name>Leif Azzopardi</name>
    </author>
    <author>
      <name>Vishwa Vinay</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-540-78646-7_46</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-540-78646-7_46" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Conference in Information Retrieval (ECIR) 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2404.08628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.08628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.08687v1</id>
    <updated>2024-04-09T08:33:43Z</updated>
    <published>2024-04-09T08:33:43Z</published>
    <title>A Survey of Reasoning for Substitution Relationships: Definitions,
  Methods, and Directions</title>
    <summary>  Substitute relationships are fundamental to people's daily lives across
various domains. This study aims to comprehend and predict substitute
relationships among products in diverse fields, extensively analyzing the
application of machine learning algorithms, natural language processing, and
other technologies. By comparing model methodologies across different domains,
such as defining substitutes, representing and learning substitute
relationships, and substitute reasoning, this study offers a methodological
foundation for delving deeper into substitute relationships. Through ongoing
research and innovation, we can further refine the personalization and accuracy
of substitute recommendation systems, thus advancing the development and
application of this field.
</summary>
    <author>
      <name>Anxin Yang</name>
    </author>
    <author>
      <name>Zhijuan Du</name>
    </author>
    <author>
      <name>Tao Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2404.08687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.08687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.08694v1</id>
    <updated>2024-04-10T07:51:50Z</updated>
    <published>2024-04-10T07:51:50Z</published>
    <title>Musical Listening Qualia: A Multivariate Approach</title>
    <summary>  French and American participants listened to new music stimuli and evaluated
the stimuli using either adjectives or quantitative musical dimensions. Results
were analyzed using correspondence analysis (CA), hierarchical cluster analysis
(HCA), multiple factor analysis (MFA), and partial least squares correlation
(PLSC). French and American listeners differed when they described the musical
stimuli using adjectives, but not when using the quantitative dimensions. The
present work serves as a case study in research methodology that allows for a
balance between relaxing experimental control and maintaining statistical
rigor.
</summary>
    <author>
      <name>Brendon Mizener</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JUNIA</arxiv:affiliation>
    </author>
    <author>
      <name>Mathilde Vandenberghe-Descamps</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JUNIA</arxiv:affiliation>
    </author>
    <author>
      <name>Hervé Abdi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JUNIA</arxiv:affiliation>
    </author>
    <author>
      <name>Sylvie Chollet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">JUNIA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/25742442.2022.2036074</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/25742442.2022.2036074" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Auditory Perception &amp; Cognition, 2022, 5 (1-2), pp.46-75.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2404.08694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.08694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.09091v2</id>
    <updated>2024-05-29T16:01:27Z</updated>
    <published>2024-04-13T22:18:14Z</published>
    <title>Semantic In-Domain Product Identification for Search Queries</title>
    <summary>  Accurate explicit and implicit product identification in search queries is
critical for enhancing user experiences, especially at a company like Adobe
which has over 50 products and covers queries across hundreds of tools. In this
work, we present a novel approach to training a product classifier from user
behavioral data. Our semantic model led to &gt;25% relative improvement in CTR
(click through rate) across the deployed surfaces; a &gt;50% decrease in null
rate; a 2x increase in the app cards surfaced, which helps drive product
visibility.
</summary>
    <author>
      <name>Sanat Sharma</name>
    </author>
    <author>
      <name>Jayant Kumar</name>
    </author>
    <author>
      <name>Twisha Naik</name>
    </author>
    <author>
      <name>Zhaoyu Lu</name>
    </author>
    <author>
      <name>Arvind Srikantan</name>
    </author>
    <author>
      <name>Tracy Holloway King</name>
    </author>
    <link href="http://arxiv.org/abs/2404.09091v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.09091v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.09253v1</id>
    <updated>2024-04-14T13:33:25Z</updated>
    <published>2024-04-14T13:33:25Z</published>
    <title>Competitive Retrieval: Going Beyond the Single Query</title>
    <summary>  Previous work on the competitive retrieval setting focused on a single-query
setting: document authors manipulate their documents so as to improve their
future ranking for a given query. We study a competitive setting where authors
opt to improve their document's ranking for multiple queries. We use game
theoretic analysis to prove that equilibrium does not necessarily exist. We
then empirically show that it is more difficult for authors to improve their
documents' rankings for multiple queries with a neural ranker than with a
state-of-the-art feature-based ranker. We also present an effective approach
for predicting the document most highly ranked in the next induced ranking.
</summary>
    <author>
      <name>Haya Nachimovsky</name>
    </author>
    <author>
      <name>Moshe Tennenholtz</name>
    </author>
    <author>
      <name>Fiana Raiber</name>
    </author>
    <author>
      <name>Oren Kurland</name>
    </author>
    <link href="http://arxiv.org/abs/2404.09253v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.09253v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2404.10371v1</id>
    <updated>2024-04-16T08:08:55Z</updated>
    <published>2024-04-16T08:08:55Z</published>
    <title>Promoting the linguistic diversity of TEI in the Maghreb and the Arab
  region</title>
    <summary>  The project targets both oral corpus and the rich text resources written in
the Maghreb region. It focuses particularly on the continuity, for more than 12
centuries, of a classical still alive Arabic language and on the extreme
hybridization of vernacular languages sustained by the rich Libyan, Roman,
Hebrew and Ottoman influences and by the more recent French, Spanish and
Italian linguistic interference. In short, the Maghreb is a place of extremely
abundant, but much unexploited, textual studies.
</summary>
    <author>
      <name>Henri Hudrisier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Chaire Unesco-ITEN</arxiv:affiliation>
    </author>
    <author>
      <name>Rachid Zghibi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISD</arxiv:affiliation>
    </author>
    <author>
      <name>Sihem Zghidi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISD</arxiv:affiliation>
    </author>
    <author>
      <name>Mokhtar Ben Henda</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MICA, ISD, GRESIC, ISIC, Chaire Unesco-ITEN</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/2404.10371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2404.10371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.02525v2</id>
    <updated>2024-06-07T11:50:16Z</updated>
    <published>2024-05-03T23:48:53Z</published>
    <title>RLStop: A Reinforcement Learning Stopping Method for TAR</title>
    <summary>  We present RLStop, a novel Technology Assisted Review (TAR) stopping rule
based on reinforcement learning that helps minimise the number of documents
that need to be manually reviewed within TAR applications. RLStop is trained on
example rankings using a reward function to identify the optimal point to stop
examining documents. Experiments at a range of target recall levels on multiple
benchmark datasets (CLEF e-Health, TREC Total Recall, and Reuters RCV1)
demonstrated that RLStop substantially reduces the workload required to screen
a document collection for relevance. RLStop outperforms a wide range of
alternative approaches, achieving performance close to the maximum possible for
the task under some circumstances.
</summary>
    <author>
      <name>Reem Bin-Hezam</name>
    </author>
    <author>
      <name>Mark Stevenson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3626772.3657911</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3626772.3657911" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at SIGIR 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.02525v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.02525v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.03382v1</id>
    <updated>2024-05-06T11:41:24Z</updated>
    <published>2024-05-06T11:41:24Z</published>
    <title>Improving (Re-)Usability of Musical Datasets: An Overview of the DOREMUS
  Project</title>
    <summary>  DOREMUS works on a better description of music by building new tools to link
and explore the data of three French institutions. This paper gives an overview
of the data model based on FRBRoo, explains the conversion and linking
processes using linked data technologies and presents the prototypes created to
consume the data according to the web users' needs.
</summary>
    <author>
      <name>Pasquale Lisena</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WEB3</arxiv:affiliation>
    </author>
    <author>
      <name>Manel Achichi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WEB3</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Choffé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BnF</arxiv:affiliation>
    </author>
    <author>
      <name>Cécile Cecconi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WEB3</arxiv:affiliation>
    </author>
    <author>
      <name>Konstantin Todorov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WEB3</arxiv:affiliation>
    </author>
    <author>
      <name>Bernard Jacquemin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GERIICO</arxiv:affiliation>
    </author>
    <author>
      <name>Raphaël Troncy</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1515/bfp-2018-0023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1515/bfp-2018-0023" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bibliothek Forschung und Praxis, 2018, 42 (2), pp.194-205.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2405.03382v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.03382v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.11612v2</id>
    <updated>2024-07-16T15:47:13Z</updated>
    <published>2024-05-19T17:04:39Z</published>
    <title>Sociotechnical Implications of Generative Artificial Intelligence for
  Information Access</title>
    <summary>  Robust access to trustworthy information is a critical need for society with
implications for knowledge production, public health education, and promoting
informed citizenry in democratic societies. Generative AI technologies may
enable new ways to access information and improve effectiveness of existing
information retrieval systems but we are only starting to understand and
grapple with their long-term social implications. In this chapter, we present
an overview of some of the systemic consequences and risks of employing
generative AI in the context of information access. We also provide
recommendations for evaluation and mitigation, and discuss challenges for
future research.
</summary>
    <author>
      <name>Bhaskar Mitra</name>
    </author>
    <author>
      <name>Henriette Cramer</name>
    </author>
    <author>
      <name>Olya Gurevich</name>
    </author>
    <link href="http://arxiv.org/abs/2405.11612v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.11612v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.12715v1</id>
    <updated>2024-05-21T12:16:20Z</updated>
    <published>2024-05-21T12:16:20Z</published>
    <title>RecGPT: Generative Pre-training for Text-based Recommendation</title>
    <summary>  We present the first domain-adapted and fully-trained large language model,
RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for
text-based recommendation. Experimental results on rating prediction and
sequential recommendation tasks show that our model, RecGPT-7B-Instruct,
outperforms previous strong baselines. We are releasing our RecGPT models as
well as their pre-training and fine-tuning datasets to facilitate future
research and downstream applications in text-based recommendation. Public
"huggingface" links to our RecGPT models and datasets are available at:
https://github.com/VinAIResearch/RecGPT
</summary>
    <author>
      <name>Hoang Ngo</name>
    </author>
    <author>
      <name>Dat Quoc Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the ACL 2024 main conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.12715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.12715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.15520v1</id>
    <updated>2024-05-24T13:03:20Z</updated>
    <published>2024-05-24T13:03:20Z</published>
    <title>From Data Complexity to User Simplicity: A Framework for Linked Open
  Data Reconciliation and Serendipitous Discovery</title>
    <summary>  This article introduces a novel software solution to create a Web portal to
align Linked Open Data sources and provide user-friendly interfaces for
serendipitous discovery. We present the Polifonia Web portal as a motivating
scenario and case study to address research problems such as data
reconciliation and serving generous interfaces in the music heritage domain.
</summary>
    <author>
      <name>Marco Grasso</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bologna</arxiv:affiliation>
    </author>
    <author>
      <name>Giulia Renda</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bologna</arxiv:affiliation>
    </author>
    <author>
      <name>Marilena Daquino</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bologna</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, part of "XIII Convegno Annuale AIUCD 2024
  Proceedings"</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.15520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.15520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.15791v1</id>
    <updated>2024-05-04T13:26:26Z</updated>
    <published>2024-05-04T13:26:26Z</published>
    <title>Learning-based models for building user profiles for personalized
  information access</title>
    <summary>  This study contributes to the literature by considering the difference in
vocabulary used to express document content and information needs. Users are
integrated into all research phases in order to provide them with relevant
information adapted to their context and their preferences meeting their
precise needs. To better express document content and information during this
phase, deep learning models are employed to learn complex representations of
documents and queries. These models can capture hierarchical, sequential, or
attention-based patterns in textual data.
</summary>
    <author>
      <name>Minyar Sassi Hidri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.28945/5275</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.28945/5275" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 18 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interdisciplinary Journal of Information, Knowledge, and
  Management, Volume 19, 2024, pp. 010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2405.15791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.15791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2405.18011v1</id>
    <updated>2024-05-28T09:53:11Z</updated>
    <published>2024-05-28T09:53:11Z</published>
    <title>Rethinking Recommender Systems: Cluster-based Algorithm Selection</title>
    <summary>  Cluster-based algorithm selection deals with selecting recommendation
algorithms on clusters of users to obtain performance gains. No studies have
been attempted for many combinations of clustering approaches and
recommendation algorithms. We want to show that clustering users prior to
algorithm selection increases the performance of recommendation algorithms. Our
study covers eight datasets, four clustering approaches, and eight
recommendation algorithms. We select the best performing recommendation
algorithm for each cluster. Our work shows that cluster-based algorithm
selection is an effective technique for optimizing recommendation algorithm
performance. For five out of eight datasets, we report an increase in nDCG@10
between 19.28% (0.032) and 360.38% (0.191) compared to algorithm selection
without prior clustering.
</summary>
    <author>
      <name>Andreas Lizenberger</name>
    </author>
    <author>
      <name>Ferdinand Pfeifer</name>
    </author>
    <author>
      <name>Bastian Polewka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2405.18011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2405.18011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.00198v1</id>
    <updated>2024-05-31T21:19:41Z</updated>
    <published>2024-05-31T21:19:41Z</published>
    <title>ImplicitSLIM and How it Improves Embedding-based Collaborative Filtering</title>
    <summary>  We present ImplicitSLIM, a novel unsupervised learning approach for sparse
high-dimensional data, with applications to collaborative filtering. Sparse
linear methods (SLIM) and their variations show outstanding performance, but
they are memory-intensive and hard to scale. ImplicitSLIM improves
embedding-based models by extracting embeddings from SLIM-like models in a
computationally cheap and memory-efficient way, without explicit learning of
heavy SLIM-like models. We show that ImplicitSLIM improves performance and
speeds up convergence for both state of the art and classical collaborative
filtering methods. The source code for ImplicitSLIM, related models, and
applications is available at https://github.com/ilya-shenbin/ImplicitSLIM.
</summary>
    <author>
      <name>Ilya Shenbin</name>
    </author>
    <author>
      <name>Sergey Nikolenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published as a conference paper at ICLR 2024; authors' version</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.00198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.00198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.01603v1</id>
    <updated>2024-05-24T07:43:00Z</updated>
    <published>2024-05-24T07:43:00Z</published>
    <title>Privacy-preserving recommender system using the data collaboration
  analysis for distributed datasets</title>
    <summary>  In order to provide high-quality recommendations for users, it is desirable
to share and integrate multiple datasets held by different parties. However,
when sharing such distributed datasets, we need to protect personal and
confidential information contained in the datasets. To this end, we establish a
framework for privacy-preserving recommender systems using the data
collaboration analysis of distributed datasets. Numerical experiments with two
public rating datasets demonstrate that our privacy-preserving method for
rating prediction can improve the prediction accuracy for distributed datasets.
This study opens up new possibilities for privacy-preserving techniques in
recommender systems.
</summary>
    <author>
      <name>Tomoya Yanagi</name>
    </author>
    <author>
      <name>Shunnosuke Ikeda</name>
    </author>
    <author>
      <name>Noriyoshi Sukegawa</name>
    </author>
    <author>
      <name>Yuichi Takano</name>
    </author>
    <link href="http://arxiv.org/abs/2406.01603v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.01603v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.05977v1</id>
    <updated>2024-06-10T02:29:35Z</updated>
    <published>2024-06-10T02:29:35Z</published>
    <title>Weighted KL-Divergence for Document Ranking Model Refinement</title>
    <summary>  Transformer-based retrieval and reranking models for text document search are
often refined through knowledge distillation together with contrastive
learning. A tight distribution matching between the teacher and student models
can be hard as over-calibration may degrade training effectiveness when a
teacher does not perform well. This paper contrastively reweights KL divergence
terms to prioritize the alignment between a student and a teacher model for
proper separation of positive and negative documents. This paper analyzes and
evaluates the proposed loss function on the MS MARCO and BEIR datasets to
demonstrate its effectiveness in improving the relevance of tested student
models.
</summary>
    <author>
      <name>Yingrui Yang</name>
    </author>
    <author>
      <name>Yifan Qiao</name>
    </author>
    <author>
      <name>Shanxiu He</name>
    </author>
    <author>
      <name>Tao Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2406.05977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.05977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.06031v1</id>
    <updated>2024-06-10T05:43:55Z</updated>
    <published>2024-06-10T05:43:55Z</published>
    <title>A WT-ResNet based fault diagnosis model for the urban rail train
  transmission system</title>
    <summary>  This study presents a novel fault diagnosis model for urban rail transit
systems based on Wavelet Transform Residual Neural Network (WT-ResNet). The
model integrates the advantages of wavelet transform for feature extraction and
ResNet for pattern recognition, offering enhanced diagnostic accuracy and
robustness. Experimental results demonstrate the effectiveness of the proposed
model in identifying faults in urban rail trains, paving the way for improved
maintenance strategies and reduced downtime.
</summary>
    <author>
      <name>Zuyu Cheng</name>
    </author>
    <author>
      <name>Zhengcai Zhao</name>
    </author>
    <author>
      <name>Yixiao Wang</name>
    </author>
    <author>
      <name>Wentao Guo</name>
    </author>
    <author>
      <name>Yufei Wang</name>
    </author>
    <author>
      <name>Xiang Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages,10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.06031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.06031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.07331v1</id>
    <updated>2024-06-11T15:01:03Z</updated>
    <published>2024-06-11T15:01:03Z</published>
    <title>Text Information Retrieval in Tetun: A Preliminary Study</title>
    <summary>  Tetun is one of Timor-Leste's official languages alongside Portuguese. It is
a low-resource language with over 932,400 speakers that started developing when
Timor-Leste restored its independence in 2002. The media mainly uses Tetun, and
more than ten national online newspapers actively broadcast news in Tetun every
day. However, since information retrieval-based solutions for Tetun do not
exist, finding Tetun information on the internet is challenging. This work aims
to investigate and develop solutions that can enable the application of
information retrieval techniques to develop search solutions for Tetun. We
present a preliminary result of an experiment conducted on the task of ad-hoc
retrieval in Tetun.
</summary>
    <author>
      <name>Gabriel de Jesus</name>
    </author>
    <link href="http://arxiv.org/abs/2406.07331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.07331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.09323v1</id>
    <updated>2024-06-13T17:01:28Z</updated>
    <published>2024-06-13T17:01:28Z</published>
    <title>Master of Disaster: A Disaster-Related Event Monitoring System From News
  Streams</title>
    <summary>  The need for a disaster-related event monitoring system has arisen due to the
societal and economic impact caused by the increasing number of severe disaster
events. An event monitoring system should be able to extract event-related
information from texts, and discriminates event instances. We demonstrate our
open-source event monitoring system, namely, Master of Disaster (MoD), which
receives news streams, extracts event information, links extracted information
to a knowledge graph (KG), in this case Wikidata, and discriminates event
instances visually. The goal of event visualization is to group event mentions
referring to the same real-world event instance so that event instance
discrimination can be achieved by visual screening.
</summary>
    <author>
      <name>Junbo Huang</name>
    </author>
    <author>
      <name>Ricardo Usbeck</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.09323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.09323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.10239v1</id>
    <updated>2024-06-04T05:52:14Z</updated>
    <published>2024-06-04T05:52:14Z</published>
    <title>Predict Click-Through Rates with Deep Interest Network Model in
  E-commerce Advertising</title>
    <summary>  This paper proposes new methods to enhance click-through rate (CTR)
prediction models using the Deep Interest Network (DIN) model, specifically
applied to the advertising system of Alibaba's Taobao platform. Unlike
traditional deep learning approaches, this research focuses on localized user
behavior activation for tailored ad targeting by leveraging extensive user
behavior data. Compared to traditional models, this method demonstrates
superior ability to handle diverse and dynamic user data, thereby improving the
efficiency of ad systems and increasing revenue.
</summary>
    <author>
      <name>Chang Zhou</name>
    </author>
    <author>
      <name>Yang Zhao</name>
    </author>
    <author>
      <name>Yuelin Zou</name>
    </author>
    <author>
      <name>Jin Cao</name>
    </author>
    <author>
      <name>Wenhan Fan</name>
    </author>
    <author>
      <name>Yi Zhao</name>
    </author>
    <author>
      <name>Chiyu Cheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by the 5th International Conference on Information Science,
  Parallel and Distributed Systems (ISPDS 2024), 2024 IEEE</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.10239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.10239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.10245v1</id>
    <updated>2024-06-07T10:30:43Z</updated>
    <published>2024-06-07T10:30:43Z</published>
    <title>On conceptualisation and an overview of learning path recommender
  systems in e-learning</title>
    <summary>  The use of e-learning systems has a long tradition, where students can study
online helped by a system. In this context, the use of recommender systems is
relatively new. In our research project, we investigated various ways to create
a recommender system. They all aim at facilitating the learning and
understanding of a student. We present a common concept of the learning path
and its learning indicators and embed 5 different recommenders in this context.
</summary>
    <author>
      <name>A. Fuster-López</name>
    </author>
    <author>
      <name>J. M. Cruz</name>
    </author>
    <author>
      <name>P. Guerrero-García</name>
    </author>
    <author>
      <name>E. M. T. Hendrix</name>
    </author>
    <author>
      <name>A. Košir</name>
    </author>
    <author>
      <name>I. Nowak</name>
    </author>
    <author>
      <name>L. Oneto</name>
    </author>
    <author>
      <name>S. Sirmakessis</name>
    </author>
    <author>
      <name>M. F. Pacheco</name>
    </author>
    <author>
      <name>F. P. Fernandes</name>
    </author>
    <author>
      <name>A. I. Pereira</name>
    </author>
    <link href="http://arxiv.org/abs/2406.10245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.10245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2406.16629v1</id>
    <updated>2024-06-24T13:23:00Z</updated>
    <published>2024-06-24T13:23:00Z</published>
    <title>Meta-experiments: Improving experimentation through experimentation</title>
    <summary>  A/B testing is widexly used in the industry to optimize customer facing
websites. Many companies employ experimentation specialists to facilitate and
improve the process of A/B testing. Here, we present the application of A/B
testing to this improvement effort itself, by running experiments on the
experimentation process, which we call 'meta-experiments'. We discuss the
challenges of this approach using the example of one of our meta-experiments,
which helped experimenters to run more sufficiently powered A/B tests. We also
point out the benefits of 'dog fooding' for the experimentation specialists
when running their own experiments.
</summary>
    <author>
      <name>Melanie J. I. Müller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2406.16629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2406.16629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.00038v1</id>
    <updated>2024-05-28T20:14:18Z</updated>
    <published>2024-05-28T20:14:18Z</published>
    <title>JungleGPT: Designing and Optimizing Compound AI Systems for E-Commerce</title>
    <summary>  LLMs have significantly advanced the e-commerce industry by powering
applications such as personalized recommendations and customer service.
However, most current efforts focus solely on monolithic LLMs and fall short in
addressing the complexity and scale of real-world e-commerce scenarios. In this
work, we present JungleGPT, the first compound AI system tailored for
real-world e-commerce applications. We outline the system's design and the
techniques used to optimize its performance for practical use cases, which have
proven to reduce inference costs to less than 1% of what they would be with a
powerful, monolithic LLM.
</summary>
    <author>
      <name>Sherry Ruan</name>
    </author>
    <author>
      <name>Tian Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2407.00038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.00038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.00834v1</id>
    <updated>2024-06-30T21:07:11Z</updated>
    <published>2024-06-30T21:07:11Z</published>
    <title>Prediction of Sentinel-2 multi-band imagery with attention BiLSTM for
  continuous earth surface monitoring</title>
    <summary>  Continuous monitoring of crops and forecasting crop conditions through time
series analysis is crucial for effective agricultural management. This study
proposes a framework based on an attention Bidirectional Long Short-Term Memory
(BiLSTM) network for predicting multiband images. Our model can forecast target
images on user-defined dates, including future dates and periods characterized
by persistent cloud cover. By focusing on short sequences within a
sequence-to-one forecasting framework, the model leverages advanced attention
mechanisms to enhance prediction accuracy. Our experimental results demonstrate
the model's superior performance in predicting NDVI, multiple vegetation
indices, and all Sentinel-2 bands, highlighting its potential for improving
remote sensing data continuity and reliability.
</summary>
    <author>
      <name>Weiying Zhao</name>
    </author>
    <author>
      <name>Natalia Efremova</name>
    </author>
    <link href="http://arxiv.org/abs/2407.00834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.00834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.01712v2</id>
    <updated>2024-07-19T04:16:03Z</updated>
    <published>2024-06-21T02:31:03Z</published>
    <title>A Survey of Retrieval Algorithms in Ad and Content Recommendation
  Systems</title>
    <summary>  This survey examines the most effective retrieval algorithms utilized in ad
recommendation and content recommendation systems. Ad targeting algorithms rely
on detailed user profiles and behavioral data to deliver personalized
advertisements, thereby driving revenue through targeted placements.
Conversely, organic retrieval systems aim to improve user experience by
recommending content that matches user preferences. This paper compares these
two applications and explains the most effective methods employed in each.
</summary>
    <author>
      <name>Yu Zhao</name>
    </author>
    <author>
      <name>Fang Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2407.01712v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.01712v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.02793v3</id>
    <updated>2024-11-26T06:34:55Z</updated>
    <published>2024-07-03T03:42:13Z</published>
    <title>Learning Positional Attention for Sequential Recommendation</title>
    <summary>  Self-attention-based networks have achieved remarkable performance in
sequential recommendation tasks. A crucial component of these models is
positional encoding. In this study, we delve into the learned positional
embedding, demonstrating that it often captures the distance between tokens.
Building on this insight, we introduce novel attention models that directly
learn positional relations. Extensive experiments reveal that our proposed
models, \textbf{PARec} and \textbf{FPARec} outperform previous
self-attention-based approaches. The code can be found here:
https://github.com/NetEase-Media/FPARec.
</summary>
    <author>
      <name>Fan Luo</name>
    </author>
    <author>
      <name>Haibo He</name>
    </author>
    <author>
      <name>Juan Zhang</name>
    </author>
    <author>
      <name>Shenghui Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2407.02793v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.02793v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.02839v1</id>
    <updated>2024-07-03T06:34:56Z</updated>
    <published>2024-07-03T06:34:56Z</published>
    <title>CRUISE on Quantum Computing for Feature Selection in Recommender Systems</title>
    <summary>  Using Quantum Computers to solve problems in Recommender Systems that
classical computers cannot address is a worthwhile research topic. In this
paper, we use Quantum Annealers to address the feature selection problem in
recommendation algorithms. This feature selection problem is a Quadratic
Unconstrained Binary Optimization(QUBO) problem. By incorporating
Counterfactual Analysis, we significantly improve the performance of the
item-based KNN recommendation algorithm compared to using pure Mutual
Information. Extensive experiments have demonstrated that the use of
Counterfactual Analysis holds great promise for addressing such problems.
</summary>
    <author>
      <name>Jiayang Niu</name>
    </author>
    <author>
      <name>Jie Li</name>
    </author>
    <author>
      <name>Ke Deng</name>
    </author>
    <author>
      <name>Yongli Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted by QuantumCLEF 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2407.02839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.02839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.03618v1</id>
    <updated>2024-07-04T04:01:05Z</updated>
    <published>2024-07-04T04:01:05Z</published>
    <title>BM25S: Orders of magnitude faster lexical search via eager sparse
  scoring</title>
    <summary>  We introduce BM25S, an efficient Python-based implementation of BM25 that
only depends on Numpy and Scipy. BM25S achieves up to a 500x speedup compared
to the most popular Python-based framework by eagerly computing BM25 scores
during indexing and storing them into sparse matrices. It also achieves
considerable speedups compared to highly optimized Java-based implementations,
which are used by popular commercial products. Finally, BM25S reproduces the
exact implementation of five BM25 variants based on Kamphuis et al. (2020) by
extending eager scoring to non-sparse variants using a novel score shifting
method. The code can be found at https://github.com/xhluca/bm25s
</summary>
    <author>
      <name>Xing Han Lù</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/2407.03618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.03618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.04577v2</id>
    <updated>2024-07-09T16:58:07Z</updated>
    <published>2024-07-05T15:12:14Z</published>
    <title>Optimizing Nepali PDF Extraction: A Comparative Study of Parser and OCR
  Technologies</title>
    <summary>  This research compares PDF parsing and Optical Character Recognition (OCR)
methods for extracting Nepali content from PDFs. PDF parsing offers fast and
accurate extraction but faces challenges with non-Unicode Nepali fonts. OCR,
specifically PyTesseract, overcomes these challenges, providing versatility for
both digital and scanned PDFs. The study reveals that while PDF parsers are
faster, their accuracy fluctuates based on PDF types. In contrast, OCRs, with a
focus on PyTesseract, demonstrate consistent accuracy at the expense of
slightly longer extraction times. Considering the project's emphasis on Nepali
PDFs, PyTesseract emerges as the most suitable library, balancing extraction
speed and accuracy.
</summary>
    <author>
      <name>Prabin Paudel</name>
    </author>
    <author>
      <name>Supriya Khadka</name>
    </author>
    <author>
      <name>Ranju G. C.</name>
    </author>
    <author>
      <name>Rahul Shah</name>
    </author>
    <link href="http://arxiv.org/abs/2407.04577v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.04577v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.05836v1</id>
    <updated>2024-07-08T11:36:17Z</updated>
    <published>2024-07-08T11:36:17Z</published>
    <title>Academic Article Recommendation Using Multiple Perspectives</title>
    <summary>  We argue that Content-based filtering (CBF) and Graph-based methods (GB)
complement one another in Academic Search recommendations. The scientific
literature can be viewed as a conversation between authors and the audience.
CBF uses abstracts to infer authors' positions, and GB uses citations to infer
responses from the audience. In this paper, we describe nine differences
between CBF and GB, as well as synergistic opportunities for hybrid
combinations. Two embeddings will be used to illustrate these opportunities:
(1) Specter, a CBF method based on BERT-like deepnet encodings of abstracts,
and (2) ProNE, a GB method based on spectral clustering of more than 200M
papers and 2B citations from Semantic Scholar.
</summary>
    <author>
      <name>Kenneth Church</name>
    </author>
    <author>
      <name>Omar Alonso</name>
    </author>
    <author>
      <name>Peter Vickers</name>
    </author>
    <author>
      <name>Jiameng Sun</name>
    </author>
    <author>
      <name>Abteen Ebrahimi</name>
    </author>
    <author>
      <name>Raman Chandrasekar</name>
    </author>
    <link href="http://arxiv.org/abs/2407.05836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.05836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.08942v1</id>
    <updated>2024-07-12T02:58:07Z</updated>
    <published>2024-07-12T02:58:07Z</published>
    <title>A Neural Matrix Decomposition Recommender System Model based on the
  Multimodal Large Language Model</title>
    <summary>  Recommendation systems have become an important solution to information
search problems. This article proposes a neural matrix factorization
recommendation system model based on the multimodal large language model called
BoNMF. This model combines BoBERTa's powerful capabilities in natural language
processing, ViT in computer in vision, and neural matrix decomposition
technology. By capturing the potential characteristics of users and items, and
after interacting with a low-dimensional matrix composed of user and item IDs,
the neural network outputs the results. recommend. Cold start and ablation
experimental results show that the BoNMF model exhibits excellent performance
on large public data sets and significantly improves the accuracy of
recommendations.
</summary>
    <author>
      <name>Ao Xiang</name>
    </author>
    <author>
      <name>Bingjie Huang</name>
    </author>
    <author>
      <name>Xinyu Guo</name>
    </author>
    <author>
      <name>Haowei Yang</name>
    </author>
    <author>
      <name>Tianyao Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2407.08942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.08942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.09394v1</id>
    <updated>2024-07-12T16:18:00Z</updated>
    <published>2024-07-12T16:18:00Z</published>
    <title>PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with
  User-Centric Agents</title>
    <summary>  Large Language Models (LLMs) struggle with generating reliable outputs due to
outdated knowledge and hallucinations. Retrieval-Augmented Generation (RAG)
models address this by enhancing LLMs with external knowledge, but often fail
to personalize the retrieval process. This paper introduces PersonaRAG, a novel
framework incorporating user-centric agents to adapt retrieval and generation
based on real-time user data and interactions. Evaluated across various
question answering datasets, PersonaRAG demonstrates superiority over baseline
models, providing tailored answers to user needs. The results suggest promising
directions for user-adapted information retrieval systems.
</summary>
    <author>
      <name>Saber Zerhoudi</name>
    </author>
    <author>
      <name>Michael Granitzer</name>
    </author>
    <link href="http://arxiv.org/abs/2407.09394v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.09394v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.12325v1</id>
    <updated>2024-07-17T05:50:32Z</updated>
    <published>2024-07-17T05:50:32Z</published>
    <title>Optimizing Query Generation for Enhanced Document Retrieval in RAG</title>
    <summary>  Large Language Models (LLMs) excel in various language tasks but they often
generate incorrect information, a phenomenon known as "hallucinations".
Retrieval-Augmented Generation (RAG) aims to mitigate this by using document
retrieval for accurate responses. However, RAG still faces hallucinations due
to vague queries. This study aims to improve RAG by optimizing query generation
with a query-document alignment score, refining queries using LLMs for better
precision and efficiency of document retrieval. Experiments have shown that our
approach improves document retrieval, resulting in an average accuracy gain of
1.6%.
</summary>
    <author>
      <name>Hamin Koo</name>
    </author>
    <author>
      <name>Minseon Kim</name>
    </author>
    <author>
      <name>Sung Ju Hwang</name>
    </author>
    <link href="http://arxiv.org/abs/2407.12325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.12325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.18383v1</id>
    <updated>2024-07-25T20:36:20Z</updated>
    <published>2024-07-25T20:36:20Z</published>
    <title>Supporting Evidence-Based Medicine by Finding Both Relevant and
  Significant Works</title>
    <summary>  In this paper, we present a new approach to improving the relevance and
reliability of medical IR, which builds upon the concept of Level of Evidence
(LoE). LoE framework categorizes medical publications into 7 distinct levels
based on the underlying empirical evidence. Despite LoE framework's relevance
in medical research and evidence-based practice, only few medical publications
explicitly state their LoE. Therefore, we develop a classification model for
automatically assigning LoE to medical publications, which successfully
classifies over 26 million documents in MEDLINE database into LoE classes. The
subsequent retrieval experiments on TREC PM datasets show substantial
improvements in retrieval relevance, when LoE is used as a search filter.
</summary>
    <author>
      <name>Sameh Frihat</name>
    </author>
    <author>
      <name>Norbert Fuhr</name>
    </author>
    <link href="http://arxiv.org/abs/2407.18383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.18383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.20856v1</id>
    <updated>2024-07-30T14:31:53Z</updated>
    <published>2024-07-30T14:31:53Z</published>
    <title>Learn by Selling: Equipping Large Language Models with Product Knowledge
  for Context-Driven Recommendations</title>
    <summary>  The rapid evolution of large language models (LLMs) has opened up new
possibilities for applications such as context-driven product recommendations.
However, the effectiveness of these models in this context is heavily reliant
on their comprehensive understanding of the product inventory. This paper
presents a novel approach to equipping LLMs with product knowledge by training
them to respond contextually to synthetic search queries that include product
IDs. We delve into an extensive analysis of this method, evaluating its
effectiveness, outlining its benefits, and highlighting its constraints. The
paper also discusses the potential improvements and future directions for this
approach, providing a comprehensive understanding of the role of LLMs in
product recommendations.
</summary>
    <author>
      <name>Sarthak Anand</name>
    </author>
    <author>
      <name>Yutong Jiang</name>
    </author>
    <author>
      <name>Giorgi Kokaia</name>
    </author>
    <link href="http://arxiv.org/abs/2407.20856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.20856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.00166v1</id>
    <updated>2024-07-31T21:30:36Z</updated>
    <published>2024-07-31T21:30:36Z</published>
    <title>Review of Explainable Graph-Based Recommender Systems</title>
    <summary>  Explainability of recommender systems has become essential to ensure users'
trust and satisfaction. Various types of explainable recommender systems have
been proposed including explainable graph-based recommender systems. This
review paper discusses state-of-the-art approaches of these systems and
categorizes them based on three aspects: learning methods, explaining methods,
and explanation types. It also explores the commonly used datasets,
explainability evaluation methods, and future directions of this research area.
Compared with the existing review papers, this paper focuses on explainability
based on graphs and covers the topics required for developing novel explainable
graph-based recommender systems.
</summary>
    <author>
      <name>Thanet Markchom</name>
    </author>
    <author>
      <name>Huizhi Liang</name>
    </author>
    <author>
      <name>James Ferryman</name>
    </author>
    <link href="http://arxiv.org/abs/2408.00166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.00166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.05330v2</id>
    <updated>2024-08-22T02:48:34Z</updated>
    <published>2024-08-09T20:36:40Z</published>
    <title>Neural Machine Unranking</title>
    <summary>  We tackle the problem of machine unlearning within neural information
retrieval, termed Neural Machine UnRanking (NuMuR) for short. Many of the
mainstream task- or model-agnostic approaches for machine unlearning were
designed for classification tasks. First, we demonstrate that these methods
perform poorly on NuMuR tasks due to the unique challenges posed by neural
information retrieval. Then, we develop a methodology for NuMuR named
Contrastive and Consistent Loss (CoCoL), which effectively balances the
objectives of data forgetting and model performance retention. Experimental
results demonstrate that CoCoL facilitates more effective and controllable data
removal than existing techniques.
</summary>
    <author>
      <name>Jingrui Hou</name>
    </author>
    <author>
      <name>Axel Finke</name>
    </author>
    <author>
      <name>Georgina Cosma</name>
    </author>
    <link href="http://arxiv.org/abs/2408.05330v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.05330v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.05344v1</id>
    <updated>2024-08-09T21:21:15Z</updated>
    <published>2024-08-09T21:21:15Z</published>
    <title>AI-assisted Coding with Cody: Lessons from Context Retrieval and
  Evaluation for Code Recommendations</title>
    <summary>  In this work, we discuss a recently popular type of recommender system: an
LLM-based coding assistant. Connecting the task of providing code
recommendations in multiple formats to traditional RecSys challenges, we
outline several similarities and differences due to domain specifics. We
emphasize the importance of providing relevant context to an LLM for this use
case and discuss lessons learned from context enhancements &amp; offline and online
evaluation of such AI-assisted coding systems.
</summary>
    <author>
      <name>Jan Hartman</name>
    </author>
    <author>
      <name>Rishabh Mehrotra</name>
    </author>
    <author>
      <name>Hitesh Sagtani</name>
    </author>
    <author>
      <name>Dominic Cooney</name>
    </author>
    <author>
      <name>Rafal Gajdulewicz</name>
    </author>
    <author>
      <name>Beyang Liu</name>
    </author>
    <author>
      <name>Julie Tibshirani</name>
    </author>
    <author>
      <name>Quinn Slack</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3640457.3688060</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3640457.3688060" rel="related"/>
    <link href="http://arxiv.org/abs/2408.05344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.05344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.06345v1</id>
    <updated>2024-07-23T08:15:55Z</updated>
    <published>2024-07-23T08:15:55Z</published>
    <title>Deep Learning based Key Information Extraction from Business Documents:
  Systematic Literature Review</title>
    <summary>  Extracting key information from documents represents a large portion of
business workloads and therefore offers a high potential for efficiency
improvements and process automation. With recent advances in deep learning, a
plethora of deep learning-based approaches for Key Information Extraction have
been proposed under the umbrella term Document Understanding that enable the
processing of complex business documents. The goal of this systematic
literature review is an in-depth analysis of existing approaches in this domain
and the identification of opportunities for further research. To this end, 96
approaches published between 2017 and 2023 are analyzed in this study.
</summary>
    <author>
      <name>Alexander Rombach</name>
    </author>
    <author>
      <name>Peter Fettke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">52 pages, 7 figures, 9 tables; Submitted to ACM Computing Surveys</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.06345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.06345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1; I.2.7; I.4.9; I.7.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.07706v1</id>
    <updated>2024-08-07T13:17:50Z</updated>
    <published>2024-08-07T13:17:50Z</published>
    <title>A Guide to Similarity Measures</title>
    <summary>  Similarity measures play a central role in various data science application
domains for a wide assortment of tasks. This guide describes a comprehensive
set of prevalent similarity measures to serve both non-experts and
professional. Non-experts that wish to understand the motivation for a measure
as well as how to use it may find a friendly and detailed exposition of the
formulas of the measures, whereas experts may find a glance to the principles
of designing similarity measures and ideas for a better way to measure
similarity for their desired task in a given application domain.
</summary>
    <author>
      <name>Avivit Levy</name>
    </author>
    <author>
      <name>B. Riva Shalom</name>
    </author>
    <author>
      <name>Michal Chalamish</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.07706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.07706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.10435v1</id>
    <updated>2024-08-19T22:01:45Z</updated>
    <published>2024-08-19T22:01:45Z</published>
    <title>Enhanced document retrieval with topic embeddings</title>
    <summary>  Document retrieval systems have experienced a revitalized interest with the
advent of retrieval-augmented generation (RAG). RAG architecture offers a lower
hallucination rate than LLM-only applications. However, the accuracy of the
retrieval mechanism is known to be a bottleneck in the efficiency of these
applications. A particular case of subpar retrieval performance is observed in
situations where multiple documents from several different but related topics
are in the corpus. We have devised a new vectorization method that takes into
account the topic information of the document. The paper introduces this new
method for text vectorization and evaluates it in the context of RAG.
Furthermore, we discuss the challenge of evaluating RAG systems, which pertains
to the case at hand.
</summary>
    <author>
      <name>Kavsar Huseynova</name>
    </author>
    <author>
      <name>Jafar Isbarov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AICT 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.10435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.10435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.12392v1</id>
    <updated>2024-08-22T13:37:30Z</updated>
    <published>2024-08-22T13:37:30Z</published>
    <title>Dynamic Product Image Generation and Recommendation at Scale for
  Personalized E-commerce</title>
    <summary>  Coupling latent diffusion based image generation with contextual bandits
enables the creation of eye-catching personalized product images at scale that
was previously either impossible or too expensive. In this paper we showcase
how we utilized these technologies to increase user engagement with
recommendations in online retargeting campaigns for e-commerce.
</summary>
    <author>
      <name>Ádám Tibor Czapp</name>
    </author>
    <author>
      <name>Mátyás Jani</name>
    </author>
    <author>
      <name>Bálint Domián</name>
    </author>
    <author>
      <name>Balázs Hidasi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3640457.3688045</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3640457.3688045" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appearing in the Proceedings of the 18th ACM Conference on
  Recommender Systems (RecSys'24) as an Industry Track paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.12392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.12392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.09722v1</id>
    <updated>2024-09-15T13:02:50Z</updated>
    <published>2024-09-15T13:02:50Z</published>
    <title>Measuring Recency Bias In Sequential Recommendation Systems</title>
    <summary>  Recency bias in a sequential recommendation system refers to the overly high
emphasis placed on recent items within a user session. This bias can diminish
the serendipity of recommendations and hinder the system's ability to capture
users' long-term interests, leading to user disengagement. We propose a simple
yet effective novel metric specifically designed to quantify recency bias. Our
findings also demonstrate that high recency bias measured in our proposed
metric adversely impacts recommendation performance too, and mitigating it
results in improved recommendation performances across all models evaluated in
our experiments, thus highlighting the importance of measuring recency bias.
</summary>
    <author>
      <name>Jeonglyul Oh</name>
    </author>
    <author>
      <name>Sungzoon Cho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the CONSEQUENCES '24 workshop, co-located with ACM RecSys
  '24</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.09722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.09722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.10271v1</id>
    <updated>2024-09-16T13:31:04Z</updated>
    <published>2024-09-16T13:31:04Z</published>
    <title>Causal Discovery in Recommender Systems: Example and Discussion</title>
    <summary>  Causality is receiving increasing attention by the artificial intelligence
and machine learning communities. This paper gives an example of modelling a
recommender system problem using causal graphs. Specifically, we approached the
causal discovery task to learn a causal graph by combining observational data
from an open-source dataset with prior knowledge. The resulting causal graph
shows that only a few variables effectively influence the analysed feedback
signals. This contrasts with the recent trend in the machine learning community
to include more and more variables in massive models, such as neural networks.
</summary>
    <author>
      <name>Emanuele Cavenaghi</name>
    </author>
    <author>
      <name>Fabio Stella</name>
    </author>
    <author>
      <name>Markus Zanker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the CONSEQUENCES '24 workshop, co-located with ACM RecSys
  '24</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.10271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.10271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.13703v1</id>
    <updated>2024-09-05T09:16:14Z</updated>
    <published>2024-09-05T09:16:14Z</published>
    <title>Zeroshot Listwise Learning to Rank Algorithm for Recommendation</title>
    <summary>  Learning to rank is a rare technology compared with other techniques such as
deep neural networks. The number of experts in the field is roughly 1/6 of the
number of professionals in deep learning. Being an effective ranking
methodology, learning to rank has been widely used in the field of information
retrieval. However, in recent years, learning to rank as a recommendation
approach has been on decline. In this paper, we take full advantage of order
statistic approximation and power law distribution to design a zeroshot
listwise learning to rank algorithm for recommendation. We prove in the
experiment section that our approach is both accurate and fair.
</summary>
    <author>
      <name>Hao Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3669754.3669821</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3669754.3669821" rel="related"/>
    <link href="http://arxiv.org/abs/2409.13703v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.13703v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.14524v1</id>
    <updated>2024-08-25T22:02:05Z</updated>
    <published>2024-08-25T22:02:05Z</published>
    <title>tabulapdf: An R Package to Extract Tables from PDF Documents</title>
    <summary>  tabulapdf is an R package that utilizes the Tabula Java library to import
tables from PDF files directly into R. This tool can reduce time and effort in
data extraction processes in fields like investigative journalism. It allows
for automatic and manual table extraction, the latter facilitated through a
Shiny interface, enabling manual areas selection with a computer mouse for data
retrieval.
</summary>
    <author>
      <name>Mauricio Vargas Sepúlveda</name>
    </author>
    <author>
      <name>Thomas J. Leeper</name>
    </author>
    <author>
      <name>Tom Paskhalis</name>
    </author>
    <author>
      <name>Manuel Aristarán</name>
    </author>
    <author>
      <name>Jeremy B. Merrill</name>
    </author>
    <author>
      <name>Mike Tigas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.14524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.14524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.19445v1</id>
    <updated>2024-09-28T19:58:29Z</updated>
    <published>2024-09-28T19:58:29Z</published>
    <title>HTML-LSTM: Information Extraction from HTML Tables in Web Pages using
  Tree-Structured LSTM</title>
    <summary>  In this paper, we propose a novel method for extracting information from HTML
tables with similar contents but with a different structure. We aim to
integrate multiple HTML tables into a single table for retrieval of information
containing in various Web pages. The method is designed by extending
tree-structured LSTM, the neural network for tree-structured data, in order to
extract information that is both linguistic and structural information of HTML
data. We evaluate the proposed method through experiments using real data
published on the WWW.
</summary>
    <author>
      <name>Kazuki Kawamura</name>
    </author>
    <author>
      <name>Akihiro Yamamoto</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-88942-5_3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-88942-5_3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Discovery Science. DS 2021. Lecture Notes in Computer Science, vol
  12986</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2409.19445v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.19445v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.19824v1</id>
    <updated>2024-09-29T23:12:04Z</updated>
    <published>2024-09-29T23:12:04Z</published>
    <title>Counterfactual Evaluation of Ads Ranking Models through Domain
  Adaptation</title>
    <summary>  We propose a domain-adapted reward model that works alongside an Offline A/B
testing system for evaluating ranking models. This approach effectively
measures reward for ranking model changes in large-scale Ads recommender
systems, where model-free methods like IPS are not feasible. Our experiments
demonstrate that the proposed technique outperforms both the vanilla IPS method
and approaches using non-generalized reward models.
</summary>
    <author>
      <name>Mohamed A. Radwan</name>
    </author>
    <author>
      <name>Himaghna Bhattacharjee</name>
    </author>
    <author>
      <name>Quinn Lanners</name>
    </author>
    <author>
      <name>Jiasheng Zhang</name>
    </author>
    <author>
      <name>Serkan Karakulak</name>
    </author>
    <author>
      <name>Houssam Nassif</name>
    </author>
    <author>
      <name>Murat Ali Bayir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the CONSEQUENCES'24 workshop, co-located with ACM
  RecSys'24</arxiv:comment>
    <link href="http://arxiv.org/abs/2409.19824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.19824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2409.20055v1</id>
    <updated>2024-09-30T08:00:04Z</updated>
    <published>2024-09-30T08:00:04Z</published>
    <title>Neural Click Models for Recommender Systems</title>
    <summary>  We develop and evaluate neural architectures to model the user behavior in
recommender systems (RS) inspired by click models for Web search but going
beyond standard click models. Proposed architectures include recurrent
networks, Transformer-based models that alleviate the quadratic complexity of
self-attention, adversarial and hierarchical architectures. Our models
outperform baselines on the ContentWise and RL4RS datasets and can be used in
RS simulators to model user response for RS evaluation and pretraining.
</summary>
    <author>
      <name>Mikhail Shirokikh</name>
    </author>
    <author>
      <name>Ilya Shenbin</name>
    </author>
    <author>
      <name>Anton Alekseev</name>
    </author>
    <author>
      <name>Anna Volodkevich</name>
    </author>
    <author>
      <name>Alexey Vasilev</name>
    </author>
    <author>
      <name>Andrey V. Savchenko</name>
    </author>
    <author>
      <name>Sergey Nikolenko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3626772.3657939</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3626772.3657939" rel="related"/>
    <link href="http://arxiv.org/abs/2409.20055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2409.20055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.01987v1</id>
    <updated>2024-10-02T19:48:17Z</updated>
    <published>2024-10-02T19:48:17Z</published>
    <title>Financial Sentiment Analysis on News and Reports Using Large Language
  Models and FinBERT</title>
    <summary>  Financial sentiment analysis (FSA) is crucial for evaluating market sentiment
and making well-informed financial decisions. The advent of large language
models (LLMs) such as BERT and its financial variant, FinBERT, has notably
enhanced sentiment analysis capabilities. This paper investigates the
application of LLMs and FinBERT for FSA, comparing their performance on news
articles, financial reports and company announcements. The study emphasizes the
advantages of prompt engineering with zero-shot and few-shot strategy to
improve sentiment classification accuracy. Experimental results indicate that
GPT-4o, with few-shot examples of financial texts, can be as competent as a
well fine-tuned FinBERT in this specialized field.
</summary>
    <author>
      <name>Yanxin Shen</name>
    </author>
    <author>
      <name>Pulin Kirin Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.01987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.01987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.02914v1</id>
    <updated>2024-10-03T19:05:47Z</updated>
    <published>2024-10-03T19:05:47Z</published>
    <title>Streamlining Conformal Information Retrieval via Score Refinement</title>
    <summary>  Information retrieval (IR) methods, like retrieval augmented generation, are
fundamental to modern applications but often lack statistical guarantees.
Conformal prediction addresses this by retrieving sets guaranteed to include
relevant information, yet existing approaches produce large-sized sets,
incurring high computational costs and slow response times. In this work, we
introduce a score refinement method that applies a simple monotone
transformation to retrieval scores, leading to significantly smaller conformal
sets while maintaining their statistical guarantees. Experiments on various
BEIR benchmarks validate the effectiveness of our approach in producing compact
sets containing relevant information.
</summary>
    <author>
      <name>Yotam Intrator</name>
    </author>
    <author>
      <name>Ori Kelner</name>
    </author>
    <author>
      <name>Regev Cohen</name>
    </author>
    <author>
      <name>Roman Goldenberg</name>
    </author>
    <author>
      <name>Ehud Rivlin</name>
    </author>
    <author>
      <name>Daniel Freedman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.02914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.02914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.05275v1</id>
    <updated>2024-09-20T12:09:49Z</updated>
    <published>2024-09-20T12:09:49Z</published>
    <title>Augmenting the Interpretability of GraphCodeBERT for Code Similarity
  Tasks</title>
    <summary>  Assessing the degree of similarity of code fragments is crucial for ensuring
software quality, but it remains challenging due to the need to capture the
deeper semantic aspects of code. Traditional syntactic methods often fail to
identify these connections. Recent advancements have addressed this challenge,
though they frequently sacrifice interpretability. To improve this, we present
an approach aiming to improve the transparency of the similarity assessment by
using GraphCodeBERT, which enables the identification of semantic relationships
between code fragments. This approach identifies similar code fragments and
clarifies the reasons behind that identification, helping developers better
understand and trust the results. The source code for our implementation is
available at
https://www.github.com/jorge-martinez-gil/graphcodebert-interpretability.
</summary>
    <author>
      <name>Jorge Martinez-Gil</name>
    </author>
    <link href="http://arxiv.org/abs/2410.05275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.05275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.05672v1</id>
    <updated>2024-10-08T04:02:06Z</updated>
    <published>2024-10-08T04:02:06Z</published>
    <title>Embedding derivatives and derivative Area operators of Hardy spaces into
  Lebesgue spaces</title>
    <summary>  We characterize the compactness of embedding derivatives from Hardy space
$H^p$ into Lebesgue space $L^q(\mu)$. We also completely characterize the
boundedness and compactness of derivative area operators from $H^p$ into
$L^q(\mathbb{S}_n)$, $0&lt;p, q&lt;\infty$. Some of the tools used in the proof of
the one-dimensional case are not available in higher dimensions, such as the
strong factorization of Hardy spaces. Therefore, we need the theory of tent
spaces which was established by Coifman, Mayer and Stein in 1985.
</summary>
    <author>
      <name>Xiaosong Liu</name>
    </author>
    <author>
      <name>Zengjian Lou</name>
    </author>
    <author>
      <name>Zixing Yuan</name>
    </author>
    <author>
      <name>Ruhan Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.05672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.05672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 47B38, Secondary 32A35, 32A37" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.06654v1</id>
    <updated>2024-10-09T08:06:15Z</updated>
    <published>2024-10-09T08:06:15Z</published>
    <title>Performance Evaluation in Multimedia Retrieval</title>
    <summary>  Performance evaluation in multimedia retrieval, as in the information
retrieval domain at large, relies heavily on retrieval experiments, employing a
broad range of techniques and metrics. These can involve human-in-the-loop and
machine-only settings for the retrieval process itself and the subsequent
verification of results. Such experiments can be elaborate and
use-case-specific, which can make them difficult to compare or replicate. In
this paper, we present a formal model to express all relevant aspects of such
retrieval experiments, as well as a flexible open-source evaluation
infrastructure that implements the model. These contributions intend to make a
step towards lowering the hurdles for conducting retrieval experiments and
improving their reproducibility.
</summary>
    <author>
      <name>Loris Sauter</name>
    </author>
    <author>
      <name>Ralph Gasser</name>
    </author>
    <author>
      <name>Heiko Schuldt</name>
    </author>
    <author>
      <name>Abraham Bernstein</name>
    </author>
    <author>
      <name>Luca Rossetto</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3678881</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3678881" rel="related"/>
    <link href="http://arxiv.org/abs/2410.06654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.06654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.09923v1</id>
    <updated>2024-10-13T17:08:16Z</updated>
    <published>2024-10-13T17:08:16Z</published>
    <title>Analysis and Design of a Personalized Recommendation System Based on a
  Dynamic User Interest Model</title>
    <summary>  With the rapid development of the internet and the explosion of information,
providing users with accurate personalized recommendations has become an
important research topic. This paper designs and analyzes a personalized
recommendation system based on a dynamic user interest model. The system
captures user behavior data, constructs a dynamic user interest model, and
combines multiple recommendation algorithms to provide personalized content to
users. The research results show that this system significantly improves
recommendation accuracy and user satisfaction. This paper discusses the
system's architecture design, algorithm implementation, and experimental
results in detail and explores future research directions.
</summary>
    <author>
      <name>Chunyan Mao</name>
    </author>
    <author>
      <name>Shuaishuai Huang</name>
    </author>
    <author>
      <name>Mingxiu Sui</name>
    </author>
    <author>
      <name>Haowei Yang</name>
    </author>
    <author>
      <name>Xueshe Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.09923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.09923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.11870v1</id>
    <updated>2024-10-09T03:16:37Z</updated>
    <published>2024-10-09T03:16:37Z</published>
    <title>Post-Userist Recommender Systems : A Manifesto</title>
    <summary>  We define userist recommendation as an approach to recommender systems framed
solely in terms of the relation between the user and system. Post-userist
recommendation posits a larger field of relations in which stakeholders are
embedded and distinguishes the recommendation function (which can potentially
connect creators with audiences) from generative media. We argue that in the
era of generative media, userist recommendation becomes indistinguishable from
personalized media generation, and therefore post-userist recommendation is the
only path forward for recommender systems research.
</summary>
    <author>
      <name>Robin Burke</name>
    </author>
    <author>
      <name>Morgan Sylvester</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended abstract for paper presented at AltRecSys Workshop 2024.
  Held at the 18th ACM Conference on Recommender Systems, Bari, Italy. October
  18, 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.11870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.11870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.13125v1</id>
    <updated>2024-10-17T01:27:57Z</updated>
    <published>2024-10-17T01:27:57Z</published>
    <title>Transformers4NewsRec: A Transformer-based News Recommendation Framework</title>
    <summary>  Pre-trained transformer models have shown great promise in various natural
language processing tasks, including personalized news recommendations. To
harness the power of these models, we introduce Transformers4NewsRec, a new
Python framework built on the \textbf{Transformers} library. This framework is
designed to unify and compare the performance of various news recommendation
models, including deep neural networks and graph-based models.
Transformers4NewsRec offers flexibility in terms of model selection, data
preprocessing, and evaluation, allowing both quantitative and qualitative
analysis.
</summary>
    <author>
      <name>Dairui Liu</name>
    </author>
    <author>
      <name>Honghui Du</name>
    </author>
    <author>
      <name>Boming Yang</name>
    </author>
    <author>
      <name>Neil Hurley</name>
    </author>
    <author>
      <name>Aonghus Lawlor</name>
    </author>
    <author>
      <name>Irene Li</name>
    </author>
    <author>
      <name>Derek Greene</name>
    </author>
    <author>
      <name>Ruihai Dong</name>
    </author>
    <link href="http://arxiv.org/abs/2410.13125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.13125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.13680v1</id>
    <updated>2024-10-17T15:40:09Z</updated>
    <published>2024-10-17T15:40:09Z</published>
    <title>Pessimistic Evaluation</title>
    <summary>  Traditional evaluation of information access systems has focused primarily on
average utility across a set of information needs (information retrieval) or
users (recommender systems). In this work, we argue that evaluating only with
average metric measurements assumes utilitarian values not aligned with
traditions of information access based on equal access. We advocate for
pessimistic evaluation of information access systems focusing on worst case
utility. These methods are (a) grounded in ethical and pragmatic concepts, (b)
theoretically complementary to existing robustness and fairness methods, and
(c) empirically validated across a set of retrieval and recommendation tasks.
These results suggest that pessimistic evaluation should be included in
existing experimentation processes to better understand the behavior of
systems, especially when concerned with principles of social good.
</summary>
    <author>
      <name>Fernando Diaz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3673791.3698428</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3673791.3698428" rel="related"/>
    <link href="http://arxiv.org/abs/2410.13680v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.13680v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.13865v1</id>
    <updated>2024-10-01T20:29:14Z</updated>
    <published>2024-10-01T20:29:14Z</published>
    <title>Classifying Peace in Global Media Using RAG and Intergroup Reciprocity</title>
    <summary>  This paper presents a novel approach to identifying insights of peace in
global media using a Retrieval Augmented Generation (RAG) model and concepts of
Positive and Negative Intergroup Reciprocity (PIR/NIR). By refining the
definitions of PIR and NIR, we offer a more accurate and meaningful analysis of
intergroup relations as represented in media articles. Our methodology provides
insights into the dynamics that contribute to or detract from peace at a
national level.
</summary>
    <author>
      <name>K. Lian</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>L. S. Liebovitch</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>M. Wild</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>H. West</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>P. T. Coleman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>F. Chen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Toyota Research Institute</arxiv:affiliation>
    </author>
    <author>
      <name>E. Kimani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Toyota Research Institute</arxiv:affiliation>
    </author>
    <author>
      <name>K. Sieck</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Toyota Research Institute</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.13865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.13865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.14625v1</id>
    <updated>2024-10-18T17:27:07Z</updated>
    <published>2024-10-18T17:27:07Z</published>
    <title>Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers
  and Electronic Health Records</title>
    <summary>  In the rapidly evolving landscape of veterinary healthcare, integrating
machine learning (ML) clinical decision-making tools with electronic health
records (EHRs) promises to improve diagnostic accuracy and patient care.
However, the seamless integration of ML classifiers into existing EHRs in
veterinary medicine is frequently hindered by the rigidity of EHR systems or
the limited availability of IT resources. To address this shortcoming, we
present Anna, a freely-available software solution that provides ML classifier
results for EHR laboratory data in real-time.
</summary>
    <author>
      <name>Chun Yin Kong</name>
    </author>
    <author>
      <name>Picasso Vasquez</name>
    </author>
    <author>
      <name>Makan Farhoodimoghadam</name>
    </author>
    <author>
      <name>Chris Brandt</name>
    </author>
    <author>
      <name>Titus C. Brown</name>
    </author>
    <author>
      <name>Krystle L. Reagan</name>
    </author>
    <author>
      <name>Allison Zwingenberger</name>
    </author>
    <author>
      <name>Stefan M. Keller</name>
    </author>
    <link href="http://arxiv.org/abs/2410.14625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.14625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.15272v1</id>
    <updated>2024-10-20T04:05:18Z</updated>
    <published>2024-10-20T04:05:18Z</published>
    <title>Performance-Driven QUBO for Recommender Systems on Quantum Annealers</title>
    <summary>  We propose Counterfactual Analysis Quadratic Unconstrained Binary
Optimization (CAQUBO) to solve QUBO problems for feature selection in
recommender systems. CAQUBO leverages counterfactual analysis to measure the
impact of individual features and feature combinations on model performance and
employs the measurements to construct the coefficient matrix for a quantum
annealer to select the optimal feature combinations for recommender systems,
thereby improving their final recommendation performance. By establishing
explicit connections between features and the recommendation performance, the
proposed approach demonstrates superior performance compared to the
state-of-the-art quantum annealing methods. Extensive experiments indicate that
integrating quantum computing with counterfactual analysis holds great promise
for addressing these challenges.
</summary>
    <author>
      <name>Jiayang Niu</name>
    </author>
    <author>
      <name>Jie Li</name>
    </author>
    <author>
      <name>Ke Deng</name>
    </author>
    <author>
      <name>Mark Sanderson</name>
    </author>
    <author>
      <name>Yongli Ren</name>
    </author>
    <link href="http://arxiv.org/abs/2410.15272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.15272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.15996v1</id>
    <updated>2024-10-21T13:27:29Z</updated>
    <published>2024-10-21T13:27:29Z</published>
    <title>Surprising Patterns in Musical Influence Networks</title>
    <summary>  Analyzing musical influence networks, such as those formed by artist
influence or sampling, has provided valuable insights into contemporary Western
music. Here, computational methods like centrality rankings help identify
influential artists. However, little attention has been given to how influence
changes over time. In this paper, we apply Bayesian Surprise to track the
evolution of musical influence networks. Using two networks -- one of artist
influence and another of covers, remixes, and samples -- our results reveal
significant periods of change in network structure. Additionally, we
demonstrate that Bayesian Surprise is a flexible framework for testing various
hypotheses on network evolution with real-world data.
</summary>
    <author>
      <name>Flavio Figueiredo</name>
    </author>
    <author>
      <name>Tales Panoutsos</name>
    </author>
    <author>
      <name>Nazareno Andrade</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the Latin American Musical Information Retrieval
  Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.15996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.15996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.17258v1</id>
    <updated>2024-10-06T02:50:41Z</updated>
    <published>2024-10-06T02:50:41Z</published>
    <title>Representing Web Applications As Knowledge Graphs</title>
    <summary>  Traditional methods for crawling and parsing web applications predominantly
rely on extracting hyperlinks from initial pages and recursively following
linked resources. This approach constructs a graph where nodes represent
unstructured data from web pages, and edges signify transitions between them.
However, these techniques are limited in capturing the dynamic and interactive
behaviors inherent to modern web applications. In contrast, the proposed method
models each node as a structured representation of the application's current
state, with edges reflecting user-initiated actions or transitions. This
structured representation enables a more comprehensive and functional
understanding of web applications, offering valuable insights for downstream
tasks such as automated testing and behavior analysis.
</summary>
    <author>
      <name>Yogesh Chandrasekharuni</name>
    </author>
    <link href="http://arxiv.org/abs/2410.17258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.17258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18122v1</id>
    <updated>2024-10-12T09:46:36Z</updated>
    <published>2024-10-12T09:46:36Z</published>
    <title>Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution
  Generalisation of Misinformation Detection Models</title>
    <summary>  This paper introduces misinfo-general, a benchmark dataset for evaluating
misinformation models' ability to perform out-of-distribution generalisation.
Misinformation changes rapidly, much quicker than moderators can annotate at
scale, resulting in a shift between the training and inference data
distributions. As a result, misinformation models need to be able to perform
out-of-distribution generalisation, an understudied problem in existing
datasets. We identify 6 axes of generalisation-time, event, topic, publisher,
political bias, misinformation type-and design evaluation procedures for each.
We also analyse some baseline models, highlighting how these fail important
desiderata.
</summary>
    <author>
      <name>Ivo Verhoeven</name>
    </author>
    <author>
      <name>Pushkar Mishra</name>
    </author>
    <author>
      <name>Ekaterina Shutova</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.20080v1</id>
    <updated>2024-10-26T05:14:32Z</updated>
    <published>2024-10-26T05:14:32Z</published>
    <title>Optimizing Keyphrase Ranking for Relevance and Diversity Using
  Submodular Function Optimization (SFO)</title>
    <summary>  Keyphrase ranking plays a crucial role in information retrieval and
summarization by indexing and retrieving relevant information efficiently.
Advances in natural language processing, especially large language models
(LLMs), have improved keyphrase extraction and ranking. However, traditional
methods often overlook diversity, resulting in redundant keyphrases. We propose
a novel approach using Submodular Function Optimization (SFO) to balance
relevance and diversity in keyphrase ranking. By framing the task as submodular
maximization, our method selects diverse and representative keyphrases.
Experiments on benchmark datasets show that our approach outperforms existing
methods in both relevance and diversity metrics, achieving SOTA performance in
execution time. Our code is available online.
</summary>
    <author>
      <name>Muhammad Umair</name>
    </author>
    <author>
      <name>Syed Jalaluddin Hashmi</name>
    </author>
    <author>
      <name>Young-Koo Lee</name>
    </author>
    <link href="http://arxiv.org/abs/2410.20080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.20080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.20301v1</id>
    <updated>2024-10-27T00:49:52Z</updated>
    <published>2024-10-27T00:49:52Z</published>
    <title>WindTunnel -- A Framework for Community Aware Sampling of Large Corpora</title>
    <summary>  Conducting comprehensive information retrieval experiments, such as in search
or retrieval augmented generation, often comes with high computational costs.
This is because evaluating a retrieval algorithm requires indexing the entire
corpus, which is significantly larger than the set of (query, result) pairs
under evaluation. This issue is especially pronounced in big data and neural
retrieval, where indexing becomes increasingly time-consuming and complex. In
this paper, we present WindTunnel, a novel framework developed at Yext to
generate representative samples of large corpora, enabling efficient end-to-end
information retrieval experiments. By preserving the community structure of the
dataset, WindTunnel overcomes limitations in current sampling methods,
providing more accurate evaluations.
</summary>
    <author>
      <name>Michael Iannelli</name>
    </author>
    <link href="http://arxiv.org/abs/2410.20301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.20301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.21549v1</id>
    <updated>2024-10-28T21:25:38Z</updated>
    <published>2024-10-28T21:25:38Z</published>
    <title>Semantic Search Evaluation</title>
    <summary>  We propose a novel method for evaluating the performance of a content search
system that measures the semantic match between a query and the results
returned by the search system. We introduce a metric called "on-topic rate" to
measure the percentage of results that are relevant to the query. To achieve
this, we design a pipeline that defines a golden query set, retrieves the top K
results for each query, and sends calls to GPT 3.5 with formulated prompts. Our
semantic evaluation pipeline helps identify common failure patterns and goals
against the metric for relevance improvements.
</summary>
    <author>
      <name>Chujie Zheng</name>
    </author>
    <author>
      <name>Jeffrey Wang</name>
    </author>
    <author>
      <name>Shuqian Albee Zhang</name>
    </author>
    <author>
      <name>Anand Kishore</name>
    </author>
    <author>
      <name>Siddharth Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by 3rd International Workshop on Industrial Recommendation
  Systems (at CIKM 2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.21549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.21549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.00395v1</id>
    <updated>2024-11-01T06:49:39Z</updated>
    <published>2024-11-01T06:49:39Z</published>
    <title>DivNet: Diversity-Aware Self-Correcting Sequential Recommendation
  Networks</title>
    <summary>  As the last stage of a typical \textit{recommendation system},
\textit{collective recommendation} aims to give the final touches to the
recommended items and their layout so as to optimize overall objectives such as
diversity and whole-page relevance. In practice, however, the interaction
dynamics among the recommended items, their visual appearances and meta-data
such as specifications are often too complex to be captured by experts'
heuristics or simple models. To address this issue, we propose a
\textit{\underline{div}ersity-aware self-correcting sequential recommendation
\underline{net}works} (\textit{DivNet}) that is able to estimate utility by
capturing the complex interactions among sequential items and diversify
recommendations simultaneously. Experiments on both offline and online settings
demonstrate that \textit{DivNet} can achieve better results compared to
baselines with or without collective recommendations.
</summary>
    <author>
      <name>Shuai Xiao</name>
    </author>
    <author>
      <name>Zaifan Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at CIKM</arxiv:comment>
    <link href="http://arxiv.org/abs/2411.00395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.00395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.01304v1</id>
    <updated>2024-11-02T16:39:45Z</updated>
    <published>2024-11-02T16:39:45Z</published>
    <title>Towards a Knowledge Graph for Teaching Knowledge Graphs</title>
    <summary>  This poster paper describes the ongoing research project for the creation of
a use-case-driven Knowledge Graph resource tailored to the needs of teaching
education in Knowledge Graphs (KGs). We gather resources related to KG courses
from lectures offered by the Semantic Web community, with the help of the COST
Action Distributed Knowledge Graphs and the interest group on KGs at The Alan
Turing Institute. Our goal is to create a resource-focused KG with multiple
interconnected semantic layers that interlink topics, courses, and materials
with each lecturer. Our approach formulates a domain KG in teaching and relates
it with multiple Personal KGs created for the lecturers.
</summary>
    <author>
      <name>Eleni Ilkou</name>
    </author>
    <author>
      <name>Ernesto Jiménez-Ruiz</name>
    </author>
    <link href="http://arxiv.org/abs/2411.01304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.01304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.15186v1</id>
    <updated>2024-11-19T05:46:20Z</updated>
    <published>2024-11-19T05:46:20Z</published>
    <title>Preliminary Evaluation of the Test-Time Training Layers in
  Recommendation System (Student Abstract)</title>
    <summary>  This paper explores the application and effectiveness of Test-Time Training
(TTT) layers in improving the performance of recommendation systems. We
developed a model, TTT4Rec, utilizing TTT-Linear as the feature extraction
layer. Our tests across multiple datasets indicate that TTT4Rec, as a base
model, performs comparably or even surpasses other baseline models in similar
environments.
</summary>
    <author>
      <name>Tianyu Zhan</name>
    </author>
    <author>
      <name>Zheqi Lv</name>
    </author>
    <author>
      <name>Shengyu Zhang</name>
    </author>
    <author>
      <name>Jiwei Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in AAAI-25 Student Abstract and Poster Program</arxiv:comment>
    <link href="http://arxiv.org/abs/2411.15186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.15186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2411.15550v1</id>
    <updated>2024-11-23T13:15:13Z</updated>
    <published>2024-11-23T13:15:13Z</published>
    <title>Class Order Disorder in Wikidata and First Fixes</title>
    <summary>  Wikidata has a large ontology with classes at several orders. The Wikidata
ontology has long been known to have violations of class order and information
related to class order that appears suspect. SPARQL queries were evaluated
against Wikidata to determine the prevalence of several kinds of violations and
suspect information and the results analyzed. Some changes were manually made
to Wikidata to remove some of these results and the queries rerun, showing the
effect of the changes. Suggestions are provided on how the problems uncovered
might be addressed, either though better tooling or involvement of the Wikidata
community.
</summary>
    <author>
      <name>Peter F. Patel-Schneider</name>
    </author>
    <author>
      <name>Ege Atacan Doğan</name>
    </author>
    <link href="http://arxiv.org/abs/2411.15550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2411.15550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.00934v1</id>
    <updated>2024-12-01T18:58:17Z</updated>
    <published>2024-12-01T18:58:17Z</published>
    <title>QABISAR: Query-Article Bipartite Interactions for Statutory Article
  Retrieval</title>
    <summary>  In this paper, we introduce QABISAR, a novel framework for statutory article
retrieval, to overcome the semantic mismatch problem when modeling each
query-article pair in isolation, making it hard to learn representation that
can effectively capture multi-faceted information. QABISAR leverages bipartite
interactions between queries and articles to capture diverse aspects inherent
in them. Further, we employ knowledge distillation to transfer enriched query
representations from the graph network into the query bi-encoder, to capture
the rich semantics present in the graph representations, despite absence of
graph-based supervision for unseen queries during inference. Our experiments on
a real-world expert-annotated dataset demonstrate its effectiveness.
</summary>
    <author>
      <name>T. Y. S. S. Santosh</name>
    </author>
    <author>
      <name>Hassan Sarwat</name>
    </author>
    <author>
      <name>Matthias Grabmair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to COLING 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2412.00934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.00934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.06649v1</id>
    <updated>2024-12-09T16:43:23Z</updated>
    <published>2024-12-09T16:43:23Z</published>
    <title>Semantic Search and Recommendation Algorithm</title>
    <summary>  This paper introduces a new semantic search algorithm that uses Word2Vec and
Annoy Index to improve the efficiency of information retrieval from large
datasets. The proposed approach addresses the limitations of traditional search
methods by offering enhanced speed, accuracy, and scalability. Testing on
datasets up to 100GB demonstrates the method's effectiveness in processing vast
amounts of data while maintaining high precision and performance.
</summary>
    <author>
      <name>Aryan Duhan</name>
    </author>
    <author>
      <name>Aryan Singhal</name>
    </author>
    <author>
      <name>Shourya Sharma</name>
    </author>
    <author>
      <name> Neeraj</name>
    </author>
    <author>
      <name>Arti MK</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2412.06649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.06649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.15973v1</id>
    <updated>2024-12-20T15:18:02Z</updated>
    <published>2024-12-20T15:18:02Z</published>
    <title>Legommenders: A Comprehensive Content-Based Recommendation Library with
  LLM Support</title>
    <summary>  We present Legommenders, a unique library designed for content-based
recommendation that enables the joint training of content encoders alongside
behavior and interaction modules, thereby facilitating the seamless integration
of content understanding directly into the recommendation pipeline.
Legommenders allows researchers to effortlessly create and analyze over 1,000
distinct models across 15 diverse datasets. Further, it supports the
incorporation of contemporary large language models, both as feature encoder
and data generator, offering a robust platform for developing state-of-the-art
recommendation models and enabling more personalized and effective content
delivery.
</summary>
    <author>
      <name>Qijiong Liu</name>
    </author>
    <author>
      <name>Lu Fan</name>
    </author>
    <author>
      <name>Xiao-Ming Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2412.15973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.15973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.20366v2</id>
    <updated>2025-01-02T17:38:21Z</updated>
    <published>2024-12-29T06:10:31Z</published>
    <title>Introducing Semantic Capability in LinkedIn's Content Search Engine</title>
    <summary>  In the past, most search queries issued to a search engine were short and
simple. A keyword based search engine was able to answer such queries quite
well. However, members are now developing the habit of issuing long and complex
natural language queries. Answering such queries requires evolution of a search
engine to have semantic capability. In this paper we present the design of
LinkedIn's new content search engine with semantic capability, and its impact
on metrics.
</summary>
    <author>
      <name>Xin Yang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name>Rachel Zheng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name>Madhumitha Mohan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name>Sonali Bhadra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name>Pansul Bhatt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name> Lingyu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Claire</arxiv:affiliation>
    </author>
    <author>
      <name> Zhang</name>
    </author>
    <author>
      <name>Rupesh Gupta</name>
    </author>
    <link href="http://arxiv.org/abs/2412.20366v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.20366v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.00367v1</id>
    <updated>2024-12-31T09:42:53Z</updated>
    <published>2024-12-31T09:42:53Z</published>
    <title>Who Gets Recommended? Investigating Gender, Race, and Country
  Disparities in Paper Recommendations from Large Language Models</title>
    <summary>  This paper investigates the performance of several representative large
models in the tasks of literature recommendation and explores potential biases
in research exposure. The results indicate that not only LLMs' overall
recommendation accuracy remains limited but also the models tend to recommend
literature with greater citation counts, later publication date, and larger
author teams. Yet, in scholar recommendation tasks, there is no evidence that
LLMs disproportionately recommend male, white, or developed-country authors,
contrasting with patterns of known human biases.
</summary>
    <author>
      <name>Yifan Tian</name>
    </author>
    <author>
      <name>Yixin Liu</name>
    </author>
    <author>
      <name>Yi Bu</name>
    </author>
    <author>
      <name>Jiqun Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2501.00367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.00367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.03072v2</id>
    <updated>2025-03-17T03:02:56Z</updated>
    <published>2024-11-22T02:49:15Z</published>
    <title>OpenTable data with multi-criteria ratings</title>
    <summary>  With the development of recommender systems (RSs), several promising systems
have emerged, such as context-aware RS, multi-criteria RS, and group RS.
Multi-criteria recommender systems (MCRSs) are designed to provide personalized
recommendations by considering user preferences in multiple attributes or
criteria simultaneously. Unlike traditional RSs that typically focus on a
single rating, these systems help users make more informed decisions by
considering their diverse preferences and needs across various dimensions. In
this article, we release the OpenTable data set which was crawled from
OpenTable.com. The data set can be considered as a benchmark data set for
multi-criteria recommendations.
</summary>
    <author>
      <name>Yong Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2501.03072v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.03072v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.03811v1</id>
    <updated>2025-01-07T14:24:49Z</updated>
    <published>2025-01-07T14:24:49Z</published>
    <title>Extending ChatGPT with a Browserless System for Web Product Price
  Extraction</title>
    <summary>  With the advenement of ChatGPT, we can find very clean, precise answers to a
varied amount of questions. However, for questions such as 'find the price of
the lemon cake at zingerman's', the answer looks like 'I can't browse the web
right now'. In this paper, we propose a system, called Wextractor, which
extends ChatGPT to answer questions as the one mentioned before. Obviously, our
system cannot be labeled as `artificial intelligence'. Simply, it offers to
cover a kind of transactional search that is not included in the current
version of ChatGPT. Moreover, Wextractor includes two improvements with respect
to the initial version: social extraction and pointing pattern extraction to
improve the answer speed.
</summary>
    <author>
      <name>Jorge Lloret-Gazo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2501.03811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.03811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.05018v1</id>
    <updated>2025-01-09T07:21:44Z</updated>
    <published>2025-01-09T07:21:44Z</published>
    <title>Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via
  Bagging and SVR Ensembles</title>
    <summary>  We introduce a retrieval approach leveraging Support Vector Regression (SVR)
ensembles, bootstrap aggregation (bagging), and embedding spaces on the German
Dataset for Legal Information Retrieval (GerDaLIR). By conceptualizing the
retrieval task in terms of multiple binary needle-in-a-haystack subtasks, we
show improved recall over the baselines (0.849 &gt; 0.803 | 0.829) using our
voting ensemble, suggesting promising initial results, without training or
fine-tuning any deep learning models. Our approach holds potential for further
enhancement, particularly through refining the encoding models and optimizing
hyperparameters.
</summary>
    <author>
      <name>Kevin Bönisch</name>
    </author>
    <author>
      <name>Alexander Mehler</name>
    </author>
    <link href="http://arxiv.org/abs/2501.05018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.05018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.05894v1</id>
    <updated>2025-01-10T11:46:51Z</updated>
    <published>2025-01-10T11:46:51Z</published>
    <title>Text2Playlist: Generating Personalized Playlists from Text on Deezer</title>
    <summary>  The streaming service Deezer heavily relies on the search to help users
navigate through its extensive music catalog. Nonetheless, it is primarily
designed to find specific items and does not lead directly to a smooth
listening experience. We present Text2Playlist, a stand-alone tool that
addresses these limitations. Text2Playlist leverages generative AI, music
information retrieval and recommendation systems to generate query-specific and
personalized playlists, successfully deployed at scale.
</summary>
    <author>
      <name>Mathieu Delcluze</name>
    </author>
    <author>
      <name>Antoine Khoury</name>
    </author>
    <author>
      <name>Clémence Vast</name>
    </author>
    <author>
      <name>Valerio Arnaudo</name>
    </author>
    <author>
      <name>Léa Briand</name>
    </author>
    <author>
      <name>Walid Bendada</name>
    </author>
    <author>
      <name>Thomas Bouabça</name>
    </author>
    <link href="http://arxiv.org/abs/2501.05894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.05894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.05964v1</id>
    <updated>2025-01-10T13:46:23Z</updated>
    <published>2025-01-10T13:46:23Z</published>
    <title>Recommender Systems for Social Good: The Role of Accountability and
  Sustainability</title>
    <summary>  This work examines the role of recommender systems in promoting
sustainability, social responsibility, and accountability, with a focus on
alignment with the United Nations Sustainable Development Goals (SDGs). As
recommender systems become increasingly integrated into daily interactions,
they must go beyond personalization to support responsible consumption, reduce
environmental impact, and foster social good. We explore strategies to mitigate
the carbon footprint of recommendation models, ensure fairness, and implement
accountability mechanisms. By adopting these approaches, recommender systems
can contribute to sustainable and socially beneficial outcomes, aligning
technological advancements with the SDGs focused on environmental
sustainability and social well-being.
</summary>
    <author>
      <name>Alan Said</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First International Workshop on Recommender Systems for
  Sustainability and Social Good (RecSoGood'24)</arxiv:comment>
    <link href="http://arxiv.org/abs/2501.05964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.05964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.13272v1</id>
    <updated>2025-01-22T23:29:45Z</updated>
    <published>2025-01-22T23:29:45Z</published>
    <title>PCSI -- The Platform for Content-Structure Inference</title>
    <summary>  The Platform for Content-Structure Inference (PCSI, pronounced "pixie")
facilitates the sharing of information about the process of converting Web
resources into structured content objects that conform to a predefined format.
PCSI records encode methods for deriving structured content from classes of
URLs, and report the results of applying particular methods to particular URLs.
The methods are scripts written in Hex, a variant of Awk with facilities for
traversing the HTML DOM.
</summary>
    <author>
      <name>Caleb Malchik</name>
    </author>
    <author>
      <name>Joan Feigenbaum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2501.13272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.13272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.14466v1</id>
    <updated>2025-01-24T12:55:42Z</updated>
    <published>2025-01-24T12:55:42Z</published>
    <title>On Correlating Factors for Domain Adaptation Performance</title>
    <summary>  Dense retrievers have demonstrated significant potential for neural
information retrieval; however, they lack robustness to domain shifts, limiting
their efficacy in zero-shot settings across diverse domains. In this paper, we
set out to analyze the possible factors that lead to successful domain
adaptation of dense retrievers. We include domain similarity proxies between
generated queries to test and source domains. Furthermore, we conduct a case
study comparing two powerful domain adaptation techniques. We find that
generated query type distribution is an important factor, and generating
queries that share a similar domain to the test documents improves the
performance of domain adaptation methods. This study further emphasizes the
importance of domain-tailored generated queries.
</summary>
    <author>
      <name>Goksenin Yuksel</name>
    </author>
    <author>
      <name>Jaap Kamps</name>
    </author>
    <link href="http://arxiv.org/abs/2501.14466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.14466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.14579v1</id>
    <updated>2025-01-24T15:38:32Z</updated>
    <published>2025-01-24T15:38:32Z</published>
    <title>Knowledge Graphs Construction from Criminal Court Appeals: Insights from
  the French Cassation Court</title>
    <summary>  Despite growing interest, accurately and reliably representing unstructured
data, such as court decisions, in a structured form, remains a challenge.
Recent advancements in generative AI applied to language modeling enabled the
transformation of text into knowledge graphs, unlocking new opportunities for
analysis and modeling. This paper presents a framework for constructing
knowledge graphs from appeals to the French Cassation Court. The framework
includes a domain-specific ontology and a derived dataset, offering a
foundation for structured legal data representation and analysis.
</summary>
    <author>
      <name>Alexander V. Belikov</name>
    </author>
    <author>
      <name>Sacha Raoult</name>
    </author>
    <link href="http://arxiv.org/abs/2501.14579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.14579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2501.14922v1</id>
    <updated>2025-01-24T21:13:45Z</updated>
    <published>2025-01-24T21:13:45Z</published>
    <title>Search results diversification in competitive search</title>
    <summary>  In Web retrieval, there are many cases of competition between authors of Web
documents: their incentive is to have their documents highly ranked for queries
of interest. As such, the Web is a prominent example of a competitive search
setting. Past work on competitive search focused on ranking functions based
solely on relevance estimation. We study ranking functions that integrate a
results-diversification aspect. We show that the competitive search setting
with diversity-based ranking has an equilibrium. Furthermore, we theoretically
and empirically show that the phenomenon of authors mimicking content in
documents highly ranked in the past, which was demonstrated in previous work,
is mitigated when search results diversification is applied.
</summary>
    <author>
      <name>Tommy Mordo</name>
    </author>
    <author>
      <name>Itamar Reinman</name>
    </author>
    <author>
      <name>Moshe Tennenholtz</name>
    </author>
    <author>
      <name>Oren Kurland</name>
    </author>
    <link href="http://arxiv.org/abs/2501.14922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2501.14922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.01555v1</id>
    <updated>2025-02-03T17:37:37Z</updated>
    <published>2025-02-03T17:37:37Z</published>
    <title>Query Brand Entity Linking in E-Commerce Search</title>
    <summary>  In this work, we address the brand entity linking problem for e-commerce
search queries. The entity linking task is done by either i)a two-stage process
consisting of entity mention detection followed by entity disambiguation or ii)
an end-to-end linking approaches that directly fetch the target entity given
the input text. The task presents unique challenges: queries are extremely
short (averaging 2.4 words), lack natural language structure, and must handle a
massive space of unique brands. We present a two-stage approach combining
named-entity recognition with matching, and a novel end-to-end solution using
extreme multi-class classification. We validate our solutions by both offline
benchmarks and the impact of online A/B test.
</summary>
    <author>
      <name>Dong Liu</name>
    </author>
    <author>
      <name>Sreyashi Nag</name>
    </author>
    <link href="http://arxiv.org/abs/2502.01555v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.01555v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.02966v1</id>
    <updated>2025-02-05T08:07:04Z</updated>
    <published>2025-02-05T08:07:04Z</published>
    <title>FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for
  Enabling Fair LLM-Based Recommender Systems</title>
    <summary>  We propose FACTER, a fairness-aware framework for LLM-based recommendation
systems that integrates conformal prediction with dynamic prompt engineering.
By introducing an adaptive semantic variance threshold and a
violation-triggered mechanism, FACTER automatically tightens fairness
constraints whenever biased patterns emerge. We further develop an adversarial
prompt generator that leverages historical violations to reduce repeated
demographic biases without retraining the LLM. Empirical results on MovieLens
and Amazon show that FACTER substantially reduces fairness violations (up to
95.5%) while maintaining strong recommendation accuracy, revealing semantic
variance as a potent proxy of bias.
</summary>
    <author>
      <name>Arya Fayyazi</name>
    </author>
    <author>
      <name>Mehdi Kamal</name>
    </author>
    <author>
      <name>Massoud Pedram</name>
    </author>
    <link href="http://arxiv.org/abs/2502.02966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.02966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.03065v1</id>
    <updated>2025-02-05T10:53:42Z</updated>
    <published>2025-02-05T10:53:42Z</published>
    <title>Scientometric Analysis of the German IR Community within TREC &amp; CLEF</title>
    <summary>  Within this study, the influence of the German Information Retrieval
community on the retrieval campaigns Text Retrieval Conference (TREC) and
Conference and Labs of the Evaluation Forum (CLEF) between 2000 and 2022 was
analyzed based on metadata provided by OpenAlex and further metadata extracted
with the GROBID framework from the publication's full texts. The analysis was
conducted at the institutional and researcher levels. It was found that the
German IR community, both on the author and institution level, mainly
contributed to CLEF. Furthermore, it was shown that productivity follows the
assumptions made by Lotka's Law.
</summary>
    <author>
      <name>A. K. Kruff</name>
    </author>
    <author>
      <name>P. Schaer</name>
    </author>
    <link href="http://arxiv.org/abs/2502.03065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.03065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.09827v2</id>
    <updated>2025-02-17T08:34:43Z</updated>
    <published>2025-02-13T23:53:40Z</published>
    <title>Data and Decision Traceability for SDA TAP Lab's Prototype Battle
  Management System</title>
    <summary>  Space Protocol is applying the principles derived from MITRE and NIST's
Supply Chain Traceability: Manufacturing Meta-Framework (NIST IR 8536) to a
complex multi party system to achieve introspection, auditing, and replay of
data and decisions that ultimately lead to a end decision. The core goal of
decision traceability is to ensure transparency, accountability, and integrity
within the WA system. This is accomplished by providing a clear, auditable path
from the system's inputs all the way to the final decision. This traceability
enables the system to track the various algorithms and data flows that have
influenced a particular outcome.
</summary>
    <author>
      <name>Latha Pratti</name>
    </author>
    <author>
      <name>Samya Bagchi</name>
    </author>
    <author>
      <name>Yasir Latif</name>
    </author>
    <link href="http://arxiv.org/abs/2502.09827v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.09827v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.18470v3</id>
    <updated>2025-03-14T02:48:55Z</updated>
    <published>2025-02-04T01:30:06Z</published>
    <title>Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World
  Spatial Reasoning Questions</title>
    <summary>  Spatial reasoning remains a challenge for Large Language Models (LLMs), which
struggle with spatial data retrieval and reasoning. We propose Spatial
Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to
spatial tasks by integrating sparse spatial retrieval (spatial databases) and
dense semantic retrieval (LLM-based similarity). A multi-objective ranking
strategy balances spatial constraints and semantic relevance, while an
LLM-guided generator ensures coherent responses. Experiments on a real-world
tourism dataset show that Spatial-RAG significantly improves spatial question
answering, bridging the gap between LLMs and spatial intelligence.
</summary>
    <author>
      <name>Dazhou Yu</name>
    </author>
    <author>
      <name>Riyang Bao</name>
    </author>
    <author>
      <name>Gengchen Mai</name>
    </author>
    <author>
      <name>Liang Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2502.18470v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18470v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.01003v1</id>
    <updated>2025-03-02T19:59:41Z</updated>
    <published>2025-03-02T19:59:41Z</published>
    <title>A Semantic Search Pipeline for Causality-driven Adhoc Information
  Retrieval</title>
    <summary>  We present a unsupervised semantic search pipeline for the Causality-driven
Adhoc Information Retrieval (CAIR-2021) shared task. The CAIR shared task
expands traditional information retrieval to support the retrieval of documents
containing the likely causes of a query event. A successful system must be able
to distinguish between topical documents and documents containing causal
descriptions of events that are causally related to the query event. Our
approach involves aggregating results from multiple query strategies over a
semantic and lexical index. The proposed approach leads the CAIR-2021
leaderboard and outperformed both traditional IR and pure semantic
embedding-based approaches.
</summary>
    <author>
      <name>Dhairya Dalal</name>
    </author>
    <author>
      <name>Sharmi Dev Gupta</name>
    </author>
    <author>
      <name>Bentolhoda Binaei</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">FIRE.(2021)1246-1254</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2503.01003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.01003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.07025v1</id>
    <updated>2025-03-10T08:06:30Z</updated>
    <published>2025-03-10T08:06:30Z</published>
    <title>Weak Supervision for Improved Precision in Search Systems</title>
    <summary>  Labeled datasets are essential for modern search engines, which increasingly
rely on supervised learning methods like Learning to Rank and massive amounts
of data to power deep learning models. However, creating these datasets is both
time-consuming and costly, leading to the common use of user click and activity
logs as proxies for relevance. In this paper, we present a weak supervision
approach to infer the quality of query-document pairs and apply it within a
Learning to Rank framework to enhance the precision of a large-scale search
system.
</summary>
    <author>
      <name>Sriram Vasudevan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.07025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.07025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.12062v1</id>
    <updated>2025-03-15T09:27:59Z</updated>
    <published>2025-03-15T09:27:59Z</published>
    <title>Genicious: Contextual Few-shot Prompting for Insights Discovery</title>
    <summary>  Data and insights discovery is critical for decision-making in modern
organizations. We present Genicious, an LLM-aided interface that enables users
to interact with tabular datasets and ask complex queries in natural language.
By benchmarking various prompting strategies and language models, we have
developed an end-to-end tool that leverages contextual few-shot prompting,
achieving superior performance in terms of latency, accuracy, and scalability.
Genicious empowers stakeholders to explore, analyze and visualize their
datasets efficiently while ensuring data security through role-based access
control and a Text-to-SQL approach.
</summary>
    <author>
      <name>Vineet Kumar</name>
    </author>
    <author>
      <name>Ronald Tony</name>
    </author>
    <author>
      <name>Darshita Rathore</name>
    </author>
    <author>
      <name>Vipasha Rana</name>
    </author>
    <author>
      <name>Bhuvanesh Mandora</name>
    </author>
    <author>
      <name> Kanishka</name>
    </author>
    <author>
      <name>Chetna Bansal</name>
    </author>
    <author>
      <name>Anindya Moitra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3703323.3704274</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3703323.3704274" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, CODS-COMAD Dec 24, Jodhpur, India</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.12062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.12062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.14800v1</id>
    <updated>2025-03-19T00:24:01Z</updated>
    <published>2025-03-19T00:24:01Z</published>
    <title>Long Context Modeling with Ranked Memory-Augmented Retrieval</title>
    <summary>  Effective long-term memory management is crucial for language models handling
extended contexts. We introduce a novel framework that dynamically ranks memory
entries based on relevance. Unlike previous works, our model introduces a novel
relevance scoring and a pointwise re-ranking model for key-value embeddings,
inspired by learning-to-rank techniques in information retrieval. Enhanced
Ranked Memory Augmented Retrieval ERMAR achieves state-of-the-art results on
standard benchmarks.
</summary>
    <author>
      <name>Ghadir Alselwi</name>
    </author>
    <author>
      <name>Hao Xue</name>
    </author>
    <author>
      <name>Shoaib Jameel</name>
    </author>
    <author>
      <name>Basem Suleiman</name>
    </author>
    <author>
      <name>Flora D. Salim</name>
    </author>
    <author>
      <name>Imran Razzak</name>
    </author>
    <link href="http://arxiv.org/abs/2503.14800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.14800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510084v1</id>
    <updated>2005-10-26T14:49:47Z</updated>
    <published>2005-10-26T14:49:47Z</published>
    <title>Réflexions sur la question fréquentielle en traitement du signal</title>
    <summary>  New definitions are suggested for frequencies which may be instantaneous or
not. The Heisenberg-Gabor inequality and the Shannon sampling theorem are
briefly discussed.
</summary>
    <author>
      <name>Michel Fliess</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0510084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.0070v1</id>
    <updated>2008-07-01T05:29:07Z</updated>
    <published>2008-07-01T05:29:07Z</published>
    <title>Quantitative Paradigm of Software Reliability as Content Relevance</title>
    <summary>  This paper presents a quantitative approach to software reliability and
content relevance definitions validated by the systems' potential reliability
law.Thus it is argued for the unified math nature or quantitative paradigm of
software reliability and content relevance.
</summary>
    <author>
      <name>Yuri Arkhipkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.0070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.0070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.5; D.2.8; D.2.9; H.3.1; D.1.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3183v2</id>
    <updated>2011-07-01T17:08:12Z</updated>
    <published>2010-04-19T13:11:56Z</published>
    <title>Statistical Physics for Natural Language Processing</title>
    <summary>  This paper has been withdrawn by the author.
</summary>
    <author>
      <name>Juan-Manuel Torres Moreno</name>
    </author>
    <author>
      <name>Silvia Fernandez</name>
    </author>
    <author>
      <name>Eric SanJuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3183v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3183v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1615v1</id>
    <updated>2012-04-07T09:28:19Z</updated>
    <published>2012-04-07T09:28:19Z</published>
    <title>Discrimination between Arabic and Latin from bilingual documents</title>
    <summary>  2011 International Conference on Communications, Computing and Control
Applications (CCCA)
</summary>
    <author>
      <name>Sofiene Haboubi</name>
    </author>
    <author>
      <name>Samia Maddouri</name>
    </author>
    <author>
      <name>Hamid Amiri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CCCA.2011.6031496</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CCCA.2011.6031496" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7917v1</id>
    <updated>2012-10-30T07:25:46Z</updated>
    <published>2012-10-30T07:25:46Z</published>
    <title>The Model of Semantic Concepts Lattice For Data Mining Of Microblogs</title>
    <summary>  The model of semantic concept lattice for data mining of microblogs has been
proposed in this work. It is shown that the use of this model is effective for
the semantic relations analysis and for the detection of associative rules of
key words.
</summary>
    <author>
      <name>Bohdan Pavlyshenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Ukrainian</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.7917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08402v1</id>
    <updated>2016-04-28T13:11:54Z</updated>
    <published>2016-04-28T13:11:54Z</published>
    <title>Two Differentially Private Rating Collection Mechanisms for Recommender
  Systems</title>
    <summary>  We design two mechanisms for the recommender system to collect user ratings.
One is modified Laplace mechanism, and the other is randomized response
mechanism. We prove that they are both differentially private and preserve the
data utility.
</summary>
    <author>
      <name>Wenjie Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02696v1</id>
    <updated>2016-12-08T15:25:35Z</updated>
    <published>2016-12-08T15:25:35Z</published>
    <title>A note on the triangle inequality for the Jaccard distance</title>
    <summary>  Two simple proofs of the triangle inequality for the Jaccard distance in
terms of nonnegative, monotone, submodular functions are given and discussed.
</summary>
    <author>
      <name>Sven Kosub</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02696v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02696v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.13301v1</id>
    <updated>2020-10-26T03:16:54Z</updated>
    <published>2020-10-26T03:16:54Z</published>
    <title>Scalable Bayesian Optimization with Sparse Gaussian Process Models</title>
    <summary>  This thesis focuses on Bayesian optimization with the improvements coming
from two aspects:(i) the use of derivative information to accelerate the
optimization convergence; and (ii) the consideration of scalable GPs for
handling massive data.
</summary>
    <author>
      <name>Ang Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.13301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.13301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.15683v1</id>
    <updated>2024-12-13T20:09:27Z</updated>
    <published>2024-12-13T20:09:27Z</published>
    <title>Results of the 2024 Video Browser Showdown</title>
    <summary>  This report presents the results of the 13th Video Browser Showdown, held at
the 2024 International Conference on Multimedia Modeling on the 29th of January
2024 in Amsterdam, the Netherlands.
</summary>
    <author>
      <name>Luca Rossetto</name>
    </author>
    <author>
      <name>Klaus Schoeffmann</name>
    </author>
    <author>
      <name>Cathal Gurrin</name>
    </author>
    <author>
      <name>Jakub Lokoč</name>
    </author>
    <author>
      <name>Werner Bailer</name>
    </author>
    <link href="http://arxiv.org/abs/2502.15683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.15683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205022v1</id>
    <updated>2002-05-14T19:25:07Z</updated>
    <published>2002-05-14T19:25:07Z</published>
    <title>The Traits of the Personable</title>
    <summary>  Information personalization is fertile ground for application of AI
techniques. In this article I relate personalization to the ability to capture
partial information in an information-seeking interaction. The specific focus
is on personalizing interactions at web sites. Using ideas from partial
evaluation and explanation-based generalization, I present a modeling
methodology for reasoning about personalization. This approach helps identify
seven tiers of `personable traits' in web sites.
</summary>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0205022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.5; H.4.2; H.5.4; I.2.6; K.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504074v1</id>
    <updated>2005-04-15T20:10:53Z</updated>
    <published>2005-04-15T20:10:53Z</published>
    <title>Metalinguistic Information Extraction for Terminology</title>
    <summary>  This paper describes and evaluates the Metalinguistic Operation Processor
(MOP) system for automatic compilation of metalinguistic information from
technical and scientific documents. This system is designed to extract
non-standard terminological resources that we have called Metalinguistic
Information Databases (or MIDs), in order to help update changing glossaries,
knowledge bases and ontologies, as well as to reflect the metastable dynamics
of special-domain knowledge.
</summary>
    <author>
      <name>Carlos Rodriguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at CompuTerm 2004, COLING. Geneve</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0504074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512007v1</id>
    <updated>2005-12-01T15:40:19Z</updated>
    <published>2005-12-01T15:40:19Z</published>
    <title>Entangled messages</title>
    <summary>  It is sometimes necessary to send copies of the same email to different
parties, but it is impossible to ensure that if one party reads the message the
other parties will bound to read it. We propose an entanglement based scheme
where if one party reads the message the other party will bound to read it
simultaneously.
</summary>
    <author>
      <name>Arindam Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PDF, 2 Pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0512007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611150v3</id>
    <updated>2006-12-05T15:04:52Z</updated>
    <published>2006-11-29T13:59:31Z</published>
    <title>A Novel Bayesian Classifier using Copula Functions</title>
    <summary>  A useful method for representing Bayesian classifiers is through
\emph{discriminant functions}. Here, using copula functions, we propose a new
model for discriminants. This model provides a rich and generalized class of
decision boundaries. These decision boundaries significantly boost the
classification accuracy especially for high dimensional feature spaces. We
strengthen our analysis through simulation results.
</summary>
    <author>
      <name>Saket Sathe</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0611150v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611150v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.0386v1</id>
    <updated>2008-01-02T13:06:37Z</updated>
    <published>2008-01-02T13:06:37Z</published>
    <title>Spam: It's Not Just for Inboxes and Search Engines! Making Hirsch
  h-index Robust to Scientospam</title>
    <summary>  What is the 'level of excellence' of a scientist and the real impact of
his/her work upon the scientific thinking and practising? How can we design a
fair, an unbiased metric -- and most importantly -- a metric robust to
manipulation?
</summary>
    <author>
      <name>Dimitrios Katsaros</name>
    </author>
    <author>
      <name>Leonidas Akritidis</name>
    </author>
    <author>
      <name>Panayiotis Bozanis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.0386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.0386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3746v1</id>
    <updated>2008-02-26T05:22:30Z</updated>
    <published>2008-02-26T05:22:30Z</published>
    <title>Information Hiding Techniques: A Tutorial Review</title>
    <summary>  The purpose of this tutorial is to present an overview of various information
hiding techniques. A brief history of steganography is provided along with
techniques that were used to hide information. Text, image and audio based
information hiding techniques are discussed. This paper also provides a basic
introduction to digital watermarking.
</summary>
    <author>
      <name>Sabu M. Thampi</name>
    </author>
    <link href="http://arxiv.org/abs/0802.3746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3006v1</id>
    <updated>2008-07-18T16:42:57Z</updated>
    <published>2008-07-18T16:42:57Z</published>
    <title>The rank convergence of HITS can be slow</title>
    <summary>  We prove that HITS, to "get right" h of the top k ranked nodes of an N&gt;=2k
node graph, can require h^(Omega(N h/k)) iterations (i.e. a substantial Omega(N
h log(h)/k) matrix multiplications even with a "squaring trick"). Our proof
requires no algebraic tools and is entirely self-contained.
</summary>
    <author>
      <name>Enoch Peserico</name>
    </author>
    <author>
      <name>Luca Pretto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure. Keywords: algorithm analysis, information
  retrieval, rank convergence</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.3006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.0056v1</id>
    <updated>2008-08-01T04:45:17Z</updated>
    <published>2008-08-01T04:45:17Z</published>
    <title>I'm sorry to say, but your understanding of image processing
  fundamentals is absolutely wrong</title>
    <summary>  The ongoing discussion whether modern vision systems have to be viewed as
visually-enabled cognitive systems or cognitively-enabled vision systems is
groundless, because perceptual and cognitive faculties of vision are separate
components of human (and consequently, artificial) information processing
system modeling.
</summary>
    <author>
      <name>Emanuel Diamant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published as chapter 5 in "Frontiers in Brain, Vision and AI",
  I-TECH Publisher, Viena, 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.0056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.0056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.1250v1</id>
    <updated>2008-11-08T23:23:08Z</updated>
    <published>2008-11-08T23:23:08Z</published>
    <title>Adaptive Base Class Boost for Multi-class Classification</title>
    <summary>  We develop the concept of ABC-Boost (Adaptive Base Class Boost) for
multi-class classification and present ABC-MART, a concrete implementation of
ABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has
been very successful in large-scale applications. For binary classification,
ABC-MART recovers MART. For multi-class classification, ABC-MART considerably
improves MART, as evaluated on several public data sets.
</summary>
    <author>
      <name>Ping Li</name>
    </author>
    <link href="http://arxiv.org/abs/0811.1250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.1250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4530v2</id>
    <updated>2009-04-12T05:12:19Z</updated>
    <published>2009-03-26T08:39:45Z</published>
    <title>Nonnegative approximations of nonnegative tensors</title>
    <summary>  We study the decomposition of a nonnegative tensor into a minimal sum of
outer product of nonnegative vectors and the associated parsimonious naive
Bayes probabilistic model. We show that the corresponding approximation
problem, which is central to nonnegative PARAFAC, will always have optimal
solutions. The result holds for any choice of norms and, under a mild
assumption, even Bregman divergences.
</summary>
    <author>
      <name>Lek-Heng Lim</name>
    </author>
    <author>
      <name>Pierre Comon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.4530v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4530v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2; G.1.6; G.3; I.2.6; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0932v1</id>
    <updated>2009-08-06T18:52:41Z</updated>
    <published>2009-08-06T18:52:41Z</published>
    <title>The Medical Algorithms Project</title>
    <summary>  The Medical Algorithms Project, a web-based resource located at
www.medal.org, is the world's largest collection of medical-related
spreadsheets, consisting of over 13,500 Excel spreadsheets each encoding a
medical algorithm from 45 different areas of medical practice. This free
resource is in use worldwide with over 106,000 registered users as of March 1,
2009.
</summary>
    <author>
      <name>M. Sriram Iyengar</name>
    </author>
    <author>
      <name>John R. Svirbely</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages, 2 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 113-118
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0700v1</id>
    <updated>2010-01-05T13:06:21Z</updated>
    <published>2010-01-05T13:06:21Z</published>
    <title>Vandalism Detection in Wikipedia: a Bag-of-Words Classifier Approach</title>
    <summary>  A bag-of-words based probabilistic classifier is trained using regularized
logistic regression to detect vandalism in the English Wikipedia. Isotonic
regression is used to calibrate the class membership probabilities. Learning
curve, reliability, ROC, and cost analysis are performed.
</summary>
    <author>
      <name>Amit Belani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7; G.3; K.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0363v1</id>
    <updated>2011-07-28T17:46:20Z</updated>
    <published>2011-07-28T17:46:20Z</published>
    <title>Typesafe Modeling in Text Mining</title>
    <summary>  Based on the concept of annotation-based agents, this report introduces tools
and a formal notation for defining and running text mining experiments using a
statically typed domain-specific language embedded in Scala. Using machine
learning for classification as an example, the framework is used to develop and
document text mining experiments, and to show how the concept of generic,
typesafe annotation corresponds to a general information model that goes beyond
text processing.
</summary>
    <author>
      <name>Fabian Steeg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">63 pages, in German</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.0363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4; I.2.5; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2261v1</id>
    <updated>2012-01-11T08:37:50Z</updated>
    <published>2012-01-11T08:37:50Z</published>
    <title>Relationships in Large-Scale Graph Computing</title>
    <summary>  In 2009 Grzegorz Czajkowski from Google's system infrastructure team has
published an article which didn't get much attention in the SEO community at
the time. It was titled "Large-scale graph computing at Google" and gave an
excellent insight into the future of Google's search. This article highlights
some of the little known facts which lead to transformation of Google's
algorithm in the last two years.
</summary>
    <author>
      <name>Dan Petrovic</name>
    </author>
    <link href="http://arxiv.org/abs/1201.2261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6158v1</id>
    <updated>2012-02-28T09:56:43Z</updated>
    <published>2012-02-28T09:56:43Z</published>
    <title>Optimized on-line computation of PageRank algorithm</title>
    <summary>  In this paper we present new ideas to accelerate the computation of the
eigenvector of the transition matrix associated to the PageRank algorithm. New
ideas are based on the decomposition of the matrix-vector product that can be
seen as a fluid diffusion model, associated to new algebraic equations. We show
through experiments on synthetic data and on real data-sets how much this
approach can improve the computation efficiency.
</summary>
    <author>
      <name>Dohy Hong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.6158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2; F.2.2; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0249v1</id>
    <updated>2012-09-03T06:00:04Z</updated>
    <published>2012-09-03T06:00:04Z</published>
    <title>Robopinion: Opinion Mining Framework Inspired by Autonomous Robot
  Navigation</title>
    <summary>  Data association methods are used by autonomous robots to find matches
between the current landmarks and the new set of observed features. We seek a
framework for opinion mining to benefit from advancements in autonomous robot
navigation in both research and development
</summary>
    <author>
      <name>M. A. El-Dosuky</name>
    </author>
    <author>
      <name>M. Z. Rashad</name>
    </author>
    <author>
      <name>T. T. Hamza</name>
    </author>
    <author>
      <name>A. H. EL-Bassiouny</name>
    </author>
    <link href="http://arxiv.org/abs/1209.0249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1483v1</id>
    <updated>2012-09-07T10:29:35Z</updated>
    <published>2012-09-07T10:29:35Z</published>
    <title>Underspecified Scientific Claims in Nanopublications</title>
    <summary>  The application range of nanopublications --- small entities of scientific
results in RDF representation --- could be greatly extended if complete formal
representations are not mandatory. To that aim, we present an approach to
represent and interlink scientific claims in an underspecified way, based on
independent English sentences.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <author>
      <name>Michael Krauthammer</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Web of Linked Entities Workshop (WoLE 2012),
  CEUR Workshop Proceedings, Volume 906, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2097v1</id>
    <updated>2012-09-07T10:27:48Z</updated>
    <published>2012-09-07T10:27:48Z</published>
    <title>Semantic web applications with regard to math and environment</title>
    <summary>  The following is an outline of possible strategies in using semantic web
techniques and math with regard to environmental issues. The article uses
concrete examples and applications and provides partially a rather basic
treatment of semantic web techniques and math in order to adress a broader
audience.
</summary>
    <author>
      <name>Nadja Kutz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.2097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00A-xx, 06-xx, 90C-xx, 65K05, 94A-xx, 94C-xx, 97Bxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.6; D.2.12; D.3; E.m; G.m; H.3; H.5; J.2; J.6; K.3.m; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2433v2</id>
    <updated>2012-10-06T22:38:57Z</updated>
    <published>2012-09-11T20:26:48Z</published>
    <title>Correlations between Google search data and Mortality Rates</title>
    <summary>  Inspired by correlations recently discovered between Google search data and
financial markets, we show correlations between Google search data mortality
rates. Words with negative connotations may provide for increased mortality
rates, while words with positive connotations may provide for decreased
mortality rates, and so statistical methods were employed to determine to
investigate further.
</summary>
    <author>
      <name>James Risk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.2433v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2433v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4471v1</id>
    <updated>2012-09-20T09:21:29Z</updated>
    <published>2012-09-20T09:21:29Z</published>
    <title>Stemmer for Serbian language</title>
    <summary>  In linguistic morphology and information retrieval, stemming is the process
for reducing inflected (or sometimes derived) words to their stem, base or root
form; generally a written word form. In this work is presented suffix stripping
stemmer for Serbian language, one of the highly inflectional languages.
</summary>
    <author>
      <name>Nikola Milošević</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures, code included</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0317v1</id>
    <updated>2013-07-01T10:03:58Z</updated>
    <published>2013-07-01T10:03:58Z</published>
    <title>Algorithms of the LDA model [REPORT]</title>
    <summary>  We review three algorithms for Latent Dirichlet Allocation (LDA). Two of them
are variational inference algorithms: Variational Bayesian inference and Online
Variational Bayesian inference and one is Markov Chain Monte Carlo (MCMC)
algorithm -- Collapsed Gibbs sampling. We compare their time complexity and
performance. We find that online variational Bayesian inference is the fastest
algorithm and still returns reasonably good results.
</summary>
    <author>
      <name>Jaka Špeh</name>
    </author>
    <author>
      <name>Andrej Muhič</name>
    </author>
    <author>
      <name>Jan Rupnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, report</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3808v1</id>
    <updated>2013-10-14T19:49:34Z</updated>
    <published>2013-10-14T19:49:34Z</published>
    <title>Pennants for Descriptors</title>
    <summary>  We present a new technique (called pennants) for displaying the descriptors
related to a descriptor across literatures, rather in a thesaurus. It has
definite implications for online searching and browsing. Pennants, named for
the flag they resemble, are a form of algorithmic prediction. Their cognitive
base is in relevance theory (RT) from linguistic pragmatics (Sperber &amp; Wilson
1995).
</summary>
    <author>
      <name>Howard D. White</name>
    </author>
    <author>
      <name>Philipp Mayr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, paper presented at the NKOS workshop at TPDL 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0543v1</id>
    <updated>2014-02-03T23:09:28Z</updated>
    <published>2014-02-03T23:09:28Z</published>
    <title>How Does Latent Semantic Analysis Work? A Visualisation Approach</title>
    <summary>  By using a small example, an analogy to photographic compression, and a
simple visualization using heatmaps, we show that latent semantic analysis
(LSA) is able to extract what appears to be semantic meaning of words from a
set of documents by blurring the distinctions between the words.
</summary>
    <author>
      <name>Jan Koeman</name>
    </author>
    <author>
      <name>William Rea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.0543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3610v1</id>
    <updated>2014-04-11T02:33:17Z</updated>
    <published>2014-04-11T02:33:17Z</published>
    <title>Targeting HIV-related Medication Side Effects and Sentiment Using
  Twitter Data</title>
    <summary>  We present a descriptive analysis of Twitter data. Our study focuses on
extracting the main side effects associated with HIV treatments. The crux of
our work was the identification of personal tweets referring to HIV. We
summarize our results in an infographic aimed at the general public. In
addition, we present a measure of user sentiment based on hand-rated tweets.
</summary>
    <author>
      <name>Cosme Adrover</name>
    </author>
    <author>
      <name>Todd Bodnar</name>
    </author>
    <author>
      <name>Marcel Salathe</name>
    </author>
    <link href="http://arxiv.org/abs/1404.3610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.3287v3</id>
    <updated>2015-02-18T19:44:24Z</updated>
    <published>2014-06-12T17:01:10Z</published>
    <title>A Clustering Analysis of Tweet Length and its Relation to Sentiment</title>
    <summary>  Sentiment analysis of Twitter data is performed. The researcher has made the
following contributions via this paper: (1) an innovative method for deriving
sentiment score dictionaries using an existing sentiment dictionary as seed
words is explored, and (2) an analysis of clustered tweet sentiment scores
based on tweet length is performed.
</summary>
    <author>
      <name>Matthew Mayo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.3287v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.3287v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04412v1</id>
    <updated>2015-07-15T23:13:48Z</updated>
    <published>2015-07-15T23:13:48Z</published>
    <title>Bridge the gap between network-based inference method and global ranking
  method in personal recommendation</title>
    <summary>  In this paper, we study the relationship between the network-based inference
method and global ranking method in personal recommendation. By some
theoretical analysis, we prove that the recommendation result under the global
ranking method is the limit of applying network-based inference method with
infinity times.
</summary>
    <author>
      <name>Xiwei Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.08800v1</id>
    <updated>2016-02-29T02:40:05Z</updated>
    <published>2016-02-29T02:40:05Z</published>
    <title>Iterative Aggregation Method for Solving Principal Component Analysis
  Problems</title>
    <summary>  Motivated by the previously developed multilevel aggregation method for
solving structural analysis problems a novel two-level aggregation approach for
efficient iterative solution of Principal Component Analysis (PCA) problems is
proposed. The course aggregation model of the original covariance matrix is
used in the iterative solution of the eigenvalue problem by a power iterations
method. The method is tested on several data sets consisting of large number of
text documents.
</summary>
    <author>
      <name>Vitaly Bulgakov</name>
    </author>
    <link href="http://arxiv.org/abs/1602.08800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.08800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06664v1</id>
    <updated>2016-08-23T22:44:42Z</updated>
    <published>2016-08-23T22:44:42Z</published>
    <title>Topic Grids for Homogeneous Data Visualization</title>
    <summary>  We propose the topic grids to detect anomaly and analyze the behavior based
on the access log content. Content-based behavioral risk is quantified in the
high dimensional space where the topics are generated from the log. The topics
are being projected homogeneously into a space that is perception- and
interaction-friendly to the human experts.
</summary>
    <author>
      <name>Shih-Chieh Su</name>
    </author>
    <author>
      <name>Joseph Vaughn</name>
    </author>
    <author>
      <name>Jean-Laurent Huynh</name>
    </author>
    <link href="http://arxiv.org/abs/1608.06664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00872v1</id>
    <updated>2016-11-03T03:53:25Z</updated>
    <published>2016-11-03T03:53:25Z</published>
    <title>A Decision Support System for Inbound Marketers: An Empirical Use of
  Latent Dirichlet Allocation Topic Model to Guide Infographic Designers</title>
    <summary>  Infographic is a type of information presentation that inbound marketers use.
I suggest a method that can allow the infographic designers to benchmark their
design against the previous viral infographics to measure whether a given
design decision can help or hurt the probability of the design becoming viral.
</summary>
    <author>
      <name>Meisam Hejazi Nia</name>
    </author>
    <link href="http://arxiv.org/abs/1611.00872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08511v1</id>
    <updated>2017-01-30T08:37:25Z</updated>
    <published>2017-01-30T08:37:25Z</published>
    <title>Binary adaptive embeddings from order statistics of random projections</title>
    <summary>  We use some of the largest order statistics of the random projections of a
reference signal to construct a binary embedding that is adapted to signals
correlated with such signal. The embedding is characterized from the analytical
standpoint and shown to provide improved performance on tasks such as
classification in a reduced-dimensionality space.
</summary>
    <author>
      <name>Diego Valsesia</name>
    </author>
    <author>
      <name>Enrico Magli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2016.2639036</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2016.2639036" rel="related"/>
    <link href="http://arxiv.org/abs/1701.08511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1808.03967v1</id>
    <updated>2018-08-12T16:32:18Z</updated>
    <published>2018-08-12T16:32:18Z</published>
    <title>Augmenting word2vec with latent Dirichlet allocation within a clinical
  application</title>
    <summary>  This paper presents three hybrid models that directly combine latent
Dirichlet allocation and word embedding for distinguishing between speakers
with and without Alzheimer's disease from transcripts of picture descriptions.
Two of our models get F-scores over the current state-of-the-art using
automatic methods on the DementiaBank dataset.
</summary>
    <author>
      <name>Akshay Budhkar</name>
    </author>
    <author>
      <name>Frank Rudzicz</name>
    </author>
    <link href="http://arxiv.org/abs/1808.03967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.03967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1810.01482v1</id>
    <updated>2018-10-02T20:02:20Z</updated>
    <published>2018-10-02T20:02:20Z</published>
    <title>Diversifying Music Recommendations</title>
    <summary>  We compare submodular and Jaccard methods to diversify Amazon Music
recommendations. Submodularity significantly improves recommendation quality
and user engagement. Unlike the Jaccard method, our submodular approach
incorporates item relevance score within its optimization function, and
produces a relevant and uniformly diverse set.
</summary>
    <author>
      <name>Houssam Nassif</name>
    </author>
    <author>
      <name>Kemal Oral Cansizlar</name>
    </author>
    <author>
      <name>Mitchell Goodman</name>
    </author>
    <author>
      <name>SVN Vishwanathan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning for Music Discovery Workshop at the 33rd
  International Conference on Machine Learning (ICML'16), New York, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1810.01482v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1810.01482v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0007v2</id>
    <updated>2014-12-07T23:36:54Z</updated>
    <published>2014-11-27T22:52:53Z</published>
    <title>Paradigm shifts. Part I. Collagen. Confirming and complementing the work
  of Henry Small</title>
    <summary>  The paradigm shift in collagen research during the early 1970s marked by the
discovery of the collagen precursor molecule procollagen was traced using
co-citation analysis and title word frequency determination, confirming
previous work performed by Henry Small.
</summary>
    <author>
      <name>Johannes Stegmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, 3 tables, corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.0007v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0007v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2416v2</id>
    <updated>2014-12-09T17:22:04Z</updated>
    <published>2014-12-07T23:51:35Z</published>
    <title>Paradigm shifts. Part II. Reverse Transcriptase. Analysis of reference
  stability and word frequencies</title>
    <summary>  The reverse transcription paradigm shift in RNA tumor virus research marked
by the discovery of the reverse transcriptase in 1970 was traced using
co-citation and title word frequency analysis. It is shown that this event is
associated with a break in citation patterns and the occurrence of previously
unknown technical terms.
</summary>
    <author>
      <name>Johannes Stegmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 tables, 1 figure, corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.2416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05240v1</id>
    <updated>2015-05-20T04:09:47Z</updated>
    <published>2015-05-20T04:09:47Z</published>
    <title>Benchmarking KAZE and MCM for Multiclass Classification</title>
    <summary>  In this paper, we propose a novel approach for feature generation by
appropriately fusing KAZE and SIFT features. We then use this feature set along
with Minimal Complexity Machine(MCM) for object classification. We show that
KAZE and SIFT features are complementary. Experimental results indicate that an
elementary integration of these techniques can outperform the state-of-the-art
approaches.
</summary>
    <author>
      <name>Siddharth Srivastava</name>
    </author>
    <author>
      <name>Prerana Mukherjee</name>
    </author>
    <author>
      <name>Brejesh Lall</name>
    </author>
    <link href="http://arxiv.org/abs/1505.05240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7; I.5.4; I.4.8; I.4.9; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1803.05337v1</id>
    <updated>2018-03-13T15:58:58Z</updated>
    <published>2018-03-13T15:58:58Z</published>
    <title>Learning to Recognize Musical Genre from Audio</title>
    <summary>  We here summarize our experience running a challenge with open data for
musical genre recognition. Those notes motivate the task and the challenge
design, show some statistics about the submissions, and present the results.
</summary>
    <author>
      <name>Michaël Defferrard</name>
    </author>
    <author>
      <name>Sharada P. Mohanty</name>
    </author>
    <author>
      <name>Sean F. Carroll</name>
    </author>
    <author>
      <name>Marcel Salathé</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to WWW'18 after challenge round-1</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.05337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.05337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02945v2</id>
    <updated>2016-05-11T17:20:26Z</updated>
    <published>2016-05-10T11:29:28Z</published>
    <title>The Yahoo Query Treebank, V. 1.0</title>
    <summary>  A description and annotation guidelines for the Yahoo Webscope release of
Query Treebank, Version 1.0, May 2016.
</summary>
    <author>
      <name>Yuval Pinter</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <author>
      <name>Idan Szpektor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Co-released with the Webscope Dataset (L-28) and with Pinter et al.,
  Syntactic Parsing of Web Queries with Question Intent, NAACL-HLT 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02945v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02945v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2001.04326v1</id>
    <updated>2020-01-13T15:08:10Z</updated>
    <published>2020-01-13T15:08:10Z</published>
    <title>Merging of Ontologies Through Merging of Their Rules</title>
    <summary>  Ontology merging is important, but not always effective. The main reason, why
ontology merging is not effective, is that ontology merging is performed
without considering goals. Goals define the way, in which ontologies to be
merged more effectively. The paper illustrates ontology merging by means of
rules, which are generated from these ontologies. This is necessary for further
use in expert systems.
</summary>
    <author>
      <name>Olegs Verhodubs</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2004.07171v1</id>
    <updated>2020-04-15T15:56:45Z</updated>
    <published>2020-04-15T15:56:45Z</published>
    <title>Musical Features for Automatic Music Transcription Evaluation</title>
    <summary>  This technical report gives a detailed, formal description of the features
introduced in the paper: Adrien Ycart, Lele Liu, Emmanouil Benetos and Marcus
T. Pearce. "Investigating the Perceptual Validity of Evaluation Metrics for
Automatic Piano Music Transcription", Transactions of the International Society
for Music Information Retrieval (TISMIR), Accepted, 2020.
</summary>
    <author>
      <name>Adrien Ycart</name>
    </author>
    <author>
      <name>Lele Liu</name>
    </author>
    <author>
      <name>Emmanouil Benetos</name>
    </author>
    <author>
      <name>Marcus T. Pearce</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/2004.07171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2004.07171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2005.09617v2</id>
    <updated>2020-05-20T14:09:11Z</updated>
    <published>2020-05-19T17:46:34Z</published>
    <title>Unlocking New York City Crime Insights using Relational Database
  Embeddings</title>
    <summary>  This version withdrawn by arXiv administrators because the author did not
have the right to agree to our license at the time of submission.
</summary>
    <author>
      <name>Apoorva Nitsure</name>
    </author>
    <author>
      <name>Rajesh Bordawekar</name>
    </author>
    <author>
      <name>Jose Neves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: This version withdrawn by arXiv administrators
  because the author did not have the right to agree to our license at the time
  of submission</arxiv:comment>
    <link href="http://arxiv.org/abs/2005.09617v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2005.09617v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1908.06318v1</id>
    <updated>2019-08-17T16:54:40Z</updated>
    <published>2019-08-17T16:54:40Z</published>
    <title>Comparison-Based Indexing From First Principles</title>
    <summary>  Basic assumptions about comparison-based indexing are laid down and a general
design space is derived from these. An index structure spanning this design
space (the sprawl) is described, along with an associated family of
partitioning predicates, or regions (the ambits), as well as algorithms for
search and, to some extent, construction. The sprawl of ambits forms a
unification and generalization of current indexing methods, and a jumping-off
point for future designs.
</summary>
    <author>
      <name>Magnus Lie Hetland</name>
    </author>
    <link href="http://arxiv.org/abs/1908.06318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2002.06450v1</id>
    <updated>2020-02-15T21:05:07Z</updated>
    <published>2020-02-15T21:05:07Z</published>
    <title>Supervised Phrase-boundary Embeddings</title>
    <summary>  We propose a new word embedding model, called SPhrase, that incorporates
supervised phrase information. Our method modifies traditional word embeddings
by ensuring that all target words in a phrase have exactly the same context. We
demonstrate that including this information within a context window produces
superior embeddings for both intrinsic evaluation tasks and downstream
extrinsic tasks.
</summary>
    <author>
      <name>Manni Singh</name>
    </author>
    <author>
      <name>David Weston</name>
    </author>
    <author>
      <name>Mark Levene</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2010.09495v1</id>
    <updated>2020-10-15T19:40:35Z</updated>
    <published>2020-10-15T19:40:35Z</published>
    <title>Blending Search and Discovery: Tag-Based Query Refinement with
  Contextual Reinforcement Learning</title>
    <summary>  We tackle tag-based query refinement as a mobile-friendly alternative to
standard facet search. We approach the inference challenge with reinforcement
learning, and propose a deep contextual bandit that can be efficiently scaled
in a multi-tenant SaaS scenario.
</summary>
    <author>
      <name>Bingqing Yu</name>
    </author>
    <author>
      <name>Jacopo Tagliabue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted at EComNLP 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2010.09495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2010.09495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.08042v1</id>
    <updated>2021-06-15T10:52:07Z</updated>
    <published>2021-06-15T10:52:07Z</published>
    <title>Hotel Recognition via Latent Image Embedding</title>
    <summary>  We approach the problem of hotel recognition with deep metric learning. We
overview the existing approaches and propose a modification to Contrastive loss
called Contrastive-Triplet loss. We construct a robust pipeline for
benchmarking metric learning models and perform experiments on Hotels-50K and
CUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval
on Hotels-50k. We open-source our code.
</summary>
    <author>
      <name>Boris Tseytlin</name>
    </author>
    <author>
      <name>Ilya Makarov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IWANN 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2106.08042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2106.08042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2201.06523v1</id>
    <updated>2022-01-17T16:57:53Z</updated>
    <published>2022-01-17T16:57:53Z</published>
    <title>Patterns of near-crash events in a naturalistic driving dataset:
  applying rules mining</title>
    <summary>  This study aims to explore the associations between near-crash events and
road geometry and trip features by investigating a naturalistic driving dataset
and a corresponding roadway inventory dataset using an association rule mining
method.
</summary>
    <author>
      <name>Xiaoqiang Kong</name>
    </author>
    <author>
      <name>Subasish Das</name>
    </author>
    <author>
      <name>Hongmin Zhou</name>
    </author>
    <author>
      <name>Yunlong Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.aap.2021.106346</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.aap.2021.106346" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Accident Analysis &amp; Prevention (2021)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2201.06523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2201.06523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.01178v1</id>
    <updated>2022-01-29T20:05:28Z</updated>
    <published>2022-01-29T20:05:28Z</published>
    <title>Information Extraction through AI techniques: The KIDs use case at
  CONSOB</title>
    <summary>  In this paper we report on the initial activities carried out within a
collaboration between Consob and Sapienza University. We focus on Information
Extraction from documents describing financial instruments. We discuss how we
automate this task, via both rule-based and machine learning-based methods and
provide our first results.
</summary>
    <author>
      <name>Domenico Lembo</name>
    </author>
    <author>
      <name>Alessandra Limosani</name>
    </author>
    <author>
      <name>Francesca Medda</name>
    </author>
    <author>
      <name>Alessandra Monaco</name>
    </author>
    <author>
      <name>Federico Maria Scafoglieri</name>
    </author>
    <link href="http://arxiv.org/abs/2202.01178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.01178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.08082v1</id>
    <updated>2022-02-16T14:09:15Z</updated>
    <published>2022-02-16T14:09:15Z</published>
    <title>Formulating Beurling LASSO for Source Separation via Proximal Gradient
  Iteration</title>
    <summary>  Beurling LASSO generalizes the LASSO problem to finite Radon measures
regularized via their total variation. Despite its theoretical appeal, this
space is hard to parametrize, which poses an algorithmic challenge. We propose
a formulation of continuous convolutional source separation with Beurling LASSO
that avoids the explicit computation of the measures and instead employs the
duality transform of the proximal mapping.
</summary>
    <author>
      <name>Sören Schulze</name>
    </author>
    <author>
      <name>Emily J. King</name>
    </author>
    <link href="http://arxiv.org/abs/2202.08082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2202.08082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1343v1</id>
    <updated>2013-06-06T08:56:32Z</updated>
    <published>2013-06-06T08:56:32Z</published>
    <title>The User Feedback on SentiWordNet</title>
    <summary>  With the release of SentiWordNet 3.0 the related Web interface has been
restyled and improved in order to allow users to submit feedback on the
SentiWordNet entries, in the form of the suggestion of alternative triplets of
values for an entry. This paper reports on the release of the user feedback
collected so far and on the plans for the future.
</summary>
    <author>
      <name>Andrea Esuli</name>
    </author>
    <link href="http://arxiv.org/abs/1306.1343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6944v1</id>
    <updated>2013-06-07T15:48:06Z</updated>
    <published>2013-06-07T15:48:06Z</published>
    <title>The DeLiVerMATH project - Text analysis in mathematics</title>
    <summary>  A high-quality content analysis is essential for retrieval functionalities
but the manual extraction of key phrases and classification is expensive.
Natural language processing provides a framework to automatize the process.
Here, a machine-based approach for the content analysis of mathematical texts
is described. A prototype for key phrase extraction and classification of
mathematical texts is presented.
</summary>
    <author>
      <name>Ulf Schöneberg</name>
    </author>
    <author>
      <name>Wolfram Sperber</name>
    </author>
    <link href="http://arxiv.org/abs/1306.6944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02781v1</id>
    <updated>2015-03-10T06:23:56Z</updated>
    <published>2015-03-10T06:23:56Z</published>
    <title>Unravelling Graph-Exchange File Formats</title>
    <summary>  A graph is used to represent data in which the relationships between the
objects in the data are at least as important as the objects themselves. Over
the last two decades nearly a hundred file formats have been proposed or used
to provide portable access to such data. This paper seeks to review these
formats, and provide some insight to both reduce the ongoing creation of
unnecessary formats, and guide the development of new formats where needed.
</summary>
    <author>
      <name>Matthew Roughan</name>
    </author>
    <author>
      <name>Jonathan Tuke</name>
    </author>
    <link href="http://arxiv.org/abs/1503.02781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
